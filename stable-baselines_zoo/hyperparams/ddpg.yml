MountainCarContinuous-v0:
  n_timesteps: 300000
  policy: 'MlpPolicy'
  noise_type: 'ornstein-uhlenbeck'
  noise_std: 0.5
  memory_limit: 5000

LunarLanderContinuous-v2:
  n_timesteps: !!float 6e5
  policy: 'MlpPolicy'
  noise_type: 'ornstein-uhlenbeck'
  noise_std: 0.1
  memory_limit: 50000

Pendulum-v0:
  n_timesteps: !!float 2e5
  policy: 'MlpPolicy'
  noise_type: 'ornstein-uhlenbeck'
  noise_std: 0.1
  memory_limit: 50000

# Tuned
BipedalWalker-v3:
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  noise_type: 'adaptive-param'
  noise_std: 0.287
  memory_limit: 100000
  normalize_observations: True
  normalize_returns: False
  gamma: 0.999
  actor_lr: !!float 0.000527
  batch_size: 256
  random_exploration: 0.0
  policy_kwargs: 'dict(layer_norm=True)'

# Tuned
HalfCheetahBulletEnv-v0:
  n_timesteps: !!float 2e6
  policy: 'LnMlpPolicy'
  gamma: 0.95
  memory_limit: 1000000
  noise_type: 'normal'
  noise_std: 0.22
  batch_size: 256
  normalize_observations: True
  normalize_returns: False

# Tuned
Walker2DBulletEnv-v0:
  n_timesteps: !!float 2e6
  policy: 'LnMlpPolicy'
  gamma: 0.95
  memory_limit: 1000000
  noise_type: 'normal'
  noise_std: 0.15
  batch_size: 128
  normalize_observations: True
  normalize_returns: True

# To be tuned
AntBulletEnv-v0:
  env_wrapper: utils.wrappers.TimeFeatureWrapper
  n_timesteps: !!float 2e6
  policy: 'MlpPolicy'
  gamma: 0.99
  memory_limit: 1000000
  noise_type: 'normal'
  noise_std: 0.22
  batch_size: 256
  normalize_observations: True
  normalize_returns: False

# To be tuned
HopperBulletEnv-v0:
  n_timesteps: !!float 2e6
  policy: 'MlpPolicy'
  gamma: 0.98
  memory_limit: 1000000
  noise_type: 'ornstein-uhlenbeck'
  noise_std: 0.652
  batch_size: 256
  actor_lr: 0.00156
  critic_lr: 0.00156
  normalize_observations: True
  normalize_returns: False


ReachingJaco-v1:
  n_timesteps: !!float 2e5
  policy: 'MlpPolicy'
  noise_type: 'ornstein-uhlenbeck'
  noise_std: 0.1
  memory_limit: 50000


widowx_reacher-v2:
  n_timesteps: !!float 2e5
  policy: 'MlpPolicy'
#   noise_type: 'ornstein-uhlenbeck'
#   noise_std: 0.1
#   memory_limit: 50000

# # tuned
# widowx_reacher-v2:
#   actor_lr: 0.0010561308249352115
#   batch_size: 64
#   critic_lr: 0.0010561308249352115
#   gamma: 0.98
#   memory_limit: 100000
#   n_timesteps: 200000.0
#   noise_std: 0.6404031783349042
#   noise_type: normal
#   normalize_observations: true
#   normalize_returns: true
#   policy: MlpPolicy


widowx_reacher-v12:
  n_timesteps: !!float 2e5
  policy: 'MlpPolicy'
#   noise_type: 'ornstein-uhlenbeck'
#   noise_std: 0.1
#   memory_limit: 50000

# # tuned
# widowx_reacher-v12:
#   actor_lr: 1.0066416439777964e-05
#   batch_size: 256
#   critic_lr: 1.0066416439777964e-05
#   gamma: 0.999
#   memory_limit: 100000
#   n_timesteps: 200000.0
#   noise_std: 0.4711262569121476
#   noise_type: adaptive-param
#   normalize_observations: true
#   normalize_returns: true
#   policy: MlpPolicy
#   policy_kwargs: dict(layer_norm=True)

# Defaults params
widowx_reacher-v5:
  n_timesteps: 500000
  policy: 'MlpPolicy'
  gamma: 0.99
  nb_train_steps: 50
  nb_rollout_steps: 100
  nb_eval_steps: 100
  normalize_observations: False
  tau: 0.001
  batch_size: 128
  param_noise_adaption_interval: 50
  normalize_returns: False
  enable_popart: False
  critic_l2_reg: 0.0
  actor_lr: 0.0001
  critic_lr: 0.001
  reward_scale: 1.0
  render: False
  render_eval: False
  buffer_size: 50000
  random_exploration: 0.0
  policy_kwargs: None

# PAPER
# widowx_reacher-v5:
#   n_timesteps: !!float 2e5
#   policy: 'MlpPolicy'
#   noise_type: 'ornstein-uhlenbeck'
#   noise_std: 0.1
#   memory_limit: 50000

# # tuned
# widowx_reacher-v5:
#   actor_lr: 0.0010561308249352115
#   batch_size: 64
#   critic_lr: 0.0010561308249352115
#   gamma: 0.98
#   memory_limit: 100000
#   n_timesteps: 200000.0
#   noise_std: 0.6404031783349042
#   noise_type: normal
#   normalize_observations: true
#   normalize_returns: true
#   policy: MlpPolicy



widowx_reacher-v7:
  n_timesteps: !!float 2e5
  policy: 'MlpPolicy'
#   noise_type: 'ornstein-uhlenbeck'
#   noise_std: 0.1
#   memory_limit: 50000

# # tuned
# widowx_reacher-v7:
#   actor_lr: 1.0066416439777964e-05
#   batch_size: 256
#   critic_lr: 1.0066416439777964e-05
#   gamma: 0.999
#   memory_limit: 100000
#   n_timesteps: 200000.0
#   noise_std: 0.4711262569121476
#   noise_type: adaptive-param
#   normalize_observations: true
#   normalize_returns: true
#   policy: MlpPolicy
#   policy_kwargs: dict(layer_norm=True)