--------------------------------------------------------------------------
WARNING: There was an error initializing an OpenFabrics device.

  Local host:   n295
  Local device: hfi1_0
--------------------------------------------------------------------------
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:141: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/sac/policies.py:194: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:232: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:294: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:314: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

========== widowx_reacher-v7 ==========
Seed: 0
OrderedDict([('n_timesteps', 60000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs', 'dict(layers=[256, 256])')])
Using 1 environments
Overwriting n_timesteps with n=500000
Creating test environment
TRAINING ENV TYPE :  <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f48f9bce4a8>
EVAL ENV TYPE :  <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f48f753ada0>
Log path: logs/train_0.5M_widowx_reacher-v7_KAY/sac/widowx_reacher-v7_1
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.94170123   |
| ent_coef_loss           | -0.6050052   |
| entropy                 | 7.868194     |
| ep_rewmean              | -0.946       |
| episodes                | 4            |
| eplenmean               | 100          |
| fps                     | 189          |
| mean 100 episode reward | -0.9         |
| n_updates               | 201          |
| policy_loss             | -6.5433807   |
| qf1_loss                | 0.0025502555 |
| qf2_loss                | 0.0018687866 |
| time_elapsed            | 1            |
| total timesteps         | 300          |
| value_loss              | 0.058045756  |
------------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.83520234 |
| ent_coef_loss           | -1.8173614 |
| entropy                 | 7.8992434  |
| ep_rewmean              | -1.67      |
| episodes                | 8          |
| eplenmean               | 100        |
| fps                     | 199        |
| mean 100 episode reward | -1.7       |
| n_updates               | 601        |
| policy_loss             | -11.77984  |
| qf1_loss                | 0.40741658 |
| qf2_loss                | 0.38459933 |
| time_elapsed            | 3          |
| total timesteps         | 700        |
| value_loss              | 0.0811948  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.74078953 |
| ent_coef_loss           | -3.0039139 |
| entropy                 | 7.8687     |
| ep_rewmean              | -1.39      |
| episodes                | 12         |
| eplenmean               | 100        |
| fps                     | 201        |
| mean 100 episode reward | -1.4       |
| n_updates               | 1001       |
| policy_loss             | -16.432854 |
| qf1_loss                | 0.06563477 |
| qf2_loss                | 0.07287982 |
| time_elapsed            | 5          |
| total timesteps         | 1100       |
| value_loss              | 0.11964999 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.6571865  |
| ent_coef_loss           | -4.2631416 |
| entropy                 | 7.97874    |
| ep_rewmean              | -1.37      |
| episodes                | 16         |
| eplenmean               | 100        |
| fps                     | 202        |
| mean 100 episode reward | -1.4       |
| n_updates               | 1401       |
| policy_loss             | -20.989826 |
| qf1_loss                | 1.566538   |
| qf2_loss                | 1.4826257  |
| time_elapsed            | 7          |
| total timesteps         | 1500       |
| value_loss              | 0.28420144 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.5830795  |
| ent_coef_loss           | -5.371697  |
| entropy                 | 8.05387    |
| ep_rewmean              | -1.54      |
| episodes                | 20         |
| eplenmean               | 100        |
| fps                     | 203        |
| mean 100 episode reward | -1.5       |
| n_updates               | 1801       |
| policy_loss             | -24.098183 |
| qf1_loss                | 0.23056653 |
| qf2_loss                | 0.24554363 |
| time_elapsed            | 9          |
| total timesteps         | 1900       |
| value_loss              | 0.38780373 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.5174244  |
| ent_coef_loss           | -6.504895  |
| entropy                 | 8.086222   |
| ep_rewmean              | -1.5       |
| episodes                | 24         |
| eplenmean               | 100        |
| fps                     | 204        |
| mean 100 episode reward | -1.5       |
| n_updates               | 2201       |
| policy_loss             | -27.382046 |
| qf1_loss                | 4.562927   |
| qf2_loss                | 4.6115913  |
| time_elapsed            | 11         |
| total timesteps         | 2300       |
| value_loss              | 0.35364166 |
----------------------------------------
---------------------------------------
| current_lr              | 0.0003    |
| ent_coef                | 0.4592216 |
| ent_coef_loss           | -7.756358 |
| entropy                 | 8.121417  |
| ep_rewmean              | -1.42     |
| episodes                | 28        |
| eplenmean               | 100       |
| fps                     | 205       |
| mean 100 episode reward | -1.4      |
| n_updates               | 2601      |
| policy_loss             | -29.49534 |
| qf1_loss                | 8.26151   |
| qf2_loss                | 8.481932  |
| time_elapsed            | 13        |
| total timesteps         | 2700      |
| value_loss              | 0.4463914 |
---------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.40766823 |
| ent_coef_loss           | -8.967653  |
| entropy                 | 7.7717915  |
| ep_rewmean              | -1.34      |
| episodes                | 32         |
| eplenmean               | 100        |
| fps                     | 205        |
| mean 100 episode reward | -1.3       |
| n_updates               | 3001       |
| policy_loss             | -31.822998 |
| qf1_loss                | 0.15927035 |
| qf2_loss                | 0.12706651 |
| time_elapsed            | 15         |
| total timesteps         | 3100       |
| value_loss              | 1.1216056  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.36208484 |
| ent_coef_loss           | -9.886995  |
| entropy                 | 7.522522   |
| ep_rewmean              | -1.43      |
| episodes                | 36         |
| eplenmean               | 100        |
| fps                     | 206        |
| mean 100 episode reward | -1.4       |
| n_updates               | 3401       |
| policy_loss             | -33.370235 |
| qf1_loss                | 0.27219623 |
| qf2_loss                | 0.2772037  |
| time_elapsed            | 16         |
| total timesteps         | 3500       |
| value_loss              | 0.5360097  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.32209787 |
| ent_coef_loss           | -10.714933 |
| entropy                 | 7.0129766  |
| ep_rewmean              | -1.47      |
| episodes                | 40         |
| eplenmean               | 100        |
| fps                     | 206        |
| mean 100 episode reward | -1.5       |
| n_updates               | 3801       |
| policy_loss             | -33.895638 |
| qf1_loss                | 0.5629575  |
| qf2_loss                | 0.55859476 |
| time_elapsed            | 18         |
| total timesteps         | 3900       |
| value_loss              | 0.85391104 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.28652436 |
| ent_coef_loss           | -11.210863 |
| entropy                 | 6.3639154  |
| ep_rewmean              | -1.6       |
| episodes                | 44         |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -1.6       |
| n_updates               | 4201       |
| policy_loss             | -34.901817 |
| qf1_loss                | 0.20140347 |
| qf2_loss                | 0.2815305  |
| time_elapsed            | 20         |
| total timesteps         | 4300       |
| value_loss              | 0.40568435 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.25520673 |
| ent_coef_loss           | -12.439022 |
| entropy                 | 6.2807903  |
| ep_rewmean              | -1.63      |
| episodes                | 48         |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -1.6       |
| n_updates               | 4601       |
| policy_loss             | -36.37389  |
| qf1_loss                | 0.38018265 |
| qf2_loss                | 0.30420482 |
| time_elapsed            | 22         |
| total timesteps         | 4700       |
| value_loss              | 0.6209195  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.22793823 |
| ent_coef_loss           | -13.013265 |
| entropy                 | 6.0580854  |
| ep_rewmean              | -1.62      |
| episodes                | 52         |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -1.6       |
| n_updates               | 5001       |
| policy_loss             | -36.11279  |
| qf1_loss                | 20.90251   |
| qf2_loss                | 20.721897  |
| time_elapsed            | 24         |
| total timesteps         | 5100       |
| value_loss              | 0.19771507 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.2036084  |
| ent_coef_loss           | -14.296843 |
| entropy                 | 6.346986   |
| ep_rewmean              | -1.6       |
| episodes                | 56         |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -1.6       |
| n_updates               | 5401       |
| policy_loss             | -36.39855  |
| qf1_loss                | 15.044737  |
| qf2_loss                | 14.825587  |
| time_elapsed            | 26         |
| total timesteps         | 5500       |
| value_loss              | 0.6352711  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.18217771 |
| ent_coef_loss           | -13.388758 |
| entropy                 | 5.3740425  |
| ep_rewmean              | -1.64      |
| episodes                | 60         |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -1.6       |
| n_updates               | 5801       |
| policy_loss             | -36.81837  |
| qf1_loss                | 7.2337584  |
| qf2_loss                | 7.5776763  |
| time_elapsed            | 28         |
| total timesteps         | 5900       |
| value_loss              | 0.5955644  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.16526848 |
| ent_coef_loss           | -12.554353 |
| entropy                 | 5.2252874  |
| ep_rewmean              | -1.72      |
| episodes                | 64         |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -1.7       |
| n_updates               | 6201       |
| policy_loss             | -36.52111  |
| qf1_loss                | 12.093666  |
| qf2_loss                | 11.3621    |
| time_elapsed            | 30         |
| total timesteps         | 6300       |
| value_loss              | 0.25304383 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.15332066 |
| ent_coef_loss           | -6.9260936 |
| entropy                 | 3.796262   |
| ep_rewmean              | -1.77      |
| episodes                | 68         |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -1.8       |
| n_updates               | 6601       |
| policy_loss             | -36.31176  |
| qf1_loss                | 0.55450666 |
| qf2_loss                | 0.641834   |
| time_elapsed            | 32         |
| total timesteps         | 6700       |
| value_loss              | 0.3121264  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.14228673 |
| ent_coef_loss           | -9.422379  |
| entropy                 | 4.6237783  |
| ep_rewmean              | -1.8       |
| episodes                | 72         |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -1.8       |
| n_updates               | 7001       |
| policy_loss             | -34.739365 |
| qf1_loss                | 11.424326  |
| qf2_loss                | 11.593261  |
| time_elapsed            | 34         |
| total timesteps         | 7100       |
| value_loss              | 0.32274476 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.13188326 |
| ent_coef_loss           | -5.4784994 |
| entropy                 | 3.761938   |
| ep_rewmean              | -1.76      |
| episodes                | 76         |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -1.8       |
| n_updates               | 7401       |
| policy_loss             | -34.05916  |
| qf1_loss                | 4.649664   |
| qf2_loss                | 4.824651   |
| time_elapsed            | 36         |
| total timesteps         | 7500       |
| value_loss              | 0.34124967 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.12066387 |
| ent_coef_loss           | -9.327053  |
| entropy                 | 4.280716   |
| ep_rewmean              | -1.79      |
| episodes                | 80         |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -1.8       |
| n_updates               | 7801       |
| policy_loss             | -33.585846 |
| qf1_loss                | 4.9800963  |
| qf2_loss                | 5.3646784  |
| time_elapsed            | 38         |
| total timesteps         | 7900       |
| value_loss              | 0.30603683 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.10977945 |
| ent_coef_loss           | -10.219675 |
| entropy                 | 4.5703683  |
| ep_rewmean              | -1.8       |
| episodes                | 84         |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -1.8       |
| n_updates               | 8201       |
| policy_loss             | -32.90715  |
| qf1_loss                | 0.57800436 |
| qf2_loss                | 0.6106745  |
| time_elapsed            | 39         |
| total timesteps         | 8300       |
| value_loss              | 0.31605935 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.09941738 |
| ent_coef_loss           | -11.265989 |
| entropy                 | 4.1251345  |
| ep_rewmean              | -1.79      |
| episodes                | 88         |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -1.8       |
| n_updates               | 8601       |
| policy_loss             | -32.541008 |
| qf1_loss                | 13.586355  |
| qf2_loss                | 14.332947  |
| time_elapsed            | 41         |
| total timesteps         | 8700       |
| value_loss              | 0.1890001  |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.093477994 |
| ent_coef_loss           | -4.748      |
| entropy                 | 3.9338264   |
| ep_rewmean              | -1.82       |
| episodes                | 92          |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -1.8        |
| n_updates               | 9001        |
| policy_loss             | -31.820923  |
| qf1_loss                | 5.880398    |
| qf2_loss                | 6.500388    |
| time_elapsed            | 43          |
| total timesteps         | 9100        |
| value_loss              | 1.396183    |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.088174924 |
| ent_coef_loss           | -2.9239068  |
| entropy                 | 3.408692    |
| ep_rewmean              | -1.82       |
| episodes                | 96          |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -1.8        |
| n_updates               | 9401        |
| policy_loss             | -30.304913  |
| qf1_loss                | 14.449015   |
| qf2_loss                | 14.901939   |
| time_elapsed            | 45          |
| total timesteps         | 9500        |
| value_loss              | 0.29548782  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.083382815 |
| ent_coef_loss           | -1.5451275  |
| entropy                 | 2.9642375   |
| ep_rewmean              | -1.81       |
| episodes                | 100         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -1.8        |
| n_updates               | 9801        |
| policy_loss             | -31.035645  |
| qf1_loss                | 0.34603852  |
| qf2_loss                | 0.35810816  |
| time_elapsed            | 47          |
| total timesteps         | 9900        |
| value_loss              | 0.34868348  |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=-1.35 +/- 0.89
Episode length: 100.00 +/- 0.00
New best mean reward!
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.07598145 |
| ent_coef_loss           | -6.260209  |
| entropy                 | 2.4269295  |
| ep_rewmean              | -1.85      |
| episodes                | 104        |
| eplenmean               | 100        |
| fps                     | 206        |
| mean 100 episode reward | -1.8       |
| n_updates               | 10201      |
| policy_loss             | -30.000778 |
| qf1_loss                | 17.158066  |
| qf2_loss                | 17.051449  |
| time_elapsed            | 49         |
| total timesteps         | 10300      |
| value_loss              | 0.42490366 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.068666995 |
| ent_coef_loss           | -8.096839   |
| entropy                 | 1.0231385   |
| ep_rewmean              | -1.81       |
| episodes                | 108         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -1.8        |
| n_updates               | 10601       |
| policy_loss             | -29.059456  |
| qf1_loss                | 0.17555507  |
| qf2_loss                | 0.20643751  |
| time_elapsed            | 51          |
| total timesteps         | 10700       |
| value_loss              | 0.10864056  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.062425345 |
| ent_coef_loss           | -2.486785   |
| entropy                 | 1.0438094   |
| ep_rewmean              | -1.83       |
| episodes                | 112         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -1.8        |
| n_updates               | 11001       |
| policy_loss             | -28.010649  |
| qf1_loss                | 0.34897688  |
| qf2_loss                | 0.24063233  |
| time_elapsed            | 53          |
| total timesteps         | 11100       |
| value_loss              | 0.87025213  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.05853642 |
| ent_coef_loss           | -4.9909945 |
| entropy                 | 0.6856231  |
| ep_rewmean              | -1.86      |
| episodes                | 116        |
| eplenmean               | 100        |
| fps                     | 206        |
| mean 100 episode reward | -1.9       |
| n_updates               | 11401      |
| policy_loss             | -28.784277 |
| qf1_loss                | 0.30938202 |
| qf2_loss                | 0.15743186 |
| time_elapsed            | 55         |
| total timesteps         | 11500      |
| value_loss              | 0.22046857 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.055577967 |
| ent_coef_loss           | -4.4601946  |
| entropy                 | 0.5142915   |
| ep_rewmean              | -1.88       |
| episodes                | 120         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -1.9        |
| n_updates               | 11801       |
| policy_loss             | -29.438534  |
| qf1_loss                | 0.28253883  |
| qf2_loss                | 0.219257    |
| time_elapsed            | 57          |
| total timesteps         | 11900       |
| value_loss              | 0.17674348  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.05280556 |
| ent_coef_loss           | -2.8477635 |
| entropy                 | 1.1708946  |
| ep_rewmean              | -1.88      |
| episodes                | 124        |
| eplenmean               | 100        |
| fps                     | 206        |
| mean 100 episode reward | -1.9       |
| n_updates               | 12201      |
| policy_loss             | -27.27039  |
| qf1_loss                | 0.3679182  |
| qf2_loss                | 0.39086765 |
| time_elapsed            | 59         |
| total timesteps         | 12300      |
| value_loss              | 0.37824315 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.051436525 |
| ent_coef_loss           | 3.6376839   |
| entropy                 | 1.2584586   |
| ep_rewmean              | -1.95       |
| episodes                | 128         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -1.9        |
| n_updates               | 12601       |
| policy_loss             | -26.573502  |
| qf1_loss                | 0.39536     |
| qf2_loss                | 0.5552645   |
| time_elapsed            | 61          |
| total timesteps         | 12700       |
| value_loss              | 0.52833915  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.051996075 |
| ent_coef_loss           | 2.05942     |
| entropy                 | 1.0607494   |
| ep_rewmean              | -1.96       |
| episodes                | 132         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -2          |
| n_updates               | 13001       |
| policy_loss             | -27.05074   |
| qf1_loss                | 7.3824477   |
| qf2_loss                | 7.4823575   |
| time_elapsed            | 63          |
| total timesteps         | 13100       |
| value_loss              | 0.25833136  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.052179944 |
| ent_coef_loss           | 2.5788972   |
| entropy                 | 1.4788774   |
| ep_rewmean              | -1.94       |
| episodes                | 136         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -1.9        |
| n_updates               | 13401       |
| policy_loss             | -24.156088  |
| qf1_loss                | 0.15505084  |
| qf2_loss                | 0.15790999  |
| time_elapsed            | 65          |
| total timesteps         | 13500       |
| value_loss              | 0.27942932  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.052353393 |
| ent_coef_loss           | 2.1807761   |
| entropy                 | 1.1279054   |
| ep_rewmean              | -1.92       |
| episodes                | 140         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -1.9        |
| n_updates               | 13801       |
| policy_loss             | -26.38694   |
| qf1_loss                | 0.39761722  |
| qf2_loss                | 0.3378262   |
| time_elapsed            | 67          |
| total timesteps         | 13900       |
| value_loss              | 0.2188062   |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.05351374 |
| ent_coef_loss           | 6.2053385  |
| entropy                 | 1.308536   |
| ep_rewmean              | -1.87      |
| episodes                | 144        |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -1.9       |
| n_updates               | 14201      |
| policy_loss             | -24.585785 |
| qf1_loss                | 6.7155504  |
| qf2_loss                | 6.71413    |
| time_elapsed            | 69         |
| total timesteps         | 14300      |
| value_loss              | 0.24081641 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.053154632 |
| ent_coef_loss           | -1.6465161  |
| entropy                 | 0.47537756  |
| ep_rewmean              | -1.85       |
| episodes                | 148         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -1.8        |
| n_updates               | 14601       |
| policy_loss             | -23.807533  |
| qf1_loss                | 0.36206225  |
| qf2_loss                | 0.38563043  |
| time_elapsed            | 70          |
| total timesteps         | 14700       |
| value_loss              | 0.32465455  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.051971197 |
| ent_coef_loss           | 1.9141332   |
| entropy                 | 0.7033878   |
| ep_rewmean              | -1.88       |
| episodes                | 152         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -1.9        |
| n_updates               | 15001       |
| policy_loss             | -25.39634   |
| qf1_loss                | 6.1540475   |
| qf2_loss                | 6.26991     |
| time_elapsed            | 72          |
| total timesteps         | 15100       |
| value_loss              | 0.16944274  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.051290724 |
| ent_coef_loss           | -1.152823   |
| entropy                 | 0.93925315  |
| ep_rewmean              | -1.91       |
| episodes                | 156         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -1.9        |
| n_updates               | 15401       |
| policy_loss             | -24.83812   |
| qf1_loss                | 0.18207315  |
| qf2_loss                | 0.25987387  |
| time_elapsed            | 74          |
| total timesteps         | 15500       |
| value_loss              | 0.08949377  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.048940655 |
| ent_coef_loss           | -0.18791837 |
| entropy                 | 0.67887765  |
| ep_rewmean              | -1.91       |
| episodes                | 160         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -1.9        |
| n_updates               | 15801       |
| policy_loss             | -23.846035  |
| qf1_loss                | 0.15522343  |
| qf2_loss                | 0.24454561  |
| time_elapsed            | 76          |
| total timesteps         | 15900       |
| value_loss              | 1.083636    |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.04915183 |
| ent_coef_loss           | 4.328519   |
| entropy                 | 0.70838976 |
| ep_rewmean              | -1.88      |
| episodes                | 164        |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -1.9       |
| n_updates               | 16201      |
| policy_loss             | -24.298223 |
| qf1_loss                | 0.32514054 |
| qf2_loss                | 0.26431042 |
| time_elapsed            | 78         |
| total timesteps         | 16300      |
| value_loss              | 0.13912809 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.050192963 |
| ent_coef_loss           | -2.5605838  |
| entropy                 | 0.43393108  |
| ep_rewmean              | -1.92       |
| episodes                | 168         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -1.9        |
| n_updates               | 16601       |
| policy_loss             | -24.635845  |
| qf1_loss                | 0.16325489  |
| qf2_loss                | 0.15548667  |
| time_elapsed            | 80          |
| total timesteps         | 16700       |
| value_loss              | 0.0932471   |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.052124627 |
| ent_coef_loss           | 2.405479    |
| entropy                 | 0.8879309   |
| ep_rewmean              | -1.9        |
| episodes                | 172         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -1.9        |
| n_updates               | 17001       |
| policy_loss             | -21.553202  |
| qf1_loss                | 0.34044266  |
| qf2_loss                | 0.4127455   |
| time_elapsed            | 82          |
| total timesteps         | 17100       |
| value_loss              | 0.75114024  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.053371795 |
| ent_coef_loss           | -0.3231205  |
| entropy                 | 0.6345625   |
| ep_rewmean              | -1.95       |
| episodes                | 176         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -1.9        |
| n_updates               | 17401       |
| policy_loss             | -23.266527  |
| qf1_loss                | 0.14885893  |
| qf2_loss                | 0.20958868  |
| time_elapsed            | 84          |
| total timesteps         | 17500       |
| value_loss              | 0.15793267  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.05336846 |
| ent_coef_loss           | -0.7490218 |
| entropy                 | 0.9716552  |
| ep_rewmean              | -1.94      |
| episodes                | 180        |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -1.9       |
| n_updates               | 17801      |
| policy_loss             | -21.845825 |
| qf1_loss                | 0.3179277  |
| qf2_loss                | 0.33150548 |
| time_elapsed            | 86         |
| total timesteps         | 17900      |
| value_loss              | 0.19677675 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.051200017 |
| ent_coef_loss           | -1.4203806  |
| entropy                 | 0.39676997  |
| ep_rewmean              | -1.97       |
| episodes                | 184         |
| eplenmean               | 100         |
| fps                     | 208         |
| mean 100 episode reward | -2          |
| n_updates               | 18201       |
| policy_loss             | -21.123383  |
| qf1_loss                | 0.16409841  |
| qf2_loss                | 0.21770197  |
| time_elapsed            | 87          |
| total timesteps         | 18300       |
| value_loss              | 0.10604014  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.04835095  |
| ent_coef_loss           | 1.6566405   |
| entropy                 | 0.74926955  |
| ep_rewmean              | -1.98       |
| episodes                | 188         |
| eplenmean               | 100         |
| fps                     | 208         |
| mean 100 episode reward | -2          |
| n_updates               | 18601       |
| policy_loss             | -19.797539  |
| qf1_loss                | 0.14731278  |
| qf2_loss                | 0.119551904 |
| time_elapsed            | 89          |
| total timesteps         | 18700       |
| value_loss              | 0.092099786 |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.04594149 |
| ent_coef_loss           | 0.10386193 |
| entropy                 | 0.56032264 |
| ep_rewmean              | -1.94      |
| episodes                | 192        |
| eplenmean               | 100        |
| fps                     | 208        |
| mean 100 episode reward | -1.9       |
| n_updates               | 19001      |
| policy_loss             | -19.087425 |
| qf1_loss                | 0.65522283 |
| qf2_loss                | 1.5068069  |
| time_elapsed            | 91         |
| total timesteps         | 19100      |
| value_loss              | 0.1706858  |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.044161376 |
| ent_coef_loss           | -1.1122265  |
| entropy                 | 0.6827439   |
| ep_rewmean              | -1.96       |
| episodes                | 196         |
| eplenmean               | 100         |
| fps                     | 208         |
| mean 100 episode reward | -2          |
| n_updates               | 19401       |
| policy_loss             | -18.975018  |
| qf1_loss                | 2.4987562   |
| qf2_loss                | 2.433065    |
| time_elapsed            | 93          |
| total timesteps         | 19500       |
| value_loss              | 0.06797839  |
-----------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.04154933    |
| ent_coef_loss           | 0.00071555376 |
| entropy                 | 0.92042696    |
| ep_rewmean              | -1.99         |
| episodes                | 200           |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 19801         |
| policy_loss             | -18.071423    |
| qf1_loss                | 0.15296146    |
| qf2_loss                | 0.11504774    |
| time_elapsed            | 95            |
| total timesteps         | 19900         |
| value_loss              | 0.11757052    |
-------------------------------------------
Eval num_timesteps=20000, episode_reward=-2.18 +/- 1.22
Episode length: 100.00 +/- 0.00
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.03981865 |
| ent_coef_loss           | -0.5774979 |
| entropy                 | 1.0883157  |
| ep_rewmean              | -1.94      |
| episodes                | 204        |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -1.9       |
| n_updates               | 20201      |
| policy_loss             | -17.776314 |
| qf1_loss                | 2.223123   |
| qf2_loss                | 2.1251178  |
| time_elapsed            | 97         |
| total timesteps         | 20300      |
| value_loss              | 0.13032718 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.036497455 |
| ent_coef_loss           | -1.506314   |
| entropy                 | 0.75439453  |
| ep_rewmean              | -1.96       |
| episodes                | 208         |
| eplenmean               | 100         |
| fps                     | 208         |
| mean 100 episode reward | -2          |
| n_updates               | 20601       |
| policy_loss             | -16.68848   |
| qf1_loss                | 1.7947018   |
| qf2_loss                | 1.7346048   |
| time_elapsed            | 99          |
| total timesteps         | 20700       |
| value_loss              | 0.09230442  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.035930946 |
| ent_coef_loss           | -3.4571543  |
| entropy                 | 0.5729978   |
| ep_rewmean              | -1.98       |
| episodes                | 212         |
| eplenmean               | 100         |
| fps                     | 208         |
| mean 100 episode reward | -2          |
| n_updates               | 21001       |
| policy_loss             | -16.96481   |
| qf1_loss                | 0.12559044  |
| qf2_loss                | 0.079058364 |
| time_elapsed            | 101         |
| total timesteps         | 21100       |
| value_loss              | 0.14070618  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.036654875 |
| ent_coef_loss           | 1.7772874   |
| entropy                 | 1.5344462   |
| ep_rewmean              | -1.92       |
| episodes                | 216         |
| eplenmean               | 100         |
| fps                     | 208         |
| mean 100 episode reward | -1.9        |
| n_updates               | 21401       |
| policy_loss             | -15.650637  |
| qf1_loss                | 1.0756834   |
| qf2_loss                | 1.608307    |
| time_elapsed            | 103         |
| total timesteps         | 21500       |
| value_loss              | 0.082442574 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.041170493 |
| ent_coef_loss           | 4.6024857   |
| entropy                 | 1.4449965   |
| ep_rewmean              | -1.88       |
| episodes                | 220         |
| eplenmean               | 100         |
| fps                     | 208         |
| mean 100 episode reward | -1.9        |
| n_updates               | 21801       |
| policy_loss             | -15.138521  |
| qf1_loss                | 0.05476304  |
| qf2_loss                | 0.07915698  |
| time_elapsed            | 105         |
| total timesteps         | 21900       |
| value_loss              | 0.13739316  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.03849196 |
| ent_coef_loss           | 0.8579029  |
| entropy                 | 1.7685444  |
| ep_rewmean              | -1.94      |
| episodes                | 224        |
| eplenmean               | 100        |
| fps                     | 208        |
| mean 100 episode reward | -1.9       |
| n_updates               | 22201      |
| policy_loss             | -14.381004 |
| qf1_loss                | 1.4958707  |
| qf2_loss                | 1.6450815  |
| time_elapsed            | 106        |
| total timesteps         | 22300      |
| value_loss              | 0.16687278 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.037050538 |
| ent_coef_loss           | 1.3411745   |
| entropy                 | 0.6804509   |
| ep_rewmean              | -1.97       |
| episodes                | 228         |
| eplenmean               | 100         |
| fps                     | 208         |
| mean 100 episode reward | -2          |
| n_updates               | 22601       |
| policy_loss             | -14.843534  |
| qf1_loss                | 0.05918991  |
| qf2_loss                | 0.050175223 |
| time_elapsed            | 108         |
| total timesteps         | 22700       |
| value_loss              | 0.09750961  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.037790567 |
| ent_coef_loss           | -1.3848089  |
| entropy                 | 0.68684447  |
| ep_rewmean              | -2.02       |
| episodes                | 232         |
| eplenmean               | 100         |
| fps                     | 208         |
| mean 100 episode reward | -2          |
| n_updates               | 23001       |
| policy_loss             | -14.142395  |
| qf1_loss                | 0.115205504 |
| qf2_loss                | 0.10239039  |
| time_elapsed            | 110         |
| total timesteps         | 23100       |
| value_loss              | 0.09743374  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.038267393 |
| ent_coef_loss           | 3.434658    |
| entropy                 | 0.64418024  |
| ep_rewmean              | -2.11       |
| episodes                | 236         |
| eplenmean               | 100         |
| fps                     | 208         |
| mean 100 episode reward | -2.1        |
| n_updates               | 23401       |
| policy_loss             | -13.695538  |
| qf1_loss                | 1.5402645   |
| qf2_loss                | 1.5430332   |
| time_elapsed            | 112         |
| total timesteps         | 23500       |
| value_loss              | 0.09990295  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.038241044 |
| ent_coef_loss           | -2.380508   |
| entropy                 | 0.60568666  |
| ep_rewmean              | -2.17       |
| episodes                | 240         |
| eplenmean               | 100         |
| fps                     | 208         |
| mean 100 episode reward | -2.2        |
| n_updates               | 23801       |
| policy_loss             | -14.023266  |
| qf1_loss                | 0.10215373  |
| qf2_loss                | 0.13168219  |
| time_elapsed            | 114         |
| total timesteps         | 23900       |
| value_loss              | 0.086873785 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.036935847 |
| ent_coef_loss           | 5.1335497   |
| entropy                 | 0.7565716   |
| ep_rewmean              | -2.25       |
| episodes                | 244         |
| eplenmean               | 100         |
| fps                     | 208         |
| mean 100 episode reward | -2.3        |
| n_updates               | 24201       |
| policy_loss             | -13.453333  |
| qf1_loss                | 0.04690092  |
| qf2_loss                | 0.06615272  |
| time_elapsed            | 116         |
| total timesteps         | 24300       |
| value_loss              | 0.16860476  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.036758605 |
| ent_coef_loss           | -1.4408848  |
| entropy                 | 1.240286    |
| ep_rewmean              | -2.26       |
| episodes                | 248         |
| eplenmean               | 100         |
| fps                     | 208         |
| mean 100 episode reward | -2.3        |
| n_updates               | 24601       |
| policy_loss             | -12.705513  |
| qf1_loss                | 1.3120544   |
| qf2_loss                | 1.3082836   |
| time_elapsed            | 118         |
| total timesteps         | 24700       |
| value_loss              | 0.08502269  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.037364703 |
| ent_coef_loss           | 1.3142769   |
| entropy                 | 0.9104439   |
| ep_rewmean              | -2.24       |
| episodes                | 252         |
| eplenmean               | 100         |
| fps                     | 208         |
| mean 100 episode reward | -2.2        |
| n_updates               | 25001       |
| policy_loss             | -12.16678   |
| qf1_loss                | 0.04220943  |
| qf2_loss                | 0.046885483 |
| time_elapsed            | 120         |
| total timesteps         | 25100       |
| value_loss              | 0.042136073 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.036110424 |
| ent_coef_loss           | -1.5127602  |
| entropy                 | 0.90610975  |
| ep_rewmean              | -2.27       |
| episodes                | 256         |
| eplenmean               | 100         |
| fps                     | 208         |
| mean 100 episode reward | -2.3        |
| n_updates               | 25401       |
| policy_loss             | -11.903709  |
| qf1_loss                | 0.05381289  |
| qf2_loss                | 0.0983632   |
| time_elapsed            | 122         |
| total timesteps         | 25500       |
| value_loss              | 0.18819013  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.034630436 |
| ent_coef_loss           | -3.4412117  |
| entropy                 | 1.3715038   |
| ep_rewmean              | -2.23       |
| episodes                | 260         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 25801       |
| policy_loss             | -10.633956  |
| qf1_loss                | 0.09142765  |
| qf2_loss                | 0.06767672  |
| time_elapsed            | 123         |
| total timesteps         | 25900       |
| value_loss              | 0.058445975 |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.03177932 |
| ent_coef_loss           | 2.9313495  |
| entropy                 | 0.909793   |
| ep_rewmean              | -2.27      |
| episodes                | 264        |
| eplenmean               | 100        |
| fps                     | 209        |
| mean 100 episode reward | -2.3       |
| n_updates               | 26201      |
| policy_loss             | -11.122755 |
| qf1_loss                | 0.96715945 |
| qf2_loss                | 0.99296755 |
| time_elapsed            | 125        |
| total timesteps         | 26300      |
| value_loss              | 0.12911402 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.030798972 |
| ent_coef_loss           | -0.5726882  |
| entropy                 | 1.1292813   |
| ep_rewmean              | -2.23       |
| episodes                | 268         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 26601       |
| policy_loss             | -10.987632  |
| qf1_loss                | 0.06917861  |
| qf2_loss                | 0.07016498  |
| time_elapsed            | 127         |
| total timesteps         | 26700       |
| value_loss              | 0.080516815 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.030047014 |
| ent_coef_loss           | -1.3331861  |
| entropy                 | 0.7638675   |
| ep_rewmean              | -2.23       |
| episodes                | 272         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 27001       |
| policy_loss             | -10.991844  |
| qf1_loss                | 0.035214555 |
| qf2_loss                | 0.036648422 |
| time_elapsed            | 129         |
| total timesteps         | 27100       |
| value_loss              | 0.16927522  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.03057496  |
| ent_coef_loss           | 1.3832035   |
| entropy                 | 1.3667791   |
| ep_rewmean              | -2.21       |
| episodes                | 276         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 27401       |
| policy_loss             | -10.657799  |
| qf1_loss                | 0.08216568  |
| qf2_loss                | 0.067730926 |
| time_elapsed            | 131         |
| total timesteps         | 27500       |
| value_loss              | 0.060621865 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.030596917 |
| ent_coef_loss           | 0.3243384   |
| entropy                 | 1.4448239   |
| ep_rewmean              | -2.18       |
| episodes                | 280         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 27801       |
| policy_loss             | -10.415393  |
| qf1_loss                | 0.06116424  |
| qf2_loss                | 0.07612767  |
| time_elapsed            | 133         |
| total timesteps         | 27900       |
| value_loss              | 0.06681579  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.028449839 |
| ent_coef_loss           | -0.5724572  |
| entropy                 | 1.5934036   |
| ep_rewmean              | -2.15       |
| episodes                | 284         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 28201       |
| policy_loss             | -10.059318  |
| qf1_loss                | 0.9913815   |
| qf2_loss                | 1.0103991   |
| time_elapsed            | 135         |
| total timesteps         | 28300       |
| value_loss              | 0.05438908  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.026886452 |
| ent_coef_loss           | 1.1352398   |
| entropy                 | 1.5822535   |
| ep_rewmean              | -2.18       |
| episodes                | 288         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 28601       |
| policy_loss             | -10.599018  |
| qf1_loss                | 0.050793868 |
| qf2_loss                | 0.04255616  |
| time_elapsed            | 137         |
| total timesteps         | 28700       |
| value_loss              | 0.16238335  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.026375262 |
| ent_coef_loss           | 0.5610969   |
| entropy                 | 1.2770776   |
| ep_rewmean              | -2.18       |
| episodes                | 292         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 29001       |
| policy_loss             | -10.909695  |
| qf1_loss                | 0.025676893 |
| qf2_loss                | 0.022473954 |
| time_elapsed            | 139         |
| total timesteps         | 29100       |
| value_loss              | 0.05229969  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.027085513 |
| ent_coef_loss           | 3.0646496   |
| entropy                 | 1.0450754   |
| ep_rewmean              | -2.17       |
| episodes                | 296         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 29401       |
| policy_loss             | -9.908648   |
| qf1_loss                | 0.039721176 |
| qf2_loss                | 0.04100553  |
| time_elapsed            | 140         |
| total timesteps         | 29500       |
| value_loss              | 0.043615438 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.026999999 |
| ent_coef_loss           | 1.0227723   |
| entropy                 | 1.3730929   |
| ep_rewmean              | -2.15       |
| episodes                | 300         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 29801       |
| policy_loss             | -9.491737   |
| qf1_loss                | 0.033695586 |
| qf2_loss                | 0.0508829   |
| time_elapsed            | 142         |
| total timesteps         | 29900       |
| value_loss              | 0.08139315  |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-2.06 +/- 0.88
Episode length: 100.00 +/- 0.00
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.025936857 |
| ent_coef_loss           | 2.978678    |
| entropy                 | 1.0529509   |
| ep_rewmean              | -2.24       |
| episodes                | 304         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 30201       |
| policy_loss             | -10.059809  |
| qf1_loss                | 0.029576937 |
| qf2_loss                | 0.029527739 |
| time_elapsed            | 144         |
| total timesteps         | 30300       |
| value_loss              | 0.056406356 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.025157414 |
| ent_coef_loss           | -2.6800485  |
| entropy                 | 1.6416012   |
| ep_rewmean              | -2.22       |
| episodes                | 308         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 30601       |
| policy_loss             | -8.669835   |
| qf1_loss                | 0.02925986  |
| qf2_loss                | 0.039844714 |
| time_elapsed            | 146         |
| total timesteps         | 30700       |
| value_loss              | 0.117831476 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.025226666 |
| ent_coef_loss           | 3.9226153   |
| entropy                 | 1.0656308   |
| ep_rewmean              | -2.2        |
| episodes                | 312         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 31001       |
| policy_loss             | -8.518946   |
| qf1_loss                | 0.121453404 |
| qf2_loss                | 0.21426271  |
| time_elapsed            | 148         |
| total timesteps         | 31100       |
| value_loss              | 0.038344525 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.029018128 |
| ent_coef_loss           | 5.0753717   |
| entropy                 | 1.7480898   |
| ep_rewmean              | -2.29       |
| episodes                | 316         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.3        |
| n_updates               | 31401       |
| policy_loss             | -8.087294   |
| qf1_loss                | 0.037876174 |
| qf2_loss                | 0.04851824  |
| time_elapsed            | 150         |
| total timesteps         | 31500       |
| value_loss              | 0.040520776 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.031882234 |
| ent_coef_loss           | 1.7128935   |
| entropy                 | 2.0984879   |
| ep_rewmean              | -2.3        |
| episodes                | 320         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.3        |
| n_updates               | 31801       |
| policy_loss             | -7.428753   |
| qf1_loss                | 0.16254552  |
| qf2_loss                | 0.18040285  |
| time_elapsed            | 152         |
| total timesteps         | 31900       |
| value_loss              | 0.06517005  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.032402493 |
| ent_coef_loss           | -0.9383314  |
| entropy                 | 2.234651    |
| ep_rewmean              | -2.27       |
| episodes                | 324         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.3        |
| n_updates               | 32201       |
| policy_loss             | -7.6253715  |
| qf1_loss                | 0.53102154  |
| qf2_loss                | 0.55797845  |
| time_elapsed            | 154         |
| total timesteps         | 32300       |
| value_loss              | 0.07973611  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.030926991 |
| ent_coef_loss           | -0.607879   |
| entropy                 | 1.717407    |
| ep_rewmean              | -2.3        |
| episodes                | 328         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.3        |
| n_updates               | 32601       |
| policy_loss             | -6.83771    |
| qf1_loss                | 0.35469005  |
| qf2_loss                | 0.38681293  |
| time_elapsed            | 156         |
| total timesteps         | 32700       |
| value_loss              | 0.01754925  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.027613577 |
| ent_coef_loss           | -4.6484795  |
| entropy                 | 1.8946576   |
| ep_rewmean              | -2.32       |
| episodes                | 332         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.3        |
| n_updates               | 33001       |
| policy_loss             | -5.930112   |
| qf1_loss                | 0.030117286 |
| qf2_loss                | 0.029857116 |
| time_elapsed            | 158         |
| total timesteps         | 33100       |
| value_loss              | 0.020099837 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.024120083 |
| ent_coef_loss           | -5.0118814  |
| entropy                 | 1.4976835   |
| ep_rewmean              | -2.25       |
| episodes                | 336         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 33401       |
| policy_loss             | -5.6558695  |
| qf1_loss                | 0.02500642  |
| qf2_loss                | 0.019970942 |
| time_elapsed            | 160         |
| total timesteps         | 33500       |
| value_loss              | 0.019897865 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.02297683  |
| ent_coef_loss           | 0.69182396  |
| entropy                 | 1.3204854   |
| ep_rewmean              | -2.21       |
| episodes                | 340         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 33801       |
| policy_loss             | -5.210533   |
| qf1_loss                | 0.023124944 |
| qf2_loss                | 0.083574325 |
| time_elapsed            | 162         |
| total timesteps         | 33900       |
| value_loss              | 0.020523079 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.021180823 |
| ent_coef_loss           | -0.42631227 |
| entropy                 | 1.8001657   |
| ep_rewmean              | -2.2        |
| episodes                | 344         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 34201       |
| policy_loss             | -4.6380024  |
| qf1_loss                | 0.16081205  |
| qf2_loss                | 0.15936303  |
| time_elapsed            | 163         |
| total timesteps         | 34300       |
| value_loss              | 0.02201571  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.018770637 |
| ent_coef_loss           | -4.3205414  |
| entropy                 | 1.4994516   |
| ep_rewmean              | -2.26       |
| episodes                | 348         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.3        |
| n_updates               | 34601       |
| policy_loss             | -4.2265234  |
| qf1_loss                | 0.096580856 |
| qf2_loss                | 0.09056537  |
| time_elapsed            | 165         |
| total timesteps         | 34700       |
| value_loss              | 0.012510856 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.016433548 |
| ent_coef_loss           | -5.5180187  |
| entropy                 | 1.4622827   |
| ep_rewmean              | -2.26       |
| episodes                | 352         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.3        |
| n_updates               | 35001       |
| policy_loss             | -3.8071957  |
| qf1_loss                | 0.13479647  |
| qf2_loss                | 0.14028628  |
| time_elapsed            | 167         |
| total timesteps         | 35100       |
| value_loss              | 0.011925008 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.014271248  |
| ent_coef_loss           | -5.225074    |
| entropy                 | 1.4405587    |
| ep_rewmean              | -2.23        |
| episodes                | 356          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.2         |
| n_updates               | 35401        |
| policy_loss             | -3.5729573   |
| qf1_loss                | 0.006791435  |
| qf2_loss                | 0.0089039635 |
| time_elapsed            | 169          |
| total timesteps         | 35500        |
| value_loss              | 0.008893741  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.012798759 |
| ent_coef_loss           | -4.335346   |
| entropy                 | 1.2316031   |
| ep_rewmean              | -2.24       |
| episodes                | 360         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 35801       |
| policy_loss             | -3.4264684  |
| qf1_loss                | 0.10129157  |
| qf2_loss                | 0.11494944  |
| time_elapsed            | 171         |
| total timesteps         | 35900       |
| value_loss              | 0.018878506 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.011392271  |
| ent_coef_loss           | -4.2333016   |
| entropy                 | 1.07824      |
| ep_rewmean              | -2.2         |
| episodes                | 364          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.2         |
| n_updates               | 36201        |
| policy_loss             | -3.4675293   |
| qf1_loss                | 0.009818062  |
| qf2_loss                | 0.0083732875 |
| time_elapsed            | 173          |
| total timesteps         | 36300        |
| value_loss              | 0.01091918   |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.010602189 |
| ent_coef_loss           | -0.5274583  |
| entropy                 | 1.1993484   |
| ep_rewmean              | -2.19       |
| episodes                | 368         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.2        |
| n_updates               | 36601       |
| policy_loss             | -2.7678418  |
| qf1_loss                | 0.118710116 |
| qf2_loss                | 0.10845107  |
| time_elapsed            | 175         |
| total timesteps         | 36700       |
| value_loss              | 0.029585326 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.010570589  |
| ent_coef_loss           | -0.43251312  |
| entropy                 | 1.4456525    |
| ep_rewmean              | -2.25        |
| episodes                | 372          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.3         |
| n_updates               | 37001        |
| policy_loss             | -2.7614098   |
| qf1_loss                | 0.03153727   |
| qf2_loss                | 0.024719976  |
| time_elapsed            | 177          |
| total timesteps         | 37100        |
| value_loss              | 0.0073750005 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.010530428  |
| ent_coef_loss           | 2.3395045    |
| entropy                 | 0.8090243    |
| ep_rewmean              | -2.32        |
| episodes                | 376          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.3         |
| n_updates               | 37401        |
| policy_loss             | -2.7978048   |
| qf1_loss                | 0.05432693   |
| qf2_loss                | 0.05427145   |
| time_elapsed            | 179          |
| total timesteps         | 37500        |
| value_loss              | 0.0046440065 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.010797306  |
| ent_coef_loss           | 1.3787334    |
| entropy                 | 1.1949047    |
| ep_rewmean              | -2.32        |
| episodes                | 380          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.3         |
| n_updates               | 37801        |
| policy_loss             | -2.2629812   |
| qf1_loss                | 0.004413495  |
| qf2_loss                | 0.0057259267 |
| time_elapsed            | 181          |
| total timesteps         | 37900        |
| value_loss              | 0.0061774687 |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.010772576 |
| ent_coef_loss           | 3.0503974   |
| entropy                 | 1.234455    |
| ep_rewmean              | -2.32       |
| episodes                | 384         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.3        |
| n_updates               | 38201       |
| policy_loss             | -2.3290849  |
| qf1_loss                | 0.004284055 |
| qf2_loss                | 0.005422961 |
| time_elapsed            | 182         |
| total timesteps         | 38300       |
| value_loss              | 0.01058425  |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.010533727  |
| ent_coef_loss           | 2.9136646    |
| entropy                 | 1.3414149    |
| ep_rewmean              | -2.3         |
| episodes                | 388          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.3         |
| n_updates               | 38601        |
| policy_loss             | -2.1533723   |
| qf1_loss                | 0.005682123  |
| qf2_loss                | 0.0048889723 |
| time_elapsed            | 184          |
| total timesteps         | 38700        |
| value_loss              | 0.007699981  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.010126844 |
| ent_coef_loss           | -0.74968386 |
| entropy                 | 1.7161517   |
| ep_rewmean              | -2.33       |
| episodes                | 392         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.3        |
| n_updates               | 39001       |
| policy_loss             | -1.8608191  |
| qf1_loss                | 0.017351959 |
| qf2_loss                | 0.007022173 |
| time_elapsed            | 186         |
| total timesteps         | 39100       |
| value_loss              | 0.007308315 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.009402484 |
| ent_coef_loss           | 2.4910598   |
| entropy                 | 0.99647105  |
| ep_rewmean              | -2.37       |
| episodes                | 396         |
| eplenmean               | 100         |
| fps                     | 209         |
| mean 100 episode reward | -2.4        |
| n_updates               | 39401       |
| policy_loss             | -1.811743   |
| qf1_loss                | 0.031691052 |
| qf2_loss                | 0.03188397  |
| time_elapsed            | 188         |
| total timesteps         | 39500       |
| value_loss              | 0.00781873  |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.008854407  |
| ent_coef_loss           | -1.874575    |
| entropy                 | 1.8275964    |
| ep_rewmean              | -2.35        |
| episodes                | 400          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.3         |
| n_updates               | 39801        |
| policy_loss             | -1.4955404   |
| qf1_loss                | 0.0025532423 |
| qf2_loss                | 0.002235652  |
| time_elapsed            | 190          |
| total timesteps         | 39900        |
| value_loss              | 0.004615942  |
------------------------------------------
Eval num_timesteps=40000, episode_reward=-1.02 +/- 0.57
Episode length: 100.00 +/- 0.00
New best mean reward!
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.00837231   |
| ent_coef_loss           | -3.6054964   |
| entropy                 | 1.7157004    |
| ep_rewmean              | -2.3         |
| episodes                | 404          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.3         |
| n_updates               | 40201        |
| policy_loss             | -1.4269855   |
| qf1_loss                | 0.0023513462 |
| qf2_loss                | 0.0018276694 |
| time_elapsed            | 192          |
| total timesteps         | 40300        |
| value_loss              | 0.0023862422 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.00786843   |
| ent_coef_loss           | -1.7237014   |
| entropy                 | 2.1137326    |
| ep_rewmean              | -2.34        |
| episodes                | 408          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.3         |
| n_updates               | 40601        |
| policy_loss             | -1.208442    |
| qf1_loss                | 0.008876258  |
| qf2_loss                | 0.011000609  |
| time_elapsed            | 194          |
| total timesteps         | 40700        |
| value_loss              | 0.0058537377 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.007423474  |
| ent_coef_loss           | -4.410663    |
| entropy                 | 2.6869707    |
| ep_rewmean              | -2.38        |
| episodes                | 412          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.4         |
| n_updates               | 41001        |
| policy_loss             | -1.0076137   |
| qf1_loss                | 0.01294918   |
| qf2_loss                | 0.01289589   |
| time_elapsed            | 196          |
| total timesteps         | 41100        |
| value_loss              | 0.0032010083 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.006582428  |
| ent_coef_loss           | 0.25319338   |
| entropy                 | 1.8033848    |
| ep_rewmean              | -2.43        |
| episodes                | 416          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.4         |
| n_updates               | 41401        |
| policy_loss             | -0.99137056  |
| qf1_loss                | 0.0043659112 |
| qf2_loss                | 0.004335916  |
| time_elapsed            | 198          |
| total timesteps         | 41500        |
| value_loss              | 0.0019736434 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.005979849  |
| ent_coef_loss           | -1.7749627   |
| entropy                 | 1.7787685    |
| ep_rewmean              | -2.46        |
| episodes                | 420          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.5         |
| n_updates               | 41801        |
| policy_loss             | -0.8236158   |
| qf1_loss                | 0.001845456  |
| qf2_loss                | 0.0010090785 |
| time_elapsed            | 200          |
| total timesteps         | 41900        |
| value_loss              | 0.0021507773 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.005289177  |
| ent_coef_loss           | -8.449976    |
| entropy                 | 2.4814918    |
| ep_rewmean              | -2.48        |
| episodes                | 424          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.5         |
| n_updates               | 42201        |
| policy_loss             | -0.7472734   |
| qf1_loss                | 0.013198682  |
| qf2_loss                | 0.009009888  |
| time_elapsed            | 202          |
| total timesteps         | 42300        |
| value_loss              | 0.0017441099 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0051820744 |
| ent_coef_loss           | 0.60989106   |
| entropy                 | 2.809515     |
| ep_rewmean              | -2.45        |
| episodes                | 428          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.5         |
| n_updates               | 42601        |
| policy_loss             | -0.75748134  |
| qf1_loss                | 0.0017746378 |
| qf2_loss                | 0.0020962832 |
| time_elapsed            | 204          |
| total timesteps         | 42700        |
| value_loss              | 0.002329697  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0050551184  |
| ent_coef_loss           | -7.5837073    |
| entropy                 | 3.404152      |
| ep_rewmean              | -2.47         |
| episodes                | 432           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 43001         |
| policy_loss             | -0.63787556   |
| qf1_loss                | 0.0007329911  |
| qf2_loss                | 0.00087973033 |
| time_elapsed            | 205           |
| total timesteps         | 43100         |
| value_loss              | 0.00088415697 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.004437456   |
| ent_coef_loss           | -8.483378     |
| entropy                 | 3.590375      |
| ep_rewmean              | -2.45         |
| episodes                | 436           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 43401         |
| policy_loss             | -0.512866     |
| qf1_loss                | 0.00069306535 |
| qf2_loss                | 0.00063659897 |
| time_elapsed            | 207           |
| total timesteps         | 43500         |
| value_loss              | 0.0010372619  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0042717084  |
| ent_coef_loss           | -7.6802826    |
| entropy                 | 3.7623763     |
| ep_rewmean              | -2.47         |
| episodes                | 440           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 43801         |
| policy_loss             | -0.59594834   |
| qf1_loss                | 0.00069727894 |
| qf2_loss                | 0.0006307097  |
| time_elapsed            | 209           |
| total timesteps         | 43900         |
| value_loss              | 0.0011986096  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.003986482  |
| ent_coef_loss           | -1.4861695   |
| entropy                 | 3.7162428    |
| ep_rewmean              | -2.38        |
| episodes                | 444          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.4         |
| n_updates               | 44201        |
| policy_loss             | -0.46278736  |
| qf1_loss                | 0.0011846957 |
| qf2_loss                | 0.0016646918 |
| time_elapsed            | 211          |
| total timesteps         | 44300        |
| value_loss              | 0.0010240315 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0039967736 |
| ent_coef_loss           | -3.6433744   |
| entropy                 | 3.368173     |
| ep_rewmean              | -2.35        |
| episodes                | 448          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.4         |
| n_updates               | 44601        |
| policy_loss             | -0.43779087  |
| qf1_loss                | 0.0031284525 |
| qf2_loss                | 0.0027109212 |
| time_elapsed            | 213          |
| total timesteps         | 44700        |
| value_loss              | 0.0020902795 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0041204547  |
| ent_coef_loss           | -3.9799128    |
| entropy                 | 3.1916633     |
| ep_rewmean              | -2.35         |
| episodes                | 452           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 45001         |
| policy_loss             | -0.42011106   |
| qf1_loss                | 0.0007484568  |
| qf2_loss                | 0.00087730435 |
| time_elapsed            | 215           |
| total timesteps         | 45100         |
| value_loss              | 0.0015439471  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.004073936  |
| ent_coef_loss           | -1.161437    |
| entropy                 | 3.397762     |
| ep_rewmean              | -2.38        |
| episodes                | 456          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.4         |
| n_updates               | 45401        |
| policy_loss             | -0.19885306  |
| qf1_loss                | 0.0010166413 |
| qf2_loss                | 0.0014692869 |
| time_elapsed            | 217          |
| total timesteps         | 45500        |
| value_loss              | 0.0011110188 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0038588138 |
| ent_coef_loss           | 2.8250468    |
| entropy                 | 3.4381466    |
| ep_rewmean              | -2.37        |
| episodes                | 460          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.4         |
| n_updates               | 45801        |
| policy_loss             | -0.25029343  |
| qf1_loss                | 0.00251752   |
| qf2_loss                | 0.0023679747 |
| time_elapsed            | 219          |
| total timesteps         | 45900        |
| value_loss              | 0.0010524786 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0037659374  |
| ent_coef_loss           | 2.8282673     |
| entropy                 | 4.4722447     |
| ep_rewmean              | -2.39         |
| episodes                | 464           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 46201         |
| policy_loss             | -0.06632818   |
| qf1_loss                | 0.00056905346 |
| qf2_loss                | 0.0005040993  |
| time_elapsed            | 221           |
| total timesteps         | 46300         |
| value_loss              | 0.0007659593  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0034035924  |
| ent_coef_loss           | -2.1711073    |
| entropy                 | 3.5673716     |
| ep_rewmean              | -2.39         |
| episodes                | 468           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 46601         |
| policy_loss             | -0.1192892    |
| qf1_loss                | 0.0003720277  |
| qf2_loss                | 0.00041359075 |
| time_elapsed            | 223           |
| total timesteps         | 46700         |
| value_loss              | 0.0005660638  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0031580196  |
| ent_coef_loss           | -3.1005256    |
| entropy                 | 3.7518888     |
| ep_rewmean              | -2.34         |
| episodes                | 472           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.3          |
| n_updates               | 47001         |
| policy_loss             | -0.018010829  |
| qf1_loss                | 0.0011444311  |
| qf2_loss                | 0.0010398428  |
| time_elapsed            | 224           |
| total timesteps         | 47100         |
| value_loss              | 0.00049249886 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0027887279 |
| ent_coef_loss           | -2.119904    |
| entropy                 | 3.7205186    |
| ep_rewmean              | -2.32        |
| episodes                | 476          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.3         |
| n_updates               | 47401        |
| policy_loss             | 0.053250093  |
| qf1_loss                | 0.0011967635 |
| qf2_loss                | 0.0009503517 |
| time_elapsed            | 226          |
| total timesteps         | 47500        |
| value_loss              | 0.0010652312 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0024472433  |
| ent_coef_loss           | -11.6825      |
| entropy                 | 3.5543268     |
| ep_rewmean              | -2.35         |
| episodes                | 480           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.3          |
| n_updates               | 47801         |
| policy_loss             | 0.017764159   |
| qf1_loss                | 0.0002820305  |
| qf2_loss                | 0.0003494242  |
| time_elapsed            | 228           |
| total timesteps         | 47900         |
| value_loss              | 0.00028667104 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021379981  |
| ent_coef_loss           | -1.6081089    |
| entropy                 | 3.1956058     |
| ep_rewmean              | -2.35         |
| episodes                | 484           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 48201         |
| policy_loss             | 0.05591511    |
| qf1_loss                | 0.00016208019 |
| qf2_loss                | 0.00025922566 |
| time_elapsed            | 230           |
| total timesteps         | 48300         |
| value_loss              | 0.00026950357 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019948403  |
| ent_coef_loss           | -0.04724902   |
| entropy                 | 3.3640726     |
| ep_rewmean              | -2.38         |
| episodes                | 488           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 48601         |
| policy_loss             | 0.085838675   |
| qf1_loss                | 0.00032091176 |
| qf2_loss                | 0.000316384   |
| time_elapsed            | 232           |
| total timesteps         | 48700         |
| value_loss              | 0.00045146773 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018718207  |
| ent_coef_loss           | 5.4156914     |
| entropy                 | 3.4776525     |
| ep_rewmean              | -2.44         |
| episodes                | 492           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 49001         |
| policy_loss             | 0.12181833    |
| qf1_loss                | 0.00021133928 |
| qf2_loss                | 0.00025744917 |
| time_elapsed            | 234           |
| total timesteps         | 49100         |
| value_loss              | 0.00031045527 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00175904    |
| ent_coef_loss           | -8.218636     |
| entropy                 | 3.28236       |
| ep_rewmean              | -2.43         |
| episodes                | 496           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 49401         |
| policy_loss             | 0.15146093    |
| qf1_loss                | 0.00026034302 |
| qf2_loss                | 0.00029566043 |
| time_elapsed            | 236           |
| total timesteps         | 49500         |
| value_loss              | 0.00020847475 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016759557  |
| ent_coef_loss           | 1.492489      |
| entropy                 | 3.0036259     |
| ep_rewmean              | -2.58         |
| episodes                | 500           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.6          |
| n_updates               | 49801         |
| policy_loss             | 0.18998042    |
| qf1_loss                | 0.00015204443 |
| qf2_loss                | 0.00014493012 |
| time_elapsed            | 238           |
| total timesteps         | 49900         |
| value_loss              | 0.00032565865 |
-------------------------------------------
Eval num_timesteps=50000, episode_reward=-1.40 +/- 0.85
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001675549   |
| ent_coef_loss           | 5.492899      |
| entropy                 | 3.1578035     |
| ep_rewmean              | -2.57         |
| episodes                | 504           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.6          |
| n_updates               | 50201         |
| policy_loss             | 0.1866854     |
| qf1_loss                | 0.0018958868  |
| qf2_loss                | 0.0020176724  |
| time_elapsed            | 240           |
| total timesteps         | 50300         |
| value_loss              | 0.00034437928 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016483839  |
| ent_coef_loss           | -8.211284     |
| entropy                 | 3.6636627     |
| ep_rewmean              | -2.54         |
| episodes                | 508           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 50601         |
| policy_loss             | 0.23271431    |
| qf1_loss                | 0.0003951604  |
| qf2_loss                | 0.0003058333  |
| time_elapsed            | 242           |
| total timesteps         | 50700         |
| value_loss              | 0.00048751006 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015572398  |
| ent_coef_loss           | -5.5500183    |
| entropy                 | 3.303529      |
| ep_rewmean              | -2.51         |
| episodes                | 512           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 51001         |
| policy_loss             | 0.24201965    |
| qf1_loss                | 0.00016218422 |
| qf2_loss                | 0.00018264486 |
| time_elapsed            | 244           |
| total timesteps         | 51100         |
| value_loss              | 0.00036455947 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014729757  |
| ent_coef_loss           | 3.8024206     |
| entropy                 | 3.0045135     |
| ep_rewmean              | -2.44         |
| episodes                | 516           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 51401         |
| policy_loss             | 0.23954397    |
| qf1_loss                | 0.00016231953 |
| qf2_loss                | 0.00012798031 |
| time_elapsed            | 246           |
| total timesteps         | 51500         |
| value_loss              | 0.00018178145 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014132033  |
| ent_coef_loss           | -3.187676     |
| entropy                 | 3.2080898     |
| ep_rewmean              | -2.42         |
| episodes                | 520           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 51801         |
| policy_loss             | 0.27055672    |
| qf1_loss                | 0.00025382388 |
| qf2_loss                | 0.0002604917  |
| time_elapsed            | 248           |
| total timesteps         | 51900         |
| value_loss              | 0.00022839649 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014217894  |
| ent_coef_loss           | 0.9734497     |
| entropy                 | 3.3197865     |
| ep_rewmean              | -2.39         |
| episodes                | 524           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 52201         |
| policy_loss             | 0.28844526    |
| qf1_loss                | 0.005157389   |
| qf2_loss                | 0.005158523   |
| time_elapsed            | 249           |
| total timesteps         | 52300         |
| value_loss              | 0.00025285274 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014384029  |
| ent_coef_loss           | -0.85263544   |
| entropy                 | 3.369513      |
| ep_rewmean              | -2.39         |
| episodes                | 528           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 52601         |
| policy_loss             | 0.31740385    |
| qf1_loss                | 0.00019422454 |
| qf2_loss                | 0.00021142053 |
| time_elapsed            | 251           |
| total timesteps         | 52700         |
| value_loss              | 0.00017733901 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014267213 |
| ent_coef_loss           | -1.9868207   |
| entropy                 | 3.405429     |
| ep_rewmean              | -2.36        |
| episodes                | 532          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.4         |
| n_updates               | 53001        |
| policy_loss             | 0.31815726   |
| qf1_loss                | 0.001178436  |
| qf2_loss                | 0.0011974673 |
| time_elapsed            | 253          |
| total timesteps         | 53100        |
| value_loss              | 0.0011548938 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013840474  |
| ent_coef_loss           | -3.7246685    |
| entropy                 | 3.598498      |
| ep_rewmean              | -2.46         |
| episodes                | 536           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 53401         |
| policy_loss             | 0.37032723    |
| qf1_loss                | 0.0012920549  |
| qf2_loss                | 0.001350299   |
| time_elapsed            | 255           |
| total timesteps         | 53500         |
| value_loss              | 0.00016279076 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.001353154    |
| ent_coef_loss           | -1.8853623     |
| entropy                 | 3.8356767      |
| ep_rewmean              | -2.43          |
| episodes                | 540            |
| eplenmean               | 100            |
| fps                     | 209            |
| mean 100 episode reward | -2.4           |
| n_updates               | 53801          |
| policy_loss             | 0.38253388     |
| qf1_loss                | 0.0017819392   |
| qf2_loss                | 0.0018876389   |
| time_elapsed            | 257            |
| total timesteps         | 53900          |
| value_loss              | 0.000120085984 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012406125  |
| ent_coef_loss           | 4.5423784     |
| entropy                 | 3.79596       |
| ep_rewmean              | -2.44         |
| episodes                | 544           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 54201         |
| policy_loss             | 0.38845897    |
| qf1_loss                | 0.0002830191  |
| qf2_loss                | 0.00032324262 |
| time_elapsed            | 259           |
| total timesteps         | 54300         |
| value_loss              | 0.0001828058  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011794278  |
| ent_coef_loss           | -2.6145842    |
| entropy                 | 3.7393973     |
| ep_rewmean              | -2.41         |
| episodes                | 548           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 54601         |
| policy_loss             | 0.44262293    |
| qf1_loss                | 0.0033505445  |
| qf2_loss                | 0.0031916178  |
| time_elapsed            | 261           |
| total timesteps         | 54700         |
| value_loss              | 0.00017545352 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010813598  |
| ent_coef_loss           | -10.322418    |
| entropy                 | 3.741813      |
| ep_rewmean              | -2.37         |
| episodes                | 552           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 55001         |
| policy_loss             | 0.46392167    |
| qf1_loss                | 0.00024130686 |
| qf2_loss                | 0.00017949627 |
| time_elapsed            | 263           |
| total timesteps         | 55100         |
| value_loss              | 0.00011276531 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010152716  |
| ent_coef_loss           | 10.709904     |
| entropy                 | 2.6692019     |
| ep_rewmean              | -2.37         |
| episodes                | 556           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 55401         |
| policy_loss             | 0.43745393    |
| qf1_loss                | 0.00043619392 |
| qf2_loss                | 0.000321624   |
| time_elapsed            | 265           |
| total timesteps         | 55500         |
| value_loss              | 0.0001761453  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011023186 |
| ent_coef_loss           | -5.658982    |
| entropy                 | 3.2561283    |
| ep_rewmean              | -2.4         |
| episodes                | 560          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.4         |
| n_updates               | 55801        |
| policy_loss             | 0.4878875    |
| qf1_loss                | 0.0027657284 |
| qf2_loss                | 0.002823358  |
| time_elapsed            | 267          |
| total timesteps         | 55900        |
| value_loss              | 0.000383652  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011547712  |
| ent_coef_loss           | 0.826121      |
| entropy                 | 3.7922716     |
| ep_rewmean              | -2.37         |
| episodes                | 564           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 56201         |
| policy_loss             | 0.49903673    |
| qf1_loss                | 0.0030063337  |
| qf2_loss                | 0.0031688416  |
| time_elapsed            | 269           |
| total timesteps         | 56300         |
| value_loss              | 0.00036430327 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011975408  |
| ent_coef_loss           | 9.77835       |
| entropy                 | 3.6280553     |
| ep_rewmean              | -2.33         |
| episodes                | 568           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.3          |
| n_updates               | 56601         |
| policy_loss             | 0.52714527    |
| qf1_loss                | 0.00024056615 |
| qf2_loss                | 0.00018458703 |
| time_elapsed            | 270           |
| total timesteps         | 56700         |
| value_loss              | 0.0001285493  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012261571  |
| ent_coef_loss           | 16.182728     |
| entropy                 | 3.1409545     |
| ep_rewmean              | -2.28         |
| episodes                | 572           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.3          |
| n_updates               | 57001         |
| policy_loss             | 0.5444765     |
| qf1_loss                | 0.00016079817 |
| qf2_loss                | 0.00016824524 |
| time_elapsed            | 272           |
| total timesteps         | 57100         |
| value_loss              | 0.00021930045 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013560102  |
| ent_coef_loss           | 9.180708      |
| entropy                 | 3.9805417     |
| ep_rewmean              | -2.22         |
| episodes                | 576           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 57401         |
| policy_loss             | 0.53701913    |
| qf1_loss                | 0.00026670744 |
| qf2_loss                | 0.00022321244 |
| time_elapsed            | 274           |
| total timesteps         | 57500         |
| value_loss              | 0.00016002916 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014222654  |
| ent_coef_loss           | -4.5446806    |
| entropy                 | 3.9236403     |
| ep_rewmean              | -2.19         |
| episodes                | 580           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 57801         |
| policy_loss             | 0.5677872     |
| qf1_loss                | 0.0027940962  |
| qf2_loss                | 0.002820147   |
| time_elapsed            | 276           |
| total timesteps         | 57900         |
| value_loss              | 0.00010793949 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014409065  |
| ent_coef_loss           | 1.2454695     |
| entropy                 | 3.7180173     |
| ep_rewmean              | -2.17         |
| episodes                | 584           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 58201         |
| policy_loss             | 0.545005      |
| qf1_loss                | 0.0028975527  |
| qf2_loss                | 0.0030111698  |
| time_elapsed            | 278           |
| total timesteps         | 58300         |
| value_loss              | 0.00021297336 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013543683  |
| ent_coef_loss           | -5.7321873    |
| entropy                 | 4.5897417     |
| ep_rewmean              | -2.16         |
| episodes                | 588           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 58601         |
| policy_loss             | 0.5945711     |
| qf1_loss                | 0.00014371288 |
| qf2_loss                | 0.00017074723 |
| time_elapsed            | 280           |
| total timesteps         | 58700         |
| value_loss              | 0.00032627292 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001282339   |
| ent_coef_loss           | 0.381302      |
| entropy                 | 3.119717      |
| ep_rewmean              | -2.12         |
| episodes                | 592           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 59001         |
| policy_loss             | 0.52498376    |
| qf1_loss                | 0.00018996415 |
| qf2_loss                | 0.00030408206 |
| time_elapsed            | 282           |
| total timesteps         | 59100         |
| value_loss              | 0.0003851811  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012190151  |
| ent_coef_loss           | -6.444278     |
| entropy                 | 3.8178916     |
| ep_rewmean              | -2.14         |
| episodes                | 596           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 59401         |
| policy_loss             | 0.60956717    |
| qf1_loss                | 0.00035103865 |
| qf2_loss                | 0.00038246482 |
| time_elapsed            | 284           |
| total timesteps         | 59500         |
| value_loss              | 0.0001769338  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00121707    |
| ent_coef_loss           | 5.1672163     |
| entropy                 | 3.4055512     |
| ep_rewmean              | -2            |
| episodes                | 600           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 59801         |
| policy_loss             | 0.60078514    |
| qf1_loss                | 0.00025304765 |
| qf2_loss                | 0.0002472974  |
| time_elapsed            | 286           |
| total timesteps         | 59900         |
| value_loss              | 0.00013065417 |
-------------------------------------------
Eval num_timesteps=60000, episode_reward=-2.24 +/- 0.59
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012541433  |
| ent_coef_loss           | -1.1235452    |
| entropy                 | 4.171484      |
| ep_rewmean              | -1.98         |
| episodes                | 604           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 60201         |
| policy_loss             | 0.61481476    |
| qf1_loss                | 0.00017216417 |
| qf2_loss                | 0.00011487854 |
| time_elapsed            | 288           |
| total timesteps         | 60300         |
| value_loss              | 0.0003390028  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012958287  |
| ent_coef_loss           | 8.308838      |
| entropy                 | 3.788157      |
| ep_rewmean              | -2.05         |
| episodes                | 608           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 60601         |
| policy_loss             | 0.64884764    |
| qf1_loss                | 0.00015271529 |
| qf2_loss                | 0.00015600037 |
| time_elapsed            | 290           |
| total timesteps         | 60700         |
| value_loss              | 0.00021553288 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012887343  |
| ent_coef_loss           | -5.2990646    |
| entropy                 | 3.724886      |
| ep_rewmean              | -2.11         |
| episodes                | 612           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 61001         |
| policy_loss             | 0.64475405    |
| qf1_loss                | 0.0001404094  |
| qf2_loss                | 0.00021358515 |
| time_elapsed            | 292           |
| total timesteps         | 61100         |
| value_loss              | 0.00018685206 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012282397  |
| ent_coef_loss           | -1.8608345    |
| entropy                 | 3.4042888     |
| ep_rewmean              | -2.1          |
| episodes                | 616           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 61401         |
| policy_loss             | 0.6499876     |
| qf1_loss                | 0.0042144936  |
| qf2_loss                | 0.00419236    |
| time_elapsed            | 294           |
| total timesteps         | 61500         |
| value_loss              | 0.00049349916 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012125476  |
| ent_coef_loss           | 2.5882652     |
| entropy                 | 3.437788      |
| ep_rewmean              | -2.11         |
| episodes                | 620           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 61801         |
| policy_loss             | 0.6666233     |
| qf1_loss                | 0.00023516692 |
| qf2_loss                | 0.000218984   |
| time_elapsed            | 295           |
| total timesteps         | 61900         |
| value_loss              | 0.0002627641  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011612106 |
| ent_coef_loss           | -11.679561   |
| entropy                 | 2.5838332    |
| ep_rewmean              | -2.11        |
| episodes                | 624          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.1         |
| n_updates               | 62201        |
| policy_loss             | 0.6333221    |
| qf1_loss                | 0.0030727822 |
| qf2_loss                | 0.0033376538 |
| time_elapsed            | 297          |
| total timesteps         | 62300        |
| value_loss              | 0.0008211607 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011167157  |
| ent_coef_loss           | -4.634006     |
| entropy                 | 2.3978777     |
| ep_rewmean              | -2.04         |
| episodes                | 628           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 62601         |
| policy_loss             | 0.6530691     |
| qf1_loss                | 0.00066725095 |
| qf2_loss                | 0.0005241002  |
| time_elapsed            | 299           |
| total timesteps         | 62700         |
| value_loss              | 0.0005368334  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011104087  |
| ent_coef_loss           | 11.0388365    |
| entropy                 | 2.8699198     |
| ep_rewmean              | -2.01         |
| episodes                | 632           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 63001         |
| policy_loss             | 0.6687932     |
| qf1_loss                | 0.0010397757  |
| qf2_loss                | 0.0010073334  |
| time_elapsed            | 301           |
| total timesteps         | 63100         |
| value_loss              | 0.00033567086 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011596314  |
| ent_coef_loss           | -1.0369303    |
| entropy                 | 2.559195      |
| ep_rewmean              | -1.91         |
| episodes                | 636           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.9          |
| n_updates               | 63401         |
| policy_loss             | 0.63120395    |
| qf1_loss                | 0.00017074801 |
| qf2_loss                | 0.00012941741 |
| time_elapsed            | 303           |
| total timesteps         | 63500         |
| value_loss              | 0.00017158139 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011561839  |
| ent_coef_loss           | 0.6468769     |
| entropy                 | 2.6448479     |
| ep_rewmean              | -1.98         |
| episodes                | 640           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 63801         |
| policy_loss             | 0.71475726    |
| qf1_loss                | 0.0002194875  |
| qf2_loss                | 0.00027158865 |
| time_elapsed            | 305           |
| total timesteps         | 63900         |
| value_loss              | 0.00010372334 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010873333 |
| ent_coef_loss           | 8.257082     |
| entropy                 | 2.3836422    |
| ep_rewmean              | -2.02        |
| episodes                | 644          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2           |
| n_updates               | 64201        |
| policy_loss             | 0.6946101    |
| qf1_loss                | 0.005490714  |
| qf2_loss                | 0.005528861  |
| time_elapsed            | 307          |
| total timesteps         | 64300        |
| value_loss              | 0.0005948151 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011806027  |
| ent_coef_loss           | 1.5107391     |
| entropy                 | 2.0344625     |
| ep_rewmean              | -2.02         |
| episodes                | 648           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 64601         |
| policy_loss             | 0.65727335    |
| qf1_loss                | 0.00022225376 |
| qf2_loss                | 0.00022792554 |
| time_elapsed            | 309           |
| total timesteps         | 64700         |
| value_loss              | 0.000126586   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012359561  |
| ent_coef_loss           | -0.6794801    |
| entropy                 | 2.6610346     |
| ep_rewmean              | -2.08         |
| episodes                | 652           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 65001         |
| policy_loss             | 0.69129765    |
| qf1_loss                | 0.0035022078  |
| qf2_loss                | 0.0035006383  |
| time_elapsed            | 311           |
| total timesteps         | 65100         |
| value_loss              | 0.00023831385 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012359367  |
| ent_coef_loss           | -1.9808089    |
| entropy                 | 1.4843528     |
| ep_rewmean              | -2.06         |
| episodes                | 656           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 65401         |
| policy_loss             | 0.6652397     |
| qf1_loss                | 0.00021796915 |
| qf2_loss                | 0.00022496047 |
| time_elapsed            | 313           |
| total timesteps         | 65500         |
| value_loss              | 0.0001914416  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012182905  |
| ent_coef_loss           | -3.08221      |
| entropy                 | 1.9424382     |
| ep_rewmean              | -2.1          |
| episodes                | 660           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 65801         |
| policy_loss             | 0.67352515    |
| qf1_loss                | 0.00028283146 |
| qf2_loss                | 0.0002637869  |
| time_elapsed            | 314           |
| total timesteps         | 65900         |
| value_loss              | 0.00015899763 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013147666  |
| ent_coef_loss           | 0.7076752     |
| entropy                 | 2.6276863     |
| ep_rewmean              | -2.14         |
| episodes                | 664           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 66201         |
| policy_loss             | 0.7013626     |
| qf1_loss                | 0.00017689833 |
| qf2_loss                | 0.00019004014 |
| time_elapsed            | 316           |
| total timesteps         | 66300         |
| value_loss              | 0.00034658427 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013104773  |
| ent_coef_loss           | -7.1553116    |
| entropy                 | 2.7375345     |
| ep_rewmean              | -2.16         |
| episodes                | 668           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 66601         |
| policy_loss             | 0.67537457    |
| qf1_loss                | 0.00022002554 |
| qf2_loss                | 0.00020822926 |
| time_elapsed            | 318           |
| total timesteps         | 66700         |
| value_loss              | 0.00022442779 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012783913 |
| ent_coef_loss           | -0.8750074   |
| entropy                 | 3.0674062    |
| ep_rewmean              | -2.18        |
| episodes                | 672          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.2         |
| n_updates               | 67001        |
| policy_loss             | 0.71994567   |
| qf1_loss                | 0.004305742  |
| qf2_loss                | 0.0041177925 |
| time_elapsed            | 320          |
| total timesteps         | 67100        |
| value_loss              | 0.0008443749 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011903106  |
| ent_coef_loss           | -6.16061      |
| entropy                 | 2.2419739     |
| ep_rewmean              | -2.24         |
| episodes                | 676           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 67401         |
| policy_loss             | 0.715867      |
| qf1_loss                | 0.007886372   |
| qf2_loss                | 0.008087464   |
| time_elapsed            | 322           |
| total timesteps         | 67500         |
| value_loss              | 0.00018244135 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011873367  |
| ent_coef_loss           | 5.0914636     |
| entropy                 | 1.6692145     |
| ep_rewmean              | -2.25         |
| episodes                | 680           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.3          |
| n_updates               | 67801         |
| policy_loss             | 0.68786407    |
| qf1_loss                | 0.00017690231 |
| qf2_loss                | 0.00016371193 |
| time_elapsed            | 324           |
| total timesteps         | 67900         |
| value_loss              | 0.00022762944 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012415368  |
| ent_coef_loss           | 17.91947      |
| entropy                 | 2.4080858     |
| ep_rewmean              | -2.31         |
| episodes                | 684           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.3          |
| n_updates               | 68201         |
| policy_loss             | 0.67524445    |
| qf1_loss                | 0.0019960331  |
| qf2_loss                | 0.0019697994  |
| time_elapsed            | 326           |
| total timesteps         | 68300         |
| value_loss              | 0.00023746047 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014952567  |
| ent_coef_loss           | 6.8949785     |
| entropy                 | 3.228881      |
| ep_rewmean              | -2.27         |
| episodes                | 688           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.3          |
| n_updates               | 68601         |
| policy_loss             | 0.6154053     |
| qf1_loss                | 0.00039147917 |
| qf2_loss                | 0.00040842127 |
| time_elapsed            | 328           |
| total timesteps         | 68700         |
| value_loss              | 0.00035686142 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014892475  |
| ent_coef_loss           | -8.125801     |
| entropy                 | 3.249114      |
| ep_rewmean              | -2.21         |
| episodes                | 692           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 69001         |
| policy_loss             | 0.6119205     |
| qf1_loss                | 0.00024147824 |
| qf2_loss                | 0.0002565289  |
| time_elapsed            | 330           |
| total timesteps         | 69100         |
| value_loss              | 0.00021763702 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012949132  |
| ent_coef_loss           | -8.154399     |
| entropy                 | 3.4227223     |
| ep_rewmean              | -2.16         |
| episodes                | 696           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 69401         |
| policy_loss             | 0.65352905    |
| qf1_loss                | 0.00019206878 |
| qf2_loss                | 0.00016531206 |
| time_elapsed            | 332           |
| total timesteps         | 69500         |
| value_loss              | 0.00032701745 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012460675  |
| ent_coef_loss           | 3.2678664     |
| entropy                 | 3.169248      |
| ep_rewmean              | -2.18         |
| episodes                | 700           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 69801         |
| policy_loss             | 0.60296273    |
| qf1_loss                | 0.0076059983  |
| qf2_loss                | 0.0076699806  |
| time_elapsed            | 333           |
| total timesteps         | 69900         |
| value_loss              | 0.00024135225 |
-------------------------------------------
Eval num_timesteps=70000, episode_reward=-1.79 +/- 0.63
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001173698   |
| ent_coef_loss           | -6.43705      |
| entropy                 | 3.2480526     |
| ep_rewmean              | -2.16         |
| episodes                | 704           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 70201         |
| policy_loss             | 0.64784944    |
| qf1_loss                | 0.00018376869 |
| qf2_loss                | 0.00019064617 |
| time_elapsed            | 336           |
| total timesteps         | 70300         |
| value_loss              | 0.00021565941 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011925683 |
| ent_coef_loss           | 5.3275356    |
| entropy                 | 2.6373916    |
| ep_rewmean              | -2.15        |
| episodes                | 708          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.1         |
| n_updates               | 70601        |
| policy_loss             | 0.6053695    |
| qf1_loss                | 0.0010828786 |
| qf2_loss                | 0.0011090448 |
| time_elapsed            | 337          |
| total timesteps         | 70700        |
| value_loss              | 0.0005769633 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012160084  |
| ent_coef_loss           | 9.447426      |
| entropy                 | 2.2822404     |
| ep_rewmean              | -2.11         |
| episodes                | 712           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 71001         |
| policy_loss             | 0.5916149     |
| qf1_loss                | 0.0037543853  |
| qf2_loss                | 0.0037765051  |
| time_elapsed            | 339           |
| total timesteps         | 71100         |
| value_loss              | 0.00034751437 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012540853  |
| ent_coef_loss           | 3.4830413     |
| entropy                 | 2.3839846     |
| ep_rewmean              | -2.15         |
| episodes                | 716           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 71401         |
| policy_loss             | 0.6022124     |
| qf1_loss                | 0.00021229402 |
| qf2_loss                | 0.00024379976 |
| time_elapsed            | 341           |
| total timesteps         | 71500         |
| value_loss              | 0.00032954826 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012694291  |
| ent_coef_loss           | -6.0844774    |
| entropy                 | 2.626574      |
| ep_rewmean              | -2.12         |
| episodes                | 720           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 71801         |
| policy_loss             | 0.61547637    |
| qf1_loss                | 0.00013101213 |
| qf2_loss                | 0.00014708802 |
| time_elapsed            | 343           |
| total timesteps         | 71900         |
| value_loss              | 0.00014530936 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012542838  |
| ent_coef_loss           | -4.886186     |
| entropy                 | 2.0577707     |
| ep_rewmean              | -2.15         |
| episodes                | 724           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 72201         |
| policy_loss             | 0.61522365    |
| qf1_loss                | 0.00026237234 |
| qf2_loss                | 0.00022370515 |
| time_elapsed            | 345           |
| total timesteps         | 72300         |
| value_loss              | 0.0001431886  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00131823    |
| ent_coef_loss           | -4.8290687    |
| entropy                 | 2.5314255     |
| ep_rewmean              | -2.17         |
| episodes                | 728           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 72601         |
| policy_loss             | 0.6306989     |
| qf1_loss                | 0.004647965   |
| qf2_loss                | 0.004502758   |
| time_elapsed            | 347           |
| total timesteps         | 72700         |
| value_loss              | 0.00011897115 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013458298  |
| ent_coef_loss           | -0.040427566  |
| entropy                 | 2.900216      |
| ep_rewmean              | -2.16         |
| episodes                | 732           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 73001         |
| policy_loss             | 0.63548124    |
| qf1_loss                | 0.0019535827  |
| qf2_loss                | 0.0020772635  |
| time_elapsed            | 349           |
| total timesteps         | 73100         |
| value_loss              | 0.00014552087 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013308185  |
| ent_coef_loss           | 3.247582      |
| entropy                 | 2.0826378     |
| ep_rewmean              | -2.17         |
| episodes                | 736           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 73401         |
| policy_loss             | 0.63761085    |
| qf1_loss                | 0.00023264464 |
| qf2_loss                | 0.00021559557 |
| time_elapsed            | 351           |
| total timesteps         | 73500         |
| value_loss              | 0.00017257081 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013787929  |
| ent_coef_loss           | 13.108352     |
| entropy                 | 2.4693577     |
| ep_rewmean              | -2.13         |
| episodes                | 740           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 73801         |
| policy_loss             | 0.59338176    |
| qf1_loss                | 0.0003711119  |
| qf2_loss                | 0.00034723213 |
| time_elapsed            | 353           |
| total timesteps         | 73900         |
| value_loss              | 0.0002807207  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014523932  |
| ent_coef_loss           | -1.9488571    |
| entropy                 | 2.6400437     |
| ep_rewmean              | -2.09         |
| episodes                | 744           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 74201         |
| policy_loss             | 0.5947449     |
| qf1_loss                | 0.0049591055  |
| qf2_loss                | 0.004704102   |
| time_elapsed            | 355           |
| total timesteps         | 74300         |
| value_loss              | 0.00019167559 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014453636  |
| ent_coef_loss           | -3.444025     |
| entropy                 | 3.1447973     |
| ep_rewmean              | -2.1          |
| episodes                | 748           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 74601         |
| policy_loss             | 0.6284963     |
| qf1_loss                | 0.00041048057 |
| qf2_loss                | 0.0003521627  |
| time_elapsed            | 356           |
| total timesteps         | 74700         |
| value_loss              | 0.00034758417 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015428566  |
| ent_coef_loss           | 3.6007662     |
| entropy                 | 2.8676004     |
| ep_rewmean              | -2.05         |
| episodes                | 752           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 75001         |
| policy_loss             | 0.6057591     |
| qf1_loss                | 0.00032901473 |
| qf2_loss                | 0.00025510596 |
| time_elapsed            | 358           |
| total timesteps         | 75100         |
| value_loss              | 0.00023880764 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015781736  |
| ent_coef_loss           | -1.75209      |
| entropy                 | 3.1509519     |
| ep_rewmean              | -2.05         |
| episodes                | 756           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 75401         |
| policy_loss             | 0.61067545    |
| qf1_loss                | 0.00036371744 |
| qf2_loss                | 0.0003740046  |
| time_elapsed            | 360           |
| total timesteps         | 75500         |
| value_loss              | 0.00017364178 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00164103    |
| ent_coef_loss           | 3.6029522     |
| entropy                 | 2.879015      |
| ep_rewmean              | -1.99         |
| episodes                | 760           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 75801         |
| policy_loss             | 0.5672034     |
| qf1_loss                | 0.00025090767 |
| qf2_loss                | 0.0002484084  |
| time_elapsed            | 362           |
| total timesteps         | 75900         |
| value_loss              | 0.0003532421  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017060603  |
| ent_coef_loss           | -3.1964512    |
| entropy                 | 2.7383244     |
| ep_rewmean              | -1.94         |
| episodes                | 764           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.9          |
| n_updates               | 76201         |
| policy_loss             | 0.5932375     |
| qf1_loss                | 0.00020813319 |
| qf2_loss                | 0.00019512259 |
| time_elapsed            | 364           |
| total timesteps         | 76300         |
| value_loss              | 0.00030142858 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017554094  |
| ent_coef_loss           | 9.212542      |
| entropy                 | 3.2075634     |
| ep_rewmean              | -1.95         |
| episodes                | 768           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 76601         |
| policy_loss             | 0.5746796     |
| qf1_loss                | 0.00027465195 |
| qf2_loss                | 0.0001898687  |
| time_elapsed            | 366           |
| total timesteps         | 76700         |
| value_loss              | 0.00030442752 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018019819  |
| ent_coef_loss           | 7.542343      |
| entropy                 | 3.2696917     |
| ep_rewmean              | -1.95         |
| episodes                | 772           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.9          |
| n_updates               | 77001         |
| policy_loss             | 0.5905832     |
| qf1_loss                | 0.0059680464  |
| qf2_loss                | 0.0059399037  |
| time_elapsed            | 368           |
| total timesteps         | 77100         |
| value_loss              | 0.00033584924 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017901802  |
| ent_coef_loss           | 2.3405495     |
| entropy                 | 3.7567358     |
| ep_rewmean              | -1.88         |
| episodes                | 776           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.9          |
| n_updates               | 77401         |
| policy_loss             | 0.57958204    |
| qf1_loss                | 0.0003669271  |
| qf2_loss                | 0.00036406878 |
| time_elapsed            | 370           |
| total timesteps         | 77500         |
| value_loss              | 0.0002832649  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0018227276 |
| ent_coef_loss           | 1.9960625    |
| entropy                 | 3.5172112    |
| ep_rewmean              | -1.88        |
| episodes                | 780          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -1.9         |
| n_updates               | 77801        |
| policy_loss             | 0.5579829    |
| qf1_loss                | 0.0014097153 |
| qf2_loss                | 0.0013614184 |
| time_elapsed            | 372          |
| total timesteps         | 77900        |
| value_loss              | 0.0005100586 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018124349  |
| ent_coef_loss           | -1.3388996    |
| entropy                 | 4.0971947     |
| ep_rewmean              | -1.83         |
| episodes                | 784           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.8          |
| n_updates               | 78201         |
| policy_loss             | 0.63366055    |
| qf1_loss                | 0.00019828696 |
| qf2_loss                | 0.00020822728 |
| time_elapsed            | 374           |
| total timesteps         | 78300         |
| value_loss              | 0.0004214193  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018085283  |
| ent_coef_loss           | -10.787058    |
| entropy                 | 3.9836        |
| ep_rewmean              | -1.82         |
| episodes                | 788           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.8          |
| n_updates               | 78601         |
| policy_loss             | 0.60777974    |
| qf1_loss                | 0.00019801114 |
| qf2_loss                | 0.00020930346 |
| time_elapsed            | 375           |
| total timesteps         | 78700         |
| value_loss              | 0.00031803784 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017447886  |
| ent_coef_loss           | -1.1778377    |
| entropy                 | 3.1023996     |
| ep_rewmean              | -1.86         |
| episodes                | 792           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.9          |
| n_updates               | 79001         |
| policy_loss             | 0.5668917     |
| qf1_loss                | 0.00026679522 |
| qf2_loss                | 0.00033738662 |
| time_elapsed            | 377           |
| total timesteps         | 79100         |
| value_loss              | 0.0005411281  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016633844  |
| ent_coef_loss           | -2.8852086    |
| entropy                 | 3.4557958     |
| ep_rewmean              | -1.87         |
| episodes                | 796           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.9          |
| n_updates               | 79401         |
| policy_loss             | 0.5592532     |
| qf1_loss                | 0.0037819988  |
| qf2_loss                | 0.0034046648  |
| time_elapsed            | 379           |
| total timesteps         | 79500         |
| value_loss              | 0.00018860254 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016463368  |
| ent_coef_loss           | 5.096376      |
| entropy                 | 2.9662702     |
| ep_rewmean              | -1.86         |
| episodes                | 800           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.9          |
| n_updates               | 79801         |
| policy_loss             | 0.5541472     |
| qf1_loss                | 0.0002596259  |
| qf2_loss                | 0.00028950223 |
| time_elapsed            | 381           |
| total timesteps         | 79900         |
| value_loss              | 0.0005814042  |
-------------------------------------------
Eval num_timesteps=80000, episode_reward=-2.01 +/- 0.82
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015881035  |
| ent_coef_loss           | -6.4617376    |
| entropy                 | 2.867928      |
| ep_rewmean              | -1.96         |
| episodes                | 804           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 80201         |
| policy_loss             | 0.5416005     |
| qf1_loss                | 0.0024736233  |
| qf2_loss                | 0.002432301   |
| time_elapsed            | 383           |
| total timesteps         | 80300         |
| value_loss              | 0.00034559384 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015087039  |
| ent_coef_loss           | -4.690451     |
| entropy                 | 3.3905663     |
| ep_rewmean              | -1.92         |
| episodes                | 808           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.9          |
| n_updates               | 80601         |
| policy_loss             | 0.58561707    |
| qf1_loss                | 0.002958298   |
| qf2_loss                | 0.0028296134  |
| time_elapsed            | 385           |
| total timesteps         | 80700         |
| value_loss              | 0.00021774194 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015458781  |
| ent_coef_loss           | 0.94260406    |
| entropy                 | 2.9964786     |
| ep_rewmean              | -1.96         |
| episodes                | 812           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 81001         |
| policy_loss             | 0.5651986     |
| qf1_loss                | 0.0002769344  |
| qf2_loss                | 0.00028651705 |
| time_elapsed            | 387           |
| total timesteps         | 81100         |
| value_loss              | 0.00025635562 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014828291  |
| ent_coef_loss           | -0.6886699    |
| entropy                 | 2.9863312     |
| ep_rewmean              | -1.96         |
| episodes                | 816           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 81401         |
| policy_loss             | 0.52639043    |
| qf1_loss                | 0.002406179   |
| qf2_loss                | 0.0023511685  |
| time_elapsed            | 389           |
| total timesteps         | 81500         |
| value_loss              | 0.00025060482 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014369879  |
| ent_coef_loss           | -7.8274345    |
| entropy                 | 2.823469      |
| ep_rewmean              | -1.94         |
| episodes                | 820           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.9          |
| n_updates               | 81801         |
| policy_loss             | 0.54862       |
| qf1_loss                | 0.0003312404  |
| qf2_loss                | 0.00038028558 |
| time_elapsed            | 391           |
| total timesteps         | 81900         |
| value_loss              | 0.00019920978 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013454141  |
| ent_coef_loss           | -13.157379    |
| entropy                 | 2.9384823     |
| ep_rewmean              | -1.94         |
| episodes                | 824           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.9          |
| n_updates               | 82201         |
| policy_loss             | 0.5509411     |
| qf1_loss                | 0.00046434524 |
| qf2_loss                | 0.0003723706  |
| time_elapsed            | 393           |
| total timesteps         | 82300         |
| value_loss              | 0.00030965862 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012865736  |
| ent_coef_loss           | 1.6269004     |
| entropy                 | 2.4853077     |
| ep_rewmean              | -1.92         |
| episodes                | 828           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.9          |
| n_updates               | 82601         |
| policy_loss             | 0.534208      |
| qf1_loss                | 0.00292054    |
| qf2_loss                | 0.0026756586  |
| time_elapsed            | 395           |
| total timesteps         | 82700         |
| value_loss              | 0.00035331654 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012017939  |
| ent_coef_loss           | -3.3856225    |
| entropy                 | 2.2632468     |
| ep_rewmean              | -1.91         |
| episodes                | 832           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.9          |
| n_updates               | 83001         |
| policy_loss             | 0.55784464    |
| qf1_loss                | 0.0002005509  |
| qf2_loss                | 0.00024265044 |
| time_elapsed            | 397           |
| total timesteps         | 83100         |
| value_loss              | 0.0003177284  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011744784  |
| ent_coef_loss           | 7.1232185     |
| entropy                 | 1.9904016     |
| ep_rewmean              | -1.92         |
| episodes                | 836           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.9          |
| n_updates               | 83401         |
| policy_loss             | 0.5000474     |
| qf1_loss                | 0.00021935461 |
| qf2_loss                | 0.0001990847  |
| time_elapsed            | 399           |
| total timesteps         | 83500         |
| value_loss              | 0.00025446294 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011741839  |
| ent_coef_loss           | 1.4724658     |
| entropy                 | 2.0796876     |
| ep_rewmean              | -1.88         |
| episodes                | 840           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.9          |
| n_updates               | 83801         |
| policy_loss             | 0.5696577     |
| qf1_loss                | 0.00029362578 |
| qf2_loss                | 0.00029712424 |
| time_elapsed            | 400           |
| total timesteps         | 83900         |
| value_loss              | 0.00020114658 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012184415  |
| ent_coef_loss           | 4.568005      |
| entropy                 | 1.880778      |
| ep_rewmean              | -1.95         |
| episodes                | 844           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 84201         |
| policy_loss             | 0.491001      |
| qf1_loss                | 0.00045615842 |
| qf2_loss                | 0.00036832137 |
| time_elapsed            | 402           |
| total timesteps         | 84300         |
| value_loss              | 0.00043049688 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012206251  |
| ent_coef_loss           | 1.5566504     |
| entropy                 | 2.225867      |
| ep_rewmean              | -1.96         |
| episodes                | 848           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 84601         |
| policy_loss             | 0.51760995    |
| qf1_loss                | 0.0034838917  |
| qf2_loss                | 0.0031713462  |
| time_elapsed            | 404           |
| total timesteps         | 84700         |
| value_loss              | 0.00025309317 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011600927  |
| ent_coef_loss           | 2.4864254     |
| entropy                 | 2.1140666     |
| ep_rewmean              | -1.96         |
| episodes                | 852           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 85001         |
| policy_loss             | 0.5220077     |
| qf1_loss                | 0.00024089584 |
| qf2_loss                | 0.00024512835 |
| time_elapsed            | 406           |
| total timesteps         | 85100         |
| value_loss              | 0.0003670502  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001199946   |
| ent_coef_loss           | 1.7912464     |
| entropy                 | 2.3917527     |
| ep_rewmean              | -1.96         |
| episodes                | 856           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 85401         |
| policy_loss             | 0.52874845    |
| qf1_loss                | 0.0022185     |
| qf2_loss                | 0.0020158275  |
| time_elapsed            | 408           |
| total timesteps         | 85500         |
| value_loss              | 0.00024671835 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012376446  |
| ent_coef_loss           | 4.9732075     |
| entropy                 | 2.7188065     |
| ep_rewmean              | -1.97         |
| episodes                | 860           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 85801         |
| policy_loss             | 0.52925575    |
| qf1_loss                | 0.00014090037 |
| qf2_loss                | 0.00015150745 |
| time_elapsed            | 410           |
| total timesteps         | 85900         |
| value_loss              | 0.00019966326 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013184826  |
| ent_coef_loss           | 5.885334      |
| entropy                 | 2.6673484     |
| ep_rewmean              | -1.93         |
| episodes                | 864           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -1.9          |
| n_updates               | 86201         |
| policy_loss             | 0.5070367     |
| qf1_loss                | 0.00075155    |
| qf2_loss                | 0.0006576134  |
| time_elapsed            | 412           |
| total timesteps         | 86300         |
| value_loss              | 0.00036862545 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014432115  |
| ent_coef_loss           | -5.4633265    |
| entropy                 | 2.346542      |
| ep_rewmean              | -1.97         |
| episodes                | 868           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 86601         |
| policy_loss             | 0.5347849     |
| qf1_loss                | 0.00020326467 |
| qf2_loss                | 0.0001789009  |
| time_elapsed            | 414           |
| total timesteps         | 86700         |
| value_loss              | 0.00029136162 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015235742  |
| ent_coef_loss           | 5.4495754     |
| entropy                 | 3.0713434     |
| ep_rewmean              | -1.97         |
| episodes                | 872           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 87001         |
| policy_loss             | 0.5389892     |
| qf1_loss                | 0.00049824937 |
| qf2_loss                | 0.00032994215 |
| time_elapsed            | 416           |
| total timesteps         | 87100         |
| value_loss              | 0.0005932988  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015733843  |
| ent_coef_loss           | 5.3682604     |
| entropy                 | 3.19414       |
| ep_rewmean              | -1.96         |
| episodes                | 876           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 87401         |
| policy_loss             | 0.59126484    |
| qf1_loss                | 0.00018955403 |
| qf2_loss                | 0.00021374233 |
| time_elapsed            | 417           |
| total timesteps         | 87500         |
| value_loss              | 0.0002133657  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016275956  |
| ent_coef_loss           | -1.5929788    |
| entropy                 | 3.0423765     |
| ep_rewmean              | -1.96         |
| episodes                | 880           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 87801         |
| policy_loss             | 0.549299      |
| qf1_loss                | 0.003083942   |
| qf2_loss                | 0.0033805247  |
| time_elapsed            | 419           |
| total timesteps         | 87900         |
| value_loss              | 0.00028827746 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016486158  |
| ent_coef_loss           | 3.2188778     |
| entropy                 | 3.112041      |
| ep_rewmean              | -2            |
| episodes                | 884           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 88201         |
| policy_loss             | 0.5508709     |
| qf1_loss                | 0.00022558874 |
| qf2_loss                | 0.00026912027 |
| time_elapsed            | 421           |
| total timesteps         | 88300         |
| value_loss              | 0.00022715579 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017000209  |
| ent_coef_loss           | -0.18942595   |
| entropy                 | 3.4466991     |
| ep_rewmean              | -2.02         |
| episodes                | 888           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2            |
| n_updates               | 88601         |
| policy_loss             | 0.5939713     |
| qf1_loss                | 0.0058390014  |
| qf2_loss                | 0.0057537295  |
| time_elapsed            | 423           |
| total timesteps         | 88700         |
| value_loss              | 0.00021551234 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019002026  |
| ent_coef_loss           | 8.061826      |
| entropy                 | 3.7347322     |
| ep_rewmean              | -2.07         |
| episodes                | 892           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 89001         |
| policy_loss             | 0.5718032     |
| qf1_loss                | 0.00014099426 |
| qf2_loss                | 0.00019301954 |
| time_elapsed            | 425           |
| total timesteps         | 89100         |
| value_loss              | 0.0003942247  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019686557  |
| ent_coef_loss           | 5.6216917     |
| entropy                 | 3.8517623     |
| ep_rewmean              | -2.11         |
| episodes                | 896           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 89401         |
| policy_loss             | 0.56283855    |
| qf1_loss                | 0.0067356164  |
| qf2_loss                | 0.006948882   |
| time_elapsed            | 427           |
| total timesteps         | 89500         |
| value_loss              | 0.00034230595 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019248518  |
| ent_coef_loss           | -0.7006041    |
| entropy                 | 3.9039407     |
| ep_rewmean              | -2.12         |
| episodes                | 900           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 89801         |
| policy_loss             | 0.60792035    |
| qf1_loss                | 0.007904945   |
| qf2_loss                | 0.007764371   |
| time_elapsed            | 429           |
| total timesteps         | 89900         |
| value_loss              | 0.00031387008 |
-------------------------------------------
Eval num_timesteps=90000, episode_reward=-2.95 +/- 1.33
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019898699  |
| ent_coef_loss           | 5.708732      |
| entropy                 | 4.1451755     |
| ep_rewmean              | -2.07         |
| episodes                | 904           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 90201         |
| policy_loss             | 0.65252805    |
| qf1_loss                | 0.00035714678 |
| qf2_loss                | 0.0003922744  |
| time_elapsed            | 431           |
| total timesteps         | 90300         |
| value_loss              | 0.00027749743 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019754535  |
| ent_coef_loss           | -1.0492461    |
| entropy                 | 4.32531       |
| ep_rewmean              | -2.08         |
| episodes                | 908           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 90601         |
| policy_loss             | 0.6307312     |
| qf1_loss                | 0.00032321253 |
| qf2_loss                | 0.00024295537 |
| time_elapsed            | 433           |
| total timesteps         | 90700         |
| value_loss              | 0.0004942947  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021392861  |
| ent_coef_loss           | -4.818141     |
| entropy                 | 4.208084      |
| ep_rewmean              | -2.08         |
| episodes                | 912           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 91001         |
| policy_loss             | 0.69029665    |
| qf1_loss                | 0.0002899532  |
| qf2_loss                | 0.00022710231 |
| time_elapsed            | 435           |
| total timesteps         | 91100         |
| value_loss              | 0.00029372374 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022680848  |
| ent_coef_loss           | 1.4410913     |
| entropy                 | 4.1783524     |
| ep_rewmean              | -2.06         |
| episodes                | 916           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 91401         |
| policy_loss             | 0.64495313    |
| qf1_loss                | 0.00025649264 |
| qf2_loss                | 0.00027802488 |
| time_elapsed            | 437           |
| total timesteps         | 91500         |
| value_loss              | 0.00040427188 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002251233   |
| ent_coef_loss           | -4.2155786    |
| entropy                 | 4.1839333     |
| ep_rewmean              | -2.08         |
| episodes                | 920           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 91801         |
| policy_loss             | 0.6627834     |
| qf1_loss                | 0.0017257576  |
| qf2_loss                | 0.0017096893  |
| time_elapsed            | 439           |
| total timesteps         | 91900         |
| value_loss              | 0.00047452401 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0020149096 |
| ent_coef_loss           | -3.3503742   |
| entropy                 | 3.7492359    |
| ep_rewmean              | -2.04        |
| episodes                | 924          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2           |
| n_updates               | 92201        |
| policy_loss             | 0.6906973    |
| qf1_loss                | 0.002524358  |
| qf2_loss                | 0.0024373068 |
| time_elapsed            | 440          |
| total timesteps         | 92300        |
| value_loss              | 0.0006921155 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017709759  |
| ent_coef_loss           | -8.294025     |
| entropy                 | 4.1248455     |
| ep_rewmean              | -2.1          |
| episodes                | 928           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 92601         |
| policy_loss             | 0.74363005    |
| qf1_loss                | 0.000372692   |
| qf2_loss                | 0.00039233582 |
| time_elapsed            | 442           |
| total timesteps         | 92700         |
| value_loss              | 0.00043106987 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017691469  |
| ent_coef_loss           | 6.482724      |
| entropy                 | 4.0273128     |
| ep_rewmean              | -2.12         |
| episodes                | 932           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 93001         |
| policy_loss             | 0.7541419     |
| qf1_loss                | 0.00017329834 |
| qf2_loss                | 0.00017050936 |
| time_elapsed            | 444           |
| total timesteps         | 93100         |
| value_loss              | 0.0004893226  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018514879  |
| ent_coef_loss           | -1.780952     |
| entropy                 | 3.9123313     |
| ep_rewmean              | -2.11         |
| episodes                | 936           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 93401         |
| policy_loss             | 0.69279873    |
| qf1_loss                | 0.00020783115 |
| qf2_loss                | 0.00021020044 |
| time_elapsed            | 446           |
| total timesteps         | 93500         |
| value_loss              | 0.0004559523  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018217935  |
| ent_coef_loss           | 1.2603652     |
| entropy                 | 3.902316      |
| ep_rewmean              | -2.12         |
| episodes                | 940           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 93801         |
| policy_loss             | 0.71530855    |
| qf1_loss                | 0.003038038   |
| qf2_loss                | 0.0028732591  |
| time_elapsed            | 448           |
| total timesteps         | 93900         |
| value_loss              | 0.00068194093 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019281156  |
| ent_coef_loss           | 6.8789167     |
| entropy                 | 3.7583976     |
| ep_rewmean              | -2.07         |
| episodes                | 944           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 94201         |
| policy_loss             | 0.67953765    |
| qf1_loss                | 0.00031408633 |
| qf2_loss                | 0.0001794383  |
| time_elapsed            | 450           |
| total timesteps         | 94300         |
| value_loss              | 0.0003474728  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021327685  |
| ent_coef_loss           | 5.336138      |
| entropy                 | 4.3695345     |
| ep_rewmean              | -2.07         |
| episodes                | 948           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 94601         |
| policy_loss             | 0.7019752     |
| qf1_loss                | 0.0046071764  |
| qf2_loss                | 0.0048925504  |
| time_elapsed            | 452           |
| total timesteps         | 94700         |
| value_loss              | 0.00035727606 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002258036   |
| ent_coef_loss           | 1.11568       |
| entropy                 | 3.9892573     |
| ep_rewmean              | -2.13         |
| episodes                | 952           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 95001         |
| policy_loss             | 0.6959256     |
| qf1_loss                | 0.0044528567  |
| qf2_loss                | 0.0044528753  |
| time_elapsed            | 454           |
| total timesteps         | 95100         |
| value_loss              | 0.00029560376 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022237059  |
| ent_coef_loss           | -3.6315172    |
| entropy                 | 3.7204933     |
| ep_rewmean              | -2.16         |
| episodes                | 956           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 95401         |
| policy_loss             | 0.8044031     |
| qf1_loss                | 0.00026512344 |
| qf2_loss                | 0.00034719612 |
| time_elapsed            | 456           |
| total timesteps         | 95500         |
| value_loss              | 0.00039844855 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021703003  |
| ent_coef_loss           | -12.847905    |
| entropy                 | 3.3032765     |
| ep_rewmean              | -2.16         |
| episodes                | 960           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 95801         |
| policy_loss             | 0.74325097    |
| qf1_loss                | 0.0037901942  |
| qf2_loss                | 0.0034520696  |
| time_elapsed            | 458           |
| total timesteps         | 95900         |
| value_loss              | 0.00023358896 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002277026   |
| ent_coef_loss           | 2.3853383     |
| entropy                 | 4.0448127     |
| ep_rewmean              | -2.18         |
| episodes                | 964           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 96201         |
| policy_loss             | 0.75471324    |
| qf1_loss                | 0.0001925666  |
| qf2_loss                | 0.00018146861 |
| time_elapsed            | 460           |
| total timesteps         | 96300         |
| value_loss              | 0.0004042423  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022172886  |
| ent_coef_loss           | -7.13367      |
| entropy                 | 3.768269      |
| ep_rewmean              | -2.15         |
| episodes                | 968           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 96601         |
| policy_loss             | 0.76089585    |
| qf1_loss                | 0.0024006756  |
| qf2_loss                | 0.0025330635  |
| time_elapsed            | 461           |
| total timesteps         | 96700         |
| value_loss              | 0.00054397096 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001958156   |
| ent_coef_loss           | 2.9249144     |
| entropy                 | 3.6751537     |
| ep_rewmean              | -2.17         |
| episodes                | 972           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 97001         |
| policy_loss             | 0.72933614    |
| qf1_loss                | 0.004247897   |
| qf2_loss                | 0.0045742188  |
| time_elapsed            | 463           |
| total timesteps         | 97100         |
| value_loss              | 0.00087002246 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001801262   |
| ent_coef_loss           | -3.5380807    |
| entropy                 | 3.628946      |
| ep_rewmean              | -2.26         |
| episodes                | 976           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.3          |
| n_updates               | 97401         |
| policy_loss             | 0.7573096     |
| qf1_loss                | 0.00022474634 |
| qf2_loss                | 0.00017411399 |
| time_elapsed            | 465           |
| total timesteps         | 97500         |
| value_loss              | 0.00033935145 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017873143  |
| ent_coef_loss           | -2.5893333    |
| entropy                 | 3.4845908     |
| ep_rewmean              | -2.26         |
| episodes                | 980           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.3          |
| n_updates               | 97801         |
| policy_loss             | 0.7909815     |
| qf1_loss                | 0.00027318904 |
| qf2_loss                | 0.00037047957 |
| time_elapsed            | 467           |
| total timesteps         | 97900         |
| value_loss              | 0.0004162123  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017847458  |
| ent_coef_loss           | 10.684879     |
| entropy                 | 3.89889       |
| ep_rewmean              | -2.23         |
| episodes                | 984           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 98201         |
| policy_loss             | 0.72635746    |
| qf1_loss                | 0.0005892349  |
| qf2_loss                | 0.00041609062 |
| time_elapsed            | 469           |
| total timesteps         | 98300         |
| value_loss              | 0.00036150325 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001811373   |
| ent_coef_loss           | -2.7100868    |
| entropy                 | 3.6000094     |
| ep_rewmean              | -2.33         |
| episodes                | 988           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.3          |
| n_updates               | 98601         |
| policy_loss             | 0.77694875    |
| qf1_loss                | 0.00026270415 |
| qf2_loss                | 0.00023100513 |
| time_elapsed            | 471           |
| total timesteps         | 98700         |
| value_loss              | 0.00024954003 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019698031  |
| ent_coef_loss           | 3.3258367     |
| entropy                 | 3.8923655     |
| ep_rewmean              | -2.25         |
| episodes                | 992           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 99001         |
| policy_loss             | 0.73491096    |
| qf1_loss                | 0.0022925127  |
| qf2_loss                | 0.002196905   |
| time_elapsed            | 473           |
| total timesteps         | 99100         |
| value_loss              | 0.00043150352 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0019327254 |
| ent_coef_loss           | -2.9816928   |
| entropy                 | 4.2881517    |
| ep_rewmean              | -2.28        |
| episodes                | 996          |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.3         |
| n_updates               | 99401        |
| policy_loss             | 0.7783062    |
| qf1_loss                | 0.007521684  |
| qf2_loss                | 0.0070738043 |
| time_elapsed            | 475          |
| total timesteps         | 99500        |
| value_loss              | 0.0003110843 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017974937  |
| ent_coef_loss           | -2.832732     |
| entropy                 | 3.727391      |
| ep_rewmean              | -2.26         |
| episodes                | 1000          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.3          |
| n_updates               | 99801         |
| policy_loss             | 0.722075      |
| qf1_loss                | 0.00028842245 |
| qf2_loss                | 0.00023894088 |
| time_elapsed            | 477           |
| total timesteps         | 99900         |
| value_loss              | 0.0005150266  |
-------------------------------------------
Eval num_timesteps=100000, episode_reward=-1.87 +/- 1.01
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017991229  |
| ent_coef_loss           | 1.2369165     |
| entropy                 | 3.9162908     |
| ep_rewmean              | -2.28         |
| episodes                | 1004          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.3          |
| n_updates               | 100201        |
| policy_loss             | 0.78768474    |
| qf1_loss                | 0.00026245046 |
| qf2_loss                | 0.00026883674 |
| time_elapsed            | 479           |
| total timesteps         | 100300        |
| value_loss              | 0.0004813863  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018146607  |
| ent_coef_loss           | 12.402992     |
| entropy                 | 3.774403      |
| ep_rewmean              | -2.25         |
| episodes                | 1008          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 100601        |
| policy_loss             | 0.6722937     |
| qf1_loss                | 0.0006609757  |
| qf2_loss                | 0.0006484101  |
| time_elapsed            | 481           |
| total timesteps         | 100700        |
| value_loss              | 0.00038542924 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0020144447 |
| ent_coef_loss           | 10.811539    |
| entropy                 | 4.493717     |
| ep_rewmean              | -2.22        |
| episodes                | 1012         |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.2         |
| n_updates               | 101001       |
| policy_loss             | 0.78416324   |
| qf1_loss                | 0.0028254695 |
| qf2_loss                | 0.003032002  |
| time_elapsed            | 483          |
| total timesteps         | 101100       |
| value_loss              | 0.0007179428 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.00199479   |
| ent_coef_loss           | -3.38415     |
| entropy                 | 3.9588585    |
| ep_rewmean              | -2.22        |
| episodes                | 1016         |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.2         |
| n_updates               | 101401       |
| policy_loss             | 0.74414957   |
| qf1_loss                | 0.0010532036 |
| qf2_loss                | 0.0010155597 |
| time_elapsed            | 484          |
| total timesteps         | 101500       |
| value_loss              | 0.0003228598 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019509543  |
| ent_coef_loss           | 4.9483957     |
| entropy                 | 3.749         |
| ep_rewmean              | -2.23         |
| episodes                | 1020          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 101801        |
| policy_loss             | 0.7200408     |
| qf1_loss                | 0.00028077906 |
| qf2_loss                | 0.00013701318 |
| time_elapsed            | 486           |
| total timesteps         | 101900        |
| value_loss              | 0.00033395353 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018634129  |
| ent_coef_loss           | 2.4965427     |
| entropy                 | 4.046259      |
| ep_rewmean              | -2.23         |
| episodes                | 1024          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 102201        |
| policy_loss             | 0.72075725    |
| qf1_loss                | 0.00037596724 |
| qf2_loss                | 0.00030319332 |
| time_elapsed            | 488           |
| total timesteps         | 102300        |
| value_loss              | 0.00034228317 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001771535   |
| ent_coef_loss           | -9.314698     |
| entropy                 | 3.7762346     |
| ep_rewmean              | -2.23         |
| episodes                | 1028          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 102601        |
| policy_loss             | 0.7673805     |
| qf1_loss                | 0.0001882268  |
| qf2_loss                | 0.0002682961  |
| time_elapsed            | 490           |
| total timesteps         | 102700        |
| value_loss              | 0.00024246497 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016660563  |
| ent_coef_loss           | -4.459398     |
| entropy                 | 3.282261      |
| ep_rewmean              | -2.25         |
| episodes                | 1032          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.2          |
| n_updates               | 103001        |
| policy_loss             | 0.7924317     |
| qf1_loss                | 0.005640808   |
| qf2_loss                | 0.005811715   |
| time_elapsed            | 492           |
| total timesteps         | 103100        |
| value_loss              | 0.00028495735 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001687236   |
| ent_coef_loss           | 1.3251351     |
| entropy                 | 3.4710214     |
| ep_rewmean              | -2.27         |
| episodes                | 1036          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.3          |
| n_updates               | 103401        |
| policy_loss             | 0.78728724    |
| qf1_loss                | 0.00051062694 |
| qf2_loss                | 0.0004805601  |
| time_elapsed            | 494           |
| total timesteps         | 103500        |
| value_loss              | 0.00028588876 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016452813  |
| ent_coef_loss           | 6.3275976     |
| entropy                 | 3.7807345     |
| ep_rewmean              | -2.33         |
| episodes                | 1040          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.3          |
| n_updates               | 103801        |
| policy_loss             | 0.71179366    |
| qf1_loss                | 0.00015246446 |
| qf2_loss                | 0.00026698544 |
| time_elapsed            | 496           |
| total timesteps         | 103900        |
| value_loss              | 0.0004259205  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016970695  |
| ent_coef_loss           | -3.159183     |
| entropy                 | 3.749896      |
| ep_rewmean              | -2.35         |
| episodes                | 1044          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 104201        |
| policy_loss             | 0.7973648     |
| qf1_loss                | 0.00037336274 |
| qf2_loss                | 0.00042448938 |
| time_elapsed            | 498           |
| total timesteps         | 104300        |
| value_loss              | 0.0012847562  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016820058 |
| ent_coef_loss           | -1.2473631   |
| entropy                 | 3.5631776    |
| ep_rewmean              | -2.4         |
| episodes                | 1048         |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.4         |
| n_updates               | 104601       |
| policy_loss             | 0.7484953    |
| qf1_loss                | 0.0006439137 |
| qf2_loss                | 0.000610559  |
| time_elapsed            | 500          |
| total timesteps         | 104700       |
| value_loss              | 0.0004151828 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017003362  |
| ent_coef_loss           | 14.931739     |
| entropy                 | 3.3302412     |
| ep_rewmean              | -2.37         |
| episodes                | 1052          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 105001        |
| policy_loss             | 0.7499593     |
| qf1_loss                | 0.008811281   |
| qf2_loss                | 0.008837143   |
| time_elapsed            | 502           |
| total timesteps         | 105100        |
| value_loss              | 0.00033308374 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018544284  |
| ent_coef_loss           | 0.5358803     |
| entropy                 | 3.694892      |
| ep_rewmean              | -2.37         |
| episodes                | 1056          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 105401        |
| policy_loss             | 0.716372      |
| qf1_loss                | 0.00020358247 |
| qf2_loss                | 0.0002758084  |
| time_elapsed            | 504           |
| total timesteps         | 105500        |
| value_loss              | 0.00025370438 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017497417  |
| ent_coef_loss           | -0.5053163    |
| entropy                 | 3.7578075     |
| ep_rewmean              | -2.43         |
| episodes                | 1060          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.4          |
| n_updates               | 105801        |
| policy_loss             | 0.75887024    |
| qf1_loss                | 0.0016041909  |
| qf2_loss                | 0.0017673487  |
| time_elapsed            | 505           |
| total timesteps         | 105900        |
| value_loss              | 0.00042017765 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017026915  |
| ent_coef_loss           | -0.064067364  |
| entropy                 | 4.0518265     |
| ep_rewmean              | -2.52         |
| episodes                | 1064          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 106201        |
| policy_loss             | 0.7710363     |
| qf1_loss                | 0.00037856516 |
| qf2_loss                | 0.0002887076  |
| time_elapsed            | 507           |
| total timesteps         | 106300        |
| value_loss              | 0.00026537996 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018992234  |
| ent_coef_loss           | 9.6205635     |
| entropy                 | 4.131338      |
| ep_rewmean              | -2.5          |
| episodes                | 1068          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 106601        |
| policy_loss             | 0.71103394    |
| qf1_loss                | 0.0052305646  |
| qf2_loss                | 0.005316844   |
| time_elapsed            | 509           |
| total timesteps         | 106700        |
| value_loss              | 0.00043418977 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020373808  |
| ent_coef_loss           | 3.7649736     |
| entropy                 | 4.235671      |
| ep_rewmean              | -2.48         |
| episodes                | 1072          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 107001        |
| policy_loss             | 0.7003236     |
| qf1_loss                | 0.00026004016 |
| qf2_loss                | 0.00021320526 |
| time_elapsed            | 511           |
| total timesteps         | 107100        |
| value_loss              | 0.00031951233 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002053887  |
| ent_coef_loss           | 0.49158978   |
| entropy                 | 3.4685502    |
| ep_rewmean              | -2.46        |
| episodes                | 1076         |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.5         |
| n_updates               | 107401       |
| policy_loss             | 0.66304445   |
| qf1_loss                | 0.0008845863 |
| qf2_loss                | 0.0008803511 |
| time_elapsed            | 513          |
| total timesteps         | 107500       |
| value_loss              | 0.0004580826 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020527386  |
| ent_coef_loss           | -1.1339729    |
| entropy                 | 3.8550897     |
| ep_rewmean              | -2.47         |
| episodes                | 1080          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 107801        |
| policy_loss             | 0.7657634     |
| qf1_loss                | 0.00054386386 |
| qf2_loss                | 0.00047340675 |
| time_elapsed            | 515           |
| total timesteps         | 107900        |
| value_loss              | 0.00035625952 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020362688  |
| ent_coef_loss           | -8.24191      |
| entropy                 | 3.6489677     |
| ep_rewmean              | -2.54         |
| episodes                | 1084          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 108201        |
| policy_loss             | 0.7828815     |
| qf1_loss                | 0.00033471768 |
| qf2_loss                | 0.00021953264 |
| time_elapsed            | 517           |
| total timesteps         | 108300        |
| value_loss              | 0.00040819842 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020526994  |
| ent_coef_loss           | -4.2034745    |
| entropy                 | 3.6020727     |
| ep_rewmean              | -2.5          |
| episodes                | 1088          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 108601        |
| policy_loss             | 0.7597992     |
| qf1_loss                | 0.00022229303 |
| qf2_loss                | 0.00025350996 |
| time_elapsed            | 519           |
| total timesteps         | 108700        |
| value_loss              | 0.00034046004 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019045959  |
| ent_coef_loss           | -9.031362     |
| entropy                 | 3.2901776     |
| ep_rewmean              | -2.52         |
| episodes                | 1092          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 109001        |
| policy_loss             | 0.80047727    |
| qf1_loss                | 0.00026540022 |
| qf2_loss                | 0.00024946028 |
| time_elapsed            | 521           |
| total timesteps         | 109100        |
| value_loss              | 0.0001963478  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017860049  |
| ent_coef_loss           | -0.55989134   |
| entropy                 | 3.6630392     |
| ep_rewmean              | -2.48         |
| episodes                | 1096          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 109401        |
| policy_loss             | 0.75817454    |
| qf1_loss                | 0.0049023423  |
| qf2_loss                | 0.005037855   |
| time_elapsed            | 522           |
| total timesteps         | 109500        |
| value_loss              | 0.00035883536 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017046892  |
| ent_coef_loss           | -3.5926256    |
| entropy                 | 3.1823034     |
| ep_rewmean              | -2.53         |
| episodes                | 1100          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 109801        |
| policy_loss             | 0.7720442     |
| qf1_loss                | 0.004119409   |
| qf2_loss                | 0.003749042   |
| time_elapsed            | 524           |
| total timesteps         | 109900        |
| value_loss              | 0.00027923725 |
-------------------------------------------
Eval num_timesteps=110000, episode_reward=-2.24 +/- 0.73
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016994025  |
| ent_coef_loss           | -7.1868234    |
| entropy                 | 3.72834       |
| ep_rewmean              | -2.5          |
| episodes                | 1104          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 110201        |
| policy_loss             | 0.7608659     |
| qf1_loss                | 0.0028412563  |
| qf2_loss                | 0.0028946402  |
| time_elapsed            | 527           |
| total timesteps         | 110300        |
| value_loss              | 0.00040041943 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016588995  |
| ent_coef_loss           | -2.725516     |
| entropy                 | 2.6916432     |
| ep_rewmean              | -2.51         |
| episodes                | 1108          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 110601        |
| policy_loss             | 0.78677404    |
| qf1_loss                | 0.00023744321 |
| qf2_loss                | 0.0004704676  |
| time_elapsed            | 528           |
| total timesteps         | 110700        |
| value_loss              | 0.00035716422 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015337674  |
| ent_coef_loss           | -6.796179     |
| entropy                 | 3.3412952     |
| ep_rewmean              | -2.55         |
| episodes                | 1112          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 111001        |
| policy_loss             | 0.7779912     |
| qf1_loss                | 0.00501644    |
| qf2_loss                | 0.0048912494  |
| time_elapsed            | 530           |
| total timesteps         | 111100        |
| value_loss              | 0.00045226607 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015621602  |
| ent_coef_loss           | 6.7245455     |
| entropy                 | 3.020431      |
| ep_rewmean              | -2.56         |
| episodes                | 1116          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.6          |
| n_updates               | 111401        |
| policy_loss             | 0.7121657     |
| qf1_loss                | 0.00047758425 |
| qf2_loss                | 0.00038867138 |
| time_elapsed            | 532           |
| total timesteps         | 111500        |
| value_loss              | 0.00036974478 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016121459  |
| ent_coef_loss           | -4.316177     |
| entropy                 | 3.4694037     |
| ep_rewmean              | -2.59         |
| episodes                | 1120          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.6          |
| n_updates               | 111801        |
| policy_loss             | 0.76466       |
| qf1_loss                | 0.00023357484 |
| qf2_loss                | 0.0002671227  |
| time_elapsed            | 534           |
| total timesteps         | 111900        |
| value_loss              | 0.00016728177 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015835875  |
| ent_coef_loss           | 0.66188735    |
| entropy                 | 3.397491      |
| ep_rewmean              | -2.62         |
| episodes                | 1124          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.6          |
| n_updates               | 112201        |
| policy_loss             | 0.7464471     |
| qf1_loss                | 0.013676086   |
| qf2_loss                | 0.013537036   |
| time_elapsed            | 536           |
| total timesteps         | 112300        |
| value_loss              | 0.00020886431 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015500648 |
| ent_coef_loss           | -0.4058339   |
| entropy                 | 2.5515232    |
| ep_rewmean              | -2.55        |
| episodes                | 1128         |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.6         |
| n_updates               | 112601       |
| policy_loss             | 0.73969865   |
| qf1_loss                | 0.0038826917 |
| qf2_loss                | 0.0040257797 |
| time_elapsed            | 538          |
| total timesteps         | 112700       |
| value_loss              | 0.0003101399 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001605553   |
| ent_coef_loss           | 2.2260196     |
| entropy                 | 2.9219527     |
| ep_rewmean              | -2.51         |
| episodes                | 1132          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 113001        |
| policy_loss             | 0.7770529     |
| qf1_loss                | 0.00027083076 |
| qf2_loss                | 0.00020808342 |
| time_elapsed            | 540           |
| total timesteps         | 113100        |
| value_loss              | 0.0004224356  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017369308  |
| ent_coef_loss           | 2.765616      |
| entropy                 | 3.5572739     |
| ep_rewmean              | -2.57         |
| episodes                | 1136          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.6          |
| n_updates               | 113401        |
| policy_loss             | 0.8040316     |
| qf1_loss                | 0.0002675677  |
| qf2_loss                | 0.00024272085 |
| time_elapsed            | 542           |
| total timesteps         | 113500        |
| value_loss              | 0.00023549673 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018380354  |
| ent_coef_loss           | 5.2597685     |
| entropy                 | 3.6212487     |
| ep_rewmean              | -2.57         |
| episodes                | 1140          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.6          |
| n_updates               | 113801        |
| policy_loss             | 0.7408935     |
| qf1_loss                | 0.00025265702 |
| qf2_loss                | 0.00028396433 |
| time_elapsed            | 544           |
| total timesteps         | 113900        |
| value_loss              | 0.0005847254  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017324112  |
| ent_coef_loss           | -10.642006    |
| entropy                 | 4.1661787     |
| ep_rewmean              | -2.55         |
| episodes                | 1144          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 114201        |
| policy_loss             | 0.82129323    |
| qf1_loss                | 0.00044914358 |
| qf2_loss                | 0.00036984996 |
| time_elapsed            | 546           |
| total timesteps         | 114300        |
| value_loss              | 0.0004505932  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016399364  |
| ent_coef_loss           | -6.9571524    |
| entropy                 | 3.5680337     |
| ep_rewmean              | -2.5          |
| episodes                | 1148          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 114601        |
| policy_loss             | 0.76051736    |
| qf1_loss                | 0.00048510003 |
| qf2_loss                | 0.00037552923 |
| time_elapsed            | 548           |
| total timesteps         | 114700        |
| value_loss              | 0.0003888188  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015459503  |
| ent_coef_loss           | 6.714597      |
| entropy                 | 3.41287       |
| ep_rewmean              | -2.49         |
| episodes                | 1152          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 115001        |
| policy_loss             | 0.8297479     |
| qf1_loss                | 0.008228991   |
| qf2_loss                | 0.008251353   |
| time_elapsed            | 549           |
| total timesteps         | 115100        |
| value_loss              | 0.00036194408 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015865368  |
| ent_coef_loss           | -3.6116214    |
| entropy                 | 3.6286314     |
| ep_rewmean              | -2.54         |
| episodes                | 1156          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 115401        |
| policy_loss             | 0.7653132     |
| qf1_loss                | 0.00024224802 |
| qf2_loss                | 0.00039303524 |
| time_elapsed            | 551           |
| total timesteps         | 115500        |
| value_loss              | 0.00025688414 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015437705  |
| ent_coef_loss           | -6.647228     |
| entropy                 | 3.4986327     |
| ep_rewmean              | -2.59         |
| episodes                | 1160          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.6          |
| n_updates               | 115801        |
| policy_loss             | 0.82337236    |
| qf1_loss                | 0.00018811488 |
| qf2_loss                | 0.00026937755 |
| time_elapsed            | 553           |
| total timesteps         | 115900        |
| value_loss              | 0.00019030408 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016030637  |
| ent_coef_loss           | 8.501449      |
| entropy                 | 2.7856452     |
| ep_rewmean              | -2.59         |
| episodes                | 1164          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.6          |
| n_updates               | 116201        |
| policy_loss             | 0.7830539     |
| qf1_loss                | 0.00046504405 |
| qf2_loss                | 0.000667183   |
| time_elapsed            | 555           |
| total timesteps         | 116300        |
| value_loss              | 0.0002665827  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016999203 |
| ent_coef_loss           | 6.6315722    |
| entropy                 | 2.8533602    |
| ep_rewmean              | -2.7         |
| episodes                | 1168         |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.7         |
| n_updates               | 116601       |
| policy_loss             | 0.7982495    |
| qf1_loss                | 0.004540012  |
| qf2_loss                | 0.0046548857 |
| time_elapsed            | 557          |
| total timesteps         | 116700       |
| value_loss              | 0.0006696539 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017837903  |
| ent_coef_loss           | 3.9471614     |
| entropy                 | 2.765825      |
| ep_rewmean              | -2.75         |
| episodes                | 1172          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.7          |
| n_updates               | 117001        |
| policy_loss             | 0.76607       |
| qf1_loss                | 0.0009907599  |
| qf2_loss                | 0.0023724178  |
| time_elapsed            | 559           |
| total timesteps         | 117100        |
| value_loss              | 0.00054812303 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017981263  |
| ent_coef_loss           | -11.048782    |
| entropy                 | 2.8245363     |
| ep_rewmean              | -2.79         |
| episodes                | 1176          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.8          |
| n_updates               | 117401        |
| policy_loss             | 0.7685485     |
| qf1_loss                | 0.007976748   |
| qf2_loss                | 0.008086666   |
| time_elapsed            | 561           |
| total timesteps         | 117500        |
| value_loss              | 0.00035322382 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001666417   |
| ent_coef_loss           | 2.8198166     |
| entropy                 | 2.248764      |
| ep_rewmean              | -2.78         |
| episodes                | 1180          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.8          |
| n_updates               | 117801        |
| policy_loss             | 0.7562575     |
| qf1_loss                | 0.00020394986 |
| qf2_loss                | 0.00024427735 |
| time_elapsed            | 563           |
| total timesteps         | 117900        |
| value_loss              | 0.00041898366 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017018409  |
| ent_coef_loss           | -3.5536685    |
| entropy                 | 2.7603645     |
| ep_rewmean              | -2.69         |
| episodes                | 1184          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.7          |
| n_updates               | 118201        |
| policy_loss             | 0.78290135    |
| qf1_loss                | 0.0030064806  |
| qf2_loss                | 0.0032603256  |
| time_elapsed            | 565           |
| total timesteps         | 118300        |
| value_loss              | 0.00023988512 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015691825 |
| ent_coef_loss           | 0.026492     |
| entropy                 | 2.4451923    |
| ep_rewmean              | -2.64        |
| episodes                | 1188         |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.6         |
| n_updates               | 118601       |
| policy_loss             | 0.6870291    |
| qf1_loss                | 0.0036118163 |
| qf2_loss                | 0.0034724653 |
| time_elapsed            | 567          |
| total timesteps         | 118700       |
| value_loss              | 0.0002724773 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001504076  |
| ent_coef_loss           | -6.5115495   |
| entropy                 | 2.211259     |
| ep_rewmean              | -2.69        |
| episodes                | 1192         |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.7         |
| n_updates               | 119001       |
| policy_loss             | 0.71228725   |
| qf1_loss                | 0.0035846613 |
| qf2_loss                | 0.0028024667 |
| time_elapsed            | 569          |
| total timesteps         | 119100       |
| value_loss              | 0.000439741  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014322527  |
| ent_coef_loss           | 9.00429       |
| entropy                 | 2.2920656     |
| ep_rewmean              | -2.7          |
| episodes                | 1196          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.7          |
| n_updates               | 119401        |
| policy_loss             | 0.7021142     |
| qf1_loss                | 0.00037566767 |
| qf2_loss                | 0.000447775   |
| time_elapsed            | 570           |
| total timesteps         | 119500        |
| value_loss              | 0.0006483673  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015333638  |
| ent_coef_loss           | -2.4874666    |
| entropy                 | 2.4464831     |
| ep_rewmean              | -2.73         |
| episodes                | 1200          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.7          |
| n_updates               | 119801        |
| policy_loss             | 0.77221406    |
| qf1_loss                | 0.00037694414 |
| qf2_loss                | 0.00043330455 |
| time_elapsed            | 572           |
| total timesteps         | 119900        |
| value_loss              | 0.00025761966 |
-------------------------------------------
Eval num_timesteps=120000, episode_reward=-3.37 +/- 2.35
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016561893 |
| ent_coef_loss           | -1.895848    |
| entropy                 | 2.635375     |
| ep_rewmean              | -2.75        |
| episodes                | 1204         |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.7         |
| n_updates               | 120201       |
| policy_loss             | 0.6945441    |
| qf1_loss                | 0.000596299  |
| qf2_loss                | 0.0006501729 |
| time_elapsed            | 575          |
| total timesteps         | 120300       |
| value_loss              | 0.000728655  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001697734   |
| ent_coef_loss           | 0.68959963    |
| entropy                 | 2.3601387     |
| ep_rewmean              | -2.82         |
| episodes                | 1208          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.8          |
| n_updates               | 120601        |
| policy_loss             | 0.7521175     |
| qf1_loss                | 0.0003742724  |
| qf2_loss                | 0.0003938562  |
| time_elapsed            | 576           |
| total timesteps         | 120700        |
| value_loss              | 0.00028143806 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016761235  |
| ent_coef_loss           | -9.075788     |
| entropy                 | 2.6377625     |
| ep_rewmean              | -2.78         |
| episodes                | 1212          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.8          |
| n_updates               | 121001        |
| policy_loss             | 0.7676206     |
| qf1_loss                | 0.00017060846 |
| qf2_loss                | 0.00019426917 |
| time_elapsed            | 578           |
| total timesteps         | 121100        |
| value_loss              | 0.00018591913 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017152197  |
| ent_coef_loss           | -3.9820151    |
| entropy                 | 2.8047242     |
| ep_rewmean              | -2.76         |
| episodes                | 1216          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.8          |
| n_updates               | 121401        |
| policy_loss             | 0.77921736    |
| qf1_loss                | 0.0002559888  |
| qf2_loss                | 0.00024075825 |
| time_elapsed            | 580           |
| total timesteps         | 121500        |
| value_loss              | 0.0003326259  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016996382 |
| ent_coef_loss           | -5.2023296   |
| entropy                 | 2.9099884    |
| ep_rewmean              | -2.71        |
| episodes                | 1220         |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.7         |
| n_updates               | 121801       |
| policy_loss             | 0.70527864   |
| qf1_loss                | 0.0020742342 |
| qf2_loss                | 0.0022262512 |
| time_elapsed            | 582          |
| total timesteps         | 121900       |
| value_loss              | 0.0010666227 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016474009  |
| ent_coef_loss           | -1.8933674    |
| entropy                 | 2.6956918     |
| ep_rewmean              | -2.66         |
| episodes                | 1224          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.7          |
| n_updates               | 122201        |
| policy_loss             | 0.75003195    |
| qf1_loss                | 0.00022058011 |
| qf2_loss                | 0.0002703536  |
| time_elapsed            | 584           |
| total timesteps         | 122300        |
| value_loss              | 0.00023511765 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015439406 |
| ent_coef_loss           | -8.329603    |
| entropy                 | 2.17206      |
| ep_rewmean              | -2.68        |
| episodes                | 1228         |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.7         |
| n_updates               | 122601       |
| policy_loss             | 0.69277596   |
| qf1_loss                | 0.0028064356 |
| qf2_loss                | 0.002869589  |
| time_elapsed            | 586          |
| total timesteps         | 122700       |
| value_loss              | 0.0006090044 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015058097  |
| ent_coef_loss           | 0.17678201    |
| entropy                 | 2.091429      |
| ep_rewmean              | -2.7          |
| episodes                | 1232          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.7          |
| n_updates               | 123001        |
| policy_loss             | 0.7283999     |
| qf1_loss                | 0.0002710583  |
| qf2_loss                | 0.00037705124 |
| time_elapsed            | 588           |
| total timesteps         | 123100        |
| value_loss              | 0.00026698495 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015008169  |
| ent_coef_loss           | -6.6445584    |
| entropy                 | 1.8253024     |
| ep_rewmean              | -2.64         |
| episodes                | 1236          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.6          |
| n_updates               | 123401        |
| policy_loss             | 0.67315775    |
| qf1_loss                | 0.00031351787 |
| qf2_loss                | 0.00034732735 |
| time_elapsed            | 590           |
| total timesteps         | 123500        |
| value_loss              | 0.00019709385 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014953258 |
| ent_coef_loss           | -0.36618328  |
| entropy                 | 1.5881593    |
| ep_rewmean              | -2.58        |
| episodes                | 1240         |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.6         |
| n_updates               | 123801       |
| policy_loss             | 0.6768693    |
| qf1_loss                | 0.0047550322 |
| qf2_loss                | 0.004825435  |
| time_elapsed            | 592          |
| total timesteps         | 123900       |
| value_loss              | 0.0001963446 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014400602  |
| ent_coef_loss           | 2.7722044     |
| entropy                 | 1.6978137     |
| ep_rewmean              | -2.54         |
| episodes                | 1244          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 124201        |
| policy_loss             | 0.6757899     |
| qf1_loss                | 0.0002603362  |
| qf2_loss                | 0.00023087213 |
| time_elapsed            | 594           |
| total timesteps         | 124300        |
| value_loss              | 0.00022219401 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015918518  |
| ent_coef_loss           | 6.7542243     |
| entropy                 | 2.2299383     |
| ep_rewmean              | -2.52         |
| episodes                | 1248          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 124601        |
| policy_loss             | 0.5833232     |
| qf1_loss                | 0.0010223018  |
| qf2_loss                | 0.0009917563  |
| time_elapsed            | 596           |
| total timesteps         | 124700        |
| value_loss              | 0.00023869697 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016989763  |
| ent_coef_loss           | -1.1074038    |
| entropy                 | 2.402189      |
| ep_rewmean              | -2.53         |
| episodes                | 1252          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 125001        |
| policy_loss             | 0.6037241     |
| qf1_loss                | 0.00042440416 |
| qf2_loss                | 0.00051449565 |
| time_elapsed            | 598           |
| total timesteps         | 125100        |
| value_loss              | 0.00049429986 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016776811  |
| ent_coef_loss           | -0.07498062   |
| entropy                 | 2.3647506     |
| ep_rewmean              | -2.47         |
| episodes                | 1256          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.5          |
| n_updates               | 125401        |
| policy_loss             | 0.62363887    |
| qf1_loss                | 0.0003573358  |
| qf2_loss                | 0.00040521257 |
| time_elapsed            | 600           |
| total timesteps         | 125500        |
| value_loss              | 0.00070380257 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017145172 |
| ent_coef_loss           | 0.3564279    |
| entropy                 | 2.6640568    |
| ep_rewmean              | -2.33        |
| episodes                | 1260         |
| eplenmean               | 100          |
| fps                     | 209          |
| mean 100 episode reward | -2.3         |
| n_updates               | 125801       |
| policy_loss             | 0.62400186   |
| qf1_loss                | 0.0074516516 |
| qf2_loss                | 0.007325428  |
| time_elapsed            | 602          |
| total timesteps         | 125900       |
| value_loss              | 0.0006337306 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017559577  |
| ent_coef_loss           | 7.0221257     |
| entropy                 | 2.8271651     |
| ep_rewmean              | -2.25         |
| episodes                | 1264          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.3          |
| n_updates               | 126201        |
| policy_loss             | 0.67555285    |
| qf1_loss                | 0.0002809483  |
| qf2_loss                | 0.00024995225 |
| time_elapsed            | 604           |
| total timesteps         | 126300        |
| value_loss              | 0.00035101248 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018106182  |
| ent_coef_loss           | -0.6859909    |
| entropy                 | 2.6880858     |
| ep_rewmean              | -2.14         |
| episodes                | 1268          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 126601        |
| policy_loss             | 0.6759684     |
| qf1_loss                | 0.00029614707 |
| qf2_loss                | 0.00032377435 |
| time_elapsed            | 606           |
| total timesteps         | 126700        |
| value_loss              | 0.00045042197 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017746117  |
| ent_coef_loss           | 1.1394498     |
| entropy                 | 2.4945045     |
| ep_rewmean              | -2.1          |
| episodes                | 1272          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 127001        |
| policy_loss             | 0.6274387     |
| qf1_loss                | 0.00025766692 |
| qf2_loss                | 0.00026103953 |
| time_elapsed            | 608           |
| total timesteps         | 127100        |
| value_loss              | 0.00027638517 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001705782   |
| ent_coef_loss           | 1.495172      |
| entropy                 | 2.5984674     |
| ep_rewmean              | -2.05         |
| episodes                | 1276          |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -2.1          |
| n_updates               | 127401        |
| policy_loss             | 0.6046314     |
| qf1_loss                | 0.0043311953  |
| qf2_loss                | 0.004232829   |
| time_elapsed            | 610           |
| total timesteps         | 127500        |
| value_loss              | 0.00025436666 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018289831  |
| ent_coef_loss           | 12.1706705    |
| entropy                 | 3.1858206     |
| ep_rewmean              | -2.09         |
| episodes                | 1280          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 127801        |
| policy_loss             | 0.66663456    |
| qf1_loss                | 0.01074658    |
| qf2_loss                | 0.010634477   |
| time_elapsed            | 611           |
| total timesteps         | 127900        |
| value_loss              | 0.00024688346 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017995896  |
| ent_coef_loss           | 4.5494        |
| entropy                 | 3.418003      |
| ep_rewmean              | -2.13         |
| episodes                | 1284          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 128201        |
| policy_loss             | 0.6652323     |
| qf1_loss                | 0.0022551054  |
| qf2_loss                | 0.0022039467  |
| time_elapsed            | 613           |
| total timesteps         | 128300        |
| value_loss              | 0.00050704693 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017254194  |
| ent_coef_loss           | -4.6036434    |
| entropy                 | 2.7049298     |
| ep_rewmean              | -2.14         |
| episodes                | 1288          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 128601        |
| policy_loss             | 0.6334104     |
| qf1_loss                | 0.0035662707  |
| qf2_loss                | 0.0036628535  |
| time_elapsed            | 615           |
| total timesteps         | 128700        |
| value_loss              | 0.00043195253 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001733064   |
| ent_coef_loss           | 5.254079      |
| entropy                 | 3.5087512     |
| ep_rewmean              | -2.1          |
| episodes                | 1292          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 129001        |
| policy_loss             | 0.63819575    |
| qf1_loss                | 0.00016635563 |
| qf2_loss                | 0.00019182883 |
| time_elapsed            | 617           |
| total timesteps         | 129100        |
| value_loss              | 0.00033566574 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017852795 |
| ent_coef_loss           | -5.133207    |
| entropy                 | 2.8745775    |
| ep_rewmean              | -2.06        |
| episodes                | 1296         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 129401       |
| policy_loss             | 0.64382064   |
| qf1_loss                | 0.001706831  |
| qf2_loss                | 0.001582629  |
| time_elapsed            | 619          |
| total timesteps         | 129500       |
| value_loss              | 0.0002027657 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017506012  |
| ent_coef_loss           | -6.5476513    |
| entropy                 | 3.1244063     |
| ep_rewmean              | -1.98         |
| episodes                | 1300          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 129801        |
| policy_loss             | 0.6356747     |
| qf1_loss                | 0.006302614   |
| qf2_loss                | 0.0068209744  |
| time_elapsed            | 621           |
| total timesteps         | 129900        |
| value_loss              | 0.00022018231 |
-------------------------------------------
Eval num_timesteps=130000, episode_reward=-0.85 +/- 0.27
Episode length: 100.00 +/- 0.00
New best mean reward!
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016822127 |
| ent_coef_loss           | 2.4716272    |
| entropy                 | 2.5171537    |
| ep_rewmean              | -1.97        |
| episodes                | 1304         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2           |
| n_updates               | 130201       |
| policy_loss             | 0.5855738    |
| qf1_loss                | 0.004106189  |
| qf2_loss                | 0.003844224  |
| time_elapsed            | 623          |
| total timesteps         | 130300       |
| value_loss              | 0.0002709713 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016975268  |
| ent_coef_loss           | -0.4599135    |
| entropy                 | 2.188841      |
| ep_rewmean              | -1.92         |
| episodes                | 1308          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 130601        |
| policy_loss             | 0.615746      |
| qf1_loss                | 0.00029433955 |
| qf2_loss                | 0.00039608168 |
| time_elapsed            | 625           |
| total timesteps         | 130700        |
| value_loss              | 0.00021037506 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001590653   |
| ent_coef_loss           | -2.2309756    |
| entropy                 | 2.8792915     |
| ep_rewmean              | -1.92         |
| episodes                | 1312          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 131001        |
| policy_loss             | 0.63481       |
| qf1_loss                | 0.00016392223 |
| qf2_loss                | 0.00020985072 |
| time_elapsed            | 627           |
| total timesteps         | 131100        |
| value_loss              | 0.00033030153 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015355332  |
| ent_coef_loss           | 3.7956035     |
| entropy                 | 3.0707145     |
| ep_rewmean              | -1.93         |
| episodes                | 1316          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 131401        |
| policy_loss             | 0.6204145     |
| qf1_loss                | 0.009821611   |
| qf2_loss                | 0.009723998   |
| time_elapsed            | 629           |
| total timesteps         | 131500        |
| value_loss              | 0.00021171474 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015880028  |
| ent_coef_loss           | 2.072984      |
| entropy                 | 2.0727696     |
| ep_rewmean              | -1.92         |
| episodes                | 1320          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 131801        |
| policy_loss             | 0.58778226    |
| qf1_loss                | 0.0021743227  |
| qf2_loss                | 0.0021971082  |
| time_elapsed            | 631           |
| total timesteps         | 131900        |
| value_loss              | 0.00020320399 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016374805  |
| ent_coef_loss           | 5.2184386     |
| entropy                 | 2.5472155     |
| ep_rewmean              | -1.94         |
| episodes                | 1324          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 132201        |
| policy_loss             | 0.5862971     |
| qf1_loss                | 0.00039978832 |
| qf2_loss                | 0.00045570382 |
| time_elapsed            | 633           |
| total timesteps         | 132300        |
| value_loss              | 0.00041929947 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016218873  |
| ent_coef_loss           | 0.48781163    |
| entropy                 | 1.6159492     |
| ep_rewmean              | -1.93         |
| episodes                | 1328          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 132601        |
| policy_loss             | 0.6102948     |
| qf1_loss                | 0.00015673997 |
| qf2_loss                | 0.00016082311 |
| time_elapsed            | 635           |
| total timesteps         | 132700        |
| value_loss              | 0.00020152988 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015463292  |
| ent_coef_loss           | 0.091584325   |
| entropy                 | 2.370181      |
| ep_rewmean              | -1.95         |
| episodes                | 1332          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 133001        |
| policy_loss             | 0.6442801     |
| qf1_loss                | 0.0075607635  |
| qf2_loss                | 0.0075255907  |
| time_elapsed            | 637           |
| total timesteps         | 133100        |
| value_loss              | 0.00025389428 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015141286  |
| ent_coef_loss           | 10.953127     |
| entropy                 | 2.3990955     |
| ep_rewmean              | -1.91         |
| episodes                | 1336          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 133401        |
| policy_loss             | 0.6010829     |
| qf1_loss                | 0.0034731799  |
| qf2_loss                | 0.0039032681  |
| time_elapsed            | 638           |
| total timesteps         | 133500        |
| value_loss              | 0.00042130434 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015286718  |
| ent_coef_loss           | -1.0246953    |
| entropy                 | 2.2525647     |
| ep_rewmean              | -1.88         |
| episodes                | 1340          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 133801        |
| policy_loss             | 0.58570826    |
| qf1_loss                | 0.00039239714 |
| qf2_loss                | 0.000398003   |
| time_elapsed            | 640           |
| total timesteps         | 133900        |
| value_loss              | 0.0004280067  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014794975  |
| ent_coef_loss           | 2.0126512     |
| entropy                 | 2.6468422     |
| ep_rewmean              | -1.88         |
| episodes                | 1344          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 134201        |
| policy_loss             | 0.66631776    |
| qf1_loss                | 0.00021785198 |
| qf2_loss                | 0.00019356454 |
| time_elapsed            | 642           |
| total timesteps         | 134300        |
| value_loss              | 0.00015954388 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014233862  |
| ent_coef_loss           | 1.9544365     |
| entropy                 | 1.6782584     |
| ep_rewmean              | -1.91         |
| episodes                | 1348          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 134601        |
| policy_loss             | 0.6282191     |
| qf1_loss                | 0.0057866992  |
| qf2_loss                | 0.0059613553  |
| time_elapsed            | 644           |
| total timesteps         | 134700        |
| value_loss              | 0.00024237033 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014092935  |
| ent_coef_loss           | 6.5893397     |
| entropy                 | 2.1922984     |
| ep_rewmean              | -1.85         |
| episodes                | 1352          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 135001        |
| policy_loss             | 0.6005576     |
| qf1_loss                | 0.0032812925  |
| qf2_loss                | 0.003152028   |
| time_elapsed            | 646           |
| total timesteps         | 135100        |
| value_loss              | 0.00015009526 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014323046  |
| ent_coef_loss           | -2.4045727    |
| entropy                 | 2.390602      |
| ep_rewmean              | -1.86         |
| episodes                | 1356          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 135401        |
| policy_loss             | 0.6093266     |
| qf1_loss                | 0.0003063367  |
| qf2_loss                | 0.00029231465 |
| time_elapsed            | 648           |
| total timesteps         | 135500        |
| value_loss              | 0.00038762676 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015673377  |
| ent_coef_loss           | 5.995575      |
| entropy                 | 1.6412773     |
| ep_rewmean              | -1.88         |
| episodes                | 1360          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 135801        |
| policy_loss             | 0.60422397    |
| qf1_loss                | 0.00038857968 |
| qf2_loss                | 0.00023891419 |
| time_elapsed            | 650           |
| total timesteps         | 135900        |
| value_loss              | 0.00069340697 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016950452  |
| ent_coef_loss           | 5.4187303     |
| entropy                 | 2.1809745     |
| ep_rewmean              | -1.96         |
| episodes                | 1364          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 136201        |
| policy_loss             | 0.58113885    |
| qf1_loss                | 0.0004170374  |
| qf2_loss                | 0.0003911358  |
| time_elapsed            | 652           |
| total timesteps         | 136300        |
| value_loss              | 0.00052943174 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017712393  |
| ent_coef_loss           | 8.253662      |
| entropy                 | 3.6319818     |
| ep_rewmean              | -2.01         |
| episodes                | 1368          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 136601        |
| policy_loss             | 0.6642692     |
| qf1_loss                | 0.0013889562  |
| qf2_loss                | 0.0014623541  |
| time_elapsed            | 654           |
| total timesteps         | 136700        |
| value_loss              | 0.00027626057 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017961133  |
| ent_coef_loss           | -2.38904      |
| entropy                 | 3.417377      |
| ep_rewmean              | -2.05         |
| episodes                | 1372          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 137001        |
| policy_loss             | 0.65920085    |
| qf1_loss                | 0.00015129859 |
| qf2_loss                | 0.00017212704 |
| time_elapsed            | 656           |
| total timesteps         | 137100        |
| value_loss              | 0.00051733217 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017766708 |
| ent_coef_loss           | -0.6477865   |
| entropy                 | 3.061086     |
| ep_rewmean              | -2.03        |
| episodes                | 1376         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2           |
| n_updates               | 137401       |
| policy_loss             | 0.5798166    |
| qf1_loss                | 0.004867862  |
| qf2_loss                | 0.004654276  |
| time_elapsed            | 658          |
| total timesteps         | 137500       |
| value_loss              | 0.0002852817 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018123536  |
| ent_coef_loss           | 2.2870448     |
| entropy                 | 2.7526815     |
| ep_rewmean              | -1.98         |
| episodes                | 1380          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 137801        |
| policy_loss             | 0.6734653     |
| qf1_loss                | 0.00035907864 |
| qf2_loss                | 0.00029586648 |
| time_elapsed            | 660           |
| total timesteps         | 137900        |
| value_loss              | 0.0003629583  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018929641  |
| ent_coef_loss           | 6.6888456     |
| entropy                 | 3.050148      |
| ep_rewmean              | -1.99         |
| episodes                | 1384          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 138201        |
| policy_loss             | 0.61443573    |
| qf1_loss                | 0.0002575282  |
| qf2_loss                | 0.00038251228 |
| time_elapsed            | 662           |
| total timesteps         | 138300        |
| value_loss              | 0.00033118762 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0018054205 |
| ent_coef_loss           | -1.2287163   |
| entropy                 | 3.3440962    |
| ep_rewmean              | -1.98        |
| episodes                | 1388         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2           |
| n_updates               | 138601       |
| policy_loss             | 0.71164954   |
| qf1_loss                | 0.001764008  |
| qf2_loss                | 0.0016615982 |
| time_elapsed            | 664          |
| total timesteps         | 138700       |
| value_loss              | 0.0005983786 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017207082  |
| ent_coef_loss           | -1.8644824    |
| entropy                 | 3.0793111     |
| ep_rewmean              | -1.98         |
| episodes                | 1392          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 139001        |
| policy_loss             | 0.6353315     |
| qf1_loss                | 0.0020916157  |
| qf2_loss                | 0.0020590464  |
| time_elapsed            | 666           |
| total timesteps         | 139100        |
| value_loss              | 0.00027440494 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017342006  |
| ent_coef_loss           | 0.21247971    |
| entropy                 | 2.7879398     |
| ep_rewmean              | -2.02         |
| episodes                | 1396          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 139401        |
| policy_loss             | 0.67415106    |
| qf1_loss                | 0.004033171   |
| qf2_loss                | 0.0040008016  |
| time_elapsed            | 668           |
| total timesteps         | 139500        |
| value_loss              | 0.00015296348 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017814469  |
| ent_coef_loss           | -2.0508375    |
| entropy                 | 2.945546      |
| ep_rewmean              | -2.01         |
| episodes                | 1400          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 139801        |
| policy_loss             | 0.6137022     |
| qf1_loss                | 0.0016475823  |
| qf2_loss                | 0.0016003248  |
| time_elapsed            | 670           |
| total timesteps         | 139900        |
| value_loss              | 0.00046135508 |
-------------------------------------------
Eval num_timesteps=140000, episode_reward=-1.94 +/- 1.51
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018683482  |
| ent_coef_loss           | 1.31558       |
| entropy                 | 3.057941      |
| ep_rewmean              | -2.01         |
| episodes                | 1404          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 140201        |
| policy_loss             | 0.6341492     |
| qf1_loss                | 0.00045706172 |
| qf2_loss                | 0.00031409774 |
| time_elapsed            | 672           |
| total timesteps         | 140300        |
| value_loss              | 0.00035739038 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018859933  |
| ent_coef_loss           | -0.28849256   |
| entropy                 | 3.1713865     |
| ep_rewmean              | -2.01         |
| episodes                | 1408          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 140601        |
| policy_loss             | 0.6285974     |
| qf1_loss                | 0.009178859   |
| qf2_loss                | 0.0093849795  |
| time_elapsed            | 674           |
| total timesteps         | 140700        |
| value_loss              | 0.00035187014 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018344761  |
| ent_coef_loss           | 0.10566461    |
| entropy                 | 3.0170608     |
| ep_rewmean              | -2.07         |
| episodes                | 1412          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 141001        |
| policy_loss             | 0.58768725    |
| qf1_loss                | 0.0019361645  |
| qf2_loss                | 0.0017818315  |
| time_elapsed            | 676           |
| total timesteps         | 141100        |
| value_loss              | 0.00028321892 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018264644  |
| ent_coef_loss           | -10.74439     |
| entropy                 | 2.660174      |
| ep_rewmean              | -2.04         |
| episodes                | 1416          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 141401        |
| policy_loss             | 0.6224296     |
| qf1_loss                | 0.0014230083  |
| qf2_loss                | 0.0013624686  |
| time_elapsed            | 678           |
| total timesteps         | 141500        |
| value_loss              | 0.00035112433 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018331392  |
| ent_coef_loss           | 1.7601913     |
| entropy                 | 2.6076393     |
| ep_rewmean              | -2.04         |
| episodes                | 1420          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 141801        |
| policy_loss             | 0.5774156     |
| qf1_loss                | 0.0002756179  |
| qf2_loss                | 0.00016803195 |
| time_elapsed            | 679           |
| total timesteps         | 141900        |
| value_loss              | 0.0002752947  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001894539   |
| ent_coef_loss           | 0.71322954    |
| entropy                 | 2.2402635     |
| ep_rewmean              | -2.07         |
| episodes                | 1424          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 142201        |
| policy_loss             | 0.5496225     |
| qf1_loss                | 0.0017267206  |
| qf2_loss                | 0.0014533047  |
| time_elapsed            | 681           |
| total timesteps         | 142300        |
| value_loss              | 0.00022868815 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018024571  |
| ent_coef_loss           | 2.131894      |
| entropy                 | 2.5386896     |
| ep_rewmean              | -2.12         |
| episodes                | 1428          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 142601        |
| policy_loss             | 0.61919266    |
| qf1_loss                | 0.0012034996  |
| qf2_loss                | 0.0010023669  |
| time_elapsed            | 683           |
| total timesteps         | 142700        |
| value_loss              | 0.00026088697 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016527544  |
| ent_coef_loss           | -4.935348     |
| entropy                 | 2.7983594     |
| ep_rewmean              | -2.13         |
| episodes                | 1432          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 143001        |
| policy_loss             | 0.54842687    |
| qf1_loss                | 0.003607826   |
| qf2_loss                | 0.0037416576  |
| time_elapsed            | 685           |
| total timesteps         | 143100        |
| value_loss              | 0.00038336136 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001579421   |
| ent_coef_loss           | -3.8033926    |
| entropy                 | 2.6849675     |
| ep_rewmean              | -2.16         |
| episodes                | 1436          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 143401        |
| policy_loss             | 0.57459116    |
| qf1_loss                | 0.005487301   |
| qf2_loss                | 0.0053651985  |
| time_elapsed            | 687           |
| total timesteps         | 143500        |
| value_loss              | 0.00018847609 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015264277  |
| ent_coef_loss           | 2.3849206     |
| entropy                 | 2.5007067     |
| ep_rewmean              | -2.25         |
| episodes                | 1440          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 143801        |
| policy_loss             | 0.58517385    |
| qf1_loss                | 0.00026743734 |
| qf2_loss                | 0.00029897355 |
| time_elapsed            | 689           |
| total timesteps         | 143900        |
| value_loss              | 0.0002557528  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014554055  |
| ent_coef_loss           | -5.738369     |
| entropy                 | 2.716426      |
| ep_rewmean              | -2.38         |
| episodes                | 1444          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 144201        |
| policy_loss             | 0.5891075     |
| qf1_loss                | 0.0015555264  |
| qf2_loss                | 0.001427361   |
| time_elapsed            | 691           |
| total timesteps         | 144300        |
| value_loss              | 0.00022549141 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001426356   |
| ent_coef_loss           | -5.4069443    |
| entropy                 | 2.7852235     |
| ep_rewmean              | -2.42         |
| episodes                | 1448          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 144601        |
| policy_loss             | 0.59173656    |
| qf1_loss                | 0.00022960895 |
| qf2_loss                | 0.00022275539 |
| time_elapsed            | 693           |
| total timesteps         | 144700        |
| value_loss              | 0.00019111828 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013917674  |
| ent_coef_loss           | 2.3933027     |
| entropy                 | 2.841569      |
| ep_rewmean              | -2.5          |
| episodes                | 1452          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 145001        |
| policy_loss             | 0.6202834     |
| qf1_loss                | 0.004443811   |
| qf2_loss                | 0.0044894195  |
| time_elapsed            | 695           |
| total timesteps         | 145100        |
| value_loss              | 0.00023870474 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014786308  |
| ent_coef_loss           | -6.97601      |
| entropy                 | 2.2570615     |
| ep_rewmean              | -2.52         |
| episodes                | 1456          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 145401        |
| policy_loss             | 0.620059      |
| qf1_loss                | 0.0011649353  |
| qf2_loss                | 0.0013278128  |
| time_elapsed            | 697           |
| total timesteps         | 145500        |
| value_loss              | 0.00024991203 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015855007  |
| ent_coef_loss           | 5.7264156     |
| entropy                 | 2.382875      |
| ep_rewmean              | -2.57         |
| episodes                | 1460          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.6          |
| n_updates               | 145801        |
| policy_loss             | 0.56463397    |
| qf1_loss                | 0.0012402383  |
| qf2_loss                | 0.0012777227  |
| time_elapsed            | 698           |
| total timesteps         | 145900        |
| value_loss              | 0.00015459105 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016221588  |
| ent_coef_loss           | -1.4782448    |
| entropy                 | 3.1025965     |
| ep_rewmean              | -2.53         |
| episodes                | 1464          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 146201        |
| policy_loss             | 0.52601504    |
| qf1_loss                | 0.00029549026 |
| qf2_loss                | 0.00024948613 |
| time_elapsed            | 700           |
| total timesteps         | 146300        |
| value_loss              | 0.00016238971 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014639366  |
| ent_coef_loss           | -4.663255     |
| entropy                 | 2.6319788     |
| ep_rewmean              | -2.52         |
| episodes                | 1468          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 146601        |
| policy_loss             | 0.6009989     |
| qf1_loss                | 0.00029812116 |
| qf2_loss                | 0.00040873    |
| time_elapsed            | 702           |
| total timesteps         | 146700        |
| value_loss              | 0.00027023    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013916884  |
| ent_coef_loss           | 5.314488      |
| entropy                 | 1.4732494     |
| ep_rewmean              | -2.51         |
| episodes                | 1472          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 147001        |
| policy_loss             | 0.56880176    |
| qf1_loss                | 0.00032303418 |
| qf2_loss                | 0.00028147016 |
| time_elapsed            | 704           |
| total timesteps         | 147100        |
| value_loss              | 0.00020743995 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014435886  |
| ent_coef_loss           | 2.5737953     |
| entropy                 | 2.839304      |
| ep_rewmean              | -2.51         |
| episodes                | 1476          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 147401        |
| policy_loss             | 0.62651753    |
| qf1_loss                | 0.00020856338 |
| qf2_loss                | 0.00035528134 |
| time_elapsed            | 706           |
| total timesteps         | 147500        |
| value_loss              | 0.00043645164 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014814637  |
| ent_coef_loss           | 3.1068928     |
| entropy                 | 2.431268      |
| ep_rewmean              | -2.5          |
| episodes                | 1480          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 147801        |
| policy_loss             | 0.5887989     |
| qf1_loss                | 0.00029810634 |
| qf2_loss                | 0.00034004814 |
| time_elapsed            | 708           |
| total timesteps         | 147900        |
| value_loss              | 0.0002857435  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015420791  |
| ent_coef_loss           | -1.8557866    |
| entropy                 | 2.7865639     |
| ep_rewmean              | -2.51         |
| episodes                | 1484          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 148201        |
| policy_loss             | 0.5967417     |
| qf1_loss                | 0.00097321084 |
| qf2_loss                | 0.00080858736 |
| time_elapsed            | 710           |
| total timesteps         | 148300        |
| value_loss              | 0.00019698968 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015506244 |
| ent_coef_loss           | -4.282075    |
| entropy                 | 1.7560554    |
| ep_rewmean              | -2.5         |
| episodes                | 1488         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.5         |
| n_updates               | 148601       |
| policy_loss             | 0.6242417    |
| qf1_loss                | 0.0033682939 |
| qf2_loss                | 0.003489938  |
| time_elapsed            | 712          |
| total timesteps         | 148700       |
| value_loss              | 0.0007521645 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015015614  |
| ent_coef_loss           | -8.214287     |
| entropy                 | 2.2686925     |
| ep_rewmean              | -2.5          |
| episodes                | 1492          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 149001        |
| policy_loss             | 0.56491375    |
| qf1_loss                | 0.00023682328 |
| qf2_loss                | 0.00022814196 |
| time_elapsed            | 714           |
| total timesteps         | 149100        |
| value_loss              | 0.0001121277  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014679771  |
| ent_coef_loss           | -0.7305425    |
| entropy                 | 2.3061037     |
| ep_rewmean              | -2.47         |
| episodes                | 1496          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 149401        |
| policy_loss             | 0.608351      |
| qf1_loss                | 0.00034681195 |
| qf2_loss                | 0.00039480327 |
| time_elapsed            | 715           |
| total timesteps         | 149500        |
| value_loss              | 0.00016424578 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014274392  |
| ent_coef_loss           | 1.6674514     |
| entropy                 | 2.903359      |
| ep_rewmean              | -2.5          |
| episodes                | 1500          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 149801        |
| policy_loss             | 0.62997675    |
| qf1_loss                | 0.004683712   |
| qf2_loss                | 0.004712578   |
| time_elapsed            | 717           |
| total timesteps         | 149900        |
| value_loss              | 0.00018416888 |
-------------------------------------------
Eval num_timesteps=150000, episode_reward=-2.11 +/- 1.42
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014661638  |
| ent_coef_loss           | 4.0213704     |
| entropy                 | 2.2297373     |
| ep_rewmean              | -2.48         |
| episodes                | 1504          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 150201        |
| policy_loss             | 0.627936      |
| qf1_loss                | 0.0011441951  |
| qf2_loss                | 0.0017570793  |
| time_elapsed            | 719           |
| total timesteps         | 150300        |
| value_loss              | 0.00015290966 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014237141  |
| ent_coef_loss           | 1.383924      |
| entropy                 | 2.7739677     |
| ep_rewmean              | -2.48         |
| episodes                | 1508          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 150601        |
| policy_loss             | 0.623986      |
| qf1_loss                | 0.00429023    |
| qf2_loss                | 0.0043150936  |
| time_elapsed            | 721           |
| total timesteps         | 150700        |
| value_loss              | 0.00018453231 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013742199  |
| ent_coef_loss           | 1.413434      |
| entropy                 | 2.655524      |
| ep_rewmean              | -2.43         |
| episodes                | 1512          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 151001        |
| policy_loss             | 0.6861554     |
| qf1_loss                | 0.00022822856 |
| qf2_loss                | 0.0002495366  |
| time_elapsed            | 723           |
| total timesteps         | 151100        |
| value_loss              | 0.00015508759 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014535267  |
| ent_coef_loss           | -2.2009134    |
| entropy                 | 2.750768      |
| ep_rewmean              | -2.43         |
| episodes                | 1516          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 151401        |
| policy_loss             | 0.63768643    |
| qf1_loss                | 0.00021092998 |
| qf2_loss                | 0.00019229628 |
| time_elapsed            | 725           |
| total timesteps         | 151500        |
| value_loss              | 0.00030300286 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014598803  |
| ent_coef_loss           | -1.1720022    |
| entropy                 | 2.8404267     |
| ep_rewmean              | -2.48         |
| episodes                | 1520          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 151801        |
| policy_loss             | 0.6334193     |
| qf1_loss                | 0.00022458183 |
| qf2_loss                | 0.00024301047 |
| time_elapsed            | 727           |
| total timesteps         | 151900        |
| value_loss              | 0.0004091936  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0014717014   |
| ent_coef_loss           | 9.232035       |
| entropy                 | 2.1940727      |
| ep_rewmean              | -2.47          |
| episodes                | 1524           |
| eplenmean               | 100            |
| fps                     | 208            |
| mean 100 episode reward | -2.5           |
| n_updates               | 152201         |
| policy_loss             | 0.5988464      |
| qf1_loss                | 0.0053186053   |
| qf2_loss                | 0.0048767463   |
| time_elapsed            | 729            |
| total timesteps         | 152300         |
| value_loss              | 0.000118488766 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014715345  |
| ent_coef_loss           | -1.4360511    |
| entropy                 | 3.0323877     |
| ep_rewmean              | -2.46         |
| episodes                | 1528          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 152601        |
| policy_loss             | 0.6426562     |
| qf1_loss                | 0.0054508736  |
| qf2_loss                | 0.0051657953  |
| time_elapsed            | 731           |
| total timesteps         | 152700        |
| value_loss              | 0.00028245212 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014560011  |
| ent_coef_loss           | -4.4700294    |
| entropy                 | 2.7787247     |
| ep_rewmean              | -2.48         |
| episodes                | 1532          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 153001        |
| policy_loss             | 0.61187387    |
| qf1_loss                | 0.0027833197  |
| qf2_loss                | 0.0024327154  |
| time_elapsed            | 733           |
| total timesteps         | 153100        |
| value_loss              | 0.00027454487 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014629235 |
| ent_coef_loss           | 3.120286     |
| entropy                 | 2.6049504    |
| ep_rewmean              | -2.53        |
| episodes                | 1536         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.5         |
| n_updates               | 153401       |
| policy_loss             | 0.602973     |
| qf1_loss                | 0.0026414886 |
| qf2_loss                | 0.0026596172 |
| time_elapsed            | 735          |
| total timesteps         | 153500       |
| value_loss              | 0.0001867902 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015145056  |
| ent_coef_loss           | 4.518523      |
| entropy                 | 2.1638205     |
| ep_rewmean              | -2.54         |
| episodes                | 1540          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 153801        |
| policy_loss             | 0.56148356    |
| qf1_loss                | 0.0017986774  |
| qf2_loss                | 0.0021516767  |
| time_elapsed            | 737           |
| total timesteps         | 153900        |
| value_loss              | 0.00023526946 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015714947  |
| ent_coef_loss           | -0.39461556   |
| entropy                 | 2.957504      |
| ep_rewmean              | -2.44         |
| episodes                | 1544          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 154201        |
| policy_loss             | 0.6116637     |
| qf1_loss                | 0.00048842264 |
| qf2_loss                | 0.00043906097 |
| time_elapsed            | 738           |
| total timesteps         | 154300        |
| value_loss              | 0.00019619701 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016235502  |
| ent_coef_loss           | 7.1070147     |
| entropy                 | 1.99593       |
| ep_rewmean              | -2.4          |
| episodes                | 1548          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 154601        |
| policy_loss             | 0.599269      |
| qf1_loss                | 0.004642927   |
| qf2_loss                | 0.004080415   |
| time_elapsed            | 740           |
| total timesteps         | 154700        |
| value_loss              | 0.00029028888 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016633257  |
| ent_coef_loss           | -1.9647326    |
| entropy                 | 2.9081378     |
| ep_rewmean              | -2.35         |
| episodes                | 1552          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 155001        |
| policy_loss             | 0.5645191     |
| qf1_loss                | 0.0032145323  |
| qf2_loss                | 0.0030786067  |
| time_elapsed            | 742           |
| total timesteps         | 155100        |
| value_loss              | 0.00030264654 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017122737  |
| ent_coef_loss           | 8.862429      |
| entropy                 | 2.926362      |
| ep_rewmean              | -2.38         |
| episodes                | 1556          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 155401        |
| policy_loss             | 0.5923325     |
| qf1_loss                | 0.003978849   |
| qf2_loss                | 0.003993621   |
| time_elapsed            | 744           |
| total timesteps         | 155500        |
| value_loss              | 0.00034380244 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017923259  |
| ent_coef_loss           | 0.6582953     |
| entropy                 | 2.9808092     |
| ep_rewmean              | -2.33         |
| episodes                | 1560          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 155801        |
| policy_loss             | 0.5740467     |
| qf1_loss                | 0.00032619305 |
| qf2_loss                | 0.0003267071  |
| time_elapsed            | 746           |
| total timesteps         | 155900        |
| value_loss              | 0.00047544253 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018473731  |
| ent_coef_loss           | -0.4464035    |
| entropy                 | 2.7143588     |
| ep_rewmean              | -2.31         |
| episodes                | 1564          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 156201        |
| policy_loss             | 0.6138351     |
| qf1_loss                | 0.00030313974 |
| qf2_loss                | 0.00029362077 |
| time_elapsed            | 748           |
| total timesteps         | 156300        |
| value_loss              | 0.0002219132  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018565536  |
| ent_coef_loss           | 3.5409675     |
| entropy                 | 2.929649      |
| ep_rewmean              | -2.27         |
| episodes                | 1568          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 156601        |
| policy_loss             | 0.5571718     |
| qf1_loss                | 0.00056162366 |
| qf2_loss                | 0.0005380325  |
| time_elapsed            | 750           |
| total timesteps         | 156700        |
| value_loss              | 0.00036402958 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018341088  |
| ent_coef_loss           | 2.9846177     |
| entropy                 | 2.7573433     |
| ep_rewmean              | -2.19         |
| episodes                | 1572          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 157001        |
| policy_loss             | 0.60560554    |
| qf1_loss                | 0.00015776097 |
| qf2_loss                | 0.00013878074 |
| time_elapsed            | 752           |
| total timesteps         | 157100        |
| value_loss              | 0.00024722924 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001859989   |
| ent_coef_loss           | 2.1430097     |
| entropy                 | 2.5924983     |
| ep_rewmean              | -2.14         |
| episodes                | 1576          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 157401        |
| policy_loss             | 0.6382347     |
| qf1_loss                | 0.0061723413  |
| qf2_loss                | 0.00607811    |
| time_elapsed            | 754           |
| total timesteps         | 157500        |
| value_loss              | 0.00023438221 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001876066   |
| ent_coef_loss           | 8.698099      |
| entropy                 | 2.94305       |
| ep_rewmean              | -2.12         |
| episodes                | 1580          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 157801        |
| policy_loss             | 0.5764615     |
| qf1_loss                | 0.0032449095  |
| qf2_loss                | 0.0032903408  |
| time_elapsed            | 756           |
| total timesteps         | 157900        |
| value_loss              | 0.00038630143 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0018537556 |
| ent_coef_loss           | 5.3176622    |
| entropy                 | 2.411652     |
| ep_rewmean              | -2.11        |
| episodes                | 1584         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 158201       |
| policy_loss             | 0.56875217   |
| qf1_loss                | 0.004779799  |
| qf2_loss                | 0.0048322496 |
| time_elapsed            | 757          |
| total timesteps         | 158300       |
| value_loss              | 0.0005665378 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001865818   |
| ent_coef_loss           | -2.9616098    |
| entropy                 | 3.0970247     |
| ep_rewmean              | -2.08         |
| episodes                | 1588          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 158601        |
| policy_loss             | 0.6352993     |
| qf1_loss                | 0.0003145646  |
| qf2_loss                | 0.00020321668 |
| time_elapsed            | 759           |
| total timesteps         | 158700        |
| value_loss              | 0.00018920032 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0018408449 |
| ent_coef_loss           | -0.7526808   |
| entropy                 | 2.6837184    |
| ep_rewmean              | -2.05        |
| episodes                | 1592         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 159001       |
| policy_loss             | 0.67517656   |
| qf1_loss                | 0.005701308  |
| qf2_loss                | 0.0050620986 |
| time_elapsed            | 761          |
| total timesteps         | 159100       |
| value_loss              | 0.0006297364 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00187321    |
| ent_coef_loss           | 3.8471339     |
| entropy                 | 2.5853233     |
| ep_rewmean              | -2.03         |
| episodes                | 1596          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 159401        |
| policy_loss             | 0.6497131     |
| qf1_loss                | 0.00032117782 |
| qf2_loss                | 0.00030776527 |
| time_elapsed            | 763           |
| total timesteps         | 159500        |
| value_loss              | 0.0004383601  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019064095  |
| ent_coef_loss           | -3.3896172    |
| entropy                 | 2.675407      |
| ep_rewmean              | -2.03         |
| episodes                | 1600          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 159801        |
| policy_loss             | 0.68100905    |
| qf1_loss                | 0.00026263116 |
| qf2_loss                | 0.0003084899  |
| time_elapsed            | 765           |
| total timesteps         | 159900        |
| value_loss              | 0.00021355045 |
-------------------------------------------
Eval num_timesteps=160000, episode_reward=-1.63 +/- 1.28
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019316005  |
| ent_coef_loss           | 7.561083      |
| entropy                 | 2.3243475     |
| ep_rewmean              | -2.05         |
| episodes                | 1604          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 160201        |
| policy_loss             | 0.64733714    |
| qf1_loss                | 0.0002051098  |
| qf2_loss                | 0.00024332393 |
| time_elapsed            | 767           |
| total timesteps         | 160300        |
| value_loss              | 0.00039456738 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019066768  |
| ent_coef_loss           | 5.3199615     |
| entropy                 | 2.9036467     |
| ep_rewmean              | -2.07         |
| episodes                | 1608          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 160601        |
| policy_loss             | 0.69423354    |
| qf1_loss                | 0.00021265761 |
| qf2_loss                | 0.00020883781 |
| time_elapsed            | 769           |
| total timesteps         | 160700        |
| value_loss              | 0.0002999448  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019177462  |
| ent_coef_loss           | -2.8006525    |
| entropy                 | 3.3186595     |
| ep_rewmean              | -2.07         |
| episodes                | 1612          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 161001        |
| policy_loss             | 0.738218      |
| qf1_loss                | 0.00032527203 |
| qf2_loss                | 0.00032760415 |
| time_elapsed            | 771           |
| total timesteps         | 161100        |
| value_loss              | 0.00024101946 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019388056  |
| ent_coef_loss           | -4.634306     |
| entropy                 | 3.382092      |
| ep_rewmean              | -2.11         |
| episodes                | 1616          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 161401        |
| policy_loss             | 0.69320625    |
| qf1_loss                | 0.00031340373 |
| qf2_loss                | 0.00041680527 |
| time_elapsed            | 773           |
| total timesteps         | 161500        |
| value_loss              | 0.0002570356  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018815353  |
| ent_coef_loss           | 2.9444442     |
| entropy                 | 2.8018339     |
| ep_rewmean              | -2.05         |
| episodes                | 1620          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 161801        |
| policy_loss             | 0.7338687     |
| qf1_loss                | 0.0002806175  |
| qf2_loss                | 0.00030424434 |
| time_elapsed            | 775           |
| total timesteps         | 161900        |
| value_loss              | 0.00039796924 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019074079  |
| ent_coef_loss           | 0.58780694    |
| entropy                 | 2.7148714     |
| ep_rewmean              | -2.03         |
| episodes                | 1624          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 162201        |
| policy_loss             | 0.72873867    |
| qf1_loss                | 0.011016322   |
| qf2_loss                | 0.010757702   |
| time_elapsed            | 777           |
| total timesteps         | 162300        |
| value_loss              | 0.00023951057 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019372688  |
| ent_coef_loss           | -2.5854585    |
| entropy                 | 2.758696      |
| ep_rewmean              | -2            |
| episodes                | 1628          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 162601        |
| policy_loss             | 0.7723681     |
| qf1_loss                | 0.0005422511  |
| qf2_loss                | 0.00047325625 |
| time_elapsed            | 779           |
| total timesteps         | 162700        |
| value_loss              | 0.00024258852 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0018988901 |
| ent_coef_loss           | 1.3617089    |
| entropy                 | 2.9550786    |
| ep_rewmean              | -1.95        |
| episodes                | 1632         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.9         |
| n_updates               | 163001       |
| policy_loss             | 0.75123143   |
| qf1_loss                | 0.0071522617 |
| qf2_loss                | 0.0065905456 |
| time_elapsed            | 781          |
| total timesteps         | 163100       |
| value_loss              | 0.0003476041 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017787485 |
| ent_coef_loss           | 5.4354653    |
| entropy                 | 1.9800023    |
| ep_rewmean              | -1.91        |
| episodes                | 1636         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.9         |
| n_updates               | 163401       |
| policy_loss             | 0.7877213    |
| qf1_loss                | 0.0015202443 |
| qf2_loss                | 0.0018325542 |
| time_elapsed            | 783          |
| total timesteps         | 163500       |
| value_loss              | 0.0003703764 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017651165  |
| ent_coef_loss           | -2.4838269    |
| entropy                 | 2.6603055     |
| ep_rewmean              | -1.81         |
| episodes                | 1640          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 163801        |
| policy_loss             | 0.788864      |
| qf1_loss                | 0.00027606022 |
| qf2_loss                | 0.00027104118 |
| time_elapsed            | 785           |
| total timesteps         | 163900        |
| value_loss              | 0.00021923226 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017100625  |
| ent_coef_loss           | 5.676244      |
| entropy                 | 2.7168467     |
| ep_rewmean              | -1.8          |
| episodes                | 1644          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 164201        |
| policy_loss             | 0.7774081     |
| qf1_loss                | 0.0031900243  |
| qf2_loss                | 0.0036165868  |
| time_elapsed            | 787           |
| total timesteps         | 164300        |
| value_loss              | 0.00020299101 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017030674  |
| ent_coef_loss           | -0.44436896   |
| entropy                 | 2.2066832     |
| ep_rewmean              | -1.79         |
| episodes                | 1648          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 164601        |
| policy_loss             | 0.8214116     |
| qf1_loss                | 0.00034766324 |
| qf2_loss                | 0.00032343355 |
| time_elapsed            | 788           |
| total timesteps         | 164700        |
| value_loss              | 0.0002656584  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016896401 |
| ent_coef_loss           | 1.5210444    |
| entropy                 | 1.9790345    |
| ep_rewmean              | -1.78        |
| episodes                | 1652         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.8         |
| n_updates               | 165001       |
| policy_loss             | 0.769797     |
| qf1_loss                | 0.007571269  |
| qf2_loss                | 0.007558738  |
| time_elapsed            | 790          |
| total timesteps         | 165100       |
| value_loss              | 0.0005008192 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016567628  |
| ent_coef_loss           | -3.5378976    |
| entropy                 | 2.0480573     |
| ep_rewmean              | -1.79         |
| episodes                | 1656          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 165401        |
| policy_loss             | 0.8294041     |
| qf1_loss                | 0.00047620945 |
| qf2_loss                | 0.0005968363  |
| time_elapsed            | 792           |
| total timesteps         | 165500        |
| value_loss              | 0.00031402655 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016362488  |
| ent_coef_loss           | 2.7309194     |
| entropy                 | 2.1992831     |
| ep_rewmean              | -1.79         |
| episodes                | 1660          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 165801        |
| policy_loss             | 0.8036125     |
| qf1_loss                | 0.0009634538  |
| qf2_loss                | 0.0009526208  |
| time_elapsed            | 794           |
| total timesteps         | 165900        |
| value_loss              | 0.00021605848 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016041893  |
| ent_coef_loss           | -3.0218935    |
| entropy                 | 2.1271563     |
| ep_rewmean              | -1.77         |
| episodes                | 1664          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 166201        |
| policy_loss             | 0.81308985    |
| qf1_loss                | 0.00030777446 |
| qf2_loss                | 0.00028372908 |
| time_elapsed            | 796           |
| total timesteps         | 166300        |
| value_loss              | 0.00017260302 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001516093   |
| ent_coef_loss           | 2.6732283     |
| entropy                 | 2.359436      |
| ep_rewmean              | -1.82         |
| episodes                | 1668          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 166601        |
| policy_loss             | 0.8540406     |
| qf1_loss                | 0.00024508248 |
| qf2_loss                | 0.00022845014 |
| time_elapsed            | 798           |
| total timesteps         | 166700        |
| value_loss              | 0.00045500678 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015457417  |
| ent_coef_loss           | 3.5421617     |
| entropy                 | 1.9921114     |
| ep_rewmean              | -1.85         |
| episodes                | 1672          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 167001        |
| policy_loss             | 0.8690845     |
| qf1_loss                | 0.00025777798 |
| qf2_loss                | 0.0002778811  |
| time_elapsed            | 800           |
| total timesteps         | 167100        |
| value_loss              | 0.00025132872 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001587799   |
| ent_coef_loss           | -3.4872773    |
| entropy                 | 2.6085825     |
| ep_rewmean              | -1.94         |
| episodes                | 1676          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 167401        |
| policy_loss             | 0.8284114     |
| qf1_loss                | 0.0009390164  |
| qf2_loss                | 0.00087517104 |
| time_elapsed            | 802           |
| total timesteps         | 167500        |
| value_loss              | 0.0008924747  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016149173  |
| ent_coef_loss           | -0.11712134   |
| entropy                 | 2.5089679     |
| ep_rewmean              | -1.92         |
| episodes                | 1680          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 167801        |
| policy_loss             | 0.8428401     |
| qf1_loss                | 0.0003332793  |
| qf2_loss                | 0.00025744142 |
| time_elapsed            | 804           |
| total timesteps         | 167900        |
| value_loss              | 0.00023016431 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016412897  |
| ent_coef_loss           | 1.2550006     |
| entropy                 | 2.491078      |
| ep_rewmean              | -1.95         |
| episodes                | 1684          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 168201        |
| policy_loss             | 0.84099734    |
| qf1_loss                | 0.0047698347  |
| qf2_loss                | 0.004958235   |
| time_elapsed            | 806           |
| total timesteps         | 168300        |
| value_loss              | 0.00015037395 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015788126 |
| ent_coef_loss           | -13.539247   |
| entropy                 | 2.2951136    |
| ep_rewmean              | -2.02        |
| episodes                | 1688         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2           |
| n_updates               | 168601       |
| policy_loss             | 0.83125323   |
| qf1_loss                | 0.0053754183 |
| qf2_loss                | 0.0047431705 |
| time_elapsed            | 808          |
| total timesteps         | 168700       |
| value_loss              | 0.0003334038 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015074038  |
| ent_coef_loss           | 3.5065687     |
| entropy                 | 1.7480968     |
| ep_rewmean              | -2.07         |
| episodes                | 1692          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 169001        |
| policy_loss             | 0.82874715    |
| qf1_loss                | 0.0100852335  |
| qf2_loss                | 0.010223952   |
| time_elapsed            | 810           |
| total timesteps         | 169100        |
| value_loss              | 0.00031597388 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015389102  |
| ent_coef_loss           | -8.951841     |
| entropy                 | 2.058512      |
| ep_rewmean              | -2.11         |
| episodes                | 1696          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 169401        |
| policy_loss             | 0.8157642     |
| qf1_loss                | 0.00022677882 |
| qf2_loss                | 0.00027988545 |
| time_elapsed            | 812           |
| total timesteps         | 169500        |
| value_loss              | 0.00025551417 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015011261 |
| ent_coef_loss           | 0.2169838    |
| entropy                 | 1.5561345    |
| ep_rewmean              | -2.13        |
| episodes                | 1700         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 169801       |
| policy_loss             | 0.82352936   |
| qf1_loss                | 0.005621041  |
| qf2_loss                | 0.00532042   |
| time_elapsed            | 814          |
| total timesteps         | 169900       |
| value_loss              | 0.0002096304 |
------------------------------------------
Eval num_timesteps=170000, episode_reward=-2.72 +/- 0.98
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014828807  |
| ent_coef_loss           | 0.23117983    |
| entropy                 | 1.4908726     |
| ep_rewmean              | -2.11         |
| episodes                | 1704          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 170201        |
| policy_loss             | 0.8181699     |
| qf1_loss                | 0.00017858819 |
| qf2_loss                | 0.00020885616 |
| time_elapsed            | 816           |
| total timesteps         | 170300        |
| value_loss              | 0.00014550345 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014809854  |
| ent_coef_loss           | -0.41233444   |
| entropy                 | 1.7681528     |
| ep_rewmean              | -2.09         |
| episodes                | 1708          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 170601        |
| policy_loss             | 0.77758527    |
| qf1_loss                | 0.0006693057  |
| qf2_loss                | 0.00052913633 |
| time_elapsed            | 818           |
| total timesteps         | 170700        |
| value_loss              | 0.00030701954 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014884091  |
| ent_coef_loss           | -2.377642     |
| entropy                 | 1.8019294     |
| ep_rewmean              | -2.1          |
| episodes                | 1712          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 171001        |
| policy_loss             | 0.8225175     |
| qf1_loss                | 0.00020333483 |
| qf2_loss                | 0.00015854216 |
| time_elapsed            | 820           |
| total timesteps         | 171100        |
| value_loss              | 0.00012304395 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014877563  |
| ent_coef_loss           | 2.879736      |
| entropy                 | 2.1371646     |
| ep_rewmean              | -2.09         |
| episodes                | 1716          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 171401        |
| policy_loss             | 0.77234113    |
| qf1_loss                | 0.0002343339  |
| qf2_loss                | 0.00028978405 |
| time_elapsed            | 822           |
| total timesteps         | 171500        |
| value_loss              | 0.0003316208  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001573878   |
| ent_coef_loss           | 7.560584      |
| entropy                 | 1.9594691     |
| ep_rewmean              | -2.09         |
| episodes                | 1720          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 171801        |
| policy_loss             | 0.7599156     |
| qf1_loss                | 0.0003836379  |
| qf2_loss                | 0.0003658617  |
| time_elapsed            | 823           |
| total timesteps         | 171900        |
| value_loss              | 0.00026102542 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017101081  |
| ent_coef_loss           | -2.5673385    |
| entropy                 | 1.946081      |
| ep_rewmean              | -2.11         |
| episodes                | 1724          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 172201        |
| policy_loss             | 0.76589286    |
| qf1_loss                | 0.00028436363 |
| qf2_loss                | 0.00020374834 |
| time_elapsed            | 825           |
| total timesteps         | 172300        |
| value_loss              | 0.00043705158 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017206934  |
| ent_coef_loss           | -5.075266     |
| entropy                 | 2.5759294     |
| ep_rewmean              | -2.1          |
| episodes                | 1728          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 172601        |
| policy_loss             | 0.7923982     |
| qf1_loss                | 0.0035855242  |
| qf2_loss                | 0.0033070934  |
| time_elapsed            | 827           |
| total timesteps         | 172700        |
| value_loss              | 0.00033698423 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017975707  |
| ent_coef_loss           | 1.3998272     |
| entropy                 | 2.330108      |
| ep_rewmean              | -2.09         |
| episodes                | 1732          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 173001        |
| policy_loss             | 0.77308893    |
| qf1_loss                | 0.001572321   |
| qf2_loss                | 0.0012749012  |
| time_elapsed            | 829           |
| total timesteps         | 173100        |
| value_loss              | 0.00027591863 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001903775   |
| ent_coef_loss           | 0.6504643     |
| entropy                 | 3.0751128     |
| ep_rewmean              | -2.11         |
| episodes                | 1736          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 173401        |
| policy_loss             | 0.80134296    |
| qf1_loss                | 0.00018481386 |
| qf2_loss                | 0.0002447846  |
| time_elapsed            | 831           |
| total timesteps         | 173500        |
| value_loss              | 0.0002730914  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018582143  |
| ent_coef_loss           | -3.8202112    |
| entropy                 | 3.0748177     |
| ep_rewmean              | -2.13         |
| episodes                | 1740          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 173801        |
| policy_loss             | 0.77038884    |
| qf1_loss                | 0.0019386942  |
| qf2_loss                | 0.0020683967  |
| time_elapsed            | 833           |
| total timesteps         | 173900        |
| value_loss              | 0.00034121878 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001739496   |
| ent_coef_loss           | 0.11671138    |
| entropy                 | 2.6539903     |
| ep_rewmean              | -2.12         |
| episodes                | 1744          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 174201        |
| policy_loss             | 0.78038645    |
| qf1_loss                | 0.0001712449  |
| qf2_loss                | 0.00016598114 |
| time_elapsed            | 835           |
| total timesteps         | 174300        |
| value_loss              | 0.0001805874  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016513875  |
| ent_coef_loss           | -4.509769     |
| entropy                 | 2.5060873     |
| ep_rewmean              | -2.1          |
| episodes                | 1748          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 174601        |
| policy_loss             | 0.7441359     |
| qf1_loss                | 0.0002459215  |
| qf2_loss                | 0.00029406333 |
| time_elapsed            | 837           |
| total timesteps         | 174700        |
| value_loss              | 0.00046767097 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015744942  |
| ent_coef_loss           | -3.0878768    |
| entropy                 | 2.3267555     |
| ep_rewmean              | -2.11         |
| episodes                | 1752          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 175001        |
| policy_loss             | 0.7273141     |
| qf1_loss                | 0.00045107916 |
| qf2_loss                | 0.00046553113 |
| time_elapsed            | 839           |
| total timesteps         | 175100        |
| value_loss              | 0.00048362848 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015192961  |
| ent_coef_loss           | -3.5422947    |
| entropy                 | 2.6598825     |
| ep_rewmean              | -2.1          |
| episodes                | 1756          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 175401        |
| policy_loss             | 0.7587241     |
| qf1_loss                | 0.0007080464  |
| qf2_loss                | 0.00053539925 |
| time_elapsed            | 840           |
| total timesteps         | 175500        |
| value_loss              | 0.00023229078 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001555059   |
| ent_coef_loss           | -5.0450735    |
| entropy                 | 2.6107507     |
| ep_rewmean              | -2.23         |
| episodes                | 1760          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 175801        |
| policy_loss             | 0.7400517     |
| qf1_loss                | 0.0047271037  |
| qf2_loss                | 0.00481337    |
| time_elapsed            | 842           |
| total timesteps         | 175900        |
| value_loss              | 0.00020746085 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015240291  |
| ent_coef_loss           | -4.1783705    |
| entropy                 | 2.2178988     |
| ep_rewmean              | -2.26         |
| episodes                | 1764          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 176201        |
| policy_loss             | 0.68864846    |
| qf1_loss                | 0.00049747684 |
| qf2_loss                | 0.0005388212  |
| time_elapsed            | 844           |
| total timesteps         | 176300        |
| value_loss              | 0.00031515193 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014515506  |
| ent_coef_loss           | -2.0817916    |
| entropy                 | 1.9330786     |
| ep_rewmean              | -2.3          |
| episodes                | 1768          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 176601        |
| policy_loss             | 0.7660459     |
| qf1_loss                | 0.00020909241 |
| qf2_loss                | 0.00028008857 |
| time_elapsed            | 846           |
| total timesteps         | 176700        |
| value_loss              | 0.0001657136  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015010738  |
| ent_coef_loss           | 2.23598       |
| entropy                 | 2.455842      |
| ep_rewmean              | -2.34         |
| episodes                | 1772          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 177001        |
| policy_loss             | 0.7098558     |
| qf1_loss                | 0.0002036088  |
| qf2_loss                | 0.00019183736 |
| time_elapsed            | 848           |
| total timesteps         | 177100        |
| value_loss              | 0.00021539518 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014798983  |
| ent_coef_loss           | -6.6816764    |
| entropy                 | 2.0915225     |
| ep_rewmean              | -2.3          |
| episodes                | 1776          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 177401        |
| policy_loss             | 0.7079543     |
| qf1_loss                | 0.0021947818  |
| qf2_loss                | 0.0020369284  |
| time_elapsed            | 850           |
| total timesteps         | 177500        |
| value_loss              | 0.00036161672 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015031145  |
| ent_coef_loss           | 3.2762408     |
| entropy                 | 1.460871      |
| ep_rewmean              | -2.35         |
| episodes                | 1780          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 177801        |
| policy_loss             | 0.64041394    |
| qf1_loss                | 0.00033030967 |
| qf2_loss                | 0.00021450759 |
| time_elapsed            | 852           |
| total timesteps         | 177900        |
| value_loss              | 0.00017396988 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015726874 |
| ent_coef_loss           | -1.6462541   |
| entropy                 | 1.6183236    |
| ep_rewmean              | -2.34        |
| episodes                | 1784         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.3         |
| n_updates               | 178201       |
| policy_loss             | 0.69266176   |
| qf1_loss                | 0.010207221  |
| qf2_loss                | 0.010536269  |
| time_elapsed            | 854          |
| total timesteps         | 178300       |
| value_loss              | 0.0001797206 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015840958  |
| ent_coef_loss           | -1.5007222    |
| entropy                 | 2.0442863     |
| ep_rewmean              | -2.3          |
| episodes                | 1788          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 178601        |
| policy_loss             | 0.672611      |
| qf1_loss                | 0.00026881445 |
| qf2_loss                | 0.000343193   |
| time_elapsed            | 856           |
| total timesteps         | 178700        |
| value_loss              | 0.00030451606 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017090525  |
| ent_coef_loss           | -3.0246367    |
| entropy                 | 1.8098524     |
| ep_rewmean              | -2.34         |
| episodes                | 1792          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 179001        |
| policy_loss             | 0.693734      |
| qf1_loss                | 0.00027656925 |
| qf2_loss                | 0.0002581712  |
| time_elapsed            | 858           |
| total timesteps         | 179100        |
| value_loss              | 0.00021686827 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017520017  |
| ent_coef_loss           | 0.5442753     |
| entropy                 | 2.2043753     |
| ep_rewmean              | -2.31         |
| episodes                | 1796          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 179401        |
| policy_loss             | 0.69067836    |
| qf1_loss                | 0.001859057   |
| qf2_loss                | 0.0017799623  |
| time_elapsed            | 859           |
| total timesteps         | 179500        |
| value_loss              | 0.00031732908 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018442301  |
| ent_coef_loss           | 6.3115597     |
| entropy                 | 2.7587404     |
| ep_rewmean              | -2.3          |
| episodes                | 1800          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 179801        |
| policy_loss             | 0.64846176    |
| qf1_loss                | 0.00028144047 |
| qf2_loss                | 0.00029970915 |
| time_elapsed            | 861           |
| total timesteps         | 179900        |
| value_loss              | 0.00032556703 |
-------------------------------------------
Eval num_timesteps=180000, episode_reward=-5.09 +/- 1.08
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018936313  |
| ent_coef_loss           | -6.3631763    |
| entropy                 | 2.8964791     |
| ep_rewmean              | -2.42         |
| episodes                | 1804          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 180201        |
| policy_loss             | 0.67493105    |
| qf1_loss                | 0.00032813856 |
| qf2_loss                | 0.00026625887 |
| time_elapsed            | 864           |
| total timesteps         | 180300        |
| value_loss              | 0.00039814337 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018054893  |
| ent_coef_loss           | 2.848661      |
| entropy                 | 3.3871717     |
| ep_rewmean              | -2.5          |
| episodes                | 1808          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 180601        |
| policy_loss             | 0.68957436    |
| qf1_loss                | 0.00034899573 |
| qf2_loss                | 0.00032103906 |
| time_elapsed            | 865           |
| total timesteps         | 180700        |
| value_loss              | 0.00041106512 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019425589  |
| ent_coef_loss           | 4.5035973     |
| entropy                 | 3.6076226     |
| ep_rewmean              | -2.49         |
| episodes                | 1812          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 181001        |
| policy_loss             | 0.74947274    |
| qf1_loss                | 0.0002506974  |
| qf2_loss                | 0.00017741357 |
| time_elapsed            | 867           |
| total timesteps         | 181100        |
| value_loss              | 0.00027783518 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020178296  |
| ent_coef_loss           | 4.629425      |
| entropy                 | 3.2585797     |
| ep_rewmean              | -2.46         |
| episodes                | 1816          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 181401        |
| policy_loss             | 0.73921573    |
| qf1_loss                | 0.00045168528 |
| qf2_loss                | 0.0007453027  |
| time_elapsed            | 869           |
| total timesteps         | 181500        |
| value_loss              | 0.00035291136 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.00201265   |
| ent_coef_loss           | -2.8989298   |
| entropy                 | 2.986187     |
| ep_rewmean              | -2.5         |
| episodes                | 1820         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.5         |
| n_updates               | 181801       |
| policy_loss             | 0.7394364    |
| qf1_loss                | 0.0026094597 |
| qf2_loss                | 0.0027031626 |
| time_elapsed            | 871          |
| total timesteps         | 181900       |
| value_loss              | 0.0005739385 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0019610282 |
| ent_coef_loss           | -5.872566    |
| entropy                 | 2.6228676    |
| ep_rewmean              | -2.52        |
| episodes                | 1824         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.5         |
| n_updates               | 182201       |
| policy_loss             | 0.7116232    |
| qf1_loss                | 0.0020729937 |
| qf2_loss                | 0.0020673715 |
| time_elapsed            | 873          |
| total timesteps         | 182300       |
| value_loss              | 0.0002844811 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018346503  |
| ent_coef_loss           | -2.9301233    |
| entropy                 | 2.6547503     |
| ep_rewmean              | -2.61         |
| episodes                | 1828          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.6          |
| n_updates               | 182601        |
| policy_loss             | 0.7149373     |
| qf1_loss                | 0.0020945796  |
| qf2_loss                | 0.0020805998  |
| time_elapsed            | 875           |
| total timesteps         | 182700        |
| value_loss              | 0.00025518832 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017434878 |
| ent_coef_loss           | 2.1808317    |
| entropy                 | 2.085791     |
| ep_rewmean              | -2.66        |
| episodes                | 1832         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.7         |
| n_updates               | 183001       |
| policy_loss             | 0.66330063   |
| qf1_loss                | 0.0007082161 |
| qf2_loss                | 0.0003091151 |
| time_elapsed            | 877          |
| total timesteps         | 183100       |
| value_loss              | 0.0005836845 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017984495  |
| ent_coef_loss           | 7.1847444     |
| entropy                 | 2.3011296     |
| ep_rewmean              | -2.66         |
| episodes                | 1836          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.7          |
| n_updates               | 183401        |
| policy_loss             | 0.7016814     |
| qf1_loss                | 0.007996609   |
| qf2_loss                | 0.00801932    |
| time_elapsed            | 879           |
| total timesteps         | 183500        |
| value_loss              | 0.00030819033 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019073461  |
| ent_coef_loss           | -1.5192256    |
| entropy                 | 2.5539362     |
| ep_rewmean              | -2.71         |
| episodes                | 1840          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.7          |
| n_updates               | 183801        |
| policy_loss             | 0.68145907    |
| qf1_loss                | 0.003999444   |
| qf2_loss                | 0.0039541     |
| time_elapsed            | 881           |
| total timesteps         | 183900        |
| value_loss              | 0.00044130193 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017891843  |
| ent_coef_loss           | -0.5408864    |
| entropy                 | 2.116355      |
| ep_rewmean              | -2.7          |
| episodes                | 1844          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.7          |
| n_updates               | 184201        |
| policy_loss             | 0.73298895    |
| qf1_loss                | 0.0003066348  |
| qf2_loss                | 0.00020189807 |
| time_elapsed            | 882           |
| total timesteps         | 184300        |
| value_loss              | 0.0004526953  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017184041  |
| ent_coef_loss           | -4.883978     |
| entropy                 | 1.6852305     |
| ep_rewmean              | -2.74         |
| episodes                | 1848          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.7          |
| n_updates               | 184601        |
| policy_loss             | 0.6757581     |
| qf1_loss                | 0.0004801838  |
| qf2_loss                | 0.00040181473 |
| time_elapsed            | 884           |
| total timesteps         | 184700        |
| value_loss              | 0.0002783126  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016568663  |
| ent_coef_loss           | -1.6696296    |
| entropy                 | 2.0158901     |
| ep_rewmean              | -2.78         |
| episodes                | 1852          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.8          |
| n_updates               | 185001        |
| policy_loss             | 0.67543864    |
| qf1_loss                | 0.00020680975 |
| qf2_loss                | 0.00016939941 |
| time_elapsed            | 886           |
| total timesteps         | 185100        |
| value_loss              | 0.00024080228 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016775116  |
| ent_coef_loss           | -9.2821045    |
| entropy                 | 1.9097056     |
| ep_rewmean              | -2.79         |
| episodes                | 1856          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.8          |
| n_updates               | 185401        |
| policy_loss             | 0.6810963     |
| qf1_loss                | 0.00014942625 |
| qf2_loss                | 0.00014606693 |
| time_elapsed            | 888           |
| total timesteps         | 185500        |
| value_loss              | 0.0002238816  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016268896  |
| ent_coef_loss           | 0.59302783    |
| entropy                 | 2.0443196     |
| ep_rewmean              | -2.69         |
| episodes                | 1860          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.7          |
| n_updates               | 185801        |
| policy_loss             | 0.63160324    |
| qf1_loss                | 0.00033105852 |
| qf2_loss                | 0.00027062613 |
| time_elapsed            | 890           |
| total timesteps         | 185900        |
| value_loss              | 0.00023308424 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001684474   |
| ent_coef_loss           | 0.55878615    |
| entropy                 | 2.4966257     |
| ep_rewmean              | -2.67         |
| episodes                | 1864          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.7          |
| n_updates               | 186201        |
| policy_loss             | 0.64528847    |
| qf1_loss                | 0.0012934008  |
| qf2_loss                | 0.0013086891  |
| time_elapsed            | 892           |
| total timesteps         | 186300        |
| value_loss              | 0.00016151901 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017145156 |
| ent_coef_loss           | -2.6308494   |
| entropy                 | 2.6313405    |
| ep_rewmean              | -2.58        |
| episodes                | 1868         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.6         |
| n_updates               | 186601       |
| policy_loss             | 0.6615073    |
| qf1_loss                | 0.00602448   |
| qf2_loss                | 0.006305064  |
| time_elapsed            | 894          |
| total timesteps         | 186700       |
| value_loss              | 0.0002800499 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017346555  |
| ent_coef_loss           | 1.3653091     |
| entropy                 | 2.0694046     |
| ep_rewmean              | -2.58         |
| episodes                | 1872          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.6          |
| n_updates               | 187001        |
| policy_loss             | 0.6193542     |
| qf1_loss                | 0.0039939466  |
| qf2_loss                | 0.003985993   |
| time_elapsed            | 896           |
| total timesteps         | 187100        |
| value_loss              | 0.00018553968 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017610459  |
| ent_coef_loss           | 0.5147677     |
| entropy                 | 2.454216      |
| ep_rewmean              | -2.58         |
| episodes                | 1876          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.6          |
| n_updates               | 187401        |
| policy_loss             | 0.5521688     |
| qf1_loss                | 0.00037559497 |
| qf2_loss                | 0.0002863882  |
| time_elapsed            | 898           |
| total timesteps         | 187500        |
| value_loss              | 0.00024203531 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018267492  |
| ent_coef_loss           | 2.6785183     |
| entropy                 | 2.597334      |
| ep_rewmean              | -2.63         |
| episodes                | 1880          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.6          |
| n_updates               | 187801        |
| policy_loss             | 0.590037      |
| qf1_loss                | 0.004762352   |
| qf2_loss                | 0.004617979   |
| time_elapsed            | 899           |
| total timesteps         | 187900        |
| value_loss              | 0.00037085637 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019386234  |
| ent_coef_loss           | 3.159511      |
| entropy                 | 2.6002822     |
| ep_rewmean              | -2.6          |
| episodes                | 1884          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.6          |
| n_updates               | 188201        |
| policy_loss             | 0.60625297    |
| qf1_loss                | 0.00046815915 |
| qf2_loss                | 0.00036259726 |
| time_elapsed            | 901           |
| total timesteps         | 188300        |
| value_loss              | 0.00025680722 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019406045  |
| ent_coef_loss           | 1.1635181     |
| entropy                 | 2.2196052     |
| ep_rewmean              | -2.58         |
| episodes                | 1888          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.6          |
| n_updates               | 188601        |
| policy_loss             | 0.59311247    |
| qf1_loss                | 0.0022527333  |
| qf2_loss                | 0.0024122181  |
| time_elapsed            | 903           |
| total timesteps         | 188700        |
| value_loss              | 0.00032923717 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019927365  |
| ent_coef_loss           | 2.5188637     |
| entropy                 | 2.7104526     |
| ep_rewmean              | -2.56         |
| episodes                | 1892          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.6          |
| n_updates               | 189001        |
| policy_loss             | 0.60781956    |
| qf1_loss                | 0.003378464   |
| qf2_loss                | 0.0034083324  |
| time_elapsed            | 905           |
| total timesteps         | 189100        |
| value_loss              | 0.00029404298 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019963859  |
| ent_coef_loss           | 2.7110584     |
| entropy                 | 2.7965417     |
| ep_rewmean              | -2.55         |
| episodes                | 1896          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 189401        |
| policy_loss             | 0.61845326    |
| qf1_loss                | 0.0075159837  |
| qf2_loss                | 0.007634939   |
| time_elapsed            | 907           |
| total timesteps         | 189500        |
| value_loss              | 0.00021778516 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021039916  |
| ent_coef_loss           | -3.515585     |
| entropy                 | 2.5285106     |
| ep_rewmean              | -2.54         |
| episodes                | 1900          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 189801        |
| policy_loss             | 0.62743926    |
| qf1_loss                | 0.00026341993 |
| qf2_loss                | 0.0002657058  |
| time_elapsed            | 909           |
| total timesteps         | 189900        |
| value_loss              | 9.852642e-05  |
-------------------------------------------
Eval num_timesteps=190000, episode_reward=-2.09 +/- 0.35
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022284063  |
| ent_coef_loss           | 1.3240714     |
| entropy                 | 3.1819704     |
| ep_rewmean              | -2.45         |
| episodes                | 1904          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 190201        |
| policy_loss             | 0.6374482     |
| qf1_loss                | 0.0026630254  |
| qf2_loss                | 0.0028789265  |
| time_elapsed            | 911           |
| total timesteps         | 190300        |
| value_loss              | 0.00029237667 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022682578  |
| ent_coef_loss           | -1.4524679    |
| entropy                 | 2.9947        |
| ep_rewmean              | -2.39         |
| episodes                | 1908          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 190601        |
| policy_loss             | 0.6819093     |
| qf1_loss                | 0.0035550203  |
| qf2_loss                | 0.003444379   |
| time_elapsed            | 913           |
| total timesteps         | 190700        |
| value_loss              | 0.00034230587 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021916674  |
| ent_coef_loss           | 0.612061      |
| entropy                 | 3.246721      |
| ep_rewmean              | -2.36         |
| episodes                | 1912          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 191001        |
| policy_loss             | 0.6772759     |
| qf1_loss                | 0.00038997235 |
| qf2_loss                | 0.00042404426 |
| time_elapsed            | 915           |
| total timesteps         | 191100        |
| value_loss              | 0.00020854521 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0021991304 |
| ent_coef_loss           | -3.6403015   |
| entropy                 | 4.03783      |
| ep_rewmean              | -2.38        |
| episodes                | 1916         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.4         |
| n_updates               | 191401       |
| policy_loss             | 0.73444647   |
| qf1_loss                | 0.005022824  |
| qf2_loss                | 0.0051831347 |
| time_elapsed            | 917          |
| total timesteps         | 191500       |
| value_loss              | 0.0002892583 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002207544   |
| ent_coef_loss           | -2.194336     |
| entropy                 | 3.2118154     |
| ep_rewmean              | -2.36         |
| episodes                | 1920          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 191801        |
| policy_loss             | 0.7248454     |
| qf1_loss                | 0.00081912824 |
| qf2_loss                | 0.0008194467  |
| time_elapsed            | 919           |
| total timesteps         | 191900        |
| value_loss              | 0.0002863903  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0023020362 |
| ent_coef_loss           | -1.6376357   |
| entropy                 | 3.8069844    |
| ep_rewmean              | -2.33        |
| episodes                | 1924         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.3         |
| n_updates               | 192201       |
| policy_loss             | 0.7263526    |
| qf1_loss                | 0.01180768   |
| qf2_loss                | 0.011555236  |
| time_elapsed            | 921          |
| total timesteps         | 192300       |
| value_loss              | 0.000195311  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0023560645  |
| ent_coef_loss           | 5.8752747     |
| entropy                 | 3.4368887     |
| ep_rewmean              | -2.26         |
| episodes                | 1928          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 192601        |
| policy_loss             | 0.7498403     |
| qf1_loss                | 0.008063839   |
| qf2_loss                | 0.008570024   |
| time_elapsed            | 923           |
| total timesteps         | 192700        |
| value_loss              | 0.00045035116 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0023841723 |
| ent_coef_loss           | 2.6538136    |
| entropy                 | 3.4988613    |
| ep_rewmean              | -2.22        |
| episodes                | 1932         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.2         |
| n_updates               | 193001       |
| policy_loss             | 0.7252713    |
| qf1_loss                | 0.006061918  |
| qf2_loss                | 0.0063565457 |
| time_elapsed            | 924          |
| total timesteps         | 193100       |
| value_loss              | 0.0003628985 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022946112  |
| ent_coef_loss           | 1.5145689     |
| entropy                 | 3.157298      |
| ep_rewmean              | -2.22         |
| episodes                | 1936          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 193401        |
| policy_loss             | 0.83363706    |
| qf1_loss                | 0.00021665907 |
| qf2_loss                | 0.00024244383 |
| time_elapsed            | 926           |
| total timesteps         | 193500        |
| value_loss              | 0.00032632623 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022205506  |
| ent_coef_loss           | 3.8189423     |
| entropy                 | 3.2520354     |
| ep_rewmean              | -2.17         |
| episodes                | 1940          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 193801        |
| policy_loss             | 0.812332      |
| qf1_loss                | 0.00030935043 |
| qf2_loss                | 0.00041573163 |
| time_elapsed            | 928           |
| total timesteps         | 193900        |
| value_loss              | 0.0003891149  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002186222   |
| ent_coef_loss           | -0.8685268    |
| entropy                 | 3.4186974     |
| ep_rewmean              | -2.21         |
| episodes                | 1944          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 194201        |
| policy_loss             | 0.85588926    |
| qf1_loss                | 0.0023037642  |
| qf2_loss                | 0.002335061   |
| time_elapsed            | 930           |
| total timesteps         | 194300        |
| value_loss              | 0.00024187041 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021332374  |
| ent_coef_loss           | -1.9370792    |
| entropy                 | 3.1376941     |
| ep_rewmean              | -2.18         |
| episodes                | 1948          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 194601        |
| policy_loss             | 0.86084586    |
| qf1_loss                | 0.022356354   |
| qf2_loss                | 0.02288216    |
| time_elapsed            | 932           |
| total timesteps         | 194700        |
| value_loss              | 0.00026462082 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001985635  |
| ent_coef_loss           | -5.3440347   |
| entropy                 | 2.6716876    |
| ep_rewmean              | -2.15        |
| episodes                | 1952         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.2         |
| n_updates               | 195001       |
| policy_loss             | 0.8322408    |
| qf1_loss                | 0.001906253  |
| qf2_loss                | 0.0018736626 |
| time_elapsed            | 934          |
| total timesteps         | 195100       |
| value_loss              | 0.0007067064 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018675075  |
| ent_coef_loss           | 2.1110501     |
| entropy                 | 2.6629138     |
| ep_rewmean              | -2.08         |
| episodes                | 1956          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 195401        |
| policy_loss             | 0.8455088     |
| qf1_loss                | 0.00043026055 |
| qf2_loss                | 0.00039069395 |
| time_elapsed            | 936           |
| total timesteps         | 195500        |
| value_loss              | 0.00071708055 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017709058  |
| ent_coef_loss           | 0.5361903     |
| entropy                 | 2.9091184     |
| ep_rewmean              | -2.1          |
| episodes                | 1960          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 195801        |
| policy_loss             | 0.8949798     |
| qf1_loss                | 0.00025290417 |
| qf2_loss                | 0.00026594888 |
| time_elapsed            | 938           |
| total timesteps         | 195900        |
| value_loss              | 0.00032084156 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017146447 |
| ent_coef_loss           | 2.197632     |
| entropy                 | 2.4775186    |
| ep_rewmean              | -2.08        |
| episodes                | 1964         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 196201       |
| policy_loss             | 0.85082555   |
| qf1_loss                | 0.0043619713 |
| qf2_loss                | 0.004030289  |
| time_elapsed            | 940          |
| total timesteps         | 196300       |
| value_loss              | 0.0001875049 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017729277  |
| ent_coef_loss           | -3.8885903    |
| entropy                 | 2.8648753     |
| ep_rewmean              | -2.11         |
| episodes                | 1968          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 196601        |
| policy_loss             | 0.914237      |
| qf1_loss                | 0.00178208    |
| qf2_loss                | 0.0021522292  |
| time_elapsed            | 942           |
| total timesteps         | 196700        |
| value_loss              | 0.00031022492 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017610266  |
| ent_coef_loss           | -4.100303     |
| entropy                 | 2.8164082     |
| ep_rewmean              | -2.14         |
| episodes                | 1972          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 197001        |
| policy_loss             | 0.8498768     |
| qf1_loss                | 0.00039106875 |
| qf2_loss                | 0.0002535196  |
| time_elapsed            | 944           |
| total timesteps         | 197100        |
| value_loss              | 0.00022060834 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001818936   |
| ent_coef_loss           | 4.1279964     |
| entropy                 | 3.012605      |
| ep_rewmean              | -2.18         |
| episodes                | 1976          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 197401        |
| policy_loss             | 0.91337556    |
| qf1_loss                | 0.0002449848  |
| qf2_loss                | 0.00020168349 |
| time_elapsed            | 945           |
| total timesteps         | 197500        |
| value_loss              | 0.00040487925 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018424572  |
| ent_coef_loss           | -3.0173426    |
| entropy                 | 3.0581048     |
| ep_rewmean              | -2.13         |
| episodes                | 1980          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 197801        |
| policy_loss             | 0.8605412     |
| qf1_loss                | 0.0051099397  |
| qf2_loss                | 0.00491452    |
| time_elapsed            | 947           |
| total timesteps         | 197900        |
| value_loss              | 0.00016830862 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019329466  |
| ent_coef_loss           | 0.26759785    |
| entropy                 | 2.8449216     |
| ep_rewmean              | -2.15         |
| episodes                | 1984          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 198201        |
| policy_loss             | 0.9080013     |
| qf1_loss                | 0.00032125798 |
| qf2_loss                | 0.0002728477  |
| time_elapsed            | 949           |
| total timesteps         | 198300        |
| value_loss              | 0.00025502354 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001990391  |
| ent_coef_loss           | 3.503712     |
| entropy                 | 2.6316853    |
| ep_rewmean              | -2.16        |
| episodes                | 1988         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.2         |
| n_updates               | 198601       |
| policy_loss             | 0.88893044   |
| qf1_loss                | 0.02079404   |
| qf2_loss                | 0.020501807  |
| time_elapsed            | 951          |
| total timesteps         | 198700       |
| value_loss              | 0.0004103524 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0020038784 |
| ent_coef_loss           | 1.7393832    |
| entropy                 | 2.873867     |
| ep_rewmean              | -2.09        |
| episodes                | 1992         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 199001       |
| policy_loss             | 0.89475095   |
| qf1_loss                | 0.0008160391 |
| qf2_loss                | 0.0007493246 |
| time_elapsed            | 953          |
| total timesteps         | 199100       |
| value_loss              | 0.0005490828 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019187249  |
| ent_coef_loss           | -5.7133064    |
| entropy                 | 2.3532739     |
| ep_rewmean              | -2.11         |
| episodes                | 1996          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 199401        |
| policy_loss             | 0.8555815     |
| qf1_loss                | 0.00035798294 |
| qf2_loss                | 0.00037206642 |
| time_elapsed            | 955           |
| total timesteps         | 199500        |
| value_loss              | 0.00048679629 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018471634  |
| ent_coef_loss           | -0.4552263    |
| entropy                 | 2.5519266     |
| ep_rewmean              | -2.14         |
| episodes                | 2000          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 199801        |
| policy_loss             | 0.8386606     |
| qf1_loss                | 0.003352524   |
| qf2_loss                | 0.003507153   |
| time_elapsed            | 957           |
| total timesteps         | 199900        |
| value_loss              | 0.00032292097 |
-------------------------------------------
Eval num_timesteps=200000, episode_reward=-6.11 +/- 0.97
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018295554  |
| ent_coef_loss           | 1.6695676     |
| entropy                 | 2.6842005     |
| ep_rewmean              | -2.26         |
| episodes                | 2004          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 200201        |
| policy_loss             | 0.9133016     |
| qf1_loss                | 0.0048570405  |
| qf2_loss                | 0.0047708773  |
| time_elapsed            | 959           |
| total timesteps         | 200300        |
| value_loss              | 0.00014266181 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019101375  |
| ent_coef_loss           | 1.6123356     |
| entropy                 | 2.5979185     |
| ep_rewmean              | -2.26         |
| episodes                | 2008          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 200601        |
| policy_loss             | 0.8305141     |
| qf1_loss                | 0.008512988   |
| qf2_loss                | 0.007985042   |
| time_elapsed            | 961           |
| total timesteps         | 200700        |
| value_loss              | 0.00031488412 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019315333  |
| ent_coef_loss           | 1.7910903     |
| entropy                 | 2.3443403     |
| ep_rewmean              | -2.28         |
| episodes                | 2012          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 201001        |
| policy_loss             | 0.903124      |
| qf1_loss                | 0.0155209545  |
| qf2_loss                | 0.015801603   |
| time_elapsed            | 963           |
| total timesteps         | 201100        |
| value_loss              | 0.00034492667 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018435768  |
| ent_coef_loss           | -4.6752176    |
| entropy                 | 2.9528744     |
| ep_rewmean              | -2.31         |
| episodes                | 2016          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 201401        |
| policy_loss             | 0.9022589     |
| qf1_loss                | 0.00022924624 |
| qf2_loss                | 0.0002341065  |
| time_elapsed            | 965           |
| total timesteps         | 201500        |
| value_loss              | 0.0002794543  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016893968  |
| ent_coef_loss           | -5.7728724    |
| entropy                 | 2.388098      |
| ep_rewmean              | -2.33         |
| episodes                | 2020          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 201801        |
| policy_loss             | 0.8540596     |
| qf1_loss                | 0.00024604588 |
| qf2_loss                | 0.00023282638 |
| time_elapsed            | 967           |
| total timesteps         | 201900        |
| value_loss              | 0.00028267025 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015327045  |
| ent_coef_loss           | 0.9266925     |
| entropy                 | 2.2386456     |
| ep_rewmean              | -2.33         |
| episodes                | 2024          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 202201        |
| policy_loss             | 0.8563999     |
| qf1_loss                | 0.00031159344 |
| qf2_loss                | 0.00027024376 |
| time_elapsed            | 969           |
| total timesteps         | 202300        |
| value_loss              | 0.0002694537  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014460253  |
| ent_coef_loss           | 1.1561257     |
| entropy                 | 1.8147593     |
| ep_rewmean              | -2.29         |
| episodes                | 2028          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 202601        |
| policy_loss             | 0.8212099     |
| qf1_loss                | 0.00038754856 |
| qf2_loss                | 0.00037504046 |
| time_elapsed            | 971           |
| total timesteps         | 202700        |
| value_loss              | 0.00027341838 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013582545  |
| ent_coef_loss           | -1.0767214    |
| entropy                 | 1.4323822     |
| ep_rewmean              | -2.23         |
| episodes                | 2032          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 203001        |
| policy_loss             | 0.932474      |
| qf1_loss                | 0.00630116    |
| qf2_loss                | 0.006266678   |
| time_elapsed            | 973           |
| total timesteps         | 203100        |
| value_loss              | 0.00032917986 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012984301 |
| ent_coef_loss           | 5.0156326    |
| entropy                 | 1.2407787    |
| ep_rewmean              | -2.25        |
| episodes                | 2036         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.2         |
| n_updates               | 203401       |
| policy_loss             | 0.8707437    |
| qf1_loss                | 0.009555861  |
| qf2_loss                | 0.009205581  |
| time_elapsed            | 975          |
| total timesteps         | 203500       |
| value_loss              | 0.0006670271 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012925697  |
| ent_coef_loss           | -3.3887343    |
| entropy                 | 1.3911302     |
| ep_rewmean              | -2.34         |
| episodes                | 2040          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 203801        |
| policy_loss             | 0.8811961     |
| qf1_loss                | 0.00038424798 |
| qf2_loss                | 0.00034173497 |
| time_elapsed            | 976           |
| total timesteps         | 203900        |
| value_loss              | 0.00024250092 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013059216  |
| ent_coef_loss           | 3.9948447     |
| entropy                 | 0.51436263    |
| ep_rewmean              | -2.34         |
| episodes                | 2044          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 204201        |
| policy_loss             | 0.8647639     |
| qf1_loss                | 0.0070589003  |
| qf2_loss                | 0.007117993   |
| time_elapsed            | 978           |
| total timesteps         | 204300        |
| value_loss              | 0.00026688725 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013319186  |
| ent_coef_loss           | 2.1616144     |
| entropy                 | 0.93184197    |
| ep_rewmean              | -2.39         |
| episodes                | 2048          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 204601        |
| policy_loss             | 0.88792473    |
| qf1_loss                | 0.00042176334 |
| qf2_loss                | 0.0004065883  |
| time_elapsed            | 980           |
| total timesteps         | 204700        |
| value_loss              | 0.0002709772  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013305831  |
| ent_coef_loss           | 0.8656584     |
| entropy                 | 1.6773399     |
| ep_rewmean              | -2.39         |
| episodes                | 2052          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 205001        |
| policy_loss             | 0.7658526     |
| qf1_loss                | 0.00043934726 |
| qf2_loss                | 0.0004344211  |
| time_elapsed            | 982           |
| total timesteps         | 205100        |
| value_loss              | 0.00027699815 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012924033  |
| ent_coef_loss           | -0.6151254    |
| entropy                 | 0.92782307    |
| ep_rewmean              | -2.39         |
| episodes                | 2056          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 205401        |
| policy_loss             | 0.8199397     |
| qf1_loss                | 0.008566511   |
| qf2_loss                | 0.008165039   |
| time_elapsed            | 984           |
| total timesteps         | 205500        |
| value_loss              | 0.00020859696 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011887837  |
| ent_coef_loss           | -1.2475715    |
| entropy                 | 1.1237726     |
| ep_rewmean              | -2.35         |
| episodes                | 2060          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 205801        |
| policy_loss             | 0.82924527    |
| qf1_loss                | 0.00034620133 |
| qf2_loss                | 0.0003098966  |
| time_elapsed            | 986           |
| total timesteps         | 205900        |
| value_loss              | 0.0005037344  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011112064  |
| ent_coef_loss           | -2.3938293    |
| entropy                 | 1.0012019     |
| ep_rewmean              | -2.37         |
| episodes                | 2064          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 206201        |
| policy_loss             | 0.8206653     |
| qf1_loss                | 0.0006151557  |
| qf2_loss                | 0.00055504846 |
| time_elapsed            | 988           |
| total timesteps         | 206300        |
| value_loss              | 0.0002634889  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010428942  |
| ent_coef_loss           | -1.8019314    |
| entropy                 | 0.451747      |
| ep_rewmean              | -2.36         |
| episodes                | 2068          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 206601        |
| policy_loss             | 0.83282256    |
| qf1_loss                | 0.01478383    |
| qf2_loss                | 0.01511446    |
| time_elapsed            | 990           |
| total timesteps         | 206700        |
| value_loss              | 0.00031624685 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010753371  |
| ent_coef_loss           | -0.45905948   |
| entropy                 | 0.50600564    |
| ep_rewmean              | -2.31         |
| episodes                | 2072          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 207001        |
| policy_loss             | 0.8036902     |
| qf1_loss                | 0.00044816133 |
| qf2_loss                | 0.00038339556 |
| time_elapsed            | 992           |
| total timesteps         | 207100        |
| value_loss              | 0.0006005581  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011276004  |
| ent_coef_loss           | 3.3020754     |
| entropy                 | 1.3094983     |
| ep_rewmean              | -2.26         |
| episodes                | 2076          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 207401        |
| policy_loss             | 0.85524315    |
| qf1_loss                | 0.006112376   |
| qf2_loss                | 0.0060490137  |
| time_elapsed            | 994           |
| total timesteps         | 207500        |
| value_loss              | 0.00022121162 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011397133  |
| ent_coef_loss           | -1.4972808    |
| entropy                 | 0.8866967     |
| ep_rewmean              | -2.28         |
| episodes                | 2080          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 207801        |
| policy_loss             | 0.80217046    |
| qf1_loss                | 0.0002873449  |
| qf2_loss                | 0.00027086138 |
| time_elapsed            | 996           |
| total timesteps         | 207900        |
| value_loss              | 0.0002048272  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011914787  |
| ent_coef_loss           | -1.9056348    |
| entropy                 | 1.41029       |
| ep_rewmean              | -2.28         |
| episodes                | 2084          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 208201        |
| policy_loss             | 0.8054443     |
| qf1_loss                | 0.0059436355  |
| qf2_loss                | 0.0055906135  |
| time_elapsed            | 998           |
| total timesteps         | 208300        |
| value_loss              | 0.00024571398 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012344866  |
| ent_coef_loss           | 1.6125927     |
| entropy                 | 1.5682507     |
| ep_rewmean              | -2.32         |
| episodes                | 2088          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 208601        |
| policy_loss             | 0.7805606     |
| qf1_loss                | 0.00033162945 |
| qf2_loss                | 0.00041002268 |
| time_elapsed            | 1000          |
| total timesteps         | 208700        |
| value_loss              | 0.00037668287 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012967807 |
| ent_coef_loss           | 10.272938    |
| entropy                 | 1.1769036    |
| ep_rewmean              | -2.37        |
| episodes                | 2092         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.4         |
| n_updates               | 209001       |
| policy_loss             | 0.7292103    |
| qf1_loss                | 0.004206317  |
| qf2_loss                | 0.004337028  |
| time_elapsed            | 1001         |
| total timesteps         | 209100       |
| value_loss              | 0.000260539  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012944465  |
| ent_coef_loss           | 0.49929714    |
| entropy                 | 1.4797812     |
| ep_rewmean              | -2.37         |
| episodes                | 2096          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 209401        |
| policy_loss             | 0.8191704     |
| qf1_loss                | 0.0003880771  |
| qf2_loss                | 0.0003832439  |
| time_elapsed            | 1003          |
| total timesteps         | 209500        |
| value_loss              | 0.00032395282 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012487316  |
| ent_coef_loss           | -2.449636     |
| entropy                 | 2.0941334     |
| ep_rewmean              | -2.34         |
| episodes                | 2100          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 209801        |
| policy_loss             | 0.7714352     |
| qf1_loss                | 0.011905737   |
| qf2_loss                | 0.012217148   |
| time_elapsed            | 1005          |
| total timesteps         | 209900        |
| value_loss              | 0.00036398863 |
-------------------------------------------
Eval num_timesteps=210000, episode_reward=-2.88 +/- 1.51
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012191267  |
| ent_coef_loss           | 4.40614       |
| entropy                 | 1.4420625     |
| ep_rewmean              | -2.2          |
| episodes                | 2104          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 210201        |
| policy_loss             | 0.70612216    |
| qf1_loss                | 0.010499237   |
| qf2_loss                | 0.010614213   |
| time_elapsed            | 1007          |
| total timesteps         | 210300        |
| value_loss              | 0.00036479867 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001262398   |
| ent_coef_loss           | -1.9796525    |
| entropy                 | 1.8753233     |
| ep_rewmean              | -2.16         |
| episodes                | 2108          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 210601        |
| policy_loss             | 0.7432884     |
| qf1_loss                | 0.00035447307 |
| qf2_loss                | 0.00041563826 |
| time_elapsed            | 1009          |
| total timesteps         | 210700        |
| value_loss              | 0.00019652976 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012642673  |
| ent_coef_loss           | 1.8430287     |
| entropy                 | 2.7910616     |
| ep_rewmean              | -2.14         |
| episodes                | 2112          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 211001        |
| policy_loss             | 0.76255494    |
| qf1_loss                | 0.00042177684 |
| qf2_loss                | 0.00037238112 |
| time_elapsed            | 1011          |
| total timesteps         | 211100        |
| value_loss              | 0.00018953404 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013332855  |
| ent_coef_loss           | -1.7661151    |
| entropy                 | 2.5598364     |
| ep_rewmean              | -2.09         |
| episodes                | 2116          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 211401        |
| policy_loss             | 0.82194793    |
| qf1_loss                | 0.00078470167 |
| qf2_loss                | 0.00080505037 |
| time_elapsed            | 1013          |
| total timesteps         | 211500        |
| value_loss              | 0.00034540665 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013507127  |
| ent_coef_loss           | -0.12124801   |
| entropy                 | 2.326011      |
| ep_rewmean              | -2.05         |
| episodes                | 2120          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 211801        |
| policy_loss             | 0.80081844    |
| qf1_loss                | 0.006546003   |
| qf2_loss                | 0.0059575303  |
| time_elapsed            | 1015          |
| total timesteps         | 211900        |
| value_loss              | 0.00041267404 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00131888    |
| ent_coef_loss           | 7.094364      |
| entropy                 | 2.3849401     |
| ep_rewmean              | -2.09         |
| episodes                | 2124          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 212201        |
| policy_loss             | 0.87228715    |
| qf1_loss                | 0.002617545   |
| qf2_loss                | 0.0027402313  |
| time_elapsed            | 1017          |
| total timesteps         | 212300        |
| value_loss              | 0.00031464017 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001314986   |
| ent_coef_loss           | -2.515564     |
| entropy                 | 2.557691      |
| ep_rewmean              | -2.17         |
| episodes                | 2128          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 212601        |
| policy_loss             | 0.825027      |
| qf1_loss                | 0.0035681794  |
| qf2_loss                | 0.0035166375  |
| time_elapsed            | 1019          |
| total timesteps         | 212700        |
| value_loss              | 0.00019548729 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013006064  |
| ent_coef_loss           | -0.83225036   |
| entropy                 | 2.1658301     |
| ep_rewmean              | -2.21         |
| episodes                | 2132          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 213001        |
| policy_loss             | 0.8432466     |
| qf1_loss                | 0.0002590923  |
| qf2_loss                | 0.00026278838 |
| time_elapsed            | 1021          |
| total timesteps         | 213100        |
| value_loss              | 0.0003395872  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012378411  |
| ent_coef_loss           | -0.6719814    |
| entropy                 | 1.3698579     |
| ep_rewmean              | -2.18         |
| episodes                | 2136          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 213401        |
| policy_loss             | 0.8551337     |
| qf1_loss                | 0.002249249   |
| qf2_loss                | 0.0021166273  |
| time_elapsed            | 1023          |
| total timesteps         | 213500        |
| value_loss              | 0.00031885988 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012743647  |
| ent_coef_loss           | 4.8904247     |
| entropy                 | 1.9013493     |
| ep_rewmean              | -2.2          |
| episodes                | 2140          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 213801        |
| policy_loss             | 0.8181573     |
| qf1_loss                | 0.00031290785 |
| qf2_loss                | 0.0004944606  |
| time_elapsed            | 1025          |
| total timesteps         | 213900        |
| value_loss              | 0.00023455206 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001306886   |
| ent_coef_loss           | 5.918144      |
| entropy                 | 2.0044417     |
| ep_rewmean              | -2.22         |
| episodes                | 2144          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 214201        |
| policy_loss             | 0.84177846    |
| qf1_loss                | 0.0004909068  |
| qf2_loss                | 0.00046585302 |
| time_elapsed            | 1027          |
| total timesteps         | 214300        |
| value_loss              | 0.00018840801 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012835778  |
| ent_coef_loss           | 0.14797783    |
| entropy                 | 1.8209724     |
| ep_rewmean              | -2.21         |
| episodes                | 2148          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 214601        |
| policy_loss             | 0.801853      |
| qf1_loss                | 0.00025804457 |
| qf2_loss                | 0.0003311614  |
| time_elapsed            | 1029          |
| total timesteps         | 214700        |
| value_loss              | 0.00048576825 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001294246   |
| ent_coef_loss           | -10.1660385   |
| entropy                 | 2.0047464     |
| ep_rewmean              | -2.25         |
| episodes                | 2152          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 215001        |
| policy_loss             | 0.8122222     |
| qf1_loss                | 0.0007305113  |
| qf2_loss                | 0.00072919886 |
| time_elapsed            | 1030          |
| total timesteps         | 215100        |
| value_loss              | 0.00029645555 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013110628  |
| ent_coef_loss           | 0.9345417     |
| entropy                 | 2.3246202     |
| ep_rewmean              | -2.23         |
| episodes                | 2156          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 215401        |
| policy_loss             | 0.877479      |
| qf1_loss                | 0.005021262   |
| qf2_loss                | 0.0050676097  |
| time_elapsed            | 1032          |
| total timesteps         | 215500        |
| value_loss              | 0.00041687305 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013255005  |
| ent_coef_loss           | -1.9191017    |
| entropy                 | 1.9964674     |
| ep_rewmean              | -2.23         |
| episodes                | 2160          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 215801        |
| policy_loss             | 0.8453597     |
| qf1_loss                | 0.00041195587 |
| qf2_loss                | 0.00034931523 |
| time_elapsed            | 1034          |
| total timesteps         | 215900        |
| value_loss              | 0.00027114362 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013478972  |
| ent_coef_loss           | 0.41971076    |
| entropy                 | 1.9691571     |
| ep_rewmean              | -2.25         |
| episodes                | 2164          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 216201        |
| policy_loss             | 0.8510833     |
| qf1_loss                | 0.003183704   |
| qf2_loss                | 0.0029286323  |
| time_elapsed            | 1036          |
| total timesteps         | 216300        |
| value_loss              | 0.00032358133 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012943558  |
| ent_coef_loss           | -2.7152584    |
| entropy                 | 1.9872712     |
| ep_rewmean              | -2.25         |
| episodes                | 2168          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 216601        |
| policy_loss             | 0.82172775    |
| qf1_loss                | 0.003074636   |
| qf2_loss                | 0.0031942595  |
| time_elapsed            | 1038          |
| total timesteps         | 216700        |
| value_loss              | 0.00039884576 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012949399  |
| ent_coef_loss           | 6.7305417     |
| entropy                 | 2.067323      |
| ep_rewmean              | -2.28         |
| episodes                | 2172          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 217001        |
| policy_loss             | 0.8026245     |
| qf1_loss                | 0.00027286902 |
| qf2_loss                | 0.00042773574 |
| time_elapsed            | 1040          |
| total timesteps         | 217100        |
| value_loss              | 0.00032042936 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013791407  |
| ent_coef_loss           | 1.0058094     |
| entropy                 | 1.7988544     |
| ep_rewmean              | -2.3          |
| episodes                | 2176          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 217401        |
| policy_loss             | 0.8084971     |
| qf1_loss                | 0.0003544071  |
| qf2_loss                | 0.00030981778 |
| time_elapsed            | 1042          |
| total timesteps         | 217500        |
| value_loss              | 0.00032527337 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013839696  |
| ent_coef_loss           | 4.1889944     |
| entropy                 | 1.9993688     |
| ep_rewmean              | -2.26         |
| episodes                | 2180          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 217801        |
| policy_loss             | 0.8356743     |
| qf1_loss                | 0.0033319443  |
| qf2_loss                | 0.0033255648  |
| time_elapsed            | 1044          |
| total timesteps         | 217900        |
| value_loss              | 0.00034958858 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013556198  |
| ent_coef_loss           | 0.41101652    |
| entropy                 | 1.2243481     |
| ep_rewmean              | -2.31         |
| episodes                | 2184          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 218201        |
| policy_loss             | 0.7445061     |
| qf1_loss                | 0.0028920553  |
| qf2_loss                | 0.0029043653  |
| time_elapsed            | 1046          |
| total timesteps         | 218300        |
| value_loss              | 0.00063731836 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012688367 |
| ent_coef_loss           | -0.9994911   |
| entropy                 | 1.2683413    |
| ep_rewmean              | -2.32        |
| episodes                | 2188         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.3         |
| n_updates               | 218601       |
| policy_loss             | 0.78848994   |
| qf1_loss                | 0.004969635  |
| qf2_loss                | 0.00464746   |
| time_elapsed            | 1048         |
| total timesteps         | 218700       |
| value_loss              | 0.000307429  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012050004  |
| ent_coef_loss           | -1.5468783    |
| entropy                 | 1.2658854     |
| ep_rewmean              | -2.32         |
| episodes                | 2192          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 219001        |
| policy_loss             | 0.7589089     |
| qf1_loss                | 0.00031614586 |
| qf2_loss                | 0.00032078137 |
| time_elapsed            | 1050          |
| total timesteps         | 219100        |
| value_loss              | 0.0002298789  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012078602  |
| ent_coef_loss           | -1.073275     |
| entropy                 | 1.4740307     |
| ep_rewmean              | -2.26         |
| episodes                | 2196          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 219401        |
| policy_loss             | 0.7905323     |
| qf1_loss                | 0.0004939493  |
| qf2_loss                | 0.0004780871  |
| time_elapsed            | 1052          |
| total timesteps         | 219500        |
| value_loss              | 0.00028072303 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011857502  |
| ent_coef_loss           | 2.067621      |
| entropy                 | 0.9828136     |
| ep_rewmean              | -2.27         |
| episodes                | 2200          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 219801        |
| policy_loss             | 0.78192294    |
| qf1_loss                | 0.004436696   |
| qf2_loss                | 0.00428833    |
| time_elapsed            | 1054          |
| total timesteps         | 219900        |
| value_loss              | 0.00052398024 |
-------------------------------------------
Eval num_timesteps=220000, episode_reward=-1.86 +/- 0.70
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001148465   |
| ent_coef_loss           | 3.2443202     |
| entropy                 | 1.4008572     |
| ep_rewmean              | -2.3          |
| episodes                | 2204          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 220201        |
| policy_loss             | 0.8215605     |
| qf1_loss                | 0.0053113406  |
| qf2_loss                | 0.0050266245  |
| time_elapsed            | 1056          |
| total timesteps         | 220300        |
| value_loss              | 0.00018872382 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011561337  |
| ent_coef_loss           | -6.062639     |
| entropy                 | 1.3657229     |
| ep_rewmean              | -2.34         |
| episodes                | 2208          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 220601        |
| policy_loss             | 0.7674227     |
| qf1_loss                | 0.0002673103  |
| qf2_loss                | 0.0002530487  |
| time_elapsed            | 1058          |
| total timesteps         | 220700        |
| value_loss              | 0.00018265742 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011273337  |
| ent_coef_loss           | 3.373868      |
| entropy                 | 1.9990414     |
| ep_rewmean              | -2.37         |
| episodes                | 2212          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 221001        |
| policy_loss             | 0.81698465    |
| qf1_loss                | 0.0002830912  |
| qf2_loss                | 0.00026548858 |
| time_elapsed            | 1060          |
| total timesteps         | 221100        |
| value_loss              | 0.00031648547 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011977081  |
| ent_coef_loss           | 0.3222952     |
| entropy                 | 1.6360395     |
| ep_rewmean              | -2.38         |
| episodes                | 2216          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 221401        |
| policy_loss             | 0.76879966    |
| qf1_loss                | 0.004274632   |
| qf2_loss                | 0.0049695107  |
| time_elapsed            | 1061          |
| total timesteps         | 221500        |
| value_loss              | 0.00037245615 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013063776  |
| ent_coef_loss           | 2.050753      |
| entropy                 | 2.400533      |
| ep_rewmean              | -2.42         |
| episodes                | 2220          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 221801        |
| policy_loss             | 0.78345144    |
| qf1_loss                | 0.00035889944 |
| qf2_loss                | 0.00030243373 |
| time_elapsed            | 1063          |
| total timesteps         | 221900        |
| value_loss              | 0.00021385867 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013926869  |
| ent_coef_loss           | 0.8990972     |
| entropy                 | 2.7936828     |
| ep_rewmean              | -2.39         |
| episodes                | 2224          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 222201        |
| policy_loss             | 0.838163      |
| qf1_loss                | 0.005799486   |
| qf2_loss                | 0.00547854    |
| time_elapsed            | 1065          |
| total timesteps         | 222300        |
| value_loss              | 0.00021356448 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016048985  |
| ent_coef_loss           | 3.0100572     |
| entropy                 | 3.0482562     |
| ep_rewmean              | -2.34         |
| episodes                | 2228          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 222601        |
| policy_loss             | 0.8449212     |
| qf1_loss                | 0.012860023   |
| qf2_loss                | 0.012578217   |
| time_elapsed            | 1067          |
| total timesteps         | 222700        |
| value_loss              | 0.00022087587 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017158692  |
| ent_coef_loss           | 1.2205572     |
| entropy                 | 2.4879532     |
| ep_rewmean              | -2.39         |
| episodes                | 2232          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 223001        |
| policy_loss             | 0.760353      |
| qf1_loss                | 0.0010372252  |
| qf2_loss                | 0.00093038596 |
| time_elapsed            | 1069          |
| total timesteps         | 223100        |
| value_loss              | 0.0007067142  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016922477  |
| ent_coef_loss           | 2.2816293     |
| entropy                 | 3.3109374     |
| ep_rewmean              | -2.41         |
| episodes                | 2236          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 223401        |
| policy_loss             | 0.8210944     |
| qf1_loss                | 0.00022874729 |
| qf2_loss                | 0.00028654802 |
| time_elapsed            | 1071          |
| total timesteps         | 223500        |
| value_loss              | 0.00021250613 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016962467 |
| ent_coef_loss           | -0.93923104  |
| entropy                 | 2.347803     |
| ep_rewmean              | -2.32        |
| episodes                | 2240         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.3         |
| n_updates               | 223801       |
| policy_loss             | 0.8060403    |
| qf1_loss                | 0.003926541  |
| qf2_loss                | 0.0036007583 |
| time_elapsed            | 1073         |
| total timesteps         | 223900       |
| value_loss              | 0.0002381799 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016145977  |
| ent_coef_loss           | -4.225859     |
| entropy                 | 1.8319919     |
| ep_rewmean              | -2.3          |
| episodes                | 2244          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 224201        |
| policy_loss             | 0.6919681     |
| qf1_loss                | 0.00083127106 |
| qf2_loss                | 0.0006182337  |
| time_elapsed            | 1075          |
| total timesteps         | 224300        |
| value_loss              | 0.00025804876 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016142905 |
| ent_coef_loss           | 3.3568203    |
| entropy                 | 2.2655773    |
| ep_rewmean              | -2.28        |
| episodes                | 2248         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.3         |
| n_updates               | 224601       |
| policy_loss             | 0.78101003   |
| qf1_loss                | 0.0071855183 |
| qf2_loss                | 0.0066024372 |
| time_elapsed            | 1077         |
| total timesteps         | 224700       |
| value_loss              | 0.0003156776 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015998358  |
| ent_coef_loss           | -3.5545976    |
| entropy                 | 1.6749145     |
| ep_rewmean              | -2.26         |
| episodes                | 2252          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 225001        |
| policy_loss             | 0.7369846     |
| qf1_loss                | 0.0018796254  |
| qf2_loss                | 0.0023178195  |
| time_elapsed            | 1079          |
| total timesteps         | 225100        |
| value_loss              | 0.00028654633 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014557366  |
| ent_coef_loss           | 1.1033475     |
| entropy                 | 1.9025271     |
| ep_rewmean              | -2.26         |
| episodes                | 2256          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 225401        |
| policy_loss             | 0.7165586     |
| qf1_loss                | 0.00036502792 |
| qf2_loss                | 0.00032266544 |
| time_elapsed            | 1081          |
| total timesteps         | 225500        |
| value_loss              | 0.00022902741 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013620233  |
| ent_coef_loss           | -5.4178085    |
| entropy                 | 1.8964452     |
| ep_rewmean              | -2.28         |
| episodes                | 2260          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 225801        |
| policy_loss             | 0.7904526     |
| qf1_loss                | 0.00065713143 |
| qf2_loss                | 0.000731754   |
| time_elapsed            | 1083          |
| total timesteps         | 225900        |
| value_loss              | 0.000397759   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012984698  |
| ent_coef_loss           | -1.0081947    |
| entropy                 | 1.9434992     |
| ep_rewmean              | -2.29         |
| episodes                | 2264          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 226201        |
| policy_loss             | 0.71138513    |
| qf1_loss                | 0.0009966412  |
| qf2_loss                | 0.00089685404 |
| time_elapsed            | 1085          |
| total timesteps         | 226300        |
| value_loss              | 0.00034127434 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012873106  |
| ent_coef_loss           | 0.8721826     |
| entropy                 | 1.4171871     |
| ep_rewmean              | -2.45         |
| episodes                | 2268          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 226601        |
| policy_loss             | 0.769609      |
| qf1_loss                | 0.011499115   |
| qf2_loss                | 0.0116387345  |
| time_elapsed            | 1086          |
| total timesteps         | 226700        |
| value_loss              | 0.00032760555 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012965215 |
| ent_coef_loss           | -1.0104508   |
| entropy                 | 1.9265845    |
| ep_rewmean              | -2.49        |
| episodes                | 2272         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.5         |
| n_updates               | 227001       |
| policy_loss             | 0.76788384   |
| qf1_loss                | 0.0018689166 |
| qf2_loss                | 0.0020343913 |
| time_elapsed            | 1088         |
| total timesteps         | 227100       |
| value_loss              | 0.0001487959 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013642014  |
| ent_coef_loss           | 1.7554306     |
| entropy                 | 2.4477315     |
| ep_rewmean              | -2.47         |
| episodes                | 2276          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 227401        |
| policy_loss             | 0.74191713    |
| qf1_loss                | 0.00023376803 |
| qf2_loss                | 0.00031971728 |
| time_elapsed            | 1090          |
| total timesteps         | 227500        |
| value_loss              | 0.00029755355 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014207688  |
| ent_coef_loss           | 0.51022136    |
| entropy                 | 2.5667672     |
| ep_rewmean              | -2.47         |
| episodes                | 2280          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 227801        |
| policy_loss             | 0.781057      |
| qf1_loss                | 0.00031928468 |
| qf2_loss                | 0.00037629143 |
| time_elapsed            | 1092          |
| total timesteps         | 227900        |
| value_loss              | 0.00021281253 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014302387  |
| ent_coef_loss           | -5.20306      |
| entropy                 | 2.120308      |
| ep_rewmean              | -2.4          |
| episodes                | 2284          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 228201        |
| policy_loss             | 0.7422532     |
| qf1_loss                | 0.0077600414  |
| qf2_loss                | 0.0076575     |
| time_elapsed            | 1094          |
| total timesteps         | 228300        |
| value_loss              | 0.00029460667 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014947206  |
| ent_coef_loss           | -0.61361194   |
| entropy                 | 2.1449673     |
| ep_rewmean              | -2.37         |
| episodes                | 2288          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 228601        |
| policy_loss             | 0.7192414     |
| qf1_loss                | 0.002860527   |
| qf2_loss                | 0.002958807   |
| time_elapsed            | 1096          |
| total timesteps         | 228700        |
| value_loss              | 0.00037284236 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014768023  |
| ent_coef_loss           | 0.061048448   |
| entropy                 | 2.2413135     |
| ep_rewmean              | -2.34         |
| episodes                | 2292          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 229001        |
| policy_loss             | 0.7339411     |
| qf1_loss                | 0.00053478335 |
| qf2_loss                | 0.0004643699  |
| time_elapsed            | 1098          |
| total timesteps         | 229100        |
| value_loss              | 0.0003907021  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013836343  |
| ent_coef_loss           | 0.090052366   |
| entropy                 | 1.8603086     |
| ep_rewmean              | -2.36         |
| episodes                | 2296          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 229401        |
| policy_loss             | 0.73493487    |
| qf1_loss                | 0.0027451518  |
| qf2_loss                | 0.002359685   |
| time_elapsed            | 1100          |
| total timesteps         | 229500        |
| value_loss              | 0.00026462722 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013617545  |
| ent_coef_loss           | -1.5028386    |
| entropy                 | 1.569053      |
| ep_rewmean              | -2.37         |
| episodes                | 2300          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 229801        |
| policy_loss             | 0.6935004     |
| qf1_loss                | 0.00030489304 |
| qf2_loss                | 0.00028250628 |
| time_elapsed            | 1102          |
| total timesteps         | 229900        |
| value_loss              | 0.00034877326 |
-------------------------------------------
Eval num_timesteps=230000, episode_reward=-2.59 +/- 1.03
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013451267 |
| ent_coef_loss           | 0.30865073   |
| entropy                 | 2.2189145    |
| ep_rewmean              | -2.33        |
| episodes                | 2304         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.3         |
| n_updates               | 230201       |
| policy_loss             | 0.72808313   |
| qf1_loss                | 0.005663563  |
| qf2_loss                | 0.006056082  |
| time_elapsed            | 1104         |
| total timesteps         | 230300       |
| value_loss              | 0.0003362107 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00136686    |
| ent_coef_loss           | -7.5061836    |
| entropy                 | 2.2257338     |
| ep_rewmean              | -2.28         |
| episodes                | 2308          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 230601        |
| policy_loss             | 0.71702135    |
| qf1_loss                | 0.0011232287  |
| qf2_loss                | 0.00093619415 |
| time_elapsed            | 1106          |
| total timesteps         | 230700        |
| value_loss              | 0.0002235327  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014109995  |
| ent_coef_loss           | -5.709863     |
| entropy                 | 2.2590675     |
| ep_rewmean              | -2.25         |
| episodes                | 2312          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 231001        |
| policy_loss             | 0.71391517    |
| qf1_loss                | 0.00031674243 |
| qf2_loss                | 0.000283525   |
| time_elapsed            | 1108          |
| total timesteps         | 231100        |
| value_loss              | 0.00024872363 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014552418  |
| ent_coef_loss           | -0.5557655    |
| entropy                 | 2.332995      |
| ep_rewmean              | -2.24         |
| episodes                | 2316          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 231401        |
| policy_loss             | 0.6685029     |
| qf1_loss                | 0.00023994704 |
| qf2_loss                | 0.0003244282  |
| time_elapsed            | 1110          |
| total timesteps         | 231500        |
| value_loss              | 0.00022833861 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001484927   |
| ent_coef_loss           | -1.5121644    |
| entropy                 | 2.2051358     |
| ep_rewmean              | -2.18         |
| episodes                | 2320          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 231801        |
| policy_loss             | 0.7275063     |
| qf1_loss                | 0.00029410765 |
| qf2_loss                | 0.0002871863  |
| time_elapsed            | 1111          |
| total timesteps         | 231900        |
| value_loss              | 0.00022004993 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014758181  |
| ent_coef_loss           | 0.44692025    |
| entropy                 | 2.1487932     |
| ep_rewmean              | -2.22         |
| episodes                | 2324          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 232201        |
| policy_loss             | 0.7592503     |
| qf1_loss                | 0.013467717   |
| qf2_loss                | 0.012982121   |
| time_elapsed            | 1113          |
| total timesteps         | 232300        |
| value_loss              | 0.00023845593 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014407018 |
| ent_coef_loss           | -7.11506     |
| entropy                 | 2.4983919    |
| ep_rewmean              | -2.25        |
| episodes                | 2328         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.2         |
| n_updates               | 232601       |
| policy_loss             | 0.7715825    |
| qf1_loss                | 0.0064629368 |
| qf2_loss                | 0.006702356  |
| time_elapsed            | 1115         |
| total timesteps         | 232700       |
| value_loss              | 0.0002540577 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013986818  |
| ent_coef_loss           | 3.3001628     |
| entropy                 | 1.8985226     |
| ep_rewmean              | -2.26         |
| episodes                | 2332          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 233001        |
| policy_loss             | 0.67915744    |
| qf1_loss                | 0.0002640544  |
| qf2_loss                | 0.00023039641 |
| time_elapsed            | 1117          |
| total timesteps         | 233100        |
| value_loss              | 0.00039077882 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013821144  |
| ent_coef_loss           | 1.0645853     |
| entropy                 | 2.235355      |
| ep_rewmean              | -2.33         |
| episodes                | 2336          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 233401        |
| policy_loss             | 0.7050556     |
| qf1_loss                | 0.00040126144 |
| qf2_loss                | 0.00043651665 |
| time_elapsed            | 1119          |
| total timesteps         | 233500        |
| value_loss              | 0.00023015508 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014023721  |
| ent_coef_loss           | 1.7582555     |
| entropy                 | 1.7511636     |
| ep_rewmean              | -2.38         |
| episodes                | 2340          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 233801        |
| policy_loss             | 0.7019706     |
| qf1_loss                | 0.00026624475 |
| qf2_loss                | 0.0002980008  |
| time_elapsed            | 1121          |
| total timesteps         | 233900        |
| value_loss              | 0.00023355492 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014141301  |
| ent_coef_loss           | -6.5145       |
| entropy                 | 2.7545447     |
| ep_rewmean              | -2.34         |
| episodes                | 2344          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 234201        |
| policy_loss             | 0.6824579     |
| qf1_loss                | 0.0003684889  |
| qf2_loss                | 0.00035549345 |
| time_elapsed            | 1123          |
| total timesteps         | 234300        |
| value_loss              | 0.00020951194 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014763257  |
| ent_coef_loss           | 4.341752      |
| entropy                 | 3.0471787     |
| ep_rewmean              | -2.34         |
| episodes                | 2348          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 234601        |
| policy_loss             | 0.7106539     |
| qf1_loss                | 0.0002364059  |
| qf2_loss                | 0.00027436193 |
| time_elapsed            | 1125          |
| total timesteps         | 234700        |
| value_loss              | 0.00020892464 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014769974  |
| ent_coef_loss           | -0.12277821   |
| entropy                 | 2.5609112     |
| ep_rewmean              | -2.29         |
| episodes                | 2352          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 235001        |
| policy_loss             | 0.70976025    |
| qf1_loss                | 0.0011085352  |
| qf2_loss                | 0.0009913278  |
| time_elapsed            | 1127          |
| total timesteps         | 235100        |
| value_loss              | 0.00016605694 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014745675  |
| ent_coef_loss           | -2.022941     |
| entropy                 | 2.6679506     |
| ep_rewmean              | -2.29         |
| episodes                | 2356          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 235401        |
| policy_loss             | 0.70548046    |
| qf1_loss                | 0.002487948   |
| qf2_loss                | 0.0023634697  |
| time_elapsed            | 1129          |
| total timesteps         | 235500        |
| value_loss              | 0.00029564727 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014877414  |
| ent_coef_loss           | -0.28046465   |
| entropy                 | 2.6922798     |
| ep_rewmean              | -2.28         |
| episodes                | 2360          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 235801        |
| policy_loss             | 0.6629904     |
| qf1_loss                | 0.00034367706 |
| qf2_loss                | 0.00045247228 |
| time_elapsed            | 1131          |
| total timesteps         | 235900        |
| value_loss              | 0.0002596759  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014987702  |
| ent_coef_loss           | -0.8076035    |
| entropy                 | 2.043857      |
| ep_rewmean              | -2.23         |
| episodes                | 2364          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 236201        |
| policy_loss             | 0.64125115    |
| qf1_loss                | 0.00051873643 |
| qf2_loss                | 0.00044039811 |
| time_elapsed            | 1133          |
| total timesteps         | 236300        |
| value_loss              | 0.0003483614  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015205151  |
| ent_coef_loss           | 3.491016      |
| entropy                 | 2.2198749     |
| ep_rewmean              | -2.08         |
| episodes                | 2368          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 236601        |
| policy_loss             | 0.63907015    |
| qf1_loss                | 0.0057847984  |
| qf2_loss                | 0.005472919   |
| time_elapsed            | 1134          |
| total timesteps         | 236700        |
| value_loss              | 0.00034961378 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00147627    |
| ent_coef_loss           | -2.1052253    |
| entropy                 | 2.7616322     |
| ep_rewmean              | -2.03         |
| episodes                | 2372          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 237001        |
| policy_loss             | 0.6175251     |
| qf1_loss                | 0.00037792264 |
| qf2_loss                | 0.00021048912 |
| time_elapsed            | 1136          |
| total timesteps         | 237100        |
| value_loss              | 0.00029134395 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014505252 |
| ent_coef_loss           | 6.014795     |
| entropy                 | 2.6697714    |
| ep_rewmean              | -2.04        |
| episodes                | 2376         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2           |
| n_updates               | 237401       |
| policy_loss             | 0.6521036    |
| qf1_loss                | 0.0053293067 |
| qf2_loss                | 0.005464607  |
| time_elapsed            | 1138         |
| total timesteps         | 237500       |
| value_loss              | 0.0003760025 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014505474  |
| ent_coef_loss           | -4.154013     |
| entropy                 | 2.3794913     |
| ep_rewmean              | -2.04         |
| episodes                | 2380          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 237801        |
| policy_loss             | 0.58919466    |
| qf1_loss                | 0.0002614147  |
| qf2_loss                | 0.00031129108 |
| time_elapsed            | 1140          |
| total timesteps         | 237900        |
| value_loss              | 0.0003260291  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015054917 |
| ent_coef_loss           | -4.4606752   |
| entropy                 | 2.5943244    |
| ep_rewmean              | -2.14        |
| episodes                | 2384         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 238201       |
| policy_loss             | 0.6339315    |
| qf1_loss                | 0.0033853697 |
| qf2_loss                | 0.0034822586 |
| time_elapsed            | 1142         |
| total timesteps         | 238300       |
| value_loss              | 0.0001575733 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015191113  |
| ent_coef_loss           | 2.0742564     |
| entropy                 | 2.028262      |
| ep_rewmean              | -2.16         |
| episodes                | 2388          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 238601        |
| policy_loss             | 0.64933133    |
| qf1_loss                | 0.0018410959  |
| qf2_loss                | 0.0018782698  |
| time_elapsed            | 1144          |
| total timesteps         | 238700        |
| value_loss              | 0.00020738802 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015468699  |
| ent_coef_loss           | -5.99393      |
| entropy                 | 2.762388      |
| ep_rewmean              | -2.2          |
| episodes                | 2392          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 239001        |
| policy_loss             | 0.66631985    |
| qf1_loss                | 0.005681634   |
| qf2_loss                | 0.006015064   |
| time_elapsed            | 1146          |
| total timesteps         | 239100        |
| value_loss              | 0.00025028575 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014728606  |
| ent_coef_loss           | 9.161241      |
| entropy                 | 2.2664378     |
| ep_rewmean              | -2.23         |
| episodes                | 2396          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 239401        |
| policy_loss             | 0.63553166    |
| qf1_loss                | 0.0004479678  |
| qf2_loss                | 0.0005753311  |
| time_elapsed            | 1148          |
| total timesteps         | 239500        |
| value_loss              | 0.00051060074 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014548664  |
| ent_coef_loss           | -2.1332176    |
| entropy                 | 2.4819303     |
| ep_rewmean              | -2.21         |
| episodes                | 2400          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 239801        |
| policy_loss             | 0.65177053    |
| qf1_loss                | 0.006745614   |
| qf2_loss                | 0.0066695292  |
| time_elapsed            | 1150          |
| total timesteps         | 239900        |
| value_loss              | 0.00032060675 |
-------------------------------------------
Eval num_timesteps=240000, episode_reward=-3.88 +/- 1.59
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001400447   |
| ent_coef_loss           | -6.873054     |
| entropy                 | 2.8113766     |
| ep_rewmean              | -2.21         |
| episodes                | 2404          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 240201        |
| policy_loss             | 0.6412875     |
| qf1_loss                | 0.012098785   |
| qf2_loss                | 0.012146197   |
| time_elapsed            | 1152          |
| total timesteps         | 240300        |
| value_loss              | 0.00019709484 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013429144  |
| ent_coef_loss           | -1.0205262    |
| entropy                 | 2.4107018     |
| ep_rewmean              | -2.22         |
| episodes                | 2408          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 240601        |
| policy_loss             | 0.62084854    |
| qf1_loss                | 0.007982088   |
| qf2_loss                | 0.0075131473  |
| time_elapsed            | 1154          |
| total timesteps         | 240700        |
| value_loss              | 0.00041101885 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013299976  |
| ent_coef_loss           | 7.741962      |
| entropy                 | 2.5199738     |
| ep_rewmean              | -2.23         |
| episodes                | 2412          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 241001        |
| policy_loss             | 0.66624576    |
| qf1_loss                | 0.00057212857 |
| qf2_loss                | 0.00045674416 |
| time_elapsed            | 1156          |
| total timesteps         | 241100        |
| value_loss              | 0.00039768196 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013447066  |
| ent_coef_loss           | 2.742724      |
| entropy                 | 2.8818998     |
| ep_rewmean              | -2.27         |
| episodes                | 2416          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 241401        |
| policy_loss             | 0.68480814    |
| qf1_loss                | 0.007088518   |
| qf2_loss                | 0.007126803   |
| time_elapsed            | 1158          |
| total timesteps         | 241500        |
| value_loss              | 0.00024789426 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001298073   |
| ent_coef_loss           | -4.4504557    |
| entropy                 | 2.3868608     |
| ep_rewmean              | -2.29         |
| episodes                | 2420          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 241801        |
| policy_loss             | 0.6131078     |
| qf1_loss                | 0.00026619213 |
| qf2_loss                | 0.00019748369 |
| time_elapsed            | 1160          |
| total timesteps         | 241900        |
| value_loss              | 0.0002528752  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012973973  |
| ent_coef_loss           | 2.792449      |
| entropy                 | 2.4220378     |
| ep_rewmean              | -2.27         |
| episodes                | 2424          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 242201        |
| policy_loss             | 0.6189287     |
| qf1_loss                | 0.009396821   |
| qf2_loss                | 0.010860719   |
| time_elapsed            | 1161          |
| total timesteps         | 242300        |
| value_loss              | 0.00016068177 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012678962  |
| ent_coef_loss           | -5.2941504    |
| entropy                 | 2.7382388     |
| ep_rewmean              | -2.26         |
| episodes                | 2428          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 242601        |
| policy_loss             | 0.63003683    |
| qf1_loss                | 0.00026482338 |
| qf2_loss                | 0.00016960705 |
| time_elapsed            | 1163          |
| total timesteps         | 242700        |
| value_loss              | 0.00015168682 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012917594  |
| ent_coef_loss           | 2.623094      |
| entropy                 | 2.6360526     |
| ep_rewmean              | -2.2          |
| episodes                | 2432          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 243001        |
| policy_loss             | 0.7192159     |
| qf1_loss                | 0.00045305624 |
| qf2_loss                | 0.0003601719  |
| time_elapsed            | 1165          |
| total timesteps         | 243100        |
| value_loss              | 0.0002134523  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.001260746    |
| ent_coef_loss           | 2.3021557      |
| entropy                 | 2.742672       |
| ep_rewmean              | -2.15          |
| episodes                | 2436           |
| eplenmean               | 100            |
| fps                     | 208            |
| mean 100 episode reward | -2.1           |
| n_updates               | 243401         |
| policy_loss             | 0.6811727      |
| qf1_loss                | 0.0022697272   |
| qf2_loss                | 0.0019050435   |
| time_elapsed            | 1167           |
| total timesteps         | 243500         |
| value_loss              | 0.000106679916 |
--------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013550045 |
| ent_coef_loss           | 5.8337626    |
| entropy                 | 2.6968808    |
| ep_rewmean              | -2.09        |
| episodes                | 2440         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 243801       |
| policy_loss             | 0.7117642    |
| qf1_loss                | 0.0032992293 |
| qf2_loss                | 0.003559253  |
| time_elapsed            | 1169         |
| total timesteps         | 243900       |
| value_loss              | 0.000221725  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014760701  |
| ent_coef_loss           | 2.5174189     |
| entropy                 | 2.788564      |
| ep_rewmean              | -2.16         |
| episodes                | 2444          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 244201        |
| policy_loss             | 0.6964251     |
| qf1_loss                | 0.0026926692  |
| qf2_loss                | 0.002716279   |
| time_elapsed            | 1171          |
| total timesteps         | 244300        |
| value_loss              | 0.00022713118 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014655612  |
| ent_coef_loss           | -0.6422193    |
| entropy                 | 3.3832786     |
| ep_rewmean              | -2.16         |
| episodes                | 2448          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 244601        |
| policy_loss             | 0.7803823     |
| qf1_loss                | 0.007094903   |
| qf2_loss                | 0.006882143   |
| time_elapsed            | 1173          |
| total timesteps         | 244700        |
| value_loss              | 0.00014930921 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013844619  |
| ent_coef_loss           | -1.6684823    |
| entropy                 | 3.3935993     |
| ep_rewmean              | -2.16         |
| episodes                | 2452          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 245001        |
| policy_loss             | 0.72368103    |
| qf1_loss                | 0.00023810631 |
| qf2_loss                | 0.00021376945 |
| time_elapsed            | 1175          |
| total timesteps         | 245100        |
| value_loss              | 0.00018183305 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013585058  |
| ent_coef_loss           | -2.7928987    |
| entropy                 | 2.8472369     |
| ep_rewmean              | -2.24         |
| episodes                | 2456          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 245401        |
| policy_loss             | 0.80768824    |
| qf1_loss                | 0.00035987323 |
| qf2_loss                | 0.0003455733  |
| time_elapsed            | 1177          |
| total timesteps         | 245500        |
| value_loss              | 0.00046116541 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013346849  |
| ent_coef_loss           | 0.026868582   |
| entropy                 | 3.3448026     |
| ep_rewmean              | -2.23         |
| episodes                | 2460          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 245801        |
| policy_loss             | 0.7603261     |
| qf1_loss                | 0.00027690068 |
| qf2_loss                | 0.00026540813 |
| time_elapsed            | 1179          |
| total timesteps         | 245900        |
| value_loss              | 0.00017171237 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013148932 |
| ent_coef_loss           | -2.6534362   |
| entropy                 | 2.679718     |
| ep_rewmean              | -2.24        |
| episodes                | 2464         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.2         |
| n_updates               | 246201       |
| policy_loss             | 0.7671292    |
| qf1_loss                | 0.00499066   |
| qf2_loss                | 0.0051216297 |
| time_elapsed            | 1180         |
| total timesteps         | 246300       |
| value_loss              | 0.0001614156 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013923575  |
| ent_coef_loss           | 4.1934037     |
| entropy                 | 2.3265176     |
| ep_rewmean              | -2.26         |
| episodes                | 2468          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 246601        |
| policy_loss             | 0.7922417     |
| qf1_loss                | 0.0003383882  |
| qf2_loss                | 0.00042670412 |
| time_elapsed            | 1182          |
| total timesteps         | 246700        |
| value_loss              | 0.00015782972 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001357163   |
| ent_coef_loss           | 0.12688541    |
| entropy                 | 2.6518326     |
| ep_rewmean              | -2.31         |
| episodes                | 2472          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 247001        |
| policy_loss             | 0.76385987    |
| qf1_loss                | 0.006788858   |
| qf2_loss                | 0.0074357167  |
| time_elapsed            | 1184          |
| total timesteps         | 247100        |
| value_loss              | 0.00019944894 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013064473  |
| ent_coef_loss           | -5.105547     |
| entropy                 | 2.544073      |
| ep_rewmean              | -2.29         |
| episodes                | 2476          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 247401        |
| policy_loss             | 0.865987      |
| qf1_loss                | 0.010502281   |
| qf2_loss                | 0.010138907   |
| time_elapsed            | 1186          |
| total timesteps         | 247500        |
| value_loss              | 0.00045393308 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013686888  |
| ent_coef_loss           | -0.2561618    |
| entropy                 | 2.584995      |
| ep_rewmean              | -2.29         |
| episodes                | 2480          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 247801        |
| policy_loss             | 0.71090615    |
| qf1_loss                | 0.00033742937 |
| qf2_loss                | 0.0003431142  |
| time_elapsed            | 1188          |
| total timesteps         | 247900        |
| value_loss              | 0.00030564357 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014230441  |
| ent_coef_loss           | 1.0934229     |
| entropy                 | 2.9389267     |
| ep_rewmean              | -2.23         |
| episodes                | 2484          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 248201        |
| policy_loss             | 0.7953681     |
| qf1_loss                | 0.00028506742 |
| qf2_loss                | 0.0004311917  |
| time_elapsed            | 1190          |
| total timesteps         | 248300        |
| value_loss              | 0.0002514148  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015236912  |
| ent_coef_loss           | 6.7373796     |
| entropy                 | 2.8889914     |
| ep_rewmean              | -2.18         |
| episodes                | 2488          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 248601        |
| policy_loss             | 0.7288737     |
| qf1_loss                | 0.00084547536 |
| qf2_loss                | 0.0007866381  |
| time_elapsed            | 1192          |
| total timesteps         | 248700        |
| value_loss              | 0.0008055767  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015559134  |
| ent_coef_loss           | -8.979817     |
| entropy                 | 2.8450549     |
| ep_rewmean              | -2.17         |
| episodes                | 2492          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 249001        |
| policy_loss             | 0.698943      |
| qf1_loss                | 0.00047739345 |
| qf2_loss                | 0.00045047846 |
| time_elapsed            | 1194          |
| total timesteps         | 249100        |
| value_loss              | 0.0002155873  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015644868  |
| ent_coef_loss           | -0.47984457   |
| entropy                 | 3.1264386     |
| ep_rewmean              | -2.16         |
| episodes                | 2496          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 249401        |
| policy_loss             | 0.7550408     |
| qf1_loss                | 0.00044490653 |
| qf2_loss                | 0.0003002456  |
| time_elapsed            | 1196          |
| total timesteps         | 249500        |
| value_loss              | 0.00021478659 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015574313  |
| ent_coef_loss           | -8.496452     |
| entropy                 | 3.2859852     |
| ep_rewmean              | -2.17         |
| episodes                | 2500          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 249801        |
| policy_loss             | 0.69418335    |
| qf1_loss                | 0.0002974139  |
| qf2_loss                | 0.0002917497  |
| time_elapsed            | 1198          |
| total timesteps         | 249900        |
| value_loss              | 0.00030210963 |
-------------------------------------------
Eval num_timesteps=250000, episode_reward=-1.80 +/- 0.56
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015222816  |
| ent_coef_loss           | -2.4837296    |
| entropy                 | 2.9192567     |
| ep_rewmean              | -2.2          |
| episodes                | 2504          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 250201        |
| policy_loss             | 0.74147916    |
| qf1_loss                | 0.00020863269 |
| qf2_loss                | 0.00026022858 |
| time_elapsed            | 1200          |
| total timesteps         | 250300        |
| value_loss              | 0.00023506816 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014570623  |
| ent_coef_loss           | -5.908163     |
| entropy                 | 3.094135      |
| ep_rewmean              | -2.21         |
| episodes                | 2508          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 250601        |
| policy_loss             | 0.78244746    |
| qf1_loss                | 0.00031857696 |
| qf2_loss                | 0.00019846279 |
| time_elapsed            | 1202          |
| total timesteps         | 250700        |
| value_loss              | 0.00016623075 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013562288 |
| ent_coef_loss           | -3.7950165   |
| entropy                 | 3.081726     |
| ep_rewmean              | -2.26        |
| episodes                | 2512         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.3         |
| n_updates               | 251001       |
| policy_loss             | 0.6803285    |
| qf1_loss                | 0.002054484  |
| qf2_loss                | 0.0016404105 |
| time_elapsed            | 1204         |
| total timesteps         | 251100       |
| value_loss              | 0.0002104457 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012369667  |
| ent_coef_loss           | -6.7719812    |
| entropy                 | 2.6269379     |
| ep_rewmean              | -2.23         |
| episodes                | 2516          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 251401        |
| policy_loss             | 0.676075      |
| qf1_loss                | 0.0062031383  |
| qf2_loss                | 0.006149553   |
| time_elapsed            | 1206          |
| total timesteps         | 251500        |
| value_loss              | 0.00016074671 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011736196  |
| ent_coef_loss           | 2.1826925     |
| entropy                 | 1.9801536     |
| ep_rewmean              | -2.23         |
| episodes                | 2520          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 251801        |
| policy_loss             | 0.6744243     |
| qf1_loss                | 0.008013035   |
| qf2_loss                | 0.00810601    |
| time_elapsed            | 1208          |
| total timesteps         | 251900        |
| value_loss              | 0.00025473215 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011582437  |
| ent_coef_loss           | 6.2770495     |
| entropy                 | 1.901417      |
| ep_rewmean              | -2.21         |
| episodes                | 2524          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 252201        |
| policy_loss             | 0.6605306     |
| qf1_loss                | 0.0002805159  |
| qf2_loss                | 0.00023361799 |
| time_elapsed            | 1210          |
| total timesteps         | 252300        |
| value_loss              | 0.00019543212 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011536572  |
| ent_coef_loss           | 0.500067      |
| entropy                 | 2.3731546     |
| ep_rewmean              | -2.22         |
| episodes                | 2528          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 252601        |
| policy_loss             | 0.6987009     |
| qf1_loss                | 0.0002512138  |
| qf2_loss                | 0.00021619973 |
| time_elapsed            | 1211          |
| total timesteps         | 252700        |
| value_loss              | 0.00031123508 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011701211  |
| ent_coef_loss           | -4.1192627    |
| entropy                 | 2.0399685     |
| ep_rewmean              | -2.26         |
| episodes                | 2532          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 253001        |
| policy_loss             | 0.6471417     |
| qf1_loss                | 0.00025937482 |
| qf2_loss                | 0.00019789886 |
| time_elapsed            | 1213          |
| total timesteps         | 253100        |
| value_loss              | 0.00019614302 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012318786  |
| ent_coef_loss           | 0.06487465    |
| entropy                 | 2.0232563     |
| ep_rewmean              | -2.23         |
| episodes                | 2536          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 253401        |
| policy_loss             | 0.6156789     |
| qf1_loss                | 0.00057322136 |
| qf2_loss                | 0.00048103664 |
| time_elapsed            | 1215          |
| total timesteps         | 253500        |
| value_loss              | 0.00029991337 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012533667  |
| ent_coef_loss           | 2.7648234     |
| entropy                 | 2.1897507     |
| ep_rewmean              | -2.24         |
| episodes                | 2540          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 253801        |
| policy_loss             | 0.6532022     |
| qf1_loss                | 0.0019253674  |
| qf2_loss                | 0.0021280516  |
| time_elapsed            | 1217          |
| total timesteps         | 253900        |
| value_loss              | 0.00028897813 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012902352  |
| ent_coef_loss           | -4.790845     |
| entropy                 | 1.9502103     |
| ep_rewmean              | -2.25         |
| episodes                | 2544          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 254201        |
| policy_loss             | 0.64972335    |
| qf1_loss                | 0.007253248   |
| qf2_loss                | 0.0073568383  |
| time_elapsed            | 1219          |
| total timesteps         | 254300        |
| value_loss              | 0.00024717406 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013159809  |
| ent_coef_loss           | 5.112664      |
| entropy                 | 2.3983574     |
| ep_rewmean              | -2.26         |
| episodes                | 2548          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 254601        |
| policy_loss             | 0.714794      |
| qf1_loss                | 0.00031152327 |
| qf2_loss                | 0.0002539597  |
| time_elapsed            | 1221          |
| total timesteps         | 254700        |
| value_loss              | 0.00045632015 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013038894  |
| ent_coef_loss           | 1.1499825     |
| entropy                 | 1.6347525     |
| ep_rewmean              | -2.38         |
| episodes                | 2552          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 255001        |
| policy_loss             | 0.6739458     |
| qf1_loss                | 0.004532691   |
| qf2_loss                | 0.004389539   |
| time_elapsed            | 1223          |
| total timesteps         | 255100        |
| value_loss              | 0.00027656523 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012885316  |
| ent_coef_loss           | -2.3184254    |
| entropy                 | 2.1164656     |
| ep_rewmean              | -2.37         |
| episodes                | 2556          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 255401        |
| policy_loss             | 0.6891002     |
| qf1_loss                | 0.0006222118  |
| qf2_loss                | 0.00062867126 |
| time_elapsed            | 1225          |
| total timesteps         | 255500        |
| value_loss              | 0.00017518974 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012630097  |
| ent_coef_loss           | 1.2228696     |
| entropy                 | 2.3945863     |
| ep_rewmean              | -2.42         |
| episodes                | 2560          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 255801        |
| policy_loss             | 0.6982951     |
| qf1_loss                | 0.00025151073 |
| qf2_loss                | 0.00016607193 |
| time_elapsed            | 1227          |
| total timesteps         | 255900        |
| value_loss              | 0.00013561832 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012270987  |
| ent_coef_loss           | -4.546761     |
| entropy                 | 1.8191782     |
| ep_rewmean              | -2.45         |
| episodes                | 2564          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 256201        |
| policy_loss             | 0.6531197     |
| qf1_loss                | 0.0031125727  |
| qf2_loss                | 0.0032625003  |
| time_elapsed            | 1229          |
| total timesteps         | 256300        |
| value_loss              | 0.00020441884 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012470809  |
| ent_coef_loss           | 0.357417      |
| entropy                 | 1.7065212     |
| ep_rewmean              | -2.47         |
| episodes                | 2568          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 256601        |
| policy_loss             | 0.66615117    |
| qf1_loss                | 0.0027204407  |
| qf2_loss                | 0.002643511   |
| time_elapsed            | 1231          |
| total timesteps         | 256700        |
| value_loss              | 0.00012793642 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012331839  |
| ent_coef_loss           | -2.323968     |
| entropy                 | 1.8808358     |
| ep_rewmean              | -2.49         |
| episodes                | 2572          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 257001        |
| policy_loss             | 0.7171382     |
| qf1_loss                | 0.00027774874 |
| qf2_loss                | 0.00021039847 |
| time_elapsed            | 1233          |
| total timesteps         | 257100        |
| value_loss              | 0.0001746548  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012009919 |
| ent_coef_loss           | 2.636612     |
| entropy                 | 1.7586275    |
| ep_rewmean              | -2.6         |
| episodes                | 2576         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.6         |
| n_updates               | 257401       |
| policy_loss             | 0.6766454    |
| qf1_loss                | 0.0010644697 |
| qf2_loss                | 0.0010073332 |
| time_elapsed            | 1235         |
| total timesteps         | 257500       |
| value_loss              | 0.0002899408 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012315093  |
| ent_coef_loss           | -1.5008402    |
| entropy                 | 1.9852519     |
| ep_rewmean              | -2.67         |
| episodes                | 2580          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.7          |
| n_updates               | 257801        |
| policy_loss             | 0.7165073     |
| qf1_loss                | 0.000353515   |
| qf2_loss                | 0.00039490557 |
| time_elapsed            | 1237          |
| total timesteps         | 257900        |
| value_loss              | 0.0001773044  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012646248  |
| ent_coef_loss           | -3.6072717    |
| entropy                 | 2.0350113     |
| ep_rewmean              | -2.73         |
| episodes                | 2584          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.7          |
| n_updates               | 258201        |
| policy_loss             | 0.6429615     |
| qf1_loss                | 0.00033079117 |
| qf2_loss                | 0.00037433353 |
| time_elapsed            | 1239          |
| total timesteps         | 258300        |
| value_loss              | 0.0004320952  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012887147  |
| ent_coef_loss           | 0.06279278    |
| entropy                 | 1.9242823     |
| ep_rewmean              | -2.81         |
| episodes                | 2588          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.8          |
| n_updates               | 258601        |
| policy_loss             | 0.71880585    |
| qf1_loss                | 0.00030002854 |
| qf2_loss                | 0.00030762143 |
| time_elapsed            | 1241          |
| total timesteps         | 258700        |
| value_loss              | 0.00023350664 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001288077   |
| ent_coef_loss           | -3.5322595    |
| entropy                 | 2.3034        |
| ep_rewmean              | -2.82         |
| episodes                | 2592          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.8          |
| n_updates               | 259001        |
| policy_loss             | 0.6966488     |
| qf1_loss                | 0.00027642897 |
| qf2_loss                | 0.0002779924  |
| time_elapsed            | 1242          |
| total timesteps         | 259100        |
| value_loss              | 0.00013506434 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013107816  |
| ent_coef_loss           | 5.7325478     |
| entropy                 | 1.5727715     |
| ep_rewmean              | -2.84         |
| episodes                | 2596          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.8          |
| n_updates               | 259401        |
| policy_loss             | 0.6443838     |
| qf1_loss                | 0.00021966067 |
| qf2_loss                | 0.0002682594  |
| time_elapsed            | 1244          |
| total timesteps         | 259500        |
| value_loss              | 0.00025786497 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013026695  |
| ent_coef_loss           | -1.6855341    |
| entropy                 | 2.371226      |
| ep_rewmean              | -2.93         |
| episodes                | 2600          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.9          |
| n_updates               | 259801        |
| policy_loss             | 0.74359167    |
| qf1_loss                | 0.00652645    |
| qf2_loss                | 0.0063962266  |
| time_elapsed            | 1246          |
| total timesteps         | 259900        |
| value_loss              | 0.00018609533 |
-------------------------------------------
Eval num_timesteps=260000, episode_reward=-2.21 +/- 0.57
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013177912  |
| ent_coef_loss           | 1.0782894     |
| entropy                 | 1.6413163     |
| ep_rewmean              | -2.91         |
| episodes                | 2604          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.9          |
| n_updates               | 260201        |
| policy_loss             | 0.63578284    |
| qf1_loss                | 0.00038335164 |
| qf2_loss                | 0.00032908758 |
| time_elapsed            | 1248          |
| total timesteps         | 260300        |
| value_loss              | 0.00017676238 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012877644  |
| ent_coef_loss           | 3.2122526     |
| entropy                 | 2.196195      |
| ep_rewmean              | -2.87         |
| episodes                | 2608          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.9          |
| n_updates               | 260601        |
| policy_loss             | 0.7176856     |
| qf1_loss                | 0.00035971458 |
| qf2_loss                | 0.00033148858 |
| time_elapsed            | 1250          |
| total timesteps         | 260700        |
| value_loss              | 0.00031613326 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012601907  |
| ent_coef_loss           | -1.7847234    |
| entropy                 | 2.4214046     |
| ep_rewmean              | -2.88         |
| episodes                | 2612          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.9          |
| n_updates               | 261001        |
| policy_loss             | 0.74986434    |
| qf1_loss                | 0.00029161194 |
| qf2_loss                | 0.00029931686 |
| time_elapsed            | 1252          |
| total timesteps         | 261100        |
| value_loss              | 0.00040491216 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012921777  |
| ent_coef_loss           | 5.3652678     |
| entropy                 | 2.149623      |
| ep_rewmean              | -2.88         |
| episodes                | 2616          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.9          |
| n_updates               | 261401        |
| policy_loss             | 0.6539075     |
| qf1_loss                | 0.0003003856  |
| qf2_loss                | 0.00022898553 |
| time_elapsed            | 1254          |
| total timesteps         | 261500        |
| value_loss              | 0.00015252236 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013637325  |
| ent_coef_loss           | -0.9581475    |
| entropy                 | 2.2918403     |
| ep_rewmean              | -2.94         |
| episodes                | 2620          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.9          |
| n_updates               | 261801        |
| policy_loss             | 0.638878      |
| qf1_loss                | 0.003219092   |
| qf2_loss                | 0.0028906004  |
| time_elapsed            | 1256          |
| total timesteps         | 261900        |
| value_loss              | 0.00018596814 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00140333    |
| ent_coef_loss           | 0.44877553    |
| entropy                 | 1.9027494     |
| ep_rewmean              | -2.91         |
| episodes                | 2624          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.9          |
| n_updates               | 262201        |
| policy_loss             | 0.6157314     |
| qf1_loss                | 0.0009671041  |
| qf2_loss                | 0.0010040607  |
| time_elapsed            | 1258          |
| total timesteps         | 262300        |
| value_loss              | 0.00025860168 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013835974  |
| ent_coef_loss           | 1.4485239     |
| entropy                 | 2.3484964     |
| ep_rewmean              | -2.95         |
| episodes                | 2628          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.9          |
| n_updates               | 262601        |
| policy_loss             | 0.6494449     |
| qf1_loss                | 0.00028149813 |
| qf2_loss                | 0.0003235654  |
| time_elapsed            | 1260          |
| total timesteps         | 262700        |
| value_loss              | 0.00041037292 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013426492  |
| ent_coef_loss           | -2.8004553    |
| entropy                 | 2.3171718     |
| ep_rewmean              | -2.9          |
| episodes                | 2632          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.9          |
| n_updates               | 263001        |
| policy_loss             | 0.6268841     |
| qf1_loss                | 0.00036825344 |
| qf2_loss                | 0.00019571802 |
| time_elapsed            | 1262          |
| total timesteps         | 263100        |
| value_loss              | 0.00012741596 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013035935  |
| ent_coef_loss           | -7.8388367    |
| entropy                 | 2.5438242     |
| ep_rewmean              | -2.89         |
| episodes                | 2636          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.9          |
| n_updates               | 263401        |
| policy_loss             | 0.6758303     |
| qf1_loss                | 0.0003502261  |
| qf2_loss                | 0.00025378738 |
| time_elapsed            | 1264          |
| total timesteps         | 263500        |
| value_loss              | 0.0002452548  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013799827  |
| ent_coef_loss           | -2.038767     |
| entropy                 | 2.71305       |
| ep_rewmean              | -2.88         |
| episodes                | 2640          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.9          |
| n_updates               | 263801        |
| policy_loss             | 0.6642288     |
| qf1_loss                | 0.0048402054  |
| qf2_loss                | 0.0045048776  |
| time_elapsed            | 1266          |
| total timesteps         | 263900        |
| value_loss              | 0.00018558971 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014625189  |
| ent_coef_loss           | -2.4272783    |
| entropy                 | 2.6398802     |
| ep_rewmean              | -2.84         |
| episodes                | 2644          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.8          |
| n_updates               | 264201        |
| policy_loss             | 0.61280346    |
| qf1_loss                | 0.00030191563 |
| qf2_loss                | 0.0003223539  |
| time_elapsed            | 1268          |
| total timesteps         | 264300        |
| value_loss              | 0.00024866353 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015372696 |
| ent_coef_loss           | 7.764702     |
| entropy                 | 2.6062953    |
| ep_rewmean              | -2.81        |
| episodes                | 2648         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.8         |
| n_updates               | 264601       |
| policy_loss             | 0.731763     |
| qf1_loss                | 0.0002682511 |
| qf2_loss                | 0.0002839488 |
| time_elapsed            | 1270         |
| total timesteps         | 264700       |
| value_loss              | 0.0005469091 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015133629  |
| ent_coef_loss           | -0.35292006   |
| entropy                 | 2.6170483     |
| ep_rewmean              | -2.69         |
| episodes                | 2652          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.7          |
| n_updates               | 265001        |
| policy_loss             | 0.70728874    |
| qf1_loss                | 0.00034823985 |
| qf2_loss                | 0.00025172182 |
| time_elapsed            | 1271          |
| total timesteps         | 265100        |
| value_loss              | 0.00029169524 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015133469  |
| ent_coef_loss           | -0.34583616   |
| entropy                 | 2.7246375     |
| ep_rewmean              | -2.59         |
| episodes                | 2656          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.6          |
| n_updates               | 265401        |
| policy_loss             | 0.7422199     |
| qf1_loss                | 0.00044583    |
| qf2_loss                | 0.00045923505 |
| time_elapsed            | 1273          |
| total timesteps         | 265500        |
| value_loss              | 0.00032402467 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015114819  |
| ent_coef_loss           | -5.8945017    |
| entropy                 | 2.7732315     |
| ep_rewmean              | -2.52         |
| episodes                | 2660          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.5          |
| n_updates               | 265801        |
| policy_loss             | 0.710638      |
| qf1_loss                | 0.0005106537  |
| qf2_loss                | 0.00035041393 |
| time_elapsed            | 1275          |
| total timesteps         | 265900        |
| value_loss              | 0.00039340748 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014971737  |
| ent_coef_loss           | 1.6876788     |
| entropy                 | 2.4687767     |
| ep_rewmean              | -2.44         |
| episodes                | 2664          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 266201        |
| policy_loss             | 0.7472671     |
| qf1_loss                | 0.00032560015 |
| qf2_loss                | 0.00033880238 |
| time_elapsed            | 1277          |
| total timesteps         | 266300        |
| value_loss              | 0.00017375691 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014869294  |
| ent_coef_loss           | -1.4471956    |
| entropy                 | 2.2974992     |
| ep_rewmean              | -2.37         |
| episodes                | 2668          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 266601        |
| policy_loss             | 0.7706207     |
| qf1_loss                | 0.00038260262 |
| qf2_loss                | 0.00038800496 |
| time_elapsed            | 1279          |
| total timesteps         | 266700        |
| value_loss              | 0.0003697328  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015590675  |
| ent_coef_loss           | 5.815828      |
| entropy                 | 3.1787038     |
| ep_rewmean              | -2.29         |
| episodes                | 2672          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 267001        |
| policy_loss             | 0.79821515    |
| qf1_loss                | 0.010203296   |
| qf2_loss                | 0.0103367595  |
| time_elapsed            | 1281          |
| total timesteps         | 267100        |
| value_loss              | 0.00025163952 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016398621  |
| ent_coef_loss           | 12.090208     |
| entropy                 | 2.8207724     |
| ep_rewmean              | -2.21         |
| episodes                | 2676          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 267401        |
| policy_loss             | 0.7400428     |
| qf1_loss                | 0.00039712555 |
| qf2_loss                | 0.00046268763 |
| time_elapsed            | 1283          |
| total timesteps         | 267500        |
| value_loss              | 0.00033489487 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001684792  |
| ent_coef_loss           | -3.2513528   |
| entropy                 | 2.8810546    |
| ep_rewmean              | -2.19        |
| episodes                | 2680         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.2         |
| n_updates               | 267801       |
| policy_loss             | 0.7692385    |
| qf1_loss                | 0.0008840698 |
| qf2_loss                | 0.0008059769 |
| time_elapsed            | 1285         |
| total timesteps         | 267900       |
| value_loss              | 0.0002788203 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017291331  |
| ent_coef_loss           | 2.987606      |
| entropy                 | 3.2517397     |
| ep_rewmean              | -2.16         |
| episodes                | 2684          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 268201        |
| policy_loss             | 0.79756176    |
| qf1_loss                | 0.0005274361  |
| qf2_loss                | 0.0004279348  |
| time_elapsed            | 1287          |
| total timesteps         | 268300        |
| value_loss              | 0.00033761282 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017939846 |
| ent_coef_loss           | 5.9694896    |
| entropy                 | 3.17629      |
| ep_rewmean              | -2.08        |
| episodes                | 2688         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 268601       |
| policy_loss             | 0.82937336   |
| qf1_loss                | 0.0032233903 |
| qf2_loss                | 0.004282518  |
| time_elapsed            | 1289         |
| total timesteps         | 268700       |
| value_loss              | 0.0005235092 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019448426  |
| ent_coef_loss           | -1.1265223    |
| entropy                 | 3.343258      |
| ep_rewmean              | -2.02         |
| episodes                | 2692          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 269001        |
| policy_loss             | 0.801015      |
| qf1_loss                | 0.000454735   |
| qf2_loss                | 0.00033666147 |
| time_elapsed            | 1291          |
| total timesteps         | 269100        |
| value_loss              | 0.00035199488 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019097904  |
| ent_coef_loss           | -19.142117    |
| entropy                 | 3.6202908     |
| ep_rewmean              | -1.98         |
| episodes                | 2696          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 269401        |
| policy_loss             | 0.82761157    |
| qf1_loss                | 0.00017358936 |
| qf2_loss                | 0.00025868247 |
| time_elapsed            | 1293          |
| total timesteps         | 269500        |
| value_loss              | 0.0003335331  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018420768  |
| ent_coef_loss           | -3.2502575    |
| entropy                 | 3.563044      |
| ep_rewmean              | -1.87         |
| episodes                | 2700          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 269801        |
| policy_loss             | 0.8867624     |
| qf1_loss                | 0.010266098   |
| qf2_loss                | 0.010006967   |
| time_elapsed            | 1295          |
| total timesteps         | 269900        |
| value_loss              | 0.00047621207 |
-------------------------------------------
Eval num_timesteps=270000, episode_reward=-1.25 +/- 0.78
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017801417  |
| ent_coef_loss           | -4.75465      |
| entropy                 | 3.7461696     |
| ep_rewmean              | -1.85         |
| episodes                | 2704          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 270201        |
| policy_loss             | 0.8595128     |
| qf1_loss                | 0.00027857843 |
| qf2_loss                | 0.00027302103 |
| time_elapsed            | 1297          |
| total timesteps         | 270300        |
| value_loss              | 0.00031762442 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017967429  |
| ent_coef_loss           | -6.392402     |
| entropy                 | 3.2743688     |
| ep_rewmean              | -1.87         |
| episodes                | 2708          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 270601        |
| policy_loss             | 0.84197426    |
| qf1_loss                | 0.0068188887  |
| qf2_loss                | 0.0066110473  |
| time_elapsed            | 1299          |
| total timesteps         | 270700        |
| value_loss              | 0.00040589538 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017742512  |
| ent_coef_loss           | 1.8549473     |
| entropy                 | 3.4661477     |
| ep_rewmean              | -1.8          |
| episodes                | 2712          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 271001        |
| policy_loss             | 0.8674909     |
| qf1_loss                | 0.0019962278  |
| qf2_loss                | 0.002335176   |
| time_elapsed            | 1301          |
| total timesteps         | 271100        |
| value_loss              | 0.00032071507 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016796022 |
| ent_coef_loss           | -0.35151386  |
| entropy                 | 3.2702625    |
| ep_rewmean              | -1.76        |
| episodes                | 2716         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.8         |
| n_updates               | 271401       |
| policy_loss             | 0.84505546   |
| qf1_loss                | 0.006158092  |
| qf2_loss                | 0.0060037826 |
| time_elapsed            | 1302         |
| total timesteps         | 271500       |
| value_loss              | 0.0004952121 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016015333 |
| ent_coef_loss           | 1.004885     |
| entropy                 | 2.8190453    |
| ep_rewmean              | -1.75        |
| episodes                | 2720         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.8         |
| n_updates               | 271801       |
| policy_loss             | 0.83710283   |
| qf1_loss                | 0.007609348  |
| qf2_loss                | 0.007461652  |
| time_elapsed            | 1304         |
| total timesteps         | 271900       |
| value_loss              | 0.0002931459 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015123104  |
| ent_coef_loss           | -7.507448     |
| entropy                 | 3.1632385     |
| ep_rewmean              | -1.77         |
| episodes                | 2724          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 272201        |
| policy_loss             | 0.87622166    |
| qf1_loss                | 0.0003458073  |
| qf2_loss                | 0.00032171814 |
| time_elapsed            | 1306          |
| total timesteps         | 272300        |
| value_loss              | 0.00020586245 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001414027   |
| ent_coef_loss           | 0.5512786     |
| entropy                 | 2.7392924     |
| ep_rewmean              | -1.71         |
| episodes                | 2728          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 272601        |
| policy_loss             | 0.9027368     |
| qf1_loss                | 0.00024542905 |
| qf2_loss                | 0.00032824493 |
| time_elapsed            | 1308          |
| total timesteps         | 272700        |
| value_loss              | 0.00022716037 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013660514  |
| ent_coef_loss           | -9.445307     |
| entropy                 | 2.9415998     |
| ep_rewmean              | -1.73         |
| episodes                | 2732          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 273001        |
| policy_loss             | 0.85682786    |
| qf1_loss                | 0.0016217206  |
| qf2_loss                | 0.0016665963  |
| time_elapsed            | 1310          |
| total timesteps         | 273100        |
| value_loss              | 0.00048663825 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013262909 |
| ent_coef_loss           | -3.3083487   |
| entropy                 | 2.675506     |
| ep_rewmean              | -1.72        |
| episodes                | 2736         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.7         |
| n_updates               | 273401       |
| policy_loss             | 0.8744673    |
| qf1_loss                | 0.0004191269 |
| qf2_loss                | 0.0003336124 |
| time_elapsed            | 1312         |
| total timesteps         | 273500       |
| value_loss              | 0.0002585795 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013164773 |
| ent_coef_loss           | -1.0510675   |
| entropy                 | 3.929202     |
| ep_rewmean              | -1.71        |
| episodes                | 2740         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.7         |
| n_updates               | 273801       |
| policy_loss             | 0.9034258    |
| qf1_loss                | 0.009735141  |
| qf2_loss                | 0.009746366  |
| time_elapsed            | 1314         |
| total timesteps         | 273900       |
| value_loss              | 0.000431052  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013277867 |
| ent_coef_loss           | 7.6163616    |
| entropy                 | 3.020526     |
| ep_rewmean              | -1.66        |
| episodes                | 2744         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.7         |
| n_updates               | 274201       |
| policy_loss             | 0.9014809    |
| qf1_loss                | 0.0017159253 |
| qf2_loss                | 0.0013818571 |
| time_elapsed            | 1316         |
| total timesteps         | 274300       |
| value_loss              | 0.0006712164 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014260493  |
| ent_coef_loss           | -2.4670758    |
| entropy                 | 3.2158422     |
| ep_rewmean              | -1.67         |
| episodes                | 2748          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 274601        |
| policy_loss             | 0.91251636    |
| qf1_loss                | 0.013710255   |
| qf2_loss                | 0.013731529   |
| time_elapsed            | 1318          |
| total timesteps         | 274700        |
| value_loss              | 0.00030402385 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014431543  |
| ent_coef_loss           | -0.8529377    |
| entropy                 | 3.3361857     |
| ep_rewmean              | -1.69         |
| episodes                | 2752          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 275001        |
| policy_loss             | 0.8992864     |
| qf1_loss                | 0.00030661692 |
| qf2_loss                | 0.0003710197  |
| time_elapsed            | 1320          |
| total timesteps         | 275100        |
| value_loss              | 0.00020257774 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014127599  |
| ent_coef_loss           | 4.536752      |
| entropy                 | 2.916192      |
| ep_rewmean              | -1.75         |
| episodes                | 2756          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 275401        |
| policy_loss             | 0.8592521     |
| qf1_loss                | 0.019107042   |
| qf2_loss                | 0.019608494   |
| time_elapsed            | 1322          |
| total timesteps         | 275500        |
| value_loss              | 0.00022124429 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013540912  |
| ent_coef_loss           | -4.415657     |
| entropy                 | 3.363912      |
| ep_rewmean              | -1.77         |
| episodes                | 2760          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 275801        |
| policy_loss             | 0.90678716    |
| qf1_loss                | 0.00019867018 |
| qf2_loss                | 0.00018002302 |
| time_elapsed            | 1324          |
| total timesteps         | 275900        |
| value_loss              | 0.00021404473 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013201383  |
| ent_coef_loss           | -8.0153675    |
| entropy                 | 3.3572185     |
| ep_rewmean              | -1.8          |
| episodes                | 2764          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 276201        |
| policy_loss             | 0.8829416     |
| qf1_loss                | 0.00066085276 |
| qf2_loss                | 0.0005953006  |
| time_elapsed            | 1326          |
| total timesteps         | 276300        |
| value_loss              | 0.0002744289  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012914422  |
| ent_coef_loss           | 0.55199194    |
| entropy                 | 3.486855      |
| ep_rewmean              | -1.85         |
| episodes                | 2768          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 276601        |
| policy_loss             | 0.8787191     |
| qf1_loss                | 0.0004076244  |
| qf2_loss                | 0.00045653837 |
| time_elapsed            | 1327          |
| total timesteps         | 276700        |
| value_loss              | 0.00021187757 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013075254  |
| ent_coef_loss           | 0.938354      |
| entropy                 | 2.976612      |
| ep_rewmean              | -1.89         |
| episodes                | 2772          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 277001        |
| policy_loss             | 0.81489664    |
| qf1_loss                | 0.000377431   |
| qf2_loss                | 0.0003295451  |
| time_elapsed            | 1329          |
| total timesteps         | 277100        |
| value_loss              | 0.00023406294 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013012633  |
| ent_coef_loss           | -4.7810493    |
| entropy                 | 2.8925397     |
| ep_rewmean              | -1.93         |
| episodes                | 2776          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 277401        |
| policy_loss             | 0.83541656    |
| qf1_loss                | 0.00020018985 |
| qf2_loss                | 0.00025978158 |
| time_elapsed            | 1331          |
| total timesteps         | 277500        |
| value_loss              | 0.00025247113 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012820229  |
| ent_coef_loss           | -5.495823     |
| entropy                 | 3.5950375     |
| ep_rewmean              | -1.87         |
| episodes                | 2780          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 277801        |
| policy_loss             | 0.81710196    |
| qf1_loss                | 0.0005242907  |
| qf2_loss                | 0.0004880631  |
| time_elapsed            | 1333          |
| total timesteps         | 277900        |
| value_loss              | 0.00028439518 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013336798  |
| ent_coef_loss           | 4.405943      |
| entropy                 | 3.447709      |
| ep_rewmean              | -1.91         |
| episodes                | 2784          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 278201        |
| policy_loss             | 0.83633393    |
| qf1_loss                | 0.00033380912 |
| qf2_loss                | 0.00041246237 |
| time_elapsed            | 1335          |
| total timesteps         | 278300        |
| value_loss              | 0.00016756493 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013345074  |
| ent_coef_loss           | 5.147672      |
| entropy                 | 3.1079679     |
| ep_rewmean              | -1.91         |
| episodes                | 2788          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 278601        |
| policy_loss             | 0.8066317     |
| qf1_loss                | 0.0006656682  |
| qf2_loss                | 0.0006879479  |
| time_elapsed            | 1337          |
| total timesteps         | 278700        |
| value_loss              | 0.00027983345 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013147396 |
| ent_coef_loss           | 1.5307791    |
| entropy                 | 2.862574     |
| ep_rewmean              | -1.96        |
| episodes                | 2792         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2           |
| n_updates               | 279001       |
| policy_loss             | 0.8330926    |
| qf1_loss                | 0.0033257555 |
| qf2_loss                | 0.0032063376 |
| time_elapsed            | 1339         |
| total timesteps         | 279100       |
| value_loss              | 0.0007272478 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012508377  |
| ent_coef_loss           | -5.93048      |
| entropy                 | 3.0376244     |
| ep_rewmean              | -2.02         |
| episodes                | 2796          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 279401        |
| policy_loss             | 0.85984397    |
| qf1_loss                | 0.00030158015 |
| qf2_loss                | 0.00026294834 |
| time_elapsed            | 1341          |
| total timesteps         | 279500        |
| value_loss              | 0.00016432368 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012045357  |
| ent_coef_loss           | -0.8626075    |
| entropy                 | 3.33789       |
| ep_rewmean              | -2.02         |
| episodes                | 2800          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 279801        |
| policy_loss             | 0.82637894    |
| qf1_loss                | 0.0052197254  |
| qf2_loss                | 0.005021095   |
| time_elapsed            | 1343          |
| total timesteps         | 279900        |
| value_loss              | 0.00010460756 |
-------------------------------------------
Eval num_timesteps=280000, episode_reward=-2.29 +/- 1.71
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012242321 |
| ent_coef_loss           | -7.171951    |
| entropy                 | 3.02524      |
| ep_rewmean              | -2.02        |
| episodes                | 2804         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2           |
| n_updates               | 280201       |
| policy_loss             | 0.82387376   |
| qf1_loss                | 0.0018979307 |
| qf2_loss                | 0.0018573925 |
| time_elapsed            | 1345         |
| total timesteps         | 280300       |
| value_loss              | 0.0003252796 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011583586  |
| ent_coef_loss           | 6.756677      |
| entropy                 | 2.1107233     |
| ep_rewmean              | -2.02         |
| episodes                | 2808          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 280601        |
| policy_loss             | 0.85052794    |
| qf1_loss                | 0.008358202   |
| qf2_loss                | 0.0083123855  |
| time_elapsed            | 1347          |
| total timesteps         | 280700        |
| value_loss              | 0.00019882419 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012035499 |
| ent_coef_loss           | -0.748626    |
| entropy                 | 2.5793839    |
| ep_rewmean              | -2.06        |
| episodes                | 2812         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 281001       |
| policy_loss             | 0.83846915   |
| qf1_loss                | 0.0038406858 |
| qf2_loss                | 0.0037831697 |
| time_elapsed            | 1349         |
| total timesteps         | 281100       |
| value_loss              | 0.0002252816 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013077898  |
| ent_coef_loss           | -4.7948036    |
| entropy                 | 2.8061047     |
| ep_rewmean              | -2.1          |
| episodes                | 2816          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 281401        |
| policy_loss             | 0.8351283     |
| qf1_loss                | 0.00018739208 |
| qf2_loss                | 0.00020153528 |
| time_elapsed            | 1351          |
| total timesteps         | 281500        |
| value_loss              | 0.00019253869 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013703854 |
| ent_coef_loss           | -4.841312    |
| entropy                 | 3.2047184    |
| ep_rewmean              | -2.09        |
| episodes                | 2820         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 281801       |
| policy_loss             | 0.82866913   |
| qf1_loss                | 0.008106688  |
| qf2_loss                | 0.0079890285 |
| time_elapsed            | 1353         |
| total timesteps         | 281900       |
| value_loss              | 0.0004112947 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013443156  |
| ent_coef_loss           | -1.9657159    |
| entropy                 | 3.0378714     |
| ep_rewmean              | -2.09         |
| episodes                | 2824          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 282201        |
| policy_loss             | 0.7965222     |
| qf1_loss                | 0.00033602328 |
| qf2_loss                | 0.00029920717 |
| time_elapsed            | 1354          |
| total timesteps         | 282300        |
| value_loss              | 0.00022246136 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013476665  |
| ent_coef_loss           | -4.54014      |
| entropy                 | 3.2924955     |
| ep_rewmean              | -2.12         |
| episodes                | 2828          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 282601        |
| policy_loss             | 0.75276697    |
| qf1_loss                | 0.0071318164  |
| qf2_loss                | 0.0069782436  |
| time_elapsed            | 1356          |
| total timesteps         | 282700        |
| value_loss              | 0.00019810151 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013406776  |
| ent_coef_loss           | -1.7063023    |
| entropy                 | 3.0892482     |
| ep_rewmean              | -2.1          |
| episodes                | 2832          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 283001        |
| policy_loss             | 0.7859744     |
| qf1_loss                | 0.0003255073  |
| qf2_loss                | 0.00043516053 |
| time_elapsed            | 1358          |
| total timesteps         | 283100        |
| value_loss              | 0.00014118079 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001240929   |
| ent_coef_loss           | 4.6440716     |
| entropy                 | 2.759298      |
| ep_rewmean              | -2.1          |
| episodes                | 2836          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 283401        |
| policy_loss             | 0.8290005     |
| qf1_loss                | 0.00021621046 |
| qf2_loss                | 0.00021705056 |
| time_elapsed            | 1360          |
| total timesteps         | 283500        |
| value_loss              | 0.0002653633  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012137798  |
| ent_coef_loss           | 2.4580767     |
| entropy                 | 2.0768213     |
| ep_rewmean              | -2.09         |
| episodes                | 2840          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 283801        |
| policy_loss             | 0.76065415    |
| qf1_loss                | 0.00026091834 |
| qf2_loss                | 0.00022396684 |
| time_elapsed            | 1362          |
| total timesteps         | 283900        |
| value_loss              | 0.00014286785 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012229217  |
| ent_coef_loss           | -0.80737066   |
| entropy                 | 2.346387      |
| ep_rewmean              | -2.15         |
| episodes                | 2844          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 284201        |
| policy_loss             | 0.80571824    |
| qf1_loss                | 0.0001413941  |
| qf2_loss                | 0.00014530103 |
| time_elapsed            | 1364          |
| total timesteps         | 284300        |
| value_loss              | 0.00015250113 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012530512  |
| ent_coef_loss           | -2.9300284    |
| entropy                 | 2.8333588     |
| ep_rewmean              | -2.13         |
| episodes                | 2848          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 284601        |
| policy_loss             | 0.82885003    |
| qf1_loss                | 0.004311122   |
| qf2_loss                | 0.004095886   |
| time_elapsed            | 1366          |
| total timesteps         | 284700        |
| value_loss              | 0.00015482528 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001227086   |
| ent_coef_loss           | 1.0347383     |
| entropy                 | 2.1849065     |
| ep_rewmean              | -2.12         |
| episodes                | 2852          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 285001        |
| policy_loss             | 0.78373337    |
| qf1_loss                | 0.0002341273  |
| qf2_loss                | 0.000210552   |
| time_elapsed            | 1368          |
| total timesteps         | 285100        |
| value_loss              | 0.00018762087 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012310718  |
| ent_coef_loss           | 2.092704      |
| entropy                 | 2.1640437     |
| ep_rewmean              | -2.08         |
| episodes                | 2856          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 285401        |
| policy_loss             | 0.80910313    |
| qf1_loss                | 0.010078522   |
| qf2_loss                | 0.010215069   |
| time_elapsed            | 1370          |
| total timesteps         | 285500        |
| value_loss              | 0.00027134496 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012885211  |
| ent_coef_loss           | -0.1257695    |
| entropy                 | 2.0003405     |
| ep_rewmean              | -2.1          |
| episodes                | 2860          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 285801        |
| policy_loss             | 0.79117906    |
| qf1_loss                | 0.005009813   |
| qf2_loss                | 0.0049964287  |
| time_elapsed            | 1372          |
| total timesteps         | 285900        |
| value_loss              | 0.00020534912 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013360361  |
| ent_coef_loss           | 4.798079      |
| entropy                 | 1.512815      |
| ep_rewmean              | -2.08         |
| episodes                | 2864          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 286201        |
| policy_loss             | 0.7765072     |
| qf1_loss                | 0.006763141   |
| qf2_loss                | 0.006889263   |
| time_elapsed            | 1374          |
| total timesteps         | 286300        |
| value_loss              | 0.00034429203 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013916101  |
| ent_coef_loss           | 5.8489323     |
| entropy                 | 2.1603513     |
| ep_rewmean              | -2.09         |
| episodes                | 2868          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 286601        |
| policy_loss             | 0.8255459     |
| qf1_loss                | 0.009405643   |
| qf2_loss                | 0.009570897   |
| time_elapsed            | 1376          |
| total timesteps         | 286700        |
| value_loss              | 0.00018157274 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001398998   |
| ent_coef_loss           | 3.7641807     |
| entropy                 | 2.396053      |
| ep_rewmean              | -2.08         |
| episodes                | 2872          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 287001        |
| policy_loss             | 0.8089376     |
| qf1_loss                | 0.0003284531  |
| qf2_loss                | 0.0002762396  |
| time_elapsed            | 1377          |
| total timesteps         | 287100        |
| value_loss              | 0.00019368395 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014136643  |
| ent_coef_loss           | 2.7037258     |
| entropy                 | 2.697341      |
| ep_rewmean              | -2.1          |
| episodes                | 2876          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 287401        |
| policy_loss             | 0.80927557    |
| qf1_loss                | 0.00016781177 |
| qf2_loss                | 0.00015222901 |
| time_elapsed            | 1379          |
| total timesteps         | 287500        |
| value_loss              | 0.0002985277  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015203208  |
| ent_coef_loss           | 9.671783      |
| entropy                 | 2.3988943     |
| ep_rewmean              | -2.19         |
| episodes                | 2880          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 287801        |
| policy_loss             | 0.793779      |
| qf1_loss                | 0.00037836685 |
| qf2_loss                | 0.00032764548 |
| time_elapsed            | 1381          |
| total timesteps         | 287900        |
| value_loss              | 0.00029244582 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014965042 |
| ent_coef_loss           | -4.7505083   |
| entropy                 | 2.9713407    |
| ep_rewmean              | -2.13        |
| episodes                | 2884         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 288201       |
| policy_loss             | 0.7982473    |
| qf1_loss                | 0.0003550551 |
| qf2_loss                | 0.0003413625 |
| time_elapsed            | 1383         |
| total timesteps         | 288300       |
| value_loss              | 0.0003668368 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013966617  |
| ent_coef_loss           | -1.3518548    |
| entropy                 | 2.2153919     |
| ep_rewmean              | -2.14         |
| episodes                | 2888          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 288601        |
| policy_loss             | 0.8300304     |
| qf1_loss                | 0.00028867286 |
| qf2_loss                | 0.00020555587 |
| time_elapsed            | 1385          |
| total timesteps         | 288700        |
| value_loss              | 0.00028059125 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013927439  |
| ent_coef_loss           | 2.0878272     |
| entropy                 | 2.601524      |
| ep_rewmean              | -2.11         |
| episodes                | 2892          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 289001        |
| policy_loss             | 0.7717887     |
| qf1_loss                | 0.00039175685 |
| qf2_loss                | 0.00033427548 |
| time_elapsed            | 1387          |
| total timesteps         | 289100        |
| value_loss              | 0.00024164584 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014222749  |
| ent_coef_loss           | 0.3661029     |
| entropy                 | 2.3861787     |
| ep_rewmean              | -2.07         |
| episodes                | 2896          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 289401        |
| policy_loss             | 0.7483685     |
| qf1_loss                | 0.0088785095  |
| qf2_loss                | 0.009152319   |
| time_elapsed            | 1389          |
| total timesteps         | 289500        |
| value_loss              | 0.00020227882 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015642832  |
| ent_coef_loss           | 3.822393      |
| entropy                 | 2.6435318     |
| ep_rewmean              | -2.14         |
| episodes                | 2900          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 289801        |
| policy_loss             | 0.84091675    |
| qf1_loss                | 0.0003045645  |
| qf2_loss                | 0.0003351189  |
| time_elapsed            | 1391          |
| total timesteps         | 289900        |
| value_loss              | 0.00023947546 |
-------------------------------------------
Eval num_timesteps=290000, episode_reward=-1.79 +/- 0.87
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016154486  |
| ent_coef_loss           | 2.7500458     |
| entropy                 | 2.768959      |
| ep_rewmean              | -2.13         |
| episodes                | 2904          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 290201        |
| policy_loss             | 0.8161497     |
| qf1_loss                | 0.0003122918  |
| qf2_loss                | 0.00032897567 |
| time_elapsed            | 1393          |
| total timesteps         | 290300        |
| value_loss              | 0.00033524807 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015326438  |
| ent_coef_loss           | 4.223871      |
| entropy                 | 2.6720192     |
| ep_rewmean              | -2.14         |
| episodes                | 2908          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 290601        |
| policy_loss             | 0.8199125     |
| qf1_loss                | 0.00044432125 |
| qf2_loss                | 0.00040803524 |
| time_elapsed            | 1395          |
| total timesteps         | 290700        |
| value_loss              | 0.00016803325 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015399717  |
| ent_coef_loss           | -6.495121     |
| entropy                 | 2.8134496     |
| ep_rewmean              | -2.12         |
| episodes                | 2912          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 291001        |
| policy_loss             | 0.82850045    |
| qf1_loss                | 0.00024529675 |
| qf2_loss                | 0.00017545062 |
| time_elapsed            | 1397          |
| total timesteps         | 291100        |
| value_loss              | 0.00014862086 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015537181  |
| ent_coef_loss           | -1.8127048    |
| entropy                 | 2.8505688     |
| ep_rewmean              | -2.15         |
| episodes                | 2916          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 291401        |
| policy_loss             | 0.85898626    |
| qf1_loss                | 0.00027985268 |
| qf2_loss                | 0.00027189628 |
| time_elapsed            | 1399          |
| total timesteps         | 291500        |
| value_loss              | 0.0002931018  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001615079   |
| ent_coef_loss           | 6.71385       |
| entropy                 | 2.5143414     |
| ep_rewmean              | -2.13         |
| episodes                | 2920          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 291801        |
| policy_loss             | 0.8345637     |
| qf1_loss                | 0.0002858069  |
| qf2_loss                | 0.00030633964 |
| time_elapsed            | 1401          |
| total timesteps         | 291900        |
| value_loss              | 0.00014835484 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016448671  |
| ent_coef_loss           | 4.8522778     |
| entropy                 | 2.3459287     |
| ep_rewmean              | -2.2          |
| episodes                | 2924          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 292201        |
| policy_loss             | 0.90096354    |
| qf1_loss                | 0.01078867    |
| qf2_loss                | 0.011190227   |
| time_elapsed            | 1403          |
| total timesteps         | 292300        |
| value_loss              | 0.00025946542 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015907979  |
| ent_coef_loss           | 3.936524      |
| entropy                 | 2.4106474     |
| ep_rewmean              | -2.22         |
| episodes                | 2928          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 292601        |
| policy_loss             | 0.86972904    |
| qf1_loss                | 0.005530634   |
| qf2_loss                | 0.0054548793  |
| time_elapsed            | 1405          |
| total timesteps         | 292700        |
| value_loss              | 0.00031091296 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015447713  |
| ent_coef_loss           | -2.645444     |
| entropy                 | 2.8568828     |
| ep_rewmean              | -2.19         |
| episodes                | 2932          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 293001        |
| policy_loss             | 0.90450835    |
| qf1_loss                | 0.00023998931 |
| qf2_loss                | 0.00022941756 |
| time_elapsed            | 1406          |
| total timesteps         | 293100        |
| value_loss              | 0.00023573698 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014852952  |
| ent_coef_loss           | -0.803879     |
| entropy                 | 2.708688      |
| ep_rewmean              | -2.21         |
| episodes                | 2936          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 293401        |
| policy_loss             | 0.86858857    |
| qf1_loss                | 0.006309798   |
| qf2_loss                | 0.006372913   |
| time_elapsed            | 1408          |
| total timesteps         | 293500        |
| value_loss              | 0.00020425393 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001435443   |
| ent_coef_loss           | -2.5910835    |
| entropy                 | 2.516911      |
| ep_rewmean              | -2.25         |
| episodes                | 2940          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 293801        |
| policy_loss             | 0.8958138     |
| qf1_loss                | 0.00042539916 |
| qf2_loss                | 0.00042451813 |
| time_elapsed            | 1410          |
| total timesteps         | 293900        |
| value_loss              | 0.00036781235 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014245466 |
| ent_coef_loss           | -0.8694191   |
| entropy                 | 2.3983936    |
| ep_rewmean              | -2.27        |
| episodes                | 2944         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.3         |
| n_updates               | 294201       |
| policy_loss             | 0.9133706    |
| qf1_loss                | 0.0022701106 |
| qf2_loss                | 0.0019895243 |
| time_elapsed            | 1412         |
| total timesteps         | 294300       |
| value_loss              | 0.0004622799 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014373834  |
| ent_coef_loss           | -0.02908063   |
| entropy                 | 3.09589       |
| ep_rewmean              | -2.28         |
| episodes                | 2948          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 294601        |
| policy_loss             | 0.8577883     |
| qf1_loss                | 0.0004947996  |
| qf2_loss                | 0.0005295398  |
| time_elapsed            | 1414          |
| total timesteps         | 294700        |
| value_loss              | 0.00048852456 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014172286 |
| ent_coef_loss           | 4.488569     |
| entropy                 | 3.274232     |
| ep_rewmean              | -2.28        |
| episodes                | 2952         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.3         |
| n_updates               | 295001       |
| policy_loss             | 0.84292555   |
| qf1_loss                | 0.0004354214 |
| qf2_loss                | 0.0004327865 |
| time_elapsed            | 1416         |
| total timesteps         | 295100       |
| value_loss              | 0.0002889205 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014942061  |
| ent_coef_loss           | -0.07317996   |
| entropy                 | 2.7949324     |
| ep_rewmean              | -2.33         |
| episodes                | 2956          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 295401        |
| policy_loss             | 0.8717304     |
| qf1_loss                | 0.012233938   |
| qf2_loss                | 0.011527429   |
| time_elapsed            | 1418          |
| total timesteps         | 295500        |
| value_loss              | 0.00014746567 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014336548  |
| ent_coef_loss           | -8.002448     |
| entropy                 | 3.0466547     |
| ep_rewmean              | -2.36         |
| episodes                | 2960          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 295801        |
| policy_loss             | 0.8931351     |
| qf1_loss                | 0.00032490413 |
| qf2_loss                | 0.00039321146 |
| time_elapsed            | 1420          |
| total timesteps         | 295900        |
| value_loss              | 0.0002278639  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014277298  |
| ent_coef_loss           | -2.424109     |
| entropy                 | 2.4164772     |
| ep_rewmean              | -2.39         |
| episodes                | 2964          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.4          |
| n_updates               | 296201        |
| policy_loss             | 0.83916867    |
| qf1_loss                | 0.00032809773 |
| qf2_loss                | 0.0003768067  |
| time_elapsed            | 1422          |
| total timesteps         | 296300        |
| value_loss              | 0.00025995506 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001496679   |
| ent_coef_loss           | 2.2582092     |
| entropy                 | 2.642983      |
| ep_rewmean              | -2.34         |
| episodes                | 2968          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 296601        |
| policy_loss             | 0.88678443    |
| qf1_loss                | 0.0072612977  |
| qf2_loss                | 0.006754991   |
| time_elapsed            | 1424          |
| total timesteps         | 296700        |
| value_loss              | 0.00045527177 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015933631  |
| ent_coef_loss           | 3.167136      |
| entropy                 | 2.433971      |
| ep_rewmean              | -2.29         |
| episodes                | 2972          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 297001        |
| policy_loss             | 0.8929552     |
| qf1_loss                | 0.00042001542 |
| qf2_loss                | 0.00033999636 |
| time_elapsed            | 1426          |
| total timesteps         | 297100        |
| value_loss              | 0.0002414991  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001624381   |
| ent_coef_loss           | 2.4902663     |
| entropy                 | 2.514541      |
| ep_rewmean              | -2.23         |
| episodes                | 2976          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 297401        |
| policy_loss             | 0.87217206    |
| qf1_loss                | 0.00030726934 |
| qf2_loss                | 0.00039774546 |
| time_elapsed            | 1428          |
| total timesteps         | 297500        |
| value_loss              | 0.00025541114 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016679664  |
| ent_coef_loss           | 4.8814297     |
| entropy                 | 2.4102337     |
| ep_rewmean              | -2.14         |
| episodes                | 2980          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 297801        |
| policy_loss             | 0.8841636     |
| qf1_loss                | 0.0013523246  |
| qf2_loss                | 0.0010627678  |
| time_elapsed            | 1430          |
| total timesteps         | 297900        |
| value_loss              | 0.00020411871 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017669953  |
| ent_coef_loss           | 9.1014        |
| entropy                 | 2.6089315     |
| ep_rewmean              | -2.13         |
| episodes                | 2984          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 298201        |
| policy_loss             | 0.8361037     |
| qf1_loss                | 0.004323516   |
| qf2_loss                | 0.0043694903  |
| time_elapsed            | 1431          |
| total timesteps         | 298300        |
| value_loss              | 0.00033489155 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017481713  |
| ent_coef_loss           | 1.8715878     |
| entropy                 | 3.0288        |
| ep_rewmean              | -2.1          |
| episodes                | 2988          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 298601        |
| policy_loss             | 0.87503463    |
| qf1_loss                | 0.012023564   |
| qf2_loss                | 0.012122239   |
| time_elapsed            | 1433          |
| total timesteps         | 298700        |
| value_loss              | 0.00033557485 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017528657  |
| ent_coef_loss           | 2.3027358     |
| entropy                 | 2.9333708     |
| ep_rewmean              | -2.09         |
| episodes                | 2992          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 299001        |
| policy_loss             | 0.8372463     |
| qf1_loss                | 0.008688556   |
| qf2_loss                | 0.0092385     |
| time_elapsed            | 1435          |
| total timesteps         | 299100        |
| value_loss              | 0.00033242474 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016720771  |
| ent_coef_loss           | -0.050712347  |
| entropy                 | 2.7155557     |
| ep_rewmean              | -2.06         |
| episodes                | 2996          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 299401        |
| policy_loss             | 0.88487375    |
| qf1_loss                | 0.00041471055 |
| qf2_loss                | 0.00038680306 |
| time_elapsed            | 1437          |
| total timesteps         | 299500        |
| value_loss              | 0.00020963831 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016337897  |
| ent_coef_loss           | -3.8918626    |
| entropy                 | 2.857339      |
| ep_rewmean              | -1.99         |
| episodes                | 3000          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 299801        |
| policy_loss             | 0.8119509     |
| qf1_loss                | 0.00032118984 |
| qf2_loss                | 0.00022656974 |
| time_elapsed            | 1439          |
| total timesteps         | 299900        |
| value_loss              | 0.0006010015  |
-------------------------------------------
Eval num_timesteps=300000, episode_reward=-1.10 +/- 0.51
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016500409  |
| ent_coef_loss           | -3.7022765    |
| entropy                 | 2.9929163     |
| ep_rewmean              | -2.01         |
| episodes                | 3004          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 300201        |
| policy_loss             | 0.85404444    |
| qf1_loss                | 0.00057805213 |
| qf2_loss                | 0.00051042484 |
| time_elapsed            | 1441          |
| total timesteps         | 300300        |
| value_loss              | 0.0007998289  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017070578 |
| ent_coef_loss           | 1.1465392    |
| entropy                 | 2.9859343    |
| ep_rewmean              | -1.97        |
| episodes                | 3008         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2           |
| n_updates               | 300601       |
| policy_loss             | 0.89601475   |
| qf1_loss                | 0.018946193  |
| qf2_loss                | 0.018706203  |
| time_elapsed            | 1443         |
| total timesteps         | 300700       |
| value_loss              | 0.0002569404 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017129091  |
| ent_coef_loss           | -4.7362742    |
| entropy                 | 2.6955733     |
| ep_rewmean              | -1.99         |
| episodes                | 3012          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 301001        |
| policy_loss             | 0.8071014     |
| qf1_loss                | 0.0002592692  |
| qf2_loss                | 0.00032708488 |
| time_elapsed            | 1445          |
| total timesteps         | 301100        |
| value_loss              | 0.0004318712  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0018863935 |
| ent_coef_loss           | -2.972464    |
| entropy                 | 3.6880898    |
| ep_rewmean              | -1.93        |
| episodes                | 3016         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.9         |
| n_updates               | 301401       |
| policy_loss             | 0.8998141    |
| qf1_loss                | 0.010743046  |
| qf2_loss                | 0.010281456  |
| time_elapsed            | 1447         |
| total timesteps         | 301500       |
| value_loss              | 0.0003315782 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020174764  |
| ent_coef_loss           | 3.382158      |
| entropy                 | 2.885294      |
| ep_rewmean              | -1.9          |
| episodes                | 3020          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 301801        |
| policy_loss             | 0.8438336     |
| qf1_loss                | 0.0005757968  |
| qf2_loss                | 0.000585736   |
| time_elapsed            | 1449          |
| total timesteps         | 301900        |
| value_loss              | 0.00053293654 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020982078  |
| ent_coef_loss           | -2.593801     |
| entropy                 | 3.2196043     |
| ep_rewmean              | -1.84         |
| episodes                | 3024          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 302201        |
| policy_loss             | 0.8180079     |
| qf1_loss                | 0.004841506   |
| qf2_loss                | 0.004989113   |
| time_elapsed            | 1451          |
| total timesteps         | 302300        |
| value_loss              | 0.00075627194 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020747194  |
| ent_coef_loss           | -7.085251     |
| entropy                 | 3.1646252     |
| ep_rewmean              | -1.77         |
| episodes                | 3028          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 302601        |
| policy_loss             | 0.79827625    |
| qf1_loss                | 0.0010837184  |
| qf2_loss                | 0.0007761518  |
| time_elapsed            | 1453          |
| total timesteps         | 302700        |
| value_loss              | 0.00046401186 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0018972358 |
| ent_coef_loss           | -1.8901122   |
| entropy                 | 3.0883586    |
| ep_rewmean              | -1.75        |
| episodes                | 3032         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.8         |
| n_updates               | 303001       |
| policy_loss             | 0.8636569    |
| qf1_loss                | 0.0015053907 |
| qf2_loss                | 0.0016697615 |
| time_elapsed            | 1455         |
| total timesteps         | 303100       |
| value_loss              | 0.0002790558 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0018677105 |
| ent_coef_loss           | 2.013927     |
| entropy                 | 2.730202     |
| ep_rewmean              | -1.77        |
| episodes                | 3036         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.8         |
| n_updates               | 303401       |
| policy_loss             | 0.79877627   |
| qf1_loss                | 0.015535441  |
| qf2_loss                | 0.015439545  |
| time_elapsed            | 1456         |
| total timesteps         | 303500       |
| value_loss              | 0.0003860755 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019071623  |
| ent_coef_loss           | 7.8952127     |
| entropy                 | 2.3472009     |
| ep_rewmean              | -1.79         |
| episodes                | 3040          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 303801        |
| policy_loss             | 0.81754434    |
| qf1_loss                | 0.008939148   |
| qf2_loss                | 0.00956796    |
| time_elapsed            | 1458          |
| total timesteps         | 303900        |
| value_loss              | 0.00052224833 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019397071  |
| ent_coef_loss           | -2.2527807    |
| entropy                 | 3.077112      |
| ep_rewmean              | -1.71         |
| episodes                | 3044          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 304201        |
| policy_loss             | 0.8342752     |
| qf1_loss                | 0.00044721263 |
| qf2_loss                | 0.0006121543  |
| time_elapsed            | 1460          |
| total timesteps         | 304300        |
| value_loss              | 0.00019676186 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019269125  |
| ent_coef_loss           | 6.227608      |
| entropy                 | 3.017266      |
| ep_rewmean              | -1.73         |
| episodes                | 3048          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 304601        |
| policy_loss             | 0.7763189     |
| qf1_loss                | 0.009742753   |
| qf2_loss                | 0.009698237   |
| time_elapsed            | 1462          |
| total timesteps         | 304700        |
| value_loss              | 0.00032491126 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0018623488 |
| ent_coef_loss           | -3.6372137   |
| entropy                 | 3.0055828    |
| ep_rewmean              | -1.72        |
| episodes                | 3052         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.7         |
| n_updates               | 305001       |
| policy_loss             | 0.8400251    |
| qf1_loss                | 0.0058233333 |
| qf2_loss                | 0.005957829  |
| time_elapsed            | 1464         |
| total timesteps         | 305100       |
| value_loss              | 0.0002313435 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018204874  |
| ent_coef_loss           | 3.9859238     |
| entropy                 | 2.8128462     |
| ep_rewmean              | -1.69         |
| episodes                | 3056          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 305401        |
| policy_loss             | 0.86245406    |
| qf1_loss                | 0.008271813   |
| qf2_loss                | 0.008049472   |
| time_elapsed            | 1466          |
| total timesteps         | 305500        |
| value_loss              | 0.00045748003 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018207097  |
| ent_coef_loss           | -3.8411899    |
| entropy                 | 3.0244281     |
| ep_rewmean              | -1.63         |
| episodes                | 3060          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 305801        |
| policy_loss             | 0.7530073     |
| qf1_loss                | 0.00052881107 |
| qf2_loss                | 0.00046204706 |
| time_elapsed            | 1468          |
| total timesteps         | 305900        |
| value_loss              | 0.0003809363  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018726232  |
| ent_coef_loss           | 0.5067935     |
| entropy                 | 2.5057092     |
| ep_rewmean              | -1.62         |
| episodes                | 3064          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 306201        |
| policy_loss             | 0.72094715    |
| qf1_loss                | 0.0044140713  |
| qf2_loss                | 0.004169619   |
| time_elapsed            | 1470          |
| total timesteps         | 306300        |
| value_loss              | 0.00029875495 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018755498  |
| ent_coef_loss           | -8.051422     |
| entropy                 | 3.0058832     |
| ep_rewmean              | -1.62         |
| episodes                | 3068          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 306601        |
| policy_loss             | 0.732147      |
| qf1_loss                | 0.00034146672 |
| qf2_loss                | 0.00040186173 |
| time_elapsed            | 1472          |
| total timesteps         | 306700        |
| value_loss              | 0.00024413857 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0018676998 |
| ent_coef_loss           | 2.2841773    |
| entropy                 | 2.7537634    |
| ep_rewmean              | -1.65        |
| episodes                | 3072         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.6         |
| n_updates               | 307001       |
| policy_loss             | 0.72245467   |
| qf1_loss                | 0.008752436  |
| qf2_loss                | 0.00880122   |
| time_elapsed            | 1474         |
| total timesteps         | 307100       |
| value_loss              | 0.000326343  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001824418   |
| ent_coef_loss           | -5.7487974    |
| entropy                 | 3.3056161     |
| ep_rewmean              | -1.6          |
| episodes                | 3076          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 307401        |
| policy_loss             | 0.7810725     |
| qf1_loss                | 0.00037140964 |
| qf2_loss                | 0.0002585046  |
| time_elapsed            | 1475          |
| total timesteps         | 307500        |
| value_loss              | 0.00020562108 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018953441  |
| ent_coef_loss           | -1.343048     |
| entropy                 | 3.177001      |
| ep_rewmean              | -1.6          |
| episodes                | 3080          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 307801        |
| policy_loss             | 0.8190161     |
| qf1_loss                | 0.000609799   |
| qf2_loss                | 0.00044293888 |
| time_elapsed            | 1477          |
| total timesteps         | 307900        |
| value_loss              | 0.00044029305 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001851601   |
| ent_coef_loss           | -0.030606031  |
| entropy                 | 4.1165457     |
| ep_rewmean              | -1.58         |
| episodes                | 3084          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 308201        |
| policy_loss             | 0.79880834    |
| qf1_loss                | 0.0033594354  |
| qf2_loss                | 0.0036523195  |
| time_elapsed            | 1479          |
| total timesteps         | 308300        |
| value_loss              | 0.00020443185 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019683563  |
| ent_coef_loss           | 3.4139938     |
| entropy                 | 3.656404      |
| ep_rewmean              | -1.63         |
| episodes                | 3088          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 308601        |
| policy_loss             | 0.7634554     |
| qf1_loss                | 0.006777605   |
| qf2_loss                | 0.006834043   |
| time_elapsed            | 1481          |
| total timesteps         | 308700        |
| value_loss              | 0.00038954208 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001999214   |
| ent_coef_loss           | 2.4720325     |
| entropy                 | 3.656335      |
| ep_rewmean              | -1.65         |
| episodes                | 3092          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 309001        |
| policy_loss             | 0.8135005     |
| qf1_loss                | 0.009647026   |
| qf2_loss                | 0.0097573865  |
| time_elapsed            | 1483          |
| total timesteps         | 309100        |
| value_loss              | 0.00032011524 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019409127  |
| ent_coef_loss           | 7.09392       |
| entropy                 | 4.0020027     |
| ep_rewmean              | -1.73         |
| episodes                | 3096          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 309401        |
| policy_loss             | 0.7811812     |
| qf1_loss                | 0.00027963865 |
| qf2_loss                | 0.00034183188 |
| time_elapsed            | 1485          |
| total timesteps         | 309500        |
| value_loss              | 0.00048133914 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018506891  |
| ent_coef_loss           | 1.2676995     |
| entropy                 | 3.6017153     |
| ep_rewmean              | -1.78         |
| episodes                | 3100          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 309801        |
| policy_loss             | 0.7728524     |
| qf1_loss                | 0.00030098576 |
| qf2_loss                | 0.00026195805 |
| time_elapsed            | 1487          |
| total timesteps         | 309900        |
| value_loss              | 0.00038668123 |
-------------------------------------------
Eval num_timesteps=310000, episode_reward=-1.83 +/- 0.97
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019861548  |
| ent_coef_loss           | 8.725818      |
| entropy                 | 4.0647335     |
| ep_rewmean              | -1.79         |
| episodes                | 3104          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 310201        |
| policy_loss             | 0.8215999     |
| qf1_loss                | 0.0006590263  |
| qf2_loss                | 0.0004966763  |
| time_elapsed            | 1489          |
| total timesteps         | 310300        |
| value_loss              | 0.00032292743 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021056838  |
| ent_coef_loss           | -0.332937     |
| entropy                 | 3.448326      |
| ep_rewmean              | -1.88         |
| episodes                | 3108          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 310601        |
| policy_loss             | 0.75608724    |
| qf1_loss                | 0.004011046   |
| qf2_loss                | 0.0039926707  |
| time_elapsed            | 1491          |
| total timesteps         | 310700        |
| value_loss              | 0.00025462144 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002187195   |
| ent_coef_loss           | 6.2092123     |
| entropy                 | 4.5190043     |
| ep_rewmean              | -1.88         |
| episodes                | 3112          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 311001        |
| policy_loss             | 0.79572004    |
| qf1_loss                | 0.00048039277 |
| qf2_loss                | 0.0004904444  |
| time_elapsed            | 1493          |
| total timesteps         | 311100        |
| value_loss              | 0.0006350038  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002175374   |
| ent_coef_loss           | -0.43967807   |
| entropy                 | 4.5253553     |
| ep_rewmean              | -1.9          |
| episodes                | 3116          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 311401        |
| policy_loss             | 0.76358914    |
| qf1_loss                | 0.0026602466  |
| qf2_loss                | 0.0027407925  |
| time_elapsed            | 1495          |
| total timesteps         | 311500        |
| value_loss              | 0.00021838347 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022161608  |
| ent_coef_loss           | 3.6854358     |
| entropy                 | 4.351894      |
| ep_rewmean              | -1.91         |
| episodes                | 3120          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 311801        |
| policy_loss             | 0.82939196    |
| qf1_loss                | 0.00044568224 |
| qf2_loss                | 0.0003159794  |
| time_elapsed            | 1497          |
| total timesteps         | 311900        |
| value_loss              | 0.00046904953 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021831011  |
| ent_coef_loss           | 2.3387856     |
| entropy                 | 4.0814543     |
| ep_rewmean              | -1.87         |
| episodes                | 3124          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 312201        |
| policy_loss             | 0.8121493     |
| qf1_loss                | 0.00095628767 |
| qf2_loss                | 0.0009319789  |
| time_elapsed            | 1499          |
| total timesteps         | 312300        |
| value_loss              | 0.0013739797  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002161568   |
| ent_coef_loss           | 1.9072769     |
| entropy                 | 4.1608124     |
| ep_rewmean              | -1.89         |
| episodes                | 3128          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 312601        |
| policy_loss             | 0.76192963    |
| qf1_loss                | 0.00023391192 |
| qf2_loss                | 0.00031049206 |
| time_elapsed            | 1500          |
| total timesteps         | 312700        |
| value_loss              | 0.00028503104 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021855123  |
| ent_coef_loss           | 1.9940002     |
| entropy                 | 4.301777      |
| ep_rewmean              | -1.9          |
| episodes                | 3132          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 313001        |
| policy_loss             | 0.7901107     |
| qf1_loss                | 0.0004472469  |
| qf2_loss                | 0.00049068435 |
| time_elapsed            | 1502          |
| total timesteps         | 313100        |
| value_loss              | 0.0005696773  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022466893  |
| ent_coef_loss           | 5.1744075     |
| entropy                 | 4.538699      |
| ep_rewmean              | -1.87         |
| episodes                | 3136          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 313401        |
| policy_loss             | 0.8413596     |
| qf1_loss                | 0.00028341403 |
| qf2_loss                | 0.00041066617 |
| time_elapsed            | 1504          |
| total timesteps         | 313500        |
| value_loss              | 0.00036622264 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0022865287 |
| ent_coef_loss           | 4.2281003    |
| entropy                 | 4.3603134    |
| ep_rewmean              | -1.8         |
| episodes                | 3140         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.8         |
| n_updates               | 313801       |
| policy_loss             | 0.84897774   |
| qf1_loss                | 0.019364394  |
| qf2_loss                | 0.018435555  |
| time_elapsed            | 1506         |
| total timesteps         | 313900       |
| value_loss              | 0.0004515821 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0021519696 |
| ent_coef_loss           | 3.2215505    |
| entropy                 | 4.278659     |
| ep_rewmean              | -1.84        |
| episodes                | 3144         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.8         |
| n_updates               | 314201       |
| policy_loss             | 0.8253627    |
| qf1_loss                | 0.008633358  |
| qf2_loss                | 0.008133415  |
| time_elapsed            | 1508         |
| total timesteps         | 314300       |
| value_loss              | 0.0006376451 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0020475006 |
| ent_coef_loss           | 0.11787915   |
| entropy                 | 3.926629     |
| ep_rewmean              | -1.81        |
| episodes                | 3148         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.8         |
| n_updates               | 314601       |
| policy_loss             | 0.71118486   |
| qf1_loss                | 0.0022591152 |
| qf2_loss                | 0.0023209318 |
| time_elapsed            | 1510         |
| total timesteps         | 314700       |
| value_loss              | 0.0002235109 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020044881  |
| ent_coef_loss           | -6.340294     |
| entropy                 | 4.069314      |
| ep_rewmean              | -1.85         |
| episodes                | 3152          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 315001        |
| policy_loss             | 0.8401525     |
| qf1_loss                | 0.002557711   |
| qf2_loss                | 0.0023588862  |
| time_elapsed            | 1512          |
| total timesteps         | 315100        |
| value_loss              | 0.00022068103 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001958876   |
| ent_coef_loss           | -4.2294245    |
| entropy                 | 4.160332      |
| ep_rewmean              | -1.84         |
| episodes                | 3156          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 315401        |
| policy_loss             | 0.80084294    |
| qf1_loss                | 0.00067240687 |
| qf2_loss                | 0.00057684665 |
| time_elapsed            | 1514          |
| total timesteps         | 315500        |
| value_loss              | 0.00070678256 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019583735  |
| ent_coef_loss           | -8.207224     |
| entropy                 | 3.9835255     |
| ep_rewmean              | -1.86         |
| episodes                | 3160          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 315801        |
| policy_loss             | 0.8118477     |
| qf1_loss                | 0.00044268472 |
| qf2_loss                | 0.00043970044 |
| time_elapsed            | 1516          |
| total timesteps         | 315900        |
| value_loss              | 0.00035151624 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020237006  |
| ent_coef_loss           | 3.8630896     |
| entropy                 | 4.152337      |
| ep_rewmean              | -1.85         |
| episodes                | 3164          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 316201        |
| policy_loss             | 0.92677236    |
| qf1_loss                | 0.00059665955 |
| qf2_loss                | 0.0005862061  |
| time_elapsed            | 1518          |
| total timesteps         | 316300        |
| value_loss              | 0.00045640732 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0020154794 |
| ent_coef_loss           | 2.5970418    |
| entropy                 | 3.9530516    |
| ep_rewmean              | -1.85        |
| episodes                | 3168         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.9         |
| n_updates               | 316601       |
| policy_loss             | 0.96002305   |
| qf1_loss                | 0.006216041  |
| qf2_loss                | 0.005718272  |
| time_elapsed            | 1520         |
| total timesteps         | 316700       |
| value_loss              | 0.0015245687 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0021356505 |
| ent_coef_loss           | 5.9811726    |
| entropy                 | 4.4107904    |
| ep_rewmean              | -1.85        |
| episodes                | 3172         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.8         |
| n_updates               | 317001       |
| policy_loss             | 0.84546006   |
| qf1_loss                | 0.0009207416 |
| qf2_loss                | 0.0009801751 |
| time_elapsed            | 1521         |
| total timesteps         | 317100       |
| value_loss              | 0.001101838  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021344207  |
| ent_coef_loss           | -1.0775493    |
| entropy                 | 4.4630547     |
| ep_rewmean              | -1.86         |
| episodes                | 3176          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 317401        |
| policy_loss             | 0.86072123    |
| qf1_loss                | 0.00058613723 |
| qf2_loss                | 0.00026132798 |
| time_elapsed            | 1523          |
| total timesteps         | 317500        |
| value_loss              | 0.0003230367  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021386854  |
| ent_coef_loss           | -13.772174    |
| entropy                 | 4.6256056     |
| ep_rewmean              | -1.85         |
| episodes                | 3180          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 317801        |
| policy_loss             | 0.8439037     |
| qf1_loss                | 0.00045283991 |
| qf2_loss                | 0.00038936906 |
| time_elapsed            | 1525          |
| total timesteps         | 317900        |
| value_loss              | 0.00050850597 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0022267257 |
| ent_coef_loss           | 2.8645697    |
| entropy                 | 3.878881     |
| ep_rewmean              | -1.85        |
| episodes                | 3184         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.8         |
| n_updates               | 318201       |
| policy_loss             | 0.84136665   |
| qf1_loss                | 0.0060512233 |
| qf2_loss                | 0.006140913  |
| time_elapsed            | 1527         |
| total timesteps         | 318300       |
| value_loss              | 0.0002807256 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022492383  |
| ent_coef_loss           | -1.3750323    |
| entropy                 | 4.068644      |
| ep_rewmean              | -1.85         |
| episodes                | 3188          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 318601        |
| policy_loss             | 0.870129      |
| qf1_loss                | 0.0026220023  |
| qf2_loss                | 0.0029446834  |
| time_elapsed            | 1529          |
| total timesteps         | 318700        |
| value_loss              | 0.00042983252 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021431518  |
| ent_coef_loss           | -2.5840764    |
| entropy                 | 4.1020145     |
| ep_rewmean              | -1.86         |
| episodes                | 3192          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 319001        |
| policy_loss             | 0.8994141     |
| qf1_loss                | 0.00026492414 |
| qf2_loss                | 0.00036753505 |
| time_elapsed            | 1531          |
| total timesteps         | 319100        |
| value_loss              | 0.0002610645  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020435213  |
| ent_coef_loss           | 1.9632828     |
| entropy                 | 3.9724822     |
| ep_rewmean              | -1.81         |
| episodes                | 3196          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 319401        |
| policy_loss             | 0.94066286    |
| qf1_loss                | 0.00120795    |
| qf2_loss                | 0.0013399342  |
| time_elapsed            | 1533          |
| total timesteps         | 319500        |
| value_loss              | 0.00055354787 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019553932  |
| ent_coef_loss           | -5.6001883    |
| entropy                 | 3.6431131     |
| ep_rewmean              | -1.74         |
| episodes                | 3200          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 319801        |
| policy_loss             | 0.9071196     |
| qf1_loss                | 0.0006785827  |
| qf2_loss                | 0.0006887328  |
| time_elapsed            | 1535          |
| total timesteps         | 319900        |
| value_loss              | 0.00035590702 |
-------------------------------------------
Eval num_timesteps=320000, episode_reward=-1.27 +/- 0.67
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001959471  |
| ent_coef_loss           | 5.4121456    |
| entropy                 | 3.6391683    |
| ep_rewmean              | -1.7         |
| episodes                | 3204         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.7         |
| n_updates               | 320201       |
| policy_loss             | 1.0387958    |
| qf1_loss                | 0.0006824832 |
| qf2_loss                | 0.0007794267 |
| time_elapsed            | 1537         |
| total timesteps         | 320300       |
| value_loss              | 0.0009935515 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002044646   |
| ent_coef_loss           | -6.48535      |
| entropy                 | 3.4537644     |
| ep_rewmean              | -1.71         |
| episodes                | 3208          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 320601        |
| policy_loss             | 0.98464143    |
| qf1_loss                | 0.0004992697  |
| qf2_loss                | 0.00033751037 |
| time_elapsed            | 1539          |
| total timesteps         | 320700        |
| value_loss              | 0.0005077453  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020719017  |
| ent_coef_loss           | -0.41032934   |
| entropy                 | 3.384965      |
| ep_rewmean              | -1.73         |
| episodes                | 3212          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 321001        |
| policy_loss             | 0.9625841     |
| qf1_loss                | 0.0008083651  |
| qf2_loss                | 0.00043026486 |
| time_elapsed            | 1541          |
| total timesteps         | 321100        |
| value_loss              | 0.0009213489  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0021816264 |
| ent_coef_loss           | -1.6330171   |
| entropy                 | 3.3023553    |
| ep_rewmean              | -1.72        |
| episodes                | 3216         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.7         |
| n_updates               | 321401       |
| policy_loss             | 0.94910854   |
| qf1_loss                | 0.017886845  |
| qf2_loss                | 0.018866774  |
| time_elapsed            | 1543         |
| total timesteps         | 321500       |
| value_loss              | 0.0005503624 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0023127173 |
| ent_coef_loss           | 0.242998     |
| entropy                 | 3.2920225    |
| ep_rewmean              | -1.77        |
| episodes                | 3220         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.8         |
| n_updates               | 321801       |
| policy_loss             | 0.9676794    |
| qf1_loss                | 0.0016786018 |
| qf2_loss                | 0.0019181573 |
| time_elapsed            | 1545         |
| total timesteps         | 321900       |
| value_loss              | 0.0013362003 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0024647724  |
| ent_coef_loss           | -2.5008626    |
| entropy                 | 3.6944256     |
| ep_rewmean              | -1.83         |
| episodes                | 3224          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 322201        |
| policy_loss             | 1.0047503     |
| qf1_loss                | 0.00057954405 |
| qf2_loss                | 0.00075658684 |
| time_elapsed            | 1547          |
| total timesteps         | 322300        |
| value_loss              | 0.00051147165 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0024582841  |
| ent_coef_loss           | -4.487318     |
| entropy                 | 3.4981546     |
| ep_rewmean              | -1.87         |
| episodes                | 3228          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 322601        |
| policy_loss             | 0.9529785     |
| qf1_loss                | 0.0005543335  |
| qf2_loss                | 0.00050428626 |
| time_elapsed            | 1549          |
| total timesteps         | 322700        |
| value_loss              | 0.0007369383  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0023443624  |
| ent_coef_loss           | -6.105121     |
| entropy                 | 3.2272184     |
| ep_rewmean              | -1.93         |
| episodes                | 3232          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 323001        |
| policy_loss             | 1.03969       |
| qf1_loss                | 0.0029161167  |
| qf2_loss                | 0.0022584118  |
| time_elapsed            | 1550          |
| total timesteps         | 323100        |
| value_loss              | 0.00074272393 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0023766016 |
| ent_coef_loss           | -3.084182    |
| entropy                 | 4.047693     |
| ep_rewmean              | -1.95        |
| episodes                | 3236         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.9         |
| n_updates               | 323401       |
| policy_loss             | 0.98287874   |
| qf1_loss                | 0.008116399  |
| qf2_loss                | 0.007925756  |
| time_elapsed            | 1552         |
| total timesteps         | 323500       |
| value_loss              | 0.0009932711 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0025217447  |
| ent_coef_loss           | 1.0115054     |
| entropy                 | 3.892959      |
| ep_rewmean              | -1.99         |
| episodes                | 3240          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 323801        |
| policy_loss             | 0.9881453     |
| qf1_loss                | 0.0016335162  |
| qf2_loss                | 0.0016682862  |
| time_elapsed            | 1554          |
| total timesteps         | 323900        |
| value_loss              | 0.00091293297 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0026018529  |
| ent_coef_loss           | 4.365139      |
| entropy                 | 3.973303      |
| ep_rewmean              | -1.98         |
| episodes                | 3244          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 324201        |
| policy_loss             | 0.947667      |
| qf1_loss                | 0.006743782   |
| qf2_loss                | 0.0066978307  |
| time_elapsed            | 1556          |
| total timesteps         | 324300        |
| value_loss              | 0.00070063106 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0025143232 |
| ent_coef_loss           | -6.973337    |
| entropy                 | 3.7795606    |
| ep_rewmean              | -2           |
| episodes                | 3248         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2           |
| n_updates               | 324601       |
| policy_loss             | 0.97759736   |
| qf1_loss                | 0.016977502  |
| qf2_loss                | 0.017506365  |
| time_elapsed            | 1558         |
| total timesteps         | 324700       |
| value_loss              | 0.003473191  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0023596038  |
| ent_coef_loss           | -10.986877    |
| entropy                 | 3.5019312     |
| ep_rewmean              | -1.98         |
| episodes                | 3252          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 325001        |
| policy_loss             | 0.9837453     |
| qf1_loss                | 0.00040772706 |
| qf2_loss                | 0.0003619035  |
| time_elapsed            | 1560          |
| total timesteps         | 325100        |
| value_loss              | 0.00048147034 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002214026   |
| ent_coef_loss           | -6.5378094    |
| entropy                 | 3.4114547     |
| ep_rewmean              | -2            |
| episodes                | 3256          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 325401        |
| policy_loss             | 0.84793305    |
| qf1_loss                | 0.007725042   |
| qf2_loss                | 0.009287976   |
| time_elapsed            | 1562          |
| total timesteps         | 325500        |
| value_loss              | 0.00038948195 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021705755  |
| ent_coef_loss           | -6.758792     |
| entropy                 | 3.4644532     |
| ep_rewmean              | -1.95         |
| episodes                | 3260          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 325801        |
| policy_loss             | 0.9140518     |
| qf1_loss                | 0.00063879136 |
| qf2_loss                | 0.000489474   |
| time_elapsed            | 1564          |
| total timesteps         | 325900        |
| value_loss              | 0.00031350076 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002156367  |
| ent_coef_loss           | -3.587082    |
| entropy                 | 4.0969334    |
| ep_rewmean              | -1.94        |
| episodes                | 3264         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.9         |
| n_updates               | 326201       |
| policy_loss             | 0.98320675   |
| qf1_loss                | 0.03912612   |
| qf2_loss                | 0.03743219   |
| time_elapsed            | 1566         |
| total timesteps         | 326300       |
| value_loss              | 0.0004450822 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020727387  |
| ent_coef_loss           | -6.0699925    |
| entropy                 | 3.2496095     |
| ep_rewmean              | -1.95         |
| episodes                | 3268          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 326601        |
| policy_loss             | 0.9251781     |
| qf1_loss                | 0.005589714   |
| qf2_loss                | 0.0052303253  |
| time_elapsed            | 1568          |
| total timesteps         | 326700        |
| value_loss              | 0.00034092146 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020879616  |
| ent_coef_loss           | 1.7312078     |
| entropy                 | 3.766716      |
| ep_rewmean              | -2.01         |
| episodes                | 3272          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 327001        |
| policy_loss             | 0.9866364     |
| qf1_loss                | 0.0012537045  |
| qf2_loss                | 0.0012182612  |
| time_elapsed            | 1570          |
| total timesteps         | 327100        |
| value_loss              | 0.00044167097 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020201844  |
| ent_coef_loss           | -5.2652206    |
| entropy                 | 3.5559387     |
| ep_rewmean              | -2            |
| episodes                | 3276          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 327401        |
| policy_loss             | 0.91294396    |
| qf1_loss                | 0.0006592111  |
| qf2_loss                | 0.00034906314 |
| time_elapsed            | 1572          |
| total timesteps         | 327500        |
| value_loss              | 0.0008530702  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0020146703 |
| ent_coef_loss           | 0.2822392    |
| entropy                 | 3.3509603    |
| ep_rewmean              | -2.03        |
| episodes                | 3280         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2           |
| n_updates               | 327801       |
| policy_loss             | 0.9737563    |
| qf1_loss                | 0.007442584  |
| qf2_loss                | 0.008136075  |
| time_elapsed            | 1573         |
| total timesteps         | 327900       |
| value_loss              | 0.0004085346 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0022216032 |
| ent_coef_loss           | -0.666052    |
| entropy                 | 3.3360753    |
| ep_rewmean              | -2.05        |
| episodes                | 3284         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2           |
| n_updates               | 328201       |
| policy_loss             | 0.84252536   |
| qf1_loss                | 0.007971552  |
| qf2_loss                | 0.008083581  |
| time_elapsed            | 1575         |
| total timesteps         | 328300       |
| value_loss              | 0.0005702521 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0023473895  |
| ent_coef_loss           | 3.6390557     |
| entropy                 | 3.8496358     |
| ep_rewmean              | -2.02         |
| episodes                | 3288          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 328601        |
| policy_loss             | 0.96992457    |
| qf1_loss                | 0.0016843419  |
| qf2_loss                | 0.0013026961  |
| time_elapsed            | 1577          |
| total timesteps         | 328700        |
| value_loss              | 0.00075870554 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0023972353  |
| ent_coef_loss           | 0.35753453    |
| entropy                 | 3.958706      |
| ep_rewmean              | -2.04         |
| episodes                | 3292          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 329001        |
| policy_loss             | 0.9843609     |
| qf1_loss                | 0.000770189   |
| qf2_loss                | 0.00056478806 |
| time_elapsed            | 1579          |
| total timesteps         | 329100        |
| value_loss              | 0.000472682   |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.00232827   |
| ent_coef_loss           | 6.5346375    |
| entropy                 | 3.8040447    |
| ep_rewmean              | -2           |
| episodes                | 3296         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2           |
| n_updates               | 329401       |
| policy_loss             | 1.0505507    |
| qf1_loss                | 0.0004838835 |
| qf2_loss                | 0.0005266046 |
| time_elapsed            | 1581         |
| total timesteps         | 329500       |
| value_loss              | 0.0014261855 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021958852  |
| ent_coef_loss           | 2.459258      |
| entropy                 | 3.695248      |
| ep_rewmean              | -2.1          |
| episodes                | 3300          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 329801        |
| policy_loss             | 1.002096      |
| qf1_loss                | 0.0005759263  |
| qf2_loss                | 0.0005504242  |
| time_elapsed            | 1583          |
| total timesteps         | 329900        |
| value_loss              | 0.00042926532 |
-------------------------------------------
Eval num_timesteps=330000, episode_reward=-1.77 +/- 0.90
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021108107  |
| ent_coef_loss           | -4.416115     |
| entropy                 | 3.7263613     |
| ep_rewmean              | -2.15         |
| episodes                | 3304          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 330201        |
| policy_loss             | 0.98874736    |
| qf1_loss                | 0.00058998575 |
| qf2_loss                | 0.00035447895 |
| time_elapsed            | 1585          |
| total timesteps         | 330300        |
| value_loss              | 0.00025910404 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002100393   |
| ent_coef_loss           | 0.34035397    |
| entropy                 | 3.6020803     |
| ep_rewmean              | -2.13         |
| episodes                | 3308          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 330601        |
| policy_loss             | 1.0394598     |
| qf1_loss                | 0.00043422275 |
| qf2_loss                | 0.0003926217  |
| time_elapsed            | 1587          |
| total timesteps         | 330700        |
| value_loss              | 0.00029067602 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0019968771 |
| ent_coef_loss           | -7.456079    |
| entropy                 | 3.7472103    |
| ep_rewmean              | -2.11        |
| episodes                | 3312         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 331001       |
| policy_loss             | 0.9956184    |
| qf1_loss                | 0.0010414193 |
| qf2_loss                | 0.0010096638 |
| time_elapsed            | 1589         |
| total timesteps         | 331100       |
| value_loss              | 0.0016807707 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017792066  |
| ent_coef_loss           | -4.528717     |
| entropy                 | 3.3737059     |
| ep_rewmean              | -2.13         |
| episodes                | 3316          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 331401        |
| policy_loss             | 1.0381875     |
| qf1_loss                | 0.00065971084 |
| qf2_loss                | 0.00051385746 |
| time_elapsed            | 1591          |
| total timesteps         | 331500        |
| value_loss              | 0.0012342031  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016775011  |
| ent_coef_loss           | -0.90369546   |
| entropy                 | 3.074944      |
| ep_rewmean              | -2.12         |
| episodes                | 3320          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 331801        |
| policy_loss             | 1.0023636     |
| qf1_loss                | 0.00055287883 |
| qf2_loss                | 0.00052576873 |
| time_elapsed            | 1593          |
| total timesteps         | 331900        |
| value_loss              | 0.00048688767 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017025949  |
| ent_coef_loss           | 7.610118      |
| entropy                 | 3.3984017     |
| ep_rewmean              | -2.08         |
| episodes                | 3324          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 332201        |
| policy_loss             | 1.0748385     |
| qf1_loss                | 0.006671485   |
| qf2_loss                | 0.0068690237  |
| time_elapsed            | 1595          |
| total timesteps         | 332300        |
| value_loss              | 0.00039226952 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016812007 |
| ent_coef_loss           | -0.02849412  |
| entropy                 | 3.1609602    |
| ep_rewmean              | -2.03        |
| episodes                | 3328         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2           |
| n_updates               | 332601       |
| policy_loss             | 0.88700485   |
| qf1_loss                | 0.00065134   |
| qf2_loss                | 0.0008363826 |
| time_elapsed            | 1597         |
| total timesteps         | 332700       |
| value_loss              | 0.000975751  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016768189  |
| ent_coef_loss           | -11.907293    |
| entropy                 | 3.446587      |
| ep_rewmean              | -2            |
| episodes                | 3332          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 333001        |
| policy_loss             | 0.9271489     |
| qf1_loss                | 0.0005590096  |
| qf2_loss                | 0.00053802534 |
| time_elapsed            | 1599          |
| total timesteps         | 333100        |
| value_loss              | 0.0003548278  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016807102  |
| ent_coef_loss           | 10.509563     |
| entropy                 | 3.110052      |
| ep_rewmean              | -1.97         |
| episodes                | 3336          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 333401        |
| policy_loss             | 1.0822465     |
| qf1_loss                | 0.0005343853  |
| qf2_loss                | 0.00040307493 |
| time_elapsed            | 1601          |
| total timesteps         | 333500        |
| value_loss              | 0.00040325476 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017262374  |
| ent_coef_loss           | 11.5205555    |
| entropy                 | 3.8058085     |
| ep_rewmean              | -1.95         |
| episodes                | 3340          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 333801        |
| policy_loss             | 1.0843663     |
| qf1_loss                | 0.0033229447  |
| qf2_loss                | 0.003273429   |
| time_elapsed            | 1603          |
| total timesteps         | 333900        |
| value_loss              | 0.00030694957 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018130408  |
| ent_coef_loss           | 2.2778997     |
| entropy                 | 3.7938523     |
| ep_rewmean              | -1.94         |
| episodes                | 3344          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 334201        |
| policy_loss             | 0.98114103    |
| qf1_loss                | 0.00031378545 |
| qf2_loss                | 0.0002451758  |
| time_elapsed            | 1605          |
| total timesteps         | 334300        |
| value_loss              | 0.0003499918  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0019222093 |
| ent_coef_loss           | 9.854097     |
| entropy                 | 3.708787     |
| ep_rewmean              | -1.94        |
| episodes                | 3348         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.9         |
| n_updates               | 334601       |
| policy_loss             | 1.0436673    |
| qf1_loss                | 0.0004789299 |
| qf2_loss                | 0.0005315074 |
| time_elapsed            | 1607         |
| total timesteps         | 334700       |
| value_loss              | 0.0004228652 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002051848  |
| ent_coef_loss           | -2.3893042   |
| entropy                 | 3.7212827    |
| ep_rewmean              | -1.98        |
| episodes                | 3352         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2           |
| n_updates               | 335001       |
| policy_loss             | 0.9751414    |
| qf1_loss                | 0.010378156  |
| qf2_loss                | 0.010463016  |
| time_elapsed            | 1609         |
| total timesteps         | 335100       |
| value_loss              | 0.0003809405 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021144052  |
| ent_coef_loss           | 5.3027787     |
| entropy                 | 3.6049716     |
| ep_rewmean              | -1.95         |
| episodes                | 3356          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 335401        |
| policy_loss             | 0.97523975    |
| qf1_loss                | 0.0014942104  |
| qf2_loss                | 0.00093749305 |
| time_elapsed            | 1611          |
| total timesteps         | 335500        |
| value_loss              | 0.0007557742  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002143211  |
| ent_coef_loss           | 1.6066298    |
| entropy                 | 3.7515912    |
| ep_rewmean              | -1.99        |
| episodes                | 3360         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2           |
| n_updates               | 335801       |
| policy_loss             | 1.0716714    |
| qf1_loss                | 0.010073702  |
| qf2_loss                | 0.010149439  |
| time_elapsed            | 1613         |
| total timesteps         | 335900       |
| value_loss              | 0.0005412086 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0021802662 |
| ent_coef_loss           | 8.257042     |
| entropy                 | 3.7178495    |
| ep_rewmean              | -2.01        |
| episodes                | 3364         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2           |
| n_updates               | 336201       |
| policy_loss             | 1.0407321    |
| qf1_loss                | 0.0006606186 |
| qf2_loss                | 0.0004423893 |
| time_elapsed            | 1615         |
| total timesteps         | 336300       |
| value_loss              | 0.0009768483 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021412293  |
| ent_coef_loss           | -2.8689454    |
| entropy                 | 3.3427782     |
| ep_rewmean              | -2.03         |
| episodes                | 3368          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 336601        |
| policy_loss             | 1.0218781     |
| qf1_loss                | 0.008022484   |
| qf2_loss                | 0.007923514   |
| time_elapsed            | 1617          |
| total timesteps         | 336700        |
| value_loss              | 0.00043813133 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021053164  |
| ent_coef_loss           | 2.6174312     |
| entropy                 | 3.20041       |
| ep_rewmean              | -1.99         |
| episodes                | 3372          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 337001        |
| policy_loss             | 0.9763112     |
| qf1_loss                | 0.00037873047 |
| qf2_loss                | 0.00039051194 |
| time_elapsed            | 1619          |
| total timesteps         | 337100        |
| value_loss              | 0.0004885533  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0020551048 |
| ent_coef_loss           | 1.9451852    |
| entropy                 | 3.5652618    |
| ep_rewmean              | -2.07        |
| episodes                | 3376         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 337401       |
| policy_loss             | 1.0381441    |
| qf1_loss                | 0.0004950103 |
| qf2_loss                | 0.0008871449 |
| time_elapsed            | 1621         |
| total timesteps         | 337500       |
| value_loss              | 0.0007379203 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020059654  |
| ent_coef_loss           | 0.12706327    |
| entropy                 | 3.7664628     |
| ep_rewmean              | -2.14         |
| episodes                | 3380          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 337801        |
| policy_loss             | 0.89194036    |
| qf1_loss                | 0.0040064766  |
| qf2_loss                | 0.0045876377  |
| time_elapsed            | 1622          |
| total timesteps         | 337900        |
| value_loss              | 0.00041832664 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0019694595 |
| ent_coef_loss           | -0.32773185  |
| entropy                 | 3.2369595    |
| ep_rewmean              | -2.14        |
| episodes                | 3384         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 338201       |
| policy_loss             | 0.8942372    |
| qf1_loss                | 0.0005099094 |
| qf2_loss                | 0.0004411938 |
| time_elapsed            | 1624         |
| total timesteps         | 338300       |
| value_loss              | 0.000416602  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019960888  |
| ent_coef_loss           | -6.515252     |
| entropy                 | 3.579068      |
| ep_rewmean              | -2.15         |
| episodes                | 3388          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 338601        |
| policy_loss             | 0.9336176     |
| qf1_loss                | 0.00081199815 |
| qf2_loss                | 0.001075255   |
| time_elapsed            | 1626          |
| total timesteps         | 338700        |
| value_loss              | 0.0008210442  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020363883  |
| ent_coef_loss           | 1.2915082     |
| entropy                 | 3.7442765     |
| ep_rewmean              | -2.16         |
| episodes                | 3392          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 339001        |
| policy_loss             | 0.9486797     |
| qf1_loss                | 0.0004488188  |
| qf2_loss                | 0.00032011207 |
| time_elapsed            | 1628          |
| total timesteps         | 339100        |
| value_loss              | 0.00038199878 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020927761  |
| ent_coef_loss           | 2.2491965     |
| entropy                 | 3.5778449     |
| ep_rewmean              | -2.2          |
| episodes                | 3396          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 339401        |
| policy_loss             | 0.86894226    |
| qf1_loss                | 0.00093054044 |
| qf2_loss                | 0.0006388407  |
| time_elapsed            | 1630          |
| total timesteps         | 339500        |
| value_loss              | 0.00061094295 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021583627  |
| ent_coef_loss           | 3.3250306     |
| entropy                 | 3.6405673     |
| ep_rewmean              | -2.14         |
| episodes                | 3400          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 339801        |
| policy_loss             | 0.9895925     |
| qf1_loss                | 0.0004885538  |
| qf2_loss                | 0.00034027494 |
| time_elapsed            | 1632          |
| total timesteps         | 339900        |
| value_loss              | 0.000535934   |
-------------------------------------------
Eval num_timesteps=340000, episode_reward=-2.28 +/- 0.75
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021501295  |
| ent_coef_loss           | -6.268074     |
| entropy                 | 3.2478328     |
| ep_rewmean              | -2.11         |
| episodes                | 3404          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 340201        |
| policy_loss             | 0.8961992     |
| qf1_loss                | 0.00067078404 |
| qf2_loss                | 0.00061393867 |
| time_elapsed            | 1634          |
| total timesteps         | 340300        |
| value_loss              | 0.0005095771  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002110204  |
| ent_coef_loss           | -3.8679676   |
| entropy                 | 3.3018057    |
| ep_rewmean              | -2.09        |
| episodes                | 3408         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 340601       |
| policy_loss             | 0.9371158    |
| qf1_loss                | 0.008598687  |
| qf2_loss                | 0.008864643  |
| time_elapsed            | 1636         |
| total timesteps         | 340700       |
| value_loss              | 0.0010741805 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0021096596 |
| ent_coef_loss           | 3.9481692    |
| entropy                 | 3.6255693    |
| ep_rewmean              | -2.11        |
| episodes                | 3412         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.1         |
| n_updates               | 341001       |
| policy_loss             | 0.9226656    |
| qf1_loss                | 0.013891885  |
| qf2_loss                | 0.01500723   |
| time_elapsed            | 1638         |
| total timesteps         | 341100       |
| value_loss              | 0.0006055442 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020869325  |
| ent_coef_loss           | -4.5653577    |
| entropy                 | 3.468103      |
| ep_rewmean              | -2.08         |
| episodes                | 3416          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 341401        |
| policy_loss             | 0.9030796     |
| qf1_loss                | 0.00031274775 |
| qf2_loss                | 0.000292601   |
| time_elapsed            | 1640          |
| total timesteps         | 341500        |
| value_loss              | 0.00023285502 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020203146  |
| ent_coef_loss           | 2.3854318     |
| entropy                 | 3.7505448     |
| ep_rewmean              | -2.08         |
| episodes                | 3420          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 341801        |
| policy_loss             | 0.895225      |
| qf1_loss                | 0.00036715058 |
| qf2_loss                | 0.00020017783 |
| time_elapsed            | 1642          |
| total timesteps         | 341900        |
| value_loss              | 0.00026773036 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019275015  |
| ent_coef_loss           | -3.6099582    |
| entropy                 | 3.4069877     |
| ep_rewmean              | -2.08         |
| episodes                | 3424          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 342201        |
| policy_loss             | 1.0235206     |
| qf1_loss                | 0.009453223   |
| qf2_loss                | 0.0093640145  |
| time_elapsed            | 1644          |
| total timesteps         | 342300        |
| value_loss              | 0.00030839298 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018902348  |
| ent_coef_loss           | -2.9215205    |
| entropy                 | 3.1482275     |
| ep_rewmean              | -2.12         |
| episodes                | 3428          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 342601        |
| policy_loss             | 0.9749045     |
| qf1_loss                | 0.0009303935  |
| qf2_loss                | 0.00066714233 |
| time_elapsed            | 1646          |
| total timesteps         | 342700        |
| value_loss              | 0.0007786064  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018672794  |
| ent_coef_loss           | 8.358143      |
| entropy                 | 2.9836905     |
| ep_rewmean              | -2.14         |
| episodes                | 3432          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 343001        |
| policy_loss             | 0.8849932     |
| qf1_loss                | 0.0058839335  |
| qf2_loss                | 0.005931252   |
| time_elapsed            | 1648          |
| total timesteps         | 343100        |
| value_loss              | 0.00038569293 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018167499  |
| ent_coef_loss           | -2.5834167    |
| entropy                 | 2.9527402     |
| ep_rewmean              | -2.14         |
| episodes                | 3436          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 343401        |
| policy_loss             | 0.8813601     |
| qf1_loss                | 0.0008179036  |
| qf2_loss                | 0.00081757514 |
| time_elapsed            | 1650          |
| total timesteps         | 343500        |
| value_loss              | 0.00030561528 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018397602  |
| ent_coef_loss           | 5.3804884     |
| entropy                 | 3.188219      |
| ep_rewmean              | -2.15         |
| episodes                | 3440          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 343801        |
| policy_loss             | 0.95719934    |
| qf1_loss                | 0.0017797742  |
| qf2_loss                | 0.0015654066  |
| time_elapsed            | 1652          |
| total timesteps         | 343900        |
| value_loss              | 0.00022719591 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019059278  |
| ent_coef_loss           | 1.5177262     |
| entropy                 | 3.422731      |
| ep_rewmean              | -2.17         |
| episodes                | 3444          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 344201        |
| policy_loss             | 0.931908      |
| qf1_loss                | 0.000677594   |
| qf2_loss                | 0.0005204229  |
| time_elapsed            | 1654          |
| total timesteps         | 344300        |
| value_loss              | 0.00035255522 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019399985  |
| ent_coef_loss           | 2.896808      |
| entropy                 | 3.122013      |
| ep_rewmean              | -2.19         |
| episodes                | 3448          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 344601        |
| policy_loss             | 0.94990003    |
| qf1_loss                | 0.00026995916 |
| qf2_loss                | 0.00026638442 |
| time_elapsed            | 1656          |
| total timesteps         | 344700        |
| value_loss              | 0.0003547866  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019732232  |
| ent_coef_loss           | -1.1302679    |
| entropy                 | 3.2123482     |
| ep_rewmean              | -2.18         |
| episodes                | 3452          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 345001        |
| policy_loss             | 0.9176049     |
| qf1_loss                | 0.0008978243  |
| qf2_loss                | 0.00067924405 |
| time_elapsed            | 1658          |
| total timesteps         | 345100        |
| value_loss              | 0.00064312783 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018877856  |
| ent_coef_loss           | -4.7430067    |
| entropy                 | 3.426774      |
| ep_rewmean              | -2.21         |
| episodes                | 3456          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 345401        |
| policy_loss             | 0.8704902     |
| qf1_loss                | 0.0004940785  |
| qf2_loss                | 0.00044722814 |
| time_elapsed            | 1660          |
| total timesteps         | 345500        |
| value_loss              | 0.0003895891  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016735632  |
| ent_coef_loss           | -6.1032076    |
| entropy                 | 3.0566823     |
| ep_rewmean              | -2.23         |
| episodes                | 3460          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 345801        |
| policy_loss             | 0.9089554     |
| qf1_loss                | 0.01576146    |
| qf2_loss                | 0.015603251   |
| time_elapsed            | 1661          |
| total timesteps         | 345900        |
| value_loss              | 0.00023805897 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015372453  |
| ent_coef_loss           | -6.826544     |
| entropy                 | 2.8929658     |
| ep_rewmean              | -2.21         |
| episodes                | 3464          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 346201        |
| policy_loss             | 0.895445      |
| qf1_loss                | 0.00030331148 |
| qf2_loss                | 0.00028501477 |
| time_elapsed            | 1663          |
| total timesteps         | 346300        |
| value_loss              | 0.00013828024 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015025175  |
| ent_coef_loss           | -3.4983127    |
| entropy                 | 3.3295248     |
| ep_rewmean              | -2.21         |
| episodes                | 3468          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 346601        |
| policy_loss             | 0.89979136    |
| qf1_loss                | 0.003307189   |
| qf2_loss                | 0.0027173543  |
| time_elapsed            | 1665          |
| total timesteps         | 346700        |
| value_loss              | 0.00031085318 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015333097  |
| ent_coef_loss           | 3.9265842     |
| entropy                 | 2.864974      |
| ep_rewmean              | -2.22         |
| episodes                | 3472          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 347001        |
| policy_loss             | 0.8044648     |
| qf1_loss                | 0.01763125    |
| qf2_loss                | 0.017646695   |
| time_elapsed            | 1667          |
| total timesteps         | 347100        |
| value_loss              | 0.00029671902 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001458559   |
| ent_coef_loss           | -4.0402617    |
| entropy                 | 2.4813294     |
| ep_rewmean              | -2.18         |
| episodes                | 3476          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 347401        |
| policy_loss             | 0.8824975     |
| qf1_loss                | 0.00031559926 |
| qf2_loss                | 0.00026908674 |
| time_elapsed            | 1669          |
| total timesteps         | 347500        |
| value_loss              | 0.0002499207  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001352082   |
| ent_coef_loss           | -6.59841      |
| entropy                 | 2.6428182     |
| ep_rewmean              | -2.11         |
| episodes                | 3480          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 347801        |
| policy_loss             | 0.8051002     |
| qf1_loss                | 0.00037359822 |
| qf2_loss                | 0.00023896375 |
| time_elapsed            | 1671          |
| total timesteps         | 347900        |
| value_loss              | 0.00018261769 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013767714  |
| ent_coef_loss           | -5.3377814    |
| entropy                 | 2.8143632     |
| ep_rewmean              | -2.1          |
| episodes                | 3484          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 348201        |
| policy_loss             | 0.86135733    |
| qf1_loss                | 0.0030142933  |
| qf2_loss                | 0.002639681   |
| time_elapsed            | 1673          |
| total timesteps         | 348300        |
| value_loss              | 0.00027907133 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013175242  |
| ent_coef_loss           | 1.0043588     |
| entropy                 | 2.7819982     |
| ep_rewmean              | -2.11         |
| episodes                | 3488          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 348601        |
| policy_loss             | 0.90294975    |
| qf1_loss                | 0.0023607123  |
| qf2_loss                | 0.0022459647  |
| time_elapsed            | 1675          |
| total timesteps         | 348700        |
| value_loss              | 0.00020039533 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013898918  |
| ent_coef_loss           | -4.8704863    |
| entropy                 | 2.6994312     |
| ep_rewmean              | -2.08         |
| episodes                | 3492          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 349001        |
| policy_loss             | 0.8303713     |
| qf1_loss                | 0.0045142486  |
| qf2_loss                | 0.0040383902  |
| time_elapsed            | 1677          |
| total timesteps         | 349100        |
| value_loss              | 0.00019030835 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013786345  |
| ent_coef_loss           | -10.690167    |
| entropy                 | 2.4484842     |
| ep_rewmean              | -2.08         |
| episodes                | 3496          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 349401        |
| policy_loss             | 0.80889493    |
| qf1_loss                | 0.009749639   |
| qf2_loss                | 0.009907709   |
| time_elapsed            | 1678          |
| total timesteps         | 349500        |
| value_loss              | 0.00035597454 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013306916  |
| ent_coef_loss           | 0.5859316     |
| entropy                 | 2.3857975     |
| ep_rewmean              | -2.05         |
| episodes                | 3500          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 349801        |
| policy_loss             | 0.8242979     |
| qf1_loss                | 0.00045481953 |
| qf2_loss                | 0.0004150932  |
| time_elapsed            | 1680          |
| total timesteps         | 349900        |
| value_loss              | 0.00017363954 |
-------------------------------------------
Eval num_timesteps=350000, episode_reward=-2.30 +/- 0.75
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013257079  |
| ent_coef_loss           | 2.166215      |
| entropy                 | 2.5013309     |
| ep_rewmean              | -2            |
| episodes                | 3504          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 350201        |
| policy_loss             | 0.75373006    |
| qf1_loss                | 0.00034767474 |
| qf2_loss                | 0.00034714513 |
| time_elapsed            | 1682          |
| total timesteps         | 350300        |
| value_loss              | 0.00019557381 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013150988  |
| ent_coef_loss           | 2.8665977     |
| entropy                 | 2.419436      |
| ep_rewmean              | -1.96         |
| episodes                | 3508          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 350601        |
| policy_loss             | 0.8294541     |
| qf1_loss                | 0.000376818   |
| qf2_loss                | 0.00030948094 |
| time_elapsed            | 1684          |
| total timesteps         | 350700        |
| value_loss              | 0.00028691706 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013166694  |
| ent_coef_loss           | -8.685029     |
| entropy                 | 2.7689133     |
| ep_rewmean              | -1.96         |
| episodes                | 3512          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 351001        |
| policy_loss             | 0.7497461     |
| qf1_loss                | 0.0023629635  |
| qf2_loss                | 0.002322186   |
| time_elapsed            | 1686          |
| total timesteps         | 351100        |
| value_loss              | 0.00017906644 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012837553  |
| ent_coef_loss           | -5.09173      |
| entropy                 | 2.4949894     |
| ep_rewmean              | -1.97         |
| episodes                | 3516          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 351401        |
| policy_loss             | 0.7741864     |
| qf1_loss                | 0.0024345433  |
| qf2_loss                | 0.0022013998  |
| time_elapsed            | 1688          |
| total timesteps         | 351500        |
| value_loss              | 0.00028483954 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012116391  |
| ent_coef_loss           | -6.597597     |
| entropy                 | 2.5528755     |
| ep_rewmean              | -1.92         |
| episodes                | 3520          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 351801        |
| policy_loss             | 0.80330145    |
| qf1_loss                | 0.006150552   |
| qf2_loss                | 0.0055237436  |
| time_elapsed            | 1690          |
| total timesteps         | 351900        |
| value_loss              | 0.00016843899 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012279294  |
| ent_coef_loss           | 3.3041332     |
| entropy                 | 2.889352      |
| ep_rewmean              | -1.91         |
| episodes                | 3524          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 352201        |
| policy_loss             | 0.84470814    |
| qf1_loss                | 0.00034236998 |
| qf2_loss                | 0.00024863344 |
| time_elapsed            | 1692          |
| total timesteps         | 352300        |
| value_loss              | 0.00022811421 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011643849  |
| ent_coef_loss           | 0.32040745    |
| entropy                 | 2.0067668     |
| ep_rewmean              | -1.88         |
| episodes                | 3528          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 352601        |
| policy_loss             | 0.73967546    |
| qf1_loss                | 0.0005041934  |
| qf2_loss                | 0.00034063694 |
| time_elapsed            | 1694          |
| total timesteps         | 352700        |
| value_loss              | 0.00021750941 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011570542  |
| ent_coef_loss           | 11.810022     |
| entropy                 | 1.921365      |
| ep_rewmean              | -1.84         |
| episodes                | 3532          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 353001        |
| policy_loss             | 0.77867305    |
| qf1_loss                | 0.0032572872  |
| qf2_loss                | 0.003164427   |
| time_elapsed            | 1696          |
| total timesteps         | 353100        |
| value_loss              | 0.00025434385 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012267408 |
| ent_coef_loss           | -2.8341408   |
| entropy                 | 2.6976128    |
| ep_rewmean              | -1.85        |
| episodes                | 3536         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.9         |
| n_updates               | 353401       |
| policy_loss             | 0.84522295   |
| qf1_loss                | 0.01334997   |
| qf2_loss                | 0.011251194  |
| time_elapsed            | 1698         |
| total timesteps         | 353500       |
| value_loss              | 0.0001684852 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011404059  |
| ent_coef_loss           | 2.1271307     |
| entropy                 | 2.106378      |
| ep_rewmean              | -1.84         |
| episodes                | 3540          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 353801        |
| policy_loss             | 0.74869704    |
| qf1_loss                | 0.0042047594  |
| qf2_loss                | 0.003774181   |
| time_elapsed            | 1700          |
| total timesteps         | 353900        |
| value_loss              | 0.00029838504 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011738805  |
| ent_coef_loss           | -1.8723805    |
| entropy                 | 2.722383      |
| ep_rewmean              | -1.81         |
| episodes                | 3544          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 354201        |
| policy_loss             | 0.7532493     |
| qf1_loss                | 0.00022904351 |
| qf2_loss                | 0.00039694662 |
| time_elapsed            | 1702          |
| total timesteps         | 354300        |
| value_loss              | 0.00016945119 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010468108 |
| ent_coef_loss           | -6.699204    |
| entropy                 | 2.2175822    |
| ep_rewmean              | -1.77        |
| episodes                | 3548         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.8         |
| n_updates               | 354601       |
| policy_loss             | 0.77737916   |
| qf1_loss                | 0.005619483  |
| qf2_loss                | 0.0058704317 |
| time_elapsed            | 1704         |
| total timesteps         | 354700       |
| value_loss              | 0.0002075579 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00093544583 |
| ent_coef_loss           | -10.065189    |
| entropy                 | 2.4753995     |
| ep_rewmean              | -1.73         |
| episodes                | 3552          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 355001        |
| policy_loss             | 0.8049299     |
| qf1_loss                | 0.00040946133 |
| qf2_loss                | 0.00028017108 |
| time_elapsed            | 1706          |
| total timesteps         | 355100        |
| value_loss              | 0.00019250793 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009272323  |
| ent_coef_loss           | 5.476529      |
| entropy                 | 2.1333675     |
| ep_rewmean              | -1.73         |
| episodes                | 3556          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 355401        |
| policy_loss             | 0.8397923     |
| qf1_loss                | 0.00036664563 |
| qf2_loss                | 0.00023843157 |
| time_elapsed            | 1707          |
| total timesteps         | 355500        |
| value_loss              | 0.00025737082 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00095003744 |
| ent_coef_loss           | 4.6604633     |
| entropy                 | 1.8947647     |
| ep_rewmean              | -1.7          |
| episodes                | 3560          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 355801        |
| policy_loss             | 0.77345955    |
| qf1_loss                | 0.0003145537  |
| qf2_loss                | 0.0004506616  |
| time_elapsed            | 1709          |
| total timesteps         | 355900        |
| value_loss              | 0.00026442023 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010026867 |
| ent_coef_loss           | 3.6014376    |
| entropy                 | 2.3781433    |
| ep_rewmean              | -1.7         |
| episodes                | 3564         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.7         |
| n_updates               | 356201       |
| policy_loss             | 0.8101189    |
| qf1_loss                | 0.00169892   |
| qf2_loss                | 0.0014310101 |
| time_elapsed            | 1711         |
| total timesteps         | 356300       |
| value_loss              | 0.0005186973 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010897272  |
| ent_coef_loss           | 1.9316213     |
| entropy                 | 2.0143597     |
| ep_rewmean              | -1.68         |
| episodes                | 3568          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 356601        |
| policy_loss             | 0.79570955    |
| qf1_loss                | 0.000996637   |
| qf2_loss                | 0.0007571395  |
| time_elapsed            | 1713          |
| total timesteps         | 356700        |
| value_loss              | 0.00058910693 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011518335  |
| ent_coef_loss           | -2.8595695    |
| entropy                 | 2.748889      |
| ep_rewmean              | -1.61         |
| episodes                | 3572          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 357001        |
| policy_loss             | 0.7966725     |
| qf1_loss                | 0.00039280517 |
| qf2_loss                | 0.00037901432 |
| time_elapsed            | 1715          |
| total timesteps         | 357100        |
| value_loss              | 0.00031731988 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011405832  |
| ent_coef_loss           | -4.5467978    |
| entropy                 | 2.4699435     |
| ep_rewmean              | -1.58         |
| episodes                | 3576          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 357401        |
| policy_loss             | 0.85576963    |
| qf1_loss                | 0.00054804084 |
| qf2_loss                | 0.0006180671  |
| time_elapsed            | 1717          |
| total timesteps         | 357500        |
| value_loss              | 0.0004738261  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012556327  |
| ent_coef_loss           | 5.0832243     |
| entropy                 | 2.891245      |
| ep_rewmean              | -1.57         |
| episodes                | 3580          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 357801        |
| policy_loss             | 0.8589621     |
| qf1_loss                | 0.0016246836  |
| qf2_loss                | 0.0017448276  |
| time_elapsed            | 1719          |
| total timesteps         | 357900        |
| value_loss              | 0.00088960386 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012500577  |
| ent_coef_loss           | -3.9911146    |
| entropy                 | 2.6861653     |
| ep_rewmean              | -1.55         |
| episodes                | 3584          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 358201        |
| policy_loss             | 0.90149546    |
| qf1_loss                | 0.00033913966 |
| qf2_loss                | 0.0004011361  |
| time_elapsed            | 1721          |
| total timesteps         | 358300        |
| value_loss              | 0.0003289414  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012456279  |
| ent_coef_loss           | -2.8109646    |
| entropy                 | 2.8835683     |
| ep_rewmean              | -1.57         |
| episodes                | 3588          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 358601        |
| policy_loss             | 0.83752143    |
| qf1_loss                | 0.0036963788  |
| qf2_loss                | 0.003436671   |
| time_elapsed            | 1723          |
| total timesteps         | 358700        |
| value_loss              | 0.00030384515 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012135229  |
| ent_coef_loss           | -5.8720703    |
| entropy                 | 2.8185382     |
| ep_rewmean              | -1.52         |
| episodes                | 3592          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.5          |
| n_updates               | 359001        |
| policy_loss             | 0.8369583     |
| qf1_loss                | 0.00043731116 |
| qf2_loss                | 0.00035710842 |
| time_elapsed            | 1725          |
| total timesteps         | 359100        |
| value_loss              | 0.0002928765  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011375286 |
| ent_coef_loss           | 8.666775     |
| entropy                 | 2.1283197    |
| ep_rewmean              | -1.5         |
| episodes                | 3596         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.5         |
| n_updates               | 359401       |
| policy_loss             | 0.8320645    |
| qf1_loss                | 0.010360439  |
| qf2_loss                | 0.010304769  |
| time_elapsed            | 1727         |
| total timesteps         | 359500       |
| value_loss              | 0.0004034243 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010911868  |
| ent_coef_loss           | -0.43110418   |
| entropy                 | 2.2065773     |
| ep_rewmean              | -1.53         |
| episodes                | 3600          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.5          |
| n_updates               | 359801        |
| policy_loss             | 0.8222178     |
| qf1_loss                | 0.005770981   |
| qf2_loss                | 0.005767083   |
| time_elapsed            | 1728          |
| total timesteps         | 359900        |
| value_loss              | 0.00029190956 |
-------------------------------------------
Eval num_timesteps=360000, episode_reward=-1.41 +/- 1.23
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010652286  |
| ent_coef_loss           | 2.8621893     |
| entropy                 | 2.4707422     |
| ep_rewmean              | -1.54         |
| episodes                | 3604          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.5          |
| n_updates               | 360201        |
| policy_loss             | 0.82144284    |
| qf1_loss                | 0.0002050563  |
| qf2_loss                | 0.00031668154 |
| time_elapsed            | 1731          |
| total timesteps         | 360300        |
| value_loss              | 0.00025375368 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001121396  |
| ent_coef_loss           | 1.191746     |
| entropy                 | 2.4307785    |
| ep_rewmean              | -1.51        |
| episodes                | 3608         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.5         |
| n_updates               | 360601       |
| policy_loss             | 0.81408817   |
| qf1_loss                | 0.0014574903 |
| qf2_loss                | 0.0013584777 |
| time_elapsed            | 1733         |
| total timesteps         | 360700       |
| value_loss              | 0.0001602913 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001185172   |
| ent_coef_loss           | 5.5933113     |
| entropy                 | 2.7467606     |
| ep_rewmean              | -1.48         |
| episodes                | 3612          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.5          |
| n_updates               | 361001        |
| policy_loss             | 0.82746804    |
| qf1_loss                | 0.00024799615 |
| qf2_loss                | 0.00025088474 |
| time_elapsed            | 1734          |
| total timesteps         | 361100        |
| value_loss              | 0.00023237464 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001233248  |
| ent_coef_loss           | -0.35212815  |
| entropy                 | 2.8043199    |
| ep_rewmean              | -1.46        |
| episodes                | 3616         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.5         |
| n_updates               | 361401       |
| policy_loss             | 0.8408909    |
| qf1_loss                | 0.011193244  |
| qf2_loss                | 0.01134764   |
| time_elapsed            | 1736         |
| total timesteps         | 361500       |
| value_loss              | 0.0002067033 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012398714  |
| ent_coef_loss           | 1.7999139     |
| entropy                 | 2.5094838     |
| ep_rewmean              | -1.51         |
| episodes                | 3620          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.5          |
| n_updates               | 361801        |
| policy_loss             | 0.87608224    |
| qf1_loss                | 0.00023991965 |
| qf2_loss                | 0.00031154093 |
| time_elapsed            | 1738          |
| total timesteps         | 361900        |
| value_loss              | 0.00024706655 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012003478  |
| ent_coef_loss           | -0.9411878    |
| entropy                 | 2.257152      |
| ep_rewmean              | -1.54         |
| episodes                | 3624          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.5          |
| n_updates               | 362201        |
| policy_loss             | 0.87939334    |
| qf1_loss                | 0.009152951   |
| qf2_loss                | 0.009541473   |
| time_elapsed            | 1740          |
| total timesteps         | 362300        |
| value_loss              | 0.00013372855 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012329888  |
| ent_coef_loss           | 2.5886269     |
| entropy                 | 2.5112047     |
| ep_rewmean              | -1.56         |
| episodes                | 3628          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 362601        |
| policy_loss             | 0.8755907     |
| qf1_loss                | 0.0002445671  |
| qf2_loss                | 0.0003044495  |
| time_elapsed            | 1742          |
| total timesteps         | 362700        |
| value_loss              | 0.00031349668 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014103712  |
| ent_coef_loss           | -4.004183     |
| entropy                 | 2.7358623     |
| ep_rewmean              | -1.58         |
| episodes                | 3632          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 363001        |
| policy_loss             | 0.8651586     |
| qf1_loss                | 0.00025446492 |
| qf2_loss                | 0.00027671224 |
| time_elapsed            | 1744          |
| total timesteps         | 363100        |
| value_loss              | 0.00014843533 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014673808  |
| ent_coef_loss           | 1.7416828     |
| entropy                 | 2.7529733     |
| ep_rewmean              | -1.63         |
| episodes                | 3636          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 363401        |
| policy_loss             | 0.85353315    |
| qf1_loss                | 0.00078040804 |
| qf2_loss                | 0.00043765013 |
| time_elapsed            | 1746          |
| total timesteps         | 363500        |
| value_loss              | 0.00017445092 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014938784  |
| ent_coef_loss           | 2.1586003     |
| entropy                 | 2.751364      |
| ep_rewmean              | -1.64         |
| episodes                | 3640          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 363801        |
| policy_loss             | 0.9184161     |
| qf1_loss                | 0.00026791444 |
| qf2_loss                | 0.00027629337 |
| time_elapsed            | 1748          |
| total timesteps         | 363900        |
| value_loss              | 0.00029903598 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014728324  |
| ent_coef_loss           | 0.98967505    |
| entropy                 | 3.1283393     |
| ep_rewmean              | -1.64         |
| episodes                | 3644          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 364201        |
| policy_loss             | 0.913922      |
| qf1_loss                | 0.0003083453  |
| qf2_loss                | 0.00037392887 |
| time_elapsed            | 1750          |
| total timesteps         | 364300        |
| value_loss              | 0.0002054777  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014489995  |
| ent_coef_loss           | 0.6111158     |
| entropy                 | 2.67447       |
| ep_rewmean              | -1.66         |
| episodes                | 3648          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 364601        |
| policy_loss             | 0.9119238     |
| qf1_loss                | 0.00031747197 |
| qf2_loss                | 0.00017385579 |
| time_elapsed            | 1752          |
| total timesteps         | 364700        |
| value_loss              | 0.00037255458 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013766249 |
| ent_coef_loss           | 5.700289     |
| entropy                 | 2.482195     |
| ep_rewmean              | -1.68        |
| episodes                | 3652         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.7         |
| n_updates               | 365001       |
| policy_loss             | 0.8707509    |
| qf1_loss                | 0.0011537223 |
| qf2_loss                | 0.0008068924 |
| time_elapsed            | 1754         |
| total timesteps         | 365100       |
| value_loss              | 0.0003868727 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014147641  |
| ent_coef_loss           | -6.349249     |
| entropy                 | 2.5955095     |
| ep_rewmean              | -1.67         |
| episodes                | 3656          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 365401        |
| policy_loss             | 0.9327471     |
| qf1_loss                | 0.009919153   |
| qf2_loss                | 0.010270914   |
| time_elapsed            | 1756          |
| total timesteps         | 365500        |
| value_loss              | 0.00015698877 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014358743  |
| ent_coef_loss           | -13.1639      |
| entropy                 | 2.6424975     |
| ep_rewmean              | -1.7          |
| episodes                | 3660          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 365801        |
| policy_loss             | 0.909137      |
| qf1_loss                | 0.00028267025 |
| qf2_loss                | 0.00025067112 |
| time_elapsed            | 1757          |
| total timesteps         | 365900        |
| value_loss              | 0.00034855976 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014541465  |
| ent_coef_loss           | 6.3602815     |
| entropy                 | 3.0547886     |
| ep_rewmean              | -1.71         |
| episodes                | 3664          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 366201        |
| policy_loss             | 0.8903668     |
| qf1_loss                | 0.0002848963  |
| qf2_loss                | 0.000194795   |
| time_elapsed            | 1759          |
| total timesteps         | 366300        |
| value_loss              | 0.00029231305 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014578212  |
| ent_coef_loss           | 4.665165      |
| entropy                 | 2.9060993     |
| ep_rewmean              | -1.68         |
| episodes                | 3668          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 366601        |
| policy_loss             | 0.8972697     |
| qf1_loss                | 0.013394114   |
| qf2_loss                | 0.014005732   |
| time_elapsed            | 1761          |
| total timesteps         | 366700        |
| value_loss              | 0.00027144584 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014578657  |
| ent_coef_loss           | 11.5355625    |
| entropy                 | 2.7519374     |
| ep_rewmean              | -1.75         |
| episodes                | 3672          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 367001        |
| policy_loss             | 0.8802711     |
| qf1_loss                | 0.00025400004 |
| qf2_loss                | 0.00026507123 |
| time_elapsed            | 1763          |
| total timesteps         | 367100        |
| value_loss              | 0.00039553628 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014797375  |
| ent_coef_loss           | -6.389914     |
| entropy                 | 2.9450178     |
| ep_rewmean              | -1.77         |
| episodes                | 3676          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 367401        |
| policy_loss             | 0.90699244    |
| qf1_loss                | 0.00021522153 |
| qf2_loss                | 0.00029647903 |
| time_elapsed            | 1765          |
| total timesteps         | 367500        |
| value_loss              | 0.00036260797 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013686718  |
| ent_coef_loss           | -7.8762727    |
| entropy                 | 2.9732137     |
| ep_rewmean              | -1.78         |
| episodes                | 3680          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 367801        |
| policy_loss             | 0.89897764    |
| qf1_loss                | 0.00026205624 |
| qf2_loss                | 0.00020743956 |
| time_elapsed            | 1767          |
| total timesteps         | 367900        |
| value_loss              | 0.0002084492  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012750692  |
| ent_coef_loss           | 2.9191246     |
| entropy                 | 2.5261521     |
| ep_rewmean              | -1.79         |
| episodes                | 3684          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 368201        |
| policy_loss             | 0.92448556    |
| qf1_loss                | 0.0008746886  |
| qf2_loss                | 0.00062875735 |
| time_elapsed            | 1769          |
| total timesteps         | 368300        |
| value_loss              | 0.00022787527 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012477102  |
| ent_coef_loss           | -14.158205    |
| entropy                 | 3.0573928     |
| ep_rewmean              | -1.81         |
| episodes                | 3688          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 368601        |
| policy_loss             | 0.92515564    |
| qf1_loss                | 0.007907609   |
| qf2_loss                | 0.007623433   |
| time_elapsed            | 1771          |
| total timesteps         | 368700        |
| value_loss              | 0.00019546057 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012019401  |
| ent_coef_loss           | 4.304878      |
| entropy                 | 2.141876      |
| ep_rewmean              | -1.86         |
| episodes                | 3692          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 369001        |
| policy_loss             | 0.89574194    |
| qf1_loss                | 0.014409503   |
| qf2_loss                | 0.01409255    |
| time_elapsed            | 1773          |
| total timesteps         | 369100        |
| value_loss              | 0.00017728118 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001319058   |
| ent_coef_loss           | 6.8485036     |
| entropy                 | 2.4814749     |
| ep_rewmean              | -1.86         |
| episodes                | 3696          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 369401        |
| policy_loss             | 0.91141677    |
| qf1_loss                | 0.012335797   |
| qf2_loss                | 0.012913938   |
| time_elapsed            | 1775          |
| total timesteps         | 369500        |
| value_loss              | 0.00012511028 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013750892  |
| ent_coef_loss           | -1.8246803    |
| entropy                 | 2.2071514     |
| ep_rewmean              | -1.87         |
| episodes                | 3700          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 369801        |
| policy_loss             | 0.89045       |
| qf1_loss                | 0.01014085    |
| qf2_loss                | 0.010835919   |
| time_elapsed            | 1777          |
| total timesteps         | 369900        |
| value_loss              | 0.00021739592 |
-------------------------------------------
Eval num_timesteps=370000, episode_reward=-1.76 +/- 0.99
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013420432  |
| ent_coef_loss           | 0.49748385    |
| entropy                 | 2.5085006     |
| ep_rewmean              | -1.95         |
| episodes                | 3704          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 370201        |
| policy_loss             | 0.85933554    |
| qf1_loss                | 0.00023955185 |
| qf2_loss                | 0.00022804784 |
| time_elapsed            | 1779          |
| total timesteps         | 370300        |
| value_loss              | 0.00014032729 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001325986   |
| ent_coef_loss           | 2.1676774     |
| entropy                 | 2.5188823     |
| ep_rewmean              | -2.09         |
| episodes                | 3708          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 370601        |
| policy_loss             | 0.8399745     |
| qf1_loss                | 0.00027951348 |
| qf2_loss                | 0.00033242512 |
| time_elapsed            | 1781          |
| total timesteps         | 370700        |
| value_loss              | 0.00014129319 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013401374  |
| ent_coef_loss           | 3.4825902     |
| entropy                 | 2.1370254     |
| ep_rewmean              | -2.16         |
| episodes                | 3712          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 371001        |
| policy_loss             | 0.85474265    |
| qf1_loss                | 0.0050819675  |
| qf2_loss                | 0.005063507   |
| time_elapsed            | 1783          |
| total timesteps         | 371100        |
| value_loss              | 0.00019280307 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012677384  |
| ent_coef_loss           | 3.6039824     |
| entropy                 | 1.7370613     |
| ep_rewmean              | -2.26         |
| episodes                | 3716          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 371401        |
| policy_loss             | 0.8953583     |
| qf1_loss                | 0.00019674776 |
| qf2_loss                | 0.00020194531 |
| time_elapsed            | 1784          |
| total timesteps         | 371500        |
| value_loss              | 0.00012645811 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012742935  |
| ent_coef_loss           | -2.7018018    |
| entropy                 | 2.3627806     |
| ep_rewmean              | -2.27         |
| episodes                | 3720          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 371801        |
| policy_loss             | 0.91281515    |
| qf1_loss                | 0.00023882752 |
| qf2_loss                | 0.0002121626  |
| time_elapsed            | 1786          |
| total timesteps         | 371900        |
| value_loss              | 0.00022603144 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012553633  |
| ent_coef_loss           | -2.5137458    |
| entropy                 | 1.8966885     |
| ep_rewmean              | -2.25         |
| episodes                | 3724          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 372201        |
| policy_loss             | 0.88947845    |
| qf1_loss                | 0.0002667625  |
| qf2_loss                | 0.00029599504 |
| time_elapsed            | 1788          |
| total timesteps         | 372300        |
| value_loss              | 0.0005635214  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013280673  |
| ent_coef_loss           | -1.4333471    |
| entropy                 | 2.3272817     |
| ep_rewmean              | -2.27         |
| episodes                | 3728          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 372601        |
| policy_loss             | 0.88785076    |
| qf1_loss                | 0.00035305423 |
| qf2_loss                | 0.0004847457  |
| time_elapsed            | 1790          |
| total timesteps         | 372700        |
| value_loss              | 0.00017339858 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013746211  |
| ent_coef_loss           | 0.47992665    |
| entropy                 | 2.2175493     |
| ep_rewmean              | -2.28         |
| episodes                | 3732          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 373001        |
| policy_loss             | 0.87036335    |
| qf1_loss                | 0.00033940858 |
| qf2_loss                | 0.00024042817 |
| time_elapsed            | 1792          |
| total timesteps         | 373100        |
| value_loss              | 0.00014447686 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001417038   |
| ent_coef_loss           | 7.2185626     |
| entropy                 | 1.4183362     |
| ep_rewmean              | -2.19         |
| episodes                | 3736          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 373401        |
| policy_loss             | 0.8223047     |
| qf1_loss                | 0.00038196758 |
| qf2_loss                | 0.00037336582 |
| time_elapsed            | 1794          |
| total timesteps         | 373500        |
| value_loss              | 0.00033178285 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001416137   |
| ent_coef_loss           | -1.9735423    |
| entropy                 | 1.9378002     |
| ep_rewmean              | -2.19         |
| episodes                | 3740          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 373801        |
| policy_loss             | 0.84452796    |
| qf1_loss                | 0.00026308742 |
| qf2_loss                | 0.00031671603 |
| time_elapsed            | 1796          |
| total timesteps         | 373900        |
| value_loss              | 0.0002989832  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001410088   |
| ent_coef_loss           | -3.2317326    |
| entropy                 | 2.0112863     |
| ep_rewmean              | -2.19         |
| episodes                | 3744          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 374201        |
| policy_loss             | 0.8614374     |
| qf1_loss                | 0.0003811632  |
| qf2_loss                | 0.00037728518 |
| time_elapsed            | 1798          |
| total timesteps         | 374300        |
| value_loss              | 0.00021308733 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014756978  |
| ent_coef_loss           | 4.7875023     |
| entropy                 | 1.8836551     |
| ep_rewmean              | -2.22         |
| episodes                | 3748          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 374601        |
| policy_loss             | 0.82286716    |
| qf1_loss                | 0.0045463527  |
| qf2_loss                | 0.0042243283  |
| time_elapsed            | 1800          |
| total timesteps         | 374700        |
| value_loss              | 0.00027638275 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015703636  |
| ent_coef_loss           | 4.4100795     |
| entropy                 | 2.4082458     |
| ep_rewmean              | -2.24         |
| episodes                | 3752          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 375001        |
| policy_loss             | 0.8748093     |
| qf1_loss                | 0.00021710526 |
| qf2_loss                | 0.00019688478 |
| time_elapsed            | 1802          |
| total timesteps         | 375100        |
| value_loss              | 0.00014803131 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016834051  |
| ent_coef_loss           | 8.644703      |
| entropy                 | 2.7259557     |
| ep_rewmean              | -2.24         |
| episodes                | 3756          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 375401        |
| policy_loss             | 0.8491447     |
| qf1_loss                | 0.011901274   |
| qf2_loss                | 0.012390279   |
| time_elapsed            | 1804          |
| total timesteps         | 375500        |
| value_loss              | 0.00032032462 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016583474  |
| ent_coef_loss           | -6.617217     |
| entropy                 | 2.453797      |
| ep_rewmean              | -2.23         |
| episodes                | 3760          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 375801        |
| policy_loss             | 0.8708108     |
| qf1_loss                | 0.00023314585 |
| qf2_loss                | 0.00021044785 |
| time_elapsed            | 1806          |
| total timesteps         | 375900        |
| value_loss              | 0.00024851208 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001624536   |
| ent_coef_loss           | -4.851612     |
| entropy                 | 2.2018774     |
| ep_rewmean              | -2.29         |
| episodes                | 3764          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 376201        |
| policy_loss             | 0.8145007     |
| qf1_loss                | 0.00029113458 |
| qf2_loss                | 0.0002660671  |
| time_elapsed            | 1807          |
| total timesteps         | 376300        |
| value_loss              | 0.0002585604  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015422512 |
| ent_coef_loss           | -5.1224303   |
| entropy                 | 2.3452148    |
| ep_rewmean              | -2.38        |
| episodes                | 3768         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.4         |
| n_updates               | 376601       |
| policy_loss             | 0.7901426    |
| qf1_loss                | 0.0019668858 |
| qf2_loss                | 0.0018437321 |
| time_elapsed            | 1809         |
| total timesteps         | 376700       |
| value_loss              | 0.000272363  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014000243 |
| ent_coef_loss           | -4.5483375   |
| entropy                 | 2.1584332    |
| ep_rewmean              | -2.33        |
| episodes                | 3772         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -2.3         |
| n_updates               | 377001       |
| policy_loss             | 0.8088181    |
| qf1_loss                | 0.0028464869 |
| qf2_loss                | 0.002864016  |
| time_elapsed            | 1811         |
| total timesteps         | 377100       |
| value_loss              | 0.0003597941 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013166568  |
| ent_coef_loss           | 0.25448227    |
| entropy                 | 1.6564959     |
| ep_rewmean              | -2.33         |
| episodes                | 3776          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 377401        |
| policy_loss             | 0.7900762     |
| qf1_loss                | 0.00035451    |
| qf2_loss                | 0.0002879567  |
| time_elapsed            | 1813          |
| total timesteps         | 377500        |
| value_loss              | 0.00026006944 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012724593  |
| ent_coef_loss           | -2.1119232    |
| entropy                 | 1.4033293     |
| ep_rewmean              | -2.28         |
| episodes                | 3780          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 377801        |
| policy_loss             | 0.75520647    |
| qf1_loss                | 0.00034226128 |
| qf2_loss                | 0.00031750178 |
| time_elapsed            | 1815          |
| total timesteps         | 377900        |
| value_loss              | 0.00023918031 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012303828  |
| ent_coef_loss           | 0.1153326     |
| entropy                 | 1.4294858     |
| ep_rewmean              | -2.27         |
| episodes                | 3784          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.3          |
| n_updates               | 378201        |
| policy_loss             | 0.79203045    |
| qf1_loss                | 0.00022739968 |
| qf2_loss                | 0.00042205938 |
| time_elapsed            | 1817          |
| total timesteps         | 378300        |
| value_loss              | 0.00020179499 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012111579  |
| ent_coef_loss           | -0.6863381    |
| entropy                 | 1.7380872     |
| ep_rewmean              | -2.21         |
| episodes                | 3788          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 378601        |
| policy_loss             | 0.7612282     |
| qf1_loss                | 0.004798338   |
| qf2_loss                | 0.0046863104  |
| time_elapsed            | 1819          |
| total timesteps         | 378700        |
| value_loss              | 0.00028016622 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012485571  |
| ent_coef_loss           | 0.6141487     |
| entropy                 | 1.4118406     |
| ep_rewmean              | -2.16         |
| episodes                | 3792          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.2          |
| n_updates               | 379001        |
| policy_loss             | 0.7443679     |
| qf1_loss                | 0.010002947   |
| qf2_loss                | 0.009817904   |
| time_elapsed            | 1821          |
| total timesteps         | 379100        |
| value_loss              | 0.00028141175 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012367496  |
| ent_coef_loss           | -0.87811446   |
| entropy                 | 1.8493881     |
| ep_rewmean              | -2.14         |
| episodes                | 3796          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 379401        |
| policy_loss             | 0.7569882     |
| qf1_loss                | 0.00024523487 |
| qf2_loss                | 0.00034365803 |
| time_elapsed            | 1823          |
| total timesteps         | 379500        |
| value_loss              | 0.00023335606 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012033714  |
| ent_coef_loss           | -2.9509025    |
| entropy                 | 1.7327771     |
| ep_rewmean              | -2.09         |
| episodes                | 3800          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 379801        |
| policy_loss             | 0.7542808     |
| qf1_loss                | 0.00042008617 |
| qf2_loss                | 0.0004337036  |
| time_elapsed            | 1825          |
| total timesteps         | 379900        |
| value_loss              | 0.0002175984  |
-------------------------------------------
Eval num_timesteps=380000, episode_reward=-0.73 +/- 0.32
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00118023    |
| ent_coef_loss           | 2.794003      |
| entropy                 | 1.7517711     |
| ep_rewmean              | -2.07         |
| episodes                | 3804          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2.1          |
| n_updates               | 380201        |
| policy_loss             | 0.72771907    |
| qf1_loss                | 0.00024659035 |
| qf2_loss                | 0.00027463597 |
| time_elapsed            | 1827          |
| total timesteps         | 380300        |
| value_loss              | 0.00013167027 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011557066  |
| ent_coef_loss           | -4.881978     |
| entropy                 | 2.1658247     |
| ep_rewmean              | -1.97         |
| episodes                | 3808          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -2            |
| n_updates               | 380601        |
| policy_loss             | 0.7381135     |
| qf1_loss                | 0.005482611   |
| qf2_loss                | 0.00546277    |
| time_elapsed            | 1829          |
| total timesteps         | 380700        |
| value_loss              | 0.00017710542 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012679573  |
| ent_coef_loss           | 7.3771567     |
| entropy                 | 2.2957544     |
| ep_rewmean              | -1.89         |
| episodes                | 3812          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 381001        |
| policy_loss             | 0.81021523    |
| qf1_loss                | 0.00410964    |
| qf2_loss                | 0.0042394954  |
| time_elapsed            | 1831          |
| total timesteps         | 381100        |
| value_loss              | 0.00021955055 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013614583  |
| ent_coef_loss           | 3.142601      |
| entropy                 | 2.0005195     |
| ep_rewmean              | -1.82         |
| episodes                | 3816          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 381401        |
| policy_loss             | 0.73935336    |
| qf1_loss                | 0.0004306034  |
| qf2_loss                | 0.0005225046  |
| time_elapsed            | 1833          |
| total timesteps         | 381500        |
| value_loss              | 0.00016896246 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013735878  |
| ent_coef_loss           | -1.2741833    |
| entropy                 | 2.5175471     |
| ep_rewmean              | -1.84         |
| episodes                | 3820          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 381801        |
| policy_loss             | 0.7617645     |
| qf1_loss                | 0.0031228755  |
| qf2_loss                | 0.0030154584  |
| time_elapsed            | 1835          |
| total timesteps         | 381900        |
| value_loss              | 0.00027103085 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013163135  |
| ent_coef_loss           | 6.6693187     |
| entropy                 | 2.466115      |
| ep_rewmean              | -1.88         |
| episodes                | 3824          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 382201        |
| policy_loss             | 0.80401254    |
| qf1_loss                | 0.00041159126 |
| qf2_loss                | 0.00038901548 |
| time_elapsed            | 1837          |
| total timesteps         | 382300        |
| value_loss              | 0.00036982223 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012171739  |
| ent_coef_loss           | -11.564848    |
| entropy                 | 2.2370868     |
| ep_rewmean              | -1.84         |
| episodes                | 3828          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 382601        |
| policy_loss             | 0.7627109     |
| qf1_loss                | 0.00027091472 |
| qf2_loss                | 0.000289596   |
| time_elapsed            | 1839          |
| total timesteps         | 382700        |
| value_loss              | 0.00020546617 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011493453  |
| ent_coef_loss           | 11.9825115    |
| entropy                 | 2.3809686     |
| ep_rewmean              | -1.86         |
| episodes                | 3832          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 383001        |
| policy_loss             | 0.7696921     |
| qf1_loss                | 0.005829476   |
| qf2_loss                | 0.005899515   |
| time_elapsed            | 1841          |
| total timesteps         | 383100        |
| value_loss              | 0.00023950843 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011333072  |
| ent_coef_loss           | -0.4476025    |
| entropy                 | 2.2634861     |
| ep_rewmean              | -1.87         |
| episodes                | 3836          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 383401        |
| policy_loss             | 0.7759513     |
| qf1_loss                | 0.004165087   |
| qf2_loss                | 0.004375034   |
| time_elapsed            | 1843          |
| total timesteps         | 383500        |
| value_loss              | 0.00024660167 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001189273   |
| ent_coef_loss           | 7.0800037     |
| entropy                 | 1.6799728     |
| ep_rewmean              | -1.88         |
| episodes                | 3840          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 383801        |
| policy_loss             | 0.72901404    |
| qf1_loss                | 0.00022438158 |
| qf2_loss                | 0.00028065318 |
| time_elapsed            | 1845          |
| total timesteps         | 383900        |
| value_loss              | 0.00015818274 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011454291  |
| ent_coef_loss           | -3.988875     |
| entropy                 | 2.0024693     |
| ep_rewmean              | -1.9          |
| episodes                | 3844          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 384201        |
| policy_loss             | 0.74211204    |
| qf1_loss                | 0.0053196116  |
| qf2_loss                | 0.0053543495  |
| time_elapsed            | 1847          |
| total timesteps         | 384300        |
| value_loss              | 0.00016397485 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011212683  |
| ent_coef_loss           | -1.5165392    |
| entropy                 | 2.4684486     |
| ep_rewmean              | -1.87         |
| episodes                | 3848          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.9          |
| n_updates               | 384601        |
| policy_loss             | 0.7677211     |
| qf1_loss                | 0.0039865505  |
| qf2_loss                | 0.0037865834  |
| time_elapsed            | 1849          |
| total timesteps         | 384700        |
| value_loss              | 0.00034024892 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001105692   |
| ent_coef_loss           | -7.0028095    |
| entropy                 | 2.7221718     |
| ep_rewmean              | -1.85         |
| episodes                | 3852          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 385001        |
| policy_loss             | 0.74309665    |
| qf1_loss                | 0.0008074146  |
| qf2_loss                | 0.0006045888  |
| time_elapsed            | 1851          |
| total timesteps         | 385100        |
| value_loss              | 0.00018843937 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010820242  |
| ent_coef_loss           | -1.604826     |
| entropy                 | 2.946542      |
| ep_rewmean              | -1.84         |
| episodes                | 3856          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 385401        |
| policy_loss             | 0.75938165    |
| qf1_loss                | 0.00015810903 |
| qf2_loss                | 0.0001666204  |
| time_elapsed            | 1853          |
| total timesteps         | 385500        |
| value_loss              | 0.00014755467 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009930618  |
| ent_coef_loss           | -3.6539485    |
| entropy                 | 1.9720901     |
| ep_rewmean              | -1.82         |
| episodes                | 3860          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 385801        |
| policy_loss             | 0.75269175    |
| qf1_loss                | 0.003790196   |
| qf2_loss                | 0.0038112276  |
| time_elapsed            | 1855          |
| total timesteps         | 385900        |
| value_loss              | 0.00016411909 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009492853  |
| ent_coef_loss           | 5.0588355     |
| entropy                 | 2.1344705     |
| ep_rewmean              | -1.73         |
| episodes                | 3864          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 386201        |
| policy_loss             | 0.7688376     |
| qf1_loss                | 0.00032854936 |
| qf2_loss                | 0.000225333   |
| time_elapsed            | 1857          |
| total timesteps         | 386300        |
| value_loss              | 0.00032367278 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00094273995 |
| ent_coef_loss           | 3.8800213     |
| entropy                 | 2.7192974     |
| ep_rewmean              | -1.66         |
| episodes                | 3868          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 386601        |
| policy_loss             | 0.7402469     |
| qf1_loss                | 0.0076914267  |
| qf2_loss                | 0.0081732245  |
| time_elapsed            | 1859          |
| total timesteps         | 386700        |
| value_loss              | 0.00019001521 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010345263  |
| ent_coef_loss           | 15.493465     |
| entropy                 | 2.9257727     |
| ep_rewmean              | -1.66         |
| episodes                | 3872          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 387001        |
| policy_loss             | 0.73186266    |
| qf1_loss                | 0.008177606   |
| qf2_loss                | 0.0083178645  |
| time_elapsed            | 1861          |
| total timesteps         | 387100        |
| value_loss              | 0.00018346145 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011081849  |
| ent_coef_loss           | -3.1694663    |
| entropy                 | 3.758594      |
| ep_rewmean              | -1.66         |
| episodes                | 3876          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 387401        |
| policy_loss             | 0.7772603     |
| qf1_loss                | 0.00016056685 |
| qf2_loss                | 0.00011371235 |
| time_elapsed            | 1862          |
| total timesteps         | 387500        |
| value_loss              | 0.00013824235 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011136687 |
| ent_coef_loss           | 0.030492783  |
| entropy                 | 3.633587     |
| ep_rewmean              | -1.73        |
| episodes                | 3880         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 387801       |
| policy_loss             | 0.75253034   |
| qf1_loss                | 0.0064063934 |
| qf2_loss                | 0.0062469016 |
| time_elapsed            | 1864         |
| total timesteps         | 387900       |
| value_loss              | 0.0001581659 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011744023  |
| ent_coef_loss           | -1.3752433    |
| entropy                 | 3.7130535     |
| ep_rewmean              | -1.75         |
| episodes                | 3884          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.7          |
| n_updates               | 388201        |
| policy_loss             | 0.7551884     |
| qf1_loss                | 0.0050520254  |
| qf2_loss                | 0.005070712   |
| time_elapsed            | 1866          |
| total timesteps         | 388300        |
| value_loss              | 0.00025507968 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011754808  |
| ent_coef_loss           | -1.6479456    |
| entropy                 | 3.337527      |
| ep_rewmean              | -1.77         |
| episodes                | 3888          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 388601        |
| policy_loss             | 0.78619206    |
| qf1_loss                | 0.009080422   |
| qf2_loss                | 0.009787354   |
| time_elapsed            | 1868          |
| total timesteps         | 388700        |
| value_loss              | 0.00015984564 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011734194  |
| ent_coef_loss           | 7.9443903     |
| entropy                 | 3.0939238     |
| ep_rewmean              | -1.79         |
| episodes                | 3892          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 389001        |
| policy_loss             | 0.7403474     |
| qf1_loss                | 0.005569655   |
| qf2_loss                | 0.0053951857  |
| time_elapsed            | 1870          |
| total timesteps         | 389100        |
| value_loss              | 0.00014662885 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011410336  |
| ent_coef_loss           | 6.4492054     |
| entropy                 | 3.5721111     |
| ep_rewmean              | -1.79         |
| episodes                | 3896          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 389401        |
| policy_loss             | 0.75650203    |
| qf1_loss                | 0.0022627194  |
| qf2_loss                | 0.0022158728  |
| time_elapsed            | 1872          |
| total timesteps         | 389500        |
| value_loss              | 0.00031903398 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011399754  |
| ent_coef_loss           | -9.878648     |
| entropy                 | 3.62994       |
| ep_rewmean              | -1.81         |
| episodes                | 3900          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 389801        |
| policy_loss             | 0.73346716    |
| qf1_loss                | 0.0045064054  |
| qf2_loss                | 0.0046205698  |
| time_elapsed            | 1874          |
| total timesteps         | 389900        |
| value_loss              | 0.00035053486 |
-------------------------------------------
Eval num_timesteps=390000, episode_reward=-1.55 +/- 0.48
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011300382  |
| ent_coef_loss           | -2.0292325    |
| entropy                 | 3.7882504     |
| ep_rewmean              | -1.82         |
| episodes                | 3904          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 390201        |
| policy_loss             | 0.77460986    |
| qf1_loss                | 0.007510563   |
| qf2_loss                | 0.0077130524  |
| time_elapsed            | 1876          |
| total timesteps         | 390300        |
| value_loss              | 0.00015544432 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011216137  |
| ent_coef_loss           | 3.462483      |
| entropy                 | 3.9306529     |
| ep_rewmean              | -1.8          |
| episodes                | 3908          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 390601        |
| policy_loss             | 0.7512201     |
| qf1_loss                | 0.00019378023 |
| qf2_loss                | 0.00014347937 |
| time_elapsed            | 1878          |
| total timesteps         | 390700        |
| value_loss              | 0.00018417444 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012414996  |
| ent_coef_loss           | 2.7845159     |
| entropy                 | 3.8151546     |
| ep_rewmean              | -1.82         |
| episodes                | 3912          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 391001        |
| policy_loss             | 0.80135006    |
| qf1_loss                | 0.0002677568  |
| qf2_loss                | 0.00026774377 |
| time_elapsed            | 1880          |
| total timesteps         | 391100        |
| value_loss              | 0.00011295934 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001308818   |
| ent_coef_loss           | -1.6866456    |
| entropy                 | 3.5627902     |
| ep_rewmean              | -1.83         |
| episodes                | 3916          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 391401        |
| policy_loss             | 0.7567854     |
| qf1_loss                | 0.0057730046  |
| qf2_loss                | 0.005738063   |
| time_elapsed            | 1882          |
| total timesteps         | 391500        |
| value_loss              | 0.00019384753 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001322264   |
| ent_coef_loss           | -3.7318852    |
| entropy                 | 3.8130682     |
| ep_rewmean              | -1.74         |
| episodes                | 3920          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 391801        |
| policy_loss             | 0.77522904    |
| qf1_loss                | 0.00024659262 |
| qf2_loss                | 0.00022878668 |
| time_elapsed            | 1884          |
| total timesteps         | 391900        |
| value_loss              | 0.00024999824 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0012786974   |
| ent_coef_loss           | -0.3365736     |
| entropy                 | 4.0962176      |
| ep_rewmean              | -1.72          |
| episodes                | 3924           |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -1.7           |
| n_updates               | 392201         |
| policy_loss             | 0.7784451      |
| qf1_loss                | 9.8399454e-05  |
| qf2_loss                | 9.9860656e-05  |
| time_elapsed            | 1886           |
| total timesteps         | 392300         |
| value_loss              | 0.000108019434 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012477471  |
| ent_coef_loss           | 3.553492      |
| entropy                 | 3.7119174     |
| ep_rewmean              | -1.72         |
| episodes                | 3928          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 392601        |
| policy_loss             | 0.72947305    |
| qf1_loss                | 0.0035775378  |
| qf2_loss                | 0.003524706   |
| time_elapsed            | 1888          |
| total timesteps         | 392700        |
| value_loss              | 0.00014226654 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012883865  |
| ent_coef_loss           | -1.9458618    |
| entropy                 | 3.7559218     |
| ep_rewmean              | -1.72         |
| episodes                | 3932          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 393001        |
| policy_loss             | 0.7739227     |
| qf1_loss                | 0.00016369729 |
| qf2_loss                | 0.00023308852 |
| time_elapsed            | 1890          |
| total timesteps         | 393100        |
| value_loss              | 0.00018018163 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012775692  |
| ent_coef_loss           | -1.4694473    |
| entropy                 | 3.593926      |
| ep_rewmean              | -1.72         |
| episodes                | 3936          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 393401        |
| policy_loss             | 0.82130975    |
| qf1_loss                | 0.00048521816 |
| qf2_loss                | 0.0003147077  |
| time_elapsed            | 1892          |
| total timesteps         | 393500        |
| value_loss              | 0.0002269939  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013001643  |
| ent_coef_loss           | 1.8837047     |
| entropy                 | 3.5520315     |
| ep_rewmean              | -1.72         |
| episodes                | 3940          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 393801        |
| policy_loss             | 0.7666245     |
| qf1_loss                | 0.00020473907 |
| qf2_loss                | 0.00028328408 |
| time_elapsed            | 1894          |
| total timesteps         | 393900        |
| value_loss              | 0.0001635491  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013770228  |
| ent_coef_loss           | 9.831884      |
| entropy                 | 3.75768       |
| ep_rewmean              | -1.76         |
| episodes                | 3944          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 394201        |
| policy_loss             | 0.74015284    |
| qf1_loss                | 0.00797676    |
| qf2_loss                | 0.0082718525  |
| time_elapsed            | 1896          |
| total timesteps         | 394300        |
| value_loss              | 0.00016446873 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013266539  |
| ent_coef_loss           | -4.2771826    |
| entropy                 | 3.4934475     |
| ep_rewmean              | -1.76         |
| episodes                | 3948          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 394601        |
| policy_loss             | 0.78078836    |
| qf1_loss                | 0.00022081652 |
| qf2_loss                | 0.00013304145 |
| time_elapsed            | 1897          |
| total timesteps         | 394700        |
| value_loss              | 0.00019810509 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012441794 |
| ent_coef_loss           | -6.070544    |
| entropy                 | 3.704368     |
| ep_rewmean              | -1.75        |
| episodes                | 3952         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 395001       |
| policy_loss             | 0.7504493    |
| qf1_loss                | 0.0055118278 |
| qf2_loss                | 0.0056385123 |
| time_elapsed            | 1899         |
| total timesteps         | 395100       |
| value_loss              | 0.0003197395 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012385555  |
| ent_coef_loss           | -2.731266     |
| entropy                 | 3.632884      |
| ep_rewmean              | -1.74         |
| episodes                | 3956          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 395401        |
| policy_loss             | 0.7578232     |
| qf1_loss                | 0.0053042495  |
| qf2_loss                | 0.0053613097  |
| time_elapsed            | 1901          |
| total timesteps         | 395500        |
| value_loss              | 0.00017482863 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001185597   |
| ent_coef_loss           | 3.3986826     |
| entropy                 | 3.1643796     |
| ep_rewmean              | -1.73         |
| episodes                | 3960          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 395801        |
| policy_loss             | 0.70710236    |
| qf1_loss                | 0.0003913031  |
| qf2_loss                | 0.00037949064 |
| time_elapsed            | 1903          |
| total timesteps         | 395900        |
| value_loss              | 0.0002627652  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011317098  |
| ent_coef_loss           | -0.5949788    |
| entropy                 | 3.5703917     |
| ep_rewmean              | -1.77         |
| episodes                | 3964          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 396201        |
| policy_loss             | 0.81741947    |
| qf1_loss                | 0.0008247487  |
| qf2_loss                | 0.00016788206 |
| time_elapsed            | 1905          |
| total timesteps         | 396300        |
| value_loss              | 0.00024973994 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001158731   |
| ent_coef_loss           | -0.323187     |
| entropy                 | 3.6430569     |
| ep_rewmean              | -1.75         |
| episodes                | 3968          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 396601        |
| policy_loss             | 0.8354881     |
| qf1_loss                | 0.005803139   |
| qf2_loss                | 0.005695243   |
| time_elapsed            | 1907          |
| total timesteps         | 396700        |
| value_loss              | 0.00012989901 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011721896  |
| ent_coef_loss           | 1.8542519     |
| entropy                 | 3.8977504     |
| ep_rewmean              | -1.76         |
| episodes                | 3972          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 397001        |
| policy_loss             | 0.72394323    |
| qf1_loss                | 0.005584863   |
| qf2_loss                | 0.0054803016  |
| time_elapsed            | 1909          |
| total timesteps         | 397100        |
| value_loss              | 0.00031454215 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011285084  |
| ent_coef_loss           | -2.4665258    |
| entropy                 | 3.1435716     |
| ep_rewmean              | -1.77         |
| episodes                | 3976          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 397401        |
| policy_loss             | 0.7603954     |
| qf1_loss                | 0.0046849283  |
| qf2_loss                | 0.004500244   |
| time_elapsed            | 1911          |
| total timesteps         | 397500        |
| value_loss              | 0.00023061872 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011177871  |
| ent_coef_loss           | 8.059781      |
| entropy                 | 3.3076775     |
| ep_rewmean              | -1.72         |
| episodes                | 3980          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 397801        |
| policy_loss             | 0.7493901     |
| qf1_loss                | 0.00041010586 |
| qf2_loss                | 0.00031165263 |
| time_elapsed            | 1913          |
| total timesteps         | 397900        |
| value_loss              | 0.0005076141  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011294871  |
| ent_coef_loss           | 9.951984      |
| entropy                 | 3.5133667     |
| ep_rewmean              | -1.75         |
| episodes                | 3984          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 398201        |
| policy_loss             | 0.7848082     |
| qf1_loss                | 0.00024924247 |
| qf2_loss                | 0.00019497136 |
| time_elapsed            | 1915          |
| total timesteps         | 398300        |
| value_loss              | 0.00026437908 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011172355  |
| ent_coef_loss           | -8.058067     |
| entropy                 | 3.1663003     |
| ep_rewmean              | -1.73         |
| episodes                | 3988          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 398601        |
| policy_loss             | 0.8141026     |
| qf1_loss                | 0.006207878   |
| qf2_loss                | 0.0063566393  |
| time_elapsed            | 1917          |
| total timesteps         | 398700        |
| value_loss              | 0.00022074264 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010789931  |
| ent_coef_loss           | -5.1129513    |
| entropy                 | 2.8839388     |
| ep_rewmean              | -1.72         |
| episodes                | 3992          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 399001        |
| policy_loss             | 0.83522993    |
| qf1_loss                | 0.00021271902 |
| qf2_loss                | 0.00017992224 |
| time_elapsed            | 1919          |
| total timesteps         | 399100        |
| value_loss              | 0.00018391194 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010727901  |
| ent_coef_loss           | 7.4960737     |
| entropy                 | 2.8373404     |
| ep_rewmean              | -1.75         |
| episodes                | 3996          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 399401        |
| policy_loss             | 0.7782371     |
| qf1_loss                | 0.0037143314  |
| qf2_loss                | 0.004047716   |
| time_elapsed            | 1921          |
| total timesteps         | 399500        |
| value_loss              | 0.00029273235 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010495252  |
| ent_coef_loss           | -9.965708     |
| entropy                 | 3.1385498     |
| ep_rewmean              | -1.75         |
| episodes                | 4000          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 399801        |
| policy_loss             | 0.802636      |
| qf1_loss                | 0.00041096218 |
| qf2_loss                | 0.00047095853 |
| time_elapsed            | 1923          |
| total timesteps         | 399900        |
| value_loss              | 0.00010295215 |
-------------------------------------------
Eval num_timesteps=400000, episode_reward=-2.01 +/- 0.90
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010250795  |
| ent_coef_loss           | -0.9570627    |
| entropy                 | 3.0014799     |
| ep_rewmean              | -1.77         |
| episodes                | 4004          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 400201        |
| policy_loss             | 0.77153385    |
| qf1_loss                | 0.00027177576 |
| qf2_loss                | 0.00026072434 |
| time_elapsed            | 1925          |
| total timesteps         | 400300        |
| value_loss              | 0.0003825114  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010034773 |
| ent_coef_loss           | 4.559018     |
| entropy                 | 2.869746     |
| ep_rewmean              | -1.8         |
| episodes                | 4008         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 400601       |
| policy_loss             | 0.8101213    |
| qf1_loss                | 0.006192006  |
| qf2_loss                | 0.0059864833 |
| time_elapsed            | 1927         |
| total timesteps         | 400700       |
| value_loss              | 0.0003042691 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010029726  |
| ent_coef_loss           | -4.058348     |
| entropy                 | 2.7978706     |
| ep_rewmean              | -1.79         |
| episodes                | 4012          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 401001        |
| policy_loss             | 0.7486657     |
| qf1_loss                | 0.00026105795 |
| qf2_loss                | 0.00041479082 |
| time_elapsed            | 1929          |
| total timesteps         | 401100        |
| value_loss              | 0.00043522933 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00103258    |
| ent_coef_loss           | 9.805936      |
| entropy                 | 2.8837128     |
| ep_rewmean              | -1.74         |
| episodes                | 4016          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 401401        |
| policy_loss             | 0.77539897    |
| qf1_loss                | 0.00030814722 |
| qf2_loss                | 0.00036764535 |
| time_elapsed            | 1930          |
| total timesteps         | 401500        |
| value_loss              | 0.00021191241 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010941827  |
| ent_coef_loss           | -5.162648     |
| entropy                 | 2.8145359     |
| ep_rewmean              | -1.82         |
| episodes                | 4020          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 401801        |
| policy_loss             | 0.75655735    |
| qf1_loss                | 0.0059683016  |
| qf2_loss                | 0.0062704445  |
| time_elapsed            | 1932          |
| total timesteps         | 401900        |
| value_loss              | 0.00014249084 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001102776   |
| ent_coef_loss           | 0.19901776    |
| entropy                 | 2.7307088     |
| ep_rewmean              | -1.77         |
| episodes                | 4024          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 402201        |
| policy_loss             | 0.76351863    |
| qf1_loss                | 0.0006876419  |
| qf2_loss                | 0.0003693006  |
| time_elapsed            | 1934          |
| total timesteps         | 402300        |
| value_loss              | 0.00023774857 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011173192  |
| ent_coef_loss           | -7.1961074    |
| entropy                 | 2.5881033     |
| ep_rewmean              | -1.77         |
| episodes                | 4028          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 402601        |
| policy_loss             | 0.83249485    |
| qf1_loss                | 0.0006933203  |
| qf2_loss                | 0.0005662764  |
| time_elapsed            | 1936          |
| total timesteps         | 402700        |
| value_loss              | 0.00015111169 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010810242  |
| ent_coef_loss           | 7.148129      |
| entropy                 | 2.6612637     |
| ep_rewmean              | -1.75         |
| episodes                | 4032          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 403001        |
| policy_loss             | 0.6816249     |
| qf1_loss                | 0.00043693557 |
| qf2_loss                | 0.00038448206 |
| time_elapsed            | 1938          |
| total timesteps         | 403100        |
| value_loss              | 0.00027359586 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010876029  |
| ent_coef_loss           | 9.869156      |
| entropy                 | 2.472612      |
| ep_rewmean              | -1.74         |
| episodes                | 4036          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 403401        |
| policy_loss             | 0.7153597     |
| qf1_loss                | 0.00060872955 |
| qf2_loss                | 0.00044770652 |
| time_elapsed            | 1940          |
| total timesteps         | 403500        |
| value_loss              | 0.00027190452 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011141213  |
| ent_coef_loss           | 4.159109      |
| entropy                 | 2.519791      |
| ep_rewmean              | -1.73         |
| episodes                | 4040          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 403801        |
| policy_loss             | 0.7574543     |
| qf1_loss                | 0.0042000744  |
| qf2_loss                | 0.0040089483  |
| time_elapsed            | 1942          |
| total timesteps         | 403900        |
| value_loss              | 0.00020391654 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011136639  |
| ent_coef_loss           | -8.215133     |
| entropy                 | 3.313493      |
| ep_rewmean              | -1.66         |
| episodes                | 4044          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 404201        |
| policy_loss             | 0.68544424    |
| qf1_loss                | 0.0067688585  |
| qf2_loss                | 0.0068389676  |
| time_elapsed            | 1944          |
| total timesteps         | 404300        |
| value_loss              | 0.00030696834 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011393911  |
| ent_coef_loss           | 5.2346272     |
| entropy                 | 3.051802      |
| ep_rewmean              | -1.67         |
| episodes                | 4048          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 404601        |
| policy_loss             | 0.7147335     |
| qf1_loss                | 0.0003729641  |
| qf2_loss                | 0.00025730862 |
| time_elapsed            | 1946          |
| total timesteps         | 404700        |
| value_loss              | 0.00025963143 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011332246  |
| ent_coef_loss           | -1.4624143    |
| entropy                 | 3.1655884     |
| ep_rewmean              | -1.66         |
| episodes                | 4052          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 405001        |
| policy_loss             | 0.76336926    |
| qf1_loss                | 0.0002138825  |
| qf2_loss                | 0.00028081535 |
| time_elapsed            | 1948          |
| total timesteps         | 405100        |
| value_loss              | 0.00017686877 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011907017  |
| ent_coef_loss           | -3.6375089    |
| entropy                 | 3.2601156     |
| ep_rewmean              | -1.65         |
| episodes                | 4056          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 405401        |
| policy_loss             | 0.7501391     |
| qf1_loss                | 0.00035537285 |
| qf2_loss                | 0.0004959927  |
| time_elapsed            | 1950          |
| total timesteps         | 405500        |
| value_loss              | 0.00014896077 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011867617  |
| ent_coef_loss           | -2.218804     |
| entropy                 | 3.2380161     |
| ep_rewmean              | -1.66         |
| episodes                | 4060          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 405801        |
| policy_loss             | 0.69121325    |
| qf1_loss                | 0.000233968   |
| qf2_loss                | 0.00021785218 |
| time_elapsed            | 1952          |
| total timesteps         | 405900        |
| value_loss              | 0.00025771675 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011747378  |
| ent_coef_loss           | -3.8010852    |
| entropy                 | 3.0663834     |
| ep_rewmean              | -1.64         |
| episodes                | 4064          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 406201        |
| policy_loss             | 0.73269534    |
| qf1_loss                | 0.0014726735  |
| qf2_loss                | 0.0014275516  |
| time_elapsed            | 1953          |
| total timesteps         | 406300        |
| value_loss              | 0.00020841145 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011721706  |
| ent_coef_loss           | -4.8369403    |
| entropy                 | 2.8030477     |
| ep_rewmean              | -1.64         |
| episodes                | 4068          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 406601        |
| policy_loss             | 0.70425457    |
| qf1_loss                | 0.0001955299  |
| qf2_loss                | 0.00018737573 |
| time_elapsed            | 1955          |
| total timesteps         | 406700        |
| value_loss              | 0.0001995665  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011786189  |
| ent_coef_loss           | 3.4204385     |
| entropy                 | 3.1947293     |
| ep_rewmean              | -1.66         |
| episodes                | 4072          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 407001        |
| policy_loss             | 0.8103063     |
| qf1_loss                | 0.00020207264 |
| qf2_loss                | 0.00028705216 |
| time_elapsed            | 1957          |
| total timesteps         | 407100        |
| value_loss              | 0.00033454498 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012079132  |
| ent_coef_loss           | -6.182425     |
| entropy                 | 3.5438418     |
| ep_rewmean              | -1.64         |
| episodes                | 4076          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 407401        |
| policy_loss             | 0.7713957     |
| qf1_loss                | 0.0016857075  |
| qf2_loss                | 0.0014168277  |
| time_elapsed            | 1959          |
| total timesteps         | 407500        |
| value_loss              | 0.00015813301 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011960508  |
| ent_coef_loss           | 0.7175162     |
| entropy                 | 3.4098744     |
| ep_rewmean              | -1.64         |
| episodes                | 4080          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 407801        |
| policy_loss             | 0.71441656    |
| qf1_loss                | 0.00039732305 |
| qf2_loss                | 0.0003724565  |
| time_elapsed            | 1961          |
| total timesteps         | 407900        |
| value_loss              | 0.00031021656 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001191331   |
| ent_coef_loss           | 5.102281      |
| entropy                 | 3.0778043     |
| ep_rewmean              | -1.58         |
| episodes                | 4084          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 408201        |
| policy_loss             | 0.6857855     |
| qf1_loss                | 0.030902315   |
| qf2_loss                | 0.028819187   |
| time_elapsed            | 1963          |
| total timesteps         | 408300        |
| value_loss              | 0.00024711725 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001239463   |
| ent_coef_loss           | -2.1549788    |
| entropy                 | 3.0527377     |
| ep_rewmean              | -1.59         |
| episodes                | 4088          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 408601        |
| policy_loss             | 0.7408753     |
| qf1_loss                | 0.0020904967  |
| qf2_loss                | 0.0020047654  |
| time_elapsed            | 1965          |
| total timesteps         | 408700        |
| value_loss              | 0.00015168279 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013086176  |
| ent_coef_loss           | 4.6590595     |
| entropy                 | 3.8000875     |
| ep_rewmean              | -1.62         |
| episodes                | 4092          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 409001        |
| policy_loss             | 0.72180355    |
| qf1_loss                | 0.006324845   |
| qf2_loss                | 0.0065786587  |
| time_elapsed            | 1967          |
| total timesteps         | 409100        |
| value_loss              | 0.00025528987 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013721666  |
| ent_coef_loss           | -1.3266039    |
| entropy                 | 3.4777179     |
| ep_rewmean              | -1.63         |
| episodes                | 4096          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 409401        |
| policy_loss             | 0.72345334    |
| qf1_loss                | 0.0002598379  |
| qf2_loss                | 0.00033034477 |
| time_elapsed            | 1969          |
| total timesteps         | 409500        |
| value_loss              | 0.00040062895 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013592043  |
| ent_coef_loss           | -3.3427494    |
| entropy                 | 3.817291      |
| ep_rewmean              | -1.65         |
| episodes                | 4100          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 409801        |
| policy_loss             | 0.7688744     |
| qf1_loss                | 0.00021511326 |
| qf2_loss                | 0.00016680657 |
| time_elapsed            | 1971          |
| total timesteps         | 409900        |
| value_loss              | 0.00020109511 |
-------------------------------------------
Eval num_timesteps=410000, episode_reward=-2.24 +/- 0.81
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012746041 |
| ent_coef_loss           | -9.509538    |
| entropy                 | 3.5431476    |
| ep_rewmean              | -1.66        |
| episodes                | 4104         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 410201       |
| policy_loss             | 0.75652325   |
| qf1_loss                | 0.0026403992 |
| qf2_loss                | 0.0027927079 |
| time_elapsed            | 1973         |
| total timesteps         | 410300       |
| value_loss              | 0.0001488628 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001320848   |
| ent_coef_loss           | 8.765978      |
| entropy                 | 3.7712917     |
| ep_rewmean              | -1.69         |
| episodes                | 4108          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 410601        |
| policy_loss             | 0.73816204    |
| qf1_loss                | 0.0003351973  |
| qf2_loss                | 0.000308431   |
| time_elapsed            | 1975          |
| total timesteps         | 410700        |
| value_loss              | 0.00020272643 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013848733  |
| ent_coef_loss           | 7.8938956     |
| entropy                 | 3.674324      |
| ep_rewmean              | -1.72         |
| episodes                | 4112          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 411001        |
| policy_loss             | 0.6591577     |
| qf1_loss                | 0.0013577499  |
| qf2_loss                | 0.0013171083  |
| time_elapsed            | 1977          |
| total timesteps         | 411100        |
| value_loss              | 0.00022200018 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013459454 |
| ent_coef_loss           | -6.3142095   |
| entropy                 | 4.2435412    |
| ep_rewmean              | -1.79        |
| episodes                | 4116         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 411401       |
| policy_loss             | 0.73658776   |
| qf1_loss                | 0.0023919318 |
| qf2_loss                | 0.0023083063 |
| time_elapsed            | 1978         |
| total timesteps         | 411500       |
| value_loss              | 0.0001535241 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013314424  |
| ent_coef_loss           | -3.8032181    |
| entropy                 | 3.7660842     |
| ep_rewmean              | -1.75         |
| episodes                | 4120          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 411801        |
| policy_loss             | 0.7248124     |
| qf1_loss                | 0.00018657558 |
| qf2_loss                | 0.00018608797 |
| time_elapsed            | 1980          |
| total timesteps         | 411900        |
| value_loss              | 0.0003802302  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014015144  |
| ent_coef_loss           | -8.919188     |
| entropy                 | 4.3371863     |
| ep_rewmean              | -1.81         |
| episodes                | 4124          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 412201        |
| policy_loss             | 0.7828669     |
| qf1_loss                | 0.0002632282  |
| qf2_loss                | 0.00020981742 |
| time_elapsed            | 1982          |
| total timesteps         | 412300        |
| value_loss              | 0.00018329863 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012881046  |
| ent_coef_loss           | -8.455305     |
| entropy                 | 4.068861      |
| ep_rewmean              | -1.81         |
| episodes                | 4128          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 412601        |
| policy_loss             | 0.75920004    |
| qf1_loss                | 0.00023157729 |
| qf2_loss                | 0.00020882479 |
| time_elapsed            | 1984          |
| total timesteps         | 412700        |
| value_loss              | 0.00027461775 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011522059  |
| ent_coef_loss           | -6.617506     |
| entropy                 | 2.58668       |
| ep_rewmean              | -1.8          |
| episodes                | 4132          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 413001        |
| policy_loss             | 0.75927854    |
| qf1_loss                | 0.0045444467  |
| qf2_loss                | 0.0044701607  |
| time_elapsed            | 1986          |
| total timesteps         | 413100        |
| value_loss              | 0.00020017185 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010411427  |
| ent_coef_loss           | -3.4554894    |
| entropy                 | 2.746338      |
| ep_rewmean              | -1.86         |
| episodes                | 4136          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 413401        |
| policy_loss             | 0.74754155    |
| qf1_loss                | 0.0007004055  |
| qf2_loss                | 0.00078033865 |
| time_elapsed            | 1988          |
| total timesteps         | 413500        |
| value_loss              | 0.00020441115 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011313936  |
| ent_coef_loss           | -0.17598861   |
| entropy                 | 2.5857654     |
| ep_rewmean              | -1.91         |
| episodes                | 4140          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 413801        |
| policy_loss             | 0.7180015     |
| qf1_loss                | 0.00035417028 |
| qf2_loss                | 0.00029226823 |
| time_elapsed            | 1990          |
| total timesteps         | 413900        |
| value_loss              | 0.00021191692 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013202309  |
| ent_coef_loss           | 15.548407     |
| entropy                 | 2.5166426     |
| ep_rewmean              | -1.92         |
| episodes                | 4144          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 414201        |
| policy_loss             | 0.75107366    |
| qf1_loss                | 0.007413706   |
| qf2_loss                | 0.0075425836  |
| time_elapsed            | 1992          |
| total timesteps         | 414300        |
| value_loss              | 0.00037527102 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001399585   |
| ent_coef_loss           | -5.1642466    |
| entropy                 | 3.5182407     |
| ep_rewmean              | -1.93         |
| episodes                | 4148          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 414601        |
| policy_loss             | 0.77498066    |
| qf1_loss                | 0.0021285764  |
| qf2_loss                | 0.0017667245  |
| time_elapsed            | 1994          |
| total timesteps         | 414700        |
| value_loss              | 0.00048795107 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013866475  |
| ent_coef_loss           | -4.054035     |
| entropy                 | 3.1074476     |
| ep_rewmean              | -1.91         |
| episodes                | 4152          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 415001        |
| policy_loss             | 0.7816654     |
| qf1_loss                | 0.0028029438  |
| qf2_loss                | 0.0028187328  |
| time_elapsed            | 1996          |
| total timesteps         | 415100        |
| value_loss              | 0.00017915067 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001383065   |
| ent_coef_loss           | -1.7137376    |
| entropy                 | 2.7530377     |
| ep_rewmean              | -1.97         |
| episodes                | 4156          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 415401        |
| policy_loss             | 0.75504875    |
| qf1_loss                | 0.00035203266 |
| qf2_loss                | 0.0003610783  |
| time_elapsed            | 1998          |
| total timesteps         | 415500        |
| value_loss              | 0.00018406357 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013903505  |
| ent_coef_loss           | 2.3925188     |
| entropy                 | 2.965705      |
| ep_rewmean              | -2.02         |
| episodes                | 4160          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 415801        |
| policy_loss             | 0.79537725    |
| qf1_loss                | 0.0001469413  |
| qf2_loss                | 0.0001475877  |
| time_elapsed            | 2000          |
| total timesteps         | 415900        |
| value_loss              | 0.00019358199 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014247593  |
| ent_coef_loss           | -1.4843633    |
| entropy                 | 3.23779       |
| ep_rewmean              | -2.07         |
| episodes                | 4164          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 416201        |
| policy_loss             | 0.7233855     |
| qf1_loss                | 0.00027815707 |
| qf2_loss                | 0.00052628946 |
| time_elapsed            | 2001          |
| total timesteps         | 416300        |
| value_loss              | 0.0003097562  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014070562  |
| ent_coef_loss           | 8.441737      |
| entropy                 | 2.5711648     |
| ep_rewmean              | -2.16         |
| episodes                | 4168          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 416601        |
| policy_loss             | 0.746622      |
| qf1_loss                | 0.001985528   |
| qf2_loss                | 0.0020123865  |
| time_elapsed            | 2003          |
| total timesteps         | 416700        |
| value_loss              | 0.00030224476 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013659641  |
| ent_coef_loss           | -3.358176     |
| entropy                 | 3.0400019     |
| ep_rewmean              | -2.17         |
| episodes                | 4172          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 417001        |
| policy_loss             | 0.7582342     |
| qf1_loss                | 0.00028257706 |
| qf2_loss                | 0.0002618049  |
| time_elapsed            | 2005          |
| total timesteps         | 417100        |
| value_loss              | 0.00023539503 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013712312  |
| ent_coef_loss           | 2.5672674     |
| entropy                 | 3.2487955     |
| ep_rewmean              | -2.2          |
| episodes                | 4176          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 417401        |
| policy_loss             | 0.73950136    |
| qf1_loss                | 0.00057104015 |
| qf2_loss                | 0.0005675942  |
| time_elapsed            | 2007          |
| total timesteps         | 417500        |
| value_loss              | 0.00021326117 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013344806  |
| ent_coef_loss           | -3.6712341    |
| entropy                 | 3.1471357     |
| ep_rewmean              | -2.22         |
| episodes                | 4180          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 417801        |
| policy_loss             | 0.794132      |
| qf1_loss                | 0.005292425   |
| qf2_loss                | 0.0049626655  |
| time_elapsed            | 2009          |
| total timesteps         | 417900        |
| value_loss              | 0.00018602781 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012722105  |
| ent_coef_loss           | -4.1768036    |
| entropy                 | 2.9828246     |
| ep_rewmean              | -2.23         |
| episodes                | 4184          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 418201        |
| policy_loss             | 0.70161116    |
| qf1_loss                | 0.0002912932  |
| qf2_loss                | 0.00030416556 |
| time_elapsed            | 2011          |
| total timesteps         | 418300        |
| value_loss              | 0.0004986501  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012498325  |
| ent_coef_loss           | -1.9370121    |
| entropy                 | 2.756895      |
| ep_rewmean              | -2.21         |
| episodes                | 4188          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 418601        |
| policy_loss             | 0.82555044    |
| qf1_loss                | 0.00035829423 |
| qf2_loss                | 0.00039463863 |
| time_elapsed            | 2013          |
| total timesteps         | 418700        |
| value_loss              | 0.00039148488 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012772878  |
| ent_coef_loss           | 11.526673     |
| entropy                 | 2.865614      |
| ep_rewmean              | -2.18         |
| episodes                | 4192          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 419001        |
| policy_loss             | 0.7914275     |
| qf1_loss                | 0.00039094    |
| qf2_loss                | 0.00044127018 |
| time_elapsed            | 2015          |
| total timesteps         | 419100        |
| value_loss              | 0.00033243737 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012949386  |
| ent_coef_loss           | -1.1441118    |
| entropy                 | 3.4380646     |
| ep_rewmean              | -2.18         |
| episodes                | 4196          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 419401        |
| policy_loss             | 0.769258      |
| qf1_loss                | 0.0050183525  |
| qf2_loss                | 0.004735585   |
| time_elapsed            | 2017          |
| total timesteps         | 419500        |
| value_loss              | 0.00036145817 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012694811  |
| ent_coef_loss           | -1.040039     |
| entropy                 | 3.6752107     |
| ep_rewmean              | -2.16         |
| episodes                | 4200          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 419801        |
| policy_loss             | 0.8479141     |
| qf1_loss                | 0.003726018   |
| qf2_loss                | 0.0041050543  |
| time_elapsed            | 2019          |
| total timesteps         | 419900        |
| value_loss              | 0.00028845863 |
-------------------------------------------
Eval num_timesteps=420000, episode_reward=-1.81 +/- 0.74
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013681909  |
| ent_coef_loss           | 11.245819     |
| entropy                 | 3.527896      |
| ep_rewmean              | -2.14         |
| episodes                | 4204          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 420201        |
| policy_loss             | 0.8271706     |
| qf1_loss                | 0.0076585426  |
| qf2_loss                | 0.007191703   |
| time_elapsed            | 2021          |
| total timesteps         | 420300        |
| value_loss              | 0.00063856185 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001565477   |
| ent_coef_loss           | 7.2595673     |
| entropy                 | 4.308004      |
| ep_rewmean              | -2.12         |
| episodes                | 4208          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 420601        |
| policy_loss             | 0.81417084    |
| qf1_loss                | 0.0034371356  |
| qf2_loss                | 0.002977549   |
| time_elapsed            | 2023          |
| total timesteps         | 420700        |
| value_loss              | 0.00041238152 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016029765  |
| ent_coef_loss           | -3.3969407    |
| entropy                 | 3.8568885     |
| ep_rewmean              | -2.08         |
| episodes                | 4212          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 421001        |
| policy_loss             | 0.76787907    |
| qf1_loss                | 0.0040471256  |
| qf2_loss                | 0.004104038   |
| time_elapsed            | 2025          |
| total timesteps         | 421100        |
| value_loss              | 0.00026501945 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015107095  |
| ent_coef_loss           | -2.6391563    |
| entropy                 | 3.842539      |
| ep_rewmean              | -2.03         |
| episodes                | 4216          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 421401        |
| policy_loss             | 0.8163912     |
| qf1_loss                | 0.00034806214 |
| qf2_loss                | 0.00031613436 |
| time_elapsed            | 2027          |
| total timesteps         | 421500        |
| value_loss              | 0.00024008652 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013583037  |
| ent_coef_loss           | -15.2437315   |
| entropy                 | 3.7376962     |
| ep_rewmean              | -2.08         |
| episodes                | 4220          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 421801        |
| policy_loss             | 0.8765341     |
| qf1_loss                | 0.00034322846 |
| qf2_loss                | 0.00031200267 |
| time_elapsed            | 2029          |
| total timesteps         | 421900        |
| value_loss              | 0.00024385305 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012295418  |
| ent_coef_loss           | -12.730204    |
| entropy                 | 3.832475      |
| ep_rewmean              | -2.04         |
| episodes                | 4224          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 422201        |
| policy_loss             | 0.9016782     |
| qf1_loss                | 0.0009179339  |
| qf2_loss                | 0.0009847049  |
| time_elapsed            | 2031          |
| total timesteps         | 422300        |
| value_loss              | 0.00028693187 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011775779  |
| ent_coef_loss           | 0.3119316     |
| entropy                 | 3.8396292     |
| ep_rewmean              | -2.04         |
| episodes                | 4228          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 422601        |
| policy_loss             | 0.87221944    |
| qf1_loss                | 0.0002602001  |
| qf2_loss                | 0.00040611322 |
| time_elapsed            | 2033          |
| total timesteps         | 422700        |
| value_loss              | 0.0003280456  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010799809  |
| ent_coef_loss           | -1.7258146    |
| entropy                 | 3.0541365     |
| ep_rewmean              | -2.02         |
| episodes                | 4232          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 423001        |
| policy_loss             | 0.82242715    |
| qf1_loss                | 0.0052998704  |
| qf2_loss                | 0.0049507804  |
| time_elapsed            | 2035          |
| total timesteps         | 423100        |
| value_loss              | 0.00021803551 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010035788  |
| ent_coef_loss           | -9.348991     |
| entropy                 | 2.9906852     |
| ep_rewmean              | -2.05         |
| episodes                | 4236          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 423401        |
| policy_loss             | 0.8786282     |
| qf1_loss                | 0.002423517   |
| qf2_loss                | 0.0024102365  |
| time_elapsed            | 2037          |
| total timesteps         | 423500        |
| value_loss              | 0.00019293508 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009879171  |
| ent_coef_loss           | 1.1770911     |
| entropy                 | 3.063573      |
| ep_rewmean              | -2.06         |
| episodes                | 4240          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 423801        |
| policy_loss             | 0.85860544    |
| qf1_loss                | 0.000224029   |
| qf2_loss                | 0.000246639   |
| time_elapsed            | 2039          |
| total timesteps         | 423900        |
| value_loss              | 0.00030808712 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010766916 |
| ent_coef_loss           | 9.443214     |
| entropy                 | 2.9097369    |
| ep_rewmean              | -2.18        |
| episodes                | 4244         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 424201       |
| policy_loss             | 0.846047     |
| qf1_loss                | 0.0021590116 |
| qf2_loss                | 0.0022919206 |
| time_elapsed            | 2040         |
| total timesteps         | 424300       |
| value_loss              | 0.0001767906 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011732538  |
| ent_coef_loss           | -1.1291237    |
| entropy                 | 2.9272728     |
| ep_rewmean              | -2.23         |
| episodes                | 4248          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 424601        |
| policy_loss             | 0.8868058     |
| qf1_loss                | 0.0113627445  |
| qf2_loss                | 0.011644303   |
| time_elapsed            | 2042          |
| total timesteps         | 424700        |
| value_loss              | 0.00017354141 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012590861  |
| ent_coef_loss           | 3.251954      |
| entropy                 | 3.3658738     |
| ep_rewmean              | -2.26         |
| episodes                | 4252          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 425001        |
| policy_loss             | 0.84122       |
| qf1_loss                | 0.00026513697 |
| qf2_loss                | 0.00026342145 |
| time_elapsed            | 2044          |
| total timesteps         | 425100        |
| value_loss              | 0.00014746567 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012783535  |
| ent_coef_loss           | -5.891525     |
| entropy                 | 3.3200645     |
| ep_rewmean              | -2.3          |
| episodes                | 4256          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 425401        |
| policy_loss             | 0.825349      |
| qf1_loss                | 0.00037089537 |
| qf2_loss                | 0.00018389123 |
| time_elapsed            | 2046          |
| total timesteps         | 425500        |
| value_loss              | 0.00024006964 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011551419  |
| ent_coef_loss           | -4.6829605    |
| entropy                 | 3.0123081     |
| ep_rewmean              | -2.26         |
| episodes                | 4260          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 425801        |
| policy_loss             | 0.8321671     |
| qf1_loss                | 0.00870016    |
| qf2_loss                | 0.008319893   |
| time_elapsed            | 2048          |
| total timesteps         | 425900        |
| value_loss              | 0.00018466052 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011252118  |
| ent_coef_loss           | -6.247139     |
| entropy                 | 3.2029238     |
| ep_rewmean              | -2.25         |
| episodes                | 4264          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 426201        |
| policy_loss             | 0.80080354    |
| qf1_loss                | 0.0021240658  |
| qf2_loss                | 0.0021347632  |
| time_elapsed            | 2050          |
| total timesteps         | 426300        |
| value_loss              | 0.00021227363 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011130067  |
| ent_coef_loss           | 5.6304526     |
| entropy                 | 2.76349       |
| ep_rewmean              | -2.21         |
| episodes                | 4268          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 426601        |
| policy_loss             | 0.73500216    |
| qf1_loss                | 0.00025123276 |
| qf2_loss                | 0.0002102661  |
| time_elapsed            | 2052          |
| total timesteps         | 426700        |
| value_loss              | 0.00014819708 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011567827 |
| ent_coef_loss           | -1.3130212   |
| entropy                 | 2.9482095    |
| ep_rewmean              | -2.2         |
| episodes                | 4272         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 427001       |
| policy_loss             | 0.70071673   |
| qf1_loss                | 0.003091334  |
| qf2_loss                | 0.0030810905 |
| time_elapsed            | 2054         |
| total timesteps         | 427100       |
| value_loss              | 0.0003428744 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001153726   |
| ent_coef_loss           | 4.118767      |
| entropy                 | 2.8688283     |
| ep_rewmean              | -2.17         |
| episodes                | 4276          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 427401        |
| policy_loss             | 0.75240165    |
| qf1_loss                | 0.0002732293  |
| qf2_loss                | 0.00032118894 |
| time_elapsed            | 2056          |
| total timesteps         | 427500        |
| value_loss              | 0.00022986514 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011629306  |
| ent_coef_loss           | 0.102047205   |
| entropy                 | 2.4799428     |
| ep_rewmean              | -2.16         |
| episodes                | 4280          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 427801        |
| policy_loss             | 0.7394987     |
| qf1_loss                | 0.005319226   |
| qf2_loss                | 0.0051185605  |
| time_elapsed            | 2058          |
| total timesteps         | 427900        |
| value_loss              | 0.00014509894 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011217971  |
| ent_coef_loss           | 1.7130604     |
| entropy                 | 2.9623394     |
| ep_rewmean              | -2.17         |
| episodes                | 4284          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 428201        |
| policy_loss             | 0.7524086     |
| qf1_loss                | 0.00027647897 |
| qf2_loss                | 0.00036330541 |
| time_elapsed            | 2060          |
| total timesteps         | 428300        |
| value_loss              | 0.00021468286 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010847067  |
| ent_coef_loss           | -0.02328223   |
| entropy                 | 2.9706643     |
| ep_rewmean              | -2.23         |
| episodes                | 4288          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 428601        |
| policy_loss             | 0.71433747    |
| qf1_loss                | 0.0013143304  |
| qf2_loss                | 0.0012613711  |
| time_elapsed            | 2062          |
| total timesteps         | 428700        |
| value_loss              | 0.00019526549 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010835271  |
| ent_coef_loss           | 0.6934035     |
| entropy                 | 2.8747463     |
| ep_rewmean              | -2.26         |
| episodes                | 4292          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 429001        |
| policy_loss             | 0.7047622     |
| qf1_loss                | 0.0001782268  |
| qf2_loss                | 0.00017934476 |
| time_elapsed            | 2064          |
| total timesteps         | 429100        |
| value_loss              | 9.6314354e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010967773  |
| ent_coef_loss           | 1.1730541     |
| entropy                 | 2.5704117     |
| ep_rewmean              | -2.25         |
| episodes                | 4296          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 429401        |
| policy_loss             | 0.7297425     |
| qf1_loss                | 0.00017839545 |
| qf2_loss                | 0.00014660283 |
| time_elapsed            | 2066          |
| total timesteps         | 429500        |
| value_loss              | 0.0001302512  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011046265  |
| ent_coef_loss           | 3.7276652     |
| entropy                 | 3.051278      |
| ep_rewmean              | -2.25         |
| episodes                | 4300          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 429801        |
| policy_loss             | 0.67761415    |
| qf1_loss                | 0.00026267534 |
| qf2_loss                | 0.00029330997 |
| time_elapsed            | 2068          |
| total timesteps         | 429900        |
| value_loss              | 0.00014775284 |
-------------------------------------------
Eval num_timesteps=430000, episode_reward=-1.88 +/- 0.76
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011083651  |
| ent_coef_loss           | -3.9018888    |
| entropy                 | 2.8947754     |
| ep_rewmean              | -2.26         |
| episodes                | 4304          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 430201        |
| policy_loss             | 0.68084246    |
| qf1_loss                | 0.0012232558  |
| qf2_loss                | 0.0013038712  |
| time_elapsed            | 2070          |
| total timesteps         | 430300        |
| value_loss              | 0.00011789297 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010896617  |
| ent_coef_loss           | -2.4417868    |
| entropy                 | 2.8698483     |
| ep_rewmean              | -2.24         |
| episodes                | 4308          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 430601        |
| policy_loss             | 0.6721691     |
| qf1_loss                | 0.00018802584 |
| qf2_loss                | 0.00015723781 |
| time_elapsed            | 2072          |
| total timesteps         | 430700        |
| value_loss              | 0.00011643249 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010283366  |
| ent_coef_loss           | -8.295139     |
| entropy                 | 2.0657582     |
| ep_rewmean              | -2.24         |
| episodes                | 4312          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 431001        |
| policy_loss             | 0.6318266     |
| qf1_loss                | 0.00016557921 |
| qf2_loss                | 0.00019532614 |
| time_elapsed            | 2074          |
| total timesteps         | 431100        |
| value_loss              | 0.00012796064 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010221713  |
| ent_coef_loss           | -3.6698241    |
| entropy                 | 3.6672673     |
| ep_rewmean              | -2.29         |
| episodes                | 4316          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 431401        |
| policy_loss             | 0.6959723     |
| qf1_loss                | 0.002966665   |
| qf2_loss                | 0.0029155067  |
| time_elapsed            | 2076          |
| total timesteps         | 431500        |
| value_loss              | 9.7015596e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010533535  |
| ent_coef_loss           | 0.5032925     |
| entropy                 | 3.451622      |
| ep_rewmean              | -2.28         |
| episodes                | 4320          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 431801        |
| policy_loss             | 0.60247755    |
| qf1_loss                | 0.0036797975  |
| qf2_loss                | 0.0034961926  |
| time_elapsed            | 2078          |
| total timesteps         | 431900        |
| value_loss              | 0.00028889521 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0010837301   |
| ent_coef_loss           | 1.947181       |
| entropy                 | 2.8863645      |
| ep_rewmean              | -2.33          |
| episodes                | 4324           |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -2.3           |
| n_updates               | 432201         |
| policy_loss             | 0.6433226      |
| qf1_loss                | 0.002860384    |
| qf2_loss                | 0.0028723646   |
| time_elapsed            | 2080           |
| total timesteps         | 432300         |
| value_loss              | 0.000113904745 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010948717  |
| ent_coef_loss           | -2.2087739    |
| entropy                 | 2.6606455     |
| ep_rewmean              | -2.36         |
| episodes                | 4328          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 432601        |
| policy_loss             | 0.65498805    |
| qf1_loss                | 0.00018246009 |
| qf2_loss                | 0.00019652258 |
| time_elapsed            | 2082          |
| total timesteps         | 432700        |
| value_loss              | 0.00019007007 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010837023  |
| ent_coef_loss           | 3.7025456     |
| entropy                 | 2.9353967     |
| ep_rewmean              | -2.39         |
| episodes                | 4332          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 433001        |
| policy_loss             | 0.64059305    |
| qf1_loss                | 0.0016808498  |
| qf2_loss                | 0.0016472458  |
| time_elapsed            | 2084          |
| total timesteps         | 433100        |
| value_loss              | 0.00011634659 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011304041  |
| ent_coef_loss           | 5.141885      |
| entropy                 | 3.1629577     |
| ep_rewmean              | -2.32         |
| episodes                | 4336          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 433401        |
| policy_loss             | 0.6506368     |
| qf1_loss                | 0.00015600436 |
| qf2_loss                | 0.00011494671 |
| time_elapsed            | 2085          |
| total timesteps         | 433500        |
| value_loss              | 0.00017841431 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00116193    |
| ent_coef_loss           | 12.415152     |
| entropy                 | 3.3094249     |
| ep_rewmean              | -2.27         |
| episodes                | 4340          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 433801        |
| policy_loss             | 0.66962165    |
| qf1_loss                | 0.0023930871  |
| qf2_loss                | 0.0023359896  |
| time_elapsed            | 2087          |
| total timesteps         | 433900        |
| value_loss              | 0.00020304148 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012297886  |
| ent_coef_loss           | 7.6852837     |
| entropy                 | 3.4556303     |
| ep_rewmean              | -2.23         |
| episodes                | 4344          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 434201        |
| policy_loss             | 0.6637383     |
| qf1_loss                | 0.0002098522  |
| qf2_loss                | 0.00018249353 |
| time_elapsed            | 2089          |
| total timesteps         | 434300        |
| value_loss              | 0.00020743936 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012374279  |
| ent_coef_loss           | -3.244452     |
| entropy                 | 3.2035697     |
| ep_rewmean              | -2.19         |
| episodes                | 4348          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 434601        |
| policy_loss             | 0.7301822     |
| qf1_loss                | 0.00015396782 |
| qf2_loss                | 0.00015876483 |
| time_elapsed            | 2091          |
| total timesteps         | 434700        |
| value_loss              | 0.00015029944 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011581487 |
| ent_coef_loss           | 7.321097     |
| entropy                 | 3.0361114    |
| ep_rewmean              | -2.2         |
| episodes                | 4352         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 435001       |
| policy_loss             | 0.698745     |
| qf1_loss                | 0.008236736  |
| qf2_loss                | 0.008195861  |
| time_elapsed            | 2093         |
| total timesteps         | 435100       |
| value_loss              | 0.0001048195 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011337007  |
| ent_coef_loss           | -6.908922     |
| entropy                 | 2.213862      |
| ep_rewmean              | -2.14         |
| episodes                | 4356          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 435401        |
| policy_loss             | 0.7178713     |
| qf1_loss                | 0.00032885262 |
| qf2_loss                | 0.0003326254  |
| time_elapsed            | 2095          |
| total timesteps         | 435500        |
| value_loss              | 0.00012920776 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011615201  |
| ent_coef_loss           | 7.784527      |
| entropy                 | 2.9432712     |
| ep_rewmean              | -2.21         |
| episodes                | 4360          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 435801        |
| policy_loss             | 0.7062128     |
| qf1_loss                | 0.002549962   |
| qf2_loss                | 0.0026466255  |
| time_elapsed            | 2097          |
| total timesteps         | 435900        |
| value_loss              | 0.00025637785 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013001562  |
| ent_coef_loss           | 6.0404005     |
| entropy                 | 2.9144628     |
| ep_rewmean              | -2.21         |
| episodes                | 4364          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 436201        |
| policy_loss             | 0.72670054    |
| qf1_loss                | 0.004163747   |
| qf2_loss                | 0.003983708   |
| time_elapsed            | 2099          |
| total timesteps         | 436300        |
| value_loss              | 0.00018020289 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013111786  |
| ent_coef_loss           | -1.5745541    |
| entropy                 | 2.919843      |
| ep_rewmean              | -2.25         |
| episodes                | 4368          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 436601        |
| policy_loss             | 0.74654996    |
| qf1_loss                | 0.004028555   |
| qf2_loss                | 0.0037496076  |
| time_elapsed            | 2101          |
| total timesteps         | 436700        |
| value_loss              | 0.00029772412 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012146321  |
| ent_coef_loss           | -1.3728714    |
| entropy                 | 3.0610056     |
| ep_rewmean              | -2.25         |
| episodes                | 4372          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 437001        |
| policy_loss             | 0.7372385     |
| qf1_loss                | 0.0043617953  |
| qf2_loss                | 0.0045238445  |
| time_elapsed            | 2103          |
| total timesteps         | 437100        |
| value_loss              | 0.00014534433 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011441009  |
| ent_coef_loss           | 2.6400764     |
| entropy                 | 2.9855623     |
| ep_rewmean              | -2.31         |
| episodes                | 4376          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 437401        |
| policy_loss             | 0.6971247     |
| qf1_loss                | 0.0035702947  |
| qf2_loss                | 0.003265642   |
| time_elapsed            | 2105          |
| total timesteps         | 437500        |
| value_loss              | 0.00028040964 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0010483543   |
| ent_coef_loss           | -9.216982      |
| entropy                 | 2.1491146      |
| ep_rewmean              | -2.36          |
| episodes                | 4380           |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -2.4           |
| n_updates               | 437801         |
| policy_loss             | 0.7604169      |
| qf1_loss                | 0.0001315756   |
| qf2_loss                | 0.00016090975  |
| time_elapsed            | 2107           |
| total timesteps         | 437900         |
| value_loss              | 0.000102171376 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00095905276 |
| ent_coef_loss           | -1.922132     |
| entropy                 | 2.2556734     |
| ep_rewmean              | -2.4          |
| episodes                | 4384          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 438201        |
| policy_loss             | 0.67306936    |
| qf1_loss                | 0.00023499629 |
| qf2_loss                | 0.00028346915 |
| time_elapsed            | 2109          |
| total timesteps         | 438300        |
| value_loss              | 0.00012776104 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009732679  |
| ent_coef_loss           | 4.0469456     |
| entropy                 | 1.8779643     |
| ep_rewmean              | -2.37         |
| episodes                | 4388          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 438601        |
| policy_loss             | 0.69679314    |
| qf1_loss                | 0.0004982739  |
| qf2_loss                | 0.00022886312 |
| time_elapsed            | 2111          |
| total timesteps         | 438700        |
| value_loss              | 0.00021263718 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010175912  |
| ent_coef_loss           | 10.181789     |
| entropy                 | 1.9117293     |
| ep_rewmean              | -2.35         |
| episodes                | 4392          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 439001        |
| policy_loss             | 0.7012044     |
| qf1_loss                | 0.0003466875  |
| qf2_loss                | 0.00024307944 |
| time_elapsed            | 2113          |
| total timesteps         | 439100        |
| value_loss              | 0.00016258357 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010482363  |
| ent_coef_loss           | -2.2011702    |
| entropy                 | 2.3022952     |
| ep_rewmean              | -2.34         |
| episodes                | 4396          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 439401        |
| policy_loss             | 0.7066316     |
| qf1_loss                | 0.0015308111  |
| qf2_loss                | 0.0016048786  |
| time_elapsed            | 2114          |
| total timesteps         | 439500        |
| value_loss              | 0.00012397236 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010557461  |
| ent_coef_loss           | 2.098406      |
| entropy                 | 2.0422325     |
| ep_rewmean              | -2.33         |
| episodes                | 4400          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 439801        |
| policy_loss             | 0.69724643    |
| qf1_loss                | 0.00029467026 |
| qf2_loss                | 0.00030202782 |
| time_elapsed            | 2116          |
| total timesteps         | 439900        |
| value_loss              | 0.00018455432 |
-------------------------------------------
Eval num_timesteps=440000, episode_reward=-2.34 +/- 0.47
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010801698  |
| ent_coef_loss           | 5.2288446     |
| entropy                 | 2.1193087     |
| ep_rewmean              | -2.31         |
| episodes                | 4404          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 440201        |
| policy_loss             | 0.6526681     |
| qf1_loss                | 0.00038429385 |
| qf2_loss                | 0.000309962   |
| time_elapsed            | 2119          |
| total timesteps         | 440300        |
| value_loss              | 0.00014524598 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010753258 |
| ent_coef_loss           | 6.6370277    |
| entropy                 | 2.5340211    |
| ep_rewmean              | -2.33        |
| episodes                | 4408         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 440601       |
| policy_loss             | 0.67083925   |
| qf1_loss                | 0.0017426477 |
| qf2_loss                | 0.0017064988 |
| time_elapsed            | 2120         |
| total timesteps         | 440700       |
| value_loss              | 0.0001286688 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010539328  |
| ent_coef_loss           | 4.6139197     |
| entropy                 | 2.3686793     |
| ep_rewmean              | -2.32         |
| episodes                | 4412          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 441001        |
| policy_loss             | 0.65909827    |
| qf1_loss                | 0.0026140832  |
| qf2_loss                | 0.0031446016  |
| time_elapsed            | 2122          |
| total timesteps         | 441100        |
| value_loss              | 0.00014417763 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010348691  |
| ent_coef_loss           | -5.3546543    |
| entropy                 | 2.0788417     |
| ep_rewmean              | -2.32         |
| episodes                | 4416          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 441401        |
| policy_loss             | 0.70741963    |
| qf1_loss                | 0.00015254809 |
| qf2_loss                | 0.000167133   |
| time_elapsed            | 2124          |
| total timesteps         | 441500        |
| value_loss              | 0.00011133465 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010035309 |
| ent_coef_loss           | -4.7215557   |
| entropy                 | 2.0371773    |
| ep_rewmean              | -2.28        |
| episodes                | 4420         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 441801       |
| policy_loss             | 0.7133498    |
| qf1_loss                | 0.0005031029 |
| qf2_loss                | 0.0003879084 |
| time_elapsed            | 2126         |
| total timesteps         | 441900       |
| value_loss              | 0.0001633046 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0009650062 |
| ent_coef_loss           | -2.9192748   |
| entropy                 | 1.643985     |
| ep_rewmean              | -2.25        |
| episodes                | 4424         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 442201       |
| policy_loss             | 0.69574916   |
| qf1_loss                | 0.000509765  |
| qf2_loss                | 0.0004967894 |
| time_elapsed            | 2128         |
| total timesteps         | 442300       |
| value_loss              | 0.0001398836 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00092294114 |
| ent_coef_loss           | 4.4450474     |
| entropy                 | 1.9358635     |
| ep_rewmean              | -2.23         |
| episodes                | 4428          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 442601        |
| policy_loss             | 0.6573859     |
| qf1_loss                | 0.0054909103  |
| qf2_loss                | 0.0052980282  |
| time_elapsed            | 2130          |
| total timesteps         | 442700        |
| value_loss              | 0.0002970018  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009360415  |
| ent_coef_loss           | 0.7992568     |
| entropy                 | 1.6259315     |
| ep_rewmean              | -2.21         |
| episodes                | 4432          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 443001        |
| policy_loss             | 0.74154496    |
| qf1_loss                | 0.0002721563  |
| qf2_loss                | 0.00022551649 |
| time_elapsed            | 2132          |
| total timesteps         | 443100        |
| value_loss              | 0.0002719964  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009394282  |
| ent_coef_loss           | 1.9584059     |
| entropy                 | 1.3290863     |
| ep_rewmean              | -2.32         |
| episodes                | 4436          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 443401        |
| policy_loss             | 0.67410123    |
| qf1_loss                | 0.00023745242 |
| qf2_loss                | 0.00019669226 |
| time_elapsed            | 2134          |
| total timesteps         | 443500        |
| value_loss              | 0.00017343086 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009101665  |
| ent_coef_loss           | -5.5147924    |
| entropy                 | 1.2526823     |
| ep_rewmean              | -2.38         |
| episodes                | 4440          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 443801        |
| policy_loss             | 0.697719      |
| qf1_loss                | 0.00023389797 |
| qf2_loss                | 0.00018558656 |
| time_elapsed            | 2136          |
| total timesteps         | 443900        |
| value_loss              | 0.00013321631 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00083241623 |
| ent_coef_loss           | -1.0229377    |
| entropy                 | 1.742647      |
| ep_rewmean              | -2.41         |
| episodes                | 4444          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 444201        |
| policy_loss             | 0.6603624     |
| qf1_loss                | 0.0033349157  |
| qf2_loss                | 0.0034986734  |
| time_elapsed            | 2138          |
| total timesteps         | 444300        |
| value_loss              | 0.00014549866 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007574684  |
| ent_coef_loss           | -0.8794217    |
| entropy                 | 1.6275308     |
| ep_rewmean              | -2.49         |
| episodes                | 4448          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 444601        |
| policy_loss             | 0.62575334    |
| qf1_loss                | 0.00031601608 |
| qf2_loss                | 0.00029629542 |
| time_elapsed            | 2140          |
| total timesteps         | 444700        |
| value_loss              | 0.00014892503 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00075756194 |
| ent_coef_loss           | -0.44254756   |
| entropy                 | 0.92554367    |
| ep_rewmean              | -2.53         |
| episodes                | 4452          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 445001        |
| policy_loss             | 0.6531067     |
| qf1_loss                | 0.00050058373 |
| qf2_loss                | 0.00045827788 |
| time_elapsed            | 2142          |
| total timesteps         | 445100        |
| value_loss              | 0.00019475017 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00077924016  |
| ent_coef_loss           | -1.0420222     |
| entropy                 | 1.4696474      |
| ep_rewmean              | -2.49          |
| episodes                | 4456           |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -2.5           |
| n_updates               | 445401         |
| policy_loss             | 0.6746665      |
| qf1_loss                | 0.00016874672  |
| qf2_loss                | 0.0002505108   |
| time_elapsed            | 2144           |
| total timesteps         | 445500         |
| value_loss              | 0.000110642104 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008291789  |
| ent_coef_loss           | 3.3733912     |
| entropy                 | 1.449986      |
| ep_rewmean              | -2.41         |
| episodes                | 4460          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 445801        |
| policy_loss             | 0.69776934    |
| qf1_loss                | 0.0006098987  |
| qf2_loss                | 0.00066231645 |
| time_elapsed            | 2146          |
| total timesteps         | 445900        |
| value_loss              | 0.00010749498 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008772436  |
| ent_coef_loss           | 1.1193643     |
| entropy                 | 1.8455982     |
| ep_rewmean              | -2.37         |
| episodes                | 4464          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 446201        |
| policy_loss             | 0.7360227     |
| qf1_loss                | 0.00025701112 |
| qf2_loss                | 0.00018895481 |
| time_elapsed            | 2148          |
| total timesteps         | 446300        |
| value_loss              | 0.0002020545  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008826479  |
| ent_coef_loss           | -0.30001903   |
| entropy                 | 1.6182071     |
| ep_rewmean              | -2.3          |
| episodes                | 4468          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 446601        |
| policy_loss             | 0.6749671     |
| qf1_loss                | 0.0043370184  |
| qf2_loss                | 0.0048333597  |
| time_elapsed            | 2150          |
| total timesteps         | 446700        |
| value_loss              | 0.00017779696 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008881702  |
| ent_coef_loss           | -0.76123214   |
| entropy                 | 1.858777      |
| ep_rewmean              | -2.3          |
| episodes                | 4472          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 447001        |
| policy_loss             | 0.6838684     |
| qf1_loss                | 0.004191244   |
| qf2_loss                | 0.0042093922  |
| time_elapsed            | 2151          |
| total timesteps         | 447100        |
| value_loss              | 0.00012977785 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008640716  |
| ent_coef_loss           | 4.7020755     |
| entropy                 | 1.5507333     |
| ep_rewmean              | -2.26         |
| episodes                | 4476          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 447401        |
| policy_loss             | 0.73818666    |
| qf1_loss                | 0.011874492   |
| qf2_loss                | 0.011244892   |
| time_elapsed            | 2153          |
| total timesteps         | 447500        |
| value_loss              | 0.00022430645 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000860453   |
| ent_coef_loss           | 0.60404575    |
| entropy                 | 1.8368503     |
| ep_rewmean              | -2.22         |
| episodes                | 4480          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 447801        |
| policy_loss             | 0.6774932     |
| qf1_loss                | 0.0010497015  |
| qf2_loss                | 0.0007693624  |
| time_elapsed            | 2155          |
| total timesteps         | 447900        |
| value_loss              | 0.00031419614 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00088000746 |
| ent_coef_loss           | -0.5135084    |
| entropy                 | 2.1993804     |
| ep_rewmean              | -2.18         |
| episodes                | 4484          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 448201        |
| policy_loss             | 0.6993823     |
| qf1_loss                | 0.009220407   |
| qf2_loss                | 0.009102771   |
| time_elapsed            | 2157          |
| total timesteps         | 448300        |
| value_loss              | 0.00014473412 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009315159  |
| ent_coef_loss           | -0.4407395    |
| entropy                 | 1.716955      |
| ep_rewmean              | -2.24         |
| episodes                | 4488          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 448601        |
| policy_loss             | 0.69091237    |
| qf1_loss                | 0.00047362357 |
| qf2_loss                | 0.00038595815 |
| time_elapsed            | 2159          |
| total timesteps         | 448700        |
| value_loss              | 0.00013350823 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009517564  |
| ent_coef_loss           | 5.695693      |
| entropy                 | 1.7371081     |
| ep_rewmean              | -2.26         |
| episodes                | 4492          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 449001        |
| policy_loss             | 0.7332643     |
| qf1_loss                | 0.006230849   |
| qf2_loss                | 0.006203174   |
| time_elapsed            | 2161          |
| total timesteps         | 449100        |
| value_loss              | 9.9246594e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00097322895 |
| ent_coef_loss           | -3.900806     |
| entropy                 | 2.0287569     |
| ep_rewmean              | -2.28         |
| episodes                | 4496          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 449401        |
| policy_loss             | 0.7000414     |
| qf1_loss                | 0.0004295875  |
| qf2_loss                | 0.00040600574 |
| time_elapsed            | 2163          |
| total timesteps         | 449500        |
| value_loss              | 0.00019798268 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009363187  |
| ent_coef_loss           | -2.8823094    |
| entropy                 | 1.8528097     |
| ep_rewmean              | -2.31         |
| episodes                | 4500          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 449801        |
| policy_loss             | 0.7341636     |
| qf1_loss                | 0.0003851362  |
| qf2_loss                | 0.00027528207 |
| time_elapsed            | 2165          |
| total timesteps         | 449900        |
| value_loss              | 0.00014458223 |
-------------------------------------------
Eval num_timesteps=450000, episode_reward=-2.31 +/- 0.82
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00094096863 |
| ent_coef_loss           | -3.4754314    |
| entropy                 | 1.6743815     |
| ep_rewmean              | -2.39         |
| episodes                | 4504          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 450201        |
| policy_loss             | 0.74223757    |
| qf1_loss                | 0.0002625777  |
| qf2_loss                | 0.00026169885 |
| time_elapsed            | 2167          |
| total timesteps         | 450300        |
| value_loss              | 0.00012315689 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00089753093  |
| ent_coef_loss           | -3.558842      |
| entropy                 | 1.5263722      |
| ep_rewmean              | -2.39          |
| episodes                | 4508           |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -2.4           |
| n_updates               | 450601         |
| policy_loss             | 0.7310964      |
| qf1_loss                | 0.00033530383  |
| qf2_loss                | 0.00042045204  |
| time_elapsed            | 2169           |
| total timesteps         | 450700         |
| value_loss              | 0.000106190346 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009083732  |
| ent_coef_loss           | -10.56109     |
| entropy                 | 1.8496356     |
| ep_rewmean              | -2.4          |
| episodes                | 4512          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 451001        |
| policy_loss             | 0.77245355    |
| qf1_loss                | 0.00025235701 |
| qf2_loss                | 0.00012506815 |
| time_elapsed            | 2171          |
| total timesteps         | 451100        |
| value_loss              | 0.00011959618 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009285252  |
| ent_coef_loss           | 4.8486204     |
| entropy                 | 1.7987787     |
| ep_rewmean              | -2.35         |
| episodes                | 4516          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 451401        |
| policy_loss             | 0.7713521     |
| qf1_loss                | 0.0046683927  |
| qf2_loss                | 0.0049962327  |
| time_elapsed            | 2173          |
| total timesteps         | 451500        |
| value_loss              | 0.00024033096 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009393816  |
| ent_coef_loss           | -5.9736805    |
| entropy                 | 2.4808629     |
| ep_rewmean              | -2.37         |
| episodes                | 4520          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 451801        |
| policy_loss             | 0.7181208     |
| qf1_loss                | 0.005160672   |
| qf2_loss                | 0.005063391   |
| time_elapsed            | 2175          |
| total timesteps         | 451900        |
| value_loss              | 0.00012823821 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0009237548 |
| ent_coef_loss           | -2.6499548   |
| entropy                 | 1.3182456    |
| ep_rewmean              | -2.33        |
| episodes                | 4524         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 452201       |
| policy_loss             | 0.7718222    |
| qf1_loss                | 0.005282761  |
| qf2_loss                | 0.0052417666 |
| time_elapsed            | 2177         |
| total timesteps         | 452300       |
| value_loss              | 0.0002797137 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009177145  |
| ent_coef_loss           | 0.16010284    |
| entropy                 | 1.1907506     |
| ep_rewmean              | -2.3          |
| episodes                | 4528          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 452601        |
| policy_loss             | 0.7682077     |
| qf1_loss                | 0.00034112757 |
| qf2_loss                | 0.00037148184 |
| time_elapsed            | 2179          |
| total timesteps         | 452700        |
| value_loss              | 0.00021864788 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00094325526 |
| ent_coef_loss           | -0.90007496   |
| entropy                 | 1.7372963     |
| ep_rewmean              | -2.33         |
| episodes                | 4532          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 453001        |
| policy_loss             | 0.78094196    |
| qf1_loss                | 0.0040797396  |
| qf2_loss                | 0.0042358283  |
| time_elapsed            | 2181          |
| total timesteps         | 453100        |
| value_loss              | 0.00017850523 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009705725  |
| ent_coef_loss           | 9.96382       |
| entropy                 | 1.370319      |
| ep_rewmean              | -2.23         |
| episodes                | 4536          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 453401        |
| policy_loss             | 0.78105843    |
| qf1_loss                | 0.00046245923 |
| qf2_loss                | 0.00047395081 |
| time_elapsed            | 2183          |
| total timesteps         | 453500        |
| value_loss              | 0.00036071657 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009961056  |
| ent_coef_loss           | -0.25747678   |
| entropy                 | 0.59711736    |
| ep_rewmean              | -2.17         |
| episodes                | 4540          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 453801        |
| policy_loss             | 0.8095095     |
| qf1_loss                | 0.0002840449  |
| qf2_loss                | 0.000281726   |
| time_elapsed            | 2185          |
| total timesteps         | 453900        |
| value_loss              | 0.00013800371 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010409729  |
| ent_coef_loss           | -1.1408522    |
| entropy                 | 1.4313047     |
| ep_rewmean              | -2.08         |
| episodes                | 4544          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 454201        |
| policy_loss             | 0.8107698     |
| qf1_loss                | 0.006204019   |
| qf2_loss                | 0.006089303   |
| time_elapsed            | 2186          |
| total timesteps         | 454300        |
| value_loss              | 0.00033972648 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010745722 |
| ent_coef_loss           | 5.735462     |
| entropy                 | 1.6420085    |
| ep_rewmean              | -1.98        |
| episodes                | 4548         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 454601       |
| policy_loss             | 0.835747     |
| qf1_loss                | 0.007172377  |
| qf2_loss                | 0.0068145622 |
| time_elapsed            | 2188         |
| total timesteps         | 454700       |
| value_loss              | 0.0003324556 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011516357  |
| ent_coef_loss           | 6.883313      |
| entropy                 | 1.7067682     |
| ep_rewmean              | -1.94         |
| episodes                | 4552          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 455001        |
| policy_loss             | 0.81339824    |
| qf1_loss                | 0.006085482   |
| qf2_loss                | 0.00634537    |
| time_elapsed            | 2190          |
| total timesteps         | 455100        |
| value_loss              | 0.00022718363 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012175796  |
| ent_coef_loss           | 0.7223134     |
| entropy                 | 2.270663      |
| ep_rewmean              | -1.96         |
| episodes                | 4556          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 455401        |
| policy_loss             | 0.8419486     |
| qf1_loss                | 0.00045430026 |
| qf2_loss                | 0.00048543507 |
| time_elapsed            | 2192          |
| total timesteps         | 455500        |
| value_loss              | 0.00023129352 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012526187  |
| ent_coef_loss           | 1.4754243     |
| entropy                 | 2.0404744     |
| ep_rewmean              | -1.94         |
| episodes                | 4560          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 455801        |
| policy_loss             | 0.78976214    |
| qf1_loss                | 0.0010696163  |
| qf2_loss                | 0.00091281417 |
| time_elapsed            | 2194          |
| total timesteps         | 455900        |
| value_loss              | 0.00030342917 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012826093  |
| ent_coef_loss           | 0.06785512    |
| entropy                 | 1.8354464     |
| ep_rewmean              | -1.97         |
| episodes                | 4564          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 456201        |
| policy_loss             | 0.82635856    |
| qf1_loss                | 0.008265882   |
| qf2_loss                | 0.007899918   |
| time_elapsed            | 2196          |
| total timesteps         | 456300        |
| value_loss              | 0.00025176606 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013505536  |
| ent_coef_loss           | 0.89651394    |
| entropy                 | 1.6362963     |
| ep_rewmean              | -2            |
| episodes                | 4568          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 456601        |
| policy_loss             | 0.8370974     |
| qf1_loss                | 0.0002572146  |
| qf2_loss                | 0.00021485944 |
| time_elapsed            | 2198          |
| total timesteps         | 456700        |
| value_loss              | 0.0003526599  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014615366  |
| ent_coef_loss           | 2.3795831     |
| entropy                 | 2.8475556     |
| ep_rewmean              | -1.97         |
| episodes                | 4572          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 457001        |
| policy_loss             | 0.8535925     |
| qf1_loss                | 0.0009760839  |
| qf2_loss                | 0.0007492992  |
| time_elapsed            | 2200          |
| total timesteps         | 457100        |
| value_loss              | 0.00038196126 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015405379  |
| ent_coef_loss           | -2.2693543    |
| entropy                 | 2.86867       |
| ep_rewmean              | -1.96         |
| episodes                | 4576          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 457401        |
| policy_loss             | 0.8391986     |
| qf1_loss                | 0.011391249   |
| qf2_loss                | 0.011999064   |
| time_elapsed            | 2202          |
| total timesteps         | 457500        |
| value_loss              | 0.00022953589 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015585442  |
| ent_coef_loss           | -3.9089248    |
| entropy                 | 2.3992045     |
| ep_rewmean              | -1.95         |
| episodes                | 4580          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 457801        |
| policy_loss             | 0.85034394    |
| qf1_loss                | 0.000373245   |
| qf2_loss                | 0.00036023516 |
| time_elapsed            | 2204          |
| total timesteps         | 457900        |
| value_loss              | 0.0002711728  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001492811   |
| ent_coef_loss           | 2.7302392     |
| entropy                 | 2.0947251     |
| ep_rewmean              | -1.96         |
| episodes                | 4584          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 458201        |
| policy_loss             | 0.90274847    |
| qf1_loss                | 0.0003318818  |
| qf2_loss                | 0.00037578234 |
| time_elapsed            | 2206          |
| total timesteps         | 458300        |
| value_loss              | 0.0002381766  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014530638  |
| ent_coef_loss           | 3.1890361     |
| entropy                 | 1.9708116     |
| ep_rewmean              | -1.9          |
| episodes                | 4588          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 458601        |
| policy_loss             | 0.8513089     |
| qf1_loss                | 0.0006708363  |
| qf2_loss                | 0.0005756951  |
| time_elapsed            | 2208          |
| total timesteps         | 458700        |
| value_loss              | 0.00033157942 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014599757  |
| ent_coef_loss           | -2.2357159    |
| entropy                 | 2.170216      |
| ep_rewmean              | -1.89         |
| episodes                | 4592          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 459001        |
| policy_loss             | 0.95289826    |
| qf1_loss                | 0.0072200485  |
| qf2_loss                | 0.008001021   |
| time_elapsed            | 2210          |
| total timesteps         | 459100        |
| value_loss              | 0.00030148833 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014300867  |
| ent_coef_loss           | -0.6247227    |
| entropy                 | 1.8859922     |
| ep_rewmean              | -1.9          |
| episodes                | 4596          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 459401        |
| policy_loss             | 0.9110141     |
| qf1_loss                | 0.00054806523 |
| qf2_loss                | 0.0007129864  |
| time_elapsed            | 2211          |
| total timesteps         | 459500        |
| value_loss              | 0.0003251579  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014465371  |
| ent_coef_loss           | 0.3674444     |
| entropy                 | 1.9633753     |
| ep_rewmean              | -1.9          |
| episodes                | 4600          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 459801        |
| policy_loss             | 0.9274672     |
| qf1_loss                | 0.031669352   |
| qf2_loss                | 0.029233124   |
| time_elapsed            | 2213          |
| total timesteps         | 459900        |
| value_loss              | 0.00027708904 |
-------------------------------------------
Eval num_timesteps=460000, episode_reward=-2.01 +/- 0.85
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014870244 |
| ent_coef_loss           | -0.8941258   |
| entropy                 | 2.146289     |
| ep_rewmean              | -1.85        |
| episodes                | 4604         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 460201       |
| policy_loss             | 0.9468918    |
| qf1_loss                | 0.0065585203 |
| qf2_loss                | 0.00624595   |
| time_elapsed            | 2216         |
| total timesteps         | 460300       |
| value_loss              | 0.0003776038 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015723942 |
| ent_coef_loss           | 0.81394833   |
| entropy                 | 2.183435     |
| ep_rewmean              | -1.8         |
| episodes                | 4608         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 460601       |
| policy_loss             | 1.0027864    |
| qf1_loss                | 0.011022151  |
| qf2_loss                | 0.010982892  |
| time_elapsed            | 2218         |
| total timesteps         | 460700       |
| value_loss              | 0.0003898957 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001676871   |
| ent_coef_loss           | 3.2379541     |
| entropy                 | 2.616474      |
| ep_rewmean              | -1.79         |
| episodes                | 4612          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 461001        |
| policy_loss             | 0.93507063    |
| qf1_loss                | 0.005550068   |
| qf2_loss                | 0.0055205487  |
| time_elapsed            | 2219          |
| total timesteps         | 461100        |
| value_loss              | 0.00024894075 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017148794 |
| ent_coef_loss           | 1.751945     |
| entropy                 | 2.5164561    |
| ep_rewmean              | -1.84        |
| episodes                | 4616         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 461401       |
| policy_loss             | 0.92517745   |
| qf1_loss                | 0.000777067  |
| qf2_loss                | 0.0008798995 |
| time_elapsed            | 2221         |
| total timesteps         | 461500       |
| value_loss              | 0.0005601557 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017282561  |
| ent_coef_loss           | -0.33220398   |
| entropy                 | 2.135338      |
| ep_rewmean              | -1.84         |
| episodes                | 4620          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 461801        |
| policy_loss             | 0.94523495    |
| qf1_loss                | 0.015617094   |
| qf2_loss                | 0.015776105   |
| time_elapsed            | 2223          |
| total timesteps         | 461900        |
| value_loss              | 0.00026563316 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017976444  |
| ent_coef_loss           | 0.6384132     |
| entropy                 | 2.4235158     |
| ep_rewmean              | -1.88         |
| episodes                | 4624          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 462201        |
| policy_loss             | 0.94444036    |
| qf1_loss                | 0.0045513175  |
| qf2_loss                | 0.004986288   |
| time_elapsed            | 2225          |
| total timesteps         | 462300        |
| value_loss              | 0.00042535568 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018012783  |
| ent_coef_loss           | -1.6835244    |
| entropy                 | 2.5709648     |
| ep_rewmean              | -1.88         |
| episodes                | 4628          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 462601        |
| policy_loss             | 0.9570298     |
| qf1_loss                | 0.03754854    |
| qf2_loss                | 0.039149094   |
| time_elapsed            | 2227          |
| total timesteps         | 462700        |
| value_loss              | 0.00038293278 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0018016717 |
| ent_coef_loss           | 0.9229443    |
| entropy                 | 2.7475061    |
| ep_rewmean              | -1.87        |
| episodes                | 4632         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 463001       |
| policy_loss             | 0.9976108    |
| qf1_loss                | 0.0066420212 |
| qf2_loss                | 0.006578764  |
| time_elapsed            | 2229         |
| total timesteps         | 463100       |
| value_loss              | 0.0003266391 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018239126  |
| ent_coef_loss           | 2.6085753     |
| entropy                 | 2.8174992     |
| ep_rewmean              | -1.86         |
| episodes                | 4636          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 463401        |
| policy_loss             | 0.9845359     |
| qf1_loss                | 0.0050866785  |
| qf2_loss                | 0.009257756   |
| time_elapsed            | 2231          |
| total timesteps         | 463500        |
| value_loss              | 0.00029355029 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018475122  |
| ent_coef_loss           | -4.433862     |
| entropy                 | 2.9160583     |
| ep_rewmean              | -1.82         |
| episodes                | 4640          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 463801        |
| policy_loss             | 0.96890247    |
| qf1_loss                | 0.0006019437  |
| qf2_loss                | 0.00054500357 |
| time_elapsed            | 2233          |
| total timesteps         | 463900        |
| value_loss              | 0.00047559885 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018361442  |
| ent_coef_loss           | -3.5043588    |
| entropy                 | 2.475298      |
| ep_rewmean              | -1.81         |
| episodes                | 4644          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 464201        |
| policy_loss             | 0.98204434    |
| qf1_loss                | 0.00061537116 |
| qf2_loss                | 0.0005000123  |
| time_elapsed            | 2235          |
| total timesteps         | 464300        |
| value_loss              | 0.0006367442  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001871801   |
| ent_coef_loss           | 2.7641299     |
| entropy                 | 2.3116114     |
| ep_rewmean              | -1.8          |
| episodes                | 4648          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 464601        |
| policy_loss             | 0.9752273     |
| qf1_loss                | 0.004363129   |
| qf2_loss                | 0.004615832   |
| time_elapsed            | 2237          |
| total timesteps         | 464700        |
| value_loss              | 0.00041100002 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018526599  |
| ent_coef_loss           | -6.0877523    |
| entropy                 | 2.116547      |
| ep_rewmean              | -1.8          |
| episodes                | 4652          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 465001        |
| policy_loss             | 0.9268993     |
| qf1_loss                | 0.0025555275  |
| qf2_loss                | 0.002679369   |
| time_elapsed            | 2239          |
| total timesteps         | 465100        |
| value_loss              | 0.00059354934 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017770758  |
| ent_coef_loss           | -1.2463613    |
| entropy                 | 2.4814315     |
| ep_rewmean              | -1.77         |
| episodes                | 4656          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 465401        |
| policy_loss             | 0.9273096     |
| qf1_loss                | 0.00032322266 |
| qf2_loss                | 0.00022732606 |
| time_elapsed            | 2241          |
| total timesteps         | 465500        |
| value_loss              | 0.00020786418 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016863327  |
| ent_coef_loss           | 2.5447927     |
| entropy                 | 2.2856932     |
| ep_rewmean              | -1.78         |
| episodes                | 4660          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 465801        |
| policy_loss             | 0.9237659     |
| qf1_loss                | 0.0024642386  |
| qf2_loss                | 0.002473042   |
| time_elapsed            | 2243          |
| total timesteps         | 465900        |
| value_loss              | 0.00025843218 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016466351  |
| ent_coef_loss           | -3.5375996    |
| entropy                 | 2.3820512     |
| ep_rewmean              | -1.76         |
| episodes                | 4664          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 466201        |
| policy_loss             | 0.95230687    |
| qf1_loss                | 0.0066080187  |
| qf2_loss                | 0.00673366    |
| time_elapsed            | 2245          |
| total timesteps         | 466300        |
| value_loss              | 0.00024656134 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016015684  |
| ent_coef_loss           | -4.793017     |
| entropy                 | 2.0539901     |
| ep_rewmean              | -1.7          |
| episodes                | 4668          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 466601        |
| policy_loss             | 0.9512447     |
| qf1_loss                | 0.019026993   |
| qf2_loss                | 0.018149849   |
| time_elapsed            | 2247          |
| total timesteps         | 466700        |
| value_loss              | 0.00024813408 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015105922  |
| ent_coef_loss           | -8.073074     |
| entropy                 | 2.17129       |
| ep_rewmean              | -1.73         |
| episodes                | 4672          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 467001        |
| policy_loss             | 0.8685194     |
| qf1_loss                | 0.0093214465  |
| qf2_loss                | 0.008870546   |
| time_elapsed            | 2249          |
| total timesteps         | 467100        |
| value_loss              | 0.00047794386 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014527783  |
| ent_coef_loss           | -4.7152576    |
| entropy                 | 1.9423987     |
| ep_rewmean              | -1.74         |
| episodes                | 4676          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 467401        |
| policy_loss             | 0.94389427    |
| qf1_loss                | 0.004677499   |
| qf2_loss                | 0.004826265   |
| time_elapsed            | 2251          |
| total timesteps         | 467500        |
| value_loss              | 0.00032158376 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014368022  |
| ent_coef_loss           | -2.6867337    |
| entropy                 | 2.0485072     |
| ep_rewmean              | -1.71         |
| episodes                | 4680          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 467801        |
| policy_loss             | 0.90537894    |
| qf1_loss                | 0.0047682794  |
| qf2_loss                | 0.0049952767  |
| time_elapsed            | 2253          |
| total timesteps         | 467900        |
| value_loss              | 0.00027742548 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015245037  |
| ent_coef_loss           | 13.6932335    |
| entropy                 | 2.4300413     |
| ep_rewmean              | -1.68         |
| episodes                | 4684          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 468201        |
| policy_loss             | 0.92622733    |
| qf1_loss                | 0.00044618474 |
| qf2_loss                | 0.00040825416 |
| time_elapsed            | 2254          |
| total timesteps         | 468300        |
| value_loss              | 0.000400393   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017011772  |
| ent_coef_loss           | 1.5841298     |
| entropy                 | 2.6110024     |
| ep_rewmean              | -1.66         |
| episodes                | 4688          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 468601        |
| policy_loss             | 0.9433696     |
| qf1_loss                | 0.01590774    |
| qf2_loss                | 0.016363127   |
| time_elapsed            | 2256          |
| total timesteps         | 468700        |
| value_loss              | 0.00040910346 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018251898  |
| ent_coef_loss           | 2.744691      |
| entropy                 | 2.6305444     |
| ep_rewmean              | -1.65         |
| episodes                | 4692          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 469001        |
| policy_loss             | 0.91541207    |
| qf1_loss                | 0.00060869206 |
| qf2_loss                | 0.00043930043 |
| time_elapsed            | 2258          |
| total timesteps         | 469100        |
| value_loss              | 0.000586102   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019277047  |
| ent_coef_loss           | 4.810009      |
| entropy                 | 2.77247       |
| ep_rewmean              | -1.65         |
| episodes                | 4696          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 469401        |
| policy_loss             | 0.89119685    |
| qf1_loss                | 0.00050537096 |
| qf2_loss                | 0.00045705625 |
| time_elapsed            | 2260          |
| total timesteps         | 469500        |
| value_loss              | 0.00034559722 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019846817  |
| ent_coef_loss           | -1.3943648    |
| entropy                 | 3.590252      |
| ep_rewmean              | -1.6          |
| episodes                | 4700          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 469801        |
| policy_loss             | 0.9747287     |
| qf1_loss                | 0.0006947524  |
| qf2_loss                | 0.00050086214 |
| time_elapsed            | 2262          |
| total timesteps         | 469900        |
| value_loss              | 0.00037680546 |
-------------------------------------------
Eval num_timesteps=470000, episode_reward=-2.35 +/- 0.85
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001910715   |
| ent_coef_loss           | -6.3688893    |
| entropy                 | 3.0160718     |
| ep_rewmean              | -1.57         |
| episodes                | 4704          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 470201        |
| policy_loss             | 0.9569709     |
| qf1_loss                | 0.0002690178  |
| qf2_loss                | 0.00022082427 |
| time_elapsed            | 2264          |
| total timesteps         | 470300        |
| value_loss              | 0.00027000415 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021524448  |
| ent_coef_loss           | 13.604133     |
| entropy                 | 3.7793899     |
| ep_rewmean              | -1.63         |
| episodes                | 4708          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 470601        |
| policy_loss             | 0.94675726    |
| qf1_loss                | 0.016527457   |
| qf2_loss                | 0.016905962   |
| time_elapsed            | 2266          |
| total timesteps         | 470700        |
| value_loss              | 0.00049328967 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002357675   |
| ent_coef_loss           | 4.575448      |
| entropy                 | 3.8241084     |
| ep_rewmean              | -1.66         |
| episodes                | 4712          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 471001        |
| policy_loss             | 0.9848154     |
| qf1_loss                | 0.00079893775 |
| qf2_loss                | 0.00046107848 |
| time_elapsed            | 2268          |
| total timesteps         | 471100        |
| value_loss              | 0.00059082353 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002510971   |
| ent_coef_loss           | 5.7691936     |
| entropy                 | 3.8481183     |
| ep_rewmean              | -1.63         |
| episodes                | 4716          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 471401        |
| policy_loss             | 0.9411187     |
| qf1_loss                | 0.0024727024  |
| qf2_loss                | 0.0029193875  |
| time_elapsed            | 2270          |
| total timesteps         | 471500        |
| value_loss              | 0.00060407876 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0026165266 |
| ent_coef_loss           | 1.0765593    |
| entropy                 | 3.603352     |
| ep_rewmean              | -1.65        |
| episodes                | 4720         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.6         |
| n_updates               | 471801       |
| policy_loss             | 0.97129315   |
| qf1_loss                | 0.004952364  |
| qf2_loss                | 0.00480123   |
| time_elapsed            | 2272         |
| total timesteps         | 471900       |
| value_loss              | 0.0007923903 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0026395065 |
| ent_coef_loss           | -1.8020921   |
| entropy                 | 4.0308456    |
| ep_rewmean              | -1.63        |
| episodes                | 4724         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.6         |
| n_updates               | 472201       |
| policy_loss             | 1.0162632    |
| qf1_loss                | 0.0002844415 |
| qf2_loss                | 0.0003087428 |
| time_elapsed            | 2274         |
| total timesteps         | 472300       |
| value_loss              | 0.0004881385 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0026371237  |
| ent_coef_loss           | -3.16222      |
| entropy                 | 4.0767713     |
| ep_rewmean              | -1.66         |
| episodes                | 4728          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 472601        |
| policy_loss             | 1.0469518     |
| qf1_loss                | 0.00042150443 |
| qf2_loss                | 0.00033263047 |
| time_elapsed            | 2276          |
| total timesteps         | 472700        |
| value_loss              | 0.000620406   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002591629   |
| ent_coef_loss           | 0.93250287    |
| entropy                 | 4.000622      |
| ep_rewmean              | -1.62         |
| episodes                | 4732          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 473001        |
| policy_loss             | 1.0443463     |
| qf1_loss                | 0.0030254382  |
| qf2_loss                | 0.0030793338  |
| time_elapsed            | 2278          |
| total timesteps         | 473100        |
| value_loss              | 0.00040905914 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0026879595  |
| ent_coef_loss           | 4.6007633     |
| entropy                 | 3.7552912     |
| ep_rewmean              | -1.64         |
| episodes                | 4736          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 473401        |
| policy_loss             | 1.1390275     |
| qf1_loss                | 0.00042155272 |
| qf2_loss                | 0.0003216307  |
| time_elapsed            | 2280          |
| total timesteps         | 473500        |
| value_loss              | 0.00032997673 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0027655368  |
| ent_coef_loss           | 2.8270998     |
| entropy                 | 3.633667      |
| ep_rewmean              | -1.68         |
| episodes                | 4740          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 473801        |
| policy_loss             | 1.1212916     |
| qf1_loss                | 0.052172817   |
| qf2_loss                | 0.053676337   |
| time_elapsed            | 2282          |
| total timesteps         | 473900        |
| value_loss              | 0.00068545167 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0027836647  |
| ent_coef_loss           | -3.0656433    |
| entropy                 | 3.9909997     |
| ep_rewmean              | -1.7          |
| episodes                | 4744          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 474201        |
| policy_loss             | 1.1089648     |
| qf1_loss                | 0.028331703   |
| qf2_loss                | 0.028803697   |
| time_elapsed            | 2284          |
| total timesteps         | 474300        |
| value_loss              | 0.00042477422 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0027525502  |
| ent_coef_loss           | -0.7961333    |
| entropy                 | 3.9851851     |
| ep_rewmean              | -1.71         |
| episodes                | 4748          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 474601        |
| policy_loss             | 1.1903653     |
| qf1_loss                | 0.00747103    |
| qf2_loss                | 0.0072232746  |
| time_elapsed            | 2286          |
| total timesteps         | 474700        |
| value_loss              | 0.00085838133 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0026935856 |
| ent_coef_loss           | -1.5660648   |
| entropy                 | 3.8582635    |
| ep_rewmean              | -1.75        |
| episodes                | 4752         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 475001       |
| policy_loss             | 1.1250727    |
| qf1_loss                | 0.0053716972 |
| qf2_loss                | 0.0003785465 |
| time_elapsed            | 2288         |
| total timesteps         | 475100       |
| value_loss              | 0.0006751629 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0026504842  |
| ent_coef_loss           | -0.5309578    |
| entropy                 | 3.5055828     |
| ep_rewmean              | -1.77         |
| episodes                | 4756          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 475401        |
| policy_loss             | 1.1706333     |
| qf1_loss                | 0.0006337814  |
| qf2_loss                | 0.00068913365 |
| time_elapsed            | 2290          |
| total timesteps         | 475500        |
| value_loss              | 0.0006250101  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0026835194 |
| ent_coef_loss           | 8.1799755    |
| entropy                 | 3.80002      |
| ep_rewmean              | -1.81        |
| episodes                | 4760         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 475801       |
| policy_loss             | 1.2367783    |
| qf1_loss                | 0.010055825  |
| qf2_loss                | 0.009822721  |
| time_elapsed            | 2292         |
| total timesteps         | 475900       |
| value_loss              | 0.0005620802 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0027066448  |
| ent_coef_loss           | -8.169497     |
| entropy                 | 4.030833      |
| ep_rewmean              | -1.85         |
| episodes                | 4764          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 476201        |
| policy_loss             | 1.1870124     |
| qf1_loss                | 0.00053980807 |
| qf2_loss                | 0.00063932943 |
| time_elapsed            | 2294          |
| total timesteps         | 476300        |
| value_loss              | 0.0007611835  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0027504785  |
| ent_coef_loss           | 0.25711375    |
| entropy                 | 4.0801067     |
| ep_rewmean              | -1.92         |
| episodes                | 4768          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 476601        |
| policy_loss             | 1.2075598     |
| qf1_loss                | 0.0005876726  |
| qf2_loss                | 0.00062330544 |
| time_elapsed            | 2295          |
| total timesteps         | 476700        |
| value_loss              | 0.0007372106  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0027464184  |
| ent_coef_loss           | 2.9039154     |
| entropy                 | 3.7996204     |
| ep_rewmean              | -1.92         |
| episodes                | 4772          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 477001        |
| policy_loss             | 1.2487547     |
| qf1_loss                | 0.00082307524 |
| qf2_loss                | 0.0006869234  |
| time_elapsed            | 2297          |
| total timesteps         | 477100        |
| value_loss              | 0.001024368   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0028552134  |
| ent_coef_loss           | -2.618368     |
| entropy                 | 3.802382      |
| ep_rewmean              | -1.93         |
| episodes                | 4776          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 477401        |
| policy_loss             | 1.2447987     |
| qf1_loss                | 0.00052529445 |
| qf2_loss                | 0.0004168243  |
| time_elapsed            | 2299          |
| total timesteps         | 477500        |
| value_loss              | 0.00036978064 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0028257798 |
| ent_coef_loss           | -2.8564005   |
| entropy                 | 3.8017292    |
| ep_rewmean              | -1.95        |
| episodes                | 4780         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 477801       |
| policy_loss             | 1.2354116    |
| qf1_loss                | 0.0006284985 |
| qf2_loss                | 0.0004780378 |
| time_elapsed            | 2301         |
| total timesteps         | 477900       |
| value_loss              | 0.000370623  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0028668777  |
| ent_coef_loss           | 5.6569386     |
| entropy                 | 3.704294      |
| ep_rewmean              | -1.95         |
| episodes                | 4784          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 478201        |
| policy_loss             | 1.2443787     |
| qf1_loss                | 0.00078279804 |
| qf2_loss                | 0.0006377344  |
| time_elapsed            | 2303          |
| total timesteps         | 478300        |
| value_loss              | 0.0005037045  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0029463673 |
| ent_coef_loss           | 1.4524924    |
| entropy                 | 3.6442053    |
| ep_rewmean              | -1.95        |
| episodes                | 4788         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 478601       |
| policy_loss             | 1.2693303    |
| qf1_loss                | 0.007956196  |
| qf2_loss                | 0.00782064   |
| time_elapsed            | 2305         |
| total timesteps         | 478700       |
| value_loss              | 0.0010247428 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0029653583  |
| ent_coef_loss           | -3.3220944    |
| entropy                 | 3.470478      |
| ep_rewmean              | -2.01         |
| episodes                | 4792          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 479001        |
| policy_loss             | 1.2673945     |
| qf1_loss                | 0.03905039    |
| qf2_loss                | 0.039470356   |
| time_elapsed            | 2307          |
| total timesteps         | 479100        |
| value_loss              | 0.00067848817 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0029524486  |
| ent_coef_loss           | 5.71284       |
| entropy                 | 3.6967347     |
| ep_rewmean              | -2            |
| episodes                | 4796          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 479401        |
| policy_loss             | 1.2695296     |
| qf1_loss                | 0.00092030206 |
| qf2_loss                | 0.0010833961  |
| time_elapsed            | 2309          |
| total timesteps         | 479500        |
| value_loss              | 0.00048256922 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0028790906 |
| ent_coef_loss           | -1.0389773   |
| entropy                 | 3.6495347    |
| ep_rewmean              | -2.05        |
| episodes                | 4800         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 479801       |
| policy_loss             | 1.2520046    |
| qf1_loss                | 0.024616659  |
| qf2_loss                | 0.026231738  |
| time_elapsed            | 2311         |
| total timesteps         | 479900       |
| value_loss              | 0.0008738894 |
------------------------------------------
Eval num_timesteps=480000, episode_reward=-4.67 +/- 1.06
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0027016844 |
| ent_coef_loss           | 1.2633083    |
| entropy                 | 3.4930634    |
| ep_rewmean              | -2.05        |
| episodes                | 4804         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 480201       |
| policy_loss             | 1.3141077    |
| qf1_loss                | 0.0011271342 |
| qf2_loss                | 0.0008861327 |
| time_elapsed            | 2313         |
| total timesteps         | 480300       |
| value_loss              | 0.0006153664 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0027940974  |
| ent_coef_loss           | -1.8540848    |
| entropy                 | 3.6849031     |
| ep_rewmean              | -2.05         |
| episodes                | 4808          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 480601        |
| policy_loss             | 1.2949706     |
| qf1_loss                | 0.00081314455 |
| qf2_loss                | 0.00073438336 |
| time_elapsed            | 2315          |
| total timesteps         | 480700        |
| value_loss              | 0.0005548856  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0027429685  |
| ent_coef_loss           | 2.9292338     |
| entropy                 | 3.8122678     |
| ep_rewmean              | -2.02         |
| episodes                | 4812          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 481001        |
| policy_loss             | 1.2759445     |
| qf1_loss                | 0.0005319728  |
| qf2_loss                | 0.00046231452 |
| time_elapsed            | 2317          |
| total timesteps         | 481100        |
| value_loss              | 0.0010350179  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0027469331 |
| ent_coef_loss           | -3.2365384   |
| entropy                 | 3.6858916    |
| ep_rewmean              | -2           |
| episodes                | 4816         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 481401       |
| policy_loss             | 1.3669753    |
| qf1_loss                | 0.011927037  |
| qf2_loss                | 0.01179002   |
| time_elapsed            | 2319         |
| total timesteps         | 481500       |
| value_loss              | 0.0013744575 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0027183127 |
| ent_coef_loss           | -1.359344    |
| entropy                 | 3.8401003    |
| ep_rewmean              | -1.98        |
| episodes                | 4820         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 481801       |
| policy_loss             | 1.3649086    |
| qf1_loss                | 0.0009842729 |
| qf2_loss                | 0.0007537256 |
| time_elapsed            | 2321         |
| total timesteps         | 481900       |
| value_loss              | 0.0008053453 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0027578764  |
| ent_coef_loss           | -1.9435687    |
| entropy                 | 4.084441      |
| ep_rewmean              | -2            |
| episodes                | 4824          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 482201        |
| policy_loss             | 1.294349      |
| qf1_loss                | 0.0005955826  |
| qf2_loss                | 0.00038398535 |
| time_elapsed            | 2323          |
| total timesteps         | 482300        |
| value_loss              | 0.00066679064 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0028332884 |
| ent_coef_loss           | 2.9471097    |
| entropy                 | 3.8326473    |
| ep_rewmean              | -1.97        |
| episodes                | 4828         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 482601       |
| policy_loss             | 1.3544911    |
| qf1_loss                | 0.0012596585 |
| qf2_loss                | 0.0010828598 |
| time_elapsed            | 2325         |
| total timesteps         | 482700       |
| value_loss              | 0.0022441489 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0028984773 |
| ent_coef_loss           | -1.1259921   |
| entropy                 | 3.948659     |
| ep_rewmean              | -1.98        |
| episodes                | 4832         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 483001       |
| policy_loss             | 1.372781     |
| qf1_loss                | 0.04158988   |
| qf2_loss                | 0.04140674   |
| time_elapsed            | 2327         |
| total timesteps         | 483100       |
| value_loss              | 0.0013497011 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0029065295 |
| ent_coef_loss           | -2.5277448   |
| entropy                 | 3.7918437    |
| ep_rewmean              | -1.95        |
| episodes                | 4836         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 483401       |
| policy_loss             | 1.2836759    |
| qf1_loss                | 0.10810621   |
| qf2_loss                | 0.10303269   |
| time_elapsed            | 2328         |
| total timesteps         | 483500       |
| value_loss              | 0.0017459544 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002917406  |
| ent_coef_loss           | 2.3105462    |
| entropy                 | 3.7195344    |
| ep_rewmean              | -1.94        |
| episodes                | 4840         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 483801       |
| policy_loss             | 1.3218921    |
| qf1_loss                | 0.01738715   |
| qf2_loss                | 0.016372995  |
| time_elapsed            | 2330         |
| total timesteps         | 483900       |
| value_loss              | 0.0007057525 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002832282  |
| ent_coef_loss           | -3.415774    |
| entropy                 | 4.0679264    |
| ep_rewmean              | -1.94        |
| episodes                | 4844         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 484201       |
| policy_loss             | 1.3830805    |
| qf1_loss                | 0.0012780069 |
| qf2_loss                | 0.0013038211 |
| time_elapsed            | 2332         |
| total timesteps         | 484300       |
| value_loss              | 0.001098371  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0028525284  |
| ent_coef_loss           | -0.65613407   |
| entropy                 | 3.4656668     |
| ep_rewmean              | -1.92         |
| episodes                | 4848          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 484601        |
| policy_loss             | 1.3126385     |
| qf1_loss                | 0.0010531329  |
| qf2_loss                | 0.0008774819  |
| time_elapsed            | 2334          |
| total timesteps         | 484700        |
| value_loss              | 0.00093892694 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002912455   |
| ent_coef_loss           | -1.4900498    |
| entropy                 | 3.8888097     |
| ep_rewmean              | -1.85         |
| episodes                | 4852          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 485001        |
| policy_loss             | 1.3907609     |
| qf1_loss                | 0.04202865    |
| qf2_loss                | 0.041721515   |
| time_elapsed            | 2336          |
| total timesteps         | 485100        |
| value_loss              | 0.00076027913 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0028295836  |
| ent_coef_loss           | -1.9086422    |
| entropy                 | 3.6327167     |
| ep_rewmean              | -1.85         |
| episodes                | 4856          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 485401        |
| policy_loss             | 1.2922037     |
| qf1_loss                | 0.00052434497 |
| qf2_loss                | 0.00056642015 |
| time_elapsed            | 2338          |
| total timesteps         | 485500        |
| value_loss              | 0.0013643333  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0028067096 |
| ent_coef_loss           | -4.0481367   |
| entropy                 | 3.5848675    |
| ep_rewmean              | -1.84        |
| episodes                | 4860         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 485801       |
| policy_loss             | 1.3760667    |
| qf1_loss                | 0.0014094939 |
| qf2_loss                | 0.0010385747 |
| time_elapsed            | 2340         |
| total timesteps         | 485900       |
| value_loss              | 0.0007183989 |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.002745227 |
| ent_coef_loss           | 1.757783    |
| entropy                 | 3.6421978   |
| ep_rewmean              | -1.79       |
| episodes                | 4864        |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -1.8        |
| n_updates               | 486201      |
| policy_loss             | 1.2759924   |
| qf1_loss                | 0.017304532 |
| qf2_loss                | 0.015494075 |
| time_elapsed            | 2342        |
| total timesteps         | 486300      |
| value_loss              | 0.001061881 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0027292524 |
| ent_coef_loss           | -0.49936187  |
| entropy                 | 3.3357573    |
| ep_rewmean              | -1.76        |
| episodes                | 4868         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 486601       |
| policy_loss             | 1.4246836    |
| qf1_loss                | 0.024041599  |
| qf2_loss                | 0.025399921  |
| time_elapsed            | 2344         |
| total timesteps         | 486700       |
| value_loss              | 0.0008257052 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0026895287 |
| ent_coef_loss           | 4.1107416    |
| entropy                 | 3.4222403    |
| ep_rewmean              | -1.75        |
| episodes                | 4872         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 487001       |
| policy_loss             | 1.3662931    |
| qf1_loss                | 0.013398015  |
| qf2_loss                | 0.012853051  |
| time_elapsed            | 2346         |
| total timesteps         | 487100       |
| value_loss              | 0.0005246904 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0026700648  |
| ent_coef_loss           | 7.22729       |
| entropy                 | 3.902245      |
| ep_rewmean              | -1.74         |
| episodes                | 4876          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 487401        |
| policy_loss             | 1.3875662     |
| qf1_loss                | 0.00046262975 |
| qf2_loss                | 0.00047273326 |
| time_elapsed            | 2348          |
| total timesteps         | 487500        |
| value_loss              | 0.0008158897  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0026383223  |
| ent_coef_loss           | -0.6243074    |
| entropy                 | 3.9972854     |
| ep_rewmean              | -1.75         |
| episodes                | 4880          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 487801        |
| policy_loss             | 1.3168476     |
| qf1_loss                | 0.00036851573 |
| qf2_loss                | 0.0005199872  |
| time_elapsed            | 2350          |
| total timesteps         | 487900        |
| value_loss              | 0.000812288   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002599338   |
| ent_coef_loss           | 6.5575585     |
| entropy                 | 3.8914437     |
| ep_rewmean              | -1.75         |
| episodes                | 4884          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 488201        |
| policy_loss             | 1.343703      |
| qf1_loss                | 0.00066090235 |
| qf2_loss                | 0.0007503296  |
| time_elapsed            | 2352          |
| total timesteps         | 488300        |
| value_loss              | 0.002485878   |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0025697532 |
| ent_coef_loss           | 0.73412085   |
| entropy                 | 4.0378428    |
| ep_rewmean              | -1.71        |
| episodes                | 4888         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 488601       |
| policy_loss             | 1.3542626    |
| qf1_loss                | 0.018218383  |
| qf2_loss                | 0.01853221   |
| time_elapsed            | 2354         |
| total timesteps         | 488700       |
| value_loss              | 0.000892307  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0027536438  |
| ent_coef_loss           | 2.8135962     |
| entropy                 | 4.603155      |
| ep_rewmean              | -1.67         |
| episodes                | 4892          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 489001        |
| policy_loss             | 1.390499      |
| qf1_loss                | 0.00048283752 |
| qf2_loss                | 0.00045732845 |
| time_elapsed            | 2356          |
| total timesteps         | 489100        |
| value_loss              | 0.00072727667 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0026717104  |
| ent_coef_loss           | -1.6819403    |
| entropy                 | 4.461528      |
| ep_rewmean              | -1.66         |
| episodes                | 4896          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 489401        |
| policy_loss             | 1.3323421     |
| qf1_loss                | 0.0329133     |
| qf2_loss                | 0.03460725    |
| time_elapsed            | 2357          |
| total timesteps         | 489500        |
| value_loss              | 0.00074344233 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0025859606  |
| ent_coef_loss           | 0.5070361     |
| entropy                 | 4.2565923     |
| ep_rewmean              | -1.65         |
| episodes                | 4900          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 489801        |
| policy_loss             | 1.2028375     |
| qf1_loss                | 0.0008070284  |
| qf2_loss                | 0.0010887024  |
| time_elapsed            | 2359          |
| total timesteps         | 489900        |
| value_loss              | 0.00072440144 |
-------------------------------------------
Eval num_timesteps=490000, episode_reward=-2.10 +/- 0.82
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002587084  |
| ent_coef_loss           | -2.0438137   |
| entropy                 | 4.3204546    |
| ep_rewmean              | -1.62        |
| episodes                | 4904         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.6         |
| n_updates               | 490201       |
| policy_loss             | 1.3191912    |
| qf1_loss                | 0.009802014  |
| qf2_loss                | 0.009557628  |
| time_elapsed            | 2362         |
| total timesteps         | 490300       |
| value_loss              | 0.0006990619 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002609493   |
| ent_coef_loss           | -0.38766265   |
| entropy                 | 4.1481657     |
| ep_rewmean              | -1.59         |
| episodes                | 4908          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 490601        |
| policy_loss             | 1.389647      |
| qf1_loss                | 0.04866581    |
| qf2_loss                | 0.048098065   |
| time_elapsed            | 2364          |
| total timesteps         | 490700        |
| value_loss              | 0.00082385127 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0027548075 |
| ent_coef_loss           | -8.669471    |
| entropy                 | 4.679269     |
| ep_rewmean              | -1.63        |
| episodes                | 4912         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.6         |
| n_updates               | 491001       |
| policy_loss             | 1.2440983    |
| qf1_loss                | 0.015052329  |
| qf2_loss                | 0.014855495  |
| time_elapsed            | 2365         |
| total timesteps         | 491100       |
| value_loss              | 0.0008052789 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0028683161  |
| ent_coef_loss           | 1.7684033     |
| entropy                 | 3.3190818     |
| ep_rewmean              | -1.69         |
| episodes                | 4916          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 491401        |
| policy_loss             | 1.355573      |
| qf1_loss                | 0.016583722   |
| qf2_loss                | 0.017927686   |
| time_elapsed            | 2367          |
| total timesteps         | 491500        |
| value_loss              | 0.00097205275 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0028265319  |
| ent_coef_loss           | -1.9246972    |
| entropy                 | 3.6191998     |
| ep_rewmean              | -1.73         |
| episodes                | 4920          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 491801        |
| policy_loss             | 1.2873447     |
| qf1_loss                | 0.00047312287 |
| qf2_loss                | 0.0005560722  |
| time_elapsed            | 2369          |
| total timesteps         | 491900        |
| value_loss              | 0.00090546545 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0028623387 |
| ent_coef_loss           | 6.7971       |
| entropy                 | 3.4485228    |
| ep_rewmean              | -1.74        |
| episodes                | 4924         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 492201       |
| policy_loss             | 1.2987671    |
| qf1_loss                | 0.02172017   |
| qf2_loss                | 0.01884609   |
| time_elapsed            | 2371         |
| total timesteps         | 492300       |
| value_loss              | 0.0017302711 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002808612  |
| ent_coef_loss           | -7.06716     |
| entropy                 | 3.6269424    |
| ep_rewmean              | -1.77        |
| episodes                | 4928         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 492601       |
| policy_loss             | 1.3311741    |
| qf1_loss                | 0.0022902212 |
| qf2_loss                | 0.0015413711 |
| time_elapsed            | 2373         |
| total timesteps         | 492700       |
| value_loss              | 0.00105055   |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.00271      |
| ent_coef_loss           | -0.13167977  |
| entropy                 | 3.27677      |
| ep_rewmean              | -1.78        |
| episodes                | 4932         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 493001       |
| policy_loss             | 1.3033206    |
| qf1_loss                | 0.0010520366 |
| qf2_loss                | 0.0015619106 |
| time_elapsed            | 2375         |
| total timesteps         | 493100       |
| value_loss              | 0.000765014  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002616267   |
| ent_coef_loss           | -3.609639     |
| entropy                 | 3.6121068     |
| ep_rewmean              | -1.84         |
| episodes                | 4936          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 493401        |
| policy_loss             | 1.4594288     |
| qf1_loss                | 0.073277056   |
| qf2_loss                | 0.07140825    |
| time_elapsed            | 2377          |
| total timesteps         | 493500        |
| value_loss              | 0.00051482697 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0024932153  |
| ent_coef_loss           | -3.2311006    |
| entropy                 | 3.6003528     |
| ep_rewmean              | -1.91         |
| episodes                | 4940          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 493801        |
| policy_loss             | 1.3922548     |
| qf1_loss                | 0.0005932886  |
| qf2_loss                | 0.0009868024  |
| time_elapsed            | 2379          |
| total timesteps         | 493900        |
| value_loss              | 0.00089245883 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0025387965 |
| ent_coef_loss           | -3.8311284   |
| entropy                 | 3.400312     |
| ep_rewmean              | -1.91        |
| episodes                | 4944         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 494201       |
| policy_loss             | 1.273901     |
| qf1_loss                | 0.0072478494 |
| qf2_loss                | 0.008088443  |
| time_elapsed            | 2381         |
| total timesteps         | 494300       |
| value_loss              | 0.0015519111 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002555983  |
| ent_coef_loss           | 7.541779     |
| entropy                 | 3.4770093    |
| ep_rewmean              | -1.94        |
| episodes                | 4948         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 494601       |
| policy_loss             | 1.425846     |
| qf1_loss                | 0.039663047  |
| qf2_loss                | 0.039985053  |
| time_elapsed            | 2383         |
| total timesteps         | 494700       |
| value_loss              | 0.0010786129 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0030136018 |
| ent_coef_loss           | 11.153256    |
| entropy                 | 4.569195     |
| ep_rewmean              | -1.97        |
| episodes                | 4952         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 495001       |
| policy_loss             | 1.2667812    |
| qf1_loss                | 0.0020543644 |
| qf2_loss                | 0.0012877795 |
| time_elapsed            | 2385         |
| total timesteps         | 495100       |
| value_loss              | 0.0019563523 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0034269765 |
| ent_coef_loss           | 11.979502    |
| entropy                 | 3.7711716    |
| ep_rewmean              | -1.98        |
| episodes                | 4956         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 495401       |
| policy_loss             | 1.3519577    |
| qf1_loss                | 0.0013158314 |
| qf2_loss                | 0.001274156  |
| time_elapsed            | 2387         |
| total timesteps         | 495500       |
| value_loss              | 0.004610248  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.003649955 |
| ent_coef_loss           | 12.453869   |
| entropy                 | 3.7494755   |
| ep_rewmean              | -1.98       |
| episodes                | 4960        |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2          |
| n_updates               | 495801      |
| policy_loss             | 1.2033067   |
| qf1_loss                | 0.008127239 |
| qf2_loss                | 0.00806628  |
| time_elapsed            | 2389        |
| total timesteps         | 495900      |
| value_loss              | 0.001667585 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0037017276 |
| ent_coef_loss           | -5.5802536   |
| entropy                 | 4.208805     |
| ep_rewmean              | -1.98        |
| episodes                | 4964         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 496201       |
| policy_loss             | 1.1868088    |
| qf1_loss                | 0.0063218153 |
| qf2_loss                | 0.0055797626 |
| time_elapsed            | 2390         |
| total timesteps         | 496300       |
| value_loss              | 0.0013336375 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0036214404 |
| ent_coef_loss           | -7.360318    |
| entropy                 | 4.442184     |
| ep_rewmean              | -1.97        |
| episodes                | 4968         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 496601       |
| policy_loss             | 1.217919     |
| qf1_loss                | 0.0080173705 |
| qf2_loss                | 0.008065617  |
| time_elapsed            | 2392         |
| total timesteps         | 496700       |
| value_loss              | 0.0007399487 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.003426867  |
| ent_coef_loss           | -14.592459   |
| entropy                 | 4.5352154    |
| ep_rewmean              | -2.01        |
| episodes                | 4972         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 497001       |
| policy_loss             | 1.1473039    |
| qf1_loss                | 0.0005666742 |
| qf2_loss                | 0.0006490297 |
| time_elapsed            | 2394         |
| total timesteps         | 497100       |
| value_loss              | 0.0008755856 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0033711414  |
| ent_coef_loss           | -1.1730497    |
| entropy                 | 4.554238      |
| ep_rewmean              | -2.01         |
| episodes                | 4976          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 497401        |
| policy_loss             | 1.2472165     |
| qf1_loss                | 0.00091416267 |
| qf2_loss                | 0.0007405336  |
| time_elapsed            | 2396          |
| total timesteps         | 497500        |
| value_loss              | 0.0008161722  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0032638547  |
| ent_coef_loss           | -2.8413167    |
| entropy                 | 4.427162      |
| ep_rewmean              | -1.99         |
| episodes                | 4980          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 497801        |
| policy_loss             | 1.2406547     |
| qf1_loss                | 0.00094698323 |
| qf2_loss                | 0.0006763522  |
| time_elapsed            | 2398          |
| total timesteps         | 497900        |
| value_loss              | 0.0008766039  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.003152483  |
| ent_coef_loss           | -1.9562347   |
| entropy                 | 4.005212     |
| ep_rewmean              | -1.99        |
| episodes                | 4984         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 498201       |
| policy_loss             | 1.0327923    |
| qf1_loss                | 0.0033578547 |
| qf2_loss                | 0.0024566455 |
| time_elapsed            | 2400         |
| total timesteps         | 498300       |
| value_loss              | 0.0013565482 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0031247241 |
| ent_coef_loss           | 3.6862786    |
| entropy                 | 4.752811     |
| ep_rewmean              | -2           |
| episodes                | 4988         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 498601       |
| policy_loss             | 1.0496438    |
| qf1_loss                | 0.0029088408 |
| qf2_loss                | 0.0026992585 |
| time_elapsed            | 2402         |
| total timesteps         | 498700       |
| value_loss              | 0.0009354335 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0032177274 |
| ent_coef_loss           | -0.87668276  |
| entropy                 | 3.8338242    |
| ep_rewmean              | -2.03        |
| episodes                | 4992         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 499001       |
| policy_loss             | 0.8767997    |
| qf1_loss                | 0.025529869  |
| qf2_loss                | 0.02446996   |
| time_elapsed            | 2404         |
| total timesteps         | 499100       |
| value_loss              | 0.0009148128 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0033416834 |
| ent_coef_loss           | 5.645685     |
| entropy                 | 4.716104     |
| ep_rewmean              | -2.03        |
| episodes                | 4996         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 499401       |
| policy_loss             | 1.0437825    |
| qf1_loss                | 0.0024817134 |
| qf2_loss                | 0.0022745046 |
| time_elapsed            | 2406         |
| total timesteps         | 499500       |
| value_loss              | 0.0009238067 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.003316997  |
| ent_coef_loss           | 0.20987391   |
| entropy                 | 4.6547685    |
| ep_rewmean              | -1.98        |
| episodes                | 5000         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 499801       |
| policy_loss             | 1.0078223    |
| qf1_loss                | 0.001024963  |
| qf2_loss                | 0.0007370339 |
| time_elapsed            | 2408         |
| total timesteps         | 499900       |
| value_loss              | 0.0009936274 |
------------------------------------------
/ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/callbacks.py:285: UserWarning: Training and eval env are not of the same type<stable_baselines.common.base_class._UnvecWrapper object at 0x7f48f753f160> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f48f753ada0>
  "{} != {}".format(self.training_env, self.eval_env))
Eval num_timesteps=500000, episode_reward=-1.35 +/- 0.78
Episode length: 100.00 +/- 0.00
Saving to logs/train_0.5M_widowx_reacher-v7_KAY/sac/widowx_reacher-v7_1
pybullet build time: May 18 2020 02:46:26
