[sonicgpu1.compute:23612] pml_ucx.c:285  Error: UCP worker does not support MPI_THREAD_MULTIPLE
WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:141: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/sac/policies.py:194: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:From /home/people/paumjaud/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:254: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/people/paumjaud/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:294: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:314: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

========== widowx_reacher-v5 ==========
Seed: 0
OrderedDict([('batch_size', 32),
             ('buffer_size', 100000),
             ('ent_coef', 0.0001),
             ('gamma', 0.95),
             ('gradient_steps', 1),
             ('learning_rate', 0.0014704926021044404),
             ('learning_starts', 0),
             ('n_timesteps', 60000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs', 'dict(layers=[256, 256])'),
             ('train_freq', 1)])
Using 1 environments
Overwriting n_timesteps with n=200000
Creating test environment
TRAINING ENV TYPE :  <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f1199347160>
EVAL ENV TYPE :  <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f119934dc50>
Log path: logs/train_0.2M_widowx_reacher-v5_SONIC/sac/widowx_reacher-v5_1
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -7.456462     |
| ep_rewmean              | -3.95         |
| episodes                | 4             |
| eplenmean               | 100           |
| fps                     | 154           |
| mean 100 episode reward | -4            |
| n_updates               | 269           |
| policy_loss             | 0.33064806    |
| qf1_loss                | 7.52342e-05   |
| qf2_loss                | 7.0133414e-05 |
| time_elapsed            | 1             |
| total timesteps         | 300           |
| value_loss              | 9.30842e-05   |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | -8.474261    |
| ep_rewmean              | -3.56        |
| episodes                | 8            |
| eplenmean               | 100          |
| fps                     | 179          |
| mean 100 episode reward | -3.6         |
| n_updates               | 669          |
| policy_loss             | 0.38407797   |
| qf1_loss                | 0.005410382  |
| qf2_loss                | 0.0057155425 |
| time_elapsed            | 3            |
| total timesteps         | 700          |
| value_loss              | 8.156362e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -7.0804453    |
| ep_rewmean              | -2.82         |
| episodes                | 12            |
| eplenmean               | 100           |
| fps                     | 188           |
| mean 100 episode reward | -2.8          |
| n_updates               | 1069          |
| policy_loss             | 0.29266116    |
| qf1_loss                | 7.843924e-05  |
| qf2_loss                | 0.00013897273 |
| time_elapsed            | 5             |
| total timesteps         | 1100          |
| value_loss              | 0.00041887187 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -3.216912     |
| ep_rewmean              | -2.36         |
| episodes                | 16            |
| eplenmean               | 100           |
| fps                     | 192           |
| mean 100 episode reward | -2.4          |
| n_updates               | 1469          |
| policy_loss             | 0.23665881    |
| qf1_loss                | 6.436046e-05  |
| qf2_loss                | 8.8731555e-05 |
| time_elapsed            | 7             |
| total timesteps         | 1500          |
| value_loss              | 8.084937e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | -6.9067144   |
| ep_rewmean              | -2.62        |
| episodes                | 20           |
| eplenmean               | 100          |
| fps                     | 194          |
| mean 100 episode reward | -2.6         |
| n_updates               | 1869         |
| policy_loss             | 0.24002013   |
| qf1_loss                | 0.0012739636 |
| qf2_loss                | 0.0013523785 |
| time_elapsed            | 9            |
| total timesteps         | 1900         |
| value_loss              | 0.0001661047 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -4.06191      |
| ep_rewmean              | -2.46         |
| episodes                | 24            |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -2.5          |
| n_updates               | 2269          |
| policy_loss             | 0.21626271    |
| qf1_loss                | 7.737217e-05  |
| qf2_loss                | 4.4178792e-05 |
| time_elapsed            | 11            |
| total timesteps         | 2300          |
| value_loss              | 0.00025547025 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -2.4043074    |
| ep_rewmean              | -2.4          |
| episodes                | 28            |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -2.4          |
| n_updates               | 2669          |
| policy_loss             | 0.21547996    |
| qf1_loss                | 3.3829594e-05 |
| qf2_loss                | 3.1473108e-05 |
| time_elapsed            | 13            |
| total timesteps         | 2700          |
| value_loss              | 5.5883924e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -4.191202     |
| ep_rewmean              | -2.31         |
| episodes                | 32            |
| eplenmean               | 100           |
| fps                     | 198           |
| mean 100 episode reward | -2.3          |
| n_updates               | 3069          |
| policy_loss             | 0.22397587    |
| qf1_loss                | 6.3443604e-06 |
| qf2_loss                | 1.2976254e-05 |
| time_elapsed            | 15            |
| total timesteps         | 3100          |
| value_loss              | 2.2131446e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -4.025171     |
| ep_rewmean              | -2.19         |
| episodes                | 36            |
| eplenmean               | 100           |
| fps                     | 198           |
| mean 100 episode reward | -2.2          |
| n_updates               | 3469          |
| policy_loss             | 0.17596823    |
| qf1_loss                | 0.00032371734 |
| qf2_loss                | 0.00032853134 |
| time_elapsed            | 17            |
| total timesteps         | 3500          |
| value_loss              | 5.283991e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | -1.0271513     |
| ep_rewmean              | -2.04          |
| episodes                | 40             |
| eplenmean               | 100            |
| fps                     | 199            |
| mean 100 episode reward | -2             |
| n_updates               | 3869           |
| policy_loss             | 0.18026637     |
| qf1_loss                | 3.0474584e-05  |
| qf2_loss                | 2.1100019e-05  |
| time_elapsed            | 19             |
| total timesteps         | 3900           |
| value_loss              | 0.000101656726 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -2.9460778    |
| ep_rewmean              | -1.91         |
| episodes                | 44            |
| eplenmean               | 100           |
| fps                     | 199           |
| mean 100 episode reward | -1.9          |
| n_updates               | 4269          |
| policy_loss             | 0.14485125    |
| qf1_loss                | 8.863176e-06  |
| qf2_loss                | 7.85687e-06   |
| time_elapsed            | 21            |
| total timesteps         | 4300          |
| value_loss              | 1.7768343e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -1.9929453    |
| ep_rewmean              | -1.77         |
| episodes                | 48            |
| eplenmean               | 100           |
| fps                     | 199           |
| mean 100 episode reward | -1.8          |
| n_updates               | 4669          |
| policy_loss             | 0.14057538    |
| qf1_loss                | 0.0001502175  |
| qf2_loss                | 0.00013746851 |
| time_elapsed            | 23            |
| total timesteps         | 4700          |
| value_loss              | 8.246921e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -3.4196002    |
| ep_rewmean              | -1.65         |
| episodes                | 52            |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -1.7          |
| n_updates               | 5069          |
| policy_loss             | 0.14241634    |
| qf1_loss                | 5.5401986e-05 |
| qf2_loss                | 5.0878465e-05 |
| time_elapsed            | 25            |
| total timesteps         | 5100          |
| value_loss              | 6.796599e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | -1.4757712     |
| ep_rewmean              | -1.58          |
| episodes                | 56             |
| eplenmean               | 100            |
| fps                     | 200            |
| mean 100 episode reward | -1.6           |
| n_updates               | 5469           |
| policy_loss             | 0.127749       |
| qf1_loss                | 7.98994e-05    |
| qf2_loss                | 5.1511168e-05  |
| time_elapsed            | 27             |
| total timesteps         | 5500           |
| value_loss              | 0.000102033344 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -2.857051     |
| ep_rewmean              | -1.51         |
| episodes                | 60            |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -1.5          |
| n_updates               | 5869          |
| policy_loss             | 0.12630683    |
| qf1_loss                | 6.6785387e-06 |
| qf2_loss                | 3.8240514e-06 |
| time_elapsed            | 29            |
| total timesteps         | 5900          |
| value_loss              | 2.5574062e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | -1.3512273     |
| ep_rewmean              | -1.45          |
| episodes                | 64             |
| eplenmean               | 100            |
| fps                     | 200            |
| mean 100 episode reward | -1.4           |
| n_updates               | 6269           |
| policy_loss             | 0.1247689      |
| qf1_loss                | 0.00015294815  |
| qf2_loss                | 0.00015867225  |
| time_elapsed            | 31             |
| total timesteps         | 6300           |
| value_loss              | 1.29336295e-05 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -1.9326       |
| ep_rewmean              | -1.37         |
| episodes                | 68            |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -1.4          |
| n_updates               | 6669          |
| policy_loss             | 0.10675597    |
| qf1_loss                | 2.0464606e-05 |
| qf2_loss                | 2.2294735e-05 |
| time_elapsed            | 33            |
| total timesteps         | 6700          |
| value_loss              | 3.1418724e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -3.0463657    |
| ep_rewmean              | -1.31         |
| episodes                | 72            |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -1.3          |
| n_updates               | 7069          |
| policy_loss             | 0.10102154    |
| qf1_loss                | 1.4973421e-05 |
| qf2_loss                | 1.0057379e-05 |
| time_elapsed            | 35            |
| total timesteps         | 7100          |
| value_loss              | 4.498882e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -1.5406364    |
| ep_rewmean              | -1.27         |
| episodes                | 76            |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -1.3          |
| n_updates               | 7469          |
| policy_loss             | 0.10188377    |
| qf1_loss                | 8.1271864e-05 |
| qf2_loss                | 8.370886e-05  |
| time_elapsed            | 37            |
| total timesteps         | 7500          |
| value_loss              | 5.9769163e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -2.009111     |
| ep_rewmean              | -1.23         |
| episodes                | 80            |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -1.2          |
| n_updates               | 7869          |
| policy_loss             | 0.08643885    |
| qf1_loss                | 3.067219e-06  |
| qf2_loss                | 4.9542177e-06 |
| time_elapsed            | 39            |
| total timesteps         | 7900          |
| value_loss              | 1.1777808e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -1.6137435    |
| ep_rewmean              | -1.19         |
| episodes                | 84            |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -1.2          |
| n_updates               | 8269          |
| policy_loss             | 0.08903782    |
| qf1_loss                | 8.692728e-06  |
| qf2_loss                | 7.2401135e-06 |
| time_elapsed            | 41            |
| total timesteps         | 8300          |
| value_loss              | 1.7235543e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -2.4808872    |
| ep_rewmean              | -1.16         |
| episodes                | 88            |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -1.2          |
| n_updates               | 8669          |
| policy_loss             | 0.09760369    |
| qf1_loss                | 1.5371686e-05 |
| qf2_loss                | 9.597442e-06  |
| time_elapsed            | 43            |
| total timesteps         | 8700          |
| value_loss              | 8.982443e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -1.4149417    |
| ep_rewmean              | -1.12         |
| episodes                | 92            |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -1.1          |
| n_updates               | 9069          |
| policy_loss             | 0.09782582    |
| qf1_loss                | 1.3626693e-05 |
| qf2_loss                | 1.0311436e-05 |
| time_elapsed            | 45            |
| total timesteps         | 9100          |
| value_loss              | 1.4693298e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -1.1686723    |
| ep_rewmean              | -1.09         |
| episodes                | 96            |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -1.1          |
| n_updates               | 9469          |
| policy_loss             | 0.08384186    |
| qf1_loss                | 5.0155522e-06 |
| qf2_loss                | 4.296734e-06  |
| time_elapsed            | 47            |
| total timesteps         | 9500          |
| value_loss              | 1.1282254e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -1.787359     |
| ep_rewmean              | -1.07         |
| episodes                | 100           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -1.1          |
| n_updates               | 9869          |
| policy_loss             | 0.08012434    |
| qf1_loss                | 6.4007913e-06 |
| qf2_loss                | 8.365727e-06  |
| time_elapsed            | 49            |
| total timesteps         | 9900          |
| value_loss              | 1.5128521e-05 |
-------------------------------------------
Eval num_timesteps=10000, episode_reward=-0.32 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -0.80617964   |
| ep_rewmean              | -0.955        |
| episodes                | 104           |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 10269         |
| policy_loss             | 0.07427332    |
| qf1_loss                | 5.2841675e-05 |
| qf2_loss                | 5.4741744e-05 |
| time_elapsed            | 52            |
| total timesteps         | 10300         |
| value_loss              | 4.5182637e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -0.53718346   |
| ep_rewmean              | -0.839        |
| episodes                | 108           |
| eplenmean               | 100           |
| fps                     | 198           |
| mean 100 episode reward | -0.8          |
| n_updates               | 10669         |
| policy_loss             | 0.06830498    |
| qf1_loss                | 1.4769155e-05 |
| qf2_loss                | 1.9895751e-05 |
| time_elapsed            | 53            |
| total timesteps         | 10700         |
| value_loss              | 1.5872702e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -0.7639873    |
| ep_rewmean              | -0.789        |
| episodes                | 112           |
| eplenmean               | 100           |
| fps                     | 198           |
| mean 100 episode reward | -0.8          |
| n_updates               | 11069         |
| policy_loss             | 0.08404415    |
| qf1_loss                | 1.8242094e-06 |
| qf2_loss                | 1.8031712e-06 |
| time_elapsed            | 55            |
| total timesteps         | 11100         |
| value_loss              | 2.0663067e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -1.561019     |
| ep_rewmean              | -0.762        |
| episodes                | 116           |
| eplenmean               | 100           |
| fps                     | 199           |
| mean 100 episode reward | -0.8          |
| n_updates               | 11469         |
| policy_loss             | 0.077436075   |
| qf1_loss                | 6.4241874e-05 |
| qf2_loss                | 6.3009495e-05 |
| time_elapsed            | 57            |
| total timesteps         | 11500         |
| value_loss              | 4.9798276e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -0.60685813   |
| ep_rewmean              | -0.631        |
| episodes                | 120           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.6          |
| n_updates               | 11869         |
| policy_loss             | 0.0691091     |
| qf1_loss                | 2.023327e-06  |
| qf2_loss                | 3.0489996e-06 |
| time_elapsed            | 59            |
| total timesteps         | 11900         |
| value_loss              | 3.5998214e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -0.81483245   |
| ep_rewmean              | -0.58         |
| episodes                | 124           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.6          |
| n_updates               | 12269         |
| policy_loss             | 0.0721375     |
| qf1_loss                | 1.3358329e-05 |
| qf2_loss                | 1.448007e-05  |
| time_elapsed            | 61            |
| total timesteps         | 12300         |
| value_loss              | 1.603655e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.037656173   |
| ep_rewmean              | -0.515        |
| episodes                | 128           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.5          |
| n_updates               | 12669         |
| policy_loss             | 0.06485981    |
| qf1_loss                | 4.3493924e-06 |
| qf2_loss                | 3.9034485e-06 |
| time_elapsed            | 63            |
| total timesteps         | 12700         |
| value_loss              | 7.941265e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -0.6325262    |
| ep_rewmean              | -0.469        |
| episodes                | 132           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.5          |
| n_updates               | 13069         |
| policy_loss             | 0.082257494   |
| qf1_loss                | 3.7392718e-05 |
| qf2_loss                | 4.249862e-05  |
| time_elapsed            | 65            |
| total timesteps         | 13100         |
| value_loss              | 9.511806e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.43966827    |
| ep_rewmean              | -0.439        |
| episodes                | 136           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.4          |
| n_updates               | 13469         |
| policy_loss             | 0.08480545    |
| qf1_loss                | 5.728478e-05  |
| qf2_loss                | 4.3126463e-05 |
| time_elapsed            | 66            |
| total timesteps         | 13500         |
| value_loss              | 5.7352943e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -0.3399575    |
| ep_rewmean              | -0.424        |
| episodes                | 140           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.4          |
| n_updates               | 13869         |
| policy_loss             | 0.06885988    |
| qf1_loss                | 3.6037163e-06 |
| qf2_loss                | 3.825197e-06  |
| time_elapsed            | 68            |
| total timesteps         | 13900         |
| value_loss              | 1.8813644e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.07980345    |
| ep_rewmean              | -0.409        |
| episodes                | 144           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.4          |
| n_updates               | 14269         |
| policy_loss             | 0.06180632    |
| qf1_loss                | 5.0659062e-05 |
| qf2_loss                | 4.9751983e-05 |
| time_elapsed            | 70            |
| total timesteps         | 14300         |
| value_loss              | 3.917159e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -0.46083432   |
| ep_rewmean              | -0.411        |
| episodes                | 148           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.4          |
| n_updates               | 14669         |
| policy_loss             | 0.06293459    |
| qf1_loss                | 3.5726374e-05 |
| qf2_loss                | 3.3740896e-05 |
| time_elapsed            | 72            |
| total timesteps         | 14700         |
| value_loss              | 2.1446099e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.30823302    |
| ep_rewmean              | -0.413        |
| episodes                | 152           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.4          |
| n_updates               | 15069         |
| policy_loss             | 0.06910533    |
| qf1_loss                | 4.9376567e-06 |
| qf2_loss                | 6.8572217e-06 |
| time_elapsed            | 74            |
| total timesteps         | 15100         |
| value_loss              | 1.6286873e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.16365942    |
| ep_rewmean              | -0.403        |
| episodes                | 156           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.4          |
| n_updates               | 15469         |
| policy_loss             | 0.07160353    |
| qf1_loss                | 2.9190163e-05 |
| qf2_loss                | 3.7700822e-05 |
| time_elapsed            | 76            |
| total timesteps         | 15500         |
| value_loss              | 6.1032333e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.628443      |
| ep_rewmean              | -0.4          |
| episodes                | 160           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.4          |
| n_updates               | 15869         |
| policy_loss             | 0.06325707    |
| qf1_loss                | 2.326508e-06  |
| qf2_loss                | 4.9895725e-06 |
| time_elapsed            | 78            |
| total timesteps         | 15900         |
| value_loss              | 6.8784484e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.009187717   |
| ep_rewmean              | -0.39         |
| episodes                | 164           |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.4          |
| n_updates               | 16269         |
| policy_loss             | 0.05771587    |
| qf1_loss                | 1.7235723e-06 |
| qf2_loss                | 1.4787346e-06 |
| time_elapsed            | 79            |
| total timesteps         | 16300         |
| value_loss              | 3.1757836e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.066052005   |
| ep_rewmean              | -0.392        |
| episodes                | 168           |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.4          |
| n_updates               | 16669         |
| policy_loss             | 0.05847655    |
| qf1_loss                | 5.273351e-05  |
| qf2_loss                | 4.4592012e-05 |
| time_elapsed            | 81            |
| total timesteps         | 16700         |
| value_loss              | 3.453905e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -1.1650516    |
| ep_rewmean              | -0.39         |
| episodes                | 172           |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.4          |
| n_updates               | 17069         |
| policy_loss             | 0.067750424   |
| qf1_loss                | 4.17103e-06   |
| qf2_loss                | 4.8349702e-06 |
| time_elapsed            | 83            |
| total timesteps         | 17100         |
| value_loss              | 4.476368e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.4314497     |
| ep_rewmean              | -0.385        |
| episodes                | 176           |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.4          |
| n_updates               | 17469         |
| policy_loss             | 0.070157915   |
| qf1_loss                | 6.957696e-05  |
| qf2_loss                | 6.673657e-05  |
| time_elapsed            | 85            |
| total timesteps         | 17500         |
| value_loss              | 4.9895298e-06 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 1.3179066    |
| ep_rewmean              | -0.379       |
| episodes                | 180          |
| eplenmean               | 100          |
| fps                     | 205          |
| mean 100 episode reward | -0.4         |
| n_updates               | 17869        |
| policy_loss             | 0.058055483  |
| qf1_loss                | 6.98643e-06  |
| qf2_loss                | 5.716056e-06 |
| time_elapsed            | 87           |
| total timesteps         | 17900        |
| value_loss              | 9.56438e-06  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.6485147     |
| ep_rewmean              | -0.378        |
| episodes                | 184           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 18269         |
| policy_loss             | 0.08075794    |
| qf1_loss                | 2.8969007e-06 |
| qf2_loss                | 5.2776195e-06 |
| time_elapsed            | 89            |
| total timesteps         | 18300         |
| value_loss              | 2.6413494e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -2.4973304    |
| ep_rewmean              | -0.371        |
| episodes                | 188           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 18669         |
| policy_loss             | 0.07116022    |
| qf1_loss                | 5.4784865e-05 |
| qf2_loss                | 4.671464e-05  |
| time_elapsed            | 90            |
| total timesteps         | 18700         |
| value_loss              | 2.3503731e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.21258071    |
| ep_rewmean              | -0.386        |
| episodes                | 192           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 19069         |
| policy_loss             | 0.08803812    |
| qf1_loss                | 1.2551076e-05 |
| qf2_loss                | 1.3197907e-05 |
| time_elapsed            | 92            |
| total timesteps         | 19100         |
| value_loss              | 4.3954053e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.111621335   |
| ep_rewmean              | -0.373        |
| episodes                | 196           |
| eplenmean               | 100           |
| fps                     | 206           |
| mean 100 episode reward | -0.4          |
| n_updates               | 19469         |
| policy_loss             | 0.08051723    |
| qf1_loss                | 7.190076e-06  |
| qf2_loss                | 4.851491e-06  |
| time_elapsed            | 94            |
| total timesteps         | 19500         |
| value_loss              | 1.1444587e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.62832224    |
| ep_rewmean              | -0.363        |
| episodes                | 200           |
| eplenmean               | 100           |
| fps                     | 206           |
| mean 100 episode reward | -0.4          |
| n_updates               | 19869         |
| policy_loss             | 0.066408224   |
| qf1_loss                | 1.2762107e-05 |
| qf2_loss                | 9.417748e-06  |
| time_elapsed            | 96            |
| total timesteps         | 19900         |
| value_loss              | 1.2994303e-05 |
-------------------------------------------
Eval num_timesteps=20000, episode_reward=-0.25 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -0.341839     |
| ep_rewmean              | -0.357        |
| episodes                | 204           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 20269         |
| policy_loss             | 0.08960111    |
| qf1_loss                | 3.7271618e-06 |
| qf2_loss                | 1.4875009e-06 |
| time_elapsed            | 98            |
| total timesteps         | 20300         |
| value_loss              | 2.5707905e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 1.1969633     |
| ep_rewmean              | -0.357        |
| episodes                | 208           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 20669         |
| policy_loss             | 0.062843546   |
| qf1_loss                | 2.4988796e-05 |
| qf2_loss                | 3.4584285e-05 |
| time_elapsed            | 100           |
| total timesteps         | 20700         |
| value_loss              | 1.5662354e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.164325      |
| ep_rewmean              | -0.368        |
| episodes                | 212           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 21069         |
| policy_loss             | 0.05872586    |
| qf1_loss                | 1.7272381e-05 |
| qf2_loss                | 1.0840817e-05 |
| time_elapsed            | 102           |
| total timesteps         | 21100         |
| value_loss              | 1.6004087e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -0.2370242    |
| ep_rewmean              | -0.383        |
| episodes                | 216           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 21469         |
| policy_loss             | 0.058783397   |
| qf1_loss                | 2.279484e-05  |
| qf2_loss                | 2.5898753e-05 |
| time_elapsed            | 104           |
| total timesteps         | 21500         |
| value_loss              | 1.6071546e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.31640184    |
| ep_rewmean              | -0.38         |
| episodes                | 220           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 21869         |
| policy_loss             | 0.0632287     |
| qf1_loss                | 1.9354171e-05 |
| qf2_loss                | 2.5725763e-05 |
| time_elapsed            | 106           |
| total timesteps         | 21900         |
| value_loss              | 1.3328808e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.6202855     |
| ep_rewmean              | -0.372        |
| episodes                | 224           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 22269         |
| policy_loss             | 0.06573752    |
| qf1_loss                | 6.30878e-06   |
| qf2_loss                | 1.9453706e-05 |
| time_elapsed            | 108           |
| total timesteps         | 22300         |
| value_loss              | 9.647524e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.4796878     |
| ep_rewmean              | -0.396        |
| episodes                | 228           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 22669         |
| policy_loss             | 0.07501347    |
| qf1_loss                | 2.6970443e-05 |
| qf2_loss                | 8.86485e-06   |
| time_elapsed            | 110           |
| total timesteps         | 22700         |
| value_loss              | 2.0994074e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.7225861     |
| ep_rewmean              | -0.387        |
| episodes                | 232           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 23069         |
| policy_loss             | 0.067653835   |
| qf1_loss                | 1.5202484e-05 |
| qf2_loss                | 9.937527e-06  |
| time_elapsed            | 112           |
| total timesteps         | 23100         |
| value_loss              | 7.788813e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 1.2271144     |
| ep_rewmean              | -0.376        |
| episodes                | 236           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 23469         |
| policy_loss             | 0.05586839    |
| qf1_loss                | 3.3871406e-06 |
| qf2_loss                | 2.946988e-06  |
| time_elapsed            | 114           |
| total timesteps         | 23500         |
| value_loss              | 9.819332e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 1.7832905     |
| ep_rewmean              | -0.372        |
| episodes                | 240           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 23869         |
| policy_loss             | 0.06032643    |
| qf1_loss                | 6.479105e-05  |
| qf2_loss                | 6.293598e-05  |
| time_elapsed            | 116           |
| total timesteps         | 23900         |
| value_loss              | 2.1034211e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.5590149     |
| ep_rewmean              | -0.378        |
| episodes                | 244           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 24269         |
| policy_loss             | 0.057611402   |
| qf1_loss                | 1.2717457e-05 |
| qf2_loss                | 1.0906948e-05 |
| time_elapsed            | 118           |
| total timesteps         | 24300         |
| value_loss              | 3.746929e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 1.4865553     |
| ep_rewmean              | -0.389        |
| episodes                | 248           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 24669         |
| policy_loss             | 0.07973015    |
| qf1_loss                | 6.8808845e-06 |
| qf2_loss                | 7.4939176e-06 |
| time_elapsed            | 120           |
| total timesteps         | 24700         |
| value_loss              | 8.511093e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 1.4694763     |
| ep_rewmean              | -0.4          |
| episodes                | 252           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 25069         |
| policy_loss             | 0.07699959    |
| qf1_loss                | 4.392551e-06  |
| qf2_loss                | 2.7087046e-06 |
| time_elapsed            | 122           |
| total timesteps         | 25100         |
| value_loss              | 1.5290867e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 1.4013622     |
| ep_rewmean              | -0.394        |
| episodes                | 256           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 25469         |
| policy_loss             | 0.07024322    |
| qf1_loss                | 3.290218e-06  |
| qf2_loss                | 2.9987682e-06 |
| time_elapsed            | 124           |
| total timesteps         | 25500         |
| value_loss              | 1.1373228e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.5323431     |
| ep_rewmean              | -0.397        |
| episodes                | 260           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 25869         |
| policy_loss             | 0.041196767   |
| qf1_loss                | 2.4799036e-05 |
| qf2_loss                | 5.62183e-05   |
| time_elapsed            | 126           |
| total timesteps         | 25900         |
| value_loss              | 1.4363419e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.2660623     |
| ep_rewmean              | -0.441        |
| episodes                | 264           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 26269         |
| policy_loss             | 0.050017193   |
| qf1_loss                | 1.1763877e-05 |
| qf2_loss                | 2.0879652e-05 |
| time_elapsed            | 128           |
| total timesteps         | 26300         |
| value_loss              | 2.153092e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.223858      |
| ep_rewmean              | -0.444        |
| episodes                | 268           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 26669         |
| policy_loss             | 0.06476794    |
| qf1_loss                | 1.39323e-05   |
| qf2_loss                | 1.3600563e-05 |
| time_elapsed            | 130           |
| total timesteps         | 26700         |
| value_loss              | 9.222765e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.3853757     |
| ep_rewmean              | -0.446        |
| episodes                | 272           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 27069         |
| policy_loss             | 0.043838527   |
| qf1_loss                | 7.1853788e-06 |
| qf2_loss                | 1.0957276e-05 |
| time_elapsed            | 132           |
| total timesteps         | 27100         |
| value_loss              | 1.6374684e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.508069      |
| ep_rewmean              | -0.438        |
| episodes                | 276           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 27469         |
| policy_loss             | 0.066342115   |
| qf1_loss                | 1.3339422e-05 |
| qf2_loss                | 3.5826495e-05 |
| time_elapsed            | 134           |
| total timesteps         | 27500         |
| value_loss              | 5.02966e-05   |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 3.4865487      |
| ep_rewmean              | -0.436         |
| episodes                | 280            |
| eplenmean               | 100            |
| fps                     | 205            |
| mean 100 episode reward | -0.4           |
| n_updates               | 27869          |
| policy_loss             | 0.04999095     |
| qf1_loss                | 1.125929e-05   |
| qf2_loss                | 1.07693395e-05 |
| time_elapsed            | 136            |
| total timesteps         | 27900          |
| value_loss              | 2.1349926e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.7367675     |
| ep_rewmean              | -0.432        |
| episodes                | 284           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 28269         |
| policy_loss             | 0.049922995   |
| qf1_loss                | 2.3091538e-05 |
| qf2_loss                | 2.5474917e-05 |
| time_elapsed            | 138           |
| total timesteps         | 28300         |
| value_loss              | 2.0823754e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.3926408     |
| ep_rewmean              | -0.431        |
| episodes                | 288           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 28669         |
| policy_loss             | 0.046823546   |
| qf1_loss                | 4.7401963e-06 |
| qf2_loss                | 5.1568936e-06 |
| time_elapsed            | 139           |
| total timesteps         | 28700         |
| value_loss              | 7.427337e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 1.7542162     |
| ep_rewmean              | -0.411        |
| episodes                | 292           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 29069         |
| policy_loss             | 0.037753683   |
| qf1_loss                | 4.3411856e-06 |
| qf2_loss                | 4.048842e-06  |
| time_elapsed            | 141           |
| total timesteps         | 29100         |
| value_loss              | 4.1548974e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.281301      |
| ep_rewmean              | -0.413        |
| episodes                | 296           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 29469         |
| policy_loss             | 0.064948946   |
| qf1_loss                | 1.0370245e-05 |
| qf2_loss                | 9.02125e-06   |
| time_elapsed            | 143           |
| total timesteps         | 29500         |
| value_loss              | 8.293038e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.2458386     |
| ep_rewmean              | -0.41         |
| episodes                | 300           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 29869         |
| policy_loss             | 0.05064366    |
| qf1_loss                | 8.090668e-06  |
| qf2_loss                | 6.2072304e-06 |
| time_elapsed            | 145           |
| total timesteps         | 29900         |
| value_loss              | 3.9411216e-06 |
-------------------------------------------
Eval num_timesteps=30000, episode_reward=-0.14 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.8603728     |
| ep_rewmean              | -0.404        |
| episodes                | 304           |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.4          |
| n_updates               | 30269         |
| policy_loss             | 0.03817694    |
| qf1_loss                | 1.5661559e-05 |
| qf2_loss                | 1.6158725e-05 |
| time_elapsed            | 148           |
| total timesteps         | 30300         |
| value_loss              | 9.478787e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.5885067     |
| ep_rewmean              | -0.397        |
| episodes                | 308           |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.4          |
| n_updates               | 30669         |
| policy_loss             | 0.04790952    |
| qf1_loss                | 6.7456212e-06 |
| qf2_loss                | 9.063198e-06  |
| time_elapsed            | 150           |
| total timesteps         | 30700         |
| value_loss              | 1.47336e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.5495918     |
| ep_rewmean              | -0.384        |
| episodes                | 312           |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.4          |
| n_updates               | 31069         |
| policy_loss             | 0.03947824    |
| qf1_loss                | 3.1491047e-05 |
| qf2_loss                | 2.468122e-05  |
| time_elapsed            | 152           |
| total timesteps         | 31100         |
| value_loss              | 9.661517e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.9319906     |
| ep_rewmean              | -0.361        |
| episodes                | 316           |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.4          |
| n_updates               | 31469         |
| policy_loss             | 0.047471732   |
| qf1_loss                | 1.5109253e-05 |
| qf2_loss                | 7.4661166e-06 |
| time_elapsed            | 153           |
| total timesteps         | 31500         |
| value_loss              | 4.626438e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.5598538     |
| ep_rewmean              | -0.365        |
| episodes                | 320           |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.4          |
| n_updates               | 31869         |
| policy_loss             | 0.036084495   |
| qf1_loss                | 6.478286e-06  |
| qf2_loss                | 8.012792e-06  |
| time_elapsed            | 155           |
| total timesteps         | 31900         |
| value_loss              | 5.7635316e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 1.9784479     |
| ep_rewmean              | -0.386        |
| episodes                | 324           |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.4          |
| n_updates               | 32269         |
| policy_loss             | 0.043310262   |
| qf1_loss                | 0.00010832168 |
| qf2_loss                | 0.00011569449 |
| time_elapsed            | 157           |
| total timesteps         | 32300         |
| value_loss              | 2.4879985e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.7287958     |
| ep_rewmean              | -0.358        |
| episodes                | 328           |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.4          |
| n_updates               | 32669         |
| policy_loss             | 0.04137202    |
| qf1_loss                | 1.0500489e-05 |
| qf2_loss                | 4.9057026e-06 |
| time_elapsed            | 159           |
| total timesteps         | 32700         |
| value_loss              | 6.358156e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.0723796     |
| ep_rewmean              | -0.358        |
| episodes                | 332           |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.4          |
| n_updates               | 33069         |
| policy_loss             | 0.035582926   |
| qf1_loss                | 1.7672625e-06 |
| qf2_loss                | 1.7655176e-06 |
| time_elapsed            | 161           |
| total timesteps         | 33100         |
| value_loss              | 2.6007067e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.038424      |
| ep_rewmean              | -0.362        |
| episodes                | 336           |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.4          |
| n_updates               | 33469         |
| policy_loss             | 0.035620175   |
| qf1_loss                | 0.00012174549 |
| qf2_loss                | 0.00013448103 |
| time_elapsed            | 163           |
| total timesteps         | 33500         |
| value_loss              | 1.7770293e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.0572062     |
| ep_rewmean              | -0.362        |
| episodes                | 340           |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.4          |
| n_updates               | 33869         |
| policy_loss             | 0.045183003   |
| qf1_loss                | 1.636564e-05  |
| qf2_loss                | 2.354956e-05  |
| time_elapsed            | 165           |
| total timesteps         | 33900         |
| value_loss              | 1.9005147e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.8653238     |
| ep_rewmean              | -0.359        |
| episodes                | 344           |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.4          |
| n_updates               | 34269         |
| policy_loss             | 0.037425958   |
| qf1_loss                | 1.1820237e-06 |
| qf2_loss                | 2.6800533e-06 |
| time_elapsed            | 167           |
| total timesteps         | 34300         |
| value_loss              | 2.4407937e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.2486608     |
| ep_rewmean              | -0.345        |
| episodes                | 348           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 34669         |
| policy_loss             | 0.03514158    |
| qf1_loss                | 1.1825389e-05 |
| qf2_loss                | 1.2523639e-05 |
| time_elapsed            | 169           |
| total timesteps         | 34700         |
| value_loss              | 4.689753e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.5046806     |
| ep_rewmean              | -0.336        |
| episodes                | 352           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 35069         |
| policy_loss             | 0.039083306   |
| qf1_loss                | 3.0467804e-06 |
| qf2_loss                | 2.8673944e-06 |
| time_elapsed            | 171           |
| total timesteps         | 35100         |
| value_loss              | 7.1792456e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.556238      |
| ep_rewmean              | -0.351        |
| episodes                | 356           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 35469         |
| policy_loss             | 0.037736062   |
| qf1_loss                | 1.7280616e-06 |
| qf2_loss                | 2.1624583e-06 |
| time_elapsed            | 173           |
| total timesteps         | 35500         |
| value_loss              | 6.092115e-06  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 4.620988     |
| ep_rewmean              | -0.342       |
| episodes                | 360          |
| eplenmean               | 100          |
| fps                     | 205          |
| mean 100 episode reward | -0.3         |
| n_updates               | 35869        |
| policy_loss             | 0.038226143  |
| qf1_loss                | 9.813088e-05 |
| qf2_loss                | 9.797708e-05 |
| time_elapsed            | 174          |
| total timesteps         | 35900        |
| value_loss              | 4.228627e-06 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.6909885     |
| ep_rewmean              | -0.295        |
| episodes                | 364           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 36269         |
| policy_loss             | 0.061917752   |
| qf1_loss                | 0.0003382358  |
| qf2_loss                | 0.00031845758 |
| time_elapsed            | 176           |
| total timesteps         | 36300         |
| value_loss              | 3.750495e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.8414764     |
| ep_rewmean              | -0.296        |
| episodes                | 368           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 36669         |
| policy_loss             | 0.039569262   |
| qf1_loss                | 2.6710746e-05 |
| qf2_loss                | 2.3703764e-05 |
| time_elapsed            | 178           |
| total timesteps         | 36700         |
| value_loss              | 3.3199674e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.3341036     |
| ep_rewmean              | -0.313        |
| episodes                | 372           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 37069         |
| policy_loss             | 0.058618072   |
| qf1_loss                | 2.1473606e-05 |
| qf2_loss                | 2.2236343e-05 |
| time_elapsed            | 180           |
| total timesteps         | 37100         |
| value_loss              | 4.4124165e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 4.154016     |
| ep_rewmean              | -0.321       |
| episodes                | 376          |
| eplenmean               | 100          |
| fps                     | 205          |
| mean 100 episode reward | -0.3         |
| n_updates               | 37469        |
| policy_loss             | 0.04759936   |
| qf1_loss                | 9.040563e-05 |
| qf2_loss                | 9.887566e-05 |
| time_elapsed            | 182          |
| total timesteps         | 37500        |
| value_loss              | 2.45327e-06  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.425338      |
| ep_rewmean              | -0.324        |
| episodes                | 380           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 37869         |
| policy_loss             | 0.04759354    |
| qf1_loss                | 3.1170202e-06 |
| qf2_loss                | 3.4873349e-06 |
| time_elapsed            | 184           |
| total timesteps         | 37900         |
| value_loss              | 2.6723144e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.5317907     |
| ep_rewmean              | -0.328        |
| episodes                | 384           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 38269         |
| policy_loss             | 0.046820644   |
| qf1_loss                | 1.8004025e-06 |
| qf2_loss                | 2.826441e-06  |
| time_elapsed            | 186           |
| total timesteps         | 38300         |
| value_loss              | 4.493397e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.543674      |
| ep_rewmean              | -0.338        |
| episodes                | 388           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 38669         |
| policy_loss             | 0.04197031    |
| qf1_loss                | 2.2586652e-05 |
| qf2_loss                | 2.220618e-05  |
| time_elapsed            | 188           |
| total timesteps         | 38700         |
| value_loss              | 3.951328e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.127291      |
| ep_rewmean              | -0.346        |
| episodes                | 392           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 39069         |
| policy_loss             | 0.05016184    |
| qf1_loss                | 2.0684076e-06 |
| qf2_loss                | 2.5353372e-06 |
| time_elapsed            | 190           |
| total timesteps         | 39100         |
| value_loss              | 3.0386122e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.5262766     |
| ep_rewmean              | -0.354        |
| episodes                | 396           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 39469         |
| policy_loss             | 0.052446      |
| qf1_loss                | 2.4934649e-05 |
| qf2_loss                | 1.8717028e-05 |
| time_elapsed            | 192           |
| total timesteps         | 39500         |
| value_loss              | 6.452371e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.594566      |
| ep_rewmean              | -0.361        |
| episodes                | 400           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 39869         |
| policy_loss             | 0.041976795   |
| qf1_loss                | 3.7519899e-06 |
| qf2_loss                | 3.9376005e-06 |
| time_elapsed            | 194           |
| total timesteps         | 39900         |
| value_loss              | 1.7276379e-06 |
-------------------------------------------
Eval num_timesteps=40000, episode_reward=-0.20 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.378417      |
| ep_rewmean              | -0.364        |
| episodes                | 404           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 40269         |
| policy_loss             | 0.04160018    |
| qf1_loss                | 3.885882e-06  |
| qf2_loss                | 2.757287e-06  |
| time_elapsed            | 196           |
| total timesteps         | 40300         |
| value_loss              | 4.1086373e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.3725157     |
| ep_rewmean              | -0.364        |
| episodes                | 408           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 40669         |
| policy_loss             | 0.04434375    |
| qf1_loss                | 1.0658682e-06 |
| qf2_loss                | 1.1010059e-06 |
| time_elapsed            | 198           |
| total timesteps         | 40700         |
| value_loss              | 4.3339514e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.7878103     |
| ep_rewmean              | -0.363        |
| episodes                | 412           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 41069         |
| policy_loss             | 0.03993594    |
| qf1_loss                | 2.8318767e-05 |
| qf2_loss                | 2.7135604e-05 |
| time_elapsed            | 199           |
| total timesteps         | 41100         |
| value_loss              | 2.5331933e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.996903      |
| ep_rewmean              | -0.362        |
| episodes                | 416           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 41469         |
| policy_loss             | 0.041856967   |
| qf1_loss                | 1.9048427e-06 |
| qf2_loss                | 1.7328421e-06 |
| time_elapsed            | 201           |
| total timesteps         | 41500         |
| value_loss              | 3.0179572e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.7225337     |
| ep_rewmean              | -0.361        |
| episodes                | 420           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.4          |
| n_updates               | 41869         |
| policy_loss             | 0.07774465    |
| qf1_loss                | 0.00070473953 |
| qf2_loss                | 0.00058773096 |
| time_elapsed            | 203           |
| total timesteps         | 41900         |
| value_loss              | 7.931858e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.6103067     |
| ep_rewmean              | -0.342        |
| episodes                | 424           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 42269         |
| policy_loss             | 0.056108277   |
| qf1_loss                | 3.7601494e-06 |
| qf2_loss                | 3.9348433e-06 |
| time_elapsed            | 205           |
| total timesteps         | 42300         |
| value_loss              | 7.753384e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.468396      |
| ep_rewmean              | -0.341        |
| episodes                | 428           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 42669         |
| policy_loss             | 0.051337477   |
| qf1_loss                | 0.00047359793 |
| qf2_loss                | 0.0004683038  |
| time_elapsed            | 207           |
| total timesteps         | 42700         |
| value_loss              | 3.7924015e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.614053      |
| ep_rewmean              | -0.335        |
| episodes                | 432           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 43069         |
| policy_loss             | 0.043861024   |
| qf1_loss                | 2.2348372e-06 |
| qf2_loss                | 1.0561694e-06 |
| time_elapsed            | 209           |
| total timesteps         | 43100         |
| value_loss              | 3.0790416e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.296068      |
| ep_rewmean              | -0.336        |
| episodes                | 436           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 43469         |
| policy_loss             | 0.044177037   |
| qf1_loss                | 2.8556738e-06 |
| qf2_loss                | 2.426375e-06  |
| time_elapsed            | 211           |
| total timesteps         | 43500         |
| value_loss              | 3.5235134e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.318624      |
| ep_rewmean              | -0.338        |
| episodes                | 440           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 43869         |
| policy_loss             | 0.040619783   |
| qf1_loss                | 2.9095969e-05 |
| qf2_loss                | 3.1183205e-05 |
| time_elapsed            | 213           |
| total timesteps         | 43900         |
| value_loss              | 4.159072e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.6206646     |
| ep_rewmean              | -0.335        |
| episodes                | 444           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 44269         |
| policy_loss             | 0.035655387   |
| qf1_loss                | 1.6034111e-05 |
| qf2_loss                | 1.5307942e-05 |
| time_elapsed            | 215           |
| total timesteps         | 44300         |
| value_loss              | 1.6416798e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.809903      |
| ep_rewmean              | -0.33         |
| episodes                | 448           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 44669         |
| policy_loss             | 0.044349447   |
| qf1_loss                | 1.4171269e-06 |
| qf2_loss                | 4.1807734e-06 |
| time_elapsed            | 217           |
| total timesteps         | 44700         |
| value_loss              | 1.7236034e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.824393      |
| ep_rewmean              | -0.326        |
| episodes                | 452           |
| eplenmean               | 100           |
| fps                     | 205           |
| mean 100 episode reward | -0.3          |
| n_updates               | 45069         |
| policy_loss             | 0.04216353    |
| qf1_loss                | 1.0248273e-05 |
| qf2_loss                | 5.9697663e-06 |
| time_elapsed            | 218           |
| total timesteps         | 45100         |
| value_loss              | 6.6035636e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.6100464     |
| ep_rewmean              | -0.309        |
| episodes                | 456           |
| eplenmean               | 100           |
| fps                     | 206           |
| mean 100 episode reward | -0.3          |
| n_updates               | 45469         |
| policy_loss             | 0.032863274   |
| qf1_loss                | 1.3664509e-06 |
| qf2_loss                | 1.6358111e-06 |
| time_elapsed            | 220           |
| total timesteps         | 45500         |
| value_loss              | 1.4570032e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.1210613     |
| ep_rewmean              | -0.312        |
| episodes                | 460           |
| eplenmean               | 100           |
| fps                     | 206           |
| mean 100 episode reward | -0.3          |
| n_updates               | 45869         |
| policy_loss             | 0.046275735   |
| qf1_loss                | 5.0917333e-06 |
| qf2_loss                | 7.947385e-06  |
| time_elapsed            | 222           |
| total timesteps         | 45900         |
| value_loss              | 6.1756255e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.45592       |
| ep_rewmean              | -0.309        |
| episodes                | 464           |
| eplenmean               | 100           |
| fps                     | 206           |
| mean 100 episode reward | -0.3          |
| n_updates               | 46269         |
| policy_loss             | 0.04703822    |
| qf1_loss                | 3.2889238e-06 |
| qf2_loss                | 2.4948233e-06 |
| time_elapsed            | 224           |
| total timesteps         | 46300         |
| value_loss              | 6.876747e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.3241463     |
| ep_rewmean              | -0.308        |
| episodes                | 468           |
| eplenmean               | 100           |
| fps                     | 206           |
| mean 100 episode reward | -0.3          |
| n_updates               | 46669         |
| policy_loss             | 0.03961151    |
| qf1_loss                | 3.6675328e-06 |
| qf2_loss                | 4.2224283e-06 |
| time_elapsed            | 226           |
| total timesteps         | 46700         |
| value_loss              | 5.2951427e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.996284      |
| ep_rewmean              | -0.29         |
| episodes                | 472           |
| eplenmean               | 100           |
| fps                     | 206           |
| mean 100 episode reward | -0.3          |
| n_updates               | 47069         |
| policy_loss             | 0.036814444   |
| qf1_loss                | 1.3301537e-05 |
| qf2_loss                | 1.2954979e-05 |
| time_elapsed            | 227           |
| total timesteps         | 47100         |
| value_loss              | 3.172686e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.305529      |
| ep_rewmean              | -0.289        |
| episodes                | 476           |
| eplenmean               | 100           |
| fps                     | 206           |
| mean 100 episode reward | -0.3          |
| n_updates               | 47469         |
| policy_loss             | 0.04762459    |
| qf1_loss                | 1.8531204e-05 |
| qf2_loss                | 9.708777e-06  |
| time_elapsed            | 229           |
| total timesteps         | 47500         |
| value_loss              | 2.3877808e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.712963      |
| ep_rewmean              | -0.286        |
| episodes                | 480           |
| eplenmean               | 100           |
| fps                     | 206           |
| mean 100 episode reward | -0.3          |
| n_updates               | 47869         |
| policy_loss             | 0.03938816    |
| qf1_loss                | 5.2295536e-06 |
| qf2_loss                | 9.542708e-06  |
| time_elapsed            | 231           |
| total timesteps         | 47900         |
| value_loss              | 8.980422e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.6426716     |
| ep_rewmean              | -0.28         |
| episodes                | 484           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -0.3          |
| n_updates               | 48269         |
| policy_loss             | 0.04173747    |
| qf1_loss                | 1.9833517e-06 |
| qf2_loss                | 2.4043861e-06 |
| time_elapsed            | 233           |
| total timesteps         | 48300         |
| value_loss              | 1.0659612e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.3242626     |
| ep_rewmean              | -0.274        |
| episodes                | 488           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -0.3          |
| n_updates               | 48669         |
| policy_loss             | 0.0381334     |
| qf1_loss                | 2.4703488e-06 |
| qf2_loss                | 3.7143031e-06 |
| time_elapsed            | 234           |
| total timesteps         | 48700         |
| value_loss              | 1.6722269e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.339262      |
| ep_rewmean              | -0.271        |
| episodes                | 492           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -0.3          |
| n_updates               | 49069         |
| policy_loss             | 0.045939405   |
| qf1_loss                | 0.00018416478 |
| qf2_loss                | 0.00016950665 |
| time_elapsed            | 236           |
| total timesteps         | 49100         |
| value_loss              | 7.1807367e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.8520055     |
| ep_rewmean              | -0.268        |
| episodes                | 496           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -0.3          |
| n_updates               | 49469         |
| policy_loss             | 0.041557673   |
| qf1_loss                | 2.037524e-06  |
| qf2_loss                | 2.7047877e-06 |
| time_elapsed            | 238           |
| total timesteps         | 49500         |
| value_loss              | 4.4644876e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.686089      |
| ep_rewmean              | -0.272        |
| episodes                | 500           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -0.3          |
| n_updates               | 49869         |
| policy_loss             | 0.035555966   |
| qf1_loss                | 1.3427008e-06 |
| qf2_loss                | 9.9987e-07    |
| time_elapsed            | 240           |
| total timesteps         | 49900         |
| value_loss              | 1.6834497e-06 |
-------------------------------------------
Eval num_timesteps=50000, episode_reward=-0.34 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.9229898     |
| ep_rewmean              | -0.277        |
| episodes                | 504           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -0.3          |
| n_updates               | 50269         |
| policy_loss             | 0.042428352   |
| qf1_loss                | 1.5605417e-06 |
| qf2_loss                | 1.453621e-06  |
| time_elapsed            | 242           |
| total timesteps         | 50300         |
| value_loss              | 4.3989266e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.8593254     |
| ep_rewmean              | -0.286        |
| episodes                | 508           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -0.3          |
| n_updates               | 50669         |
| policy_loss             | 0.045276456   |
| qf1_loss                | 2.0882746e-05 |
| qf2_loss                | 2.1163005e-05 |
| time_elapsed            | 244           |
| total timesteps         | 50700         |
| value_loss              | 2.1481626e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.7581406     |
| ep_rewmean              | -0.293        |
| episodes                | 512           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -0.3          |
| n_updates               | 51069         |
| policy_loss             | 0.042215355   |
| qf1_loss                | 1.9168974e-06 |
| qf2_loss                | 8.129275e-07  |
| time_elapsed            | 246           |
| total timesteps         | 51100         |
| value_loss              | 3.3483525e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.731323      |
| ep_rewmean              | -0.3          |
| episodes                | 516           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -0.3          |
| n_updates               | 51469         |
| policy_loss             | 0.052647762   |
| qf1_loss                | 1.236127e-05  |
| qf2_loss                | 4.038071e-06  |
| time_elapsed            | 247           |
| total timesteps         | 51500         |
| value_loss              | 1.1869835e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.389017      |
| ep_rewmean              | -0.301        |
| episodes                | 520           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -0.3          |
| n_updates               | 51869         |
| policy_loss             | 0.054854035   |
| qf1_loss                | 1.5623204e-06 |
| qf2_loss                | 2.8911618e-06 |
| time_elapsed            | 249           |
| total timesteps         | 51900         |
| value_loss              | 7.934646e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.0774794     |
| ep_rewmean              | -0.3          |
| episodes                | 524           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -0.3          |
| n_updates               | 52269         |
| policy_loss             | 0.039983526   |
| qf1_loss                | 6.393326e-05  |
| qf2_loss                | 6.1733794e-05 |
| time_elapsed            | 251           |
| total timesteps         | 52300         |
| value_loss              | 6.60467e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.5334544     |
| ep_rewmean              | -0.3          |
| episodes                | 528           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -0.3          |
| n_updates               | 52669         |
| policy_loss             | 0.03933884    |
| qf1_loss                | 7.925944e-06  |
| qf2_loss                | 2.1157948e-06 |
| time_elapsed            | 253           |
| total timesteps         | 52700         |
| value_loss              | 1.6850407e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.059784      |
| ep_rewmean              | -0.304        |
| episodes                | 532           |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -0.3          |
| n_updates               | 53069         |
| policy_loss             | 0.04574783    |
| qf1_loss                | 1.3629766e-06 |
| qf2_loss                | 1.2635492e-06 |
| time_elapsed            | 255           |
| total timesteps         | 53100         |
| value_loss              | 1.068247e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.385874      |
| ep_rewmean              | -0.306        |
| episodes                | 536           |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -0.3          |
| n_updates               | 53469         |
| policy_loss             | 0.03845992    |
| qf1_loss                | 3.975733e-05  |
| qf2_loss                | 4.1344952e-05 |
| time_elapsed            | 256           |
| total timesteps         | 53500         |
| value_loss              | 1.4925557e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.5188627     |
| ep_rewmean              | -0.309        |
| episodes                | 540           |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -0.3          |
| n_updates               | 53869         |
| policy_loss             | 0.04274193    |
| qf1_loss                | 4.7441627e-05 |
| qf2_loss                | 4.9096663e-05 |
| time_elapsed            | 258           |
| total timesteps         | 53900         |
| value_loss              | 3.5581913e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.24773       |
| ep_rewmean              | -0.318        |
| episodes                | 544           |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -0.3          |
| n_updates               | 54269         |
| policy_loss             | 0.049735446   |
| qf1_loss                | 1.3800604e-06 |
| qf2_loss                | 1.6010895e-06 |
| time_elapsed            | 260           |
| total timesteps         | 54300         |
| value_loss              | 1.6654844e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.7685356     |
| ep_rewmean              | -0.327        |
| episodes                | 548           |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -0.3          |
| n_updates               | 54669         |
| policy_loss             | 0.049861282   |
| qf1_loss                | 0.00053816376 |
| qf2_loss                | 0.00050885836 |
| time_elapsed            | 262           |
| total timesteps         | 54700         |
| value_loss              | 8.728991e-06  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 4.274235       |
| ep_rewmean              | -0.329         |
| episodes                | 552            |
| eplenmean               | 100            |
| fps                     | 208            |
| mean 100 episode reward | -0.3           |
| n_updates               | 55069          |
| policy_loss             | 0.04911871     |
| qf1_loss                | 2.9052544e-06  |
| qf2_loss                | 4.790493e-06   |
| time_elapsed            | 264            |
| total timesteps         | 55100          |
| value_loss              | 1.08666345e-05 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.011576      |
| ep_rewmean              | -0.33         |
| episodes                | 556           |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -0.3          |
| n_updates               | 55469         |
| policy_loss             | 0.046614494   |
| qf1_loss                | 5.4743236e-06 |
| qf2_loss                | 6.6595057e-06 |
| time_elapsed            | 266           |
| total timesteps         | 55500         |
| value_loss              | 2.1180672e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.295306      |
| ep_rewmean              | -0.328        |
| episodes                | 560           |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -0.3          |
| n_updates               | 55869         |
| policy_loss             | 0.044674337   |
| qf1_loss                | 1.4586369e-06 |
| qf2_loss                | 8.2697704e-07 |
| time_elapsed            | 267           |
| total timesteps         | 55900         |
| value_loss              | 3.0803599e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.9084115     |
| ep_rewmean              | -0.336        |
| episodes                | 564           |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -0.3          |
| n_updates               | 56269         |
| policy_loss             | 0.051807806   |
| qf1_loss                | 2.1179909e-05 |
| qf2_loss                | 1.9871672e-05 |
| time_elapsed            | 269           |
| total timesteps         | 56300         |
| value_loss              | 4.709449e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.8465934     |
| ep_rewmean              | -0.339        |
| episodes                | 568           |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -0.3          |
| n_updates               | 56669         |
| policy_loss             | 0.04450409    |
| qf1_loss                | 3.8943012e-06 |
| qf2_loss                | 2.313566e-06  |
| time_elapsed            | 271           |
| total timesteps         | 56700         |
| value_loss              | 1.6331174e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.153841      |
| ep_rewmean              | -0.345        |
| episodes                | 572           |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -0.3          |
| n_updates               | 57069         |
| policy_loss             | 0.048917204   |
| qf1_loss                | 0.00031571783 |
| qf2_loss                | 0.00027214963 |
| time_elapsed            | 273           |
| total timesteps         | 57100         |
| value_loss              | 2.1478725e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.647079      |
| ep_rewmean              | -0.344        |
| episodes                | 576           |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -0.3          |
| n_updates               | 57469         |
| policy_loss             | 0.045894053   |
| qf1_loss                | 3.5200674e-06 |
| qf2_loss                | 2.5049549e-06 |
| time_elapsed            | 275           |
| total timesteps         | 57500         |
| value_loss              | 5.1357683e-06 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 5.912652       |
| ep_rewmean              | -0.345         |
| episodes                | 580            |
| eplenmean               | 100            |
| fps                     | 208            |
| mean 100 episode reward | -0.3           |
| n_updates               | 57869          |
| policy_loss             | 0.048057847    |
| qf1_loss                | 0.000102770464 |
| qf2_loss                | 0.00011579455  |
| time_elapsed            | 277            |
| total timesteps         | 57900          |
| value_loss              | 2.6260273e-06  |
--------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 6.3862724    |
| ep_rewmean              | -0.347       |
| episodes                | 584          |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -0.3         |
| n_updates               | 58269        |
| policy_loss             | 0.05702188   |
| qf1_loss                | 4.986835e-06 |
| qf2_loss                | 7.968112e-06 |
| time_elapsed            | 279          |
| total timesteps         | 58300        |
| value_loss              | 5.429346e-06 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.8490896     |
| ep_rewmean              | -0.347        |
| episodes                | 588           |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -0.3          |
| n_updates               | 58669         |
| policy_loss             | 0.045614738   |
| qf1_loss                | 3.401952e-05  |
| qf2_loss                | 3.3749053e-05 |
| time_elapsed            | 280           |
| total timesteps         | 58700         |
| value_loss              | 6.870646e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.000782      |
| ep_rewmean              | -0.354        |
| episodes                | 592           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.4          |
| n_updates               | 59069         |
| policy_loss             | 0.049067512   |
| qf1_loss                | 1.8978885e-06 |
| qf2_loss                | 1.4853346e-06 |
| time_elapsed            | 282           |
| total timesteps         | 59100         |
| value_loss              | 3.5838052e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.0653815     |
| ep_rewmean              | -0.352        |
| episodes                | 596           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.4          |
| n_updates               | 59469         |
| policy_loss             | 0.03951582    |
| qf1_loss                | 3.1665259e-06 |
| qf2_loss                | 2.762217e-06  |
| time_elapsed            | 284           |
| total timesteps         | 59500         |
| value_loss              | 2.489825e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.578209      |
| ep_rewmean              | -0.345        |
| episodes                | 600           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 59869         |
| policy_loss             | 0.04262174    |
| qf1_loss                | 3.0998803e-05 |
| qf2_loss                | 3.155182e-05  |
| time_elapsed            | 286           |
| total timesteps         | 59900         |
| value_loss              | 1.7027238e-06 |
-------------------------------------------
Eval num_timesteps=60000, episode_reward=-0.26 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.834256      |
| ep_rewmean              | -0.342        |
| episodes                | 604           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 60269         |
| policy_loss             | 0.050666016   |
| qf1_loss                | 2.2844057e-05 |
| qf2_loss                | 2.2400194e-05 |
| time_elapsed            | 288           |
| total timesteps         | 60300         |
| value_loss              | 1.7539892e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.8983035     |
| ep_rewmean              | -0.343        |
| episodes                | 608           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 60669         |
| policy_loss             | 0.04378639    |
| qf1_loss                | 3.0468054e-06 |
| qf2_loss                | 4.348109e-06  |
| time_elapsed            | 290           |
| total timesteps         | 60700         |
| value_loss              | 4.5078596e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.044243      |
| ep_rewmean              | -0.344        |
| episodes                | 612           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 61069         |
| policy_loss             | 0.053063944   |
| qf1_loss                | 2.7691565e-05 |
| qf2_loss                | 2.8726074e-05 |
| time_elapsed            | 292           |
| total timesteps         | 61100         |
| value_loss              | 4.5883125e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.821426      |
| ep_rewmean              | -0.344        |
| episodes                | 616           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 61469         |
| policy_loss             | 0.058691923   |
| qf1_loss                | 2.674391e-05  |
| qf2_loss                | 2.6605692e-05 |
| time_elapsed            | 293           |
| total timesteps         | 61500         |
| value_loss              | 6.066485e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.055251      |
| ep_rewmean              | -0.348        |
| episodes                | 620           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 61869         |
| policy_loss             | 0.049293466   |
| qf1_loss                | 1.575932e-06  |
| qf2_loss                | 1.219382e-06  |
| time_elapsed            | 295           |
| total timesteps         | 61900         |
| value_loss              | 2.5566824e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.027617      |
| ep_rewmean              | -0.346        |
| episodes                | 624           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 62269         |
| policy_loss             | 0.042554468   |
| qf1_loss                | 1.7618238e-05 |
| qf2_loss                | 1.5433616e-05 |
| time_elapsed            | 297           |
| total timesteps         | 62300         |
| value_loss              | 2.2320482e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.132813      |
| ep_rewmean              | -0.344        |
| episodes                | 628           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 62669         |
| policy_loss             | 0.054538146   |
| qf1_loss                | 1.0364929e-05 |
| qf2_loss                | 5.990284e-06  |
| time_elapsed            | 299           |
| total timesteps         | 62700         |
| value_loss              | 1.0059501e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.836615      |
| ep_rewmean              | -0.347        |
| episodes                | 632           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 63069         |
| policy_loss             | 0.041612983   |
| qf1_loss                | 4.1420662e-05 |
| qf2_loss                | 5.601017e-05  |
| time_elapsed            | 301           |
| total timesteps         | 63100         |
| value_loss              | 1.5040184e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.6848974     |
| ep_rewmean              | -0.341        |
| episodes                | 636           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 63469         |
| policy_loss             | 0.056303196   |
| qf1_loss                | 1.5031087e-06 |
| qf2_loss                | 2.365661e-06  |
| time_elapsed            | 303           |
| total timesteps         | 63500         |
| value_loss              | 6.801742e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.6672997     |
| ep_rewmean              | -0.336        |
| episodes                | 640           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 63869         |
| policy_loss             | 0.05023407    |
| qf1_loss                | 8.695057e-07  |
| qf2_loss                | 3.7562706e-06 |
| time_elapsed            | 304           |
| total timesteps         | 63900         |
| value_loss              | 4.023374e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.30478       |
| ep_rewmean              | -0.325        |
| episodes                | 644           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 64269         |
| policy_loss             | 0.043213423   |
| qf1_loss                | 5.836303e-06  |
| qf2_loss                | 1.6419783e-06 |
| time_elapsed            | 306           |
| total timesteps         | 64300         |
| value_loss              | 3.2793612e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.447742      |
| ep_rewmean              | -0.324        |
| episodes                | 648           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 64669         |
| policy_loss             | 0.046195436   |
| qf1_loss                | 2.988373e-06  |
| qf2_loss                | 2.7272272e-06 |
| time_elapsed            | 308           |
| total timesteps         | 64700         |
| value_loss              | 3.7712166e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.1485767     |
| ep_rewmean              | -0.32         |
| episodes                | 652           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 65069         |
| policy_loss             | 0.04536315    |
| qf1_loss                | 3.053286e-06  |
| qf2_loss                | 2.7330902e-06 |
| time_elapsed            | 310           |
| total timesteps         | 65100         |
| value_loss              | 1.813609e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.99755       |
| ep_rewmean              | -0.318        |
| episodes                | 656           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 65469         |
| policy_loss             | 0.040939424   |
| qf1_loss                | 4.6177942e-07 |
| qf2_loss                | 2.2944398e-06 |
| time_elapsed            | 312           |
| total timesteps         | 65500         |
| value_loss              | 1.1820741e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.011416      |
| ep_rewmean              | -0.315        |
| episodes                | 660           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 65869         |
| policy_loss             | 0.037252933   |
| qf1_loss                | 3.1810094e-05 |
| qf2_loss                | 2.551754e-05  |
| time_elapsed            | 313           |
| total timesteps         | 65900         |
| value_loss              | 9.984815e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.260544      |
| ep_rewmean              | -0.311        |
| episodes                | 664           |
| eplenmean               | 100           |
| fps                     | 209           |
| mean 100 episode reward | -0.3          |
| n_updates               | 66269         |
| policy_loss             | 0.042633504   |
| qf1_loss                | 2.182312e-05  |
| qf2_loss                | 2.1600388e-05 |
| time_elapsed            | 315           |
| total timesteps         | 66300         |
| value_loss              | 9.974176e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.9041123     |
| ep_rewmean              | -0.309        |
| episodes                | 668           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 66669         |
| policy_loss             | 0.06115006    |
| qf1_loss                | 2.1790734e-06 |
| qf2_loss                | 3.2693697e-06 |
| time_elapsed            | 317           |
| total timesteps         | 66700         |
| value_loss              | 2.6148862e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.333495      |
| ep_rewmean              | -0.302        |
| episodes                | 672           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 67069         |
| policy_loss             | 0.04735279    |
| qf1_loss                | 3.1966367e-05 |
| qf2_loss                | 4.583549e-05  |
| time_elapsed            | 319           |
| total timesteps         | 67100         |
| value_loss              | 3.458402e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.7299323     |
| ep_rewmean              | -0.3          |
| episodes                | 676           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 67469         |
| policy_loss             | 0.04447189    |
| qf1_loss                | 1.8422663e-05 |
| qf2_loss                | 1.8572899e-05 |
| time_elapsed            | 321           |
| total timesteps         | 67500         |
| value_loss              | 9.019827e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.562531      |
| ep_rewmean              | -0.3          |
| episodes                | 680           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 67869         |
| policy_loss             | 0.041617792   |
| qf1_loss                | 2.3483378e-06 |
| qf2_loss                | 1.6610895e-06 |
| time_elapsed            | 323           |
| total timesteps         | 67900         |
| value_loss              | 1.3588218e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.7561116     |
| ep_rewmean              | -0.297        |
| episodes                | 684           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 68269         |
| policy_loss             | 0.03737633    |
| qf1_loss                | 2.5689426e-06 |
| qf2_loss                | 1.9212277e-06 |
| time_elapsed            | 324           |
| total timesteps         | 68300         |
| value_loss              | 2.681791e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.630351      |
| ep_rewmean              | -0.294        |
| episodes                | 688           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 68669         |
| policy_loss             | 0.03780928    |
| qf1_loss                | 2.3986351e-05 |
| qf2_loss                | 2.1747614e-05 |
| time_elapsed            | 326           |
| total timesteps         | 68700         |
| value_loss              | 1.7158302e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.5269566     |
| ep_rewmean              | -0.288        |
| episodes                | 692           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 69069         |
| policy_loss             | 0.03701999    |
| qf1_loss                | 4.896424e-05  |
| qf2_loss                | 4.884627e-05  |
| time_elapsed            | 328           |
| total timesteps         | 69100         |
| value_loss              | 3.1452942e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.382098      |
| ep_rewmean              | -0.312        |
| episodes                | 696           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 69469         |
| policy_loss             | 0.048525788   |
| qf1_loss                | 2.4241085e-06 |
| qf2_loss                | 1.2408927e-06 |
| time_elapsed            | 330           |
| total timesteps         | 69500         |
| value_loss              | 6.2536365e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.0741916     |
| ep_rewmean              | -0.317        |
| episodes                | 700           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 69869         |
| policy_loss             | 0.041752413   |
| qf1_loss                | 3.3230817e-06 |
| qf2_loss                | 3.4318314e-06 |
| time_elapsed            | 332           |
| total timesteps         | 69900         |
| value_loss              | 5.2151927e-06 |
-------------------------------------------
Eval num_timesteps=70000, episode_reward=-0.14 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.8469796     |
| ep_rewmean              | -0.319        |
| episodes                | 704           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 70269         |
| policy_loss             | 0.038735073   |
| qf1_loss                | 1.4560623e-05 |
| qf2_loss                | 1.975138e-05  |
| time_elapsed            | 334           |
| total timesteps         | 70300         |
| value_loss              | 1.6287252e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4722223     |
| ep_rewmean              | -0.31         |
| episodes                | 708           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 70669         |
| policy_loss             | 0.048030604   |
| qf1_loss                | 1.299029e-06  |
| qf2_loss                | 1.6458023e-06 |
| time_elapsed            | 336           |
| total timesteps         | 70700         |
| value_loss              | 1.1520747e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.7165384     |
| ep_rewmean              | -0.305        |
| episodes                | 712           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 71069         |
| policy_loss             | 0.03926267    |
| qf1_loss                | 1.2801332e-06 |
| qf2_loss                | 2.050242e-06  |
| time_elapsed            | 338           |
| total timesteps         | 71100         |
| value_loss              | 2.9333685e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.7502403     |
| ep_rewmean              | -0.303        |
| episodes                | 716           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 71469         |
| policy_loss             | 0.04491505    |
| qf1_loss                | 1.6708658e-06 |
| qf2_loss                | 1.9091285e-06 |
| time_elapsed            | 340           |
| total timesteps         | 71500         |
| value_loss              | 1.2642515e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.8397083     |
| ep_rewmean              | -0.298        |
| episodes                | 720           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 71869         |
| policy_loss             | 0.05566088    |
| qf1_loss                | 4.8488505e-06 |
| qf2_loss                | 2.281518e-06  |
| time_elapsed            | 342           |
| total timesteps         | 71900         |
| value_loss              | 5.1804373e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.480594      |
| ep_rewmean              | -0.3          |
| episodes                | 724           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 72269         |
| policy_loss             | 0.05146396    |
| qf1_loss                | 1.8349534e-06 |
| qf2_loss                | 2.7559277e-06 |
| time_elapsed            | 343           |
| total timesteps         | 72300         |
| value_loss              | 1.1146809e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6835766     |
| ep_rewmean              | -0.301        |
| episodes                | 728           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 72669         |
| policy_loss             | 0.035757877   |
| qf1_loss                | 1.9039142e-05 |
| qf2_loss                | 1.8414214e-05 |
| time_elapsed            | 345           |
| total timesteps         | 72700         |
| value_loss              | 3.2238613e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.998045      |
| ep_rewmean              | -0.296        |
| episodes                | 732           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 73069         |
| policy_loss             | 0.043447793   |
| qf1_loss                | 1.6930285e-06 |
| qf2_loss                | 9.947911e-07  |
| time_elapsed            | 347           |
| total timesteps         | 73100         |
| value_loss              | 1.5709688e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.862859      |
| ep_rewmean              | -0.3          |
| episodes                | 736           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 73469         |
| policy_loss             | 0.052039422   |
| qf1_loss                | 1.8367195e-05 |
| qf2_loss                | 1.8275658e-05 |
| time_elapsed            | 349           |
| total timesteps         | 73500         |
| value_loss              | 3.1969976e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.0500584     |
| ep_rewmean              | -0.301        |
| episodes                | 740           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 73869         |
| policy_loss             | 0.04104168    |
| qf1_loss                | 1.7120567e-06 |
| qf2_loss                | 2.1978574e-06 |
| time_elapsed            | 351           |
| total timesteps         | 73900         |
| value_loss              | 3.6450847e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.1855783     |
| ep_rewmean              | -0.306        |
| episodes                | 744           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 74269         |
| policy_loss             | 0.037083026   |
| qf1_loss                | 2.6225107e-06 |
| qf2_loss                | 1.4038388e-06 |
| time_elapsed            | 353           |
| total timesteps         | 74300         |
| value_loss              | 2.5797654e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.9052696     |
| ep_rewmean              | -0.304        |
| episodes                | 748           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 74669         |
| policy_loss             | 0.037389558   |
| qf1_loss                | 2.1791723e-06 |
| qf2_loss                | 1.1119062e-06 |
| time_elapsed            | 354           |
| total timesteps         | 74700         |
| value_loss              | 1.2270036e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.2186046     |
| ep_rewmean              | -0.307        |
| episodes                | 752           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 75069         |
| policy_loss             | 0.040259544   |
| qf1_loss                | 4.2308957e-06 |
| qf2_loss                | 6.831947e-06  |
| time_elapsed            | 356           |
| total timesteps         | 75100         |
| value_loss              | 4.322831e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.567015      |
| ep_rewmean              | -0.31         |
| episodes                | 756           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 75469         |
| policy_loss             | 0.04217183    |
| qf1_loss                | 2.4516095e-05 |
| qf2_loss                | 2.774904e-05  |
| time_elapsed            | 358           |
| total timesteps         | 75500         |
| value_loss              | 4.908084e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.943814      |
| ep_rewmean              | -0.313        |
| episodes                | 760           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 75869         |
| policy_loss             | 0.037127756   |
| qf1_loss                | 2.0205027e-05 |
| qf2_loss                | 1.4215065e-05 |
| time_elapsed            | 360           |
| total timesteps         | 75900         |
| value_loss              | 2.8467464e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.6089745     |
| ep_rewmean              | -0.315        |
| episodes                | 764           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 76269         |
| policy_loss             | 0.043058336   |
| qf1_loss                | 4.9618968e-05 |
| qf2_loss                | 4.6467303e-05 |
| time_elapsed            | 362           |
| total timesteps         | 76300         |
| value_loss              | 2.0811808e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5336876     |
| ep_rewmean              | -0.312        |
| episodes                | 768           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 76669         |
| policy_loss             | 0.044943016   |
| qf1_loss                | 3.0516807e-05 |
| qf2_loss                | 3.6284284e-05 |
| time_elapsed            | 363           |
| total timesteps         | 76700         |
| value_loss              | 1.718102e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.058066      |
| ep_rewmean              | -0.313        |
| episodes                | 772           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 77069         |
| policy_loss             | 0.039738145   |
| qf1_loss                | 2.4619987e-06 |
| qf2_loss                | 2.9384346e-06 |
| time_elapsed            | 365           |
| total timesteps         | 77100         |
| value_loss              | 2.258667e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5098295     |
| ep_rewmean              | -0.315        |
| episodes                | 776           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 77469         |
| policy_loss             | 0.03795948    |
| qf1_loss                | 1.5441514e-05 |
| qf2_loss                | 1.7056993e-05 |
| time_elapsed            | 367           |
| total timesteps         | 77500         |
| value_loss              | 2.0507855e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.143833      |
| ep_rewmean              | -0.314        |
| episodes                | 780           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 77869         |
| policy_loss             | 0.037337963   |
| qf1_loss                | 1.0288369e-06 |
| qf2_loss                | 1.6584172e-06 |
| time_elapsed            | 369           |
| total timesteps         | 77900         |
| value_loss              | 1.4477937e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5707874     |
| ep_rewmean              | -0.32         |
| episodes                | 784           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 78269         |
| policy_loss             | 0.039373096   |
| qf1_loss                | 1.9590618e-06 |
| qf2_loss                | 1.9430936e-06 |
| time_elapsed            | 371           |
| total timesteps         | 78300         |
| value_loss              | 2.983339e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.87126       |
| ep_rewmean              | -0.323        |
| episodes                | 788           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 78669         |
| policy_loss             | 0.04557366    |
| qf1_loss                | 6.6721104e-06 |
| qf2_loss                | 5.252468e-06  |
| time_elapsed            | 372           |
| total timesteps         | 78700         |
| value_loss              | 2.5779725e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.332319      |
| ep_rewmean              | -0.321        |
| episodes                | 792           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 79069         |
| policy_loss             | 0.046457045   |
| qf1_loss                | 1.3865232e-05 |
| qf2_loss                | 1.5513107e-05 |
| time_elapsed            | 374           |
| total timesteps         | 79100         |
| value_loss              | 2.4204887e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.460552      |
| ep_rewmean              | -0.295        |
| episodes                | 796           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 79469         |
| policy_loss             | 0.03769177    |
| qf1_loss                | 1.6710449e-06 |
| qf2_loss                | 5.445686e-07  |
| time_elapsed            | 376           |
| total timesteps         | 79500         |
| value_loss              | 5.0867743e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7740297     |
| ep_rewmean              | -0.292        |
| episodes                | 800           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 79869         |
| policy_loss             | 0.039458133   |
| qf1_loss                | 1.7132275e-05 |
| qf2_loss                | 1.2525263e-05 |
| time_elapsed            | 378           |
| total timesteps         | 79900         |
| value_loss              | 6.4274136e-06 |
-------------------------------------------
Eval num_timesteps=80000, episode_reward=-0.25 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.917761      |
| ep_rewmean              | -0.288        |
| episodes                | 804           |
| eplenmean               | 100           |
| fps                     | 210           |
| mean 100 episode reward | -0.3          |
| n_updates               | 80269         |
| policy_loss             | 0.033390157   |
| qf1_loss                | 1.2863776e-06 |
| qf2_loss                | 6.715717e-07  |
| time_elapsed            | 380           |
| total timesteps         | 80300         |
| value_loss              | 9.096241e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.2793856     |
| ep_rewmean              | -0.292        |
| episodes                | 808           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 80669         |
| policy_loss             | 0.03827342    |
| qf1_loss                | 5.2715345e-06 |
| qf2_loss                | 6.4720502e-06 |
| time_elapsed            | 382           |
| total timesteps         | 80700         |
| value_loss              | 4.9101454e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.438504      |
| ep_rewmean              | -0.292        |
| episodes                | 812           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 81069         |
| policy_loss             | 0.03873864    |
| qf1_loss                | 1.454489e-05  |
| qf2_loss                | 1.4137256e-05 |
| time_elapsed            | 384           |
| total timesteps         | 81100         |
| value_loss              | 2.681117e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.376853      |
| ep_rewmean              | -0.288        |
| episodes                | 816           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 81469         |
| policy_loss             | 0.038399808   |
| qf1_loss                | 4.484489e-06  |
| qf2_loss                | 3.8057283e-06 |
| time_elapsed            | 386           |
| total timesteps         | 81500         |
| value_loss              | 2.297177e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.981925      |
| ep_rewmean              | -0.288        |
| episodes                | 820           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 81869         |
| policy_loss             | 0.039493635   |
| qf1_loss                | 3.5201288e-06 |
| qf2_loss                | 4.3632654e-06 |
| time_elapsed            | 387           |
| total timesteps         | 81900         |
| value_loss              | 5.4620496e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.581993      |
| ep_rewmean              | -0.29         |
| episodes                | 824           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 82269         |
| policy_loss             | 0.038760543   |
| qf1_loss                | 2.9859843e-06 |
| qf2_loss                | 2.4064707e-06 |
| time_elapsed            | 389           |
| total timesteps         | 82300         |
| value_loss              | 6.75203e-06   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.1823063     |
| ep_rewmean              | -0.298        |
| episodes                | 828           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 82669         |
| policy_loss             | 0.04546423    |
| qf1_loss                | 1.6401906e-06 |
| qf2_loss                | 5.7793e-07    |
| time_elapsed            | 391           |
| total timesteps         | 82700         |
| value_loss              | 1.9760307e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4030066     |
| ep_rewmean              | -0.302        |
| episodes                | 832           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 83069         |
| policy_loss             | 0.04299764    |
| qf1_loss                | 5.4797747e-06 |
| qf2_loss                | 6.2597173e-06 |
| time_elapsed            | 393           |
| total timesteps         | 83100         |
| value_loss              | 6.86346e-06   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.279046      |
| ep_rewmean              | -0.302        |
| episodes                | 836           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 83469         |
| policy_loss             | 0.046939634   |
| qf1_loss                | 1.7951108e-06 |
| qf2_loss                | 1.1159623e-06 |
| time_elapsed            | 395           |
| total timesteps         | 83500         |
| value_loss              | 3.2612397e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.144167      |
| ep_rewmean              | -0.301        |
| episodes                | 840           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 83869         |
| policy_loss             | 0.04289584    |
| qf1_loss                | 1.8230027e-06 |
| qf2_loss                | 1.4470312e-06 |
| time_elapsed            | 396           |
| total timesteps         | 83900         |
| value_loss              | 5.3936874e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.234588      |
| ep_rewmean              | -0.297        |
| episodes                | 844           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 84269         |
| policy_loss             | 0.03821189    |
| qf1_loss                | 3.691337e-05  |
| qf2_loss                | 3.5723257e-05 |
| time_elapsed            | 398           |
| total timesteps         | 84300         |
| value_loss              | 1.6135075e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.14845       |
| ep_rewmean              | -0.296        |
| episodes                | 848           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 84669         |
| policy_loss             | 0.036162503   |
| qf1_loss                | 2.3863638e-06 |
| qf2_loss                | 1.6417313e-06 |
| time_elapsed            | 400           |
| total timesteps         | 84700         |
| value_loss              | 2.0060093e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.135132      |
| ep_rewmean              | -0.297        |
| episodes                | 852           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 85069         |
| policy_loss             | 0.041978285   |
| qf1_loss                | 1.0808924e-05 |
| qf2_loss                | 3.6555434e-06 |
| time_elapsed            | 402           |
| total timesteps         | 85100         |
| value_loss              | 2.424339e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.940013      |
| ep_rewmean              | -0.299        |
| episodes                | 856           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 85469         |
| policy_loss             | 0.03636343    |
| qf1_loss                | 1.5728714e-05 |
| qf2_loss                | 1.5368882e-05 |
| time_elapsed            | 404           |
| total timesteps         | 85500         |
| value_loss              | 3.0723495e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.714793      |
| ep_rewmean              | -0.298        |
| episodes                | 860           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 85869         |
| policy_loss             | 0.039236635   |
| qf1_loss                | 1.5372519e-06 |
| qf2_loss                | 1.361396e-06  |
| time_elapsed            | 406           |
| total timesteps         | 85900         |
| value_loss              | 1.9287343e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7935615     |
| ep_rewmean              | -0.302        |
| episodes                | 864           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 86269         |
| policy_loss             | 0.03891408    |
| qf1_loss                | 1.4332586e-06 |
| qf2_loss                | 8.2149455e-07 |
| time_elapsed            | 407           |
| total timesteps         | 86300         |
| value_loss              | 1.595665e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.542733      |
| ep_rewmean              | -0.306        |
| episodes                | 868           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 86669         |
| policy_loss             | 0.034634676   |
| qf1_loss                | 2.801627e-06  |
| qf2_loss                | 2.3950442e-06 |
| time_elapsed            | 409           |
| total timesteps         | 86700         |
| value_loss              | 6.5706314e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4905243     |
| ep_rewmean              | -0.306        |
| episodes                | 872           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 87069         |
| policy_loss             | 0.041997373   |
| qf1_loss                | 2.0605623e-05 |
| qf2_loss                | 7.4876107e-06 |
| time_elapsed            | 411           |
| total timesteps         | 87100         |
| value_loss              | 1.4819831e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.916177      |
| ep_rewmean              | -0.305        |
| episodes                | 876           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 87469         |
| policy_loss             | 0.035407275   |
| qf1_loss                | 1.160253e-06  |
| qf2_loss                | 1.3705162e-06 |
| time_elapsed            | 413           |
| total timesteps         | 87500         |
| value_loss              | 5.8032794e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.675288      |
| ep_rewmean              | -0.308        |
| episodes                | 880           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 87869         |
| policy_loss             | 0.03545412    |
| qf1_loss                | 1.0102882e-06 |
| qf2_loss                | 5.356436e-07  |
| time_elapsed            | 415           |
| total timesteps         | 87900         |
| value_loss              | 8.575022e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.010748      |
| ep_rewmean              | -0.307        |
| episodes                | 884           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 88269         |
| policy_loss             | 0.034256518   |
| qf1_loss                | 2.8935952e-05 |
| qf2_loss                | 2.9602135e-05 |
| time_elapsed            | 416           |
| total timesteps         | 88300         |
| value_loss              | 7.43291e-07   |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 6.072191     |
| ep_rewmean              | -0.305       |
| episodes                | 888          |
| eplenmean               | 100          |
| fps                     | 211          |
| mean 100 episode reward | -0.3         |
| n_updates               | 88669        |
| policy_loss             | 0.05244243   |
| qf1_loss                | 9.920818e-06 |
| qf2_loss                | 9.302628e-06 |
| time_elapsed            | 418          |
| total timesteps         | 88700        |
| value_loss              | 5.05876e-06  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6322474     |
| ep_rewmean              | -0.31         |
| episodes                | 892           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 89069         |
| policy_loss             | 0.038389966   |
| qf1_loss                | 3.978478e-06  |
| qf2_loss                | 2.3563366e-06 |
| time_elapsed            | 420           |
| total timesteps         | 89100         |
| value_loss              | 2.598632e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.418413      |
| ep_rewmean              | -0.315        |
| episodes                | 896           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 89469         |
| policy_loss             | 0.046999224   |
| qf1_loss                | 4.4622097e-06 |
| qf2_loss                | 7.5528317e-07 |
| time_elapsed            | 422           |
| total timesteps         | 89500         |
| value_loss              | 1.3281235e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4260926     |
| ep_rewmean              | -0.317        |
| episodes                | 900           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 89869         |
| policy_loss             | 0.047300894   |
| qf1_loss                | 5.0290205e-06 |
| qf2_loss                | 4.771367e-06  |
| time_elapsed            | 424           |
| total timesteps         | 89900         |
| value_loss              | 4.839618e-06  |
-------------------------------------------
Eval num_timesteps=90000, episode_reward=-0.30 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.307235      |
| ep_rewmean              | -0.324        |
| episodes                | 904           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 90269         |
| policy_loss             | 0.04406363    |
| qf1_loss                | 1.6048953e-05 |
| qf2_loss                | 2.5867064e-05 |
| time_elapsed            | 426           |
| total timesteps         | 90300         |
| value_loss              | 1.4447805e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.040102      |
| ep_rewmean              | -0.325        |
| episodes                | 908           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 90669         |
| policy_loss             | 0.039935634   |
| qf1_loss                | 2.3529226e-06 |
| qf2_loss                | 4.3622044e-06 |
| time_elapsed            | 428           |
| total timesteps         | 90700         |
| value_loss              | 1.4171442e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4849596     |
| ep_rewmean              | -0.327        |
| episodes                | 912           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 91069         |
| policy_loss             | 0.03768694    |
| qf1_loss                | 8.691819e-07  |
| qf2_loss                | 1.351094e-06  |
| time_elapsed            | 429           |
| total timesteps         | 91100         |
| value_loss              | 5.3859367e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.503787      |
| ep_rewmean              | -0.328        |
| episodes                | 916           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 91469         |
| policy_loss             | 0.043883204   |
| qf1_loss                | 2.1881776e-06 |
| qf2_loss                | 1.1176389e-06 |
| time_elapsed            | 431           |
| total timesteps         | 91500         |
| value_loss              | 2.1482633e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.378518      |
| ep_rewmean              | -0.326        |
| episodes                | 920           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 91869         |
| policy_loss             | 0.04299909    |
| qf1_loss                | 1.7470468e-06 |
| qf2_loss                | 1.984141e-06  |
| time_elapsed            | 433           |
| total timesteps         | 91900         |
| value_loss              | 1.0409804e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9228477     |
| ep_rewmean              | -0.328        |
| episodes                | 924           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 92269         |
| policy_loss             | 0.041230112   |
| qf1_loss                | 2.9098821e-05 |
| qf2_loss                | 2.5429108e-05 |
| time_elapsed            | 435           |
| total timesteps         | 92300         |
| value_loss              | 4.5272945e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.1164656     |
| ep_rewmean              | -0.323        |
| episodes                | 928           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 92669         |
| policy_loss             | 0.041128434   |
| qf1_loss                | 2.9941748e-06 |
| qf2_loss                | 1.81004e-06   |
| time_elapsed            | 437           |
| total timesteps         | 92700         |
| value_loss              | 2.7140732e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5875473     |
| ep_rewmean              | -0.323        |
| episodes                | 932           |
| eplenmean               | 100           |
| fps                     | 211           |
| mean 100 episode reward | -0.3          |
| n_updates               | 93069         |
| policy_loss             | 0.04323407    |
| qf1_loss                | 1.449802e-06  |
| qf2_loss                | 1.4729845e-06 |
| time_elapsed            | 439           |
| total timesteps         | 93100         |
| value_loss              | 2.935644e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.33377       |
| ep_rewmean              | -0.324        |
| episodes                | 936           |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.3          |
| n_updates               | 93469         |
| policy_loss             | 0.040552378   |
| qf1_loss                | 2.8794625e-06 |
| qf2_loss                | 4.7247067e-06 |
| time_elapsed            | 440           |
| total timesteps         | 93500         |
| value_loss              | 1.395216e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.1337404     |
| ep_rewmean              | -0.323        |
| episodes                | 940           |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.3          |
| n_updates               | 93869         |
| policy_loss             | 0.049517993   |
| qf1_loss                | 7.9898695e-05 |
| qf2_loss                | 8.167489e-05  |
| time_elapsed            | 442           |
| total timesteps         | 93900         |
| value_loss              | 1.0831044e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.270705      |
| ep_rewmean              | -0.327        |
| episodes                | 944           |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.3          |
| n_updates               | 94269         |
| policy_loss             | 0.040918462   |
| qf1_loss                | 1.3927031e-06 |
| qf2_loss                | 1.9374368e-06 |
| time_elapsed            | 444           |
| total timesteps         | 94300         |
| value_loss              | 1.9323827e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.2188253     |
| ep_rewmean              | -0.33         |
| episodes                | 948           |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.3          |
| n_updates               | 94669         |
| policy_loss             | 0.055434875   |
| qf1_loss                | 9.866306e-06  |
| qf2_loss                | 4.0975815e-06 |
| time_elapsed            | 446           |
| total timesteps         | 94700         |
| value_loss              | 3.2515732e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8677063     |
| ep_rewmean              | -0.332        |
| episodes                | 952           |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.3          |
| n_updates               | 95069         |
| policy_loss             | 0.032515578   |
| qf1_loss                | 2.3186096e-06 |
| qf2_loss                | 1.2347405e-06 |
| time_elapsed            | 448           |
| total timesteps         | 95100         |
| value_loss              | 1.0152372e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.946087      |
| ep_rewmean              | -0.338        |
| episodes                | 956           |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.3          |
| n_updates               | 95469         |
| policy_loss             | 0.04040135    |
| qf1_loss                | 9.2327156e-07 |
| qf2_loss                | 4.615465e-07  |
| time_elapsed            | 449           |
| total timesteps         | 95500         |
| value_loss              | 7.26023e-07   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6161137     |
| ep_rewmean              | -0.342        |
| episodes                | 960           |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.3          |
| n_updates               | 95869         |
| policy_loss             | 0.039469898   |
| qf1_loss                | 4.323624e-06  |
| qf2_loss                | 4.153999e-06  |
| time_elapsed            | 451           |
| total timesteps         | 95900         |
| value_loss              | 1.3399799e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1735477     |
| ep_rewmean              | -0.345        |
| episodes                | 964           |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.3          |
| n_updates               | 96269         |
| policy_loss             | 0.04288619    |
| qf1_loss                | 1.1580762e-06 |
| qf2_loss                | 1.0513611e-06 |
| time_elapsed            | 453           |
| total timesteps         | 96300         |
| value_loss              | 3.7694756e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5375023     |
| ep_rewmean              | -0.346        |
| episodes                | 968           |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.3          |
| n_updates               | 96669         |
| policy_loss             | 0.0379896     |
| qf1_loss                | 1.742262e-05  |
| qf2_loss                | 1.737962e-05  |
| time_elapsed            | 455           |
| total timesteps         | 96700         |
| value_loss              | 1.1836676e-06 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 6.720207     |
| ep_rewmean              | -0.351       |
| episodes                | 972          |
| eplenmean               | 100          |
| fps                     | 212          |
| mean 100 episode reward | -0.4         |
| n_updates               | 97069        |
| policy_loss             | 0.049835276  |
| qf1_loss                | 4.74913e-06  |
| qf2_loss                | 4.930257e-06 |
| time_elapsed            | 457          |
| total timesteps         | 97100        |
| value_loss              | 5.610211e-06 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8303194     |
| ep_rewmean              | -0.357        |
| episodes                | 976           |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 97469         |
| policy_loss             | 0.037144743   |
| qf1_loss                | 2.5026668e-06 |
| qf2_loss                | 8.3181715e-07 |
| time_elapsed            | 458           |
| total timesteps         | 97500         |
| value_loss              | 3.1835286e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.386442      |
| ep_rewmean              | -0.359        |
| episodes                | 980           |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 97869         |
| policy_loss             | 0.04237686    |
| qf1_loss                | 4.2655697e-06 |
| qf2_loss                | 1.8413324e-06 |
| time_elapsed            | 460           |
| total timesteps         | 97900         |
| value_loss              | 2.5895172e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.7101755     |
| ep_rewmean              | -0.363        |
| episodes                | 984           |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 98269         |
| policy_loss             | 0.046869606   |
| qf1_loss                | 3.1251147e-06 |
| qf2_loss                | 1.6847454e-06 |
| time_elapsed            | 462           |
| total timesteps         | 98300         |
| value_loss              | 9.608501e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.595034      |
| ep_rewmean              | -0.366        |
| episodes                | 988           |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 98669         |
| policy_loss             | 0.044878505   |
| qf1_loss                | 7.118934e-06  |
| qf2_loss                | 3.822106e-06  |
| time_elapsed            | 464           |
| total timesteps         | 98700         |
| value_loss              | 3.4253205e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5377603     |
| ep_rewmean              | -0.361        |
| episodes                | 992           |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 99069         |
| policy_loss             | 0.0480586     |
| qf1_loss                | 2.2441025e-05 |
| qf2_loss                | 2.2075012e-05 |
| time_elapsed            | 466           |
| total timesteps         | 99100         |
| value_loss              | 2.8988225e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.026869      |
| ep_rewmean              | -0.354        |
| episodes                | 996           |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 99469         |
| policy_loss             | 0.0535523     |
| qf1_loss                | 2.0068896e-06 |
| qf2_loss                | 1.6638355e-06 |
| time_elapsed            | 468           |
| total timesteps         | 99500         |
| value_loss              | 1.6103196e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5500574     |
| ep_rewmean              | -0.352        |
| episodes                | 1000          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 99869         |
| policy_loss             | 0.046335742   |
| qf1_loss                | 3.2876108e-06 |
| qf2_loss                | 4.659077e-06  |
| time_elapsed            | 469           |
| total timesteps         | 99900         |
| value_loss              | 5.731602e-06  |
-------------------------------------------
Eval num_timesteps=100000, episode_reward=-0.40 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.17331       |
| ep_rewmean              | -0.352        |
| episodes                | 1004          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 100269        |
| policy_loss             | 0.04683671    |
| qf1_loss                | 4.3815817e-05 |
| qf2_loss                | 4.1523377e-05 |
| time_elapsed            | 472           |
| total timesteps         | 100300        |
| value_loss              | 2.226816e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.7275867     |
| ep_rewmean              | -0.354        |
| episodes                | 1008          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 100669        |
| policy_loss             | 0.051611632   |
| qf1_loss                | 2.1145392e-05 |
| qf2_loss                | 2.5472942e-05 |
| time_elapsed            | 473           |
| total timesteps         | 100700        |
| value_loss              | 3.4348895e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.464876      |
| ep_rewmean              | -0.352        |
| episodes                | 1012          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 101069        |
| policy_loss             | 0.04370773    |
| qf1_loss                | 1.1311455e-06 |
| qf2_loss                | 7.9016684e-07 |
| time_elapsed            | 475           |
| total timesteps         | 101100        |
| value_loss              | 9.847877e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.8610296     |
| ep_rewmean              | -0.355        |
| episodes                | 1016          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 101469        |
| policy_loss             | 0.035184447   |
| qf1_loss                | 4.0164596e-06 |
| qf2_loss                | 3.4629325e-06 |
| time_elapsed            | 477           |
| total timesteps         | 101500        |
| value_loss              | 5.7541015e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4039636     |
| ep_rewmean              | -0.357        |
| episodes                | 1020          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 101869        |
| policy_loss             | 0.043599278   |
| qf1_loss                | 1.4014249e-06 |
| qf2_loss                | 7.440966e-07  |
| time_elapsed            | 479           |
| total timesteps         | 101900        |
| value_loss              | 2.788821e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.2487674     |
| ep_rewmean              | -0.354        |
| episodes                | 1024          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 102269        |
| policy_loss             | 0.04464311    |
| qf1_loss                | 1.9296708e-06 |
| qf2_loss                | 9.801362e-07  |
| time_elapsed            | 481           |
| total timesteps         | 102300        |
| value_loss              | 1.662911e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.1375647     |
| ep_rewmean              | -0.355        |
| episodes                | 1028          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 102669        |
| policy_loss             | 0.04996731    |
| qf1_loss                | 2.0087555e-06 |
| qf2_loss                | 3.3791644e-06 |
| time_elapsed            | 482           |
| total timesteps         | 102700        |
| value_loss              | 6.954809e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.3900785     |
| ep_rewmean              | -0.358        |
| episodes                | 1032          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 103069        |
| policy_loss             | 0.04092609    |
| qf1_loss                | 8.3513237e-07 |
| qf2_loss                | 4.2203294e-07 |
| time_elapsed            | 484           |
| total timesteps         | 103100        |
| value_loss              | 1.8531543e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6871214     |
| ep_rewmean              | -0.356        |
| episodes                | 1036          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 103469        |
| policy_loss             | 0.0418096     |
| qf1_loss                | 7.8170194e-07 |
| qf2_loss                | 1.0214426e-06 |
| time_elapsed            | 486           |
| total timesteps         | 103500        |
| value_loss              | 1.55759e-06   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.1920314     |
| ep_rewmean              | -0.356        |
| episodes                | 1040          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 103869        |
| policy_loss             | 0.04120139    |
| qf1_loss                | 5.6040604e-05 |
| qf2_loss                | 4.2283187e-05 |
| time_elapsed            | 488           |
| total timesteps         | 103900        |
| value_loss              | 4.641922e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.394492      |
| ep_rewmean              | -0.351        |
| episodes                | 1044          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.4          |
| n_updates               | 104269        |
| policy_loss             | 0.039821006   |
| qf1_loss                | 1.2308865e-06 |
| qf2_loss                | 9.007888e-07  |
| time_elapsed            | 490           |
| total timesteps         | 104300        |
| value_loss              | 1.6263905e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8589134     |
| ep_rewmean              | -0.347        |
| episodes                | 1048          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.3          |
| n_updates               | 104669        |
| policy_loss             | 0.041624457   |
| qf1_loss                | 1.0882574e-06 |
| qf2_loss                | 8.055571e-07  |
| time_elapsed            | 492           |
| total timesteps         | 104700        |
| value_loss              | 7.370795e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.3642063     |
| ep_rewmean              | -0.343        |
| episodes                | 1052          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.3          |
| n_updates               | 105069        |
| policy_loss             | 0.037865344   |
| qf1_loss                | 2.1298201e-06 |
| qf2_loss                | 2.0990626e-06 |
| time_elapsed            | 493           |
| total timesteps         | 105100        |
| value_loss              | 1.2787048e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.426788      |
| ep_rewmean              | -0.336        |
| episodes                | 1056          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.3          |
| n_updates               | 105469        |
| policy_loss             | 0.03905213    |
| qf1_loss                | 1.3133406e-06 |
| qf2_loss                | 8.65419e-07   |
| time_elapsed            | 495           |
| total timesteps         | 105500        |
| value_loss              | 2.2176569e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.605406      |
| ep_rewmean              | -0.331        |
| episodes                | 1060          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.3          |
| n_updates               | 105869        |
| policy_loss             | 0.034693677   |
| qf1_loss                | 4.7213896e-07 |
| qf2_loss                | 2.0413643e-07 |
| time_elapsed            | 497           |
| total timesteps         | 105900        |
| value_loss              | 1.0073559e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5217133     |
| ep_rewmean              | -0.324        |
| episodes                | 1064          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.3          |
| n_updates               | 106269        |
| policy_loss             | 0.045265812   |
| qf1_loss                | 1.2610947e-06 |
| qf2_loss                | 7.990411e-07  |
| time_elapsed            | 499           |
| total timesteps         | 106300        |
| value_loss              | 2.614319e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.6646113     |
| ep_rewmean              | -0.32         |
| episodes                | 1068          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.3          |
| n_updates               | 106669        |
| policy_loss             | 0.039996114   |
| qf1_loss                | 5.5075634e-05 |
| qf2_loss                | 5.9096004e-05 |
| time_elapsed            | 501           |
| total timesteps         | 106700        |
| value_loss              | 1.0425301e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.108221      |
| ep_rewmean              | -0.316        |
| episodes                | 1072          |
| eplenmean               | 100           |
| fps                     | 212           |
| mean 100 episode reward | -0.3          |
| n_updates               | 107069        |
| policy_loss             | 0.040145583   |
| qf1_loss                | 7.6803644e-07 |
| qf2_loss                | 6.521981e-07  |
| time_elapsed            | 502           |
| total timesteps         | 107100        |
| value_loss              | 3.5058113e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.268858      |
| ep_rewmean              | -0.31         |
| episodes                | 1076          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 107469        |
| policy_loss             | 0.0397371     |
| qf1_loss                | 9.4757695e-07 |
| qf2_loss                | 1.3066663e-06 |
| time_elapsed            | 504           |
| total timesteps         | 107500        |
| value_loss              | 1.0238565e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.2194843     |
| ep_rewmean              | -0.306        |
| episodes                | 1080          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 107869        |
| policy_loss             | 0.037046142   |
| qf1_loss                | 2.092602e-06  |
| qf2_loss                | 1.8518241e-06 |
| time_elapsed            | 506           |
| total timesteps         | 107900        |
| value_loss              | 8.079537e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4407077     |
| ep_rewmean              | -0.3          |
| episodes                | 1084          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 108269        |
| policy_loss             | 0.036669925   |
| qf1_loss                | 1.4913954e-05 |
| qf2_loss                | 1.6081032e-05 |
| time_elapsed            | 508           |
| total timesteps         | 108300        |
| value_loss              | 1.3007115e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.1316004     |
| ep_rewmean              | -0.295        |
| episodes                | 1088          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 108669        |
| policy_loss             | 0.03887496    |
| qf1_loss                | 2.0748992e-05 |
| qf2_loss                | 2.1515361e-05 |
| time_elapsed            | 510           |
| total timesteps         | 108700        |
| value_loss              | 4.44202e-06   |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 6.5598464    |
| ep_rewmean              | -0.293       |
| episodes                | 1092         |
| eplenmean               | 100          |
| fps                     | 213          |
| mean 100 episode reward | -0.3         |
| n_updates               | 109069       |
| policy_loss             | 0.03673219   |
| qf1_loss                | 5.972164e-07 |
| qf2_loss                | 5.549283e-07 |
| time_elapsed            | 511          |
| total timesteps         | 109100       |
| value_loss              | 8.940455e-07 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5527754     |
| ep_rewmean              | -0.293        |
| episodes                | 1096          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 109469        |
| policy_loss             | 0.035826813   |
| qf1_loss                | 4.5018737e-07 |
| qf2_loss                | 5.749589e-07  |
| time_elapsed            | 513           |
| total timesteps         | 109500        |
| value_loss              | 1.5919723e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.656284      |
| ep_rewmean              | -0.292        |
| episodes                | 1100          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 109869        |
| policy_loss             | 0.036389995   |
| qf1_loss                | 8.8028514e-07 |
| qf2_loss                | 7.9283245e-07 |
| time_elapsed            | 515           |
| total timesteps         | 109900        |
| value_loss              | 2.3264195e-06 |
-------------------------------------------
Eval num_timesteps=110000, episode_reward=-0.20 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.40166       |
| ep_rewmean              | -0.285        |
| episodes                | 1104          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 110269        |
| policy_loss             | 0.03396832    |
| qf1_loss                | 4.2416796e-05 |
| qf2_loss                | 4.2292155e-05 |
| time_elapsed            | 517           |
| total timesteps         | 110300        |
| value_loss              | 1.4824234e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5577593     |
| ep_rewmean              | -0.28         |
| episodes                | 1108          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 110669        |
| policy_loss             | 0.032763343   |
| qf1_loss                | 1.6337544e-06 |
| qf2_loss                | 7.9808115e-07 |
| time_elapsed            | 519           |
| total timesteps         | 110700        |
| value_loss              | 5.714485e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.255622      |
| ep_rewmean              | -0.277        |
| episodes                | 1112          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 111069        |
| policy_loss             | 0.035546813   |
| qf1_loss                | 1.1419263e-06 |
| qf2_loss                | 8.488279e-07  |
| time_elapsed            | 521           |
| total timesteps         | 111100        |
| value_loss              | 5.584254e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.197892      |
| ep_rewmean              | -0.27         |
| episodes                | 1116          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 111469        |
| policy_loss             | 0.032821566   |
| qf1_loss                | 6.406103e-07  |
| qf2_loss                | 5.8729495e-07 |
| time_elapsed            | 522           |
| total timesteps         | 111500        |
| value_loss              | 3.6681156e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.423728      |
| ep_rewmean              | -0.264        |
| episodes                | 1120          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 111869        |
| policy_loss             | 0.031002145   |
| qf1_loss                | 1.3593433e-05 |
| qf2_loss                | 1.1979663e-05 |
| time_elapsed            | 524           |
| total timesteps         | 111900        |
| value_loss              | 3.1176453e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.490987      |
| ep_rewmean              | -0.263        |
| episodes                | 1124          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 112269        |
| policy_loss             | 0.032556705   |
| qf1_loss                | 1.4618886e-06 |
| qf2_loss                | 2.0476607e-06 |
| time_elapsed            | 526           |
| total timesteps         | 112300        |
| value_loss              | 8.5039306e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5601215     |
| ep_rewmean              | -0.257        |
| episodes                | 1128          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 112669        |
| policy_loss             | 0.034542862   |
| qf1_loss                | 5.4832594e-07 |
| qf2_loss                | 5.790199e-07  |
| time_elapsed            | 528           |
| total timesteps         | 112700        |
| value_loss              | 1.1183711e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5703096     |
| ep_rewmean              | -0.25         |
| episodes                | 1132          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 113069        |
| policy_loss             | 0.029225567   |
| qf1_loss                | 9.579599e-06  |
| qf2_loss                | 1.0044578e-05 |
| time_elapsed            | 530           |
| total timesteps         | 113100        |
| value_loss              | 9.3301173e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4734097     |
| ep_rewmean              | -0.25         |
| episodes                | 1136          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 113469        |
| policy_loss             | 0.028958537   |
| qf1_loss                | 1.1114516e-05 |
| qf2_loss                | 1.1524986e-05 |
| time_elapsed            | 531           |
| total timesteps         | 113500        |
| value_loss              | 3.0141057e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4752226     |
| ep_rewmean              | -0.248        |
| episodes                | 1140          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 113869        |
| policy_loss             | 0.031767286   |
| qf1_loss                | 1.039193e-05  |
| qf2_loss                | 1.1319233e-05 |
| time_elapsed            | 533           |
| total timesteps         | 113900        |
| value_loss              | 3.0932526e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.838664      |
| ep_rewmean              | -0.249        |
| episodes                | 1144          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 114269        |
| policy_loss             | 0.026296927   |
| qf1_loss                | 9.859029e-06  |
| qf2_loss                | 1.0698024e-05 |
| time_elapsed            | 535           |
| total timesteps         | 114300        |
| value_loss              | 9.055268e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.792987      |
| ep_rewmean              | -0.249        |
| episodes                | 1148          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 114669        |
| policy_loss             | 0.031093264   |
| qf1_loss                | 6.784297e-07  |
| qf2_loss                | 5.855273e-07  |
| time_elapsed            | 537           |
| total timesteps         | 114700        |
| value_loss              | 6.1203826e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5588803     |
| ep_rewmean              | -0.246        |
| episodes                | 1152          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 115069        |
| policy_loss             | 0.03284207    |
| qf1_loss                | 2.2229951e-06 |
| qf2_loss                | 6.466581e-07  |
| time_elapsed            | 539           |
| total timesteps         | 115100        |
| value_loss              | 7.3095396e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.499058      |
| ep_rewmean              | -0.243        |
| episodes                | 1156          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 115469        |
| policy_loss             | 0.034943596   |
| qf1_loss                | 2.5158888e-06 |
| qf2_loss                | 1.2466668e-06 |
| time_elapsed            | 541           |
| total timesteps         | 115500        |
| value_loss              | 1.3367206e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.610776      |
| ep_rewmean              | -0.241        |
| episodes                | 1160          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 115869        |
| policy_loss             | 0.027142918   |
| qf1_loss                | 1.0287228e-05 |
| qf2_loss                | 1.1070497e-05 |
| time_elapsed            | 543           |
| total timesteps         | 115900        |
| value_loss              | 5.823394e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.803096      |
| ep_rewmean              | -0.238        |
| episodes                | 1164          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 116269        |
| policy_loss             | 0.032401703   |
| qf1_loss                | 6.819651e-07  |
| qf2_loss                | 1.3864934e-06 |
| time_elapsed            | 545           |
| total timesteps         | 116300        |
| value_loss              | 1.2371993e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.287229      |
| ep_rewmean              | -0.234        |
| episodes                | 1168          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 116669        |
| policy_loss             | 0.038138546   |
| qf1_loss                | 9.01798e-06   |
| qf2_loss                | 9.500084e-06  |
| time_elapsed            | 546           |
| total timesteps         | 116700        |
| value_loss              | 2.3852783e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8957357     |
| ep_rewmean              | -0.234        |
| episodes                | 1172          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 117069        |
| policy_loss             | 0.03398513    |
| qf1_loss                | 4.9613203e-07 |
| qf2_loss                | 5.239376e-07  |
| time_elapsed            | 548           |
| total timesteps         | 117100        |
| value_loss              | 6.530053e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.857118      |
| ep_rewmean              | -0.233        |
| episodes                | 1176          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 117469        |
| policy_loss             | 0.030892383   |
| qf1_loss                | 3.9476893e-07 |
| qf2_loss                | 5.0862945e-07 |
| time_elapsed            | 550           |
| total timesteps         | 117500        |
| value_loss              | 6.279672e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6713266     |
| ep_rewmean              | -0.231        |
| episodes                | 1180          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 117869        |
| policy_loss             | 0.028360706   |
| qf1_loss                | 4.1966092e-07 |
| qf2_loss                | 2.5250034e-07 |
| time_elapsed            | 552           |
| total timesteps         | 117900        |
| value_loss              | 9.316596e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7135954     |
| ep_rewmean              | -0.228        |
| episodes                | 1184          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 118269        |
| policy_loss             | 0.033583      |
| qf1_loss                | 1.7887871e-06 |
| qf2_loss                | 1.5241494e-06 |
| time_elapsed            | 554           |
| total timesteps         | 118300        |
| value_loss              | 2.805672e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.658141      |
| ep_rewmean              | -0.227        |
| episodes                | 1188          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 118669        |
| policy_loss             | 0.028589468   |
| qf1_loss                | 5.1466503e-07 |
| qf2_loss                | 6.784662e-07  |
| time_elapsed            | 556           |
| total timesteps         | 118700        |
| value_loss              | 9.709876e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7293625     |
| ep_rewmean              | -0.229        |
| episodes                | 1192          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 119069        |
| policy_loss             | 0.03497123    |
| qf1_loss                | 3.5434991e-06 |
| qf2_loss                | 2.3818268e-06 |
| time_elapsed            | 557           |
| total timesteps         | 119100        |
| value_loss              | 2.1665735e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.636502      |
| ep_rewmean              | -0.231        |
| episodes                | 1196          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 119469        |
| policy_loss             | 0.039091017   |
| qf1_loss                | 1.1420703e-05 |
| qf2_loss                | 1.3016504e-05 |
| time_elapsed            | 559           |
| total timesteps         | 119500        |
| value_loss              | 1.8126733e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5040855     |
| ep_rewmean              | -0.232        |
| episodes                | 1200          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 119869        |
| policy_loss             | 0.038538978   |
| qf1_loss                | 1.2839503e-05 |
| qf2_loss                | 1.2686347e-05 |
| time_elapsed            | 561           |
| total timesteps         | 119900        |
| value_loss              | 1.8271865e-06 |
-------------------------------------------
Eval num_timesteps=120000, episode_reward=-0.26 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.706889      |
| ep_rewmean              | -0.231        |
| episodes                | 1204          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 120269        |
| policy_loss             | 0.035719182   |
| qf1_loss                | 1.9722012e-05 |
| qf2_loss                | 1.5651796e-05 |
| time_elapsed            | 563           |
| total timesteps         | 120300        |
| value_loss              | 1.247257e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7037926     |
| ep_rewmean              | -0.234        |
| episodes                | 1208          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 120669        |
| policy_loss             | 0.03304722    |
| qf1_loss                | 1.5672599e-06 |
| qf2_loss                | 1.8377915e-06 |
| time_elapsed            | 565           |
| total timesteps         | 120700        |
| value_loss              | 3.738493e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.477589      |
| ep_rewmean              | -0.234        |
| episodes                | 1212          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 121069        |
| policy_loss             | 0.034063563   |
| qf1_loss                | 5.4512225e-06 |
| qf2_loss                | 6.471335e-06  |
| time_elapsed            | 567           |
| total timesteps         | 121100        |
| value_loss              | 1.1343856e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.950476      |
| ep_rewmean              | -0.243        |
| episodes                | 1216          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 121469        |
| policy_loss             | 0.036525223   |
| qf1_loss                | 2.0333744e-06 |
| qf2_loss                | 5.3044114e-06 |
| time_elapsed            | 569           |
| total timesteps         | 121500        |
| value_loss              | 5.207641e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2871323     |
| ep_rewmean              | -0.248        |
| episodes                | 1220          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.2          |
| n_updates               | 121869        |
| policy_loss             | 0.030965589   |
| qf1_loss                | 4.257405e-07  |
| qf2_loss                | 3.2622015e-07 |
| time_elapsed            | 571           |
| total timesteps         | 121900        |
| value_loss              | 1.2984876e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8941045     |
| ep_rewmean              | -0.254        |
| episodes                | 1224          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 122269        |
| policy_loss             | 0.038162436   |
| qf1_loss                | 1.1167048e-06 |
| qf2_loss                | 7.6300745e-07 |
| time_elapsed            | 572           |
| total timesteps         | 122300        |
| value_loss              | 6.731366e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.0652056     |
| ep_rewmean              | -0.256        |
| episodes                | 1228          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 122669        |
| policy_loss             | 0.033975124   |
| qf1_loss                | 1.4585696e-05 |
| qf2_loss                | 1.4354389e-05 |
| time_elapsed            | 574           |
| total timesteps         | 122700        |
| value_loss              | 2.8418035e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.113348      |
| ep_rewmean              | -0.263        |
| episodes                | 1232          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 123069        |
| policy_loss             | 0.036342964   |
| qf1_loss                | 2.3236591e-06 |
| qf2_loss                | 1.919587e-06  |
| time_elapsed            | 576           |
| total timesteps         | 123100        |
| value_loss              | 1.0145824e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.004298      |
| ep_rewmean              | -0.271        |
| episodes                | 1236          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 123469        |
| policy_loss             | 0.036593556   |
| qf1_loss                | 8.42188e-07   |
| qf2_loss                | 6.0589986e-07 |
| time_elapsed            | 578           |
| total timesteps         | 123500        |
| value_loss              | 6.6471375e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.057458      |
| ep_rewmean              | -0.287        |
| episodes                | 1240          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 123869        |
| policy_loss             | 0.03479178    |
| qf1_loss                | 3.191039e-05  |
| qf2_loss                | 3.446403e-05  |
| time_elapsed            | 580           |
| total timesteps         | 123900        |
| value_loss              | 4.4465733e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8179374     |
| ep_rewmean              | -0.3          |
| episodes                | 1244          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 124269        |
| policy_loss             | 0.035135876   |
| qf1_loss                | 7.801403e-06  |
| qf2_loss                | 3.156762e-06  |
| time_elapsed            | 582           |
| total timesteps         | 124300        |
| value_loss              | 1.5763653e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6331606     |
| ep_rewmean              | -0.31         |
| episodes                | 1248          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 124669        |
| policy_loss             | 0.030622073   |
| qf1_loss                | 1.1288504e-06 |
| qf2_loss                | 1.5120609e-06 |
| time_elapsed            | 583           |
| total timesteps         | 124700        |
| value_loss              | 1.0955451e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.834547      |
| ep_rewmean              | -0.314        |
| episodes                | 1252          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 125069        |
| policy_loss             | 0.03568507    |
| qf1_loss                | 1.2969422e-06 |
| qf2_loss                | 1.4885718e-06 |
| time_elapsed            | 585           |
| total timesteps         | 125100        |
| value_loss              | 4.983092e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9171104     |
| ep_rewmean              | -0.32         |
| episodes                | 1256          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 125469        |
| policy_loss             | 0.031381838   |
| qf1_loss                | 1.2595686e-05 |
| qf2_loss                | 1.2668165e-05 |
| time_elapsed            | 587           |
| total timesteps         | 125500        |
| value_loss              | 8.246036e-07  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 6.6652484      |
| ep_rewmean              | -0.324         |
| episodes                | 1260           |
| eplenmean               | 100            |
| fps                     | 213            |
| mean 100 episode reward | -0.3           |
| n_updates               | 125869         |
| policy_loss             | 0.033207193    |
| qf1_loss                | 1.49754915e-05 |
| qf2_loss                | 1.5101023e-05  |
| time_elapsed            | 589            |
| total timesteps         | 125900         |
| value_loss              | 2.2684226e-06  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.912517      |
| ep_rewmean              | -0.324        |
| episodes                | 1264          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 126269        |
| policy_loss             | 0.03547152    |
| qf1_loss                | 3.5106814e-06 |
| qf2_loss                | 1.5016503e-06 |
| time_elapsed            | 591           |
| total timesteps         | 126300        |
| value_loss              | 2.6295324e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9106092     |
| ep_rewmean              | -0.33         |
| episodes                | 1268          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 126669        |
| policy_loss             | 0.03751164    |
| qf1_loss                | 3.101969e-05  |
| qf2_loss                | 2.7811502e-05 |
| time_elapsed            | 592           |
| total timesteps         | 126700        |
| value_loss              | 1.5886334e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9328036     |
| ep_rewmean              | -0.329        |
| episodes                | 1272          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 127069        |
| policy_loss             | 0.035152573   |
| qf1_loss                | 1.086494e-06  |
| qf2_loss                | 6.1992273e-07 |
| time_elapsed            | 594           |
| total timesteps         | 127100        |
| value_loss              | 1.7183081e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.690989      |
| ep_rewmean              | -0.332        |
| episodes                | 1276          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 127469        |
| policy_loss             | 0.03580737    |
| qf1_loss                | 1.5413389e-05 |
| qf2_loss                | 1.4946268e-05 |
| time_elapsed            | 596           |
| total timesteps         | 127500        |
| value_loss              | 1.8677574e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.757821      |
| ep_rewmean              | -0.335        |
| episodes                | 1280          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 127869        |
| policy_loss             | 0.03496361    |
| qf1_loss                | 3.1058436e-05 |
| qf2_loss                | 3.2201744e-05 |
| time_elapsed            | 598           |
| total timesteps         | 127900        |
| value_loss              | 1.170792e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.810151      |
| ep_rewmean              | -0.345        |
| episodes                | 1284          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 128269        |
| policy_loss             | 0.036533073   |
| qf1_loss                | 9.966434e-07  |
| qf2_loss                | 8.6267886e-07 |
| time_elapsed            | 599           |
| total timesteps         | 128300        |
| value_loss              | 1.5694546e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.034541      |
| ep_rewmean              | -0.348        |
| episodes                | 1288          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 128669        |
| policy_loss             | 0.034221344   |
| qf1_loss                | 6.3500765e-06 |
| qf2_loss                | 1.3213957e-05 |
| time_elapsed            | 601           |
| total timesteps         | 128700        |
| value_loss              | 3.7594898e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.492861      |
| ep_rewmean              | -0.349        |
| episodes                | 1292          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 129069        |
| policy_loss             | 0.03539987    |
| qf1_loss                | 4.9363894e-07 |
| qf2_loss                | 3.0447347e-07 |
| time_elapsed            | 603           |
| total timesteps         | 129100        |
| value_loss              | 8.508801e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.504719      |
| ep_rewmean              | -0.349        |
| episodes                | 1296          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 129469        |
| policy_loss             | 0.0392266     |
| qf1_loss                | 2.7284133e-07 |
| qf2_loss                | 9.222859e-07  |
| time_elapsed            | 605           |
| total timesteps         | 129500        |
| value_loss              | 1.7477164e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.545193      |
| ep_rewmean              | -0.347        |
| episodes                | 1300          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 129869        |
| policy_loss             | 0.034023173   |
| qf1_loss                | 7.4844127e-07 |
| qf2_loss                | 9.57039e-07   |
| time_elapsed            | 607           |
| total timesteps         | 129900        |
| value_loss              | 1.426666e-06  |
-------------------------------------------
Eval num_timesteps=130000, episode_reward=-0.16 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 6.619278     |
| ep_rewmean              | -0.347       |
| episodes                | 1304         |
| eplenmean               | 100          |
| fps                     | 213          |
| mean 100 episode reward | -0.3         |
| n_updates               | 130269       |
| policy_loss             | 0.033439644  |
| qf1_loss                | 2.508254e-07 |
| qf2_loss                | 1.148362e-06 |
| time_elapsed            | 609          |
| total timesteps         | 130300       |
| value_loss              | 5.742521e-07 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9357796     |
| ep_rewmean              | -0.348        |
| episodes                | 1308          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 130669        |
| policy_loss             | 0.033259436   |
| qf1_loss                | 1.3331302e-06 |
| qf2_loss                | 1.6562999e-06 |
| time_elapsed            | 610           |
| total timesteps         | 130700        |
| value_loss              | 2.764527e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.724845      |
| ep_rewmean              | -0.35         |
| episodes                | 1312          |
| eplenmean               | 100           |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 131069        |
| policy_loss             | 0.04025955    |
| qf1_loss                | 1.618553e-05  |
| qf2_loss                | 1.7093154e-05 |
| time_elapsed            | 612           |
| total timesteps         | 131100        |
| value_loss              | 2.8231034e-06 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 6.550358     |
| ep_rewmean              | -0.342       |
| episodes                | 1316         |
| eplenmean               | 100          |
| fps                     | 213          |
| mean 100 episode reward | -0.3         |
| n_updates               | 131465       |
| policy_loss             | 0.036178187  |
| qf1_loss                | 6.760059e-07 |
| qf2_loss                | 4.000208e-07 |
| time_elapsed            | 614          |
| total timesteps         | 131496       |
| value_loss              | 1.316096e-06 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.605628      |
| ep_rewmean              | -0.34         |
| episodes                | 1320          |
| eplenmean               | 99.9          |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 131863        |
| policy_loss             | 0.03651304    |
| qf1_loss                | 2.2646739e-07 |
| qf2_loss                | 3.2110168e-07 |
| time_elapsed            | 616           |
| total timesteps         | 131894        |
| value_loss              | 8.078975e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.402249      |
| ep_rewmean              | -0.333        |
| episodes                | 1324          |
| eplenmean               | 99.9          |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 132263        |
| policy_loss             | 0.03649985    |
| qf1_loss                | 1.7654054e-05 |
| qf2_loss                | 1.8481302e-05 |
| time_elapsed            | 618           |
| total timesteps         | 132294        |
| value_loss              | 1.0220136e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.015192      |
| ep_rewmean              | -0.329        |
| episodes                | 1328          |
| eplenmean               | 99.9          |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 132663        |
| policy_loss             | 0.036280565   |
| qf1_loss                | 1.1927889e-06 |
| qf2_loss                | 3.5431438e-07 |
| time_elapsed            | 620           |
| total timesteps         | 132694        |
| value_loss              | 3.0221001e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.386208      |
| ep_rewmean              | -0.32         |
| episodes                | 1332          |
| eplenmean               | 99.9          |
| fps                     | 213           |
| mean 100 episode reward | -0.3          |
| n_updates               | 133063        |
| policy_loss             | 0.036072966   |
| qf1_loss                | 4.2745458e-07 |
| qf2_loss                | 1.0492398e-06 |
| time_elapsed            | 621           |
| total timesteps         | 133094        |
| value_loss              | 2.737853e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.2771196     |
| ep_rewmean              | -0.311        |
| episodes                | 1336          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.3          |
| n_updates               | 133463        |
| policy_loss             | 0.035648882   |
| qf1_loss                | 2.3126303e-07 |
| qf2_loss                | 1.1502345e-06 |
| time_elapsed            | 623           |
| total timesteps         | 133494        |
| value_loss              | 1.6842314e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.077737      |
| ep_rewmean              | -0.292        |
| episodes                | 1340          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.3          |
| n_updates               | 133863        |
| policy_loss             | 0.034506757   |
| qf1_loss                | 1.3394358e-06 |
| qf2_loss                | 1.9397232e-06 |
| time_elapsed            | 625           |
| total timesteps         | 133894        |
| value_loss              | 3.703722e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.021263      |
| ep_rewmean              | -0.278        |
| episodes                | 1344          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.3          |
| n_updates               | 134263        |
| policy_loss             | 0.04320489    |
| qf1_loss                | 1.3743951e-06 |
| qf2_loss                | 1.5457226e-06 |
| time_elapsed            | 627           |
| total timesteps         | 134294        |
| value_loss              | 3.018899e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.233428      |
| ep_rewmean              | -0.264        |
| episodes                | 1348          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.3          |
| n_updates               | 134663        |
| policy_loss             | 0.03700635    |
| qf1_loss                | 1.7417435e-05 |
| qf2_loss                | 1.7356308e-05 |
| time_elapsed            | 629           |
| total timesteps         | 134694        |
| value_loss              | 2.403648e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.889928      |
| ep_rewmean              | -0.259        |
| episodes                | 1352          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.3          |
| n_updates               | 135063        |
| policy_loss             | 0.035165623   |
| qf1_loss                | 1.8266078e-07 |
| qf2_loss                | 5.1735674e-07 |
| time_elapsed            | 630           |
| total timesteps         | 135094        |
| value_loss              | 2.4568856e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5258346     |
| ep_rewmean              | -0.251        |
| episodes                | 1356          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.3          |
| n_updates               | 135463        |
| policy_loss             | 0.03498535    |
| qf1_loss                | 1.6553662e-05 |
| qf2_loss                | 1.7104949e-05 |
| time_elapsed            | 632           |
| total timesteps         | 135494        |
| value_loss              | 1.8887799e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.3865776     |
| ep_rewmean              | -0.245        |
| episodes                | 1360          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 135863        |
| policy_loss             | 0.040682964   |
| qf1_loss                | 1.7291733e-05 |
| qf2_loss                | 1.7594422e-05 |
| time_elapsed            | 634           |
| total timesteps         | 135894        |
| value_loss              | 1.2557636e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.634012      |
| ep_rewmean              | -0.243        |
| episodes                | 1364          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 136263        |
| policy_loss             | 0.03283643    |
| qf1_loss                | 5.2326214e-07 |
| qf2_loss                | 7.6423214e-07 |
| time_elapsed            | 636           |
| total timesteps         | 136294        |
| value_loss              | 1.1382422e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.646063      |
| ep_rewmean              | -0.235        |
| episodes                | 1368          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 136663        |
| policy_loss             | 0.040058438   |
| qf1_loss                | 1.7103519e-05 |
| qf2_loss                | 1.6311778e-05 |
| time_elapsed            | 638           |
| total timesteps         | 136694        |
| value_loss              | 1.6488311e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5874104     |
| ep_rewmean              | -0.229        |
| episodes                | 1372          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 137063        |
| policy_loss             | 0.038789727   |
| qf1_loss                | 1.3077599e-07 |
| qf2_loss                | 1.4343563e-07 |
| time_elapsed            | 639           |
| total timesteps         | 137094        |
| value_loss              | 1.9445008e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.556138      |
| ep_rewmean              | -0.224        |
| episodes                | 1376          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 137463        |
| policy_loss             | 0.034032144   |
| qf1_loss                | 7.853526e-07  |
| qf2_loss                | 1.1018824e-06 |
| time_elapsed            | 641           |
| total timesteps         | 137494        |
| value_loss              | 9.398337e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.759227      |
| ep_rewmean              | -0.217        |
| episodes                | 1380          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 137863        |
| policy_loss             | 0.036104754   |
| qf1_loss                | 1.2323258e-06 |
| qf2_loss                | 2.3252546e-06 |
| time_elapsed            | 643           |
| total timesteps         | 137894        |
| value_loss              | 1.45993e-06   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9721317     |
| ep_rewmean              | -0.205        |
| episodes                | 1384          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 138263        |
| policy_loss             | 0.036084022   |
| qf1_loss                | 1.5327125e-06 |
| qf2_loss                | 1.834303e-06  |
| time_elapsed            | 645           |
| total timesteps         | 138294        |
| value_loss              | 3.518313e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7553096     |
| ep_rewmean              | -0.2          |
| episodes                | 1388          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 138663        |
| policy_loss             | 0.03522235    |
| qf1_loss                | 7.007649e-07  |
| qf2_loss                | 6.4139635e-07 |
| time_elapsed            | 647           |
| total timesteps         | 138694        |
| value_loss              | 2.8120871e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.882091      |
| ep_rewmean              | -0.194        |
| episodes                | 1392          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 139063        |
| policy_loss             | 0.031138169   |
| qf1_loss                | 8.8831877e-07 |
| qf2_loss                | 8.971549e-07  |
| time_elapsed            | 648           |
| total timesteps         | 139094        |
| value_loss              | 1.1467159e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6708126     |
| ep_rewmean              | -0.191        |
| episodes                | 1396          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 139463        |
| policy_loss             | 0.03472914    |
| qf1_loss                | 2.5974265e-07 |
| qf2_loss                | 5.577155e-07  |
| time_elapsed            | 650           |
| total timesteps         | 139494        |
| value_loss              | 2.8471154e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.799584      |
| ep_rewmean              | -0.187        |
| episodes                | 1400          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 139863        |
| policy_loss             | 0.033239394   |
| qf1_loss                | 1.5960852e-05 |
| qf2_loss                | 1.6469223e-05 |
| time_elapsed            | 652           |
| total timesteps         | 139894        |
| value_loss              | 2.456048e-06  |
-------------------------------------------
Eval num_timesteps=140000, episode_reward=-0.15 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6736507     |
| ep_rewmean              | -0.186        |
| episodes                | 1404          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 140263        |
| policy_loss             | 0.034085713   |
| qf1_loss                | 3.0217776e-05 |
| qf2_loss                | 3.052425e-05  |
| time_elapsed            | 654           |
| total timesteps         | 140294        |
| value_loss              | 1.4006323e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8797007     |
| ep_rewmean              | -0.18         |
| episodes                | 1408          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 140663        |
| policy_loss             | 0.032671392   |
| qf1_loss                | 2.9635953e-07 |
| qf2_loss                | 2.8094573e-07 |
| time_elapsed            | 656           |
| total timesteps         | 140694        |
| value_loss              | 3.2820474e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7398653     |
| ep_rewmean              | -0.178        |
| episodes                | 1412          |
| eplenmean               | 99.9          |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 141063        |
| policy_loss             | 0.03463228    |
| qf1_loss                | 4.8624406e-07 |
| qf2_loss                | 3.5634935e-07 |
| time_elapsed            | 658           |
| total timesteps         | 141094        |
| value_loss              | 2.2036807e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8313036     |
| ep_rewmean              | -0.175        |
| episodes                | 1416          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 141463        |
| policy_loss             | 0.031962916   |
| qf1_loss                | 1.519055e-05  |
| qf2_loss                | 1.6041848e-05 |
| time_elapsed            | 660           |
| total timesteps         | 141494        |
| value_loss              | 4.3862433e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9801106     |
| ep_rewmean              | -0.17         |
| episodes                | 1420          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 141863        |
| policy_loss             | 0.031616207   |
| qf1_loss                | 5.876427e-07  |
| qf2_loss                | 1.065448e-06  |
| time_elapsed            | 662           |
| total timesteps         | 141894        |
| value_loss              | 1.4075348e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1210766     |
| ep_rewmean              | -0.169        |
| episodes                | 1424          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 142263        |
| policy_loss             | 0.032363627   |
| qf1_loss                | 1.0786524e-06 |
| qf2_loss                | 5.7326133e-07 |
| time_elapsed            | 663           |
| total timesteps         | 142294        |
| value_loss              | 1.8967789e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0878725     |
| ep_rewmean              | -0.167        |
| episodes                | 1428          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 142663        |
| policy_loss             | 0.039189354   |
| qf1_loss                | 2.9530569e-05 |
| qf2_loss                | 2.8535454e-05 |
| time_elapsed            | 665           |
| total timesteps         | 142694        |
| value_loss              | 2.5570705e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.56804       |
| ep_rewmean              | -0.167        |
| episodes                | 1432          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 143063        |
| policy_loss             | 0.039189823   |
| qf1_loss                | 5.9080423e-07 |
| qf2_loss                | 8.626016e-07  |
| time_elapsed            | 667           |
| total timesteps         | 143094        |
| value_loss              | 3.9230104e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8263197     |
| ep_rewmean              | -0.166        |
| episodes                | 1436          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 143463        |
| policy_loss             | 0.031700015   |
| qf1_loss                | 1.4732078e-05 |
| qf2_loss                | 1.439773e-05  |
| time_elapsed            | 669           |
| total timesteps         | 143494        |
| value_loss              | 6.915851e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8484464     |
| ep_rewmean              | -0.167        |
| episodes                | 1440          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 143863        |
| policy_loss             | 0.03466122    |
| qf1_loss                | 3.884918e-07  |
| qf2_loss                | 5.690573e-07  |
| time_elapsed            | 671           |
| total timesteps         | 143894        |
| value_loss              | 3.1069071e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.066198      |
| ep_rewmean              | -0.166        |
| episodes                | 1444          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 144263        |
| policy_loss             | 0.035481475   |
| qf1_loss                | 1.4450647e-05 |
| qf2_loss                | 1.6908158e-05 |
| time_elapsed            | 672           |
| total timesteps         | 144294        |
| value_loss              | 5.506003e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.079028      |
| ep_rewmean              | -0.166        |
| episodes                | 1448          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 144663        |
| policy_loss             | 0.032033417   |
| qf1_loss                | 1.2420944e-07 |
| qf2_loss                | 2.1448108e-07 |
| time_elapsed            | 674           |
| total timesteps         | 144694        |
| value_loss              | 1.5411749e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0187554     |
| ep_rewmean              | -0.166        |
| episodes                | 1452          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 145063        |
| policy_loss             | 0.03283362    |
| qf1_loss                | 2.6467683e-07 |
| qf2_loss                | 9.723544e-07  |
| time_elapsed            | 676           |
| total timesteps         | 145094        |
| value_loss              | 4.5006964e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.020327      |
| ep_rewmean              | -0.166        |
| episodes                | 1456          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 145463        |
| policy_loss             | 0.031724192   |
| qf1_loss                | 2.3520815e-07 |
| qf2_loss                | 1.8357258e-07 |
| time_elapsed            | 678           |
| total timesteps         | 145494        |
| value_loss              | 9.457652e-07  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 6.9040003      |
| ep_rewmean              | -0.166         |
| episodes                | 1460           |
| eplenmean               | 100            |
| fps                     | 214            |
| mean 100 episode reward | -0.2           |
| n_updates               | 145863         |
| policy_loss             | 0.03421796     |
| qf1_loss                | 1.16017844e-07 |
| qf2_loss                | 3.6844034e-07  |
| time_elapsed            | 680            |
| total timesteps         | 145894         |
| value_loss              | 2.9063117e-06  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.086589      |
| ep_rewmean              | -0.166        |
| episodes                | 1464          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 146263        |
| policy_loss             | 0.032242984   |
| qf1_loss                | 1.2995929e-07 |
| qf2_loss                | 1.5489886e-07 |
| time_elapsed            | 681           |
| total timesteps         | 146294        |
| value_loss              | 2.0416537e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.933986      |
| ep_rewmean              | -0.166        |
| episodes                | 1468          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 146663        |
| policy_loss             | 0.03111865    |
| qf1_loss                | 2.7366826e-07 |
| qf2_loss                | 2.5061397e-07 |
| time_elapsed            | 683           |
| total timesteps         | 146694        |
| value_loss              | 1.9265801e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0858374     |
| ep_rewmean              | -0.169        |
| episodes                | 1472          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 147063        |
| policy_loss             | 0.032318644   |
| qf1_loss                | 2.860451e-07  |
| qf2_loss                | 4.04162e-07   |
| time_elapsed            | 685           |
| total timesteps         | 147094        |
| value_loss              | 1.6594067e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0068135     |
| ep_rewmean              | -0.169        |
| episodes                | 1476          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 147463        |
| policy_loss             | 0.033659637   |
| qf1_loss                | 1.4002036e-05 |
| qf2_loss                | 1.3644677e-05 |
| time_elapsed            | 687           |
| total timesteps         | 147494        |
| value_loss              | 1.969078e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.3245316     |
| ep_rewmean              | -0.171        |
| episodes                | 1480          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 147863        |
| policy_loss             | 0.033244643   |
| qf1_loss                | 2.1773046e-07 |
| qf2_loss                | 2.7547395e-07 |
| time_elapsed            | 688           |
| total timesteps         | 147894        |
| value_loss              | 1.319395e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0222874     |
| ep_rewmean              | -0.172        |
| episodes                | 1484          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 148263        |
| policy_loss             | 0.03173887    |
| qf1_loss                | 2.6534207e-07 |
| qf2_loss                | 1.5428472e-07 |
| time_elapsed            | 690           |
| total timesteps         | 148294        |
| value_loss              | 8.3926966e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2029915     |
| ep_rewmean              | -0.174        |
| episodes                | 1488          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 148663        |
| policy_loss             | 0.03294407    |
| qf1_loss                | 2.923742e-07  |
| qf2_loss                | 1.6159943e-07 |
| time_elapsed            | 692           |
| total timesteps         | 148694        |
| value_loss              | 1.2830869e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2007914     |
| ep_rewmean              | -0.176        |
| episodes                | 1492          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 149063        |
| policy_loss             | 0.032365937   |
| qf1_loss                | 1.2370415e-07 |
| qf2_loss                | 1.7441792e-07 |
| time_elapsed            | 694           |
| total timesteps         | 149094        |
| value_loss              | 9.565604e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9971895     |
| ep_rewmean              | -0.177        |
| episodes                | 1496          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 149463        |
| policy_loss             | 0.033747695   |
| qf1_loss                | 1.2819821e-05 |
| qf2_loss                | 1.2567601e-05 |
| time_elapsed            | 696           |
| total timesteps         | 149494        |
| value_loss              | 8.099855e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0593657     |
| ep_rewmean              | -0.178        |
| episodes                | 1500          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 149863        |
| policy_loss             | 0.029852074   |
| qf1_loss                | 1.3798766e-05 |
| qf2_loss                | 1.3562955e-05 |
| time_elapsed            | 697           |
| total timesteps         | 149894        |
| value_loss              | 1.8581584e-06 |
-------------------------------------------
Eval num_timesteps=150000, episode_reward=-0.18 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0074663     |
| ep_rewmean              | -0.179        |
| episodes                | 1504          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 150263        |
| policy_loss             | 0.03363496    |
| qf1_loss                | 4.2126013e-07 |
| qf2_loss                | 9.174268e-07  |
| time_elapsed            | 699           |
| total timesteps         | 150294        |
| value_loss              | 2.656576e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.220381      |
| ep_rewmean              | -0.181        |
| episodes                | 1508          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 150663        |
| policy_loss             | 0.030165812   |
| qf1_loss                | 6.9761154e-07 |
| qf2_loss                | 1.1174968e-06 |
| time_elapsed            | 701           |
| total timesteps         | 150694        |
| value_loss              | 1.5392176e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.159571      |
| ep_rewmean              | -0.18         |
| episodes                | 1512          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 151063        |
| policy_loss             | 0.03159578    |
| qf1_loss                | 3.1492397e-07 |
| qf2_loss                | 4.2362447e-07 |
| time_elapsed            | 703           |
| total timesteps         | 151094        |
| value_loss              | 1.5156851e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9025693     |
| ep_rewmean              | -0.181        |
| episodes                | 1516          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 151463        |
| policy_loss             | 0.032938577   |
| qf1_loss                | 2.8420225e-05 |
| qf2_loss                | 2.8385597e-05 |
| time_elapsed            | 705           |
| total timesteps         | 151494        |
| value_loss              | 2.1337141e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.974948      |
| ep_rewmean              | -0.183        |
| episodes                | 1520          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 151863        |
| policy_loss             | 0.032827795   |
| qf1_loss                | 4.8354855e-07 |
| qf2_loss                | 6.1366615e-07 |
| time_elapsed            | 707           |
| total timesteps         | 151894        |
| value_loss              | 2.9839657e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.051467      |
| ep_rewmean              | -0.184        |
| episodes                | 1524          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 152263        |
| policy_loss             | 0.029235188   |
| qf1_loss                | 1.2560358e-05 |
| qf2_loss                | 1.2861636e-05 |
| time_elapsed            | 709           |
| total timesteps         | 152294        |
| value_loss              | 1.0795247e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.847503      |
| ep_rewmean              | -0.185        |
| episodes                | 1528          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 152663        |
| policy_loss             | 0.040720295   |
| qf1_loss                | 2.0138492e-07 |
| qf2_loss                | 3.8819294e-07 |
| time_elapsed            | 710           |
| total timesteps         | 152694        |
| value_loss              | 1.0227524e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1112757     |
| ep_rewmean              | -0.185        |
| episodes                | 1532          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 153063        |
| policy_loss             | 0.03327541    |
| qf1_loss                | 5.2788986e-05 |
| qf2_loss                | 5.3234773e-05 |
| time_elapsed            | 712           |
| total timesteps         | 153094        |
| value_loss              | 3.972327e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8364153     |
| ep_rewmean              | -0.185        |
| episodes                | 1536          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 153463        |
| policy_loss             | 0.03203335    |
| qf1_loss                | 2.4311453e-07 |
| qf2_loss                | 3.4869635e-07 |
| time_elapsed            | 714           |
| total timesteps         | 153494        |
| value_loss              | 2.3233858e-06 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 7.2320013      |
| ep_rewmean              | -0.185         |
| episodes                | 1540           |
| eplenmean               | 100            |
| fps                     | 214            |
| mean 100 episode reward | -0.2           |
| n_updates               | 153863         |
| policy_loss             | 0.03201527     |
| qf1_loss                | 1.23185555e-05 |
| qf2_loss                | 1.1902883e-05  |
| time_elapsed            | 716            |
| total timesteps         | 153894         |
| value_loss              | 1.4298633e-06  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0667706     |
| ep_rewmean              | -0.186        |
| episodes                | 1544          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 154263        |
| policy_loss             | 0.02992323    |
| qf1_loss                | 6.3043706e-07 |
| qf2_loss                | 7.7143255e-07 |
| time_elapsed            | 718           |
| total timesteps         | 154294        |
| value_loss              | 2.2185263e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2704067     |
| ep_rewmean              | -0.186        |
| episodes                | 1548          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 154663        |
| policy_loss             | 0.029505147   |
| qf1_loss                | 1.2075331e-05 |
| qf2_loss                | 1.2624545e-05 |
| time_elapsed            | 719           |
| total timesteps         | 154694        |
| value_loss              | 1.4806587e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.107809      |
| ep_rewmean              | -0.186        |
| episodes                | 1552          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 155063        |
| policy_loss             | 0.028900646   |
| qf1_loss                | 2.5137357e-08 |
| qf2_loss                | 2.4922906e-07 |
| time_elapsed            | 721           |
| total timesteps         | 155094        |
| value_loss              | 2.789403e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.966673      |
| ep_rewmean              | -0.187        |
| episodes                | 1556          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 155463        |
| policy_loss             | 0.032475956   |
| qf1_loss                | 1.071613e-06  |
| qf2_loss                | 9.239578e-07  |
| time_elapsed            | 723           |
| total timesteps         | 155494        |
| value_loss              | 2.5225615e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.088392      |
| ep_rewmean              | -0.187        |
| episodes                | 1560          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 155863        |
| policy_loss             | 0.030104501   |
| qf1_loss                | 1.3129973e-05 |
| qf2_loss                | 1.3268412e-05 |
| time_elapsed            | 725           |
| total timesteps         | 155894        |
| value_loss              | 2.7163392e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2816887     |
| ep_rewmean              | -0.186        |
| episodes                | 1564          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 156263        |
| policy_loss             | 0.03024564    |
| qf1_loss                | 4.2774306e-07 |
| qf2_loss                | 1.4153916e-07 |
| time_elapsed            | 727           |
| total timesteps         | 156294        |
| value_loss              | 7.131499e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0778913     |
| ep_rewmean              | -0.186        |
| episodes                | 1568          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 156663        |
| policy_loss             | 0.031255808   |
| qf1_loss                | 2.0031907e-06 |
| qf2_loss                | 1.9175372e-06 |
| time_elapsed            | 729           |
| total timesteps         | 156694        |
| value_loss              | 1.7391944e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.178482      |
| ep_rewmean              | -0.184        |
| episodes                | 1572          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 157063        |
| policy_loss             | 0.034194753   |
| qf1_loss                | 1.1921147e-06 |
| qf2_loss                | 9.096516e-07  |
| time_elapsed            | 730           |
| total timesteps         | 157094        |
| value_loss              | 4.433609e-06  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 7.1242895      |
| ep_rewmean              | -0.188         |
| episodes                | 1576           |
| eplenmean               | 100            |
| fps                     | 214            |
| mean 100 episode reward | -0.2           |
| n_updates               | 157463         |
| policy_loss             | 0.03127866     |
| qf1_loss                | 1.03179005e-07 |
| qf2_loss                | 2.0345959e-07  |
| time_elapsed            | 732            |
| total timesteps         | 157494         |
| value_loss              | 1.5874945e-06  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2356586     |
| ep_rewmean              | -0.187        |
| episodes                | 1580          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 157863        |
| policy_loss             | 0.031376146   |
| qf1_loss                | 1.2672217e-07 |
| qf2_loss                | 2.116044e-07  |
| time_elapsed            | 734           |
| total timesteps         | 157894        |
| value_loss              | 1.0281549e-06 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 7.0433116    |
| ep_rewmean              | -0.187       |
| episodes                | 1584         |
| eplenmean               | 100          |
| fps                     | 214          |
| mean 100 episode reward | -0.2         |
| n_updates               | 158263       |
| policy_loss             | 0.028429508  |
| qf1_loss                | 3.066213e-07 |
| qf2_loss                | 1.54329e-07  |
| time_elapsed            | 736          |
| total timesteps         | 158294       |
| value_loss              | 7.61405e-07  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.015581      |
| ep_rewmean              | -0.185        |
| episodes                | 1588          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 158663        |
| policy_loss             | 0.0333681     |
| qf1_loss                | 1.2617549e-05 |
| qf2_loss                | 1.2518674e-05 |
| time_elapsed            | 738           |
| total timesteps         | 158694        |
| value_loss              | 1.8353405e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.13245       |
| ep_rewmean              | -0.185        |
| episodes                | 1592          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 159063        |
| policy_loss             | 0.03379738    |
| qf1_loss                | 8.58998e-08   |
| qf2_loss                | 2.3565946e-07 |
| time_elapsed            | 740           |
| total timesteps         | 159094        |
| value_loss              | 3.1216396e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.990266      |
| ep_rewmean              | -0.186        |
| episodes                | 1596          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 159463        |
| policy_loss             | 0.029279169   |
| qf1_loss                | 1.0836723e-06 |
| qf2_loss                | 4.07809e-07   |
| time_elapsed            | 741           |
| total timesteps         | 159494        |
| value_loss              | 1.2134809e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1440053     |
| ep_rewmean              | -0.186        |
| episodes                | 1600          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 159863        |
| policy_loss             | 0.030223705   |
| qf1_loss                | 4.6607295e-07 |
| qf2_loss                | 2.867144e-07  |
| time_elapsed            | 743           |
| total timesteps         | 159894        |
| value_loss              | 1.8466889e-06 |
-------------------------------------------
Eval num_timesteps=160000, episode_reward=-0.15 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0311575     |
| ep_rewmean              | -0.19         |
| episodes                | 1604          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 160263        |
| policy_loss             | 0.028867813   |
| qf1_loss                | 2.2997268e-07 |
| qf2_loss                | 6.768696e-07  |
| time_elapsed            | 745           |
| total timesteps         | 160294        |
| value_loss              | 2.3477767e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2409344     |
| ep_rewmean              | -0.189        |
| episodes                | 1608          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 160663        |
| policy_loss             | 0.03087667    |
| qf1_loss                | 1.8190909e-07 |
| qf2_loss                | 3.3960526e-07 |
| time_elapsed            | 747           |
| total timesteps         | 160694        |
| value_loss              | 1.8577111e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.730814      |
| ep_rewmean              | -0.189        |
| episodes                | 1612          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 161063        |
| policy_loss             | 0.029622924   |
| qf1_loss                | 1.9145914e-07 |
| qf2_loss                | 3.41583e-07   |
| time_elapsed            | 749           |
| total timesteps         | 161094        |
| value_loss              | 2.3714401e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.077409      |
| ep_rewmean              | -0.187        |
| episodes                | 1616          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 161463        |
| policy_loss             | 0.032186024   |
| qf1_loss                | 2.380993e-07  |
| qf2_loss                | 2.7073241e-07 |
| time_elapsed            | 751           |
| total timesteps         | 161494        |
| value_loss              | 3.3248027e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0185385     |
| ep_rewmean              | -0.186        |
| episodes                | 1620          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 161863        |
| policy_loss             | 0.03484099    |
| qf1_loss                | 7.5311186e-07 |
| qf2_loss                | 8.0511677e-07 |
| time_elapsed            | 753           |
| total timesteps         | 161894        |
| value_loss              | 2.3067878e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0533047     |
| ep_rewmean              | -0.185        |
| episodes                | 1624          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 162263        |
| policy_loss             | 0.033317726   |
| qf1_loss                | 1.0317872e-05 |
| qf2_loss                | 1.0472365e-05 |
| time_elapsed            | 755           |
| total timesteps         | 162294        |
| value_loss              | 8.721317e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.83675       |
| ep_rewmean              | -0.185        |
| episodes                | 1628          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 162663        |
| policy_loss             | 0.03363022    |
| qf1_loss                | 1.240832e-05  |
| qf2_loss                | 1.2001752e-05 |
| time_elapsed            | 756           |
| total timesteps         | 162694        |
| value_loss              | 4.5306742e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2205734     |
| ep_rewmean              | -0.185        |
| episodes                | 1632          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 163063        |
| policy_loss             | 0.026828796   |
| qf1_loss                | 3.819207e-07  |
| qf2_loss                | 1.654745e-07  |
| time_elapsed            | 758           |
| total timesteps         | 163094        |
| value_loss              | 9.2503245e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9528213     |
| ep_rewmean              | -0.185        |
| episodes                | 1636          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 163463        |
| policy_loss             | 0.034855686   |
| qf1_loss                | 1.7217445e-07 |
| qf2_loss                | 9.566136e-08  |
| time_elapsed            | 760           |
| total timesteps         | 163494        |
| value_loss              | 1.1600323e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2361565     |
| ep_rewmean              | -0.184        |
| episodes                | 1640          |
| eplenmean               | 100           |
| fps                     | 214           |
| mean 100 episode reward | -0.2          |
| n_updates               | 163863        |
| policy_loss             | 0.026936747   |
| qf1_loss                | 2.0042295e-07 |
| qf2_loss                | 3.221511e-07  |
| time_elapsed            | 762           |
| total timesteps         | 163894        |
| value_loss              | 3.035123e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.024723      |
| ep_rewmean              | -0.183        |
| episodes                | 1644          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 164263        |
| policy_loss             | 0.028544659   |
| qf1_loss                | 1.0879923e-05 |
| qf2_loss                | 1.0942068e-05 |
| time_elapsed            | 764           |
| total timesteps         | 164294        |
| value_loss              | 2.2405907e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.11273       |
| ep_rewmean              | -0.183        |
| episodes                | 1648          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 164663        |
| policy_loss             | 0.02698048    |
| qf1_loss                | 8.906683e-08  |
| qf2_loss                | 1.2759094e-07 |
| time_elapsed            | 765           |
| total timesteps         | 164694        |
| value_loss              | 1.5100458e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0736513     |
| ep_rewmean              | -0.183        |
| episodes                | 1652          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 165063        |
| policy_loss             | 0.030619271   |
| qf1_loss                | 1.2880062e-07 |
| qf2_loss                | 1.8759792e-07 |
| time_elapsed            | 767           |
| total timesteps         | 165094        |
| value_loss              | 1.997149e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1531076     |
| ep_rewmean              | -0.183        |
| episodes                | 1656          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 165463        |
| policy_loss             | 0.03041216    |
| qf1_loss                | 2.100115e-05  |
| qf2_loss                | 2.0730915e-05 |
| time_elapsed            | 769           |
| total timesteps         | 165494        |
| value_loss              | 1.1113423e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2171926     |
| ep_rewmean              | -0.183        |
| episodes                | 1660          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 165863        |
| policy_loss             | 0.026373357   |
| qf1_loss                | 2.1080584e-07 |
| qf2_loss                | 8.691994e-08  |
| time_elapsed            | 771           |
| total timesteps         | 165894        |
| value_loss              | 8.3217014e-07 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 7.137708       |
| ep_rewmean              | -0.184         |
| episodes                | 1664           |
| eplenmean               | 100            |
| fps                     | 215            |
| mean 100 episode reward | -0.2           |
| n_updates               | 166263         |
| policy_loss             | 0.034067642    |
| qf1_loss                | 1.133736e-05   |
| qf2_loss                | 1.01859705e-05 |
| time_elapsed            | 773            |
| total timesteps         | 166294         |
| value_loss              | 1.460653e-06   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1301265     |
| ep_rewmean              | -0.183        |
| episodes                | 1668          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 166663        |
| policy_loss             | 0.029819809   |
| qf1_loss                | 2.086133e-05  |
| qf2_loss                | 2.0360987e-05 |
| time_elapsed            | 775           |
| total timesteps         | 166694        |
| value_loss              | 1.6175028e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.768855      |
| ep_rewmean              | -0.182        |
| episodes                | 1672          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 167063        |
| policy_loss             | 0.03296643    |
| qf1_loss                | 1.9345681e-07 |
| qf2_loss                | 3.9286329e-07 |
| time_elapsed            | 776           |
| total timesteps         | 167094        |
| value_loss              | 1.1480613e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1545215     |
| ep_rewmean              | -0.178        |
| episodes                | 1676          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 167463        |
| policy_loss             | 0.026888093   |
| qf1_loss                | 1.1671386e-06 |
| qf2_loss                | 5.679883e-07  |
| time_elapsed            | 778           |
| total timesteps         | 167494        |
| value_loss              | 2.4348801e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.860756      |
| ep_rewmean              | -0.178        |
| episodes                | 1680          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 167863        |
| policy_loss             | 0.028690742   |
| qf1_loss                | 2.3446648e-07 |
| qf2_loss                | 1.4584955e-07 |
| time_elapsed            | 780           |
| total timesteps         | 167894        |
| value_loss              | 3.4165164e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1216335     |
| ep_rewmean              | -0.178        |
| episodes                | 1684          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 168263        |
| policy_loss             | 0.029298874   |
| qf1_loss                | 9.754249e-06  |
| qf2_loss                | 9.77666e-06   |
| time_elapsed            | 782           |
| total timesteps         | 168294        |
| value_loss              | 1.1865528e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.812601      |
| ep_rewmean              | -0.178        |
| episodes                | 1688          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 168663        |
| policy_loss             | 0.03135579    |
| qf1_loss                | 4.076834e-07  |
| qf2_loss                | 1.4681963e-07 |
| time_elapsed            | 784           |
| total timesteps         | 168694        |
| value_loss              | 1.6401365e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1422725     |
| ep_rewmean              | -0.177        |
| episodes                | 1692          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 169063        |
| policy_loss             | 0.027439961   |
| qf1_loss                | 1.0932926e-07 |
| qf2_loss                | 1.2417631e-06 |
| time_elapsed            | 786           |
| total timesteps         | 169094        |
| value_loss              | 1.9266768e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.015603      |
| ep_rewmean              | -0.176        |
| episodes                | 1696          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 169463        |
| policy_loss             | 0.028458178   |
| qf1_loss                | 3.515142e-07  |
| qf2_loss                | 4.040848e-07  |
| time_elapsed            | 788           |
| total timesteps         | 169494        |
| value_loss              | 2.5405886e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.380969      |
| ep_rewmean              | -0.175        |
| episodes                | 1700          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 169863        |
| policy_loss             | 0.026545024   |
| qf1_loss                | 3.036468e-07  |
| qf2_loss                | 5.346502e-07  |
| time_elapsed            | 789           |
| total timesteps         | 169894        |
| value_loss              | 2.1403223e-06 |
-------------------------------------------
Eval num_timesteps=170000, episode_reward=-0.15 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.940652      |
| ep_rewmean              | -0.17         |
| episodes                | 1704          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 170263        |
| policy_loss             | 0.027988596   |
| qf1_loss                | 8.562041e-08  |
| qf2_loss                | 2.1508336e-07 |
| time_elapsed            | 791           |
| total timesteps         | 170294        |
| value_loss              | 1.6638462e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0484343     |
| ep_rewmean              | -0.17         |
| episodes                | 1708          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 170663        |
| policy_loss             | 0.03184561    |
| qf1_loss                | 9.281234e-06  |
| qf2_loss                | 9.588097e-06  |
| time_elapsed            | 793           |
| total timesteps         | 170694        |
| value_loss              | 1.5624457e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.927064      |
| ep_rewmean              | -0.171        |
| episodes                | 1712          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 171063        |
| policy_loss             | 0.02900947    |
| qf1_loss                | 2.2044166e-07 |
| qf2_loss                | 3.3821914e-07 |
| time_elapsed            | 795           |
| total timesteps         | 171094        |
| value_loss              | 1.9855138e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0648956     |
| ep_rewmean              | -0.171        |
| episodes                | 1716          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 171463        |
| policy_loss             | 0.024927853   |
| qf1_loss                | 1.567652e-07  |
| qf2_loss                | 2.626687e-07  |
| time_elapsed            | 797           |
| total timesteps         | 171494        |
| value_loss              | 1.8153423e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1380777     |
| ep_rewmean              | -0.171        |
| episodes                | 1720          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 171863        |
| policy_loss             | 0.029546287   |
| qf1_loss                | 5.680543e-07  |
| qf2_loss                | 1.3128587e-07 |
| time_elapsed            | 799           |
| total timesteps         | 171894        |
| value_loss              | 1.3263698e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0360765     |
| ep_rewmean              | -0.171        |
| episodes                | 1724          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 172263        |
| policy_loss             | 0.029806567   |
| qf1_loss                | 3.4269252e-07 |
| qf2_loss                | 4.1543834e-07 |
| time_elapsed            | 800           |
| total timesteps         | 172294        |
| value_loss              | 4.328709e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.3109217     |
| ep_rewmean              | -0.172        |
| episodes                | 1728          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 172663        |
| policy_loss             | 0.030121107   |
| qf1_loss                | 1.0461128e-05 |
| qf2_loss                | 1.0582835e-05 |
| time_elapsed            | 802           |
| total timesteps         | 172694        |
| value_loss              | 3.3105848e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.283023      |
| ep_rewmean              | -0.171        |
| episodes                | 1732          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 173063        |
| policy_loss             | 0.02482829    |
| qf1_loss                | 1.1582263e-07 |
| qf2_loss                | 1.5294036e-07 |
| time_elapsed            | 804           |
| total timesteps         | 173094        |
| value_loss              | 6.53028e-07   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6932316     |
| ep_rewmean              | -0.17         |
| episodes                | 1736          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 173463        |
| policy_loss             | 0.029747615   |
| qf1_loss                | 1.6073975e-07 |
| qf2_loss                | 2.974228e-07  |
| time_elapsed            | 806           |
| total timesteps         | 173494        |
| value_loss              | 1.6075725e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9604297     |
| ep_rewmean              | -0.17         |
| episodes                | 1740          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 173863        |
| policy_loss             | 0.029187856   |
| qf1_loss                | 2.6400878e-07 |
| qf2_loss                | 2.2309318e-07 |
| time_elapsed            | 807           |
| total timesteps         | 173894        |
| value_loss              | 1.5901676e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.345714      |
| ep_rewmean              | -0.171        |
| episodes                | 1744          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 174263        |
| policy_loss             | 0.02839023    |
| qf1_loss                | 4.8841196e-07 |
| qf2_loss                | 5.918647e-07  |
| time_elapsed            | 809           |
| total timesteps         | 174294        |
| value_loss              | 1.8472036e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.989788      |
| ep_rewmean              | -0.17         |
| episodes                | 1748          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 174663        |
| policy_loss             | 0.02950791    |
| qf1_loss                | 4.703082e-07  |
| qf2_loss                | 9.2352064e-07 |
| time_elapsed            | 811           |
| total timesteps         | 174694        |
| value_loss              | 1.2825842e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1326303     |
| ep_rewmean              | -0.171        |
| episodes                | 1752          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 175063        |
| policy_loss             | 0.02428942    |
| qf1_loss                | 8.843214e-06  |
| qf2_loss                | 9.141576e-06  |
| time_elapsed            | 813           |
| total timesteps         | 175094        |
| value_loss              | 1.1903805e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.057355      |
| ep_rewmean              | -0.172        |
| episodes                | 1756          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 175463        |
| policy_loss             | 0.031565778   |
| qf1_loss                | 6.131513e-07  |
| qf2_loss                | 5.9314004e-07 |
| time_elapsed            | 815           |
| total timesteps         | 175494        |
| value_loss              | 2.474822e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1468773     |
| ep_rewmean              | -0.173        |
| episodes                | 1760          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 175863        |
| policy_loss             | 0.02760896    |
| qf1_loss                | 1.4627956e-07 |
| qf2_loss                | 2.7962895e-07 |
| time_elapsed            | 817           |
| total timesteps         | 175894        |
| value_loss              | 1.5711506e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.331398      |
| ep_rewmean              | -0.172        |
| episodes                | 1764          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 176263        |
| policy_loss             | 0.024650985   |
| qf1_loss                | 7.655096e-07  |
| qf2_loss                | 6.4026494e-07 |
| time_elapsed            | 818           |
| total timesteps         | 176294        |
| value_loss              | 1.4965613e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.378604      |
| ep_rewmean              | -0.173        |
| episodes                | 1768          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 176663        |
| policy_loss             | 0.02379515    |
| qf1_loss                | 7.6511947e-07 |
| qf2_loss                | 6.758873e-07  |
| time_elapsed            | 820           |
| total timesteps         | 176694        |
| value_loss              | 8.955491e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2077427     |
| ep_rewmean              | -0.174        |
| episodes                | 1772          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 177063        |
| policy_loss             | 0.027098877   |
| qf1_loss                | 2.6279582e-07 |
| qf2_loss                | 3.8786914e-07 |
| time_elapsed            | 822           |
| total timesteps         | 177094        |
| value_loss              | 1.2850551e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9966083     |
| ep_rewmean              | -0.174        |
| episodes                | 1776          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 177463        |
| policy_loss             | 0.023906413   |
| qf1_loss                | 1.2467126e-07 |
| qf2_loss                | 1.3733974e-07 |
| time_elapsed            | 824           |
| total timesteps         | 177494        |
| value_loss              | 5.3470734e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.051753      |
| ep_rewmean              | -0.174        |
| episodes                | 1780          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 177863        |
| policy_loss             | 0.024053032   |
| qf1_loss                | 7.705004e-06  |
| qf2_loss                | 8.325435e-06  |
| time_elapsed            | 826           |
| total timesteps         | 177894        |
| value_loss              | 6.4561203e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.355831      |
| ep_rewmean              | -0.173        |
| episodes                | 1784          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 178263        |
| policy_loss             | 0.02204131    |
| qf1_loss                | 3.243468e-07  |
| qf2_loss                | 3.498753e-07  |
| time_elapsed            | 828           |
| total timesteps         | 178294        |
| value_loss              | 2.1648566e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.355731      |
| ep_rewmean              | -0.173        |
| episodes                | 1788          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 178663        |
| policy_loss             | 0.024398323   |
| qf1_loss                | 6.648473e-08  |
| qf2_loss                | 8.499565e-08  |
| time_elapsed            | 829           |
| total timesteps         | 178694        |
| value_loss              | 2.2409479e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.3694243     |
| ep_rewmean              | -0.173        |
| episodes                | 1792          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 179063        |
| policy_loss             | 0.025190152   |
| qf1_loss                | 5.2609742e-08 |
| qf2_loss                | 1.162754e-07  |
| time_elapsed            | 831           |
| total timesteps         | 179094        |
| value_loss              | 2.4686674e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0718184     |
| ep_rewmean              | -0.174        |
| episodes                | 1796          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 179463        |
| policy_loss             | 0.027016524   |
| qf1_loss                | 2.304268e-07  |
| qf2_loss                | 4.0477966e-07 |
| time_elapsed            | 833           |
| total timesteps         | 179494        |
| value_loss              | 1.9619006e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1421394     |
| ep_rewmean              | -0.174        |
| episodes                | 1800          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 179863        |
| policy_loss             | 0.023661269   |
| qf1_loss                | 2.1185703e-07 |
| qf2_loss                | 1.4234774e-07 |
| time_elapsed            | 835           |
| total timesteps         | 179894        |
| value_loss              | 1.6145199e-06 |
-------------------------------------------
Eval num_timesteps=180000, episode_reward=-0.13 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0486593     |
| ep_rewmean              | -0.174        |
| episodes                | 1804          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 180263        |
| policy_loss             | 0.02887204    |
| qf1_loss                | 7.4008076e-06 |
| qf2_loss                | 7.5614353e-06 |
| time_elapsed            | 837           |
| total timesteps         | 180294        |
| value_loss              | 1.9094105e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0797224     |
| ep_rewmean              | -0.173        |
| episodes                | 1808          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 180663        |
| policy_loss             | 0.026198763   |
| qf1_loss                | 3.636614e-07  |
| qf2_loss                | 3.3298582e-07 |
| time_elapsed            | 839           |
| total timesteps         | 180694        |
| value_loss              | 1.4831749e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9498777     |
| ep_rewmean              | -0.189        |
| episodes                | 1812          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 181063        |
| policy_loss             | 0.02265047    |
| qf1_loss                | 7.095847e-06  |
| qf2_loss                | 6.6542707e-06 |
| time_elapsed            | 840           |
| total timesteps         | 181094        |
| value_loss              | 7.532843e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8151608     |
| ep_rewmean              | -0.205        |
| episodes                | 1816          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 181463        |
| policy_loss             | 0.024585133   |
| qf1_loss                | 5.0031696e-07 |
| qf2_loss                | 1.4093573e-07 |
| time_elapsed            | 842           |
| total timesteps         | 181494        |
| value_loss              | 1.1493566e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6544046     |
| ep_rewmean              | -0.211        |
| episodes                | 1820          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 181863        |
| policy_loss             | 0.027372576   |
| qf1_loss                | 8.311204e-06  |
| qf2_loss                | 8.286674e-06  |
| time_elapsed            | 844           |
| total timesteps         | 181894        |
| value_loss              | 1.8974238e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.550082      |
| ep_rewmean              | -0.219        |
| episodes                | 1824          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 182263        |
| policy_loss             | 0.026806772   |
| qf1_loss                | 6.2216543e-07 |
| qf2_loss                | 4.5872605e-07 |
| time_elapsed            | 846           |
| total timesteps         | 182294        |
| value_loss              | 2.091026e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.101245      |
| ep_rewmean              | -0.22         |
| episodes                | 1828          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 182663        |
| policy_loss             | 0.030847255   |
| qf1_loss                | 3.4908498e-07 |
| qf2_loss                | 2.687679e-07  |
| time_elapsed            | 848           |
| total timesteps         | 182694        |
| value_loss              | 1.9088911e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.087411      |
| ep_rewmean              | -0.22         |
| episodes                | 1832          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 183063        |
| policy_loss             | 0.022973586   |
| qf1_loss                | 1.0146849e-07 |
| qf2_loss                | 1.1699282e-07 |
| time_elapsed            | 850           |
| total timesteps         | 183094        |
| value_loss              | 6.5073175e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8399553     |
| ep_rewmean              | -0.222        |
| episodes                | 1836          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 183463        |
| policy_loss             | 0.024881436   |
| qf1_loss                | 7.783763e-06  |
| qf2_loss                | 8.092049e-06  |
| time_elapsed            | 851           |
| total timesteps         | 183494        |
| value_loss              | 2.1224769e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0527277     |
| ep_rewmean              | -0.23         |
| episodes                | 1840          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 183863        |
| policy_loss             | 0.025478229   |
| qf1_loss                | 1.5149542e-05 |
| qf2_loss                | 1.4842843e-05 |
| time_elapsed            | 853           |
| total timesteps         | 183894        |
| value_loss              | 2.4082415e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8324213     |
| ep_rewmean              | -0.231        |
| episodes                | 1844          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 184263        |
| policy_loss             | 0.024819208   |
| qf1_loss                | 1.9999507e-07 |
| qf2_loss                | 6.770815e-07  |
| time_elapsed            | 855           |
| total timesteps         | 184294        |
| value_loss              | 2.0463633e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9976816     |
| ep_rewmean              | -0.234        |
| episodes                | 1848          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 184663        |
| policy_loss             | 0.023705248   |
| qf1_loss                | 1.9321081e-07 |
| qf2_loss                | 8.145831e-07  |
| time_elapsed            | 857           |
| total timesteps         | 184694        |
| value_loss              | 1.9699025e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4350405     |
| ep_rewmean              | -0.233        |
| episodes                | 1852          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 185063        |
| policy_loss             | 0.024914486   |
| qf1_loss                | 2.332969e-06  |
| qf2_loss                | 1.1154397e-06 |
| time_elapsed            | 858           |
| total timesteps         | 185094        |
| value_loss              | 3.3893073e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6883163     |
| ep_rewmean              | -0.233        |
| episodes                | 1856          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 185463        |
| policy_loss             | 0.024270916   |
| qf1_loss                | 1.34548e-07   |
| qf2_loss                | 9.7415395e-08 |
| time_elapsed            | 860           |
| total timesteps         | 185494        |
| value_loss              | 2.875749e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9117956     |
| ep_rewmean              | -0.234        |
| episodes                | 1860          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 185863        |
| policy_loss             | 0.023487832   |
| qf1_loss                | 6.297105e-06  |
| qf2_loss                | 6.6566786e-06 |
| time_elapsed            | 862           |
| total timesteps         | 185894        |
| value_loss              | 1.3363936e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.230136      |
| ep_rewmean              | -0.237        |
| episodes                | 1864          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 186263        |
| policy_loss             | 0.024618063   |
| qf1_loss                | 2.8816103e-07 |
| qf2_loss                | 3.0040167e-07 |
| time_elapsed            | 864           |
| total timesteps         | 186294        |
| value_loss              | 6.6341477e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8735843     |
| ep_rewmean              | -0.242        |
| episodes                | 1868          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 186663        |
| policy_loss             | 0.02698316    |
| qf1_loss                | 1.9112368e-07 |
| qf2_loss                | 3.7387787e-07 |
| time_elapsed            | 865           |
| total timesteps         | 186694        |
| value_loss              | 1.7111361e-06 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 6.7846174    |
| ep_rewmean              | -0.242       |
| episodes                | 1872         |
| eplenmean               | 100          |
| fps                     | 215          |
| mean 100 episode reward | -0.2         |
| n_updates               | 187063       |
| policy_loss             | 0.023148159  |
| qf1_loss                | 6.10319e-06  |
| qf2_loss                | 6.072563e-06 |
| time_elapsed            | 867          |
| total timesteps         | 187094       |
| value_loss              | 9.015377e-07 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.967553      |
| ep_rewmean              | -0.246        |
| episodes                | 1876          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 187463        |
| policy_loss             | 0.019714406   |
| qf1_loss                | 5.264105e-07  |
| qf2_loss                | 5.3835504e-07 |
| time_elapsed            | 869           |
| total timesteps         | 187494        |
| value_loss              | 2.3902394e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1321282     |
| ep_rewmean              | -0.25         |
| episodes                | 1880          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 187863        |
| policy_loss             | 0.022870343   |
| qf1_loss                | 2.357176e-06  |
| qf2_loss                | 6.2656613e-06 |
| time_elapsed            | 871           |
| total timesteps         | 187894        |
| value_loss              | 1.5180876e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.910985      |
| ep_rewmean              | -0.251        |
| episodes                | 1884          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.3          |
| n_updates               | 188263        |
| policy_loss             | 0.020585721   |
| qf1_loss                | 6.2448707e-06 |
| qf2_loss                | 6.146473e-06  |
| time_elapsed            | 873           |
| total timesteps         | 188294        |
| value_loss              | 1.5032949e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.581398      |
| ep_rewmean              | -0.251        |
| episodes                | 1888          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.3          |
| n_updates               | 188663        |
| policy_loss             | 0.024853358   |
| qf1_loss                | 6.648849e-06  |
| qf2_loss                | 6.4607148e-06 |
| time_elapsed            | 875           |
| total timesteps         | 188694        |
| value_loss              | 1.1562622e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.140945      |
| ep_rewmean              | -0.255        |
| episodes                | 1892          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.3          |
| n_updates               | 189063        |
| policy_loss             | 0.020895198   |
| qf1_loss                | 5.608392e-07  |
| qf2_loss                | 4.5514273e-07 |
| time_elapsed            | 876           |
| total timesteps         | 189094        |
| value_loss              | 1.1432973e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9987383     |
| ep_rewmean              | -0.253        |
| episodes                | 1896          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.3          |
| n_updates               | 189463        |
| policy_loss             | 0.022846054   |
| qf1_loss                | 4.773948e-07  |
| qf2_loss                | 3.4456275e-07 |
| time_elapsed            | 878           |
| total timesteps         | 189494        |
| value_loss              | 1.4793786e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9072        |
| ep_rewmean              | -0.254        |
| episodes                | 1900          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.3          |
| n_updates               | 189863        |
| policy_loss             | 0.022799749   |
| qf1_loss                | 1.206337e-07  |
| qf2_loss                | 4.004548e-07  |
| time_elapsed            | 880           |
| total timesteps         | 189894        |
| value_loss              | 1.1088558e-06 |
-------------------------------------------
Eval num_timesteps=190000, episode_reward=-0.18 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.829851      |
| ep_rewmean              | -0.256        |
| episodes                | 1904          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.3          |
| n_updates               | 190263        |
| policy_loss             | 0.023672849   |
| qf1_loss                | 5.8588944e-06 |
| qf2_loss                | 6.0940447e-06 |
| time_elapsed            | 882           |
| total timesteps         | 190294        |
| value_loss              | 2.3529997e-06 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 6.929943     |
| ep_rewmean              | -0.257       |
| episodes                | 1908         |
| eplenmean               | 100          |
| fps                     | 215          |
| mean 100 episode reward | -0.3         |
| n_updates               | 190663       |
| policy_loss             | 0.023533128  |
| qf1_loss                | 1.253461e-07 |
| qf2_loss                | 9.188537e-08 |
| time_elapsed            | 884          |
| total timesteps         | 190694       |
| value_loss              | 6.861865e-07 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.707677      |
| ep_rewmean              | -0.239        |
| episodes                | 1912          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 191063        |
| policy_loss             | 0.026953911   |
| qf1_loss                | 5.518299e-07  |
| qf2_loss                | 1.3620086e-06 |
| time_elapsed            | 886           |
| total timesteps         | 191094        |
| value_loss              | 1.6257819e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0362883     |
| ep_rewmean              | -0.225        |
| episodes                | 1916          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 191463        |
| policy_loss             | 0.021319509   |
| qf1_loss                | 4.3692944e-06 |
| qf2_loss                | 1.3475405e-06 |
| time_elapsed            | 888           |
| total timesteps         | 191494        |
| value_loss              | 9.758023e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6698184     |
| ep_rewmean              | -0.233        |
| episodes                | 1920          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 191863        |
| policy_loss             | 0.020745192   |
| qf1_loss                | 5.752728e-06  |
| qf2_loss                | 5.4870748e-06 |
| time_elapsed            | 889           |
| total timesteps         | 191894        |
| value_loss              | 1.787635e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8828573     |
| ep_rewmean              | -0.224        |
| episodes                | 1924          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 192263        |
| policy_loss             | 0.022967447   |
| qf1_loss                | 1.1922495e-07 |
| qf2_loss                | 1.3902468e-07 |
| time_elapsed            | 891           |
| total timesteps         | 192294        |
| value_loss              | 1.2116147e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.101286      |
| ep_rewmean              | -0.225        |
| episodes                | 1928          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 192663        |
| policy_loss             | 0.021290153   |
| qf1_loss                | 2.8008685e-07 |
| qf2_loss                | 5.258888e-07  |
| time_elapsed            | 893           |
| total timesteps         | 192694        |
| value_loss              | 1.7367291e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.927801      |
| ep_rewmean              | -0.232        |
| episodes                | 1932          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 193063        |
| policy_loss             | 0.021586215   |
| qf1_loss                | 1.7755585e-07 |
| qf2_loss                | 4.350003e-08  |
| time_elapsed            | 895           |
| total timesteps         | 193094        |
| value_loss              | 6.3774394e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.789363      |
| ep_rewmean              | -0.231        |
| episodes                | 1936          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 193463        |
| policy_loss             | 0.020063998   |
| qf1_loss                | 2.8037363e-07 |
| qf2_loss                | 3.965788e-07  |
| time_elapsed            | 896           |
| total timesteps         | 193494        |
| value_loss              | 1.0484661e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.673465      |
| ep_rewmean              | -0.223        |
| episodes                | 1940          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 193863        |
| policy_loss             | 0.027625635   |
| qf1_loss                | 1.3426651e-07 |
| qf2_loss                | 2.0403505e-07 |
| time_elapsed            | 898           |
| total timesteps         | 193894        |
| value_loss              | 7.963053e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1328955     |
| ep_rewmean              | -0.222        |
| episodes                | 1944          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 194263        |
| policy_loss             | 0.024834555   |
| qf1_loss                | 3.716327e-07  |
| qf2_loss                | 7.782638e-07  |
| time_elapsed            | 900           |
| total timesteps         | 194294        |
| value_loss              | 2.7569452e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.343917      |
| ep_rewmean              | -0.222        |
| episodes                | 1948          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 194663        |
| policy_loss             | 0.023121065   |
| qf1_loss                | 5.0340273e-06 |
| qf2_loss                | 4.703347e-06  |
| time_elapsed            | 902           |
| total timesteps         | 194694        |
| value_loss              | 7.3980533e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.139805      |
| ep_rewmean              | -0.222        |
| episodes                | 1952          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 195063        |
| policy_loss             | 0.024018377   |
| qf1_loss                | 3.248141e-07  |
| qf2_loss                | 2.1088438e-07 |
| time_elapsed            | 904           |
| total timesteps         | 195094        |
| value_loss              | 2.5977265e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.25243       |
| ep_rewmean              | -0.221        |
| episodes                | 1956          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 195463        |
| policy_loss             | 0.018928122   |
| qf1_loss                | 1.7674209e-07 |
| qf2_loss                | 1.7393407e-07 |
| time_elapsed            | 906           |
| total timesteps         | 195494        |
| value_loss              | 5.0941367e-07 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 7.14317        |
| ep_rewmean              | -0.219         |
| episodes                | 1960           |
| eplenmean               | 100            |
| fps                     | 215            |
| mean 100 episode reward | -0.2           |
| n_updates               | 195863         |
| policy_loss             | 0.02296333     |
| qf1_loss                | 1.14337254e-07 |
| qf2_loss                | 3.1678735e-07  |
| time_elapsed            | 907            |
| total timesteps         | 195894         |
| value_loss              | 9.934247e-07   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1417146     |
| ep_rewmean              | -0.216        |
| episodes                | 1964          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 196263        |
| policy_loss             | 0.020654058   |
| qf1_loss                | 5.1768043e-06 |
| qf2_loss                | 5.0120943e-06 |
| time_elapsed            | 909           |
| total timesteps         | 196294        |
| value_loss              | 1.1110851e-06 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 7.0481386    |
| ep_rewmean              | -0.209       |
| episodes                | 1968         |
| eplenmean               | 100          |
| fps                     | 215          |
| mean 100 episode reward | -0.2         |
| n_updates               | 196663       |
| policy_loss             | 0.01882044   |
| qf1_loss                | 7.889538e-08 |
| qf2_loss                | 6.288356e-08 |
| time_elapsed            | 911          |
| total timesteps         | 196694       |
| value_loss              | 6.302615e-07 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.034667      |
| ep_rewmean              | -0.208        |
| episodes                | 1972          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 197063        |
| policy_loss             | 0.024789896   |
| qf1_loss                | 8.4859255e-07 |
| qf2_loss                | 6.0192895e-07 |
| time_elapsed            | 913           |
| total timesteps         | 197094        |
| value_loss              | 1.5389885e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7777705     |
| ep_rewmean              | -0.205        |
| episodes                | 1976          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 197463        |
| policy_loss             | 0.017726928   |
| qf1_loss                | 4.810642e-06  |
| qf2_loss                | 4.9469986e-06 |
| time_elapsed            | 915           |
| total timesteps         | 197494        |
| value_loss              | 6.637552e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.917365      |
| ep_rewmean              | -0.202        |
| episodes                | 1980          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 197863        |
| policy_loss             | 0.020411206   |
| qf1_loss                | 5.8235585e-08 |
| qf2_loss                | 9.516337e-08  |
| time_elapsed            | 917           |
| total timesteps         | 197894        |
| value_loss              | 9.249366e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8832464     |
| ep_rewmean              | -0.202        |
| episodes                | 1984          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 198263        |
| policy_loss             | 0.020621035   |
| qf1_loss                | 3.8532673e-07 |
| qf2_loss                | 2.475743e-07  |
| time_elapsed            | 918           |
| total timesteps         | 198294        |
| value_loss              | 2.4399728e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.183509      |
| ep_rewmean              | -0.202        |
| episodes                | 1988          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 198663        |
| policy_loss             | 0.022110414   |
| qf1_loss                | 4.6143828e-06 |
| qf2_loss                | 4.584131e-06  |
| time_elapsed            | 920           |
| total timesteps         | 198694        |
| value_loss              | 1.376199e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.76781       |
| ep_rewmean              | -0.201        |
| episodes                | 1992          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 199063        |
| policy_loss             | 0.026312478   |
| qf1_loss                | 3.6305102e-07 |
| qf2_loss                | 2.6700542e-07 |
| time_elapsed            | 922           |
| total timesteps         | 199094        |
| value_loss              | 8.0932216e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.934801      |
| ep_rewmean              | -0.2          |
| episodes                | 1996          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 199463        |
| policy_loss             | 0.016626814   |
| qf1_loss                | 6.454849e-07  |
| qf2_loss                | 3.3551936e-07 |
| time_elapsed            | 924           |
| total timesteps         | 199494        |
| value_loss              | 1.0672835e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9215484     |
| ep_rewmean              | -0.199        |
| episodes                | 2000          |
| eplenmean               | 100           |
| fps                     | 215           |
| mean 100 episode reward | -0.2          |
| n_updates               | 199863        |
| policy_loss             | 0.023097267   |
| qf1_loss                | 4.489378e-06  |
| qf2_loss                | 5.1031143e-06 |
| time_elapsed            | 926           |
| total timesteps         | 199894        |
| value_loss              | 1.5099154e-06 |
-------------------------------------------
/home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/common/callbacks.py:285: UserWarning: Training and eval env are not of the same type<stable_baselines.common.base_class._UnvecWrapper object at 0x7f119934dcc0> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f119934dc50>
  "{} != {}".format(self.training_env, self.eval_env))
Eval num_timesteps=200000, episode_reward=-0.14 +/- 0.00
Episode length: 100.00 +/- 0.00
Saving to logs/train_0.2M_widowx_reacher-v5_SONIC/sac/widowx_reacher-v5_1
pybullet build time: May 18 2020 02:46:26
