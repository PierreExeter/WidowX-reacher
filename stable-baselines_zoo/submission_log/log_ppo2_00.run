--------------------------------------------------------------------------
WARNING: There was an error initializing an OpenFabrics device.

  Local host:   n295
  Local device: hfi1_0
--------------------------------------------------------------------------
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

========== widowx_reacher-v7 ==========
Seed: 0
OrderedDict([('cliprange', 0.2),
             ('ent_coef', 0.0),
             ('gamma', 0.99),
             ('lam', 0.95),
             ('learning_rate', 0.00025),
             ('n_envs', 8),
             ('n_steps', 256),
             ('n_timesteps', 1000000.0),
             ('nminibatches', 32),
             ('noptepochs', 10),
             ('normalize', True),
             ('policy', 'MlpPolicy')])
Using 8 environments
Overwriting n_timesteps with n=500000
Normalizing input and reward
Creating test environment
TRAINING ENV TYPE :  <stable_baselines.common.vec_env.vec_normalize.VecNormalize object at 0x7fdc2fcda6a0>
Normalization activated: {'norm_reward': False}
EVAL ENV TYPE :  <stable_baselines.common.vec_env.vec_normalize.VecNormalize object at 0x7fdc2d64e518>
Log path: logs/train_0.5M_widowx_reacher-v7_KAY/ppo2/widowx_reacher-v7_1
-------------------------------------
| approxkl           | 0.0069376244 |
| clipfrac           | 0.09272461   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.69        |
| explained_variance | 0.0978       |
| fps                | 1480         |
| n_updates          | 1            |
| policy_entropy     | 8.526085     |
| policy_loss        | -0.012520125 |
| serial_timesteps   | 256          |
| time_elapsed       | 2.96e-05     |
| total_timesteps    | 2048         |
| value_loss         | 0.8181718    |
-------------------------------------
-------------------------------------
| approxkl           | 0.007870275  |
| clipfrac           | 0.110644534  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.68        |
| explained_variance | -0.000444    |
| fps                | 2044         |
| n_updates          | 2            |
| policy_entropy     | 8.540168     |
| policy_loss        | -0.015359402 |
| serial_timesteps   | 512          |
| time_elapsed       | 1.38         |
| total_timesteps    | 4096         |
| value_loss         | 0.09643181   |
-------------------------------------
-------------------------------------
| approxkl           | 0.005387032  |
| clipfrac           | 0.068408206  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | -0.0778      |
| fps                | 2099         |
| n_updates          | 3            |
| policy_entropy     | 8.543457     |
| policy_loss        | -0.010968332 |
| serial_timesteps   | 768          |
| time_elapsed       | 2.39         |
| total_timesteps    | 6144         |
| value_loss         | 0.09909734   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0089549525 |
| clipfrac           | 0.12885742   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.217        |
| fps                | 2179         |
| n_updates          | 4            |
| policy_entropy     | 8.529777     |
| policy_loss        | -0.017199796 |
| serial_timesteps   | 1024         |
| time_elapsed       | 3.36         |
| total_timesteps    | 8192         |
| value_loss         | 0.07899678   |
-------------------------------------
Eval num_timesteps=10000, episode_reward=-3.88 +/- 3.59
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.00788503   |
| clipfrac           | 0.1078125    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | -0.225       |
| fps                | 1377         |
| n_updates          | 5            |
| policy_entropy     | 8.53974      |
| policy_loss        | -0.012604359 |
| serial_timesteps   | 1280         |
| time_elapsed       | 4.3          |
| total_timesteps    | 10240        |
| value_loss         | 0.14833938   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007296552  |
| clipfrac           | 0.10551758   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.7         |
| explained_variance | -0.088       |
| fps                | 2168         |
| n_updates          | 6            |
| policy_entropy     | 8.552433     |
| policy_loss        | -0.013596199 |
| serial_timesteps   | 1536         |
| time_elapsed       | 5.79         |
| total_timesteps    | 12288        |
| value_loss         | 0.10672589   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0060940813 |
| clipfrac           | 0.07895508   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.76        |
| explained_variance | 0.0464       |
| fps                | 1969         |
| n_updates          | 7            |
| policy_entropy     | 8.544488     |
| policy_loss        | -0.00941533  |
| serial_timesteps   | 1792         |
| time_elapsed       | 6.73         |
| total_timesteps    | 14336        |
| value_loss         | 0.19049457   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007139601  |
| clipfrac           | 0.09658203   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.99        |
| explained_variance | 0.354        |
| fps                | 2103         |
| n_updates          | 8            |
| policy_entropy     | 8.522286     |
| policy_loss        | -0.013572926 |
| serial_timesteps   | 2048         |
| time_elapsed       | 7.77         |
| total_timesteps    | 16384        |
| value_loss         | 0.04905577   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0059954072 |
| clipfrac           | 0.07607422   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.02        |
| explained_variance | 0.533        |
| fps                | 2103         |
| n_updates          | 9            |
| policy_entropy     | 8.504562     |
| policy_loss        | -0.009786475 |
| serial_timesteps   | 2304         |
| time_elapsed       | 8.75         |
| total_timesteps    | 18432        |
| value_loss         | 0.033862866  |
-------------------------------------
Eval num_timesteps=20000, episode_reward=-2.52 +/- 1.49
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.007980102  |
| clipfrac           | 0.10942383   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.95        |
| explained_variance | 0.401        |
| fps                | 1414         |
| n_updates          | 10           |
| policy_entropy     | 8.505485     |
| policy_loss        | -0.014835626 |
| serial_timesteps   | 2560         |
| time_elapsed       | 9.72         |
| total_timesteps    | 20480        |
| value_loss         | 0.03976304   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0068669105 |
| clipfrac           | 0.092480466  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.647        |
| fps                | 2093         |
| n_updates          | 11           |
| policy_entropy     | 8.495974     |
| policy_loss        | -0.011364755 |
| serial_timesteps   | 2816         |
| time_elapsed       | 11.2         |
| total_timesteps    | 22528        |
| value_loss         | 0.034732375  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008658609  |
| clipfrac           | 0.12822266   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.73        |
| explained_variance | 0.514        |
| fps                | 2073         |
| n_updates          | 12           |
| policy_entropy     | 8.498331     |
| policy_loss        | -0.013905624 |
| serial_timesteps   | 3072         |
| time_elapsed       | 12.1         |
| total_timesteps    | 24576        |
| value_loss         | 0.040493168  |
-------------------------------------
------------------------------------
| approxkl           | 0.005745356 |
| clipfrac           | 0.074121095 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.63       |
| explained_variance | 0.452       |
| fps                | 2247        |
| n_updates          | 13          |
| policy_entropy     | 8.519712    |
| policy_loss        | -0.00878022 |
| serial_timesteps   | 3328        |
| time_elapsed       | 13.1        |
| total_timesteps    | 26624       |
| value_loss         | 0.041295312 |
------------------------------------
-------------------------------------
| approxkl           | 0.008034923  |
| clipfrac           | 0.11098633   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.609        |
| fps                | 2199         |
| n_updates          | 14           |
| policy_entropy     | 8.505737     |
| policy_loss        | -0.014605726 |
| serial_timesteps   | 3584         |
| time_elapsed       | 14           |
| total_timesteps    | 28672        |
| value_loss         | 0.034895394  |
-------------------------------------
Eval num_timesteps=30000, episode_reward=-1.46 +/- 0.32
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.008249848  |
| clipfrac           | 0.1159668    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.443        |
| fps                | 1491         |
| n_updates          | 15           |
| policy_entropy     | 8.486072     |
| policy_loss        | -0.013386863 |
| serial_timesteps   | 3840         |
| time_elapsed       | 15           |
| total_timesteps    | 30720        |
| value_loss         | 0.078477785  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010317239  |
| clipfrac           | 0.15346679   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.592        |
| fps                | 2203         |
| n_updates          | 16           |
| policy_entropy     | 8.484808     |
| policy_loss        | -0.016503738 |
| serial_timesteps   | 4096         |
| time_elapsed       | 16.4         |
| total_timesteps    | 32768        |
| value_loss         | 0.034776594  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0071484917 |
| clipfrac           | 0.09482422   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.488        |
| fps                | 2178         |
| n_updates          | 17           |
| policy_entropy     | 8.486118     |
| policy_loss        | -0.012339391 |
| serial_timesteps   | 4352         |
| time_elapsed       | 17.3         |
| total_timesteps    | 34816        |
| value_loss         | 0.049113967  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0070162727 |
| clipfrac           | 0.091796875  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.554        |
| fps                | 2158         |
| n_updates          | 18           |
| policy_entropy     | 8.469604     |
| policy_loss        | -0.009613901 |
| serial_timesteps   | 4608         |
| time_elapsed       | 18.2         |
| total_timesteps    | 36864        |
| value_loss         | 0.04028533   |
-------------------------------------
-------------------------------------
| approxkl           | 0.006619564  |
| clipfrac           | 0.08198242   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.573        |
| fps                | 2117         |
| n_updates          | 19           |
| policy_entropy     | 8.445785     |
| policy_loss        | -0.010325903 |
| serial_timesteps   | 4864         |
| time_elapsed       | 19.2         |
| total_timesteps    | 38912        |
| value_loss         | 0.036524624  |
-------------------------------------
Eval num_timesteps=40000, episode_reward=-1.57 +/- 0.62
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.0061314926  |
| clipfrac           | 0.07104492    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.51         |
| explained_variance | 0.658         |
| fps                | 1502          |
| n_updates          | 20            |
| policy_entropy     | 8.413024      |
| policy_loss        | -0.0077062296 |
| serial_timesteps   | 5120          |
| time_elapsed       | 20.1          |
| total_timesteps    | 40960         |
| value_loss         | 0.028079966   |
--------------------------------------
-------------------------------------
| approxkl           | 0.007900724  |
| clipfrac           | 0.11010742   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.584        |
| fps                | 2131         |
| n_updates          | 21           |
| policy_entropy     | 8.368525     |
| policy_loss        | -0.011678847 |
| serial_timesteps   | 5376         |
| time_elapsed       | 21.5         |
| total_timesteps    | 43008        |
| value_loss         | 0.03536128   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0118392175 |
| clipfrac           | 0.1805664    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.709        |
| fps                | 2017         |
| n_updates          | 22           |
| policy_entropy     | 8.343016     |
| policy_loss        | -0.017204892 |
| serial_timesteps   | 5632         |
| time_elapsed       | 22.5         |
| total_timesteps    | 45056        |
| value_loss         | 0.029997414  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008002633  |
| clipfrac           | 0.11079101   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.522        |
| fps                | 2070         |
| n_updates          | 23           |
| policy_entropy     | 8.341115     |
| policy_loss        | -0.014507157 |
| serial_timesteps   | 5888         |
| time_elapsed       | 23.5         |
| total_timesteps    | 47104        |
| value_loss         | 0.04025722   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0059680957 |
| clipfrac           | 0.07353516   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.601        |
| fps                | 2094         |
| n_updates          | 24           |
| policy_entropy     | 8.327957     |
| policy_loss        | -0.007305932 |
| serial_timesteps   | 6144         |
| time_elapsed       | 24.5         |
| total_timesteps    | 49152        |
| value_loss         | 0.04872206   |
-------------------------------------
Eval num_timesteps=50000, episode_reward=-2.03 +/- 0.80
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0064942753 |
| clipfrac           | 0.08305664   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.613        |
| fps                | 1388         |
| n_updates          | 25           |
| policy_entropy     | 8.308961     |
| policy_loss        | -0.009021688 |
| serial_timesteps   | 6400         |
| time_elapsed       | 25.4         |
| total_timesteps    | 51200        |
| value_loss         | 0.033522747  |
-------------------------------------
-------------------------------------
| approxkl           | 0.005983419  |
| clipfrac           | 0.07314453   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.482        |
| fps                | 2024         |
| n_updates          | 26           |
| policy_entropy     | 8.2990265    |
| policy_loss        | -0.007894431 |
| serial_timesteps   | 6656         |
| time_elapsed       | 26.9         |
| total_timesteps    | 53248        |
| value_loss         | 0.06385331   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0081061255 |
| clipfrac           | 0.11513672   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.737        |
| fps                | 2136         |
| n_updates          | 27           |
| policy_entropy     | 8.294569     |
| policy_loss        | -0.01243413  |
| serial_timesteps   | 6912         |
| time_elapsed       | 27.9         |
| total_timesteps    | 55296        |
| value_loss         | 0.044089444  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0070340894 |
| clipfrac           | 0.0909668    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.713        |
| fps                | 2225         |
| n_updates          | 28           |
| policy_entropy     | 8.264256     |
| policy_loss        | -0.011493622 |
| serial_timesteps   | 7168         |
| time_elapsed       | 28.9         |
| total_timesteps    | 57344        |
| value_loss         | 0.025825491  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007903051  |
| clipfrac           | 0.10366211   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.68         |
| fps                | 2173         |
| n_updates          | 29           |
| policy_entropy     | 8.207088     |
| policy_loss        | -0.012790635 |
| serial_timesteps   | 7424         |
| time_elapsed       | 29.8         |
| total_timesteps    | 59392        |
| value_loss         | 0.030047562  |
-------------------------------------
Eval num_timesteps=60000, episode_reward=-2.18 +/- 0.74
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008252086  |
| clipfrac           | 0.1121582    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.688        |
| fps                | 1468         |
| n_updates          | 30           |
| policy_entropy     | 8.201967     |
| policy_loss        | -0.012957314 |
| serial_timesteps   | 7680         |
| time_elapsed       | 30.8         |
| total_timesteps    | 61440        |
| value_loss         | 0.026732441  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0067740353 |
| clipfrac           | 0.08598633   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.735        |
| fps                | 2106         |
| n_updates          | 31           |
| policy_entropy     | 8.197489     |
| policy_loss        | -0.010975183 |
| serial_timesteps   | 7936         |
| time_elapsed       | 32.2         |
| total_timesteps    | 63488        |
| value_loss         | 0.033564255  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009086234  |
| clipfrac           | 0.12817383   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.656        |
| fps                | 2064         |
| n_updates          | 32           |
| policy_entropy     | 8.188463     |
| policy_loss        | -0.014481036 |
| serial_timesteps   | 8192         |
| time_elapsed       | 33.1         |
| total_timesteps    | 65536        |
| value_loss         | 0.045813825  |
-------------------------------------
------------------------------------
| approxkl           | 0.008675044 |
| clipfrac           | 0.113134764 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.6        |
| explained_variance | 0.662       |
| fps                | 2095        |
| n_updates          | 33          |
| policy_entropy     | 8.183935    |
| policy_loss        | -0.01658887 |
| serial_timesteps   | 8448        |
| time_elapsed       | 34.1        |
| total_timesteps    | 67584       |
| value_loss         | 0.049372315 |
------------------------------------
-------------------------------------
| approxkl           | 0.009114774  |
| clipfrac           | 0.12675782   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.65        |
| explained_variance | 0.597        |
| fps                | 2011         |
| n_updates          | 34           |
| policy_entropy     | 8.159621     |
| policy_loss        | -0.011894925 |
| serial_timesteps   | 8704         |
| time_elapsed       | 35.1         |
| total_timesteps    | 69632        |
| value_loss         | 0.05477829   |
-------------------------------------
Eval num_timesteps=70000, episode_reward=-3.61 +/- 1.74
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008238727  |
| clipfrac           | 0.11674805   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.7         |
| explained_variance | 0.744        |
| fps                | 1360         |
| n_updates          | 35           |
| policy_entropy     | 8.144244     |
| policy_loss        | -0.012064211 |
| serial_timesteps   | 8960         |
| time_elapsed       | 36.1         |
| total_timesteps    | 71680        |
| value_loss         | 0.033293925  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008398175  |
| clipfrac           | 0.11757813   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.75        |
| explained_variance | 0.752        |
| fps                | 2013         |
| n_updates          | 36           |
| policy_entropy     | 8.141989     |
| policy_loss        | -0.015413973 |
| serial_timesteps   | 9216         |
| time_elapsed       | 37.6         |
| total_timesteps    | 73728        |
| value_loss         | 0.04420147   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007915219  |
| clipfrac           | 0.10688476   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.74        |
| explained_variance | 0.632        |
| fps                | 2006         |
| n_updates          | 37           |
| policy_entropy     | 8.143492     |
| policy_loss        | -0.012887964 |
| serial_timesteps   | 9472         |
| time_elapsed       | 38.6         |
| total_timesteps    | 75776        |
| value_loss         | 0.05054011   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008556323  |
| clipfrac           | 0.11489258   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.65        |
| explained_variance | 0.806        |
| fps                | 2153         |
| n_updates          | 38           |
| policy_entropy     | 8.129668     |
| policy_loss        | -0.012918058 |
| serial_timesteps   | 9728         |
| time_elapsed       | 39.7         |
| total_timesteps    | 77824        |
| value_loss         | 0.028117973  |
-------------------------------------
------------------------------------
| approxkl           | 0.007459654 |
| clipfrac           | 0.096142575 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.68       |
| explained_variance | 0.558       |
| fps                | 2161        |
| n_updates          | 39          |
| policy_entropy     | 8.114654    |
| policy_loss        | -0.01066486 |
| serial_timesteps   | 9984        |
| time_elapsed       | 40.6        |
| total_timesteps    | 79872       |
| value_loss         | 0.05885308  |
------------------------------------
Eval num_timesteps=80000, episode_reward=-2.30 +/- 1.41
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0068003265 |
| clipfrac           | 0.083544925  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.72        |
| explained_variance | 0.596        |
| fps                | 1423         |
| n_updates          | 40           |
| policy_entropy     | 8.105561     |
| policy_loss        | -0.008818012 |
| serial_timesteps   | 10240        |
| time_elapsed       | 41.6         |
| total_timesteps    | 81920        |
| value_loss         | 0.057185255  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0087114815 |
| clipfrac           | 0.12290039   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.67        |
| explained_variance | 0.69         |
| fps                | 2028         |
| n_updates          | 41           |
| policy_entropy     | 8.096914     |
| policy_loss        | -0.012740245 |
| serial_timesteps   | 10496        |
| time_elapsed       | 43           |
| total_timesteps    | 83968        |
| value_loss         | 0.029878551  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0089244265 |
| clipfrac           | 0.12700196   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | 0.584        |
| fps                | 2103         |
| n_updates          | 42           |
| policy_entropy     | 8.094005     |
| policy_loss        | -0.0136224   |
| serial_timesteps   | 10752        |
| time_elapsed       | 44           |
| total_timesteps    | 86016        |
| value_loss         | 0.052056663  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008738327  |
| clipfrac           | 0.12929687   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.564        |
| fps                | 2085         |
| n_updates          | 43           |
| policy_entropy     | 8.105112     |
| policy_loss        | -0.011213877 |
| serial_timesteps   | 11008        |
| time_elapsed       | 45           |
| total_timesteps    | 88064        |
| value_loss         | 0.0544905    |
-------------------------------------
Eval num_timesteps=90000, episode_reward=-2.89 +/- 1.80
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008288553  |
| clipfrac           | 0.11196289   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.602        |
| fps                | 1498         |
| n_updates          | 44           |
| policy_entropy     | 8.100833     |
| policy_loss        | -0.012743597 |
| serial_timesteps   | 11264        |
| time_elapsed       | 46           |
| total_timesteps    | 90112        |
| value_loss         | 0.044863783  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008810466  |
| clipfrac           | 0.12456055   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.44         |
| fps                | 2105         |
| n_updates          | 45           |
| policy_entropy     | 8.098498     |
| policy_loss        | -0.011221516 |
| serial_timesteps   | 11520        |
| time_elapsed       | 47.3         |
| total_timesteps    | 92160        |
| value_loss         | 0.08525944   |
-------------------------------------
--------------------------------------
| approxkl           | 0.006898211   |
| clipfrac           | 0.089990236   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.59         |
| explained_variance | 0.645         |
| fps                | 2126          |
| n_updates          | 46            |
| policy_entropy     | 8.082284      |
| policy_loss        | -0.0076140896 |
| serial_timesteps   | 11776         |
| time_elapsed       | 48.3          |
| total_timesteps    | 94208         |
| value_loss         | 0.039928548   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009361399  |
| clipfrac           | 0.13535157   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | 0.634        |
| fps                | 2172         |
| n_updates          | 47           |
| policy_entropy     | 8.062098     |
| policy_loss        | -0.011681381 |
| serial_timesteps   | 12032        |
| time_elapsed       | 49.3         |
| total_timesteps    | 96256        |
| value_loss         | 0.056540824  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009364543  |
| clipfrac           | 0.12792969   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.716        |
| fps                | 2141         |
| n_updates          | 48           |
| policy_entropy     | 8.056013     |
| policy_loss        | -0.015424853 |
| serial_timesteps   | 12288        |
| time_elapsed       | 50.2         |
| total_timesteps    | 98304        |
| value_loss         | 0.0299844    |
-------------------------------------
Eval num_timesteps=100000, episode_reward=-2.23 +/- 1.03
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008717417  |
| clipfrac           | 0.12539062   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.733        |
| fps                | 1497         |
| n_updates          | 49           |
| policy_entropy     | 8.039227     |
| policy_loss        | -0.013710278 |
| serial_timesteps   | 12544        |
| time_elapsed       | 51.2         |
| total_timesteps    | 100352       |
| value_loss         | 0.022997512  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008063385  |
| clipfrac           | 0.11235352   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.39        |
| explained_variance | 0.714        |
| fps                | 2203         |
| n_updates          | 50           |
| policy_entropy     | 8.026082     |
| policy_loss        | -0.009549565 |
| serial_timesteps   | 12800        |
| time_elapsed       | 52.5         |
| total_timesteps    | 102400       |
| value_loss         | 0.034130458  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0071056844 |
| clipfrac           | 0.091845706  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.702        |
| fps                | 2196         |
| n_updates          | 51           |
| policy_entropy     | 8.019302     |
| policy_loss        | -0.008607586 |
| serial_timesteps   | 13056        |
| time_elapsed       | 53.5         |
| total_timesteps    | 104448       |
| value_loss         | 0.037139453  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0076557347  |
| clipfrac           | 0.101464845   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.52         |
| explained_variance | 0.692         |
| fps                | 2119          |
| n_updates          | 52            |
| policy_entropy     | 8.004879      |
| policy_loss        | -0.0106054405 |
| serial_timesteps   | 13312         |
| time_elapsed       | 54.4          |
| total_timesteps    | 106496        |
| value_loss         | 0.051739298   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0076427124 |
| clipfrac           | 0.10317383   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.819        |
| fps                | 2151         |
| n_updates          | 53           |
| policy_entropy     | 7.9883475    |
| policy_loss        | -0.010170594 |
| serial_timesteps   | 13568        |
| time_elapsed       | 55.4         |
| total_timesteps    | 108544       |
| value_loss         | 0.02319059   |
-------------------------------------
Eval num_timesteps=110000, episode_reward=-1.56 +/- 0.65
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.00847505  |
| clipfrac           | 0.122363284 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.61       |
| explained_variance | 0.725       |
| fps                | 1570        |
| n_updates          | 54          |
| policy_entropy     | 7.996662    |
| policy_loss        | -0.01379365 |
| serial_timesteps   | 13824       |
| time_elapsed       | 56.3        |
| total_timesteps    | 110592      |
| value_loss         | 0.03442355  |
------------------------------------
------------------------------------
| approxkl           | 0.007982298 |
| clipfrac           | 0.10551758  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.62       |
| explained_variance | 0.822       |
| fps                | 2165        |
| n_updates          | 55          |
| policy_entropy     | 7.985438    |
| policy_loss        | -0.01343671 |
| serial_timesteps   | 14080       |
| time_elapsed       | 57.6        |
| total_timesteps    | 112640      |
| value_loss         | 0.015207922 |
------------------------------------
-------------------------------------
| approxkl           | 0.010936874  |
| clipfrac           | 0.15449218   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.737        |
| fps                | 2126         |
| n_updates          | 56           |
| policy_entropy     | 7.9466147    |
| policy_loss        | -0.015357268 |
| serial_timesteps   | 14336        |
| time_elapsed       | 58.6         |
| total_timesteps    | 114688       |
| value_loss         | 0.03350958   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008924468  |
| clipfrac           | 0.1237793    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.632        |
| fps                | 2157         |
| n_updates          | 57           |
| policy_entropy     | 7.9309516    |
| policy_loss        | -0.013546546 |
| serial_timesteps   | 14592        |
| time_elapsed       | 59.5         |
| total_timesteps    | 116736       |
| value_loss         | 0.036271535  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008761971  |
| clipfrac           | 0.12084961   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.72         |
| fps                | 2117         |
| n_updates          | 58           |
| policy_entropy     | 7.9457574    |
| policy_loss        | -0.014059397 |
| serial_timesteps   | 14848        |
| time_elapsed       | 60.5         |
| total_timesteps    | 118784       |
| value_loss         | 0.029047426  |
-------------------------------------
Eval num_timesteps=120000, episode_reward=-2.06 +/- 1.04
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0065360954 |
| clipfrac           | 0.08286133   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.699        |
| fps                | 1458         |
| n_updates          | 59           |
| policy_entropy     | 7.96927      |
| policy_loss        | -0.008156937 |
| serial_timesteps   | 15104        |
| time_elapsed       | 61.4         |
| total_timesteps    | 120832       |
| value_loss         | 0.034441732  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00874056   |
| clipfrac           | 0.12021484   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.707        |
| fps                | 2123         |
| n_updates          | 60           |
| policy_entropy     | 7.9418235    |
| policy_loss        | -0.014292653 |
| serial_timesteps   | 15360        |
| time_elapsed       | 62.8         |
| total_timesteps    | 122880       |
| value_loss         | 0.035850637  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007885797  |
| clipfrac           | 0.10566406   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.674        |
| fps                | 2139         |
| n_updates          | 61           |
| policy_entropy     | 7.9121575    |
| policy_loss        | -0.009916404 |
| serial_timesteps   | 15616        |
| time_elapsed       | 63.8         |
| total_timesteps    | 124928       |
| value_loss         | 0.042379282  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008550791  |
| clipfrac           | 0.11904297   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.772        |
| fps                | 2127         |
| n_updates          | 62           |
| policy_entropy     | 7.911218     |
| policy_loss        | -0.013477129 |
| serial_timesteps   | 15872        |
| time_elapsed       | 64.8         |
| total_timesteps    | 126976       |
| value_loss         | 0.021507068  |
-------------------------------------
------------------------------------
| approxkl           | 0.009673717 |
| clipfrac           | 0.14223632  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.5        |
| explained_variance | 0.781       |
| fps                | 2031        |
| n_updates          | 63          |
| policy_entropy     | 7.9145722   |
| policy_loss        | -0.01701265 |
| serial_timesteps   | 16128       |
| time_elapsed       | 65.7        |
| total_timesteps    | 129024      |
| value_loss         | 0.027201002 |
------------------------------------
Eval num_timesteps=130000, episode_reward=-2.00 +/- 0.84
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0065983296 |
| clipfrac           | 0.08154297   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.697        |
| fps                | 1484         |
| n_updates          | 64           |
| policy_entropy     | 7.8900437    |
| policy_loss        | -0.010410604 |
| serial_timesteps   | 16384        |
| time_elapsed       | 66.7         |
| total_timesteps    | 131072       |
| value_loss         | 0.026370347  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0092192115 |
| clipfrac           | 0.13520508   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.744        |
| fps                | 2154         |
| n_updates          | 65           |
| policy_entropy     | 7.870083     |
| policy_loss        | -0.013089143 |
| serial_timesteps   | 16640        |
| time_elapsed       | 68.1         |
| total_timesteps    | 133120       |
| value_loss         | 0.032632362  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009497411  |
| clipfrac           | 0.13662109   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.605        |
| fps                | 2157         |
| n_updates          | 66           |
| policy_entropy     | 7.8580537    |
| policy_loss        | -0.013766711 |
| serial_timesteps   | 16896        |
| time_elapsed       | 69.1         |
| total_timesteps    | 135168       |
| value_loss         | 0.04755997   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007808232  |
| clipfrac           | 0.10249023   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.673        |
| fps                | 2201         |
| n_updates          | 67           |
| policy_entropy     | 7.8461847    |
| policy_loss        | -0.010974032 |
| serial_timesteps   | 17152        |
| time_elapsed       | 70           |
| total_timesteps    | 137216       |
| value_loss         | 0.041586198  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010129666  |
| clipfrac           | 0.14404297   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.844        |
| fps                | 2099         |
| n_updates          | 68           |
| policy_entropy     | 7.8187447    |
| policy_loss        | -0.015616442 |
| serial_timesteps   | 17408        |
| time_elapsed       | 71           |
| total_timesteps    | 139264       |
| value_loss         | 0.02261303   |
-------------------------------------
Eval num_timesteps=140000, episode_reward=-2.39 +/- 0.97
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.008920437 |
| clipfrac           | 0.12524414  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.48       |
| explained_variance | 0.791       |
| fps                | 1563        |
| n_updates          | 69          |
| policy_entropy     | 7.8179283   |
| policy_loss        | -0.01236859 |
| serial_timesteps   | 17664       |
| time_elapsed       | 71.9        |
| total_timesteps    | 141312      |
| value_loss         | 0.025291482 |
------------------------------------
-------------------------------------
| approxkl           | 0.008929342  |
| clipfrac           | 0.12495117   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.803        |
| fps                | 2184         |
| n_updates          | 70           |
| policy_entropy     | 7.847142     |
| policy_loss        | -0.013422887 |
| serial_timesteps   | 17920        |
| time_elapsed       | 73.2         |
| total_timesteps    | 143360       |
| value_loss         | 0.035721827  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009177976  |
| clipfrac           | 0.12451172   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.743        |
| fps                | 2170         |
| n_updates          | 71           |
| policy_entropy     | 7.848526     |
| policy_loss        | -0.012961896 |
| serial_timesteps   | 18176        |
| time_elapsed       | 74.2         |
| total_timesteps    | 145408       |
| value_loss         | 0.038483243  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008462125  |
| clipfrac           | 0.114794925  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.819        |
| fps                | 2157         |
| n_updates          | 72           |
| policy_entropy     | 7.821191     |
| policy_loss        | -0.012450597 |
| serial_timesteps   | 18432        |
| time_elapsed       | 75.1         |
| total_timesteps    | 147456       |
| value_loss         | 0.027756464  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00837453   |
| clipfrac           | 0.1171875    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.613        |
| fps                | 2210         |
| n_updates          | 73           |
| policy_entropy     | 7.7922297    |
| policy_loss        | -0.010255136 |
| serial_timesteps   | 18688        |
| time_elapsed       | 76.1         |
| total_timesteps    | 149504       |
| value_loss         | 0.04482861   |
-------------------------------------
Eval num_timesteps=150000, episode_reward=-1.28 +/- 0.49
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.008801965  |
| clipfrac           | 0.12202148   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.742        |
| fps                | 1518         |
| n_updates          | 74           |
| policy_entropy     | 7.7929726    |
| policy_loss        | -0.011947777 |
| serial_timesteps   | 18944        |
| time_elapsed       | 77           |
| total_timesteps    | 151552       |
| value_loss         | 0.039349157  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0095630735 |
| clipfrac           | 0.13139649   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.82         |
| fps                | 2147         |
| n_updates          | 75           |
| policy_entropy     | 7.7960067    |
| policy_loss        | -0.013842143 |
| serial_timesteps   | 19200        |
| time_elapsed       | 78.3         |
| total_timesteps    | 153600       |
| value_loss         | 0.019604374  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008476723  |
| clipfrac           | 0.11826172   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.705        |
| fps                | 2143         |
| n_updates          | 76           |
| policy_entropy     | 7.7939453    |
| policy_loss        | -0.013088135 |
| serial_timesteps   | 19456        |
| time_elapsed       | 79.3         |
| total_timesteps    | 155648       |
| value_loss         | 0.039689843  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0073539913 |
| clipfrac           | 0.09804688   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.707        |
| fps                | 2123         |
| n_updates          | 77           |
| policy_entropy     | 7.80085      |
| policy_loss        | -0.010577744 |
| serial_timesteps   | 19712        |
| time_elapsed       | 80.3         |
| total_timesteps    | 157696       |
| value_loss         | 0.031255644  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009103729  |
| clipfrac           | 0.12158203   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.56         |
| fps                | 2163         |
| n_updates          | 78           |
| policy_entropy     | 7.796344     |
| policy_loss        | -0.013734902 |
| serial_timesteps   | 19968        |
| time_elapsed       | 81.2         |
| total_timesteps    | 159744       |
| value_loss         | 0.034811977  |
-------------------------------------
Eval num_timesteps=160000, episode_reward=-1.71 +/- 0.87
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010156423  |
| clipfrac           | 0.14765625   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.721        |
| fps                | 1439         |
| n_updates          | 79           |
| policy_entropy     | 7.7873206    |
| policy_loss        | -0.013977444 |
| serial_timesteps   | 20224        |
| time_elapsed       | 82.2         |
| total_timesteps    | 161792       |
| value_loss         | 0.035509273  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008886481  |
| clipfrac           | 0.12290039   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.523        |
| fps                | 2097         |
| n_updates          | 80           |
| policy_entropy     | 7.7956047    |
| policy_loss        | -0.012352902 |
| serial_timesteps   | 20480        |
| time_elapsed       | 83.6         |
| total_timesteps    | 163840       |
| value_loss         | 0.049799073  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008312431  |
| clipfrac           | 0.114550784  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.667        |
| fps                | 2091         |
| n_updates          | 81           |
| policy_entropy     | 7.809588     |
| policy_loss        | -0.009506671 |
| serial_timesteps   | 20736        |
| time_elapsed       | 84.6         |
| total_timesteps    | 165888       |
| value_loss         | 0.03335906   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077591324 |
| clipfrac           | 0.10727539   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.658        |
| fps                | 2045         |
| n_updates          | 82           |
| policy_entropy     | 7.817529     |
| policy_loss        | -0.012348149 |
| serial_timesteps   | 20992        |
| time_elapsed       | 85.5         |
| total_timesteps    | 167936       |
| value_loss         | 0.036002353  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008200245  |
| clipfrac           | 0.107617185  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.655        |
| fps                | 2098         |
| n_updates          | 83           |
| policy_entropy     | 7.8072424    |
| policy_loss        | -0.011615405 |
| serial_timesteps   | 21248        |
| time_elapsed       | 86.5         |
| total_timesteps    | 169984       |
| value_loss         | 0.039366905  |
-------------------------------------
Eval num_timesteps=170000, episode_reward=-2.51 +/- 1.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.00788185   |
| clipfrac           | 0.10776367   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | 0.728        |
| fps                | 1527         |
| n_updates          | 84           |
| policy_entropy     | 7.80482      |
| policy_loss        | -0.011328002 |
| serial_timesteps   | 21504        |
| time_elapsed       | 87.5         |
| total_timesteps    | 172032       |
| value_loss         | 0.034425896  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009535946  |
| clipfrac           | 0.13139649   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.753        |
| fps                | 2217         |
| n_updates          | 85           |
| policy_entropy     | 7.779142     |
| policy_loss        | -0.014597215 |
| serial_timesteps   | 21760        |
| time_elapsed       | 88.9         |
| total_timesteps    | 174080       |
| value_loss         | 0.02840067   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008428433  |
| clipfrac           | 0.11796875   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.609        |
| fps                | 2171         |
| n_updates          | 86           |
| policy_entropy     | 7.7548547    |
| policy_loss        | -0.009226798 |
| serial_timesteps   | 22016        |
| time_elapsed       | 89.8         |
| total_timesteps    | 176128       |
| value_loss         | 0.053458653  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009011881  |
| clipfrac           | 0.12978515   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.643        |
| fps                | 2151         |
| n_updates          | 87           |
| policy_entropy     | 7.7400618    |
| policy_loss        | -0.013746208 |
| serial_timesteps   | 22272        |
| time_elapsed       | 90.7         |
| total_timesteps    | 178176       |
| value_loss         | 0.04442135   |
-------------------------------------
Eval num_timesteps=180000, episode_reward=-2.63 +/- 0.61
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.00739964    |
| clipfrac           | 0.09697266    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.59         |
| explained_variance | 0.703         |
| fps                | 1539          |
| n_updates          | 88            |
| policy_entropy     | 7.7121115     |
| policy_loss        | -0.0104593495 |
| serial_timesteps   | 22528         |
| time_elapsed       | 91.7          |
| total_timesteps    | 180224        |
| value_loss         | 0.040643547   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0073987283 |
| clipfrac           | 0.099169925  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.75         |
| fps                | 2196         |
| n_updates          | 89           |
| policy_entropy     | 7.694915     |
| policy_loss        | -0.009928952 |
| serial_timesteps   | 22784        |
| time_elapsed       | 93           |
| total_timesteps    | 182272       |
| value_loss         | 0.027401427  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0098774275 |
| clipfrac           | 0.13847657   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.801        |
| fps                | 2231         |
| n_updates          | 90           |
| policy_entropy     | 7.664398     |
| policy_loss        | -0.016441267 |
| serial_timesteps   | 23040        |
| time_elapsed       | 93.9         |
| total_timesteps    | 184320       |
| value_loss         | 0.025221357  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008256469  |
| clipfrac           | 0.111572266  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.667        |
| fps                | 2166         |
| n_updates          | 91           |
| policy_entropy     | 7.615718     |
| policy_loss        | -0.011636602 |
| serial_timesteps   | 23296        |
| time_elapsed       | 94.9         |
| total_timesteps    | 186368       |
| value_loss         | 0.044688303  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009633001  |
| clipfrac           | 0.12817383   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.74        |
| explained_variance | 0.787        |
| fps                | 2226         |
| n_updates          | 92           |
| policy_entropy     | 7.5836663    |
| policy_loss        | -0.015811246 |
| serial_timesteps   | 23552        |
| time_elapsed       | 95.8         |
| total_timesteps    | 188416       |
| value_loss         | 0.025650006  |
-------------------------------------
Eval num_timesteps=190000, episode_reward=-2.02 +/- 0.82
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0075316853 |
| clipfrac           | 0.1046875    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.722        |
| fps                | 1521         |
| n_updates          | 93           |
| policy_entropy     | 7.5707693    |
| policy_loss        | -0.010330499 |
| serial_timesteps   | 23808        |
| time_elapsed       | 96.7         |
| total_timesteps    | 190464       |
| value_loss         | 0.037381545  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0068619223 |
| clipfrac           | 0.08798828   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.72        |
| explained_variance | 0.704        |
| fps                | 2175         |
| n_updates          | 94           |
| policy_entropy     | 7.5598807    |
| policy_loss        | -0.009455286 |
| serial_timesteps   | 24064        |
| time_elapsed       | 98.1         |
| total_timesteps    | 192512       |
| value_loss         | 0.052354712  |
-------------------------------------
------------------------------------
| approxkl           | 0.010614738 |
| clipfrac           | 0.15092774  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.76       |
| explained_variance | 0.804       |
| fps                | 2111        |
| n_updates          | 95          |
| policy_entropy     | 7.567052    |
| policy_loss        | -0.01357353 |
| serial_timesteps   | 24320       |
| time_elapsed       | 99          |
| total_timesteps    | 194560      |
| value_loss         | 0.043032307 |
------------------------------------
-------------------------------------
| approxkl           | 0.0074367314 |
| clipfrac           | 0.09907226   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.75        |
| explained_variance | 0.693        |
| fps                | 2212         |
| n_updates          | 96           |
| policy_entropy     | 7.5726266    |
| policy_loss        | -0.010663976 |
| serial_timesteps   | 24576        |
| time_elapsed       | 100          |
| total_timesteps    | 196608       |
| value_loss         | 0.047126144  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008402068  |
| clipfrac           | 0.11508789   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.857        |
| fps                | 2199         |
| n_updates          | 97           |
| policy_entropy     | 7.558873     |
| policy_loss        | -0.011883057 |
| serial_timesteps   | 24832        |
| time_elapsed       | 101          |
| total_timesteps    | 198656       |
| value_loss         | 0.021642648  |
-------------------------------------
Eval num_timesteps=200000, episode_reward=-1.73 +/- 0.59
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008102907  |
| clipfrac           | 0.111328125  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.771        |
| fps                | 1559         |
| n_updates          | 98           |
| policy_entropy     | 7.5509424    |
| policy_loss        | -0.011950016 |
| serial_timesteps   | 25088        |
| time_elapsed       | 102          |
| total_timesteps    | 200704       |
| value_loss         | 0.026790664  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0075358404 |
| clipfrac           | 0.09541015   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.855        |
| fps                | 2183         |
| n_updates          | 99           |
| policy_entropy     | 7.5061464    |
| policy_loss        | -0.010747422 |
| serial_timesteps   | 25344        |
| time_elapsed       | 103          |
| total_timesteps    | 202752       |
| value_loss         | 0.02024006   |
-------------------------------------
------------------------------------
| approxkl           | 0.008667705 |
| clipfrac           | 0.118457034 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.4        |
| explained_variance | 0.705       |
| fps                | 2189        |
| n_updates          | 100         |
| policy_entropy     | 7.480508    |
| policy_loss        | -0.0118514  |
| serial_timesteps   | 25600       |
| time_elapsed       | 104         |
| total_timesteps    | 204800      |
| value_loss         | 0.044082783 |
------------------------------------
-------------------------------------
| approxkl           | 0.007270948  |
| clipfrac           | 0.09423828   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.74         |
| fps                | 2161         |
| n_updates          | 101          |
| policy_entropy     | 7.4892664    |
| policy_loss        | -0.008479135 |
| serial_timesteps   | 25856        |
| time_elapsed       | 105          |
| total_timesteps    | 206848       |
| value_loss         | 0.032803167  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009975025  |
| clipfrac           | 0.13808593   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.745        |
| fps                | 2157         |
| n_updates          | 102          |
| policy_entropy     | 7.499486     |
| policy_loss        | -0.014305656 |
| serial_timesteps   | 26112        |
| time_elapsed       | 106          |
| total_timesteps    | 208896       |
| value_loss         | 0.043453325  |
-------------------------------------
Eval num_timesteps=210000, episode_reward=-1.71 +/- 0.97
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008010515  |
| clipfrac           | 0.11166992   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.751        |
| fps                | 1530         |
| n_updates          | 103          |
| policy_entropy     | 7.5097976    |
| policy_loss        | -0.010246579 |
| serial_timesteps   | 26368        |
| time_elapsed       | 107          |
| total_timesteps    | 210944       |
| value_loss         | 0.038390633  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008444851  |
| clipfrac           | 0.11352539   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | 0.767        |
| fps                | 2193         |
| n_updates          | 104          |
| policy_entropy     | 7.5169473    |
| policy_loss        | -0.011989665 |
| serial_timesteps   | 26624        |
| time_elapsed       | 108          |
| total_timesteps    | 212992       |
| value_loss         | 0.038525842  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00903695   |
| clipfrac           | 0.13100585   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.74         |
| fps                | 2199         |
| n_updates          | 105          |
| policy_entropy     | 7.516017     |
| policy_loss        | -0.011875654 |
| serial_timesteps   | 26880        |
| time_elapsed       | 109          |
| total_timesteps    | 215040       |
| value_loss         | 0.043232564  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009586791  |
| clipfrac           | 0.13603516   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.797        |
| fps                | 2203         |
| n_updates          | 106          |
| policy_entropy     | 7.5030837    |
| policy_loss        | -0.013545292 |
| serial_timesteps   | 27136        |
| time_elapsed       | 110          |
| total_timesteps    | 217088       |
| value_loss         | 0.038193837  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010313052  |
| clipfrac           | 0.15200195   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.831        |
| fps                | 2197         |
| n_updates          | 107          |
| policy_entropy     | 7.5000944    |
| policy_loss        | -0.014579492 |
| serial_timesteps   | 27392        |
| time_elapsed       | 111          |
| total_timesteps    | 219136       |
| value_loss         | 0.026941419  |
-------------------------------------
Eval num_timesteps=220000, episode_reward=-1.72 +/- 0.29
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009708576  |
| clipfrac           | 0.122998044  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | 0.794        |
| fps                | 1535         |
| n_updates          | 108          |
| policy_entropy     | 7.5165315    |
| policy_loss        | -0.016829766 |
| serial_timesteps   | 27648        |
| time_elapsed       | 112          |
| total_timesteps    | 221184       |
| value_loss         | 0.039319504  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009343008  |
| clipfrac           | 0.1309082    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | 0.815        |
| fps                | 2221         |
| n_updates          | 109          |
| policy_entropy     | 7.518897     |
| policy_loss        | -0.013513173 |
| serial_timesteps   | 27904        |
| time_elapsed       | 113          |
| total_timesteps    | 223232       |
| value_loss         | 0.043620832  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007342159  |
| clipfrac           | 0.09482422   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.817        |
| fps                | 2135         |
| n_updates          | 110          |
| policy_entropy     | 7.50242      |
| policy_loss        | -0.007823053 |
| serial_timesteps   | 28160        |
| time_elapsed       | 114          |
| total_timesteps    | 225280       |
| value_loss         | 0.041920863  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008900663  |
| clipfrac           | 0.12685546   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.846        |
| fps                | 2248         |
| n_updates          | 111          |
| policy_entropy     | 7.4974146    |
| policy_loss        | -0.012082657 |
| serial_timesteps   | 28416        |
| time_elapsed       | 115          |
| total_timesteps    | 227328       |
| value_loss         | 0.032622416  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008897891   |
| clipfrac           | 0.12563476    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.6          |
| explained_variance | 0.809         |
| fps                | 2222          |
| n_updates          | 112           |
| policy_entropy     | 7.4962206     |
| policy_loss        | -0.0114027485 |
| serial_timesteps   | 28672         |
| time_elapsed       | 116           |
| total_timesteps    | 229376        |
| value_loss         | 0.03604734    |
--------------------------------------
Eval num_timesteps=230000, episode_reward=-1.57 +/- 0.86
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.00821669   |
| clipfrac           | 0.11274414   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.814        |
| fps                | 1490         |
| n_updates          | 113          |
| policy_entropy     | 7.470703     |
| policy_loss        | -0.011237051 |
| serial_timesteps   | 28928        |
| time_elapsed       | 117          |
| total_timesteps    | 231424       |
| value_loss         | 0.034315825  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0073789256 |
| clipfrac           | 0.09428711   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | 0.748        |
| fps                | 2083         |
| n_updates          | 114          |
| policy_entropy     | 7.4389687    |
| policy_loss        | -0.009214501 |
| serial_timesteps   | 29184        |
| time_elapsed       | 118          |
| total_timesteps    | 233472       |
| value_loss         | 0.033010993  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009573113  |
| clipfrac           | 0.13828126   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.75         |
| fps                | 2193         |
| n_updates          | 115          |
| policy_entropy     | 7.413349     |
| policy_loss        | -0.013317387 |
| serial_timesteps   | 29440        |
| time_elapsed       | 119          |
| total_timesteps    | 235520       |
| value_loss         | 0.038952198  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009354329  |
| clipfrac           | 0.13666992   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.82         |
| fps                | 2173         |
| n_updates          | 116          |
| policy_entropy     | 7.390235     |
| policy_loss        | -0.013363478 |
| serial_timesteps   | 29696        |
| time_elapsed       | 120          |
| total_timesteps    | 237568       |
| value_loss         | 0.022609401  |
-------------------------------------
-------------------------------------
| approxkl           | 0.012210615  |
| clipfrac           | 0.13408203   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | 0.698        |
| fps                | 2208         |
| n_updates          | 117          |
| policy_entropy     | 7.3951936    |
| policy_loss        | -0.015987631 |
| serial_timesteps   | 29952        |
| time_elapsed       | 121          |
| total_timesteps    | 239616       |
| value_loss         | 0.044450633  |
-------------------------------------
Eval num_timesteps=240000, episode_reward=-0.90 +/- 0.50
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.00827476   |
| clipfrac           | 0.115917966  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.805        |
| fps                | 1511         |
| n_updates          | 118          |
| policy_entropy     | 7.40528      |
| policy_loss        | -0.012557099 |
| serial_timesteps   | 30208        |
| time_elapsed       | 122          |
| total_timesteps    | 241664       |
| value_loss         | 0.030623447  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009545842  |
| clipfrac           | 0.1395996    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.732        |
| fps                | 2204         |
| n_updates          | 119          |
| policy_entropy     | 7.3947167    |
| policy_loss        | -0.015651375 |
| serial_timesteps   | 30464        |
| time_elapsed       | 124          |
| total_timesteps    | 243712       |
| value_loss         | 0.040445015  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007864468  |
| clipfrac           | 0.10136719   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.881        |
| fps                | 2208         |
| n_updates          | 120          |
| policy_entropy     | 7.391089     |
| policy_loss        | -0.010080409 |
| serial_timesteps   | 30720        |
| time_elapsed       | 124          |
| total_timesteps    | 245760       |
| value_loss         | 0.019298423  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010094238  |
| clipfrac           | 0.1390625    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.769        |
| fps                | 2182         |
| n_updates          | 121          |
| policy_entropy     | 7.3927       |
| policy_loss        | -0.017258406 |
| serial_timesteps   | 30976        |
| time_elapsed       | 125          |
| total_timesteps    | 247808       |
| value_loss         | 0.037114345  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008314041  |
| clipfrac           | 0.10854492   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.832        |
| fps                | 2160         |
| n_updates          | 122          |
| policy_entropy     | 7.360489     |
| policy_loss        | -0.010014889 |
| serial_timesteps   | 31232        |
| time_elapsed       | 126          |
| total_timesteps    | 249856       |
| value_loss         | 0.035864867  |
-------------------------------------
Eval num_timesteps=250000, episode_reward=-1.52 +/- 0.72
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007908901  |
| clipfrac           | 0.10019531   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.739        |
| fps                | 1563         |
| n_updates          | 123          |
| policy_entropy     | 7.2961373    |
| policy_loss        | -0.009117146 |
| serial_timesteps   | 31488        |
| time_elapsed       | 127          |
| total_timesteps    | 251904       |
| value_loss         | 0.049547236  |
-------------------------------------
------------------------------------
| approxkl           | 0.008736614 |
| clipfrac           | 0.12158203  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.69       |
| explained_variance | 0.806       |
| fps                | 2234        |
| n_updates          | 124         |
| policy_entropy     | 7.2459574   |
| policy_loss        | -0.01311118 |
| serial_timesteps   | 31744       |
| time_elapsed       | 129         |
| total_timesteps    | 253952      |
| value_loss         | 0.030546755 |
------------------------------------
-------------------------------------
| approxkl           | 0.008460405  |
| clipfrac           | 0.1046875    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.765        |
| fps                | 2211         |
| n_updates          | 125          |
| policy_entropy     | 7.231488     |
| policy_loss        | -0.010592995 |
| serial_timesteps   | 32000        |
| time_elapsed       | 130          |
| total_timesteps    | 256000       |
| value_loss         | 0.04287722   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009421378  |
| clipfrac           | 0.13095704   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.807        |
| fps                | 2096         |
| n_updates          | 126          |
| policy_entropy     | 7.219077     |
| policy_loss        | -0.012948746 |
| serial_timesteps   | 32256        |
| time_elapsed       | 130          |
| total_timesteps    | 258048       |
| value_loss         | 0.028734427  |
-------------------------------------
Eval num_timesteps=260000, episode_reward=-1.73 +/- 0.75
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009610264  |
| clipfrac           | 0.13867188   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.857        |
| fps                | 1569         |
| n_updates          | 127          |
| policy_entropy     | 7.1986756    |
| policy_loss        | -0.010294228 |
| serial_timesteps   | 32512        |
| time_elapsed       | 131          |
| total_timesteps    | 260096       |
| value_loss         | 0.023208585  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009755751  |
| clipfrac           | 0.12939453   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.733        |
| fps                | 2211         |
| n_updates          | 128          |
| policy_entropy     | 7.16892      |
| policy_loss        | -0.011482824 |
| serial_timesteps   | 32768        |
| time_elapsed       | 133          |
| total_timesteps    | 262144       |
| value_loss         | 0.034454476  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0101432605 |
| clipfrac           | 0.1421875    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.826        |
| fps                | 2198         |
| n_updates          | 129          |
| policy_entropy     | 7.1613626    |
| policy_loss        | -0.015442883 |
| serial_timesteps   | 33024        |
| time_elapsed       | 134          |
| total_timesteps    | 264192       |
| value_loss         | 0.029661596  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010311951  |
| clipfrac           | 0.14389649   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.861        |
| fps                | 2189         |
| n_updates          | 130          |
| policy_entropy     | 7.17298      |
| policy_loss        | -0.014612715 |
| serial_timesteps   | 33280        |
| time_elapsed       | 135          |
| total_timesteps    | 266240       |
| value_loss         | 0.02081764   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009885596  |
| clipfrac           | 0.1394043    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.785        |
| fps                | 2187         |
| n_updates          | 131          |
| policy_entropy     | 7.1967635    |
| policy_loss        | -0.011295365 |
| serial_timesteps   | 33536        |
| time_elapsed       | 136          |
| total_timesteps    | 268288       |
| value_loss         | 0.0429376    |
-------------------------------------
Eval num_timesteps=270000, episode_reward=-2.87 +/- 0.71
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008106878  |
| clipfrac           | 0.107470706  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.711        |
| fps                | 1524         |
| n_updates          | 132          |
| policy_entropy     | 7.196223     |
| policy_loss        | -0.009160312 |
| serial_timesteps   | 33792        |
| time_elapsed       | 136          |
| total_timesteps    | 270336       |
| value_loss         | 0.042859357  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008629724  |
| clipfrac           | 0.1203125    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.811        |
| fps                | 2183         |
| n_updates          | 133          |
| policy_entropy     | 7.164355     |
| policy_loss        | -0.010131695 |
| serial_timesteps   | 34048        |
| time_elapsed       | 138          |
| total_timesteps    | 272384       |
| value_loss         | 0.03129772   |
-------------------------------------
------------------------------------
| approxkl           | 0.008354389 |
| clipfrac           | 0.11513672  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.49       |
| explained_variance | 0.824       |
| fps                | 2166        |
| n_updates          | 134         |
| policy_entropy     | 7.138459    |
| policy_loss        | -0.00903155 |
| serial_timesteps   | 34304       |
| time_elapsed       | 139         |
| total_timesteps    | 274432      |
| value_loss         | 0.02768771  |
------------------------------------
-------------------------------------
| approxkl           | 0.007965669  |
| clipfrac           | 0.10957031   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.688        |
| fps                | 2222         |
| n_updates          | 135          |
| policy_entropy     | 7.1190176    |
| policy_loss        | -0.009550212 |
| serial_timesteps   | 34560        |
| time_elapsed       | 140          |
| total_timesteps    | 276480       |
| value_loss         | 0.04173333   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009583482  |
| clipfrac           | 0.1324707    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.831        |
| fps                | 2255         |
| n_updates          | 136          |
| policy_entropy     | 7.09431      |
| policy_loss        | -0.010496704 |
| serial_timesteps   | 34816        |
| time_elapsed       | 141          |
| total_timesteps    | 278528       |
| value_loss         | 0.02337857   |
-------------------------------------
Eval num_timesteps=280000, episode_reward=-2.65 +/- 0.59
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009511892  |
| clipfrac           | 0.13222656   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.784        |
| fps                | 1585         |
| n_updates          | 137          |
| policy_entropy     | 7.075157     |
| policy_loss        | -0.009307974 |
| serial_timesteps   | 35072        |
| time_elapsed       | 142          |
| total_timesteps    | 280576       |
| value_loss         | 0.034393568  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009352585  |
| clipfrac           | 0.12783203   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.783        |
| fps                | 2199         |
| n_updates          | 138          |
| policy_entropy     | 7.063225     |
| policy_loss        | -0.011052743 |
| serial_timesteps   | 35328        |
| time_elapsed       | 143          |
| total_timesteps    | 282624       |
| value_loss         | 0.04175757   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008397395  |
| clipfrac           | 0.11640625   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.767        |
| fps                | 2257         |
| n_updates          | 139          |
| policy_entropy     | 7.0381866    |
| policy_loss        | -0.010938807 |
| serial_timesteps   | 35584        |
| time_elapsed       | 144          |
| total_timesteps    | 284672       |
| value_loss         | 0.03337191   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007289567  |
| clipfrac           | 0.099169925  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.856        |
| fps                | 2255         |
| n_updates          | 140          |
| policy_entropy     | 7.012784     |
| policy_loss        | -0.009097759 |
| serial_timesteps   | 35840        |
| time_elapsed       | 145          |
| total_timesteps    | 286720       |
| value_loss         | 0.02760005   |
-------------------------------------
------------------------------------
| approxkl           | 0.007079856 |
| clipfrac           | 0.09047852  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.57       |
| explained_variance | 0.797       |
| fps                | 2189        |
| n_updates          | 141         |
| policy_entropy     | 6.99714     |
| policy_loss        | -0.00886646 |
| serial_timesteps   | 36096       |
| time_elapsed       | 146         |
| total_timesteps    | 288768      |
| value_loss         | 0.032945294 |
------------------------------------
Eval num_timesteps=290000, episode_reward=-1.36 +/- 0.89
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008762094  |
| clipfrac           | 0.12138672   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.728        |
| fps                | 1538         |
| n_updates          | 142          |
| policy_entropy     | 6.987546     |
| policy_loss        | -0.013197215 |
| serial_timesteps   | 36352        |
| time_elapsed       | 147          |
| total_timesteps    | 290816       |
| value_loss         | 0.04524566   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008993031  |
| clipfrac           | 0.12539062   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.853        |
| fps                | 2164         |
| n_updates          | 143          |
| policy_entropy     | 6.9800973    |
| policy_loss        | -0.012377246 |
| serial_timesteps   | 36608        |
| time_elapsed       | 148          |
| total_timesteps    | 292864       |
| value_loss         | 0.022226214  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077784373 |
| clipfrac           | 0.10727539   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.801        |
| fps                | 2210         |
| n_updates          | 144          |
| policy_entropy     | 6.9610596    |
| policy_loss        | -0.007639627 |
| serial_timesteps   | 36864        |
| time_elapsed       | 149          |
| total_timesteps    | 294912       |
| value_loss         | 0.030185431  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008176862  |
| clipfrac           | 0.11074219   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.828        |
| fps                | 2235         |
| n_updates          | 145          |
| policy_entropy     | 6.950129     |
| policy_loss        | -0.009079935 |
| serial_timesteps   | 37120        |
| time_elapsed       | 150          |
| total_timesteps    | 296960       |
| value_loss         | 0.03585743   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009747637  |
| clipfrac           | 0.13496093   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.825        |
| fps                | 2141         |
| n_updates          | 146          |
| policy_entropy     | 6.920484     |
| policy_loss        | -0.012826214 |
| serial_timesteps   | 37376        |
| time_elapsed       | 151          |
| total_timesteps    | 299008       |
| value_loss         | 0.027982702  |
-------------------------------------
Eval num_timesteps=300000, episode_reward=-1.51 +/- 0.42
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0091194315 |
| clipfrac           | 0.13051757   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.824        |
| fps                | 1569         |
| n_updates          | 147          |
| policy_entropy     | 6.8909707    |
| policy_loss        | -0.01449019  |
| serial_timesteps   | 37632        |
| time_elapsed       | 152          |
| total_timesteps    | 301056       |
| value_loss         | 0.03542571   |
-------------------------------------
--------------------------------------
| approxkl           | 0.008034965   |
| clipfrac           | 0.112695314   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.56         |
| explained_variance | 0.762         |
| fps                | 2188          |
| n_updates          | 148           |
| policy_entropy     | 6.883686      |
| policy_loss        | -0.0071249967 |
| serial_timesteps   | 37888         |
| time_elapsed       | 153           |
| total_timesteps    | 303104        |
| value_loss         | 0.039184324   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008432495  |
| clipfrac           | 0.11772461   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.881        |
| fps                | 2235         |
| n_updates          | 149          |
| policy_entropy     | 6.879345     |
| policy_loss        | -0.010216719 |
| serial_timesteps   | 38144        |
| time_elapsed       | 154          |
| total_timesteps    | 305152       |
| value_loss         | 0.022408921  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009252068  |
| clipfrac           | 0.1315918    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.798        |
| fps                | 2200         |
| n_updates          | 150          |
| policy_entropy     | 6.8814607    |
| policy_loss        | -0.010213015 |
| serial_timesteps   | 38400        |
| time_elapsed       | 155          |
| total_timesteps    | 307200       |
| value_loss         | 0.03691002   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008860811  |
| clipfrac           | 0.123242185  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.788        |
| fps                | 2237         |
| n_updates          | 151          |
| policy_entropy     | 6.8818474    |
| policy_loss        | -0.011649853 |
| serial_timesteps   | 38656        |
| time_elapsed       | 156          |
| total_timesteps    | 309248       |
| value_loss         | 0.03256859   |
-------------------------------------
Eval num_timesteps=310000, episode_reward=-1.41 +/- 0.65
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010414301  |
| clipfrac           | 0.14414063   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.853        |
| fps                | 1565         |
| n_updates          | 152          |
| policy_entropy     | 6.892633     |
| policy_loss        | -0.014479011 |
| serial_timesteps   | 38912        |
| time_elapsed       | 157          |
| total_timesteps    | 311296       |
| value_loss         | 0.02435161   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0075991154 |
| clipfrac           | 0.10341797   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.857        |
| fps                | 2232         |
| n_updates          | 153          |
| policy_entropy     | 6.9019547    |
| policy_loss        | -0.007593537 |
| serial_timesteps   | 39168        |
| time_elapsed       | 158          |
| total_timesteps    | 313344       |
| value_loss         | 0.019353472  |
-------------------------------------
--------------------------------------
| approxkl           | 0.00981687    |
| clipfrac           | 0.14248046    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.51         |
| explained_variance | 0.843         |
| fps                | 2213          |
| n_updates          | 154           |
| policy_entropy     | 6.8808694     |
| policy_loss        | -0.0136922095 |
| serial_timesteps   | 39424         |
| time_elapsed       | 159           |
| total_timesteps    | 315392        |
| value_loss         | 0.029834276   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0089194495 |
| clipfrac           | 0.12519531   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.746        |
| fps                | 2230         |
| n_updates          | 155          |
| policy_entropy     | 6.882239     |
| policy_loss        | -0.009268377 |
| serial_timesteps   | 39680        |
| time_elapsed       | 160          |
| total_timesteps    | 317440       |
| value_loss         | 0.04147863   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009131576  |
| clipfrac           | 0.13310547   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.842        |
| fps                | 2244         |
| n_updates          | 156          |
| policy_entropy     | 6.8809037    |
| policy_loss        | -0.011960708 |
| serial_timesteps   | 39936        |
| time_elapsed       | 161          |
| total_timesteps    | 319488       |
| value_loss         | 0.03324067   |
-------------------------------------
Eval num_timesteps=320000, episode_reward=-1.53 +/- 0.40
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009461949  |
| clipfrac           | 0.1265625    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.838        |
| fps                | 1572         |
| n_updates          | 157          |
| policy_entropy     | 6.8529043    |
| policy_loss        | -0.011630727 |
| serial_timesteps   | 40192        |
| time_elapsed       | 162          |
| total_timesteps    | 321536       |
| value_loss         | 0.028518477  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009147729   |
| clipfrac           | 0.12871094    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.52         |
| explained_variance | 0.814         |
| fps                | 2197          |
| n_updates          | 158           |
| policy_entropy     | 6.8382673     |
| policy_loss        | -0.0095698405 |
| serial_timesteps   | 40448         |
| time_elapsed       | 163           |
| total_timesteps    | 323584        |
| value_loss         | 0.038278025   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009115203  |
| clipfrac           | 0.13061523   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.788        |
| fps                | 2189         |
| n_updates          | 159          |
| policy_entropy     | 6.8584275    |
| policy_loss        | -0.008223616 |
| serial_timesteps   | 40704        |
| time_elapsed       | 164          |
| total_timesteps    | 325632       |
| value_loss         | 0.039722003  |
-------------------------------------
-------------------------------------
| approxkl           | 0.01031501   |
| clipfrac           | 0.1319336    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.817        |
| fps                | 2237         |
| n_updates          | 160          |
| policy_entropy     | 6.8515725    |
| policy_loss        | -0.011319089 |
| serial_timesteps   | 40960        |
| time_elapsed       | 165          |
| total_timesteps    | 327680       |
| value_loss         | 0.032300316  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010171937  |
| clipfrac           | 0.14267579   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.797        |
| fps                | 2233         |
| n_updates          | 161          |
| policy_entropy     | 6.81494      |
| policy_loss        | -0.015222457 |
| serial_timesteps   | 41216        |
| time_elapsed       | 166          |
| total_timesteps    | 329728       |
| value_loss         | 0.0438248    |
-------------------------------------
Eval num_timesteps=330000, episode_reward=-1.69 +/- 0.73
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0101135485 |
| clipfrac           | 0.13964844   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.811        |
| fps                | 1553         |
| n_updates          | 162          |
| policy_entropy     | 6.8013253    |
| policy_loss        | -0.013048945 |
| serial_timesteps   | 41472        |
| time_elapsed       | 167          |
| total_timesteps    | 331776       |
| value_loss         | 0.02786167   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008074406  |
| clipfrac           | 0.111328125  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.855        |
| fps                | 2206         |
| n_updates          | 163          |
| policy_entropy     | 6.7916665    |
| policy_loss        | -0.008793265 |
| serial_timesteps   | 41728        |
| time_elapsed       | 168          |
| total_timesteps    | 333824       |
| value_loss         | 0.03256332   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009311362  |
| clipfrac           | 0.13374023   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.71        |
| explained_variance | 0.769        |
| fps                | 2217         |
| n_updates          | 164          |
| policy_entropy     | 6.7730875    |
| policy_loss        | -0.009566629 |
| serial_timesteps   | 41984        |
| time_elapsed       | 169          |
| total_timesteps    | 335872       |
| value_loss         | 0.039717995  |
-------------------------------------
------------------------------------
| approxkl           | 0.009703079 |
| clipfrac           | 0.14208984  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.65       |
| explained_variance | 0.865       |
| fps                | 2206        |
| n_updates          | 165         |
| policy_entropy     | 6.7620378   |
| policy_loss        | -0.01462809 |
| serial_timesteps   | 42240       |
| time_elapsed       | 170         |
| total_timesteps    | 337920      |
| value_loss         | 0.028577466 |
------------------------------------
-------------------------------------
| approxkl           | 0.009030437  |
| clipfrac           | 0.12841797   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.71        |
| explained_variance | 0.838        |
| fps                | 2134         |
| n_updates          | 166          |
| policy_entropy     | 6.763064     |
| policy_loss        | -0.010189002 |
| serial_timesteps   | 42496        |
| time_elapsed       | 171          |
| total_timesteps    | 339968       |
| value_loss         | 0.028246019  |
-------------------------------------
Eval num_timesteps=340000, episode_reward=-1.89 +/- 0.59
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008154999  |
| clipfrac           | 0.11118164   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.75        |
| explained_variance | 0.788        |
| fps                | 1570         |
| n_updates          | 167          |
| policy_entropy     | 6.7563887    |
| policy_loss        | -0.008154807 |
| serial_timesteps   | 42752        |
| time_elapsed       | 172          |
| total_timesteps    | 342016       |
| value_loss         | 0.044583425  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008904675  |
| clipfrac           | 0.1262207    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.66        |
| explained_variance | 0.833        |
| fps                | 2235         |
| n_updates          | 168          |
| policy_entropy     | 6.73899      |
| policy_loss        | -0.008831004 |
| serial_timesteps   | 43008        |
| time_elapsed       | 173          |
| total_timesteps    | 344064       |
| value_loss         | 0.035916947  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0089320885 |
| clipfrac           | 0.11625977   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.826        |
| fps                | 2203         |
| n_updates          | 169          |
| policy_entropy     | 6.714499     |
| policy_loss        | -0.013434964 |
| serial_timesteps   | 43264        |
| time_elapsed       | 174          |
| total_timesteps    | 346112       |
| value_loss         | 0.032232013  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009507591  |
| clipfrac           | 0.12856445   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.798        |
| fps                | 2168         |
| n_updates          | 170          |
| policy_entropy     | 6.7017426    |
| policy_loss        | -0.010263595 |
| serial_timesteps   | 43520        |
| time_elapsed       | 175          |
| total_timesteps    | 348160       |
| value_loss         | 0.044547938  |
-------------------------------------
Eval num_timesteps=350000, episode_reward=-2.15 +/- 0.88
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009173246   |
| clipfrac           | 0.12617187    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.57         |
| explained_variance | 0.828         |
| fps                | 1560          |
| n_updates          | 171           |
| policy_entropy     | 6.707282      |
| policy_loss        | -0.0071550473 |
| serial_timesteps   | 43776         |
| time_elapsed       | 176           |
| total_timesteps    | 350208        |
| value_loss         | 0.026180804   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010478608   |
| clipfrac           | 0.14487305    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.53         |
| explained_variance | 0.805         |
| fps                | 2240          |
| n_updates          | 172           |
| policy_entropy     | 6.6848273     |
| policy_loss        | -0.0127847325 |
| serial_timesteps   | 44032         |
| time_elapsed       | 177           |
| total_timesteps    | 352256        |
| value_loss         | 0.038021136   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010779644  |
| clipfrac           | 0.15903321   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.856        |
| fps                | 2212         |
| n_updates          | 173          |
| policy_entropy     | 6.642108     |
| policy_loss        | -0.012391177 |
| serial_timesteps   | 44288        |
| time_elapsed       | 178          |
| total_timesteps    | 354304       |
| value_loss         | 0.020249935  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0094745625 |
| clipfrac           | 0.13564453   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.745        |
| fps                | 2148         |
| n_updates          | 174          |
| policy_entropy     | 6.628736     |
| policy_loss        | -0.009961733 |
| serial_timesteps   | 44544        |
| time_elapsed       | 179          |
| total_timesteps    | 356352       |
| value_loss         | 0.056354206  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009579414  |
| clipfrac           | 0.13330078   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.802        |
| fps                | 2217         |
| n_updates          | 175          |
| policy_entropy     | 6.6432686    |
| policy_loss        | -0.013169898 |
| serial_timesteps   | 44800        |
| time_elapsed       | 180          |
| total_timesteps    | 358400       |
| value_loss         | 0.035453897  |
-------------------------------------
Eval num_timesteps=360000, episode_reward=-1.57 +/- 0.88
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010219792  |
| clipfrac           | 0.15083008   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.808        |
| fps                | 1579         |
| n_updates          | 176          |
| policy_entropy     | 6.649755     |
| policy_loss        | -0.010753684 |
| serial_timesteps   | 45056        |
| time_elapsed       | 181          |
| total_timesteps    | 360448       |
| value_loss         | 0.037613273  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00902982   |
| clipfrac           | 0.12626953   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.817        |
| fps                | 2221         |
| n_updates          | 177          |
| policy_entropy     | 6.6294317    |
| policy_loss        | -0.012257088 |
| serial_timesteps   | 45312        |
| time_elapsed       | 182          |
| total_timesteps    | 362496       |
| value_loss         | 0.03773091   |
-------------------------------------
------------------------------------
| approxkl           | 0.0091476   |
| clipfrac           | 0.12646484  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.52       |
| explained_variance | 0.787       |
| fps                | 2154        |
| n_updates          | 178         |
| policy_entropy     | 6.58319     |
| policy_loss        | -0.0109102  |
| serial_timesteps   | 45568       |
| time_elapsed       | 183         |
| total_timesteps    | 364544      |
| value_loss         | 0.051600195 |
------------------------------------
--------------------------------------
| approxkl           | 0.008595904   |
| clipfrac           | 0.11977539    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.58         |
| explained_variance | 0.855         |
| fps                | 2220          |
| n_updates          | 179           |
| policy_entropy     | 6.5454607     |
| policy_loss        | -0.0071770893 |
| serial_timesteps   | 45824         |
| time_elapsed       | 184           |
| total_timesteps    | 366592        |
| value_loss         | 0.035286147   |
--------------------------------------
--------------------------------------
| approxkl           | 0.0077330507  |
| clipfrac           | 0.10634766    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.59         |
| explained_variance | 0.814         |
| fps                | 2201          |
| n_updates          | 180           |
| policy_entropy     | 6.5254555     |
| policy_loss        | -0.0068594674 |
| serial_timesteps   | 46080         |
| time_elapsed       | 185           |
| total_timesteps    | 368640        |
| value_loss         | 0.03215034    |
--------------------------------------
Eval num_timesteps=370000, episode_reward=-1.48 +/- 0.73
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0088239955 |
| clipfrac           | 0.11679687   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.828        |
| fps                | 1553         |
| n_updates          | 181          |
| policy_entropy     | 6.5041656    |
| policy_loss        | -0.010048731 |
| serial_timesteps   | 46336        |
| time_elapsed       | 186          |
| total_timesteps    | 370688       |
| value_loss         | 0.03893336   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009391276  |
| clipfrac           | 0.13481446   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.86         |
| fps                | 2190         |
| n_updates          | 182          |
| policy_entropy     | 6.496293     |
| policy_loss        | -0.009097679 |
| serial_timesteps   | 46592        |
| time_elapsed       | 187          |
| total_timesteps    | 372736       |
| value_loss         | 0.021969354  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010074386  |
| clipfrac           | 0.14594726   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.829        |
| fps                | 2226         |
| n_updates          | 183          |
| policy_entropy     | 6.501783     |
| policy_loss        | -0.013761993 |
| serial_timesteps   | 46848        |
| time_elapsed       | 188          |
| total_timesteps    | 374784       |
| value_loss         | 0.032000054  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0093447585 |
| clipfrac           | 0.13051757   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.873        |
| fps                | 2194         |
| n_updates          | 184          |
| policy_entropy     | 6.5119143    |
| policy_loss        | -0.009313229 |
| serial_timesteps   | 47104        |
| time_elapsed       | 189          |
| total_timesteps    | 376832       |
| value_loss         | 0.020286342  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008513481  |
| clipfrac           | 0.12084961   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.39        |
| explained_variance | 0.782        |
| fps                | 2226         |
| n_updates          | 185          |
| policy_entropy     | 6.5136337    |
| policy_loss        | -0.010714403 |
| serial_timesteps   | 47360        |
| time_elapsed       | 190          |
| total_timesteps    | 378880       |
| value_loss         | 0.030634683  |
-------------------------------------
Eval num_timesteps=380000, episode_reward=-1.30 +/- 0.48
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009284822  |
| clipfrac           | 0.13022462   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.31        |
| explained_variance | 0.872        |
| fps                | 1511         |
| n_updates          | 186          |
| policy_entropy     | 6.5019655    |
| policy_loss        | -0.011912598 |
| serial_timesteps   | 47616        |
| time_elapsed       | 191          |
| total_timesteps    | 380928       |
| value_loss         | 0.022533186  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0076901717 |
| clipfrac           | 0.10078125   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.37        |
| explained_variance | 0.77         |
| fps                | 2189         |
| n_updates          | 187          |
| policy_entropy     | 6.5122347    |
| policy_loss        | -0.00888527  |
| serial_timesteps   | 47872        |
| time_elapsed       | 192          |
| total_timesteps    | 382976       |
| value_loss         | 0.03968402   |
-------------------------------------
------------------------------------
| approxkl           | 0.008681672 |
| clipfrac           | 0.1140625   |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.4        |
| explained_variance | 0.833       |
| fps                | 2215        |
| n_updates          | 188         |
| policy_entropy     | 6.531878    |
| policy_loss        | -0.0099289  |
| serial_timesteps   | 48128       |
| time_elapsed       | 193         |
| total_timesteps    | 385024      |
| value_loss         | 0.027464617 |
------------------------------------
-------------------------------------
| approxkl           | 0.009309443  |
| clipfrac           | 0.1319336    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.762        |
| fps                | 2207         |
| n_updates          | 189          |
| policy_entropy     | 6.5287423    |
| policy_loss        | -0.009332994 |
| serial_timesteps   | 48384        |
| time_elapsed       | 194          |
| total_timesteps    | 387072       |
| value_loss         | 0.037593324  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0114694     |
| clipfrac           | 0.1631836     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.48         |
| explained_variance | 0.878         |
| fps                | 2175          |
| n_updates          | 190           |
| policy_entropy     | 6.51997       |
| policy_loss        | -0.0137711745 |
| serial_timesteps   | 48640         |
| time_elapsed       | 195           |
| total_timesteps    | 389120        |
| value_loss         | 0.02160352    |
--------------------------------------
Eval num_timesteps=390000, episode_reward=-1.79 +/- 1.12
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010505006  |
| clipfrac           | 0.15273437   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.751        |
| fps                | 1532         |
| n_updates          | 191          |
| policy_entropy     | 6.519815     |
| policy_loss        | -0.014168915 |
| serial_timesteps   | 48896        |
| time_elapsed       | 196          |
| total_timesteps    | 391168       |
| value_loss         | 0.03848646   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008686283  |
| clipfrac           | 0.11972656   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.704        |
| fps                | 2187         |
| n_updates          | 192          |
| policy_entropy     | 6.5241785    |
| policy_loss        | -0.010610025 |
| serial_timesteps   | 49152        |
| time_elapsed       | 197          |
| total_timesteps    | 393216       |
| value_loss         | 0.05456643   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009898116  |
| clipfrac           | 0.14360352   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.825        |
| fps                | 2200         |
| n_updates          | 193          |
| policy_entropy     | 6.516973     |
| policy_loss        | -0.011193764 |
| serial_timesteps   | 49408        |
| time_elapsed       | 198          |
| total_timesteps    | 395264       |
| value_loss         | 0.030943599  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009094417  |
| clipfrac           | 0.12749024   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.764        |
| fps                | 2225         |
| n_updates          | 194          |
| policy_entropy     | 6.5103736    |
| policy_loss        | -0.012366794 |
| serial_timesteps   | 49664        |
| time_elapsed       | 199          |
| total_timesteps    | 397312       |
| value_loss         | 0.043867182  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010643865  |
| clipfrac           | 0.15327148   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.809        |
| fps                | 2204         |
| n_updates          | 195          |
| policy_entropy     | 6.4892883    |
| policy_loss        | -0.013459136 |
| serial_timesteps   | 49920        |
| time_elapsed       | 200          |
| total_timesteps    | 399360       |
| value_loss         | 0.043960497  |
-------------------------------------
Eval num_timesteps=400000, episode_reward=-1.45 +/- 1.10
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.008837594   |
| clipfrac           | 0.1194336     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.47         |
| explained_variance | 0.743         |
| fps                | 1555          |
| n_updates          | 196           |
| policy_entropy     | 6.44864       |
| policy_loss        | -0.0082818605 |
| serial_timesteps   | 50176         |
| time_elapsed       | 201           |
| total_timesteps    | 401408        |
| value_loss         | 0.041500285   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009144187  |
| clipfrac           | 0.12749024   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.849        |
| fps                | 2188         |
| n_updates          | 197          |
| policy_entropy     | 6.4213157    |
| policy_loss        | -0.013304299 |
| serial_timesteps   | 50432        |
| time_elapsed       | 202          |
| total_timesteps    | 403456       |
| value_loss         | 0.028519133  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009107376  |
| clipfrac           | 0.1269043    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.729        |
| fps                | 2224         |
| n_updates          | 198          |
| policy_entropy     | 6.4092507    |
| policy_loss        | -0.011453457 |
| serial_timesteps   | 50688        |
| time_elapsed       | 203          |
| total_timesteps    | 405504       |
| value_loss         | 0.042768367  |
-------------------------------------
--------------------------------------
| approxkl           | 0.010130378   |
| clipfrac           | 0.13789062    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.43         |
| explained_variance | 0.842         |
| fps                | 2211          |
| n_updates          | 199           |
| policy_entropy     | 6.3826036     |
| policy_loss        | -0.0143760275 |
| serial_timesteps   | 50944         |
| time_elapsed       | 204           |
| total_timesteps    | 407552        |
| value_loss         | 0.028318321   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010317115  |
| clipfrac           | 0.1508789    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.875        |
| fps                | 2241         |
| n_updates          | 200          |
| policy_entropy     | 6.376516     |
| policy_loss        | -0.014109172 |
| serial_timesteps   | 51200        |
| time_elapsed       | 205          |
| total_timesteps    | 409600       |
| value_loss         | 0.017846787  |
-------------------------------------
Eval num_timesteps=410000, episode_reward=-1.23 +/- 0.50
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0099665085 |
| clipfrac           | 0.1415039    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.817        |
| fps                | 1548         |
| n_updates          | 201          |
| policy_entropy     | 6.359975     |
| policy_loss        | -0.011875781 |
| serial_timesteps   | 51456        |
| time_elapsed       | 206          |
| total_timesteps    | 411648       |
| value_loss         | 0.03153419   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00894976   |
| clipfrac           | 0.1272461    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.86         |
| fps                | 2249         |
| n_updates          | 202          |
| policy_entropy     | 6.3443003    |
| policy_loss        | -0.012518833 |
| serial_timesteps   | 51712        |
| time_elapsed       | 207          |
| total_timesteps    | 413696       |
| value_loss         | 0.021788433  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010236953  |
| clipfrac           | 0.14785156   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.779        |
| fps                | 2237         |
| n_updates          | 203          |
| policy_entropy     | 6.344399     |
| policy_loss        | -0.012103373 |
| serial_timesteps   | 51968        |
| time_elapsed       | 208          |
| total_timesteps    | 415744       |
| value_loss         | 0.043952674  |
-------------------------------------
-------------------------------------
| approxkl           | 0.011022018  |
| clipfrac           | 0.15410157   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.65        |
| explained_variance | 0.875        |
| fps                | 2223         |
| n_updates          | 204          |
| policy_entropy     | 6.3281164    |
| policy_loss        | -0.011322418 |
| serial_timesteps   | 52224        |
| time_elapsed       | 209          |
| total_timesteps    | 417792       |
| value_loss         | 0.030010045  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009104483  |
| clipfrac           | 0.13017578   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.771        |
| fps                | 2246         |
| n_updates          | 205          |
| policy_entropy     | 6.3025446    |
| policy_loss        | -0.008862981 |
| serial_timesteps   | 52480        |
| time_elapsed       | 210          |
| total_timesteps    | 419840       |
| value_loss         | 0.04537801   |
-------------------------------------
Eval num_timesteps=420000, episode_reward=-2.31 +/- 0.66
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009840518  |
| clipfrac           | 0.1421875    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.847        |
| fps                | 1556         |
| n_updates          | 206          |
| policy_entropy     | 6.290429     |
| policy_loss        | -0.013124889 |
| serial_timesteps   | 52736        |
| time_elapsed       | 211          |
| total_timesteps    | 421888       |
| value_loss         | 0.03834133   |
-------------------------------------
------------------------------------
| approxkl           | 0.009165745 |
| clipfrac           | 0.13144532  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.55       |
| explained_variance | 0.797       |
| fps                | 2215        |
| n_updates          | 207         |
| policy_entropy     | 6.30622     |
| policy_loss        | -0.01077976 |
| serial_timesteps   | 52992       |
| time_elapsed       | 212         |
| total_timesteps    | 423936      |
| value_loss         | 0.038230646 |
------------------------------------
-------------------------------------
| approxkl           | 0.009517561  |
| clipfrac           | 0.13134766   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.881        |
| fps                | 2208         |
| n_updates          | 208          |
| policy_entropy     | 6.2788515    |
| policy_loss        | -0.011623329 |
| serial_timesteps   | 53248        |
| time_elapsed       | 213          |
| total_timesteps    | 425984       |
| value_loss         | 0.020742703  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009967655  |
| clipfrac           | 0.14516601   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.857        |
| fps                | 2205         |
| n_updates          | 209          |
| policy_entropy     | 6.2574077    |
| policy_loss        | -0.012429091 |
| serial_timesteps   | 53504        |
| time_elapsed       | 214          |
| total_timesteps    | 428032       |
| value_loss         | 0.0278458    |
-------------------------------------
Eval num_timesteps=430000, episode_reward=-1.53 +/- 0.14
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010482249  |
| clipfrac           | 0.15166016   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.804        |
| fps                | 1565         |
| n_updates          | 210          |
| policy_entropy     | 6.252816     |
| policy_loss        | -0.013535976 |
| serial_timesteps   | 53760        |
| time_elapsed       | 215          |
| total_timesteps    | 430080       |
| value_loss         | 0.03736203   |
-------------------------------------
-------------------------------------
| approxkl           | 0.011067975  |
| clipfrac           | 0.159375     |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.68        |
| explained_variance | 0.895        |
| fps                | 2237         |
| n_updates          | 211          |
| policy_entropy     | 6.2473855    |
| policy_loss        | -0.011319615 |
| serial_timesteps   | 54016        |
| time_elapsed       | 216          |
| total_timesteps    | 432128       |
| value_loss         | 0.02275552   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008633247  |
| clipfrac           | 0.119189456  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.863        |
| fps                | 2205         |
| n_updates          | 212          |
| policy_entropy     | 6.229499     |
| policy_loss        | -0.007124978 |
| serial_timesteps   | 54272        |
| time_elapsed       | 217          |
| total_timesteps    | 434176       |
| value_loss         | 0.025115231  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009193057  |
| clipfrac           | 0.12734374   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.7         |
| explained_variance | 0.854        |
| fps                | 2204         |
| n_updates          | 213          |
| policy_entropy     | 6.216376     |
| policy_loss        | -0.009222302 |
| serial_timesteps   | 54528        |
| time_elapsed       | 218          |
| total_timesteps    | 436224       |
| value_loss         | 0.037109327  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010322748  |
| clipfrac           | 0.14604492   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.67        |
| explained_variance | 0.827        |
| fps                | 2182         |
| n_updates          | 214          |
| policy_entropy     | 6.1865864    |
| policy_loss        | -0.012306398 |
| serial_timesteps   | 54784        |
| time_elapsed       | 219          |
| total_timesteps    | 438272       |
| value_loss         | 0.03922105   |
-------------------------------------
Eval num_timesteps=440000, episode_reward=-0.89 +/- 0.66
Episode length: 100.00 +/- 0.00
New best mean reward!
--------------------------------------
| approxkl           | 0.009565593   |
| clipfrac           | 0.1328125     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.65         |
| explained_variance | 0.847         |
| fps                | 1530          |
| n_updates          | 215           |
| policy_entropy     | 6.163905      |
| policy_loss        | -0.0098286895 |
| serial_timesteps   | 55040         |
| time_elapsed       | 220           |
| total_timesteps    | 440320        |
| value_loss         | 0.039030973   |
--------------------------------------
--------------------------------------
| approxkl           | 0.00925366    |
| clipfrac           | 0.13061523    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.62         |
| explained_variance | 0.884         |
| fps                | 2226          |
| n_updates          | 216           |
| policy_entropy     | 6.15232       |
| policy_loss        | -0.0073029483 |
| serial_timesteps   | 55296         |
| time_elapsed       | 221           |
| total_timesteps    | 442368        |
| value_loss         | 0.023197785   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010031917  |
| clipfrac           | 0.13793945   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.69        |
| explained_variance | 0.817        |
| fps                | 2177         |
| n_updates          | 217          |
| policy_entropy     | 6.153183     |
| policy_loss        | -0.011169625 |
| serial_timesteps   | 55552        |
| time_elapsed       | 222          |
| total_timesteps    | 444416       |
| value_loss         | 0.044831567  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010132962  |
| clipfrac           | 0.13945313   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.814        |
| fps                | 2241         |
| n_updates          | 218          |
| policy_entropy     | 6.151923     |
| policy_loss        | -0.010516009 |
| serial_timesteps   | 55808        |
| time_elapsed       | 223          |
| total_timesteps    | 446464       |
| value_loss         | 0.049284466  |
-------------------------------------
--------------------------------------
| approxkl           | 0.010095129   |
| clipfrac           | 0.14003906    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.6          |
| explained_variance | 0.845         |
| fps                | 2219          |
| n_updates          | 219           |
| policy_entropy     | 6.139672      |
| policy_loss        | -0.0095985355 |
| serial_timesteps   | 56064         |
| time_elapsed       | 224           |
| total_timesteps    | 448512        |
| value_loss         | 0.033296525   |
--------------------------------------
Eval num_timesteps=450000, episode_reward=-1.90 +/- 0.67
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010522573  |
| clipfrac           | 0.14550781   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.786        |
| fps                | 1592         |
| n_updates          | 220          |
| policy_entropy     | 6.1401167    |
| policy_loss        | -0.011860706 |
| serial_timesteps   | 56320        |
| time_elapsed       | 225          |
| total_timesteps    | 450560       |
| value_loss         | 0.037439406  |
-------------------------------------
-------------------------------------
| approxkl           | 0.011052867  |
| clipfrac           | 0.16025391   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.793        |
| fps                | 2175         |
| n_updates          | 221          |
| policy_entropy     | 6.1379085    |
| policy_loss        | -0.014268182 |
| serial_timesteps   | 56576        |
| time_elapsed       | 226          |
| total_timesteps    | 452608       |
| value_loss         | 0.027633673  |
-------------------------------------
-------------------------------------
| approxkl           | 0.012423265  |
| clipfrac           | 0.18198243   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.83         |
| fps                | 2160         |
| n_updates          | 222          |
| policy_entropy     | 6.1276484    |
| policy_loss        | -0.015280863 |
| serial_timesteps   | 56832        |
| time_elapsed       | 227          |
| total_timesteps    | 454656       |
| value_loss         | 0.026596045  |
-------------------------------------
------------------------------------
| approxkl           | 0.007896036 |
| clipfrac           | 0.10805664  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.58       |
| explained_variance | 0.759       |
| fps                | 2204        |
| n_updates          | 223         |
| policy_entropy     | 6.104081    |
| policy_loss        | -0.00847435 |
| serial_timesteps   | 57088       |
| time_elapsed       | 228         |
| total_timesteps    | 456704      |
| value_loss         | 0.04063865  |
------------------------------------
-------------------------------------
| approxkl           | 0.010571355  |
| clipfrac           | 0.15366212   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.851        |
| fps                | 2211         |
| n_updates          | 224          |
| policy_entropy     | 6.0816817    |
| policy_loss        | -0.012764545 |
| serial_timesteps   | 57344        |
| time_elapsed       | 229          |
| total_timesteps    | 458752       |
| value_loss         | 0.029051205  |
-------------------------------------
Eval num_timesteps=460000, episode_reward=-2.12 +/- 0.91
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010668908  |
| clipfrac           | 0.15620117   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.762        |
| fps                | 1514         |
| n_updates          | 225          |
| policy_entropy     | 6.056766     |
| policy_loss        | -0.013278323 |
| serial_timesteps   | 57600        |
| time_elapsed       | 230          |
| total_timesteps    | 460800       |
| value_loss         | 0.05009982   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009995036  |
| clipfrac           | 0.1381836    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.816        |
| fps                | 2159         |
| n_updates          | 226          |
| policy_entropy     | 6.014168     |
| policy_loss        | -0.008994207 |
| serial_timesteps   | 57856        |
| time_elapsed       | 231          |
| total_timesteps    | 462848       |
| value_loss         | 0.03269876   |
-------------------------------------
--------------------------------------
| approxkl           | 0.008401826   |
| clipfrac           | 0.11401367    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.44         |
| explained_variance | 0.842         |
| fps                | 2229          |
| n_updates          | 227           |
| policy_entropy     | 6.0024195     |
| policy_loss        | -0.0070933984 |
| serial_timesteps   | 58112         |
| time_elapsed       | 232           |
| total_timesteps    | 464896        |
| value_loss         | 0.03554795    |
--------------------------------------
-------------------------------------
| approxkl           | 0.010426689  |
| clipfrac           | 0.15083008   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.792        |
| fps                | 2225         |
| n_updates          | 228          |
| policy_entropy     | 5.9987893    |
| policy_loss        | -0.009450415 |
| serial_timesteps   | 58368        |
| time_elapsed       | 233          |
| total_timesteps    | 466944       |
| value_loss         | 0.0338023    |
-------------------------------------
--------------------------------------
| approxkl           | 0.008907081   |
| clipfrac           | 0.12045898    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.43         |
| explained_variance | 0.823         |
| fps                | 2195          |
| n_updates          | 229           |
| policy_entropy     | 5.989032      |
| policy_loss        | -0.0074143326 |
| serial_timesteps   | 58624         |
| time_elapsed       | 234           |
| total_timesteps    | 468992        |
| value_loss         | 0.034949664   |
--------------------------------------
Eval num_timesteps=470000, episode_reward=-1.72 +/- 0.12
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010261783  |
| clipfrac           | 0.14418945   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.34        |
| explained_variance | 0.818        |
| fps                | 1568         |
| n_updates          | 230          |
| policy_entropy     | 5.991386     |
| policy_loss        | -0.011405846 |
| serial_timesteps   | 58880        |
| time_elapsed       | 235          |
| total_timesteps    | 471040       |
| value_loss         | 0.028729726  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008184237  |
| clipfrac           | 0.107421875  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.39        |
| explained_variance | 0.85         |
| fps                | 2136         |
| n_updates          | 231          |
| policy_entropy     | 5.981551     |
| policy_loss        | -0.007229711 |
| serial_timesteps   | 59136        |
| time_elapsed       | 237          |
| total_timesteps    | 473088       |
| value_loss         | 0.029650917  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00947695   |
| clipfrac           | 0.14116211   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.819        |
| fps                | 2201         |
| n_updates          | 232          |
| policy_entropy     | 5.9629107    |
| policy_loss        | -0.012138909 |
| serial_timesteps   | 59392        |
| time_elapsed       | 237          |
| total_timesteps    | 475136       |
| value_loss         | 0.033712655  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0097981235 |
| clipfrac           | 0.13217774   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.887        |
| fps                | 2188         |
| n_updates          | 233          |
| policy_entropy     | 5.9505315    |
| policy_loss        | -0.01162474  |
| serial_timesteps   | 59648        |
| time_elapsed       | 238          |
| total_timesteps    | 477184       |
| value_loss         | 0.023085097  |
-------------------------------------
------------------------------------
| approxkl           | 0.009074797 |
| clipfrac           | 0.12773438  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.7        |
| explained_variance | 0.811       |
| fps                | 2195        |
| n_updates          | 234         |
| policy_entropy     | 5.9754834   |
| policy_loss        | -0.0106976  |
| serial_timesteps   | 59904       |
| time_elapsed       | 239         |
| total_timesteps    | 479232      |
| value_loss         | 0.04345175  |
------------------------------------
Eval num_timesteps=480000, episode_reward=-0.84 +/- 0.50
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.008923074  |
| clipfrac           | 0.12456055   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.67        |
| explained_variance | 0.869        |
| fps                | 1554         |
| n_updates          | 235          |
| policy_entropy     | 6.001963     |
| policy_loss        | -0.008220864 |
| serial_timesteps   | 60160        |
| time_elapsed       | 240          |
| total_timesteps    | 481280       |
| value_loss         | 0.029461548  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009841762  |
| clipfrac           | 0.13916016   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.75        |
| explained_variance | 0.832        |
| fps                | 2227         |
| n_updates          | 236          |
| policy_entropy     | 6.0197763    |
| policy_loss        | -0.013505304 |
| serial_timesteps   | 60416        |
| time_elapsed       | 242          |
| total_timesteps    | 483328       |
| value_loss         | 0.039873965  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009961719  |
| clipfrac           | 0.14248046   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.853        |
| fps                | 2183         |
| n_updates          | 237          |
| policy_entropy     | 6.026322     |
| policy_loss        | -0.011871701 |
| serial_timesteps   | 60672        |
| time_elapsed       | 243          |
| total_timesteps    | 485376       |
| value_loss         | 0.025818944  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009566987  |
| clipfrac           | 0.1324707    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.886        |
| fps                | 2216         |
| n_updates          | 238          |
| policy_entropy     | 6.014286     |
| policy_loss        | -0.011462325 |
| serial_timesteps   | 60928        |
| time_elapsed       | 243          |
| total_timesteps    | 487424       |
| value_loss         | 0.023415286  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010555935  |
| clipfrac           | 0.15048829   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.769        |
| fps                | 2194         |
| n_updates          | 239          |
| policy_entropy     | 6.0086427    |
| policy_loss        | -0.010273131 |
| serial_timesteps   | 61184        |
| time_elapsed       | 244          |
| total_timesteps    | 489472       |
| value_loss         | 0.042030092  |
-------------------------------------
Eval num_timesteps=490000, episode_reward=-2.15 +/- 0.36
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009245534  |
| clipfrac           | 0.12880859   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.878        |
| fps                | 1581         |
| n_updates          | 240          |
| policy_entropy     | 6.0150757    |
| policy_loss        | -0.010679311 |
| serial_timesteps   | 61440        |
| time_elapsed       | 245          |
| total_timesteps    | 491520       |
| value_loss         | 0.016064744  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009557546  |
| clipfrac           | 0.13540038   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.34        |
| explained_variance | 0.819        |
| fps                | 2148         |
| n_updates          | 241          |
| policy_entropy     | 6.0071454    |
| policy_loss        | -0.010711889 |
| serial_timesteps   | 61696        |
| time_elapsed       | 247          |
| total_timesteps    | 493568       |
| value_loss         | 0.025784781  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00912891   |
| clipfrac           | 0.12695312   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.34        |
| explained_variance | 0.854        |
| fps                | 2258         |
| n_updates          | 242          |
| policy_entropy     | 5.975612     |
| policy_loss        | -0.010538454 |
| serial_timesteps   | 61952        |
| time_elapsed       | 248          |
| total_timesteps    | 495616       |
| value_loss         | 0.01997312   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0094974525  |
| clipfrac           | 0.12983398    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.31         |
| explained_variance | 0.867         |
| fps                | 2221          |
| n_updates          | 243           |
| policy_entropy     | 5.951878      |
| policy_loss        | -0.0103640575 |
| serial_timesteps   | 62208         |
| time_elapsed       | 248           |
| total_timesteps    | 497664        |
| value_loss         | 0.022851672   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008953779  |
| clipfrac           | 0.123046875  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.35        |
| explained_variance | 0.732        |
| fps                | 2216         |
| n_updates          | 244          |
| policy_entropy     | 5.903034     |
| policy_loss        | -0.009101643 |
| serial_timesteps   | 62464        |
| time_elapsed       | 249          |
| total_timesteps    | 499712       |
| value_loss         | 0.04529754   |
-------------------------------------
Saving to logs/train_0.5M_widowx_reacher-v7_KAY/ppo2/widowx_reacher-v7_1
pybullet build time: May 18 2020 02:46:26
