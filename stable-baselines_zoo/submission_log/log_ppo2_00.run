--------------------------------------------------------------------------
WARNING: There was an error initializing an OpenFabrics device.

  Local host:   n371
  Local device: hfi1_0
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Warning: Open MPI has detected that you are running in an environment with CUDA
devices present and that you are using Intel(r) Ompi-Path networking. However,
the environment variable PSM2_CUDA was not set, meaning that the PSM2 Omni-Path
networking library was not told how to handle CUDA support.

If your application uses CUDA buffers, you should set the environment variable
PSM2_CUDA to 1; otherwise, set it to 0. Setting the variable to the wrong value
can have performance implications on your application, or even cause it to
crash.

Since it was not set, Open MPI has defaulted to setting the PSM2_CUDA
environment variable to 1.

Local hostname: n371
--------------------------------------------------------------------------
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

========== widowx_reacher-v5 ==========
Seed: 0
OrderedDict([('cliprange', 0.2),
             ('ent_coef', 0.0),
             ('gamma', 0.99),
             ('lam', 0.95),
             ('learning_rate', 0.00025),
             ('n_envs', 8),
             ('n_steps', 256),
             ('n_timesteps', 1000000.0),
             ('nminibatches', 32),
             ('noptepochs', 10),
             ('normalize', True),
             ('policy', 'MlpPolicy')])
Using 8 environments
Overwriting n_timesteps with n=500000
Normalizing input and reward
Creating test environment
TRAINING ENV TYPE :  <stable_baselines.common.vec_env.vec_normalize.VecNormalize object at 0x7f0bb1bad5f8>
Normalization activated: {'norm_reward': False}
EVAL ENV TYPE :  <stable_baselines.common.vec_env.vec_normalize.VecNormalize object at 0x7f0baf5214a8>
Log path: logs/train_0.5M_widowx_reacher-v5_KAY/ppo2/widowx_reacher-v5_1
-------------------------------------
| approxkl           | 0.00560163   |
| clipfrac           | 0.06889649   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.0789       |
| fps                | 1501         |
| n_updates          | 1            |
| policy_entropy     | 8.521804     |
| policy_loss        | -0.009302722 |
| serial_timesteps   | 256          |
| time_elapsed       | 2.53e-05     |
| total_timesteps    | 2048         |
| value_loss         | 0.66420585   |
-------------------------------------
-------------------------------------
| approxkl           | 0.005698769  |
| clipfrac           | 0.07172851   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.69        |
| explained_variance | -0.0682      |
| fps                | 2040         |
| n_updates          | 2            |
| policy_entropy     | 8.544058     |
| policy_loss        | -0.012838028 |
| serial_timesteps   | 512          |
| time_elapsed       | 1.36         |
| total_timesteps    | 4096         |
| value_loss         | 0.07393888   |
-------------------------------------
-------------------------------------
| approxkl           | 0.006661956  |
| clipfrac           | 0.08149414   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.71        |
| explained_variance | 0.132        |
| fps                | 1991         |
| n_updates          | 3            |
| policy_entropy     | 8.525917     |
| policy_loss        | -0.012149079 |
| serial_timesteps   | 768          |
| time_elapsed       | 2.37         |
| total_timesteps    | 6144         |
| value_loss         | 0.095826656  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00516941   |
| clipfrac           | 0.061279297  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.72        |
| explained_variance | 0.264        |
| fps                | 2085         |
| n_updates          | 4            |
| policy_entropy     | 8.508169     |
| policy_loss        | -0.010164945 |
| serial_timesteps   | 1024         |
| time_elapsed       | 3.4          |
| total_timesteps    | 8192         |
| value_loss         | 0.06606139   |
-------------------------------------
Eval num_timesteps=10000, episode_reward=-0.55 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
------------------------------------
| approxkl           | 0.006938561 |
| clipfrac           | 0.09077148  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.71       |
| explained_variance | 0.375       |
| fps                | 1349        |
| n_updates          | 5           |
| policy_entropy     | 8.500387    |
| policy_loss        | -0.01077279 |
| serial_timesteps   | 1280        |
| time_elapsed       | 4.38        |
| total_timesteps    | 10240       |
| value_loss         | 0.050810117 |
------------------------------------
-------------------------------------
| approxkl           | 0.006422584  |
| clipfrac           | 0.082177736  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.69        |
| explained_variance | 0.345        |
| fps                | 2138         |
| n_updates          | 6            |
| policy_entropy     | 8.463248     |
| policy_loss        | -0.011053555 |
| serial_timesteps   | 1536         |
| time_elapsed       | 5.9          |
| total_timesteps    | 12288        |
| value_loss         | 0.051261194  |
-------------------------------------
------------------------------------
| approxkl           | 0.007611188 |
| clipfrac           | 0.10771485  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.71       |
| explained_variance | 0.384       |
| fps                | 2081        |
| n_updates          | 7           |
| policy_entropy     | 8.458132    |
| policy_loss        | -0.01363465 |
| serial_timesteps   | 1792        |
| time_elapsed       | 6.85        |
| total_timesteps    | 14336       |
| value_loss         | 0.057209294 |
------------------------------------
-------------------------------------
| approxkl           | 0.0070435097 |
| clipfrac           | 0.09169922   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.71        |
| explained_variance | 0.474        |
| fps                | 2117         |
| n_updates          | 8            |
| policy_entropy     | 8.478674     |
| policy_loss        | -0.013786906 |
| serial_timesteps   | 2048         |
| time_elapsed       | 7.84         |
| total_timesteps    | 16384        |
| value_loss         | 0.062546685  |
-------------------------------------
-------------------------------------
| approxkl           | 0.006993889  |
| clipfrac           | 0.09833984   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.71        |
| explained_variance | 0.602        |
| fps                | 2122         |
| n_updates          | 9            |
| policy_entropy     | 8.483402     |
| policy_loss        | -0.012067447 |
| serial_timesteps   | 2304         |
| time_elapsed       | 8.81         |
| total_timesteps    | 18432        |
| value_loss         | 0.055170543  |
-------------------------------------
Eval num_timesteps=20000, episode_reward=-0.56 +/- 0.01
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.007828535 |
| clipfrac           | 0.10625     |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.68       |
| explained_variance | 0.617       |
| fps                | 1534        |
| n_updates          | 10          |
| policy_entropy     | 8.488953    |
| policy_loss        | -0.0141987  |
| serial_timesteps   | 2560        |
| time_elapsed       | 9.77        |
| total_timesteps    | 20480       |
| value_loss         | 0.038878467 |
------------------------------------
-------------------------------------
| approxkl           | 0.0068263225 |
| clipfrac           | 0.08676758   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.562        |
| fps                | 2088         |
| n_updates          | 11           |
| policy_entropy     | 8.480192     |
| policy_loss        | -0.011987901 |
| serial_timesteps   | 2816         |
| time_elapsed       | 11.1         |
| total_timesteps    | 22528        |
| value_loss         | 0.0554806    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0068485937 |
| clipfrac           | 0.09072266   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.69        |
| explained_variance | 0.231        |
| fps                | 1951         |
| n_updates          | 12           |
| policy_entropy     | 8.475577     |
| policy_loss        | -0.011073323 |
| serial_timesteps   | 3072         |
| time_elapsed       | 12.1         |
| total_timesteps    | 24576        |
| value_loss         | 0.09919165   |
-------------------------------------
--------------------------------------
| approxkl           | 0.006476658   |
| clipfrac           | 0.08657227    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.67         |
| explained_variance | 0.603         |
| fps                | 2139          |
| n_updates          | 13            |
| policy_entropy     | 8.471651      |
| policy_loss        | -0.0116262855 |
| serial_timesteps   | 3328          |
| time_elapsed       | 13.1          |
| total_timesteps    | 26624         |
| value_loss         | 0.06337929    |
--------------------------------------
-------------------------------------
| approxkl           | 0.008040833  |
| clipfrac           | 0.11103515   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.66        |
| explained_variance | 0.562        |
| fps                | 2137         |
| n_updates          | 14           |
| policy_entropy     | 8.468665     |
| policy_loss        | -0.014187503 |
| serial_timesteps   | 3584         |
| time_elapsed       | 14.1         |
| total_timesteps    | 28672        |
| value_loss         | 0.066041484  |
-------------------------------------
Eval num_timesteps=30000, episode_reward=-0.53 +/- 0.01
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.009465917  |
| clipfrac           | 0.14204101   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.777        |
| fps                | 1392         |
| n_updates          | 15           |
| policy_entropy     | 8.466575     |
| policy_loss        | -0.014896229 |
| serial_timesteps   | 3840         |
| time_elapsed       | 15.1         |
| total_timesteps    | 30720        |
| value_loss         | 0.040561944  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00827901   |
| clipfrac           | 0.111572266  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.437        |
| fps                | 2132         |
| n_updates          | 16           |
| policy_entropy     | 8.460427     |
| policy_loss        | -0.014506511 |
| serial_timesteps   | 4096         |
| time_elapsed       | 16.5         |
| total_timesteps    | 32768        |
| value_loss         | 0.092938796  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077881417 |
| clipfrac           | 0.107617185  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.65        |
| explained_variance | 0.457        |
| fps                | 2150         |
| n_updates          | 17           |
| policy_entropy     | 8.441069     |
| policy_loss        | -0.012223331 |
| serial_timesteps   | 4352         |
| time_elapsed       | 17.5         |
| total_timesteps    | 34816        |
| value_loss         | 0.08147894   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007142964  |
| clipfrac           | 0.088378906  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.622        |
| fps                | 2109         |
| n_updates          | 18           |
| policy_entropy     | 8.4189825    |
| policy_loss        | -0.012047103 |
| serial_timesteps   | 4608         |
| time_elapsed       | 18.4         |
| total_timesteps    | 36864        |
| value_loss         | 0.058978014  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009109331  |
| clipfrac           | 0.12734374   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.5          |
| fps                | 2098         |
| n_updates          | 19           |
| policy_entropy     | 8.411334     |
| policy_loss        | -0.016210284 |
| serial_timesteps   | 4864         |
| time_elapsed       | 19.4         |
| total_timesteps    | 38912        |
| value_loss         | 0.07030387   |
-------------------------------------
Eval num_timesteps=40000, episode_reward=-0.95 +/- 0.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.006527637  |
| clipfrac           | 0.08339844   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.627        |
| fps                | 1484         |
| n_updates          | 20           |
| policy_entropy     | 8.398728     |
| policy_loss        | -0.007756441 |
| serial_timesteps   | 5120         |
| time_elapsed       | 20.4         |
| total_timesteps    | 40960        |
| value_loss         | 0.05864101   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0060929228 |
| clipfrac           | 0.076660156  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.66        |
| explained_variance | 0.516        |
| fps                | 2120         |
| n_updates          | 21           |
| policy_entropy     | 8.378013     |
| policy_loss        | -0.008299993 |
| serial_timesteps   | 5376         |
| time_elapsed       | 21.8         |
| total_timesteps    | 43008        |
| value_loss         | 0.061653294  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00752443   |
| clipfrac           | 0.106738284  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.567        |
| fps                | 2102         |
| n_updates          | 22           |
| policy_entropy     | 8.351591     |
| policy_loss        | -0.013854118 |
| serial_timesteps   | 5632         |
| time_elapsed       | 22.7         |
| total_timesteps    | 45056        |
| value_loss         | 0.06204335   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007696229  |
| clipfrac           | 0.10263672   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.585        |
| fps                | 1943         |
| n_updates          | 23           |
| policy_entropy     | 8.324589     |
| policy_loss        | -0.011698155 |
| serial_timesteps   | 5888         |
| time_elapsed       | 23.7         |
| total_timesteps    | 47104        |
| value_loss         | 0.06578733   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008811327  |
| clipfrac           | 0.1199707    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.763        |
| fps                | 2073         |
| n_updates          | 24           |
| policy_entropy     | 8.308979     |
| policy_loss        | -0.011640398 |
| serial_timesteps   | 6144         |
| time_elapsed       | 24.8         |
| total_timesteps    | 49152        |
| value_loss         | 0.037006848  |
-------------------------------------
Eval num_timesteps=50000, episode_reward=-1.05 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.006021199  |
| clipfrac           | 0.070410155  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.614        |
| fps                | 1519         |
| n_updates          | 25           |
| policy_entropy     | 8.268103     |
| policy_loss        | -0.010259979 |
| serial_timesteps   | 6400         |
| time_elapsed       | 25.7         |
| total_timesteps    | 51200        |
| value_loss         | 0.059646584  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00701847   |
| clipfrac           | 0.09472656   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.512        |
| fps                | 2100         |
| n_updates          | 26           |
| policy_entropy     | 8.253383     |
| policy_loss        | -0.011949821 |
| serial_timesteps   | 6656         |
| time_elapsed       | 27.1         |
| total_timesteps    | 53248        |
| value_loss         | 0.06201137   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0057016546 |
| clipfrac           | 0.064013675  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.601        |
| fps                | 2080         |
| n_updates          | 27           |
| policy_entropy     | 8.238435     |
| policy_loss        | -0.007810778 |
| serial_timesteps   | 6912         |
| time_elapsed       | 28.1         |
| total_timesteps    | 55296        |
| value_loss         | 0.06322472   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0068459893 |
| clipfrac           | 0.087841794  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.502        |
| fps                | 2096         |
| n_updates          | 28           |
| policy_entropy     | 8.216192     |
| policy_loss        | -0.008030391 |
| serial_timesteps   | 7168         |
| time_elapsed       | 29.1         |
| total_timesteps    | 57344        |
| value_loss         | 0.067362234  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0069117113 |
| clipfrac           | 0.08730469   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.554        |
| fps                | 2145         |
| n_updates          | 29           |
| policy_entropy     | 8.192371     |
| policy_loss        | -0.010949944 |
| serial_timesteps   | 7424         |
| time_elapsed       | 30           |
| total_timesteps    | 59392        |
| value_loss         | 0.05948015   |
-------------------------------------
Eval num_timesteps=60000, episode_reward=-0.41 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.008150326  |
| clipfrac           | 0.10668945   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.564        |
| fps                | 1462         |
| n_updates          | 30           |
| policy_entropy     | 8.175291     |
| policy_loss        | -0.011903227 |
| serial_timesteps   | 7680         |
| time_elapsed       | 31           |
| total_timesteps    | 61440        |
| value_loss         | 0.052986532  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007941095  |
| clipfrac           | 0.11240234   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.627        |
| fps                | 2109         |
| n_updates          | 31           |
| policy_entropy     | 8.172968     |
| policy_loss        | -0.011928203 |
| serial_timesteps   | 7936         |
| time_elapsed       | 32.4         |
| total_timesteps    | 63488        |
| value_loss         | 0.053673886  |
-------------------------------------
------------------------------------
| approxkl           | 0.009183858 |
| clipfrac           | 0.11860351  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.53       |
| explained_variance | 0.549       |
| fps                | 2095        |
| n_updates          | 32          |
| policy_entropy     | 8.135373    |
| policy_loss        | -0.01281829 |
| serial_timesteps   | 8192        |
| time_elapsed       | 33.4        |
| total_timesteps    | 65536       |
| value_loss         | 0.055433534 |
------------------------------------
------------------------------------
| approxkl           | 0.009734181 |
| clipfrac           | 0.12958984  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.51       |
| explained_variance | -0.137      |
| fps                | 2111        |
| n_updates          | 33          |
| policy_entropy     | 8.112387    |
| policy_loss        | -0.01526857 |
| serial_timesteps   | 8448        |
| time_elapsed       | 34.3        |
| total_timesteps    | 67584       |
| value_loss         | 0.15208331  |
------------------------------------
-------------------------------------
| approxkl           | 0.008605303  |
| clipfrac           | 0.11630859   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.424        |
| fps                | 2084         |
| n_updates          | 34           |
| policy_entropy     | 8.111092     |
| policy_loss        | -0.014012711 |
| serial_timesteps   | 8704         |
| time_elapsed       | 35.3         |
| total_timesteps    | 69632        |
| value_loss         | 0.05958103   |
-------------------------------------
Eval num_timesteps=70000, episode_reward=-3.16 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009651921  |
| clipfrac           | 0.13969727   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.728        |
| fps                | 1498         |
| n_updates          | 35           |
| policy_entropy     | 8.082837     |
| policy_loss        | -0.014791618 |
| serial_timesteps   | 8960         |
| time_elapsed       | 36.3         |
| total_timesteps    | 71680        |
| value_loss         | 0.03019305   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008050597  |
| clipfrac           | 0.10942383   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.41         |
| fps                | 1968         |
| n_updates          | 36           |
| policy_entropy     | 8.077704     |
| policy_loss        | -0.015229909 |
| serial_timesteps   | 9216         |
| time_elapsed       | 37.7         |
| total_timesteps    | 73728        |
| value_loss         | 0.089979164  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007452031  |
| clipfrac           | 0.09829102   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.66        |
| explained_variance | 0.679        |
| fps                | 2147         |
| n_updates          | 37           |
| policy_entropy     | 8.084608     |
| policy_loss        | -0.012070875 |
| serial_timesteps   | 9472         |
| time_elapsed       | 38.7         |
| total_timesteps    | 75776        |
| value_loss         | 0.042888485  |
-------------------------------------
-------------------------------------
| approxkl           | 0.006858398  |
| clipfrac           | 0.08569336   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.65        |
| explained_variance | 0.625        |
| fps                | 2104         |
| n_updates          | 38           |
| policy_entropy     | 8.086782     |
| policy_loss        | -0.008943768 |
| serial_timesteps   | 9728         |
| time_elapsed       | 39.7         |
| total_timesteps    | 77824        |
| value_loss         | 0.051948775  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0105272485 |
| clipfrac           | 0.15478516   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.411        |
| fps                | 2127         |
| n_updates          | 39           |
| policy_entropy     | 8.092514     |
| policy_loss        | -0.018375259 |
| serial_timesteps   | 9984         |
| time_elapsed       | 40.6         |
| total_timesteps    | 79872        |
| value_loss         | 0.08972253   |
-------------------------------------
Eval num_timesteps=80000, episode_reward=-2.97 +/- 0.05
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0075722164 |
| clipfrac           | 0.10224609   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.7         |
| explained_variance | 0.686        |
| fps                | 1525         |
| n_updates          | 40           |
| policy_entropy     | 8.067605     |
| policy_loss        | -0.011224031 |
| serial_timesteps   | 10240        |
| time_elapsed       | 41.6         |
| total_timesteps    | 81920        |
| value_loss         | 0.035280257  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007245881  |
| clipfrac           | 0.09672852   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.615        |
| fps                | 2151         |
| n_updates          | 41           |
| policy_entropy     | 8.040522     |
| policy_loss        | -0.010232568 |
| serial_timesteps   | 10496        |
| time_elapsed       | 42.9         |
| total_timesteps    | 83968        |
| value_loss         | 0.038964786  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007504913  |
| clipfrac           | 0.09624024   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.65        |
| explained_variance | 0.608        |
| fps                | 2119         |
| n_updates          | 42           |
| policy_entropy     | 8.016314     |
| policy_loss        | -0.011141801 |
| serial_timesteps   | 10752        |
| time_elapsed       | 43.9         |
| total_timesteps    | 86016        |
| value_loss         | 0.049049564  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008014202  |
| clipfrac           | 0.11005859   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | 0.652        |
| fps                | 2212         |
| n_updates          | 43           |
| policy_entropy     | 8.009741     |
| policy_loss        | -0.010821739 |
| serial_timesteps   | 11008        |
| time_elapsed       | 44.9         |
| total_timesteps    | 88064        |
| value_loss         | 0.03810573   |
-------------------------------------
Eval num_timesteps=90000, episode_reward=-0.78 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007289921  |
| clipfrac           | 0.09604492   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.649        |
| fps                | 1539         |
| n_updates          | 44           |
| policy_entropy     | 8.003595     |
| policy_loss        | -0.008485125 |
| serial_timesteps   | 11264        |
| time_elapsed       | 45.8         |
| total_timesteps    | 90112        |
| value_loss         | 0.03692048   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007356924  |
| clipfrac           | 0.103125     |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.693        |
| fps                | 2127         |
| n_updates          | 45           |
| policy_entropy     | 7.9802246    |
| policy_loss        | -0.012064105 |
| serial_timesteps   | 11520        |
| time_elapsed       | 47.1         |
| total_timesteps    | 92160        |
| value_loss         | 0.040020205  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008036168  |
| clipfrac           | 0.1071289    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.676        |
| fps                | 2135         |
| n_updates          | 46           |
| policy_entropy     | 7.96131      |
| policy_loss        | -0.012044687 |
| serial_timesteps   | 11776        |
| time_elapsed       | 48.1         |
| total_timesteps    | 94208        |
| value_loss         | 0.033702597  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077804374 |
| clipfrac           | 0.099365234  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.689        |
| fps                | 2129         |
| n_updates          | 47           |
| policy_entropy     | 7.9262085    |
| policy_loss        | -0.00950033  |
| serial_timesteps   | 12032        |
| time_elapsed       | 49           |
| total_timesteps    | 96256        |
| value_loss         | 0.04613088   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007872069  |
| clipfrac           | 0.10541992   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.727        |
| fps                | 2181         |
| n_updates          | 48           |
| policy_entropy     | 7.9075713    |
| policy_loss        | -0.010935981 |
| serial_timesteps   | 12288        |
| time_elapsed       | 50           |
| total_timesteps    | 98304        |
| value_loss         | 0.033591487  |
-------------------------------------
Eval num_timesteps=100000, episode_reward=-0.51 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0069733015 |
| clipfrac           | 0.09472656   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.781        |
| fps                | 1453         |
| n_updates          | 49           |
| policy_entropy     | 7.8935766    |
| policy_loss        | -0.009745344 |
| serial_timesteps   | 12544        |
| time_elapsed       | 50.9         |
| total_timesteps    | 100352       |
| value_loss         | 0.032471467  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0072792494 |
| clipfrac           | 0.09423828   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.78         |
| fps                | 2135         |
| n_updates          | 50           |
| policy_entropy     | 7.8715615    |
| policy_loss        | -0.010394122 |
| serial_timesteps   | 12800        |
| time_elapsed       | 52.3         |
| total_timesteps    | 102400       |
| value_loss         | 0.035786264  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008325981  |
| clipfrac           | 0.117773436  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.677        |
| fps                | 2132         |
| n_updates          | 51           |
| policy_entropy     | 7.84842      |
| policy_loss        | -0.011439198 |
| serial_timesteps   | 13056        |
| time_elapsed       | 53.3         |
| total_timesteps    | 104448       |
| value_loss         | 0.04189771   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0062876022 |
| clipfrac           | 0.07631836   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.752        |
| fps                | 2129         |
| n_updates          | 52           |
| policy_entropy     | 7.8293405    |
| policy_loss        | -0.009264666 |
| serial_timesteps   | 13312        |
| time_elapsed       | 54.3         |
| total_timesteps    | 106496       |
| value_loss         | 0.036584318  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0082595525 |
| clipfrac           | 0.11254883   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.646        |
| fps                | 2102         |
| n_updates          | 53           |
| policy_entropy     | 7.807055     |
| policy_loss        | -0.011102186 |
| serial_timesteps   | 13568        |
| time_elapsed       | 55.2         |
| total_timesteps    | 108544       |
| value_loss         | 0.033271607  |
-------------------------------------
Eval num_timesteps=110000, episode_reward=-0.71 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0074165845 |
| clipfrac           | 0.097802736  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.775        |
| fps                | 1514         |
| n_updates          | 54           |
| policy_entropy     | 7.7814765    |
| policy_loss        | -0.010378614 |
| serial_timesteps   | 13824        |
| time_elapsed       | 56.2         |
| total_timesteps    | 110592       |
| value_loss         | 0.029156018  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008582916  |
| clipfrac           | 0.12128906   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.729        |
| fps                | 2134         |
| n_updates          | 55           |
| policy_entropy     | 7.7629066    |
| policy_loss        | -0.012653287 |
| serial_timesteps   | 14080        |
| time_elapsed       | 57.5         |
| total_timesteps    | 112640       |
| value_loss         | 0.027797136  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007819275  |
| clipfrac           | 0.1050293    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.784        |
| fps                | 2168         |
| n_updates          | 56           |
| policy_entropy     | 7.733712     |
| policy_loss        | -0.008851265 |
| serial_timesteps   | 14336        |
| time_elapsed       | 58.5         |
| total_timesteps    | 114688       |
| value_loss         | 0.032348845  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008140156  |
| clipfrac           | 0.10834961   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.716        |
| fps                | 2170         |
| n_updates          | 57           |
| policy_entropy     | 7.7031503    |
| policy_loss        | -0.013593091 |
| serial_timesteps   | 14592        |
| time_elapsed       | 59.5         |
| total_timesteps    | 116736       |
| value_loss         | 0.03329594   |
-------------------------------------
--------------------------------------
| approxkl           | 0.008915062   |
| clipfrac           | 0.11767578    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.49         |
| explained_variance | 0.669         |
| fps                | 2180          |
| n_updates          | 58            |
| policy_entropy     | 7.697272      |
| policy_loss        | -0.0144340005 |
| serial_timesteps   | 14848         |
| time_elapsed       | 60.4          |
| total_timesteps    | 118784        |
| value_loss         | 0.0498885     |
--------------------------------------
Eval num_timesteps=120000, episode_reward=-1.28 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.00830777   |
| clipfrac           | 0.11279297   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.72         |
| fps                | 1530         |
| n_updates          | 59           |
| policy_entropy     | 7.685514     |
| policy_loss        | -0.011829795 |
| serial_timesteps   | 15104        |
| time_elapsed       | 61.3         |
| total_timesteps    | 120832       |
| value_loss         | 0.03846755   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008122737  |
| clipfrac           | 0.099365234  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.688        |
| fps                | 2159         |
| n_updates          | 60           |
| policy_entropy     | 7.6837807    |
| policy_loss        | -0.011624519 |
| serial_timesteps   | 15360        |
| time_elapsed       | 62.7         |
| total_timesteps    | 122880       |
| value_loss         | 0.04132989   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00740769   |
| clipfrac           | 0.101660155  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.782        |
| fps                | 2165         |
| n_updates          | 61           |
| policy_entropy     | 7.6803474    |
| policy_loss        | -0.011030121 |
| serial_timesteps   | 15616        |
| time_elapsed       | 63.6         |
| total_timesteps    | 124928       |
| value_loss         | 0.032176215  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0074929884 |
| clipfrac           | 0.10517578   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.732        |
| fps                | 2194         |
| n_updates          | 62           |
| policy_entropy     | 7.648538     |
| policy_loss        | -0.011506247 |
| serial_timesteps   | 15872        |
| time_elapsed       | 64.6         |
| total_timesteps    | 126976       |
| value_loss         | 0.03246956   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008663058  |
| clipfrac           | 0.116601564  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.768        |
| fps                | 2172         |
| n_updates          | 63           |
| policy_entropy     | 7.6273947    |
| policy_loss        | -0.010948278 |
| serial_timesteps   | 16128        |
| time_elapsed       | 65.5         |
| total_timesteps    | 129024       |
| value_loss         | 0.040202163  |
-------------------------------------
Eval num_timesteps=130000, episode_reward=-1.32 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007336758  |
| clipfrac           | 0.093652345  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.752        |
| fps                | 1502         |
| n_updates          | 64           |
| policy_entropy     | 7.585519     |
| policy_loss        | -0.011024106 |
| serial_timesteps   | 16384        |
| time_elapsed       | 66.4         |
| total_timesteps    | 131072       |
| value_loss         | 0.031972416  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007453007  |
| clipfrac           | 0.1          |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.767        |
| fps                | 2153         |
| n_updates          | 65           |
| policy_entropy     | 7.532116     |
| policy_loss        | -0.011843444 |
| serial_timesteps   | 16640        |
| time_elapsed       | 67.8         |
| total_timesteps    | 133120       |
| value_loss         | 0.028720567  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0068839206 |
| clipfrac           | 0.08730469   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.696        |
| fps                | 2156         |
| n_updates          | 66           |
| policy_entropy     | 7.502726     |
| policy_loss        | -0.011941827 |
| serial_timesteps   | 16896        |
| time_elapsed       | 68.8         |
| total_timesteps    | 135168       |
| value_loss         | 0.025033643  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008104899  |
| clipfrac           | 0.10600586   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.701        |
| fps                | 2133         |
| n_updates          | 67           |
| policy_entropy     | 7.484713     |
| policy_loss        | -0.012246167 |
| serial_timesteps   | 17152        |
| time_elapsed       | 69.7         |
| total_timesteps    | 137216       |
| value_loss         | 0.036577158  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0078029744 |
| clipfrac           | 0.104882814  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.743        |
| fps                | 2116         |
| n_updates          | 68           |
| policy_entropy     | 7.460473     |
| policy_loss        | -0.010408824 |
| serial_timesteps   | 17408        |
| time_elapsed       | 70.7         |
| total_timesteps    | 139264       |
| value_loss         | 0.03128566   |
-------------------------------------
Eval num_timesteps=140000, episode_reward=-1.26 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0077067735 |
| clipfrac           | 0.109960936  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.751        |
| fps                | 1418         |
| n_updates          | 69           |
| policy_entropy     | 7.4347925    |
| policy_loss        | -0.010154275 |
| serial_timesteps   | 17664        |
| time_elapsed       | 71.6         |
| total_timesteps    | 141312       |
| value_loss         | 0.03152469   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0075994334 |
| clipfrac           | 0.099121094  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.786        |
| fps                | 2100         |
| n_updates          | 70           |
| policy_entropy     | 7.397151     |
| policy_loss        | -0.010372454 |
| serial_timesteps   | 17920        |
| time_elapsed       | 73.1         |
| total_timesteps    | 143360       |
| value_loss         | 0.034047585  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0069545032 |
| clipfrac           | 0.091601565  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.758        |
| fps                | 2131         |
| n_updates          | 71           |
| policy_entropy     | 7.3753495    |
| policy_loss        | -0.007564751 |
| serial_timesteps   | 18176        |
| time_elapsed       | 74.1         |
| total_timesteps    | 145408       |
| value_loss         | 0.0310697    |
-------------------------------------
-------------------------------------
| approxkl           | 0.00693559   |
| clipfrac           | 0.08828125   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.814        |
| fps                | 2102         |
| n_updates          | 72           |
| policy_entropy     | 7.3673697    |
| policy_loss        | -0.008689335 |
| serial_timesteps   | 18432        |
| time_elapsed       | 75           |
| total_timesteps    | 147456       |
| value_loss         | 0.028797071  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0073984666 |
| clipfrac           | 0.09814453   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.716        |
| fps                | 2109         |
| n_updates          | 73           |
| policy_entropy     | 7.3660064    |
| policy_loss        | -0.010329902 |
| serial_timesteps   | 18688        |
| time_elapsed       | 76           |
| total_timesteps    | 149504       |
| value_loss         | 0.035607465  |
-------------------------------------
Eval num_timesteps=150000, episode_reward=-1.11 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007894719  |
| clipfrac           | 0.10898437   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.799        |
| fps                | 1501         |
| n_updates          | 74           |
| policy_entropy     | 7.337696     |
| policy_loss        | -0.009879915 |
| serial_timesteps   | 18944        |
| time_elapsed       | 77           |
| total_timesteps    | 151552       |
| value_loss         | 0.03171245   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007668534  |
| clipfrac           | 0.10288086   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.776        |
| fps                | 2162         |
| n_updates          | 75           |
| policy_entropy     | 7.313803     |
| policy_loss        | -0.010580681 |
| serial_timesteps   | 19200        |
| time_elapsed       | 78.3         |
| total_timesteps    | 153600       |
| value_loss         | 0.029786056  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007117264  |
| clipfrac           | 0.09189453   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.684        |
| fps                | 2050         |
| n_updates          | 76           |
| policy_entropy     | 7.2937913    |
| policy_loss        | -0.006725733 |
| serial_timesteps   | 19456        |
| time_elapsed       | 79.3         |
| total_timesteps    | 155648       |
| value_loss         | 0.03894686   |
-------------------------------------
--------------------------------------
| approxkl           | 0.008328495   |
| clipfrac           | 0.113378905   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.44         |
| explained_variance | 0.785         |
| fps                | 2143          |
| n_updates          | 77            |
| policy_entropy     | 7.280842      |
| policy_loss        | -0.0125187365 |
| serial_timesteps   | 19712         |
| time_elapsed       | 80.3          |
| total_timesteps    | 157696        |
| value_loss         | 0.028945893   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0071945554 |
| clipfrac           | 0.09951172   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.733        |
| fps                | 2143         |
| n_updates          | 78           |
| policy_entropy     | 7.2983985    |
| policy_loss        | -0.009546033 |
| serial_timesteps   | 19968        |
| time_elapsed       | 81.2         |
| total_timesteps    | 159744       |
| value_loss         | 0.039768085  |
-------------------------------------
Eval num_timesteps=160000, episode_reward=-1.05 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007544203  |
| clipfrac           | 0.10117187   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.816        |
| fps                | 1504         |
| n_updates          | 79           |
| policy_entropy     | 7.3021965    |
| policy_loss        | -0.008856105 |
| serial_timesteps   | 20224        |
| time_elapsed       | 82.2         |
| total_timesteps    | 161792       |
| value_loss         | 0.034735836  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008222266  |
| clipfrac           | 0.11674805   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.78         |
| fps                | 2058         |
| n_updates          | 80           |
| policy_entropy     | 7.288508     |
| policy_loss        | -0.009385517 |
| serial_timesteps   | 20480        |
| time_elapsed       | 83.6         |
| total_timesteps    | 163840       |
| value_loss         | 0.0350662    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008644985  |
| clipfrac           | 0.120507814  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.773        |
| fps                | 2159         |
| n_updates          | 81           |
| policy_entropy     | 7.272714     |
| policy_loss        | -0.011293855 |
| serial_timesteps   | 20736        |
| time_elapsed       | 84.5         |
| total_timesteps    | 165888       |
| value_loss         | 0.034564056  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007916162  |
| clipfrac           | 0.10751953   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.817        |
| fps                | 2170         |
| n_updates          | 82           |
| policy_entropy     | 7.256274     |
| policy_loss        | -0.011102859 |
| serial_timesteps   | 20992        |
| time_elapsed       | 85.5         |
| total_timesteps    | 167936       |
| value_loss         | 0.028714534  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008565275   |
| clipfrac           | 0.12001953    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.44         |
| explained_variance | 0.783         |
| fps                | 2184          |
| n_updates          | 83            |
| policy_entropy     | 7.2316732     |
| policy_loss        | -0.0117062675 |
| serial_timesteps   | 21248         |
| time_elapsed       | 86.4          |
| total_timesteps    | 169984        |
| value_loss         | 0.03674806    |
--------------------------------------
Eval num_timesteps=170000, episode_reward=-1.05 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.01007274   |
| clipfrac           | 0.13916016   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.759        |
| fps                | 1559         |
| n_updates          | 84           |
| policy_entropy     | 7.2133417    |
| policy_loss        | -0.012587385 |
| serial_timesteps   | 21504        |
| time_elapsed       | 87.4         |
| total_timesteps    | 172032       |
| value_loss         | 0.030604169  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008018978  |
| clipfrac           | 0.10986328   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.5          |
| fps                | 2205         |
| n_updates          | 85           |
| policy_entropy     | 7.1901298    |
| policy_loss        | -0.009909312 |
| serial_timesteps   | 21760        |
| time_elapsed       | 88.7         |
| total_timesteps    | 174080       |
| value_loss         | 0.062095266  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008421552  |
| clipfrac           | 0.11806641   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.736        |
| fps                | 2181         |
| n_updates          | 86           |
| policy_entropy     | 7.1652894    |
| policy_loss        | -0.012728971 |
| serial_timesteps   | 22016        |
| time_elapsed       | 89.6         |
| total_timesteps    | 176128       |
| value_loss         | 0.03714757   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0074294405 |
| clipfrac           | 0.10136719   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.741        |
| fps                | 2211         |
| n_updates          | 87           |
| policy_entropy     | 7.1396117    |
| policy_loss        | -0.009807644 |
| serial_timesteps   | 22272        |
| time_elapsed       | 90.6         |
| total_timesteps    | 178176       |
| value_loss         | 0.03032226   |
-------------------------------------
Eval num_timesteps=180000, episode_reward=-1.18 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009406764   |
| clipfrac           | 0.1350586     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.5          |
| explained_variance | 0.71          |
| fps                | 1395          |
| n_updates          | 88            |
| policy_entropy     | 7.121402      |
| policy_loss        | -0.0121944295 |
| serial_timesteps   | 22528         |
| time_elapsed       | 91.5          |
| total_timesteps    | 180224        |
| value_loss         | 0.045744576   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009207225  |
| clipfrac           | 0.12338867   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.496        |
| fps                | 2108         |
| n_updates          | 89           |
| policy_entropy     | 7.0983076    |
| policy_loss        | -0.013817477 |
| serial_timesteps   | 22784        |
| time_elapsed       | 93           |
| total_timesteps    | 182272       |
| value_loss         | 0.0684441    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008653497  |
| clipfrac           | 0.11884765   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.741        |
| fps                | 2130         |
| n_updates          | 90           |
| policy_entropy     | 7.0764933    |
| policy_loss        | -0.013419107 |
| serial_timesteps   | 23040        |
| time_elapsed       | 93.9         |
| total_timesteps    | 184320       |
| value_loss         | 0.037326075  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009337889  |
| clipfrac           | 0.13417968   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.674        |
| fps                | 2138         |
| n_updates          | 91           |
| policy_entropy     | 7.0508814    |
| policy_loss        | -0.014161865 |
| serial_timesteps   | 23296        |
| time_elapsed       | 94.9         |
| total_timesteps    | 186368       |
| value_loss         | 0.042781994  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007545489  |
| clipfrac           | 0.09868164   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.743        |
| fps                | 2098         |
| n_updates          | 92           |
| policy_entropy     | 7.033764     |
| policy_loss        | -0.008899665 |
| serial_timesteps   | 23552        |
| time_elapsed       | 95.8         |
| total_timesteps    | 188416       |
| value_loss         | 0.03887308   |
-------------------------------------
Eval num_timesteps=190000, episode_reward=-1.00 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.00784672   |
| clipfrac           | 0.10551758   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.785        |
| fps                | 1519         |
| n_updates          | 93           |
| policy_entropy     | 7.0189934    |
| policy_loss        | -0.009003565 |
| serial_timesteps   | 23808        |
| time_elapsed       | 96.8         |
| total_timesteps    | 190464       |
| value_loss         | 0.03537316   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008901048  |
| clipfrac           | 0.122558594  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.663        |
| fps                | 2196         |
| n_updates          | 94           |
| policy_entropy     | 7.0141897    |
| policy_loss        | -0.012497538 |
| serial_timesteps   | 24064        |
| time_elapsed       | 98.2         |
| total_timesteps    | 192512       |
| value_loss         | 0.050003838  |
-------------------------------------
------------------------------------
| approxkl           | 0.008818058 |
| clipfrac           | 0.12431641  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.55       |
| explained_variance | 0.773       |
| fps                | 2113        |
| n_updates          | 95          |
| policy_entropy     | 7.0110826   |
| policy_loss        | -0.01148947 |
| serial_timesteps   | 24320       |
| time_elapsed       | 99.1        |
| total_timesteps    | 194560      |
| value_loss         | 0.04163203  |
------------------------------------
-------------------------------------
| approxkl           | 0.009591274  |
| clipfrac           | 0.13720703   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.706        |
| fps                | 2136         |
| n_updates          | 96           |
| policy_entropy     | 6.9989967    |
| policy_loss        | -0.014663625 |
| serial_timesteps   | 24576        |
| time_elapsed       | 100          |
| total_timesteps    | 196608       |
| value_loss         | 0.04365149   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008849694  |
| clipfrac           | 0.12368164   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.784        |
| fps                | 2089         |
| n_updates          | 97           |
| policy_entropy     | 6.9793997    |
| policy_loss        | -0.011433812 |
| serial_timesteps   | 24832        |
| time_elapsed       | 101          |
| total_timesteps    | 198656       |
| value_loss         | 0.038671046  |
-------------------------------------
Eval num_timesteps=200000, episode_reward=-0.69 +/- 0.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008982735  |
| clipfrac           | 0.12475586   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.773        |
| fps                | 1445         |
| n_updates          | 98           |
| policy_entropy     | 6.9762983    |
| policy_loss        | -0.013774062 |
| serial_timesteps   | 25088        |
| time_elapsed       | 102          |
| total_timesteps    | 200704       |
| value_loss         | 0.030779645  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00781334   |
| clipfrac           | 0.11040039   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.769        |
| fps                | 2080         |
| n_updates          | 99           |
| policy_entropy     | 6.986352     |
| policy_loss        | -0.010441203 |
| serial_timesteps   | 25344        |
| time_elapsed       | 103          |
| total_timesteps    | 202752       |
| value_loss         | 0.040839855  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008047717   |
| clipfrac           | 0.11069336    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.5          |
| explained_variance | 0.765         |
| fps                | 2148          |
| n_updates          | 100           |
| policy_entropy     | 6.9725585     |
| policy_loss        | -0.0108745815 |
| serial_timesteps   | 25600         |
| time_elapsed       | 104           |
| total_timesteps    | 204800        |
| value_loss         | 0.037054434   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008077176  |
| clipfrac           | 0.11147461   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.763        |
| fps                | 2090         |
| n_updates          | 101          |
| policy_entropy     | 6.9523935    |
| policy_loss        | -0.012248695 |
| serial_timesteps   | 25856        |
| time_elapsed       | 105          |
| total_timesteps    | 206848       |
| value_loss         | 0.03866214   |
-------------------------------------
------------------------------------
| approxkl           | 0.007324071 |
| clipfrac           | 0.095214844 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.49       |
| explained_variance | 0.719       |
| fps                | 2133        |
| n_updates          | 102         |
| policy_entropy     | 6.9416146   |
| policy_loss        | -0.00918722 |
| serial_timesteps   | 26112       |
| time_elapsed       | 106         |
| total_timesteps    | 208896      |
| value_loss         | 0.047222503 |
------------------------------------
Eval num_timesteps=210000, episode_reward=-1.14 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.008319449   |
| clipfrac           | 0.11025391    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.52         |
| explained_variance | 0.789         |
| fps                | 1515          |
| n_updates          | 103           |
| policy_entropy     | 6.926709      |
| policy_loss        | -0.0120268185 |
| serial_timesteps   | 26368         |
| time_elapsed       | 107           |
| total_timesteps    | 210944        |
| value_loss         | 0.02601633    |
--------------------------------------
-------------------------------------
| approxkl           | 0.009367415  |
| clipfrac           | 0.13046876   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.792        |
| fps                | 2144         |
| n_updates          | 104          |
| policy_entropy     | 6.914444     |
| policy_loss        | -0.012887044 |
| serial_timesteps   | 26624        |
| time_elapsed       | 109          |
| total_timesteps    | 212992       |
| value_loss         | 0.037439223  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008708334  |
| clipfrac           | 0.11699219   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.759        |
| fps                | 2170         |
| n_updates          | 105          |
| policy_entropy     | 6.9182396    |
| policy_loss        | -0.012196302 |
| serial_timesteps   | 26880        |
| time_elapsed       | 110          |
| total_timesteps    | 215040       |
| value_loss         | 0.034926392  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009990251  |
| clipfrac           | 0.1461914    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.827        |
| fps                | 2135         |
| n_updates          | 106          |
| policy_entropy     | 6.9109993    |
| policy_loss        | -0.012267378 |
| serial_timesteps   | 27136        |
| time_elapsed       | 111          |
| total_timesteps    | 217088       |
| value_loss         | 0.032179434  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008084128  |
| clipfrac           | 0.1137207    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.678        |
| fps                | 2083         |
| n_updates          | 107          |
| policy_entropy     | 6.900412     |
| policy_loss        | -0.010224374 |
| serial_timesteps   | 27392        |
| time_elapsed       | 112          |
| total_timesteps    | 219136       |
| value_loss         | 0.042220216  |
-------------------------------------
Eval num_timesteps=220000, episode_reward=-0.96 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0085242875 |
| clipfrac           | 0.11826172   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.763        |
| fps                | 1517         |
| n_updates          | 108          |
| policy_entropy     | 6.9006066    |
| policy_loss        | -0.012970069 |
| serial_timesteps   | 27648        |
| time_elapsed       | 113          |
| total_timesteps    | 221184       |
| value_loss         | 0.037157916  |
-------------------------------------
------------------------------------
| approxkl           | 0.008595567 |
| clipfrac           | 0.12021484  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.56       |
| explained_variance | 0.704       |
| fps                | 2130        |
| n_updates          | 109         |
| policy_entropy     | 6.907304    |
| policy_loss        | -0.01241617 |
| serial_timesteps   | 27904       |
| time_elapsed       | 114         |
| total_timesteps    | 223232      |
| value_loss         | 0.043171126 |
------------------------------------
-------------------------------------
| approxkl           | 0.007833498  |
| clipfrac           | 0.11015625   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.707        |
| fps                | 2120         |
| n_updates          | 110          |
| policy_entropy     | 6.9097786    |
| policy_loss        | -0.009569878 |
| serial_timesteps   | 28160        |
| time_elapsed       | 115          |
| total_timesteps    | 225280       |
| value_loss         | 0.035637356  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0073998617 |
| clipfrac           | 0.09663086   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.767        |
| fps                | 2114         |
| n_updates          | 111          |
| policy_entropy     | 6.887641     |
| policy_loss        | -0.009500138 |
| serial_timesteps   | 28416        |
| time_elapsed       | 116          |
| total_timesteps    | 227328       |
| value_loss         | 0.03530614   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008617205  |
| clipfrac           | 0.119580075  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.707        |
| fps                | 2147         |
| n_updates          | 112          |
| policy_entropy     | 6.847833     |
| policy_loss        | -0.011027259 |
| serial_timesteps   | 28672        |
| time_elapsed       | 117          |
| total_timesteps    | 229376       |
| value_loss         | 0.033900656  |
-------------------------------------
Eval num_timesteps=230000, episode_reward=-1.03 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007918602  |
| clipfrac           | 0.101220705  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.705        |
| fps                | 1466         |
| n_updates          | 113          |
| policy_entropy     | 6.842589     |
| policy_loss        | -0.010146252 |
| serial_timesteps   | 28928        |
| time_elapsed       | 118          |
| total_timesteps    | 231424       |
| value_loss         | 0.041181322  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009619227  |
| clipfrac           | 0.13227539   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.736        |
| fps                | 2021         |
| n_updates          | 114          |
| policy_entropy     | 6.8146186    |
| policy_loss        | -0.011557683 |
| serial_timesteps   | 29184        |
| time_elapsed       | 119          |
| total_timesteps    | 233472       |
| value_loss         | 0.032472692  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008174754  |
| clipfrac           | 0.11401367   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.803        |
| fps                | 2021         |
| n_updates          | 115          |
| policy_entropy     | 6.765831     |
| policy_loss        | -0.010161155 |
| serial_timesteps   | 29440        |
| time_elapsed       | 120          |
| total_timesteps    | 235520       |
| value_loss         | 0.031731028  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008244779  |
| clipfrac           | 0.11254883   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.774        |
| fps                | 2145         |
| n_updates          | 116          |
| policy_entropy     | 6.7481737    |
| policy_loss        | -0.011088817 |
| serial_timesteps   | 29696        |
| time_elapsed       | 121          |
| total_timesteps    | 237568       |
| value_loss         | 0.030804625  |
-------------------------------------
--------------------------------------
| approxkl           | 0.006508339   |
| clipfrac           | 0.080078125   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.56         |
| explained_variance | 0.713         |
| fps                | 2083          |
| n_updates          | 117           |
| policy_entropy     | 6.7424736     |
| policy_loss        | -0.0068892054 |
| serial_timesteps   | 29952         |
| time_elapsed       | 122           |
| total_timesteps    | 239616        |
| value_loss         | 0.036379702   |
--------------------------------------
Eval num_timesteps=240000, episode_reward=-1.03 +/- 0.01
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.00797792  |
| clipfrac           | 0.108105466 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.52       |
| explained_variance | 0.782       |
| fps                | 1479        |
| n_updates          | 118         |
| policy_entropy     | 6.723401    |
| policy_loss        | -0.01115828 |
| serial_timesteps   | 30208       |
| time_elapsed       | 123         |
| total_timesteps    | 241664      |
| value_loss         | 0.03922356  |
------------------------------------
-------------------------------------
| approxkl           | 0.008390104  |
| clipfrac           | 0.11357422   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.764        |
| fps                | 2127         |
| n_updates          | 119          |
| policy_entropy     | 6.7101846    |
| policy_loss        | -0.010685502 |
| serial_timesteps   | 30464        |
| time_elapsed       | 124          |
| total_timesteps    | 243712       |
| value_loss         | 0.03045163   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009205851  |
| clipfrac           | 0.12451172   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.753        |
| fps                | 2124         |
| n_updates          | 120          |
| policy_entropy     | 6.705304     |
| policy_loss        | -0.013568072 |
| serial_timesteps   | 30720        |
| time_elapsed       | 125          |
| total_timesteps    | 245760       |
| value_loss         | 0.042852685  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008283181  |
| clipfrac           | 0.110839844  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.78         |
| fps                | 2169         |
| n_updates          | 121          |
| policy_entropy     | 6.690871     |
| policy_loss        | -0.011084635 |
| serial_timesteps   | 30976        |
| time_elapsed       | 126          |
| total_timesteps    | 247808       |
| value_loss         | 0.03622543   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0075791627 |
| clipfrac           | 0.10117187   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.778        |
| fps                | 2143         |
| n_updates          | 122          |
| policy_entropy     | 6.67883      |
| policy_loss        | -0.009675015 |
| serial_timesteps   | 31232        |
| time_elapsed       | 127          |
| total_timesteps    | 249856       |
| value_loss         | 0.04125707   |
-------------------------------------
Eval num_timesteps=250000, episode_reward=-0.60 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0074751573 |
| clipfrac           | 0.10253906   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | 0.749        |
| fps                | 1539         |
| n_updates          | 123          |
| policy_entropy     | 6.677237     |
| policy_loss        | -0.009440822 |
| serial_timesteps   | 31488        |
| time_elapsed       | 128          |
| total_timesteps    | 251904       |
| value_loss         | 0.040269274  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008161115  |
| clipfrac           | 0.113427736  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.65        |
| explained_variance | 0.732        |
| fps                | 2165         |
| n_updates          | 124          |
| policy_entropy     | 6.678487     |
| policy_loss        | -0.009799624 |
| serial_timesteps   | 31744        |
| time_elapsed       | 130          |
| total_timesteps    | 253952       |
| value_loss         | 0.049012102  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009098689   |
| clipfrac           | 0.13500977    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.66         |
| explained_variance | 0.688         |
| fps                | 2106          |
| n_updates          | 125           |
| policy_entropy     | 6.69568       |
| policy_loss        | -0.0126916785 |
| serial_timesteps   | 32000         |
| time_elapsed       | 131           |
| total_timesteps    | 256000        |
| value_loss         | 0.057776332   |
--------------------------------------
--------------------------------------
| approxkl           | 0.0074842074  |
| clipfrac           | 0.10219727    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.65         |
| explained_variance | 0.758         |
| fps                | 2117          |
| n_updates          | 126           |
| policy_entropy     | 6.6991906     |
| policy_loss        | -0.0092336405 |
| serial_timesteps   | 32256         |
| time_elapsed       | 132           |
| total_timesteps    | 258048        |
| value_loss         | 0.04048191    |
--------------------------------------
Eval num_timesteps=260000, episode_reward=-0.63 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0093918685 |
| clipfrac           | 0.13461915   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.67        |
| explained_variance | 0.659        |
| fps                | 1539         |
| n_updates          | 127          |
| policy_entropy     | 6.6933722    |
| policy_loss        | -0.010373007 |
| serial_timesteps   | 32512        |
| time_elapsed       | 132          |
| total_timesteps    | 260096       |
| value_loss         | 0.06322545   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009848227  |
| clipfrac           | 0.13652344   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.67        |
| explained_variance | 0.737        |
| fps                | 2174         |
| n_updates          | 128          |
| policy_entropy     | 6.701953     |
| policy_loss        | -0.015034815 |
| serial_timesteps   | 32768        |
| time_elapsed       | 134          |
| total_timesteps    | 262144       |
| value_loss         | 0.04294517   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0075584403  |
| clipfrac           | 0.09995117    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.66         |
| explained_variance | 0.772         |
| fps                | 2148          |
| n_updates          | 129           |
| policy_entropy     | 6.684892      |
| policy_loss        | -0.0071167424 |
| serial_timesteps   | 33024         |
| time_elapsed       | 135           |
| total_timesteps    | 264192        |
| value_loss         | 0.047026202   |
--------------------------------------
--------------------------------------
| approxkl           | 0.00778146    |
| clipfrac           | 0.101708986   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.63         |
| explained_variance | 0.7           |
| fps                | 2114          |
| n_updates          | 130           |
| policy_entropy     | 6.656443      |
| policy_loss        | -0.0076303137 |
| serial_timesteps   | 33280         |
| time_elapsed       | 136           |
| total_timesteps    | 266240        |
| value_loss         | 0.046880282   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008286985  |
| clipfrac           | 0.1109375    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.66        |
| explained_variance | 0.776        |
| fps                | 2104         |
| n_updates          | 131          |
| policy_entropy     | 6.655938     |
| policy_loss        | -0.009170966 |
| serial_timesteps   | 33536        |
| time_elapsed       | 137          |
| total_timesteps    | 268288       |
| value_loss         | 0.047220487  |
-------------------------------------
Eval num_timesteps=270000, episode_reward=-1.53 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008000427  |
| clipfrac           | 0.10541992   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.746        |
| fps                | 1522         |
| n_updates          | 132          |
| policy_entropy     | 6.636019     |
| policy_loss        | -0.008224861 |
| serial_timesteps   | 33792        |
| time_elapsed       | 138          |
| total_timesteps    | 270336       |
| value_loss         | 0.044372056  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009116944  |
| clipfrac           | 0.12578125   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.65        |
| explained_variance | 0.716        |
| fps                | 2167         |
| n_updates          | 133          |
| policy_entropy     | 6.5943193    |
| policy_loss        | -0.011091278 |
| serial_timesteps   | 34048        |
| time_elapsed       | 139          |
| total_timesteps    | 272384       |
| value_loss         | 0.05369497   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009208716  |
| clipfrac           | 0.13203125   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.753        |
| fps                | 2150         |
| n_updates          | 134          |
| policy_entropy     | 6.58521      |
| policy_loss        | -0.010506674 |
| serial_timesteps   | 34304        |
| time_elapsed       | 140          |
| total_timesteps    | 274432       |
| value_loss         | 0.051130015  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009416818  |
| clipfrac           | 0.13017578   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.805        |
| fps                | 2205         |
| n_updates          | 135          |
| policy_entropy     | 6.599427     |
| policy_loss        | -0.009905449 |
| serial_timesteps   | 34560        |
| time_elapsed       | 141          |
| total_timesteps    | 276480       |
| value_loss         | 0.036467157  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009929539  |
| clipfrac           | 0.1284668    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.748        |
| fps                | 2142         |
| n_updates          | 136          |
| policy_entropy     | 6.5728927    |
| policy_loss        | -0.010437652 |
| serial_timesteps   | 34816        |
| time_elapsed       | 142          |
| total_timesteps    | 278528       |
| value_loss         | 0.040229894  |
-------------------------------------
Eval num_timesteps=280000, episode_reward=-0.58 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008964676  |
| clipfrac           | 0.12827149   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.816        |
| fps                | 1547         |
| n_updates          | 137          |
| policy_entropy     | 6.550454     |
| policy_loss        | -0.011231244 |
| serial_timesteps   | 35072        |
| time_elapsed       | 143          |
| total_timesteps    | 280576       |
| value_loss         | 0.023566924  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0088828765 |
| clipfrac           | 0.12231445   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.822        |
| fps                | 2143         |
| n_updates          | 138          |
| policy_entropy     | 6.5367575    |
| policy_loss        | -0.008779726 |
| serial_timesteps   | 35328        |
| time_elapsed       | 144          |
| total_timesteps    | 282624       |
| value_loss         | 0.03546949   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00794555   |
| clipfrac           | 0.1046875    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.815        |
| fps                | 2142         |
| n_updates          | 139          |
| policy_entropy     | 6.5066147    |
| policy_loss        | -0.008854767 |
| serial_timesteps   | 35584        |
| time_elapsed       | 145          |
| total_timesteps    | 284672       |
| value_loss         | 0.028658742  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010065115  |
| clipfrac           | 0.14482422   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.843        |
| fps                | 2148         |
| n_updates          | 140          |
| policy_entropy     | 6.491089     |
| policy_loss        | -0.012479819 |
| serial_timesteps   | 35840        |
| time_elapsed       | 146          |
| total_timesteps    | 286720       |
| value_loss         | 0.027662959  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009493015  |
| clipfrac           | 0.13857421   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.83         |
| fps                | 2105         |
| n_updates          | 141          |
| policy_entropy     | 6.4449906    |
| policy_loss        | -0.012852602 |
| serial_timesteps   | 36096        |
| time_elapsed       | 147          |
| total_timesteps    | 288768       |
| value_loss         | 0.024856802  |
-------------------------------------
Eval num_timesteps=290000, episode_reward=-0.59 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008660374  |
| clipfrac           | 0.11669922   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.811        |
| fps                | 1531         |
| n_updates          | 142          |
| policy_entropy     | 6.4196424    |
| policy_loss        | -0.009944557 |
| serial_timesteps   | 36352        |
| time_elapsed       | 148          |
| total_timesteps    | 290816       |
| value_loss         | 0.027787957  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00813265   |
| clipfrac           | 0.10991211   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.834        |
| fps                | 2177         |
| n_updates          | 143          |
| policy_entropy     | 6.420109     |
| policy_loss        | -0.008373011 |
| serial_timesteps   | 36608        |
| time_elapsed       | 149          |
| total_timesteps    | 292864       |
| value_loss         | 0.027436953  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008408431  |
| clipfrac           | 0.113183595  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.846        |
| fps                | 2178         |
| n_updates          | 144          |
| policy_entropy     | 6.4004846    |
| policy_loss        | -0.009613739 |
| serial_timesteps   | 36864        |
| time_elapsed       | 150          |
| total_timesteps    | 294912       |
| value_loss         | 0.024452195  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008154898  |
| clipfrac           | 0.11225586   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.87         |
| fps                | 2209         |
| n_updates          | 145          |
| policy_entropy     | 6.3710394    |
| policy_loss        | -0.008675763 |
| serial_timesteps   | 37120        |
| time_elapsed       | 151          |
| total_timesteps    | 296960       |
| value_loss         | 0.02602427   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008871647  |
| clipfrac           | 0.12138672   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.872        |
| fps                | 2177         |
| n_updates          | 146          |
| policy_entropy     | 6.3434825    |
| policy_loss        | -0.010792231 |
| serial_timesteps   | 37376        |
| time_elapsed       | 152          |
| total_timesteps    | 299008       |
| value_loss         | 0.019140597  |
-------------------------------------
Eval num_timesteps=300000, episode_reward=-0.67 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009668321  |
| clipfrac           | 0.13066407   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.875        |
| fps                | 1555         |
| n_updates          | 147          |
| policy_entropy     | 6.3417764    |
| policy_loss        | -0.009495525 |
| serial_timesteps   | 37632        |
| time_elapsed       | 153          |
| total_timesteps    | 301056       |
| value_loss         | 0.027412927  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009219708   |
| clipfrac           | 0.13515624    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.54         |
| explained_variance | 0.773         |
| fps                | 2205          |
| n_updates          | 148           |
| policy_entropy     | 6.341737      |
| policy_loss        | -0.0087473085 |
| serial_timesteps   | 37888         |
| time_elapsed       | 154           |
| total_timesteps    | 303104        |
| value_loss         | 0.034705855   |
--------------------------------------
--------------------------------------
| approxkl           | 0.008040391   |
| clipfrac           | 0.109521486   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.57         |
| explained_variance | 0.849         |
| fps                | 2194          |
| n_updates          | 149           |
| policy_entropy     | 6.3252306     |
| policy_loss        | -0.0062394813 |
| serial_timesteps   | 38144         |
| time_elapsed       | 155           |
| total_timesteps    | 305152        |
| value_loss         | 0.031467933   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008593795  |
| clipfrac           | 0.11928711   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.879        |
| fps                | 2219         |
| n_updates          | 150          |
| policy_entropy     | 6.300151     |
| policy_loss        | -0.008386234 |
| serial_timesteps   | 38400        |
| time_elapsed       | 156          |
| total_timesteps    | 307200       |
| value_loss         | 0.023817878  |
-------------------------------------
------------------------------------
| approxkl           | 0.008185769 |
| clipfrac           | 0.11303711  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.59       |
| explained_variance | 0.805       |
| fps                | 2196        |
| n_updates          | 151         |
| policy_entropy     | 6.256208    |
| policy_loss        | -0.00868329 |
| serial_timesteps   | 38656       |
| time_elapsed       | 157         |
| total_timesteps    | 309248      |
| value_loss         | 0.032399546 |
------------------------------------
Eval num_timesteps=310000, episode_reward=-0.64 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009969497  |
| clipfrac           | 0.14243165   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.851        |
| fps                | 1576         |
| n_updates          | 152          |
| policy_entropy     | 6.244421     |
| policy_loss        | -0.007840652 |
| serial_timesteps   | 38912        |
| time_elapsed       | 158          |
| total_timesteps    | 311296       |
| value_loss         | 0.029412523  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010369239  |
| clipfrac           | 0.14960937   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.842        |
| fps                | 2145         |
| n_updates          | 153          |
| policy_entropy     | 6.251521     |
| policy_loss        | -0.011709442 |
| serial_timesteps   | 39168        |
| time_elapsed       | 159          |
| total_timesteps    | 313344       |
| value_loss         | 0.027455643  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008338148  |
| clipfrac           | 0.115039065  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | 0.861        |
| fps                | 2232         |
| n_updates          | 154          |
| policy_entropy     | 6.239102     |
| policy_loss        | -0.007993376 |
| serial_timesteps   | 39424        |
| time_elapsed       | 160          |
| total_timesteps    | 315392       |
| value_loss         | 0.030511323  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009261799  |
| clipfrac           | 0.13076171   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.841        |
| fps                | 2246         |
| n_updates          | 155          |
| policy_entropy     | 6.236022     |
| policy_loss        | -0.011494873 |
| serial_timesteps   | 39680        |
| time_elapsed       | 161          |
| total_timesteps    | 317440       |
| value_loss         | 0.028101677  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010235984  |
| clipfrac           | 0.14448242   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.866        |
| fps                | 2202         |
| n_updates          | 156          |
| policy_entropy     | 6.2236223    |
| policy_loss        | -0.011158305 |
| serial_timesteps   | 39936        |
| time_elapsed       | 162          |
| total_timesteps    | 319488       |
| value_loss         | 0.031733565  |
-------------------------------------
Eval num_timesteps=320000, episode_reward=-0.72 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.008838415 |
| clipfrac           | 0.1199707   |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.62       |
| explained_variance | 0.833       |
| fps                | 1554        |
| n_updates          | 157         |
| policy_entropy     | 6.1969857   |
| policy_loss        | -0.00970646 |
| serial_timesteps   | 40192       |
| time_elapsed       | 163         |
| total_timesteps    | 321536      |
| value_loss         | 0.02923902  |
------------------------------------
--------------------------------------
| approxkl           | 0.007447851   |
| clipfrac           | 0.096386716   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.61         |
| explained_variance | 0.836         |
| fps                | 2210          |
| n_updates          | 158           |
| policy_entropy     | 6.182866      |
| policy_loss        | -0.0074220644 |
| serial_timesteps   | 40448         |
| time_elapsed       | 164           |
| total_timesteps    | 323584        |
| value_loss         | 0.03058418    |
--------------------------------------
-------------------------------------
| approxkl           | 0.009774516  |
| clipfrac           | 0.14726563   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.813        |
| fps                | 2202         |
| n_updates          | 159          |
| policy_entropy     | 6.1769133    |
| policy_loss        | -0.010697709 |
| serial_timesteps   | 40704        |
| time_elapsed       | 165          |
| total_timesteps    | 325632       |
| value_loss         | 0.038616586  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007680646  |
| clipfrac           | 0.1027832    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | 0.783        |
| fps                | 2206         |
| n_updates          | 160          |
| policy_entropy     | 6.174416     |
| policy_loss        | -0.010921454 |
| serial_timesteps   | 40960        |
| time_elapsed       | 166          |
| total_timesteps    | 327680       |
| value_loss         | 0.039804645  |
-------------------------------------
--------------------------------------
| approxkl           | 0.007976925   |
| clipfrac           | 0.11015625    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.6          |
| explained_variance | 0.832         |
| fps                | 2181          |
| n_updates          | 161           |
| policy_entropy     | 6.1730437     |
| policy_loss        | -0.0067600072 |
| serial_timesteps   | 41216         |
| time_elapsed       | 167           |
| total_timesteps    | 329728        |
| value_loss         | 0.03726306    |
--------------------------------------
Eval num_timesteps=330000, episode_reward=-0.77 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.008703031   |
| clipfrac           | 0.119335935   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.61         |
| explained_variance | 0.773         |
| fps                | 1579          |
| n_updates          | 162           |
| policy_entropy     | 6.159277      |
| policy_loss        | -0.0077876956 |
| serial_timesteps   | 41472         |
| time_elapsed       | 168           |
| total_timesteps    | 331776        |
| value_loss         | 0.044770274   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009825634  |
| clipfrac           | 0.14448242   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.88         |
| fps                | 2223         |
| n_updates          | 163          |
| policy_entropy     | 6.1359587    |
| policy_loss        | -0.010078902 |
| serial_timesteps   | 41728        |
| time_elapsed       | 169          |
| total_timesteps    | 333824       |
| value_loss         | 0.029295567  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008437916  |
| clipfrac           | 0.11445312   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.809        |
| fps                | 2228         |
| n_updates          | 164          |
| policy_entropy     | 6.124929     |
| policy_loss        | -0.005780169 |
| serial_timesteps   | 41984        |
| time_elapsed       | 170          |
| total_timesteps    | 335872       |
| value_loss         | 0.03886783   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010002984  |
| clipfrac           | 0.14267579   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.868        |
| fps                | 2205         |
| n_updates          | 165          |
| policy_entropy     | 6.1096807    |
| policy_loss        | -0.011962699 |
| serial_timesteps   | 42240        |
| time_elapsed       | 171          |
| total_timesteps    | 337920       |
| value_loss         | 0.027911628  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009922609  |
| clipfrac           | 0.14975587   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.795        |
| fps                | 2228         |
| n_updates          | 166          |
| policy_entropy     | 6.1178737    |
| policy_loss        | -0.010327271 |
| serial_timesteps   | 42496        |
| time_elapsed       | 172          |
| total_timesteps    | 339968       |
| value_loss         | 0.04425441   |
-------------------------------------
Eval num_timesteps=340000, episode_reward=-0.71 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.007983038   |
| clipfrac           | 0.10219727    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.63         |
| explained_variance | 0.787         |
| fps                | 1552          |
| n_updates          | 167           |
| policy_entropy     | 6.1569986     |
| policy_loss        | -0.0078452425 |
| serial_timesteps   | 42752         |
| time_elapsed       | 173           |
| total_timesteps    | 342016        |
| value_loss         | 0.046773463   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009620314  |
| clipfrac           | 0.13334961   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.812        |
| fps                | 2214         |
| n_updates          | 168          |
| policy_entropy     | 6.174747     |
| policy_loss        | -0.009015591 |
| serial_timesteps   | 43008        |
| time_elapsed       | 174          |
| total_timesteps    | 344064       |
| value_loss         | 0.04702276   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009794589  |
| clipfrac           | 0.13857421   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.823        |
| fps                | 2220         |
| n_updates          | 169          |
| policy_entropy     | 6.16002      |
| policy_loss        | -0.010458568 |
| serial_timesteps   | 43264        |
| time_elapsed       | 175          |
| total_timesteps    | 346112       |
| value_loss         | 0.03881683   |
-------------------------------------
--------------------------------------
| approxkl           | 0.007699198   |
| clipfrac           | 0.10522461    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.65         |
| explained_variance | 0.856         |
| fps                | 2216          |
| n_updates          | 170           |
| policy_entropy     | 6.167604      |
| policy_loss        | -0.0054695066 |
| serial_timesteps   | 43520         |
| time_elapsed       | 176           |
| total_timesteps    | 348160        |
| value_loss         | 0.036206007   |
--------------------------------------
Eval num_timesteps=350000, episode_reward=-0.69 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009241926   |
| clipfrac           | 0.123095706   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.65         |
| explained_variance | 0.818         |
| fps                | 1581          |
| n_updates          | 171           |
| policy_entropy     | 6.1619825     |
| policy_loss        | -0.0093265185 |
| serial_timesteps   | 43776         |
| time_elapsed       | 177           |
| total_timesteps    | 350208        |
| value_loss         | 0.037090205   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009734305  |
| clipfrac           | 0.13979492   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.65        |
| explained_variance | 0.838        |
| fps                | 2179         |
| n_updates          | 172          |
| policy_entropy     | 6.1520076    |
| policy_loss        | -0.008142955 |
| serial_timesteps   | 44032        |
| time_elapsed       | 179          |
| total_timesteps    | 352256       |
| value_loss         | 0.047357485  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0086555695 |
| clipfrac           | 0.118945315  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.83         |
| fps                | 2186         |
| n_updates          | 173          |
| policy_entropy     | 6.1693697    |
| policy_loss        | -0.009345916 |
| serial_timesteps   | 44288        |
| time_elapsed       | 179          |
| total_timesteps    | 354304       |
| value_loss         | 0.039825782  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0094506955 |
| clipfrac           | 0.13085938   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.844        |
| fps                | 2207         |
| n_updates          | 174          |
| policy_entropy     | 6.1700296    |
| policy_loss        | -0.007677266 |
| serial_timesteps   | 44544        |
| time_elapsed       | 180          |
| total_timesteps    | 356352       |
| value_loss         | 0.034085035  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008636785   |
| clipfrac           | 0.12011719    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.65         |
| explained_variance | 0.818         |
| fps                | 2233          |
| n_updates          | 175           |
| policy_entropy     | 6.166109      |
| policy_loss        | -0.0076443283 |
| serial_timesteps   | 44800         |
| time_elapsed       | 181           |
| total_timesteps    | 358400        |
| value_loss         | 0.039580755   |
--------------------------------------
Eval num_timesteps=360000, episode_reward=-0.72 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010936547  |
| clipfrac           | 0.15961914   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.771        |
| fps                | 1552         |
| n_updates          | 176          |
| policy_entropy     | 6.181636     |
| policy_loss        | -0.012137391 |
| serial_timesteps   | 45056        |
| time_elapsed       | 182          |
| total_timesteps    | 360448       |
| value_loss         | 0.03846624   |
-------------------------------------
--------------------------------------
| approxkl           | 0.009807475   |
| clipfrac           | 0.1381836     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.64         |
| explained_variance | 0.796         |
| fps                | 2148          |
| n_updates          | 177           |
| policy_entropy     | 6.1856003     |
| policy_loss        | -0.0113198925 |
| serial_timesteps   | 45312         |
| time_elapsed       | 184           |
| total_timesteps    | 362496        |
| value_loss         | 0.04965473    |
--------------------------------------
-------------------------------------
| approxkl           | 0.009839942  |
| clipfrac           | 0.1416504    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.65        |
| explained_variance | 0.821        |
| fps                | 2195         |
| n_updates          | 178          |
| policy_entropy     | 6.1910195    |
| policy_loss        | -0.008511967 |
| serial_timesteps   | 45568        |
| time_elapsed       | 185          |
| total_timesteps    | 364544       |
| value_loss         | 0.03756452   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009827051  |
| clipfrac           | 0.14174804   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.851        |
| fps                | 2218         |
| n_updates          | 179          |
| policy_entropy     | 6.191889     |
| policy_loss        | -0.009785408 |
| serial_timesteps   | 45824        |
| time_elapsed       | 185          |
| total_timesteps    | 366592       |
| value_loss         | 0.042150117  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008517931  |
| clipfrac           | 0.12333985   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.808        |
| fps                | 2234         |
| n_updates          | 180          |
| policy_entropy     | 6.184643     |
| policy_loss        | -0.007418547 |
| serial_timesteps   | 46080        |
| time_elapsed       | 186          |
| total_timesteps    | 368640       |
| value_loss         | 0.043581314  |
-------------------------------------
Eval num_timesteps=370000, episode_reward=-0.68 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008770521  |
| clipfrac           | 0.11772461   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.867        |
| fps                | 1546         |
| n_updates          | 181          |
| policy_entropy     | 6.184331     |
| policy_loss        | -0.008216357 |
| serial_timesteps   | 46336        |
| time_elapsed       | 187          |
| total_timesteps    | 370688       |
| value_loss         | 0.033519227  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077181375 |
| clipfrac           | 0.1003418    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.825        |
| fps                | 2189         |
| n_updates          | 182          |
| policy_entropy     | 6.2107553    |
| policy_loss        | -0.01006686  |
| serial_timesteps   | 46592        |
| time_elapsed       | 189          |
| total_timesteps    | 372736       |
| value_loss         | 0.02917153   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008811032  |
| clipfrac           | 0.123242185  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.82         |
| fps                | 2084         |
| n_updates          | 183          |
| policy_entropy     | 6.229574     |
| policy_loss        | -0.008150984 |
| serial_timesteps   | 46848        |
| time_elapsed       | 190          |
| total_timesteps    | 374784       |
| value_loss         | 0.04026537   |
-------------------------------------
--------------------------------------
| approxkl           | 0.009183539   |
| clipfrac           | 0.12817383    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.62         |
| explained_variance | 0.812         |
| fps                | 2148          |
| n_updates          | 184           |
| policy_entropy     | 6.2293243     |
| policy_loss        | -0.0075350134 |
| serial_timesteps   | 47104         |
| time_elapsed       | 191           |
| total_timesteps    | 376832        |
| value_loss         | 0.041079607   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009672103  |
| clipfrac           | 0.13237305   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.791        |
| fps                | 2132         |
| n_updates          | 185          |
| policy_entropy     | 6.2159953    |
| policy_loss        | -0.009925327 |
| serial_timesteps   | 47360        |
| time_elapsed       | 191          |
| total_timesteps    | 378880       |
| value_loss         | 0.04111295   |
-------------------------------------
Eval num_timesteps=380000, episode_reward=-0.77 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008079003  |
| clipfrac           | 0.11142578   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.82         |
| fps                | 1557         |
| n_updates          | 186          |
| policy_entropy     | 6.199962     |
| policy_loss        | -0.007815044 |
| serial_timesteps   | 47616        |
| time_elapsed       | 192          |
| total_timesteps    | 380928       |
| value_loss         | 0.04323874   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008872403  |
| clipfrac           | 0.123291016  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.863        |
| fps                | 2239         |
| n_updates          | 187          |
| policy_entropy     | 6.16317      |
| policy_loss        | -0.008852851 |
| serial_timesteps   | 47872        |
| time_elapsed       | 194          |
| total_timesteps    | 382976       |
| value_loss         | 0.02776898   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008992322  |
| clipfrac           | 0.12763672   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.885        |
| fps                | 2212         |
| n_updates          | 188          |
| policy_entropy     | 6.131316     |
| policy_loss        | -0.008879693 |
| serial_timesteps   | 48128        |
| time_elapsed       | 195          |
| total_timesteps    | 385024       |
| value_loss         | 0.028195571  |
-------------------------------------
------------------------------------
| approxkl           | 0.008572622 |
| clipfrac           | 0.117089845 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.63       |
| explained_variance | 0.9         |
| fps                | 2189        |
| n_updates          | 189         |
| policy_entropy     | 6.122079    |
| policy_loss        | -0.00784136 |
| serial_timesteps   | 48384       |
| time_elapsed       | 196         |
| total_timesteps    | 387072      |
| value_loss         | 0.02076261  |
------------------------------------
-------------------------------------
| approxkl           | 0.008417138  |
| clipfrac           | 0.11582031   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.922        |
| fps                | 2196         |
| n_updates          | 190          |
| policy_entropy     | 6.11312      |
| policy_loss        | -0.007284321 |
| serial_timesteps   | 48640        |
| time_elapsed       | 197          |
| total_timesteps    | 389120       |
| value_loss         | 0.020271944  |
-------------------------------------
Eval num_timesteps=390000, episode_reward=-0.68 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008498161  |
| clipfrac           | 0.11655273   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.846        |
| fps                | 1571         |
| n_updates          | 191          |
| policy_entropy     | 6.103645     |
| policy_loss        | -0.008652376 |
| serial_timesteps   | 48896        |
| time_elapsed       | 197          |
| total_timesteps    | 391168       |
| value_loss         | 0.03354372   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00870664   |
| clipfrac           | 0.12509766   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.879        |
| fps                | 2153         |
| n_updates          | 192          |
| policy_entropy     | 6.084035     |
| policy_loss        | -0.007914919 |
| serial_timesteps   | 49152        |
| time_elapsed       | 199          |
| total_timesteps    | 393216       |
| value_loss         | 0.029568624  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009566069  |
| clipfrac           | 0.13432617   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.849        |
| fps                | 2211         |
| n_updates          | 193          |
| policy_entropy     | 6.0515       |
| policy_loss        | -0.008625435 |
| serial_timesteps   | 49408        |
| time_elapsed       | 200          |
| total_timesteps    | 395264       |
| value_loss         | 0.03746064   |
-------------------------------------
--------------------------------------
| approxkl           | 0.008395645   |
| clipfrac           | 0.11713867    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.59         |
| explained_variance | 0.857         |
| fps                | 2164          |
| n_updates          | 194           |
| policy_entropy     | 6.058428      |
| policy_loss        | -0.0067388937 |
| serial_timesteps   | 49664         |
| time_elapsed       | 201           |
| total_timesteps    | 397312        |
| value_loss         | 0.032537792   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010073795  |
| clipfrac           | 0.14487305   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.871        |
| fps                | 2172         |
| n_updates          | 195          |
| policy_entropy     | 6.0541787    |
| policy_loss        | -0.009871783 |
| serial_timesteps   | 49920        |
| time_elapsed       | 202          |
| total_timesteps    | 399360       |
| value_loss         | 0.03569268   |
-------------------------------------
Eval num_timesteps=400000, episode_reward=-0.64 +/- 0.01
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009577792   |
| clipfrac           | 0.13520508    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.59         |
| explained_variance | 0.861         |
| fps                | 1508          |
| n_updates          | 196           |
| policy_entropy     | 6.015792      |
| policy_loss        | -0.0105950115 |
| serial_timesteps   | 50176         |
| time_elapsed       | 203           |
| total_timesteps    | 401408        |
| value_loss         | 0.032310046   |
--------------------------------------
-------------------------------------
| approxkl           | 0.007805218  |
| clipfrac           | 0.10361328   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.887        |
| fps                | 2197         |
| n_updates          | 197          |
| policy_entropy     | 5.9923944    |
| policy_loss        | -0.007111074 |
| serial_timesteps   | 50432        |
| time_elapsed       | 204          |
| total_timesteps    | 403456       |
| value_loss         | 0.03270875   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008981181  |
| clipfrac           | 0.12519531   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.892        |
| fps                | 2226         |
| n_updates          | 198          |
| policy_entropy     | 5.973251     |
| policy_loss        | -0.008705569 |
| serial_timesteps   | 50688        |
| time_elapsed       | 205          |
| total_timesteps    | 405504       |
| value_loss         | 0.022426745  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008405546   |
| clipfrac           | 0.11401367    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.58         |
| explained_variance | 0.923         |
| fps                | 2221          |
| n_updates          | 199           |
| policy_entropy     | 5.960143      |
| policy_loss        | -0.0067381086 |
| serial_timesteps   | 50944         |
| time_elapsed       | 206           |
| total_timesteps    | 407552        |
| value_loss         | 0.021173924   |
--------------------------------------
-------------------------------------
| approxkl           | 0.011964312  |
| clipfrac           | 0.17504883   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.928        |
| fps                | 2188         |
| n_updates          | 200          |
| policy_entropy     | 5.971196     |
| policy_loss        | -0.016315501 |
| serial_timesteps   | 51200        |
| time_elapsed       | 207          |
| total_timesteps    | 409600       |
| value_loss         | 0.019578543  |
-------------------------------------
Eval num_timesteps=410000, episode_reward=-0.66 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009711755  |
| clipfrac           | 0.14228515   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.903        |
| fps                | 1568         |
| n_updates          | 201          |
| policy_entropy     | 5.984126     |
| policy_loss        | -0.012665102 |
| serial_timesteps   | 51456        |
| time_elapsed       | 208          |
| total_timesteps    | 411648       |
| value_loss         | 0.02202544   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008475467  |
| clipfrac           | 0.1137207    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.913        |
| fps                | 2199         |
| n_updates          | 202          |
| policy_entropy     | 5.9764886    |
| policy_loss        | -0.006498704 |
| serial_timesteps   | 51712        |
| time_elapsed       | 209          |
| total_timesteps    | 413696       |
| value_loss         | 0.0239501    |
-------------------------------------
--------------------------------------
| approxkl           | 0.007942352   |
| clipfrac           | 0.105322264   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.54         |
| explained_variance | 0.892         |
| fps                | 2213          |
| n_updates          | 203           |
| policy_entropy     | 5.965597      |
| policy_loss        | -0.0060191923 |
| serial_timesteps   | 51968         |
| time_elapsed       | 210           |
| total_timesteps    | 415744        |
| value_loss         | 0.024200901   |
--------------------------------------
-------------------------------------
| approxkl           | 0.01018369   |
| clipfrac           | 0.1362793    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.882        |
| fps                | 2208         |
| n_updates          | 204          |
| policy_entropy     | 5.959558     |
| policy_loss        | -0.006532381 |
| serial_timesteps   | 52224        |
| time_elapsed       | 211          |
| total_timesteps    | 417792       |
| value_loss         | 0.03053185   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008344352  |
| clipfrac           | 0.11235352   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.872        |
| fps                | 2193         |
| n_updates          | 205          |
| policy_entropy     | 5.9466076    |
| policy_loss        | -0.008068472 |
| serial_timesteps   | 52480        |
| time_elapsed       | 212          |
| total_timesteps    | 419840       |
| value_loss         | 0.027596813  |
-------------------------------------
Eval num_timesteps=420000, episode_reward=-0.51 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.008807867   |
| clipfrac           | 0.11679687    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.56         |
| explained_variance | 0.899         |
| fps                | 1574          |
| n_updates          | 206           |
| policy_entropy     | 5.9238157     |
| policy_loss        | -0.0074044326 |
| serial_timesteps   | 52736         |
| time_elapsed       | 213           |
| total_timesteps    | 421888        |
| value_loss         | 0.030350918   |
--------------------------------------
--------------------------------------
| approxkl           | 0.007484278   |
| clipfrac           | 0.09584961    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.56         |
| explained_variance | 0.896         |
| fps                | 2215          |
| n_updates          | 207           |
| policy_entropy     | 5.903606      |
| policy_loss        | -0.0039399574 |
| serial_timesteps   | 52992         |
| time_elapsed       | 214           |
| total_timesteps    | 423936        |
| value_loss         | 0.025662845   |
--------------------------------------
--------------------------------------
| approxkl           | 0.008413405   |
| clipfrac           | 0.11611328    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.57         |
| explained_variance | 0.904         |
| fps                | 2183          |
| n_updates          | 208           |
| policy_entropy     | 5.894921      |
| policy_loss        | -0.0067917355 |
| serial_timesteps   | 53248         |
| time_elapsed       | 215           |
| total_timesteps    | 425984        |
| value_loss         | 0.025748327   |
--------------------------------------
-------------------------------------
| approxkl           | 0.011014345  |
| clipfrac           | 0.15595703   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.873        |
| fps                | 2227         |
| n_updates          | 209          |
| policy_entropy     | 5.8804154    |
| policy_loss        | -0.009964971 |
| serial_timesteps   | 53504        |
| time_elapsed       | 216          |
| total_timesteps    | 428032       |
| value_loss         | 0.031303763  |
-------------------------------------
Eval num_timesteps=430000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009714166  |
| clipfrac           | 0.140625     |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.894        |
| fps                | 1544         |
| n_updates          | 210          |
| policy_entropy     | 5.8735785    |
| policy_loss        | -0.009849488 |
| serial_timesteps   | 53760        |
| time_elapsed       | 217          |
| total_timesteps    | 430080       |
| value_loss         | 0.023267616  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009950865  |
| clipfrac           | 0.13671875   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.893        |
| fps                | 2165         |
| n_updates          | 211          |
| policy_entropy     | 5.871463     |
| policy_loss        | -0.007858971 |
| serial_timesteps   | 54016        |
| time_elapsed       | 218          |
| total_timesteps    | 432128       |
| value_loss         | 0.026129574  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008506408   |
| clipfrac           | 0.115478516   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.54         |
| explained_variance | 0.888         |
| fps                | 2203          |
| n_updates          | 212           |
| policy_entropy     | 5.841426      |
| policy_loss        | -0.0064997943 |
| serial_timesteps   | 54272         |
| time_elapsed       | 219           |
| total_timesteps    | 434176        |
| value_loss         | 0.024055125   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009647267  |
| clipfrac           | 0.1340332    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.909        |
| fps                | 2213         |
| n_updates          | 213          |
| policy_entropy     | 5.7876554    |
| policy_loss        | -0.009451818 |
| serial_timesteps   | 54528        |
| time_elapsed       | 220          |
| total_timesteps    | 436224       |
| value_loss         | 0.024469653  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0099039655 |
| clipfrac           | 0.13212891   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.876        |
| fps                | 2227         |
| n_updates          | 214          |
| policy_entropy     | 5.7611403    |
| policy_loss        | -0.009916089 |
| serial_timesteps   | 54784        |
| time_elapsed       | 221          |
| total_timesteps    | 438272       |
| value_loss         | 0.026681906  |
-------------------------------------
Eval num_timesteps=440000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008942422  |
| clipfrac           | 0.124658205  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.903        |
| fps                | 1565         |
| n_updates          | 215          |
| policy_entropy     | 5.762975     |
| policy_loss        | -0.007098043 |
| serial_timesteps   | 55040        |
| time_elapsed       | 222          |
| total_timesteps    | 440320       |
| value_loss         | 0.024689177  |
-------------------------------------
------------------------------------
| approxkl           | 0.008634691 |
| clipfrac           | 0.119580075 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.54       |
| explained_variance | 0.873       |
| fps                | 2162        |
| n_updates          | 216         |
| policy_entropy     | 5.7641006   |
| policy_loss        | -0.00806197 |
| serial_timesteps   | 55296       |
| time_elapsed       | 223         |
| total_timesteps    | 442368      |
| value_loss         | 0.028469872 |
------------------------------------
--------------------------------------
| approxkl           | 0.0086259525  |
| clipfrac           | 0.12084961    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.54         |
| explained_variance | 0.899         |
| fps                | 2212          |
| n_updates          | 217           |
| policy_entropy     | 5.7655287     |
| policy_loss        | -0.0071211355 |
| serial_timesteps   | 55552         |
| time_elapsed       | 224           |
| total_timesteps    | 444416        |
| value_loss         | 0.02539072    |
--------------------------------------
-------------------------------------
| approxkl           | 0.009558914  |
| clipfrac           | 0.13422851   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.907        |
| fps                | 2200         |
| n_updates          | 218          |
| policy_entropy     | 5.7734437    |
| policy_loss        | -0.008348735 |
| serial_timesteps   | 55808        |
| time_elapsed       | 225          |
| total_timesteps    | 446464       |
| value_loss         | 0.023141576  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0106134815 |
| clipfrac           | 0.15605469   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.878        |
| fps                | 2180         |
| n_updates          | 219          |
| policy_entropy     | 5.7847586    |
| policy_loss        | -0.012348471 |
| serial_timesteps   | 56064        |
| time_elapsed       | 226          |
| total_timesteps    | 448512       |
| value_loss         | 0.0250063    |
-------------------------------------
Eval num_timesteps=450000, episode_reward=-0.68 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.010461315 |
| clipfrac           | 0.1484375   |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.54       |
| explained_variance | 0.918       |
| fps                | 1574        |
| n_updates          | 220         |
| policy_entropy     | 5.784198    |
| policy_loss        | -0.00884919 |
| serial_timesteps   | 56320       |
| time_elapsed       | 227         |
| total_timesteps    | 450560      |
| value_loss         | 0.021240517 |
------------------------------------
--------------------------------------
| approxkl           | 0.008661779   |
| clipfrac           | 0.11484375    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.54         |
| explained_variance | 0.881         |
| fps                | 2209          |
| n_updates          | 221           |
| policy_entropy     | 5.782238      |
| policy_loss        | -0.0070836158 |
| serial_timesteps   | 56576         |
| time_elapsed       | 228           |
| total_timesteps    | 452608        |
| value_loss         | 0.02358394    |
--------------------------------------
-------------------------------------
| approxkl           | 0.009063776  |
| clipfrac           | 0.1258789    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.919        |
| fps                | 2222         |
| n_updates          | 222          |
| policy_entropy     | 5.776592     |
| policy_loss        | -0.007587213 |
| serial_timesteps   | 56832        |
| time_elapsed       | 229          |
| total_timesteps    | 454656       |
| value_loss         | 0.024752164  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009434143  |
| clipfrac           | 0.11640625   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.713        |
| fps                | 2251         |
| n_updates          | 223          |
| policy_entropy     | 5.772819     |
| policy_loss        | -0.012121954 |
| serial_timesteps   | 57088        |
| time_elapsed       | 230          |
| total_timesteps    | 456704       |
| value_loss         | 0.052223556  |
-------------------------------------
------------------------------------
| approxkl           | 0.008619605 |
| clipfrac           | 0.11816406  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.56       |
| explained_variance | 0.891       |
| fps                | 2205        |
| n_updates          | 224         |
| policy_entropy     | 5.751963    |
| policy_loss        | -0.00820275 |
| serial_timesteps   | 57344       |
| time_elapsed       | 231         |
| total_timesteps    | 458752      |
| value_loss         | 0.02600379  |
------------------------------------
Eval num_timesteps=460000, episode_reward=-0.61 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008729529  |
| clipfrac           | 0.12182617   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.884        |
| fps                | 1550         |
| n_updates          | 225          |
| policy_entropy     | 5.7235413    |
| policy_loss        | -0.007158474 |
| serial_timesteps   | 57600        |
| time_elapsed       | 232          |
| total_timesteps    | 460800       |
| value_loss         | 0.029843178  |
-------------------------------------
-------------------------------------
| approxkl           | 0.01044634   |
| clipfrac           | 0.15014648   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.87         |
| fps                | 2233         |
| n_updates          | 226          |
| policy_entropy     | 5.716802     |
| policy_loss        | -0.008659793 |
| serial_timesteps   | 57856        |
| time_elapsed       | 233          |
| total_timesteps    | 462848       |
| value_loss         | 0.030897692  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008692903  |
| clipfrac           | 0.12363281   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.901        |
| fps                | 2236         |
| n_updates          | 227          |
| policy_entropy     | 5.717808     |
| policy_loss        | -0.008698917 |
| serial_timesteps   | 58112        |
| time_elapsed       | 234          |
| total_timesteps    | 464896       |
| value_loss         | 0.027646165  |
-------------------------------------
-------------------------------------
| approxkl           | 0.011740389  |
| clipfrac           | 0.16987304   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.89         |
| fps                | 2191         |
| n_updates          | 228          |
| policy_entropy     | 5.7050357    |
| policy_loss        | -0.012742275 |
| serial_timesteps   | 58368        |
| time_elapsed       | 235          |
| total_timesteps    | 466944       |
| value_loss         | 0.026525974  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009961636  |
| clipfrac           | 0.14614257   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.923        |
| fps                | 2170         |
| n_updates          | 229          |
| policy_entropy     | 5.6848707    |
| policy_loss        | -0.010647401 |
| serial_timesteps   | 58624        |
| time_elapsed       | 236          |
| total_timesteps    | 468992       |
| value_loss         | 0.022405757  |
-------------------------------------
Eval num_timesteps=470000, episode_reward=-0.54 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.018959733  |
| clipfrac           | 0.15102538   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.592        |
| fps                | 1573         |
| n_updates          | 230          |
| policy_entropy     | 5.681878     |
| policy_loss        | -0.017888438 |
| serial_timesteps   | 58880        |
| time_elapsed       | 237          |
| total_timesteps    | 471040       |
| value_loss         | 0.11700215   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007986824  |
| clipfrac           | 0.10683594   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.891        |
| fps                | 2211         |
| n_updates          | 231          |
| policy_entropy     | 5.6733108    |
| policy_loss        | -0.007241483 |
| serial_timesteps   | 59136        |
| time_elapsed       | 238          |
| total_timesteps    | 473088       |
| value_loss         | 0.031353172  |
-------------------------------------
-------------------------------------
| approxkl           | 0.011618934  |
| clipfrac           | 0.17211914   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.884        |
| fps                | 2146         |
| n_updates          | 232          |
| policy_entropy     | 5.6655188    |
| policy_loss        | -0.014477554 |
| serial_timesteps   | 59392        |
| time_elapsed       | 239          |
| total_timesteps    | 475136       |
| value_loss         | 0.027059382  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009509694   |
| clipfrac           | 0.13354492    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.58         |
| explained_variance | 0.899         |
| fps                | 2211          |
| n_updates          | 233           |
| policy_entropy     | 5.6557884     |
| policy_loss        | -0.0062408275 |
| serial_timesteps   | 59648         |
| time_elapsed       | 240           |
| total_timesteps    | 477184        |
| value_loss         | 0.028319497   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010878096  |
| clipfrac           | 0.15585938   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.855        |
| fps                | 2204         |
| n_updates          | 234          |
| policy_entropy     | 5.661677     |
| policy_loss        | -0.012696837 |
| serial_timesteps   | 59904        |
| time_elapsed       | 241          |
| total_timesteps    | 479232       |
| value_loss         | 0.03862567   |
-------------------------------------
Eval num_timesteps=480000, episode_reward=-0.58 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.0077410555  |
| clipfrac           | 0.10449219    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.57         |
| explained_variance | 0.878         |
| fps                | 1560          |
| n_updates          | 235           |
| policy_entropy     | 5.6655054     |
| policy_loss        | -0.0068538226 |
| serial_timesteps   | 60160         |
| time_elapsed       | 242           |
| total_timesteps    | 481280        |
| value_loss         | 0.030008469   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009720273  |
| clipfrac           | 0.13374023   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.906        |
| fps                | 2224         |
| n_updates          | 236          |
| policy_entropy     | 5.6476364    |
| policy_loss        | -0.007854351 |
| serial_timesteps   | 60416        |
| time_elapsed       | 243          |
| total_timesteps    | 483328       |
| value_loss         | 0.025795642  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009559192  |
| clipfrac           | 0.13452148   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.853        |
| fps                | 2190         |
| n_updates          | 237          |
| policy_entropy     | 5.643006     |
| policy_loss        | -0.010999461 |
| serial_timesteps   | 60672        |
| time_elapsed       | 244          |
| total_timesteps    | 485376       |
| value_loss         | 0.03180272   |
-------------------------------------
------------------------------------
| approxkl           | 0.008582645 |
| clipfrac           | 0.117529295 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.57       |
| explained_variance | 0.906       |
| fps                | 2216        |
| n_updates          | 238         |
| policy_entropy     | 5.629368    |
| policy_loss        | -0.00869563 |
| serial_timesteps   | 60928       |
| time_elapsed       | 245         |
| total_timesteps    | 487424      |
| value_loss         | 0.028269375 |
------------------------------------
-------------------------------------
| approxkl           | 0.009899449  |
| clipfrac           | 0.13642578   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.887        |
| fps                | 2223         |
| n_updates          | 239          |
| policy_entropy     | 5.598315     |
| policy_loss        | -0.009084003 |
| serial_timesteps   | 61184        |
| time_elapsed       | 246          |
| total_timesteps    | 489472       |
| value_loss         | 0.026851509  |
-------------------------------------
Eval num_timesteps=490000, episode_reward=-0.51 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009377141  |
| clipfrac           | 0.12929687   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.888        |
| fps                | 1568         |
| n_updates          | 240          |
| policy_entropy     | 5.589992     |
| policy_loss        | -0.008774439 |
| serial_timesteps   | 61440        |
| time_elapsed       | 247          |
| total_timesteps    | 491520       |
| value_loss         | 0.028095663  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0105006145 |
| clipfrac           | 0.14331055   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.858        |
| fps                | 2154         |
| n_updates          | 241          |
| policy_entropy     | 5.5815935    |
| policy_loss        | -0.012855235 |
| serial_timesteps   | 61696        |
| time_elapsed       | 248          |
| total_timesteps    | 493568       |
| value_loss         | 0.03309051   |
-------------------------------------
--------------------------------------
| approxkl           | 0.009184931   |
| clipfrac           | 0.13017578    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.56         |
| explained_variance | 0.895         |
| fps                | 2191          |
| n_updates          | 242           |
| policy_entropy     | 5.571822      |
| policy_loss        | -0.0077486387 |
| serial_timesteps   | 61952         |
| time_elapsed       | 249           |
| total_timesteps    | 495616        |
| value_loss         | 0.025329705   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009733144  |
| clipfrac           | 0.13779297   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.913        |
| fps                | 2224         |
| n_updates          | 243          |
| policy_entropy     | 5.593346     |
| policy_loss        | -0.012928548 |
| serial_timesteps   | 62208        |
| time_elapsed       | 250          |
| total_timesteps    | 497664       |
| value_loss         | 0.021625813  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009105613  |
| clipfrac           | 0.12939453   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.841        |
| fps                | 2208         |
| n_updates          | 244          |
| policy_entropy     | 5.6132817    |
| policy_loss        | -0.007592113 |
| serial_timesteps   | 62464        |
| time_elapsed       | 251          |
| total_timesteps    | 499712       |
| value_loss         | 0.03385697   |
-------------------------------------
Saving to logs/train_0.5M_widowx_reacher-v5_KAY/ppo2/widowx_reacher-v5_1
pybullet build time: May 18 2020 02:46:26
