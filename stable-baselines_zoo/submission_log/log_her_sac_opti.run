WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/sac/sac.py:141: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/sac/policies.py:194: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/sac/sac.py:254: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/sac/sac.py:294: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/sac/sac.py:314: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

[32m[I 2020-06-16 22:36:26,691][0m Finished trial#2 with value: 1.569103717803955 with parameters: {'gamma': 0.98, 'lr': 0.002257502502738456, 'batch_size': 16, 'buffer_size': 1000000, 'learning_starts': 20000, 'train_freq': 100, 'ent_coef': 'auto', 'net_arch': 'small', 'target_entropy': -10, 'random_exploration': 0.13670719064820813, 'n_sampled_goal': 1}. Best is trial#2 with value: 1.569103717803955.[0m
[32m[I 2020-06-16 22:36:36,848][0m Finished trial#8 with value: 2.3057522773742676 with parameters: {'gamma': 0.95, 'lr': 0.0002632356056651019, 'batch_size': 16, 'buffer_size': 10000, 'learning_starts': 20000, 'train_freq': 300, 'ent_coef': 0.5, 'net_arch': 'small', 'random_exploration': 0.6031479330984335, 'n_sampled_goal': 2}. Best is trial#2 with value: 1.569103717803955.[0m
[32m[I 2020-06-16 22:36:37,705][0m Finished trial#7 with value: 0.5374864935874939 with parameters: {'gamma': 0.99, 'lr': 0.0001786453976345072, 'batch_size': 128, 'buffer_size': 10000, 'learning_starts': 10000, 'train_freq': 300, 'ent_coef': 0.01, 'net_arch': 'big', 'random_exploration': 0.010237788089887179, 'n_sampled_goal': 2}. Best is trial#7 with value: 0.5374864935874939.[0m
[32m[I 2020-06-16 22:37:04,567][0m Finished trial#9 with value: 0.4096602499485016 with parameters: {'gamma': 0.999, 'lr': 0.14434449753441736, 'batch_size': 128, 'buffer_size': 10000, 'learning_starts': 20000, 'train_freq': 100, 'ent_coef': 0.1, 'net_arch': 'big', 'random_exploration': 0.3041946427329273, 'n_sampled_goal': 6}. Best is trial#9 with value: 0.4096602499485016.[0m
[32m[I 2020-06-16 22:37:15,088][0m Finished trial#0 with value: 0.8424204587936401 with parameters: {'gamma': 0.9999, 'lr': 0.003925373889482272, 'batch_size': 32, 'buffer_size': 100000, 'learning_starts': 10000, 'train_freq': 1, 'ent_coef': 0.05, 'net_arch': 'big', 'random_exploration': 0.48398623067929947, 'n_sampled_goal': 8}. Best is trial#9 with value: 0.4096602499485016.[0m
[32m[I 2020-06-16 22:39:36,581][0m Finished trial#3 with value: 3.488281726837158 with parameters: {'gamma': 0.98, 'lr': 0.205092469252999, 'batch_size': 64, 'buffer_size': 1000000, 'learning_starts': 1000, 'train_freq': 1, 'ent_coef': 0.05, 'net_arch': 'medium', 'random_exploration': 0.9506297088137795, 'n_sampled_goal': 8}. Best is trial#9 with value: 0.4096602499485016.[0m
[32m[I 2020-06-16 22:40:30,953][0m Finished trial#1 with value: 0.4509069323539734 with parameters: {'gamma': 0.9, 'lr': 0.003706805214491796, 'batch_size': 128, 'buffer_size': 100000, 'learning_starts': 0, 'train_freq': 1, 'ent_coef': 0.5, 'net_arch': 'small', 'random_exploration': 0.9055452944980147, 'n_sampled_goal': 6}. Best is trial#9 with value: 0.4096602499485016.[0m
[32m[I 2020-06-16 22:40:57,308][0m Finished trial#5 with value: 0.19432958960533142 with parameters: {'gamma': 0.98, 'lr': 0.00010383791081159555, 'batch_size': 128, 'buffer_size': 100000, 'learning_starts': 0, 'train_freq': 300, 'ent_coef': 0.05, 'net_arch': 'big', 'random_exploration': 0.7588438866538812, 'n_sampled_goal': 8}. Best is trial#5 with value: 0.19432958960533142.[0m
[32m[I 2020-06-16 22:41:00,194][0m Finished trial#4 with value: 0.37679892778396606 with parameters: {'gamma': 0.9, 'lr': 0.001169352678147085, 'batch_size': 128, 'buffer_size': 1000000, 'learning_starts': 0, 'train_freq': 1, 'ent_coef': 0.05, 'net_arch': 'big', 'random_exploration': 0.36366731774080485, 'n_sampled_goal': 8}. Best is trial#5 with value: 0.19432958960533142.[0m
[32m[I 2020-06-16 22:41:04,597][0m Finished trial#6 with value: 1.8788044452667236 with parameters: {'gamma': 0.99, 'lr': 0.004678140326769684, 'batch_size': 256, 'buffer_size': 10000, 'learning_starts': 1000, 'train_freq': 10, 'ent_coef': 0.05, 'net_arch': 'small', 'random_exploration': 0.18754576453118166, 'n_sampled_goal': 8}. Best is trial#5 with value: 0.19432958960533142.[0m
========== widowx_reacher-v6 ==========
Seed: 0
OrderedDict([('batch_size', 256),
             ('buffer_size', 1000000),
             ('ent_coef', 'auto'),
             ('gamma', 0.95),
             ('goal_selection_strategy', 'future'),
             ('learning_rate', 0.001),
             ('learning_starts', 1000),
             ('model_class', 'sac'),
             ('n_sampled_goal', 4),
             ('n_timesteps', 20000.0),
             ('policy', 'MlpPolicy')])
Using 1 environments
Overwriting n_timesteps with n=10000
Creating test environment
TRAINING ENV TYPE :  <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f55d9e5d1d0>
Not replacing HERGoalEnvWrapper env by a DummyVecEnv
EVAL ENV TYPE :  <stable_baselines.her.utils.HERGoalEnvWrapper object at 0x7f55d9e61cf8>
Optimizing hyperparameters
Sampler: tpe - Pruner: median
Not replacing HERGoalEnvWrapper env by a DummyVecEnv
EVAL ENV TYPE :  <stable_baselines.her.utils.HERGoalEnvWrapper object at 0x7f551016c588>
Not replacing HERGoalEnvWrapper env by a DummyVecEnv
EVAL ENV TYPE :  <stable_baselines.her.utils.HERGoalEnvWrapper object at 0x7f55082e08d0>
Not replacing HERGoalEnvWrapper env by a DummyVecEnv
EVAL ENV TYPE :  <stable_baselines.her.utils.HERGoalEnvWrapper object at 0x7f55083e5400>
Not replacing HERGoalEnvWrapper env by a DummyVecEnv
EVAL ENV TYPE :  <stable_baselines.her.utils.HERGoalEnvWrapper object at 0x7f55083e5da0>
Not replacing HERGoalEnvWrapper env by a DummyVecEnv
EVAL ENV TYPE :  <stable_baselines.her.utils.HERGoalEnvWrapper object at 0x7f5508394e48>
Not replacing HERGoalEnvWrapper env by a DummyVecEnv
EVAL ENV TYPE :  <stable_baselines.her.utils.HERGoalEnvWrapper object at 0x7f550858dcf8>
Not replacing HERGoalEnvWrapper env by a DummyVecEnv
EVAL ENV TYPE :  <stable_baselines.her.utils.HERGoalEnvWrapper object at 0x7f55082d2b38>
Not replacing HERGoalEnvWrapper env by a DummyVecEnv
EVAL ENV TYPE :  <stable_baselines.her.utils.HERGoalEnvWrapper object at 0x7f55cc066d68>
Not replacing HERGoalEnvWrapper env by a DummyVecEnv
EVAL ENV TYPE :  <stable_baselines.her.utils.HERGoalEnvWrapper object at 0x7f55083b9128>
Not replacing HERGoalEnvWrapper env by a DummyVecEnv
EVAL ENV TYPE :  <stable_baselines.her.utils.HERGoalEnvWrapper object at 0x7f55081d3fd0>
Number of finished trials:  10
Best trial:
Value:  0.19432958960533142
Params: 
    gamma: 0.98
    lr: 0.00010383791081159555
    batch_size: 128
    buffer_size: 100000
    learning_starts: 0
    train_freq: 300
    ent_coef: 0.05
    net_arch: big
    random_exploration: 0.7588438866538812
    n_sampled_goal: 8
best params:  {'gamma': 0.98, 'lr': 0.00010383791081159555, 'batch_size': 128, 'buffer_size': 100000, 'learning_starts': 0, 'train_freq': 300, 'ent_coef': 0.05, 'net_arch': 'big', 'random_exploration': 0.7588438866538812, 'n_sampled_goal': 8}
Writing report to logs/opti10t_0.01M_widowx_reacher-v6/her/report_widowx_reacher-v6_10-trials-10000-tpe-median_1592340064.csv
pybullet build time: May 18 2020 02:46:26
