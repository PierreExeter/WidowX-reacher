WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/ddpg/ddpg.py:332: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/ddpg/policies.py:134: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/ddpg/policies.py:136: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/ddpg/ddpg.py:412: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/pierre/bin/anaconda3/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/ddpg/ddpg.py:452: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

========== widowx_reacher-v5 ==========
Seed: 1
OrderedDict([('actor_lr', 0.0001),
             ('batch_size', 128),
             ('buffer_size', 50000),
             ('critic_l2_reg', 0.0),
             ('critic_lr', 0.001),
             ('enable_popart', False),
             ('gamma', 0.99),
             ('n_timesteps', 10000),
             ('nb_eval_steps', 100),
             ('nb_rollout_steps', 100),
             ('nb_train_steps', 50),
             ('normalize_observations', False),
             ('normalize_returns', False),
             ('param_noise_adaption_interval', 50),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs', 'None'),
             ('random_exploration', 0.0),
             ('render', False),
             ('render_eval', False),
             ('reward_scale', 1.0),
             ('tau', 0.001)])
Using 1 environments
Creating test environment
TRAINING ENV TYPE :  <Monitor<TimeLimit<WidowxEnv<widowx_reacher-v5>>>>
EVAL ENV TYPE :  <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7ff081719da0>
Log path: logs/train_10K_widowx_reacher-v5/ddpg/widowx_reacher-v5_2
Eval num_timesteps=10000, episode_reward=-0.17 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
--------------------------------------
| reference_Q_mean        | -0.0302  |
| reference_Q_std         | 0.0261   |
| reference_action_mean   | 0.32     |
| reference_action_std    | 0.356    |
| reference_actor_Q_mean  | -0.028   |
| reference_actor_Q_std   | 0.0232   |
| rollout/Q_mean          | -0.0221  |
| rollout/actions_mean    | 0.295    |
| rollout/actions_std     | 0.348    |
| rollout/episode_steps   | 100      |
| rollout/episodes        | 100      |
| rollout/return          | -0.537   |
| rollout/return_history  | -0.537   |
| total/duration          | 15.9     |
| total/episodes          | 100      |
| total/epochs            | 1        |
| total/steps             | 9998     |
| total/steps_per_second  | 631      |
| train/loss_actor        | 0.0297   |
| train/loss_critic       | 9.3e-06  |
| train/param_noise_di... | 0        |
--------------------------------------

/home/pierre/HDD/0_Complearn/1_learning/0_Reinforcement_learning/18_replab/pierreExeter_github/stable-baselines/stable_baselines/common/callbacks.py:285: UserWarning: Training and eval env are not of the same type<Monitor<TimeLimit<WidowxEnv<widowx_reacher-v5>>>> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7ff081719da0>
  "{} != {}".format(self.training_env, self.eval_env))
Saving to logs/train_10K_widowx_reacher-v5/ddpg/widowx_reacher-v5_2
pybullet build time: May 18 2020 02:46:26
