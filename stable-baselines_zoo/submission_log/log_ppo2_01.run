--------------------------------------------------------------------------
WARNING: There was an error initializing an OpenFabrics device.

  Local host:   n371
  Local device: hfi1_0
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Warning: Open MPI has detected that you are running in an environment with CUDA
devices present and that you are using Intel(r) Ompi-Path networking. However,
the environment variable PSM2_CUDA was not set, meaning that the PSM2 Omni-Path
networking library was not told how to handle CUDA support.

If your application uses CUDA buffers, you should set the environment variable
PSM2_CUDA to 1; otherwise, set it to 0. Setting the variable to the wrong value
can have performance implications on your application, or even cause it to
crash.

Since it was not set, Open MPI has defaulted to setting the PSM2_CUDA
environment variable to 1.

Local hostname: n371
--------------------------------------------------------------------------
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

========== widowx_reacher-v5 ==========
Seed: 1
OrderedDict([('cliprange', 0.2),
             ('ent_coef', 0.0),
             ('gamma', 0.99),
             ('lam', 0.95),
             ('learning_rate', 0.00025),
             ('n_envs', 8),
             ('n_steps', 256),
             ('n_timesteps', 1000000.0),
             ('nminibatches', 32),
             ('noptepochs', 10),
             ('normalize', True),
             ('policy', 'MlpPolicy')])
Using 8 environments
Overwriting n_timesteps with n=500000
Normalizing input and reward
Creating test environment
TRAINING ENV TYPE :  <stable_baselines.common.vec_env.vec_normalize.VecNormalize object at 0x7f463814c6a0>
Normalization activated: {'norm_reward': False}
EVAL ENV TYPE :  <stable_baselines.common.vec_env.vec_normalize.VecNormalize object at 0x7f4635ac0518>
Log path: logs/train_0.5M_widowx_reacher-v5_KAY/ppo2/widowx_reacher-v5_2
-------------------------------------
| approxkl           | 0.0067832144 |
| clipfrac           | 0.09648438   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.71        |
| explained_variance | 0.189        |
| fps                | 1465         |
| n_updates          | 1            |
| policy_entropy     | 8.505063     |
| policy_loss        | -0.011016973 |
| serial_timesteps   | 256          |
| time_elapsed       | 2.67e-05     |
| total_timesteps    | 2048         |
| value_loss         | 0.72372645   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007929049  |
| clipfrac           | 0.11206055   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.01        |
| explained_variance | 0.199        |
| fps                | 2092         |
| n_updates          | 2            |
| policy_entropy     | 8.509845     |
| policy_loss        | -0.015954789 |
| serial_timesteps   | 512          |
| time_elapsed       | 1.4          |
| total_timesteps    | 4096         |
| value_loss         | 0.25754294   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009400944  |
| clipfrac           | 0.1340332    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.04        |
| explained_variance | 0.382        |
| fps                | 2159         |
| n_updates          | 3            |
| policy_entropy     | 8.535485     |
| policy_loss        | -0.016458698 |
| serial_timesteps   | 768          |
| time_elapsed       | 2.38         |
| total_timesteps    | 6144         |
| value_loss         | 0.138708     |
-------------------------------------
-------------------------------------
| approxkl           | 0.006931146  |
| clipfrac           | 0.091357425  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.14        |
| explained_variance | -0.0372      |
| fps                | 2137         |
| n_updates          | 4            |
| policy_entropy     | 8.546465     |
| policy_loss        | -0.011481239 |
| serial_timesteps   | 1024         |
| time_elapsed       | 3.33         |
| total_timesteps    | 8192         |
| value_loss         | 0.197485     |
-------------------------------------
Eval num_timesteps=10000, episode_reward=-3.06 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.0081527475 |
| clipfrac           | 0.11411133   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.12        |
| explained_variance | 0.208        |
| fps                | 1378         |
| n_updates          | 5            |
| policy_entropy     | 8.552866     |
| policy_loss        | -0.01246084  |
| serial_timesteps   | 1280         |
| time_elapsed       | 4.28         |
| total_timesteps    | 10240        |
| value_loss         | 0.068804085  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0068410723 |
| clipfrac           | 0.08979492   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.26        |
| explained_variance | 0.0604       |
| fps                | 2180         |
| n_updates          | 6            |
| policy_entropy     | 8.541605     |
| policy_loss        | -0.014569117 |
| serial_timesteps   | 1536         |
| time_elapsed       | 5.77         |
| total_timesteps    | 12288        |
| value_loss         | 0.09810402   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008892932  |
| clipfrac           | 0.12197266   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.27        |
| explained_variance | 0.21         |
| fps                | 2146         |
| n_updates          | 7            |
| policy_entropy     | 8.50413      |
| policy_loss        | -0.014710826 |
| serial_timesteps   | 1792         |
| time_elapsed       | 6.71         |
| total_timesteps    | 14336        |
| value_loss         | 0.07702176   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0070506325 |
| clipfrac           | 0.091308594  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.26        |
| explained_variance | 0.277        |
| fps                | 2151         |
| n_updates          | 8            |
| policy_entropy     | 8.471317     |
| policy_loss        | -0.011033225 |
| serial_timesteps   | 2048         |
| time_elapsed       | 7.66         |
| total_timesteps    | 16384        |
| value_loss         | 0.070233844  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0051985355 |
| clipfrac           | 0.060595702  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.31        |
| explained_variance | 0.334        |
| fps                | 2132         |
| n_updates          | 9            |
| policy_entropy     | 8.453039     |
| policy_loss        | -0.007391474 |
| serial_timesteps   | 2304         |
| time_elapsed       | 8.62         |
| total_timesteps    | 18432        |
| value_loss         | 0.08343185   |
-------------------------------------
Eval num_timesteps=20000, episode_reward=-3.70 +/- 0.05
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.006697773  |
| clipfrac           | 0.08681641   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.33        |
| explained_variance | 0.499        |
| fps                | 1512         |
| n_updates          | 10           |
| policy_entropy     | 8.427614     |
| policy_loss        | -0.010466138 |
| serial_timesteps   | 2560         |
| time_elapsed       | 9.58         |
| total_timesteps    | 20480        |
| value_loss         | 0.06080391   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00579084   |
| clipfrac           | 0.07001953   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.3         |
| explained_variance | 0.466        |
| fps                | 2098         |
| n_updates          | 11           |
| policy_entropy     | 8.417946     |
| policy_loss        | -0.009773431 |
| serial_timesteps   | 2816         |
| time_elapsed       | 10.9         |
| total_timesteps    | 22528        |
| value_loss         | 0.076381624  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0059208693  |
| clipfrac           | 0.069970705   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -2.34         |
| explained_variance | 0.448         |
| fps                | 2136          |
| n_updates          | 12            |
| policy_entropy     | 8.424835      |
| policy_loss        | -0.0103830695 |
| serial_timesteps   | 3072          |
| time_elapsed       | 11.9          |
| total_timesteps    | 24576         |
| value_loss         | 0.087569855   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008096477  |
| clipfrac           | 0.11240234   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.33        |
| explained_variance | 0.428        |
| fps                | 2173         |
| n_updates          | 13           |
| policy_entropy     | 8.437067     |
| policy_loss        | -0.012472169 |
| serial_timesteps   | 3328         |
| time_elapsed       | 12.9         |
| total_timesteps    | 26624        |
| value_loss         | 0.08747044   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0074531385 |
| clipfrac           | 0.10239258   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.33        |
| explained_variance | 0.424        |
| fps                | 2172         |
| n_updates          | 14           |
| policy_entropy     | 8.413241     |
| policy_loss        | -0.012708785 |
| serial_timesteps   | 3584         |
| time_elapsed       | 13.8         |
| total_timesteps    | 28672        |
| value_loss         | 0.07353326   |
-------------------------------------
Eval num_timesteps=30000, episode_reward=-3.57 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0054139504 |
| clipfrac           | 0.06298828   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.26        |
| explained_variance | 0.671        |
| fps                | 1507         |
| n_updates          | 15           |
| policy_entropy     | 8.377314     |
| policy_loss        | -0.009151776 |
| serial_timesteps   | 3840         |
| time_elapsed       | 14.8         |
| total_timesteps    | 30720        |
| value_loss         | 0.048422124  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0067897327 |
| clipfrac           | 0.08427735   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.3         |
| explained_variance | 0.44         |
| fps                | 2152         |
| n_updates          | 16           |
| policy_entropy     | 8.367118     |
| policy_loss        | -0.010753629 |
| serial_timesteps   | 4096         |
| time_elapsed       | 16.1         |
| total_timesteps    | 32768        |
| value_loss         | 0.08480771   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00711277   |
| clipfrac           | 0.09379883   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.29        |
| explained_variance | 0.529        |
| fps                | 2119         |
| n_updates          | 17           |
| policy_entropy     | 8.380368     |
| policy_loss        | -0.011401879 |
| serial_timesteps   | 4352         |
| time_elapsed       | 17.1         |
| total_timesteps    | 34816        |
| value_loss         | 0.075861916  |
-------------------------------------
------------------------------------
| approxkl           | 0.007822362 |
| clipfrac           | 0.109033205 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -2.32       |
| explained_variance | 0.536       |
| fps                | 2099        |
| n_updates          | 18          |
| policy_entropy     | 8.383505    |
| policy_loss        | -0.01159297 |
| serial_timesteps   | 4608        |
| time_elapsed       | 18          |
| total_timesteps    | 36864       |
| value_loss         | 0.086303115 |
------------------------------------
-------------------------------------
| approxkl           | 0.008052206  |
| clipfrac           | 0.11621094   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.34        |
| explained_variance | 0.45         |
| fps                | 2059         |
| n_updates          | 19           |
| policy_entropy     | 8.3737135    |
| policy_loss        | -0.014331761 |
| serial_timesteps   | 4864         |
| time_elapsed       | 19           |
| total_timesteps    | 38912        |
| value_loss         | 0.115585685  |
-------------------------------------
Eval num_timesteps=40000, episode_reward=-4.14 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008037131  |
| clipfrac           | 0.11464844   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.49        |
| explained_variance | 0.398        |
| fps                | 1520         |
| n_updates          | 20           |
| policy_entropy     | 8.355477     |
| policy_loss        | -0.012200261 |
| serial_timesteps   | 5120         |
| time_elapsed       | 20           |
| total_timesteps    | 40960        |
| value_loss         | 0.107627235  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008042754  |
| clipfrac           | 0.113134764  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.47        |
| explained_variance | 0.496        |
| fps                | 2130         |
| n_updates          | 21           |
| policy_entropy     | 8.340708     |
| policy_loss        | -0.014327558 |
| serial_timesteps   | 5376         |
| time_elapsed       | 21.3         |
| total_timesteps    | 43008        |
| value_loss         | 0.08174758   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008276441  |
| clipfrac           | 0.11557617   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.38        |
| explained_variance | 0.626        |
| fps                | 2070         |
| n_updates          | 22           |
| policy_entropy     | 8.359217     |
| policy_loss        | -0.012046797 |
| serial_timesteps   | 5632         |
| time_elapsed       | 22.3         |
| total_timesteps    | 45056        |
| value_loss         | 0.059392832  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007868347  |
| clipfrac           | 0.10649414   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.34        |
| explained_variance | 0.455        |
| fps                | 2125         |
| n_updates          | 23           |
| policy_entropy     | 8.378869     |
| policy_loss        | -0.012897827 |
| serial_timesteps   | 5888         |
| time_elapsed       | 23.3         |
| total_timesteps    | 47104        |
| value_loss         | 0.08887856   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0090751555  |
| clipfrac           | 0.13251953    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -2.28         |
| explained_variance | 0.665         |
| fps                | 2080          |
| n_updates          | 24            |
| policy_entropy     | 8.366973      |
| policy_loss        | -0.0155504495 |
| serial_timesteps   | 6144          |
| time_elapsed       | 24.3          |
| total_timesteps    | 49152         |
| value_loss         | 0.04181826    |
--------------------------------------
Eval num_timesteps=50000, episode_reward=-1.49 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.007606731  |
| clipfrac           | 0.10341797   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.13        |
| explained_variance | 0.573        |
| fps                | 1479         |
| n_updates          | 25           |
| policy_entropy     | 8.329834     |
| policy_loss        | -0.012564167 |
| serial_timesteps   | 6400         |
| time_elapsed       | 25.2         |
| total_timesteps    | 51200        |
| value_loss         | 0.063888386  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007245952  |
| clipfrac           | 0.094091795  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.15        |
| explained_variance | 0.54         |
| fps                | 2107         |
| n_updates          | 26           |
| policy_entropy     | 8.308763     |
| policy_loss        | -0.010582639 |
| serial_timesteps   | 6656         |
| time_elapsed       | 26.6         |
| total_timesteps    | 53248        |
| value_loss         | 0.07315437   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007766708  |
| clipfrac           | 0.10341797   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.23        |
| explained_variance | 0.534        |
| fps                | 2116         |
| n_updates          | 27           |
| policy_entropy     | 8.305838     |
| policy_loss        | -0.009385259 |
| serial_timesteps   | 6912         |
| time_elapsed       | 27.6         |
| total_timesteps    | 55296        |
| value_loss         | 0.062648654  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007671199  |
| clipfrac           | 0.10415039   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.16        |
| explained_variance | 0.412        |
| fps                | 2139         |
| n_updates          | 28           |
| policy_entropy     | 8.308048     |
| policy_loss        | -0.010969566 |
| serial_timesteps   | 7168         |
| time_elapsed       | 28.6         |
| total_timesteps    | 57344        |
| value_loss         | 0.063600086  |
-------------------------------------
--------------------------------------
| approxkl           | 0.00751369    |
| clipfrac           | 0.09536133    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -2.18         |
| explained_variance | 0.553         |
| fps                | 2066          |
| n_updates          | 29            |
| policy_entropy     | 8.297945      |
| policy_loss        | -0.0101769995 |
| serial_timesteps   | 7424          |
| time_elapsed       | 29.5          |
| total_timesteps    | 59392         |
| value_loss         | 0.06140583    |
--------------------------------------
Eval num_timesteps=60000, episode_reward=-1.50 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008252071  |
| clipfrac           | 0.11508789   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.24        |
| explained_variance | 0.423        |
| fps                | 1472         |
| n_updates          | 30           |
| policy_entropy     | 8.291491     |
| policy_loss        | -0.012087366 |
| serial_timesteps   | 7680         |
| time_elapsed       | 30.5         |
| total_timesteps    | 61440        |
| value_loss         | 0.06693517   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077401483 |
| clipfrac           | 0.10454102   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.26        |
| explained_variance | 0.546        |
| fps                | 2075         |
| n_updates          | 31           |
| policy_entropy     | 8.276631     |
| policy_loss        | -0.012788208 |
| serial_timesteps   | 7936         |
| time_elapsed       | 31.9         |
| total_timesteps    | 63488        |
| value_loss         | 0.06517756   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008096955  |
| clipfrac           | 0.11044922   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.28        |
| explained_variance | 0.478        |
| fps                | 2202         |
| n_updates          | 32           |
| policy_entropy     | 8.256574     |
| policy_loss        | -0.014730044 |
| serial_timesteps   | 8192         |
| time_elapsed       | 32.9         |
| total_timesteps    | 65536        |
| value_loss         | 0.066624895  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009411457  |
| clipfrac           | 0.13081054   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.21        |
| explained_variance | 0.698        |
| fps                | 2086         |
| n_updates          | 33           |
| policy_entropy     | 8.260902     |
| policy_loss        | -0.014632362 |
| serial_timesteps   | 8448         |
| time_elapsed       | 33.8         |
| total_timesteps    | 67584        |
| value_loss         | 0.031103933  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0067892903  |
| clipfrac           | 0.085351564   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -2.19         |
| explained_variance | 0.531         |
| fps                | 2057          |
| n_updates          | 34            |
| policy_entropy     | 8.256346      |
| policy_loss        | -0.0076872646 |
| serial_timesteps   | 8704          |
| time_elapsed       | 34.8          |
| total_timesteps    | 69632         |
| value_loss         | 0.046698727   |
--------------------------------------
Eval num_timesteps=70000, episode_reward=-1.30 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.0071529634 |
| clipfrac           | 0.09399414   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.24        |
| explained_variance | 0.555        |
| fps                | 1391         |
| n_updates          | 35           |
| policy_entropy     | 8.240054     |
| policy_loss        | -0.010300672 |
| serial_timesteps   | 8960         |
| time_elapsed       | 35.8         |
| total_timesteps    | 71680        |
| value_loss         | 0.06398418   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007799448  |
| clipfrac           | 0.10541992   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.2         |
| explained_variance | 0.584        |
| fps                | 2110         |
| n_updates          | 36           |
| policy_entropy     | 8.2274275    |
| policy_loss        | -0.014443591 |
| serial_timesteps   | 9216         |
| time_elapsed       | 37.3         |
| total_timesteps    | 73728        |
| value_loss         | 0.0594831    |
-------------------------------------
--------------------------------------
| approxkl           | 0.007146229   |
| clipfrac           | 0.09121094    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -2.2          |
| explained_variance | 0.342         |
| fps                | 2119          |
| n_updates          | 37            |
| policy_entropy     | 8.211119      |
| policy_loss        | -0.0118688755 |
| serial_timesteps   | 9472          |
| time_elapsed       | 38.3          |
| total_timesteps    | 75776         |
| value_loss         | 0.0715007     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0071738474 |
| clipfrac           | 0.096191406  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.31        |
| explained_variance | 0.546        |
| fps                | 2090         |
| n_updates          | 38           |
| policy_entropy     | 8.211413     |
| policy_loss        | -0.009460966 |
| serial_timesteps   | 9728         |
| time_elapsed       | 39.2         |
| total_timesteps    | 77824        |
| value_loss         | 0.07222087   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008754828  |
| clipfrac           | 0.12436523   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.34        |
| explained_variance | 0.374        |
| fps                | 2123         |
| n_updates          | 39           |
| policy_entropy     | 8.222017     |
| policy_loss        | -0.016109413 |
| serial_timesteps   | 9984         |
| time_elapsed       | 40.2         |
| total_timesteps    | 79872        |
| value_loss         | 0.08935196   |
-------------------------------------
Eval num_timesteps=80000, episode_reward=-1.08 +/- 0.01
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.008228701  |
| clipfrac           | 0.113183595  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.28        |
| explained_variance | 0.622        |
| fps                | 1397         |
| n_updates          | 40           |
| policy_entropy     | 8.220249     |
| policy_loss        | -0.012489842 |
| serial_timesteps   | 10240        |
| time_elapsed       | 41.2         |
| total_timesteps    | 81920        |
| value_loss         | 0.039185125  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007545457  |
| clipfrac           | 0.10083008   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.29        |
| explained_variance | 0.49         |
| fps                | 2049         |
| n_updates          | 41           |
| policy_entropy     | 8.208179     |
| policy_loss        | -0.010255219 |
| serial_timesteps   | 10496        |
| time_elapsed       | 42.6         |
| total_timesteps    | 83968        |
| value_loss         | 0.073759064  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0064940318 |
| clipfrac           | 0.079589844  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.27        |
| explained_variance | 0.54         |
| fps                | 2036         |
| n_updates          | 42           |
| policy_entropy     | 8.183767     |
| policy_loss        | -0.010326089 |
| serial_timesteps   | 10752        |
| time_elapsed       | 43.6         |
| total_timesteps    | 86016        |
| value_loss         | 0.05855093   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008665637  |
| clipfrac           | 0.123291016  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.18        |
| explained_variance | 0.595        |
| fps                | 2012         |
| n_updates          | 43           |
| policy_entropy     | 8.1518955    |
| policy_loss        | -0.014476864 |
| serial_timesteps   | 11008        |
| time_elapsed       | 44.6         |
| total_timesteps    | 88064        |
| value_loss         | 0.05861508   |
-------------------------------------
Eval num_timesteps=90000, episode_reward=-1.48 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.009228635 |
| clipfrac           | 0.13046876  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -2.15       |
| explained_variance | 0.546       |
| fps                | 1494        |
| n_updates          | 44          |
| policy_entropy     | 8.127041    |
| policy_loss        | -0.0154449  |
| serial_timesteps   | 11264       |
| time_elapsed       | 45.7        |
| total_timesteps    | 90112       |
| value_loss         | 0.05671228  |
------------------------------------
-------------------------------------
| approxkl           | 0.007917279  |
| clipfrac           | 0.105371095  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.22        |
| explained_variance | 0.643        |
| fps                | 2046         |
| n_updates          | 45           |
| policy_entropy     | 8.092223     |
| policy_loss        | -0.012356825 |
| serial_timesteps   | 11520        |
| time_elapsed       | 47           |
| total_timesteps    | 92160        |
| value_loss         | 0.052311897  |
-------------------------------------
-------------------------------------
| approxkl           | 0.006878422  |
| clipfrac           | 0.083789065  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.22        |
| explained_variance | 0.467        |
| fps                | 2113         |
| n_updates          | 46           |
| policy_entropy     | 8.069995     |
| policy_loss        | -0.010938862 |
| serial_timesteps   | 11776        |
| time_elapsed       | 48           |
| total_timesteps    | 94208        |
| value_loss         | 0.058494814  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0067395903 |
| clipfrac           | 0.08491211   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.31        |
| explained_variance | 0.605        |
| fps                | 2125         |
| n_updates          | 47           |
| policy_entropy     | 8.072754     |
| policy_loss        | -0.011305729 |
| serial_timesteps   | 12032        |
| time_elapsed       | 49           |
| total_timesteps    | 96256        |
| value_loss         | 0.06625142   |
-------------------------------------
------------------------------------
| approxkl           | 0.008031065 |
| clipfrac           | 0.107373044 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -2.43       |
| explained_variance | 0.479       |
| fps                | 2115        |
| n_updates          | 48          |
| policy_entropy     | 8.069172    |
| policy_loss        | -0.01021446 |
| serial_timesteps   | 12288       |
| time_elapsed       | 50          |
| total_timesteps    | 98304       |
| value_loss         | 0.08086897  |
------------------------------------
Eval num_timesteps=100000, episode_reward=-1.70 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007856429  |
| clipfrac           | 0.10883789   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.49        |
| explained_variance | 0.674        |
| fps                | 1378         |
| n_updates          | 49           |
| policy_entropy     | 8.075489     |
| policy_loss        | -0.014267236 |
| serial_timesteps   | 12544        |
| time_elapsed       | 50.9         |
| total_timesteps    | 100352       |
| value_loss         | 0.054785896  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00792771   |
| clipfrac           | 0.10493164   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.55        |
| explained_variance | 0.587        |
| fps                | 2094         |
| n_updates          | 50           |
| policy_entropy     | 8.057771     |
| policy_loss        | -0.013035929 |
| serial_timesteps   | 12800        |
| time_elapsed       | 52.4         |
| total_timesteps    | 102400       |
| value_loss         | 0.087355316  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008591872  |
| clipfrac           | 0.12700196   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.55        |
| explained_variance | 0.621        |
| fps                | 2126         |
| n_updates          | 51           |
| policy_entropy     | 8.0359955    |
| policy_loss        | -0.011698415 |
| serial_timesteps   | 13056        |
| time_elapsed       | 53.4         |
| total_timesteps    | 104448       |
| value_loss         | 0.05814612   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007925747  |
| clipfrac           | 0.10664062   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.56        |
| explained_variance | 0.447        |
| fps                | 2072         |
| n_updates          | 52           |
| policy_entropy     | 8.051518     |
| policy_loss        | -0.013296872 |
| serial_timesteps   | 13312        |
| time_elapsed       | 54.4         |
| total_timesteps    | 106496       |
| value_loss         | 0.09546535   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0069789095 |
| clipfrac           | 0.09194336   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.51        |
| explained_variance | 0.578        |
| fps                | 2107         |
| n_updates          | 53           |
| policy_entropy     | 8.042269     |
| policy_loss        | -0.011663997 |
| serial_timesteps   | 13568        |
| time_elapsed       | 55.3         |
| total_timesteps    | 108544       |
| value_loss         | 0.055564635  |
-------------------------------------
Eval num_timesteps=110000, episode_reward=-1.56 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009509619  |
| clipfrac           | 0.13066407   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.46        |
| explained_variance | 0.648        |
| fps                | 1499         |
| n_updates          | 54           |
| policy_entropy     | 8.01485      |
| policy_loss        | -0.013542801 |
| serial_timesteps   | 13824        |
| time_elapsed       | 56.3         |
| total_timesteps    | 110592       |
| value_loss         | 0.07411883   |
-------------------------------------
------------------------------------
| approxkl           | 0.008484395 |
| clipfrac           | 0.119140625 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -2.36       |
| explained_variance | 0.615       |
| fps                | 2115        |
| n_updates          | 55          |
| policy_entropy     | 8.005718    |
| policy_loss        | -0.01171562 |
| serial_timesteps   | 14080       |
| time_elapsed       | 57.7        |
| total_timesteps    | 112640      |
| value_loss         | 0.060271464 |
------------------------------------
-------------------------------------
| approxkl           | 0.008057933  |
| clipfrac           | 0.112939455  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.37        |
| explained_variance | 0.481        |
| fps                | 2061         |
| n_updates          | 56           |
| policy_entropy     | 8.017379     |
| policy_loss        | -0.014141617 |
| serial_timesteps   | 14336        |
| time_elapsed       | 58.6         |
| total_timesteps    | 114688       |
| value_loss         | 0.07161575   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008308149  |
| clipfrac           | 0.10771485   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.34        |
| explained_variance | 0.599        |
| fps                | 2124         |
| n_updates          | 57           |
| policy_entropy     | 8.008581     |
| policy_loss        | -0.012001179 |
| serial_timesteps   | 14592        |
| time_elapsed       | 59.6         |
| total_timesteps    | 116736       |
| value_loss         | 0.046965297  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008084058  |
| clipfrac           | 0.11630859   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.26        |
| explained_variance | 0.458        |
| fps                | 2080         |
| n_updates          | 58           |
| policy_entropy     | 7.9930487    |
| policy_loss        | -0.011571436 |
| serial_timesteps   | 14848        |
| time_elapsed       | 60.6         |
| total_timesteps    | 118784       |
| value_loss         | 0.07059142   |
-------------------------------------
Eval num_timesteps=120000, episode_reward=-2.55 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.006788511  |
| clipfrac           | 0.08481445   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.33        |
| explained_variance | 0.591        |
| fps                | 1537         |
| n_updates          | 59           |
| policy_entropy     | 7.981238     |
| policy_loss        | -0.010243779 |
| serial_timesteps   | 15104        |
| time_elapsed       | 61.6         |
| total_timesteps    | 120832       |
| value_loss         | 0.06824626   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009237393  |
| clipfrac           | 0.13432617   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.34        |
| explained_variance | 0.583        |
| fps                | 2121         |
| n_updates          | 60           |
| policy_entropy     | 7.9703712    |
| policy_loss        | -0.013230657 |
| serial_timesteps   | 15360        |
| time_elapsed       | 62.9         |
| total_timesteps    | 122880       |
| value_loss         | 0.06136468   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008625192  |
| clipfrac           | 0.120507814  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.29        |
| explained_variance | 0.667        |
| fps                | 2120         |
| n_updates          | 61           |
| policy_entropy     | 7.955909     |
| policy_loss        | -0.014272021 |
| serial_timesteps   | 15616        |
| time_elapsed       | 63.9         |
| total_timesteps    | 124928       |
| value_loss         | 0.056837223  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0072492957 |
| clipfrac           | 0.09458008   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.33        |
| explained_variance | 0.609        |
| fps                | 2130         |
| n_updates          | 62           |
| policy_entropy     | 7.944684     |
| policy_loss        | -0.011531425 |
| serial_timesteps   | 15872        |
| time_elapsed       | 64.9         |
| total_timesteps    | 126976       |
| value_loss         | 0.05504314   |
-------------------------------------
-------------------------------------
| approxkl           | 0.006903165  |
| clipfrac           | 0.087841794  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.38        |
| explained_variance | 0.587        |
| fps                | 2086         |
| n_updates          | 63           |
| policy_entropy     | 7.9360404    |
| policy_loss        | -0.010031844 |
| serial_timesteps   | 16128        |
| time_elapsed       | 65.8         |
| total_timesteps    | 129024       |
| value_loss         | 0.07241307   |
-------------------------------------
Eval num_timesteps=130000, episode_reward=-2.17 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007315421  |
| clipfrac           | 0.09853516   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.37        |
| explained_variance | 0.59         |
| fps                | 1454         |
| n_updates          | 64           |
| policy_entropy     | 7.929138     |
| policy_loss        | -0.011064752 |
| serial_timesteps   | 16384        |
| time_elapsed       | 66.8         |
| total_timesteps    | 131072       |
| value_loss         | 0.070559144  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007731429  |
| clipfrac           | 0.1          |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.38        |
| explained_variance | 0.6          |
| fps                | 2142         |
| n_updates          | 65           |
| policy_entropy     | 7.920385     |
| policy_loss        | -0.012866795 |
| serial_timesteps   | 16640        |
| time_elapsed       | 68.2         |
| total_timesteps    | 133120       |
| value_loss         | 0.059891276  |
-------------------------------------
------------------------------------
| approxkl           | 0.009464099 |
| clipfrac           | 0.12924805  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -2.38       |
| explained_variance | 0.54        |
| fps                | 2147        |
| n_updates          | 66          |
| policy_entropy     | 7.9031982   |
| policy_loss        | -0.01511727 |
| serial_timesteps   | 16896       |
| time_elapsed       | 69.2        |
| total_timesteps    | 135168      |
| value_loss         | 0.07049619  |
------------------------------------
-------------------------------------
| approxkl           | 0.008791884  |
| clipfrac           | 0.12553711   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.32        |
| explained_variance | 0.69         |
| fps                | 2118         |
| n_updates          | 67           |
| policy_entropy     | 7.8948774    |
| policy_loss        | -0.014673265 |
| serial_timesteps   | 17152        |
| time_elapsed       | 70.1         |
| total_timesteps    | 137216       |
| value_loss         | 0.042832583  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0074432148 |
| clipfrac           | 0.100048825  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.23        |
| explained_variance | 0.48         |
| fps                | 2056         |
| n_updates          | 68           |
| policy_entropy     | 7.883423     |
| policy_loss        | -0.009832467 |
| serial_timesteps   | 17408        |
| time_elapsed       | 71.1         |
| total_timesteps    | 139264       |
| value_loss         | 0.071640514  |
-------------------------------------
Eval num_timesteps=140000, episode_reward=-0.67 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.009805408  |
| clipfrac           | 0.14169922   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.28        |
| explained_variance | 0.512        |
| fps                | 1485         |
| n_updates          | 69           |
| policy_entropy     | 7.872523     |
| policy_loss        | -0.015998434 |
| serial_timesteps   | 17664        |
| time_elapsed       | 72.1         |
| total_timesteps    | 141312       |
| value_loss         | 0.07512388   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008885094  |
| clipfrac           | 0.12446289   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.22        |
| explained_variance | 0.287        |
| fps                | 2144         |
| n_updates          | 70           |
| policy_entropy     | 7.8826323    |
| policy_loss        | -0.013411616 |
| serial_timesteps   | 17920        |
| time_elapsed       | 73.5         |
| total_timesteps    | 143360       |
| value_loss         | 0.09574086   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0075768316 |
| clipfrac           | 0.104199216  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.24        |
| explained_variance | 0.501        |
| fps                | 2134         |
| n_updates          | 71           |
| policy_entropy     | 7.894085     |
| policy_loss        | -0.008570256 |
| serial_timesteps   | 18176        |
| time_elapsed       | 74.4         |
| total_timesteps    | 145408       |
| value_loss         | 0.066980675  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0063051432 |
| clipfrac           | 0.076855466  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.28        |
| explained_variance | 0.566        |
| fps                | 2034         |
| n_updates          | 72           |
| policy_entropy     | 7.896285     |
| policy_loss        | -0.008907782 |
| serial_timesteps   | 18432        |
| time_elapsed       | 75.4         |
| total_timesteps    | 147456       |
| value_loss         | 0.06584302   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0087398365 |
| clipfrac           | 0.12006836   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.32        |
| explained_variance | 0.518        |
| fps                | 2042         |
| n_updates          | 73           |
| policy_entropy     | 7.9148536    |
| policy_loss        | -0.012015453 |
| serial_timesteps   | 18688        |
| time_elapsed       | 76.4         |
| total_timesteps    | 149504       |
| value_loss         | 0.06633622   |
-------------------------------------
Eval num_timesteps=150000, episode_reward=-0.68 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008351563  |
| clipfrac           | 0.11611328   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.24        |
| explained_variance | 0.645        |
| fps                | 1452         |
| n_updates          | 74           |
| policy_entropy     | 7.91885      |
| policy_loss        | -0.010894437 |
| serial_timesteps   | 18944        |
| time_elapsed       | 77.4         |
| total_timesteps    | 151552       |
| value_loss         | 0.0427134    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008107125  |
| clipfrac           | 0.11303711   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.22        |
| explained_variance | 0.643        |
| fps                | 2067         |
| n_updates          | 75           |
| policy_entropy     | 7.9020247    |
| policy_loss        | -0.011951422 |
| serial_timesteps   | 19200        |
| time_elapsed       | 78.8         |
| total_timesteps    | 153600       |
| value_loss         | 0.049894355  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007839831  |
| clipfrac           | 0.1038086    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.25        |
| explained_variance | 0.497        |
| fps                | 2108         |
| n_updates          | 76           |
| policy_entropy     | 7.8720956    |
| policy_loss        | -0.011253656 |
| serial_timesteps   | 19456        |
| time_elapsed       | 79.8         |
| total_timesteps    | 155648       |
| value_loss         | 0.062173158  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0097464435 |
| clipfrac           | 0.14033203   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.21        |
| explained_variance | 0.539        |
| fps                | 2100         |
| n_updates          | 77           |
| policy_entropy     | 7.849036     |
| policy_loss        | -0.01235221  |
| serial_timesteps   | 19712        |
| time_elapsed       | 80.8         |
| total_timesteps    | 157696       |
| value_loss         | 0.05227403   |
-------------------------------------
------------------------------------
| approxkl           | 0.008454501 |
| clipfrac           | 0.11635742  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -2.12       |
| explained_variance | 0.581       |
| fps                | 2129        |
| n_updates          | 78          |
| policy_entropy     | 7.8577623   |
| policy_loss        | -0.01020707 |
| serial_timesteps   | 19968       |
| time_elapsed       | 81.7        |
| total_timesteps    | 159744      |
| value_loss         | 0.041740805 |
------------------------------------
Eval num_timesteps=160000, episode_reward=-0.67 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007020732  |
| clipfrac           | 0.091601565  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.11        |
| explained_variance | 0.674        |
| fps                | 1439         |
| n_updates          | 79           |
| policy_entropy     | 7.848916     |
| policy_loss        | -0.008249511 |
| serial_timesteps   | 20224        |
| time_elapsed       | 82.7         |
| total_timesteps    | 161792       |
| value_loss         | 0.04776957   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0085443575 |
| clipfrac           | 0.11767578   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.1         |
| explained_variance | 0.674        |
| fps                | 2123         |
| n_updates          | 80           |
| policy_entropy     | 7.8336425    |
| policy_loss        | -0.008864039 |
| serial_timesteps   | 20480        |
| time_elapsed       | 84.1         |
| total_timesteps    | 163840       |
| value_loss         | 0.050240915  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00774754   |
| clipfrac           | 0.09990235   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.08        |
| explained_variance | 0.528        |
| fps                | 2123         |
| n_updates          | 81           |
| policy_entropy     | 7.816142     |
| policy_loss        | -0.010316099 |
| serial_timesteps   | 20736        |
| time_elapsed       | 85.1         |
| total_timesteps    | 165888       |
| value_loss         | 0.06577591   |
-------------------------------------
-------------------------------------
| approxkl           | 0.006670651  |
| clipfrac           | 0.08164062   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.04        |
| explained_variance | 0.619        |
| fps                | 2143         |
| n_updates          | 82           |
| policy_entropy     | 7.7894135    |
| policy_loss        | -0.009045722 |
| serial_timesteps   | 20992        |
| time_elapsed       | 86           |
| total_timesteps    | 167936       |
| value_loss         | 0.05349008   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009185068  |
| clipfrac           | 0.13452148   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.05        |
| explained_variance | 0.661        |
| fps                | 2007         |
| n_updates          | 83           |
| policy_entropy     | 7.756685     |
| policy_loss        | -0.011486776 |
| serial_timesteps   | 21248        |
| time_elapsed       | 87           |
| total_timesteps    | 169984       |
| value_loss         | 0.051115774  |
-------------------------------------
Eval num_timesteps=170000, episode_reward=-0.60 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.0087840855 |
| clipfrac           | 0.12084961   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.06        |
| explained_variance | 0.6          |
| fps                | 1521         |
| n_updates          | 84           |
| policy_entropy     | 7.7589884    |
| policy_loss        | -0.013006386 |
| serial_timesteps   | 21504        |
| time_elapsed       | 88           |
| total_timesteps    | 172032       |
| value_loss         | 0.043056563  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0072791204 |
| clipfrac           | 0.09233399   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.06        |
| explained_variance | 0.616        |
| fps                | 2147         |
| n_updates          | 85           |
| policy_entropy     | 7.778867     |
| policy_loss        | -0.011587528 |
| serial_timesteps   | 21760        |
| time_elapsed       | 89.4         |
| total_timesteps    | 174080       |
| value_loss         | 0.05095973   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077230395 |
| clipfrac           | 0.10439453   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.05        |
| explained_variance | 0.54         |
| fps                | 2106         |
| n_updates          | 86           |
| policy_entropy     | 7.780379     |
| policy_loss        | -0.010654737 |
| serial_timesteps   | 22016        |
| time_elapsed       | 90.3         |
| total_timesteps    | 176128       |
| value_loss         | 0.057128977  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0082026385 |
| clipfrac           | 0.10976563   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.08        |
| explained_variance | 0.519        |
| fps                | 2116         |
| n_updates          | 87           |
| policy_entropy     | 7.7561774    |
| policy_loss        | -0.013735938 |
| serial_timesteps   | 22272        |
| time_elapsed       | 91.3         |
| total_timesteps    | 178176       |
| value_loss         | 0.05241859   |
-------------------------------------
Eval num_timesteps=180000, episode_reward=-0.38 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.008521026  |
| clipfrac           | 0.12207031   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.05        |
| explained_variance | 0.636        |
| fps                | 1530         |
| n_updates          | 88           |
| policy_entropy     | 7.741687     |
| policy_loss        | -0.011201183 |
| serial_timesteps   | 22528        |
| time_elapsed       | 92.3         |
| total_timesteps    | 180224       |
| value_loss         | 0.056118976  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009940511  |
| clipfrac           | 0.14389649   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.08        |
| explained_variance | 0.537        |
| fps                | 2157         |
| n_updates          | 89           |
| policy_entropy     | 7.7331657    |
| policy_loss        | -0.014582929 |
| serial_timesteps   | 22784        |
| time_elapsed       | 93.6         |
| total_timesteps    | 182272       |
| value_loss         | 0.053618878  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008334814  |
| clipfrac           | 0.10932617   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.09        |
| explained_variance | 0.589        |
| fps                | 2130         |
| n_updates          | 90           |
| policy_entropy     | 7.690657     |
| policy_loss        | -0.010632931 |
| serial_timesteps   | 23040        |
| time_elapsed       | 94.6         |
| total_timesteps    | 184320       |
| value_loss         | 0.047823142  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0073449677 |
| clipfrac           | 0.09399414   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.1         |
| explained_variance | 0.597        |
| fps                | 2163         |
| n_updates          | 91           |
| policy_entropy     | 7.6683044    |
| policy_loss        | -0.009026767 |
| serial_timesteps   | 23296        |
| time_elapsed       | 95.5         |
| total_timesteps    | 186368       |
| value_loss         | 0.059446882  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008673285  |
| clipfrac           | 0.11625977   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.22        |
| explained_variance | 0.27         |
| fps                | 2172         |
| n_updates          | 92           |
| policy_entropy     | 7.6748896    |
| policy_loss        | -0.010369494 |
| serial_timesteps   | 23552        |
| time_elapsed       | 96.5         |
| total_timesteps    | 188416       |
| value_loss         | 0.09631254   |
-------------------------------------
Eval num_timesteps=190000, episode_reward=-3.24 +/- 0.06
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.007724572   |
| clipfrac           | 0.10019531    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -2.29         |
| explained_variance | 0.548         |
| fps                | 1551          |
| n_updates          | 93            |
| policy_entropy     | 7.663063      |
| policy_loss        | -0.0076446794 |
| serial_timesteps   | 23808         |
| time_elapsed       | 97.4          |
| total_timesteps    | 190464        |
| value_loss         | 0.06412871    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0084794145 |
| clipfrac           | 0.117285155  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.21        |
| explained_variance | 0.657        |
| fps                | 2162         |
| n_updates          | 94           |
| policy_entropy     | 7.643056     |
| policy_loss        | -0.011781538 |
| serial_timesteps   | 24064        |
| time_elapsed       | 98.7         |
| total_timesteps    | 192512       |
| value_loss         | 0.04871615   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0076694144 |
| clipfrac           | 0.09882812   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.22        |
| explained_variance | 0.586        |
| fps                | 2164         |
| n_updates          | 95           |
| policy_entropy     | 7.646669     |
| policy_loss        | -0.010338083 |
| serial_timesteps   | 24320        |
| time_elapsed       | 99.7         |
| total_timesteps    | 194560       |
| value_loss         | 0.06534858   |
-------------------------------------
------------------------------------
| approxkl           | 0.008077157 |
| clipfrac           | 0.10834961  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -2.27       |
| explained_variance | 0.625       |
| fps                | 2133        |
| n_updates          | 96          |
| policy_entropy     | 7.666198    |
| policy_loss        | -0.0120582  |
| serial_timesteps   | 24576       |
| time_elapsed       | 101         |
| total_timesteps    | 196608      |
| value_loss         | 0.0430195   |
------------------------------------
-------------------------------------
| approxkl           | 0.00855382   |
| clipfrac           | 0.12036133   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.15        |
| explained_variance | 0.679        |
| fps                | 2096         |
| n_updates          | 97           |
| policy_entropy     | 7.678975     |
| policy_loss        | -0.011959782 |
| serial_timesteps   | 24832        |
| time_elapsed       | 102          |
| total_timesteps    | 198656       |
| value_loss         | 0.03748724   |
-------------------------------------
Eval num_timesteps=200000, episode_reward=-0.29 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.0072795274 |
| clipfrac           | 0.09541015   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.15        |
| explained_variance | 0.579        |
| fps                | 1495         |
| n_updates          | 98           |
| policy_entropy     | 7.6616173    |
| policy_loss        | -0.008711269 |
| serial_timesteps   | 25088        |
| time_elapsed       | 103          |
| total_timesteps    | 200704       |
| value_loss         | 0.05674951   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0080039    |
| clipfrac           | 0.10527344   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.17        |
| explained_variance | 0.618        |
| fps                | 2122         |
| n_updates          | 99           |
| policy_entropy     | 7.6185236    |
| policy_loss        | -0.011725508 |
| serial_timesteps   | 25344        |
| time_elapsed       | 104          |
| total_timesteps    | 202752       |
| value_loss         | 0.05000466   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0068947785 |
| clipfrac           | 0.09067383   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.15        |
| explained_variance | 0.405        |
| fps                | 2094         |
| n_updates          | 100          |
| policy_entropy     | 7.604773     |
| policy_loss        | -0.013037999 |
| serial_timesteps   | 25600        |
| time_elapsed       | 105          |
| total_timesteps    | 204800       |
| value_loss         | 0.07639657   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00789265   |
| clipfrac           | 0.10478516   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.14        |
| explained_variance | 0.562        |
| fps                | 2140         |
| n_updates          | 101          |
| policy_entropy     | 7.5877357    |
| policy_loss        | -0.010557704 |
| serial_timesteps   | 25856        |
| time_elapsed       | 106          |
| total_timesteps    | 206848       |
| value_loss         | 0.06217438   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00699426   |
| clipfrac           | 0.09189453   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.15        |
| explained_variance | 0.608        |
| fps                | 2068         |
| n_updates          | 102          |
| policy_entropy     | 7.56314      |
| policy_loss        | -0.008597173 |
| serial_timesteps   | 26112        |
| time_elapsed       | 107          |
| total_timesteps    | 208896       |
| value_loss         | 0.043337837  |
-------------------------------------
Eval num_timesteps=210000, episode_reward=-0.27 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.0077023185 |
| clipfrac           | 0.0972168    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.13        |
| explained_variance | 0.556        |
| fps                | 1411         |
| n_updates          | 103          |
| policy_entropy     | 7.5424285    |
| policy_loss        | -0.009381538 |
| serial_timesteps   | 26368        |
| time_elapsed       | 108          |
| total_timesteps    | 210944       |
| value_loss         | 0.05354295   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008122944  |
| clipfrac           | 0.10908203   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.1         |
| explained_variance | 0.669        |
| fps                | 2112         |
| n_updates          | 104          |
| policy_entropy     | 7.5298986    |
| policy_loss        | -0.010248302 |
| serial_timesteps   | 26624        |
| time_elapsed       | 109          |
| total_timesteps    | 212992       |
| value_loss         | 0.046873316  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009358829  |
| clipfrac           | 0.12451172   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.08        |
| explained_variance | 0.524        |
| fps                | 2160         |
| n_updates          | 105          |
| policy_entropy     | 7.522321     |
| policy_loss        | -0.014233883 |
| serial_timesteps   | 26880        |
| time_elapsed       | 110          |
| total_timesteps    | 215040       |
| value_loss         | 0.054886032  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007036434  |
| clipfrac           | 0.091992185  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.99        |
| explained_variance | 0.594        |
| fps                | 2120         |
| n_updates          | 106          |
| policy_entropy     | 7.5432787    |
| policy_loss        | -0.009247947 |
| serial_timesteps   | 27136        |
| time_elapsed       | 111          |
| total_timesteps    | 217088       |
| value_loss         | 0.048090722  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008882984  |
| clipfrac           | 0.1227539    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.99        |
| explained_variance | 0.615        |
| fps                | 2129         |
| n_updates          | 107          |
| policy_entropy     | 7.551984     |
| policy_loss        | -0.012674841 |
| serial_timesteps   | 27392        |
| time_elapsed       | 112          |
| total_timesteps    | 219136       |
| value_loss         | 0.04865799   |
-------------------------------------
Eval num_timesteps=220000, episode_reward=-0.27 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
--------------------------------------
| approxkl           | 0.008657702   |
| clipfrac           | 0.11928711    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -2.02         |
| explained_variance | 0.395         |
| fps                | 1507          |
| n_updates          | 108           |
| policy_entropy     | 7.5373545     |
| policy_loss        | -0.0096912235 |
| serial_timesteps   | 27648         |
| time_elapsed       | 113           |
| total_timesteps    | 221184        |
| value_loss         | 0.07902702    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0092095    |
| clipfrac           | 0.12685546   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.03        |
| explained_variance | 0.578        |
| fps                | 2109         |
| n_updates          | 109          |
| policy_entropy     | 7.5236387    |
| policy_loss        | -0.012289407 |
| serial_timesteps   | 27904        |
| time_elapsed       | 114          |
| total_timesteps    | 223232       |
| value_loss         | 0.05177591   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008217376  |
| clipfrac           | 0.11489258   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.98        |
| explained_variance | 0.466        |
| fps                | 2105         |
| n_updates          | 110          |
| policy_entropy     | 7.520771     |
| policy_loss        | -0.009605097 |
| serial_timesteps   | 28160        |
| time_elapsed       | 115          |
| total_timesteps    | 225280       |
| value_loss         | 0.05829717   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0075004385  |
| clipfrac           | 0.0949707     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.99         |
| explained_variance | 0.608         |
| fps                | 2105          |
| n_updates          | 111           |
| policy_entropy     | 7.522564      |
| policy_loss        | -0.0072400244 |
| serial_timesteps   | 28416         |
| time_elapsed       | 116           |
| total_timesteps    | 227328        |
| value_loss         | 0.056122065   |
--------------------------------------
-------------------------------------
| approxkl           | 0.007514698  |
| clipfrac           | 0.09604492   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.98        |
| explained_variance | 0.615        |
| fps                | 2051         |
| n_updates          | 112          |
| policy_entropy     | 7.513934     |
| policy_loss        | -0.008130543 |
| serial_timesteps   | 28672        |
| time_elapsed       | 117          |
| total_timesteps    | 229376       |
| value_loss         | 0.043559197  |
-------------------------------------
Eval num_timesteps=230000, episode_reward=-1.27 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008943791  |
| clipfrac           | 0.1284668    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.667        |
| fps                | 1464         |
| n_updates          | 113          |
| policy_entropy     | 7.5009894    |
| policy_loss        | -0.010632553 |
| serial_timesteps   | 28928        |
| time_elapsed       | 118          |
| total_timesteps    | 231424       |
| value_loss         | 0.043233573  |
-------------------------------------
-------------------------------------
| approxkl           | 0.006459025  |
| clipfrac           | 0.08222656   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.615        |
| fps                | 2182         |
| n_updates          | 114          |
| policy_entropy     | 7.4897103    |
| policy_loss        | -0.008425213 |
| serial_timesteps   | 29184        |
| time_elapsed       | 120          |
| total_timesteps    | 233472       |
| value_loss         | 0.039259385  |
-------------------------------------
--------------------------------------
| approxkl           | 0.006946236   |
| clipfrac           | 0.09125976    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.89         |
| explained_variance | 0.595         |
| fps                | 2192          |
| n_updates          | 115           |
| policy_entropy     | 7.486416      |
| policy_loss        | -0.0072974795 |
| serial_timesteps   | 29440         |
| time_elapsed       | 121           |
| total_timesteps    | 235520        |
| value_loss         | 0.038072906   |
--------------------------------------
------------------------------------
| approxkl           | 0.007995376 |
| clipfrac           | 0.10942383  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.86       |
| explained_variance | 0.581       |
| fps                | 2159        |
| n_updates          | 116         |
| policy_entropy     | 7.47088     |
| policy_loss        | -0.01006812 |
| serial_timesteps   | 29696       |
| time_elapsed       | 122         |
| total_timesteps    | 237568      |
| value_loss         | 0.049052157 |
------------------------------------
--------------------------------------
| approxkl           | 0.0064062094  |
| clipfrac           | 0.07519531    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.84         |
| explained_variance | 0.662         |
| fps                | 2129          |
| n_updates          | 117           |
| policy_entropy     | 7.4620194     |
| policy_loss        | -0.0041428204 |
| serial_timesteps   | 29952         |
| time_elapsed       | 123           |
| total_timesteps    | 239616        |
| value_loss         | 0.03997262    |
--------------------------------------
Eval num_timesteps=240000, episode_reward=-1.22 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008155542  |
| clipfrac           | 0.11381836   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.666        |
| fps                | 1537         |
| n_updates          | 118          |
| policy_entropy     | 7.4422483    |
| policy_loss        | -0.008702844 |
| serial_timesteps   | 30208        |
| time_elapsed       | 124          |
| total_timesteps    | 241664       |
| value_loss         | 0.043846365  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0075612823 |
| clipfrac           | 0.0925293    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.596        |
| fps                | 2175         |
| n_updates          | 119          |
| policy_entropy     | 7.4240503    |
| policy_loss        | -0.010236332 |
| serial_timesteps   | 30464        |
| time_elapsed       | 125          |
| total_timesteps    | 243712       |
| value_loss         | 0.042005952  |
-------------------------------------
--------------------------------------
| approxkl           | 0.007235553   |
| clipfrac           | 0.09448242    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.89         |
| explained_variance | 0.687         |
| fps                | 2120          |
| n_updates          | 120           |
| policy_entropy     | 7.4378433     |
| policy_loss        | -0.0063423375 |
| serial_timesteps   | 30720         |
| time_elapsed       | 126           |
| total_timesteps    | 245760        |
| value_loss         | 0.043651633   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0071250424 |
| clipfrac           | 0.096386716  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.666        |
| fps                | 1926         |
| n_updates          | 121          |
| policy_entropy     | 7.435238     |
| policy_loss        | -0.00861439  |
| serial_timesteps   | 30976        |
| time_elapsed       | 127          |
| total_timesteps    | 247808       |
| value_loss         | 0.04014904   |
-------------------------------------
--------------------------------------
| approxkl           | 0.00781308    |
| clipfrac           | 0.1           |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.9          |
| explained_variance | 0.645         |
| fps                | 2131          |
| n_updates          | 122           |
| policy_entropy     | 7.4335794     |
| policy_loss        | -0.0078105377 |
| serial_timesteps   | 31232         |
| time_elapsed       | 128           |
| total_timesteps    | 249856        |
| value_loss         | 0.04439627    |
--------------------------------------
Eval num_timesteps=250000, episode_reward=-0.74 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007915968  |
| clipfrac           | 0.10175781   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.573        |
| fps                | 1490         |
| n_updates          | 123          |
| policy_entropy     | 7.4416595    |
| policy_loss        | -0.008919839 |
| serial_timesteps   | 31488        |
| time_elapsed       | 129          |
| total_timesteps    | 251904       |
| value_loss         | 0.05219221   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009562349  |
| clipfrac           | 0.1416504    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.637        |
| fps                | 2119         |
| n_updates          | 124          |
| policy_entropy     | 7.455452     |
| policy_loss        | -0.012297125 |
| serial_timesteps   | 31744        |
| time_elapsed       | 130          |
| total_timesteps    | 253952       |
| value_loss         | 0.04621762   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007359742  |
| clipfrac           | 0.09472656   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.711        |
| fps                | 2007         |
| n_updates          | 125          |
| policy_entropy     | 7.450226     |
| policy_loss        | -0.008829197 |
| serial_timesteps   | 32000        |
| time_elapsed       | 131          |
| total_timesteps    | 256000       |
| value_loss         | 0.038990427  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008751826  |
| clipfrac           | 0.12553711   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.689        |
| fps                | 2140         |
| n_updates          | 126          |
| policy_entropy     | 7.4305787    |
| policy_loss        | -0.011208184 |
| serial_timesteps   | 32256        |
| time_elapsed       | 132          |
| total_timesteps    | 258048       |
| value_loss         | 0.036769304  |
-------------------------------------
Eval num_timesteps=260000, episode_reward=-0.94 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0077633196 |
| clipfrac           | 0.10224609   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.71         |
| fps                | 1468         |
| n_updates          | 127          |
| policy_entropy     | 7.3959465    |
| policy_loss        | -0.010528652 |
| serial_timesteps   | 32512        |
| time_elapsed       | 133          |
| total_timesteps    | 260096       |
| value_loss         | 0.038012322  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008643569  |
| clipfrac           | 0.12045898   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.659        |
| fps                | 2125         |
| n_updates          | 128          |
| policy_entropy     | 7.375923     |
| policy_loss        | -0.009622012 |
| serial_timesteps   | 32768        |
| time_elapsed       | 135          |
| total_timesteps    | 262144       |
| value_loss         | 0.040828142  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008017888  |
| clipfrac           | 0.111767575  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.718        |
| fps                | 2105         |
| n_updates          | 129          |
| policy_entropy     | 7.380458     |
| policy_loss        | -0.009719329 |
| serial_timesteps   | 33024        |
| time_elapsed       | 136          |
| total_timesteps    | 264192       |
| value_loss         | 0.0454916    |
-------------------------------------
-------------------------------------
| approxkl           | 0.00844264   |
| clipfrac           | 0.117773436  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.732        |
| fps                | 2040         |
| n_updates          | 130          |
| policy_entropy     | 7.391716     |
| policy_loss        | -0.010451332 |
| serial_timesteps   | 33280        |
| time_elapsed       | 136          |
| total_timesteps    | 266240       |
| value_loss         | 0.031311534  |
-------------------------------------
--------------------------------------
| approxkl           | 0.007424418   |
| clipfrac           | 0.09604492    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.87         |
| explained_variance | 0.751         |
| fps                | 2149          |
| n_updates          | 131           |
| policy_entropy     | 7.377412      |
| policy_loss        | -0.0073850797 |
| serial_timesteps   | 33536         |
| time_elapsed       | 137           |
| total_timesteps    | 268288        |
| value_loss         | 0.035864912   |
--------------------------------------
Eval num_timesteps=270000, episode_reward=-0.97 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0072688074 |
| clipfrac           | 0.091992185  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.648        |
| fps                | 1439         |
| n_updates          | 132          |
| policy_entropy     | 7.3478913    |
| policy_loss        | -0.009050049 |
| serial_timesteps   | 33792        |
| time_elapsed       | 138          |
| total_timesteps    | 270336       |
| value_loss         | 0.03799287   |
-------------------------------------
--------------------------------------
| approxkl           | 0.006923144   |
| clipfrac           | 0.08515625    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.83         |
| explained_variance | 0.693         |
| fps                | 2138          |
| n_updates          | 133           |
| policy_entropy     | 7.316083      |
| policy_loss        | -0.0090359235 |
| serial_timesteps   | 34048         |
| time_elapsed       | 140           |
| total_timesteps    | 272384        |
| value_loss         | 0.03480001    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0083327405 |
| clipfrac           | 0.11069336   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.79        |
| explained_variance | 0.646        |
| fps                | 2097         |
| n_updates          | 134          |
| policy_entropy     | 7.296168     |
| policy_loss        | -0.009542864 |
| serial_timesteps   | 34304        |
| time_elapsed       | 141          |
| total_timesteps    | 274432       |
| value_loss         | 0.040785063  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009135234  |
| clipfrac           | 0.13295898   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.78        |
| explained_variance | 0.669        |
| fps                | 2129         |
| n_updates          | 135          |
| policy_entropy     | 7.2788725    |
| policy_loss        | -0.010479072 |
| serial_timesteps   | 34560        |
| time_elapsed       | 142          |
| total_timesteps    | 276480       |
| value_loss         | 0.035510782  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007988481  |
| clipfrac           | 0.10869141   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.78        |
| explained_variance | 0.682        |
| fps                | 2085         |
| n_updates          | 136          |
| policy_entropy     | 7.2593446    |
| policy_loss        | -0.010456652 |
| serial_timesteps   | 34816        |
| time_elapsed       | 143          |
| total_timesteps    | 278528       |
| value_loss         | 0.040046435  |
-------------------------------------
Eval num_timesteps=280000, episode_reward=-0.93 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009035559  |
| clipfrac           | 0.123486325  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.79        |
| explained_variance | 0.654        |
| fps                | 1507         |
| n_updates          | 137          |
| policy_entropy     | 7.239038     |
| policy_loss        | -0.009372416 |
| serial_timesteps   | 35072        |
| time_elapsed       | 144          |
| total_timesteps    | 280576       |
| value_loss         | 0.039868362  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0074404264  |
| clipfrac           | 0.095703125   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.83         |
| explained_variance | 0.68          |
| fps                | 2126          |
| n_updates          | 138           |
| policy_entropy     | 7.229833      |
| policy_loss        | -0.0070826067 |
| serial_timesteps   | 35328         |
| time_elapsed       | 145           |
| total_timesteps    | 282624        |
| value_loss         | 0.046920817   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0072712386 |
| clipfrac           | 0.09057617   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.84        |
| explained_variance | 0.625        |
| fps                | 2131         |
| n_updates          | 139          |
| policy_entropy     | 7.235845     |
| policy_loss        | -0.00844311  |
| serial_timesteps   | 35584        |
| time_elapsed       | 146          |
| total_timesteps    | 284672       |
| value_loss         | 0.039085247  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0068302876  |
| clipfrac           | 0.0847168     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.87         |
| explained_variance | 0.614         |
| fps                | 2104          |
| n_updates          | 140           |
| policy_entropy     | 7.2583594     |
| policy_loss        | -0.0073815184 |
| serial_timesteps   | 35840         |
| time_elapsed       | 147           |
| total_timesteps    | 286720        |
| value_loss         | 0.040575907   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0070400597 |
| clipfrac           | 0.09082031   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.628        |
| fps                | 2215         |
| n_updates          | 141          |
| policy_entropy     | 7.2659445    |
| policy_loss        | -0.006166148 |
| serial_timesteps   | 36096        |
| time_elapsed       | 148          |
| total_timesteps    | 288768       |
| value_loss         | 0.03947439   |
-------------------------------------
Eval num_timesteps=290000, episode_reward=-1.14 +/- 0.06
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0077860532 |
| clipfrac           | 0.104199216  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.708        |
| fps                | 1566         |
| n_updates          | 142          |
| policy_entropy     | 7.241122     |
| policy_loss        | -0.009235103 |
| serial_timesteps   | 36352        |
| time_elapsed       | 149          |
| total_timesteps    | 290816       |
| value_loss         | 0.04239496   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077461163 |
| clipfrac           | 0.103466794  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.83        |
| explained_variance | 0.703        |
| fps                | 2136         |
| n_updates          | 143          |
| policy_entropy     | 7.2222776    |
| policy_loss        | -0.00745856  |
| serial_timesteps   | 36608        |
| time_elapsed       | 150          |
| total_timesteps    | 292864       |
| value_loss         | 0.043746285  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008953332  |
| clipfrac           | 0.12392578   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.84        |
| explained_variance | 0.721        |
| fps                | 2155         |
| n_updates          | 144          |
| policy_entropy     | 7.2031355    |
| policy_loss        | -0.012875907 |
| serial_timesteps   | 36864        |
| time_elapsed       | 151          |
| total_timesteps    | 294912       |
| value_loss         | 0.035799608  |
-------------------------------------
------------------------------------
| approxkl           | 0.008934965 |
| clipfrac           | 0.12387695  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.86       |
| explained_variance | 0.677       |
| fps                | 2178        |
| n_updates          | 145         |
| policy_entropy     | 7.1896286   |
| policy_loss        | -0.01002712 |
| serial_timesteps   | 37120       |
| time_elapsed       | 152         |
| total_timesteps    | 296960      |
| value_loss         | 0.043502305 |
------------------------------------
-------------------------------------
| approxkl           | 0.008372819  |
| clipfrac           | 0.1140625    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.6          |
| fps                | 2192         |
| n_updates          | 146          |
| policy_entropy     | 7.184958     |
| policy_loss        | -0.010159412 |
| serial_timesteps   | 37376        |
| time_elapsed       | 153          |
| total_timesteps    | 299008       |
| value_loss         | 0.043016642  |
-------------------------------------
Eval num_timesteps=300000, episode_reward=-0.89 +/- 0.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010037533  |
| clipfrac           | 0.14135742   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.62         |
| fps                | 1553         |
| n_updates          | 147          |
| policy_entropy     | 7.155018     |
| policy_loss        | -0.014492671 |
| serial_timesteps   | 37632        |
| time_elapsed       | 154          |
| total_timesteps    | 301056       |
| value_loss         | 0.044871315  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008493421  |
| clipfrac           | 0.11689453   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.95        |
| explained_variance | 0.545        |
| fps                | 2187         |
| n_updates          | 148          |
| policy_entropy     | 7.1549745    |
| policy_loss        | -0.012470015 |
| serial_timesteps   | 37888        |
| time_elapsed       | 155          |
| total_timesteps    | 303104       |
| value_loss         | 0.049995534  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008458239  |
| clipfrac           | 0.11977539   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.97        |
| explained_variance | 0.579        |
| fps                | 2158         |
| n_updates          | 149          |
| policy_entropy     | 7.156329     |
| policy_loss        | -0.011355503 |
| serial_timesteps   | 38144        |
| time_elapsed       | 156          |
| total_timesteps    | 305152       |
| value_loss         | 0.045068838  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0086086    |
| clipfrac           | 0.12011719   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.95        |
| explained_variance | 0.618        |
| fps                | 2166         |
| n_updates          | 150          |
| policy_entropy     | 7.1435423    |
| policy_loss        | -0.010470696 |
| serial_timesteps   | 38400        |
| time_elapsed       | 157          |
| total_timesteps    | 307200       |
| value_loss         | 0.03568708   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008346027  |
| clipfrac           | 0.11601563   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.732        |
| fps                | 2141         |
| n_updates          | 151          |
| policy_entropy     | 7.14174      |
| policy_loss        | -0.010195488 |
| serial_timesteps   | 38656        |
| time_elapsed       | 158          |
| total_timesteps    | 309248       |
| value_loss         | 0.030058727  |
-------------------------------------
Eval num_timesteps=310000, episode_reward=-1.07 +/- 0.01
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.007890007   |
| clipfrac           | 0.103125      |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.89         |
| explained_variance | 0.678         |
| fps                | 1555          |
| n_updates          | 152           |
| policy_entropy     | 7.14452       |
| policy_loss        | -0.0072098896 |
| serial_timesteps   | 38912         |
| time_elapsed       | 159           |
| total_timesteps    | 311296        |
| value_loss         | 0.038949993   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0063139885 |
| clipfrac           | 0.07475586   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.692        |
| fps                | 2175         |
| n_updates          | 153          |
| policy_entropy     | 7.134417     |
| policy_loss        | -0.007466115 |
| serial_timesteps   | 39168        |
| time_elapsed       | 160          |
| total_timesteps    | 313344       |
| value_loss         | 0.031972047  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0063088527  |
| clipfrac           | 0.07915039    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.85         |
| explained_variance | 0.756         |
| fps                | 2173          |
| n_updates          | 154           |
| policy_entropy     | 7.1272287     |
| policy_loss        | -0.0087762205 |
| serial_timesteps   | 39424         |
| time_elapsed       | 161           |
| total_timesteps    | 315392        |
| value_loss         | 0.03435991    |
--------------------------------------
-------------------------------------
| approxkl           | 0.007546764  |
| clipfrac           | 0.09995117   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.729        |
| fps                | 2150         |
| n_updates          | 155          |
| policy_entropy     | 7.124898     |
| policy_loss        | -0.009012589 |
| serial_timesteps   | 39680        |
| time_elapsed       | 162          |
| total_timesteps    | 317440       |
| value_loss         | 0.031602457  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010393542  |
| clipfrac           | 0.15170899   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.745        |
| fps                | 2154         |
| n_updates          | 156          |
| policy_entropy     | 7.1210313    |
| policy_loss        | -0.013984166 |
| serial_timesteps   | 39936        |
| time_elapsed       | 163          |
| total_timesteps    | 319488       |
| value_loss         | 0.034200173  |
-------------------------------------
Eval num_timesteps=320000, episode_reward=-1.26 +/- 0.03
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008201112  |
| clipfrac           | 0.108789064  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.84        |
| explained_variance | 0.622        |
| fps                | 1551         |
| n_updates          | 157          |
| policy_entropy     | 7.0840354    |
| policy_loss        | -0.011403403 |
| serial_timesteps   | 40192        |
| time_elapsed       | 164          |
| total_timesteps    | 321536       |
| value_loss         | 0.03849826   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008706755  |
| clipfrac           | 0.123535156  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.701        |
| fps                | 2161         |
| n_updates          | 158          |
| policy_entropy     | 7.0643454    |
| policy_loss        | -0.011144271 |
| serial_timesteps   | 40448        |
| time_elapsed       | 166          |
| total_timesteps    | 323584       |
| value_loss         | 0.035872974  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00919156   |
| clipfrac           | 0.13012695   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.72         |
| fps                | 2160         |
| n_updates          | 159          |
| policy_entropy     | 7.0644274    |
| policy_loss        | -0.011287099 |
| serial_timesteps   | 40704        |
| time_elapsed       | 167          |
| total_timesteps    | 325632       |
| value_loss         | 0.037050925  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007195886  |
| clipfrac           | 0.09462891   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.657        |
| fps                | 2204         |
| n_updates          | 160          |
| policy_entropy     | 7.0635004    |
| policy_loss        | -0.008538144 |
| serial_timesteps   | 40960        |
| time_elapsed       | 167          |
| total_timesteps    | 327680       |
| value_loss         | 0.04044612   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0070371395 |
| clipfrac           | 0.08496094   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.696        |
| fps                | 2200         |
| n_updates          | 161          |
| policy_entropy     | 7.063591     |
| policy_loss        | -0.00721984  |
| serial_timesteps   | 41216        |
| time_elapsed       | 168          |
| total_timesteps    | 329728       |
| value_loss         | 0.04091581   |
-------------------------------------
Eval num_timesteps=330000, episode_reward=-1.24 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0074336887 |
| clipfrac           | 0.09667969   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.653        |
| fps                | 1520         |
| n_updates          | 162          |
| policy_entropy     | 7.0506454    |
| policy_loss        | -0.00799242  |
| serial_timesteps   | 41472        |
| time_elapsed       | 169          |
| total_timesteps    | 331776       |
| value_loss         | 0.033994555  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008206319  |
| clipfrac           | 0.1121582    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.744        |
| fps                | 2127         |
| n_updates          | 163          |
| policy_entropy     | 7.028647     |
| policy_loss        | -0.011102044 |
| serial_timesteps   | 41728        |
| time_elapsed       | 171          |
| total_timesteps    | 333824       |
| value_loss         | 0.036008302  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00775499   |
| clipfrac           | 0.10288086   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.729        |
| fps                | 2164         |
| n_updates          | 164          |
| policy_entropy     | 6.992644     |
| policy_loss        | -0.009987073 |
| serial_timesteps   | 41984        |
| time_elapsed       | 172          |
| total_timesteps    | 335872       |
| value_loss         | 0.031086197  |
-------------------------------------
--------------------------------------
| approxkl           | 0.007064557   |
| clipfrac           | 0.09194336    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.91         |
| explained_variance | 0.747         |
| fps                | 2179          |
| n_updates          | 165           |
| policy_entropy     | 6.9691696     |
| policy_loss        | -0.0076293005 |
| serial_timesteps   | 42240         |
| time_elapsed       | 173           |
| total_timesteps    | 337920        |
| value_loss         | 0.03404161    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0076975487 |
| clipfrac           | 0.103955075  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.666        |
| fps                | 2195         |
| n_updates          | 166          |
| policy_entropy     | 6.9718614    |
| policy_loss        | -0.009017651 |
| serial_timesteps   | 42496        |
| time_elapsed       | 174          |
| total_timesteps    | 339968       |
| value_loss         | 0.03847388   |
-------------------------------------
Eval num_timesteps=340000, episode_reward=-1.14 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.007814022 |
| clipfrac           | 0.106738284 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.9        |
| explained_variance | 0.708       |
| fps                | 1550        |
| n_updates          | 167         |
| policy_entropy     | 6.950061    |
| policy_loss        | -0.00819649 |
| serial_timesteps   | 42752       |
| time_elapsed       | 174         |
| total_timesteps    | 342016      |
| value_loss         | 0.03552948  |
------------------------------------
-------------------------------------
| approxkl           | 0.009289107  |
| clipfrac           | 0.12910156   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.675        |
| fps                | 2216         |
| n_updates          | 168          |
| policy_entropy     | 6.9033737    |
| policy_loss        | -0.009863959 |
| serial_timesteps   | 43008        |
| time_elapsed       | 176          |
| total_timesteps    | 344064       |
| value_loss         | 0.04220919   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0081230225 |
| clipfrac           | 0.10859375   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.645        |
| fps                | 2220         |
| n_updates          | 169          |
| policy_entropy     | 6.8692193    |
| policy_loss        | -0.008400733 |
| serial_timesteps   | 43264        |
| time_elapsed       | 177          |
| total_timesteps    | 346112       |
| value_loss         | 0.03929836   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010174856  |
| clipfrac           | 0.14389649   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.92        |
| explained_variance | 0.682        |
| fps                | 2189         |
| n_updates          | 170          |
| policy_entropy     | 6.882634     |
| policy_loss        | -0.014716853 |
| serial_timesteps   | 43520        |
| time_elapsed       | 178          |
| total_timesteps    | 348160       |
| value_loss         | 0.0390199    |
-------------------------------------
Eval num_timesteps=350000, episode_reward=-1.20 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007969927  |
| clipfrac           | 0.1059082    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.93        |
| explained_variance | 0.664        |
| fps                | 1554         |
| n_updates          | 171          |
| policy_entropy     | 6.8785887    |
| policy_loss        | -0.010173851 |
| serial_timesteps   | 43776        |
| time_elapsed       | 179          |
| total_timesteps    | 350208       |
| value_loss         | 0.035023693  |
-------------------------------------
--------------------------------------
| approxkl           | 0.007243929   |
| clipfrac           | 0.09306641    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.93         |
| explained_variance | 0.745         |
| fps                | 2170          |
| n_updates          | 172           |
| policy_entropy     | 6.868139      |
| policy_loss        | -0.0077611394 |
| serial_timesteps   | 44032         |
| time_elapsed       | 180           |
| total_timesteps    | 352256        |
| value_loss         | 0.03824697    |
--------------------------------------
-------------------------------------
| approxkl           | 0.008927043  |
| clipfrac           | 0.11972656   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.95        |
| explained_variance | 0.661        |
| fps                | 2196         |
| n_updates          | 173          |
| policy_entropy     | 6.8860083    |
| policy_loss        | -0.008641497 |
| serial_timesteps   | 44288        |
| time_elapsed       | 181          |
| total_timesteps    | 354304       |
| value_loss         | 0.044141736  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0071728034 |
| clipfrac           | 0.0959961    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.95        |
| explained_variance | 0.717        |
| fps                | 2195         |
| n_updates          | 174          |
| policy_entropy     | 6.9204035    |
| policy_loss        | -0.007975435 |
| serial_timesteps   | 44544        |
| time_elapsed       | 182          |
| total_timesteps    | 356352       |
| value_loss         | 0.036854748  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007266565  |
| clipfrac           | 0.097314455  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.92        |
| explained_variance | 0.64         |
| fps                | 2187         |
| n_updates          | 175          |
| policy_entropy     | 6.9401217    |
| policy_loss        | -0.006868855 |
| serial_timesteps   | 44800        |
| time_elapsed       | 183          |
| total_timesteps    | 358400       |
| value_loss         | 0.045946974  |
-------------------------------------
Eval num_timesteps=360000, episode_reward=-1.22 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0077746822 |
| clipfrac           | 0.10317383   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.713        |
| fps                | 1566         |
| n_updates          | 176          |
| policy_entropy     | 6.926909     |
| policy_loss        | -0.007676539 |
| serial_timesteps   | 45056        |
| time_elapsed       | 184          |
| total_timesteps    | 360448       |
| value_loss         | 0.03501835   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009115865  |
| clipfrac           | 0.1270996    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.752        |
| fps                | 2179         |
| n_updates          | 177          |
| policy_entropy     | 6.9179506    |
| policy_loss        | -0.009597646 |
| serial_timesteps   | 45312        |
| time_elapsed       | 185          |
| total_timesteps    | 362496       |
| value_loss         | 0.03564656   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008621683  |
| clipfrac           | 0.1149414    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.684        |
| fps                | 2216         |
| n_updates          | 178          |
| policy_entropy     | 6.9298654    |
| policy_loss        | -0.009956281 |
| serial_timesteps   | 45568        |
| time_elapsed       | 186          |
| total_timesteps    | 364544       |
| value_loss         | 0.031959273  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008053465   |
| clipfrac           | 0.103759766   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.87         |
| explained_variance | 0.795         |
| fps                | 2147          |
| n_updates          | 179           |
| policy_entropy     | 6.9518332     |
| policy_loss        | -0.0067846393 |
| serial_timesteps   | 45824         |
| time_elapsed       | 187           |
| total_timesteps    | 366592        |
| value_loss         | 0.032298915   |
--------------------------------------
--------------------------------------
| approxkl           | 0.0072591407  |
| clipfrac           | 0.09140625    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.86         |
| explained_variance | 0.705         |
| fps                | 2214          |
| n_updates          | 180           |
| policy_entropy     | 6.952263      |
| policy_loss        | -0.0079026325 |
| serial_timesteps   | 46080         |
| time_elapsed       | 188           |
| total_timesteps    | 368640        |
| value_loss         | 0.033238534   |
--------------------------------------
Eval num_timesteps=370000, episode_reward=-1.20 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0072272606 |
| clipfrac           | 0.0972168    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.767        |
| fps                | 1558         |
| n_updates          | 181          |
| policy_entropy     | 6.9341063    |
| policy_loss        | -0.010221042 |
| serial_timesteps   | 46336        |
| time_elapsed       | 189          |
| total_timesteps    | 370688       |
| value_loss         | 0.033009328  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0064717173 |
| clipfrac           | 0.08100586   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.723        |
| fps                | 2185         |
| n_updates          | 182          |
| policy_entropy     | 6.9138603    |
| policy_loss        | -0.00762937  |
| serial_timesteps   | 46592        |
| time_elapsed       | 190          |
| total_timesteps    | 372736       |
| value_loss         | 0.03549207   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008373018  |
| clipfrac           | 0.11738281   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.665        |
| fps                | 2188         |
| n_updates          | 183          |
| policy_entropy     | 6.883841     |
| policy_loss        | -0.012051878 |
| serial_timesteps   | 46848        |
| time_elapsed       | 191          |
| total_timesteps    | 374784       |
| value_loss         | 0.046392374  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009256231  |
| clipfrac           | 0.13134766   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.701        |
| fps                | 2219         |
| n_updates          | 184          |
| policy_entropy     | 6.869194     |
| policy_loss        | -0.011992533 |
| serial_timesteps   | 47104        |
| time_elapsed       | 192          |
| total_timesteps    | 376832       |
| value_loss         | 0.04835043   |
-------------------------------------
-------------------------------------
| approxkl           | 0.01102291   |
| clipfrac           | 0.14936523   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.94        |
| explained_variance | 0.605        |
| fps                | 2189         |
| n_updates          | 185          |
| policy_entropy     | 6.8651986    |
| policy_loss        | -0.015125833 |
| serial_timesteps   | 47360        |
| time_elapsed       | 193          |
| total_timesteps    | 378880       |
| value_loss         | 0.04971705   |
-------------------------------------
Eval num_timesteps=380000, episode_reward=-1.06 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0086538885 |
| clipfrac           | 0.114550784  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.98        |
| explained_variance | 0.654        |
| fps                | 1551         |
| n_updates          | 186          |
| policy_entropy     | 6.85798      |
| policy_loss        | -0.012655931 |
| serial_timesteps   | 47616        |
| time_elapsed       | 194          |
| total_timesteps    | 380928       |
| value_loss         | 0.051358532  |
-------------------------------------
------------------------------------
| approxkl           | 0.009702063 |
| clipfrac           | 0.13535157  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -2          |
| explained_variance | 0.584       |
| fps                | 2154        |
| n_updates          | 187         |
| policy_entropy     | 6.838295    |
| policy_loss        | -0.01063499 |
| serial_timesteps   | 47872       |
| time_elapsed       | 195         |
| total_timesteps    | 382976      |
| value_loss         | 0.04996229  |
------------------------------------
------------------------------------
| approxkl           | 0.01025576  |
| clipfrac           | 0.15117188  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -2          |
| explained_variance | 0.656       |
| fps                | 2214        |
| n_updates          | 188         |
| policy_entropy     | 6.8145347   |
| policy_loss        | -0.01369251 |
| serial_timesteps   | 48128       |
| time_elapsed       | 196         |
| total_timesteps    | 385024      |
| value_loss         | 0.045422077 |
------------------------------------
-------------------------------------
| approxkl           | 0.009746278  |
| clipfrac           | 0.13955078   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.98        |
| explained_variance | 0.686        |
| fps                | 2195         |
| n_updates          | 189          |
| policy_entropy     | 6.794265     |
| policy_loss        | -0.012582382 |
| serial_timesteps   | 48384        |
| time_elapsed       | 197          |
| total_timesteps    | 387072       |
| value_loss         | 0.034129377  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008424125  |
| clipfrac           | 0.11147461   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.95        |
| explained_variance | 0.771        |
| fps                | 2189         |
| n_updates          | 190          |
| policy_entropy     | 6.751481     |
| policy_loss        | -0.008241945 |
| serial_timesteps   | 48640        |
| time_elapsed       | 198          |
| total_timesteps    | 389120       |
| value_loss         | 0.03553515   |
-------------------------------------
Eval num_timesteps=390000, episode_reward=-1.20 +/- 0.04
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008910032  |
| clipfrac           | 0.123095706  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.95        |
| explained_variance | 0.642        |
| fps                | 1542         |
| n_updates          | 191          |
| policy_entropy     | 6.7230935    |
| policy_loss        | -0.011714484 |
| serial_timesteps   | 48896        |
| time_elapsed       | 199          |
| total_timesteps    | 391168       |
| value_loss         | 0.04638891   |
-------------------------------------
------------------------------------
| approxkl           | 0.008161444 |
| clipfrac           | 0.10820313  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.92       |
| explained_variance | 0.735       |
| fps                | 2193        |
| n_updates          | 192         |
| policy_entropy     | 6.696878    |
| policy_loss        | -0.00908907 |
| serial_timesteps   | 49152       |
| time_elapsed       | 200         |
| total_timesteps    | 393216      |
| value_loss         | 0.038797077 |
------------------------------------
-------------------------------------
| approxkl           | 0.00792568   |
| clipfrac           | 0.11000977   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.693        |
| fps                | 2223         |
| n_updates          | 193          |
| policy_entropy     | 6.659434     |
| policy_loss        | -0.009066723 |
| serial_timesteps   | 49408        |
| time_elapsed       | 201          |
| total_timesteps    | 395264       |
| value_loss         | 0.04302121   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008702556  |
| clipfrac           | 0.120996095  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.92        |
| explained_variance | 0.737        |
| fps                | 2187         |
| n_updates          | 194          |
| policy_entropy     | 6.6596856    |
| policy_loss        | -0.009294683 |
| serial_timesteps   | 49664        |
| time_elapsed       | 202          |
| total_timesteps    | 397312       |
| value_loss         | 0.03640137   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0090808105 |
| clipfrac           | 0.12924805   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.754        |
| fps                | 2167         |
| n_updates          | 195          |
| policy_entropy     | 6.6699386    |
| policy_loss        | -0.011179059 |
| serial_timesteps   | 49920        |
| time_elapsed       | 203          |
| total_timesteps    | 399360       |
| value_loss         | 0.03579892   |
-------------------------------------
Eval num_timesteps=400000, episode_reward=-1.22 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0077519277 |
| clipfrac           | 0.10273437   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.698        |
| fps                | 1565         |
| n_updates          | 196          |
| policy_entropy     | 6.6542153    |
| policy_loss        | -0.009865159 |
| serial_timesteps   | 50176        |
| time_elapsed       | 204          |
| total_timesteps    | 401408       |
| value_loss         | 0.035575736  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009327849  |
| clipfrac           | 0.1305664    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.773        |
| fps                | 2216         |
| n_updates          | 197          |
| policy_entropy     | 6.614492     |
| policy_loss        | -0.013608603 |
| serial_timesteps   | 50432        |
| time_elapsed       | 205          |
| total_timesteps    | 403456       |
| value_loss         | 0.035403453  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009457847   |
| clipfrac           | 0.12939453    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.88         |
| explained_variance | 0.701         |
| fps                | 2196          |
| n_updates          | 198           |
| policy_entropy     | 6.5644236     |
| policy_loss        | -0.0104668755 |
| serial_timesteps   | 50688         |
| time_elapsed       | 206           |
| total_timesteps    | 405504        |
| value_loss         | 0.039073434   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010255011  |
| clipfrac           | 0.14443359   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.703        |
| fps                | 2165         |
| n_updates          | 199          |
| policy_entropy     | 6.5597816    |
| policy_loss        | -0.016047938 |
| serial_timesteps   | 50944        |
| time_elapsed       | 207          |
| total_timesteps    | 407552       |
| value_loss         | 0.0445228    |
-------------------------------------
-------------------------------------
| approxkl           | 0.009130019  |
| clipfrac           | 0.13286133   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.92        |
| explained_variance | 0.692        |
| fps                | 2225         |
| n_updates          | 200          |
| policy_entropy     | 6.584497     |
| policy_loss        | -0.011962479 |
| serial_timesteps   | 51200        |
| time_elapsed       | 208          |
| total_timesteps    | 409600       |
| value_loss         | 0.040371843  |
-------------------------------------
Eval num_timesteps=410000, episode_reward=-1.32 +/- 0.03
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008192597  |
| clipfrac           | 0.11616211   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.657        |
| fps                | 1556         |
| n_updates          | 201          |
| policy_entropy     | 6.601134     |
| policy_loss        | -0.010851096 |
| serial_timesteps   | 51456        |
| time_elapsed       | 209          |
| total_timesteps    | 411648       |
| value_loss         | 0.034540467  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008052228  |
| clipfrac           | 0.10776367   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.706        |
| fps                | 2187         |
| n_updates          | 202          |
| policy_entropy     | 6.6099534    |
| policy_loss        | -0.008411056 |
| serial_timesteps   | 51712        |
| time_elapsed       | 210          |
| total_timesteps    | 413696       |
| value_loss         | 0.034961816  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007991424  |
| clipfrac           | 0.10449219   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.734        |
| fps                | 2178         |
| n_updates          | 203          |
| policy_entropy     | 6.597734     |
| policy_loss        | -0.009337304 |
| serial_timesteps   | 51968        |
| time_elapsed       | 211          |
| total_timesteps    | 415744       |
| value_loss         | 0.028152134  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0099855075 |
| clipfrac           | 0.14570312   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.789        |
| fps                | 2175         |
| n_updates          | 204          |
| policy_entropy     | 6.6038046    |
| policy_loss        | -0.012643608 |
| serial_timesteps   | 52224        |
| time_elapsed       | 212          |
| total_timesteps    | 417792       |
| value_loss         | 0.02858929   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009064958  |
| clipfrac           | 0.124853514  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.81        |
| explained_variance | 0.763        |
| fps                | 2214         |
| n_updates          | 205          |
| policy_entropy     | 6.6001487    |
| policy_loss        | -0.010940976 |
| serial_timesteps   | 52480        |
| time_elapsed       | 213          |
| total_timesteps    | 419840       |
| value_loss         | 0.024856912  |
-------------------------------------
Eval num_timesteps=420000, episode_reward=-1.15 +/- 0.03
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008634624  |
| clipfrac           | 0.119628906  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.754        |
| fps                | 1530         |
| n_updates          | 206          |
| policy_entropy     | 6.5946016    |
| policy_loss        | -0.008711972 |
| serial_timesteps   | 52736        |
| time_elapsed       | 214          |
| total_timesteps    | 421888       |
| value_loss         | 0.035291463  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010496125  |
| clipfrac           | 0.15063477   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.83        |
| explained_variance | 0.706        |
| fps                | 2178         |
| n_updates          | 207          |
| policy_entropy     | 6.5698557    |
| policy_loss        | -0.014573974 |
| serial_timesteps   | 52992        |
| time_elapsed       | 215          |
| total_timesteps    | 423936       |
| value_loss         | 0.029608231  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008945744  |
| clipfrac           | 0.12211914   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.728        |
| fps                | 2200         |
| n_updates          | 208          |
| policy_entropy     | 6.5658264    |
| policy_loss        | -0.012198688 |
| serial_timesteps   | 53248        |
| time_elapsed       | 216          |
| total_timesteps    | 425984       |
| value_loss         | 0.03551925   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008636323  |
| clipfrac           | 0.12192383   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.634        |
| fps                | 2203         |
| n_updates          | 209          |
| policy_entropy     | 6.5919404    |
| policy_loss        | -0.012105963 |
| serial_timesteps   | 53504        |
| time_elapsed       | 217          |
| total_timesteps    | 428032       |
| value_loss         | 0.050468605  |
-------------------------------------
Eval num_timesteps=430000, episode_reward=-0.97 +/- 0.09
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008775742  |
| clipfrac           | 0.12431641   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.96        |
| explained_variance | 0.639        |
| fps                | 1542         |
| n_updates          | 210          |
| policy_entropy     | 6.588418     |
| policy_loss        | -0.011749452 |
| serial_timesteps   | 53760        |
| time_elapsed       | 218          |
| total_timesteps    | 430080       |
| value_loss         | 0.036905658  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0076687904 |
| clipfrac           | 0.10541992   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.93        |
| explained_variance | 0.696        |
| fps                | 2170         |
| n_updates          | 211          |
| policy_entropy     | 6.58924      |
| policy_loss        | -0.009404672 |
| serial_timesteps   | 54016        |
| time_elapsed       | 219          |
| total_timesteps    | 432128       |
| value_loss         | 0.03942492   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009001046  |
| clipfrac           | 0.1293457    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.715        |
| fps                | 2200         |
| n_updates          | 212          |
| policy_entropy     | 6.5798173    |
| policy_loss        | -0.011521178 |
| serial_timesteps   | 54272        |
| time_elapsed       | 220          |
| total_timesteps    | 434176       |
| value_loss         | 0.031918753  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009638088  |
| clipfrac           | 0.13564453   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.748        |
| fps                | 2225         |
| n_updates          | 213          |
| policy_entropy     | 6.5658255    |
| policy_loss        | -0.014158264 |
| serial_timesteps   | 54528        |
| time_elapsed       | 221          |
| total_timesteps    | 436224       |
| value_loss         | 0.042126186  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008792138  |
| clipfrac           | 0.1227539    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.83        |
| explained_variance | 0.709        |
| fps                | 2199         |
| n_updates          | 214          |
| policy_entropy     | 6.552179     |
| policy_loss        | -0.014519649 |
| serial_timesteps   | 54784        |
| time_elapsed       | 222          |
| total_timesteps    | 438272       |
| value_loss         | 0.033078723  |
-------------------------------------
Eval num_timesteps=440000, episode_reward=-0.83 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009074875  |
| clipfrac           | 0.12919922   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.79        |
| explained_variance | 0.755        |
| fps                | 1543         |
| n_updates          | 215          |
| policy_entropy     | 6.5550013    |
| policy_loss        | -0.011466974 |
| serial_timesteps   | 55040        |
| time_elapsed       | 223          |
| total_timesteps    | 440320       |
| value_loss         | 0.034443017  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010847647  |
| clipfrac           | 0.15634766   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.79        |
| explained_variance | 0.77         |
| fps                | 2210         |
| n_updates          | 216          |
| policy_entropy     | 6.569391     |
| policy_loss        | -0.014584842 |
| serial_timesteps   | 55296        |
| time_elapsed       | 224          |
| total_timesteps    | 442368       |
| value_loss         | 0.028262397  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008677144  |
| clipfrac           | 0.122363284  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.77        |
| explained_variance | 0.74         |
| fps                | 2203         |
| n_updates          | 217          |
| policy_entropy     | 6.5627604    |
| policy_loss        | -0.011706727 |
| serial_timesteps   | 55552        |
| time_elapsed       | 225          |
| total_timesteps    | 444416       |
| value_loss         | 0.028226268  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0106108915 |
| clipfrac           | 0.14453125   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.84        |
| explained_variance | 0.687        |
| fps                | 2199         |
| n_updates          | 218          |
| policy_entropy     | 6.584793     |
| policy_loss        | -0.015766675 |
| serial_timesteps   | 55808        |
| time_elapsed       | 226          |
| total_timesteps    | 446464       |
| value_loss         | 0.04414092   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008969917  |
| clipfrac           | 0.12792969   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.82        |
| explained_variance | 0.742        |
| fps                | 2193         |
| n_updates          | 219          |
| policy_entropy     | 6.6122956    |
| policy_loss        | -0.010123573 |
| serial_timesteps   | 56064        |
| time_elapsed       | 227          |
| total_timesteps    | 448512       |
| value_loss         | 0.0293461    |
-------------------------------------
Eval num_timesteps=450000, episode_reward=-1.11 +/- 0.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010087719  |
| clipfrac           | 0.15         |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.8         |
| explained_variance | 0.797        |
| fps                | 1558         |
| n_updates          | 220          |
| policy_entropy     | 6.622103     |
| policy_loss        | -0.014048879 |
| serial_timesteps   | 56320        |
| time_elapsed       | 228          |
| total_timesteps    | 450560       |
| value_loss         | 0.030662235  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008820817  |
| clipfrac           | 0.12319336   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.83        |
| explained_variance | 0.716        |
| fps                | 2213         |
| n_updates          | 221          |
| policy_entropy     | 6.6401505    |
| policy_loss        | -0.012931553 |
| serial_timesteps   | 56576        |
| time_elapsed       | 229          |
| total_timesteps    | 452608       |
| value_loss         | 0.034650806  |
-------------------------------------
------------------------------------
| approxkl           | 0.010152361 |
| clipfrac           | 0.15063477  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.85       |
| explained_variance | 0.794       |
| fps                | 2187        |
| n_updates          | 222         |
| policy_entropy     | 6.636924    |
| policy_loss        | -0.01490487 |
| serial_timesteps   | 56832       |
| time_elapsed       | 230         |
| total_timesteps    | 454656      |
| value_loss         | 0.029386768 |
------------------------------------
-------------------------------------
| approxkl           | 0.0094442805 |
| clipfrac           | 0.13637695   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.84        |
| explained_variance | 0.6          |
| fps                | 2199         |
| n_updates          | 223          |
| policy_entropy     | 6.626606     |
| policy_loss        | -0.014119226 |
| serial_timesteps   | 57088        |
| time_elapsed       | 231          |
| total_timesteps    | 456704       |
| value_loss         | 0.04022549   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010571333  |
| clipfrac           | 0.159375     |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.799        |
| fps                | 2233         |
| n_updates          | 224          |
| policy_entropy     | 6.6222887    |
| policy_loss        | -0.015479254 |
| serial_timesteps   | 57344        |
| time_elapsed       | 232          |
| total_timesteps    | 458752       |
| value_loss         | 0.028718129  |
-------------------------------------
Eval num_timesteps=460000, episode_reward=-1.19 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010016417  |
| clipfrac           | 0.13681641   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.653        |
| fps                | 1569         |
| n_updates          | 225          |
| policy_entropy     | 6.5868025    |
| policy_loss        | -0.013513369 |
| serial_timesteps   | 57600        |
| time_elapsed       | 233          |
| total_timesteps    | 460800       |
| value_loss         | 0.04245185   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008908896  |
| clipfrac           | 0.12871094   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.83        |
| explained_variance | 0.664        |
| fps                | 2175         |
| n_updates          | 226          |
| policy_entropy     | 6.5561457    |
| policy_loss        | -0.013003515 |
| serial_timesteps   | 57856        |
| time_elapsed       | 235          |
| total_timesteps    | 462848       |
| value_loss         | 0.035626538  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009102379  |
| clipfrac           | 0.13354492   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.648        |
| fps                | 2189         |
| n_updates          | 227          |
| policy_entropy     | 6.554422     |
| policy_loss        | -0.013134073 |
| serial_timesteps   | 58112        |
| time_elapsed       | 235          |
| total_timesteps    | 464896       |
| value_loss         | 0.053271808  |
-------------------------------------
------------------------------------
| approxkl           | 0.01063451  |
| clipfrac           | 0.15058593  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.89       |
| explained_variance | 0.599       |
| fps                | 2214        |
| n_updates          | 228         |
| policy_entropy     | 6.5457373   |
| policy_loss        | -0.01293706 |
| serial_timesteps   | 58368       |
| time_elapsed       | 236         |
| total_timesteps    | 466944      |
| value_loss         | 0.044121627 |
------------------------------------
-------------------------------------
| approxkl           | 0.010731959  |
| clipfrac           | 0.15703125   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.804        |
| fps                | 2117         |
| n_updates          | 229          |
| policy_entropy     | 6.507776     |
| policy_loss        | -0.015886527 |
| serial_timesteps   | 58624        |
| time_elapsed       | 237          |
| total_timesteps    | 468992       |
| value_loss         | 0.02755641   |
-------------------------------------
Eval num_timesteps=470000, episode_reward=-1.02 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.008349772   |
| clipfrac           | 0.11289062    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.87         |
| explained_variance | 0.686         |
| fps                | 1550          |
| n_updates          | 230           |
| policy_entropy     | 6.470201      |
| policy_loss        | -0.0102926325 |
| serial_timesteps   | 58880         |
| time_elapsed       | 238           |
| total_timesteps    | 471040        |
| value_loss         | 0.03680626    |
--------------------------------------
-------------------------------------
| approxkl           | 0.010304471  |
| clipfrac           | 0.15122071   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.83        |
| explained_variance | 0.777        |
| fps                | 2182         |
| n_updates          | 231          |
| policy_entropy     | 6.4606614    |
| policy_loss        | -0.017110944 |
| serial_timesteps   | 59136        |
| time_elapsed       | 240          |
| total_timesteps    | 473088       |
| value_loss         | 0.03434388   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008384696  |
| clipfrac           | 0.1171875    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.79        |
| explained_variance | 0.745        |
| fps                | 2187         |
| n_updates          | 232          |
| policy_entropy     | 6.457263     |
| policy_loss        | -0.010407521 |
| serial_timesteps   | 59392        |
| time_elapsed       | 241          |
| total_timesteps    | 475136       |
| value_loss         | 0.03780114   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008295374  |
| clipfrac           | 0.1140625    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.75        |
| explained_variance | 0.737        |
| fps                | 2190         |
| n_updates          | 233          |
| policy_entropy     | 6.445768     |
| policy_loss        | -0.009071789 |
| serial_timesteps   | 59648        |
| time_elapsed       | 241          |
| total_timesteps    | 477184       |
| value_loss         | 0.035028037  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0098228315 |
| clipfrac           | 0.14033203   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.79        |
| explained_variance | 0.711        |
| fps                | 2169         |
| n_updates          | 234          |
| policy_entropy     | 6.427015     |
| policy_loss        | -0.014533708 |
| serial_timesteps   | 59904        |
| time_elapsed       | 242          |
| total_timesteps    | 479232       |
| value_loss         | 0.038307037  |
-------------------------------------
Eval num_timesteps=480000, episode_reward=-1.05 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008383663  |
| clipfrac           | 0.111328125  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.77        |
| explained_variance | 0.742        |
| fps                | 1567         |
| n_updates          | 235          |
| policy_entropy     | 6.43097      |
| policy_loss        | -0.009922669 |
| serial_timesteps   | 60160        |
| time_elapsed       | 243          |
| total_timesteps    | 481280       |
| value_loss         | 0.032978885  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010695405  |
| clipfrac           | 0.16206054   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.83        |
| explained_variance | 0.727        |
| fps                | 2230         |
| n_updates          | 236          |
| policy_entropy     | 6.441068     |
| policy_loss        | -0.017458389 |
| serial_timesteps   | 60416        |
| time_elapsed       | 245          |
| total_timesteps    | 483328       |
| value_loss         | 0.043213468  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009497303  |
| clipfrac           | 0.13398437   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.758        |
| fps                | 2188         |
| n_updates          | 237          |
| policy_entropy     | 6.419698     |
| policy_loss        | -0.012525341 |
| serial_timesteps   | 60672        |
| time_elapsed       | 246          |
| total_timesteps    | 485376       |
| value_loss         | 0.02940258   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010532258  |
| clipfrac           | 0.15395507   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.768        |
| fps                | 2196         |
| n_updates          | 238          |
| policy_entropy     | 6.4055276    |
| policy_loss        | -0.016901055 |
| serial_timesteps   | 60928        |
| time_elapsed       | 247          |
| total_timesteps    | 487424       |
| value_loss         | 0.03712293   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00988028   |
| clipfrac           | 0.14091797   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.718        |
| fps                | 2186         |
| n_updates          | 239          |
| policy_entropy     | 6.394168     |
| policy_loss        | -0.012883423 |
| serial_timesteps   | 61184        |
| time_elapsed       | 247          |
| total_timesteps    | 489472       |
| value_loss         | 0.040349815  |
-------------------------------------
Eval num_timesteps=490000, episode_reward=-1.02 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008650488  |
| clipfrac           | 0.1206543    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.93        |
| explained_variance | 0.832        |
| fps                | 1528         |
| n_updates          | 240          |
| policy_entropy     | 6.374425     |
| policy_loss        | -0.009754771 |
| serial_timesteps   | 61440        |
| time_elapsed       | 248          |
| total_timesteps    | 491520       |
| value_loss         | 0.027761975  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009594301  |
| clipfrac           | 0.13623047   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.716        |
| fps                | 2200         |
| n_updates          | 241          |
| policy_entropy     | 6.336328     |
| policy_loss        | -0.012083417 |
| serial_timesteps   | 61696        |
| time_elapsed       | 250          |
| total_timesteps    | 493568       |
| value_loss         | 0.0363923    |
-------------------------------------
-------------------------------------
| approxkl           | 0.009255504  |
| clipfrac           | 0.12871094   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.802        |
| fps                | 2163         |
| n_updates          | 242          |
| policy_entropy     | 6.302321     |
| policy_loss        | -0.009596452 |
| serial_timesteps   | 61952        |
| time_elapsed       | 251          |
| total_timesteps    | 495616       |
| value_loss         | 0.02893208   |
-------------------------------------
-------------------------------------
| approxkl           | 0.012094672  |
| clipfrac           | 0.18242188   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.81        |
| explained_variance | 0.8          |
| fps                | 2223         |
| n_updates          | 243          |
| policy_entropy     | 6.2746353    |
| policy_loss        | -0.015543851 |
| serial_timesteps   | 62208        |
| time_elapsed       | 252          |
| total_timesteps    | 497664       |
| value_loss         | 0.027824149  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00927439   |
| clipfrac           | 0.1352539    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.8         |
| explained_variance | 0.769        |
| fps                | 2235         |
| n_updates          | 244          |
| policy_entropy     | 6.229995     |
| policy_loss        | -0.013472801 |
| serial_timesteps   | 62464        |
| time_elapsed       | 253          |
| total_timesteps    | 499712       |
| value_loss         | 0.025537962  |
-------------------------------------
Saving to logs/train_0.5M_widowx_reacher-v5_KAY/ppo2/widowx_reacher-v5_2
pybullet build time: May 18 2020 02:46:26
