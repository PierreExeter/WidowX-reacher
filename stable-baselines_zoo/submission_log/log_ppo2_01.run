--------------------------------------------------------------------------
WARNING: There was an error initializing an OpenFabrics device.

  Local host:   n295
  Local device: hfi1_0
--------------------------------------------------------------------------
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

========== widowx_reacher-v7 ==========
Seed: 1
OrderedDict([('cliprange', 0.2),
             ('ent_coef', 0.0),
             ('gamma', 0.99),
             ('lam', 0.95),
             ('learning_rate', 0.00025),
             ('n_envs', 8),
             ('n_steps', 256),
             ('n_timesteps', 1000000.0),
             ('nminibatches', 32),
             ('noptepochs', 10),
             ('normalize', True),
             ('policy', 'MlpPolicy')])
Using 8 environments
Overwriting n_timesteps with n=500000
Normalizing input and reward
Creating test environment
TRAINING ENV TYPE :  <stable_baselines.common.vec_env.vec_normalize.VecNormalize object at 0x7fef431a6588>
Normalization activated: {'norm_reward': False}
EVAL ENV TYPE :  <stable_baselines.common.vec_env.vec_normalize.VecNormalize object at 0x7fef40b19668>
Log path: logs/train_0.5M_widowx_reacher-v7_KAY/ppo2/widowx_reacher-v7_2
-------------------------------------
| approxkl           | 0.0071878606 |
| clipfrac           | 0.09418945   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.35        |
| explained_variance | -0.102       |
| fps                | 1514         |
| n_updates          | 1            |
| policy_entropy     | 8.505735     |
| policy_loss        | -0.012294281 |
| serial_timesteps   | 256          |
| time_elapsed       | 2.62e-05     |
| total_timesteps    | 2048         |
| value_loss         | 0.5611867    |
-------------------------------------
-------------------------------------
| approxkl           | 0.005591267  |
| clipfrac           | 0.07138672   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.69        |
| explained_variance | 0.0307       |
| fps                | 2021         |
| n_updates          | 2            |
| policy_entropy     | 8.491748     |
| policy_loss        | -0.011532059 |
| serial_timesteps   | 512          |
| time_elapsed       | 1.35         |
| total_timesteps    | 4096         |
| value_loss         | 0.15019147   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007911532  |
| clipfrac           | 0.10795899   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.66        |
| explained_variance | 0.284        |
| fps                | 2045         |
| n_updates          | 3            |
| policy_entropy     | 8.486055     |
| policy_loss        | -0.014057288 |
| serial_timesteps   | 768          |
| time_elapsed       | 2.37         |
| total_timesteps    | 6144         |
| value_loss         | 0.083173595  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0065756133 |
| clipfrac           | 0.08408203   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.7         |
| explained_variance | 0.347        |
| fps                | 2213         |
| n_updates          | 4            |
| policy_entropy     | 8.491086     |
| policy_loss        | -0.012509277 |
| serial_timesteps   | 1024         |
| time_elapsed       | 3.37         |
| total_timesteps    | 8192         |
| value_loss         | 0.07446943   |
-------------------------------------
Eval num_timesteps=10000, episode_reward=-2.12 +/- 0.59
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.008184437  |
| clipfrac           | 0.11469726   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.424        |
| fps                | 1453         |
| n_updates          | 5            |
| policy_entropy     | 8.479212     |
| policy_loss        | -0.013728024 |
| serial_timesteps   | 1280         |
| time_elapsed       | 4.29         |
| total_timesteps    | 10240        |
| value_loss         | 0.048639216  |
-------------------------------------
------------------------------------
| approxkl           | 0.006653332 |
| clipfrac           | 0.08671875  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.72       |
| explained_variance | 0.414       |
| fps                | 2071        |
| n_updates          | 6           |
| policy_entropy     | 8.4663      |
| policy_loss        | -0.01231681 |
| serial_timesteps   | 1536        |
| time_elapsed       | 5.7         |
| total_timesteps    | 12288       |
| value_loss         | 0.081138566 |
------------------------------------
-------------------------------------
| approxkl           | 0.0069265803 |
| clipfrac           | 0.09194336   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.67        |
| explained_variance | 0.587        |
| fps                | 2085         |
| n_updates          | 7            |
| policy_entropy     | 8.481793     |
| policy_loss        | -0.010700714 |
| serial_timesteps   | 1792         |
| time_elapsed       | 6.69         |
| total_timesteps    | 14336        |
| value_loss         | 0.050619382  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0068776244 |
| clipfrac           | 0.091113284  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.74        |
| explained_variance | 0.492        |
| fps                | 2094         |
| n_updates          | 8            |
| policy_entropy     | 8.513761     |
| policy_loss        | -0.011223669 |
| serial_timesteps   | 2048         |
| time_elapsed       | 7.67         |
| total_timesteps    | 16384        |
| value_loss         | 0.0670473    |
-------------------------------------
-------------------------------------
| approxkl           | 0.005155605  |
| clipfrac           | 0.06318359   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.79        |
| explained_variance | 0.426        |
| fps                | 2121         |
| n_updates          | 9            |
| policy_entropy     | 8.5198       |
| policy_loss        | -0.007211987 |
| serial_timesteps   | 2304         |
| time_elapsed       | 8.65         |
| total_timesteps    | 18432        |
| value_loss         | 0.05822734   |
-------------------------------------
Eval num_timesteps=20000, episode_reward=-2.17 +/- 0.79
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0081290975 |
| clipfrac           | 0.11098633   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.77        |
| explained_variance | 0.699        |
| fps                | 1506         |
| n_updates          | 10           |
| policy_entropy     | 8.477359     |
| policy_loss        | -0.014966829 |
| serial_timesteps   | 2560         |
| time_elapsed       | 9.62         |
| total_timesteps    | 20480        |
| value_loss         | 0.023840861  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0071161003 |
| clipfrac           | 0.09243164   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.7         |
| explained_variance | 0.36         |
| fps                | 2158         |
| n_updates          | 11           |
| policy_entropy     | 8.451433     |
| policy_loss        | -0.013476336 |
| serial_timesteps   | 2816         |
| time_elapsed       | 11           |
| total_timesteps    | 22528        |
| value_loss         | 0.07849624   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00792993   |
| clipfrac           | 0.10893555   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.7         |
| explained_variance | 0.694        |
| fps                | 2185         |
| n_updates          | 12           |
| policy_entropy     | 8.432823     |
| policy_loss        | -0.013326168 |
| serial_timesteps   | 3072         |
| time_elapsed       | 11.9         |
| total_timesteps    | 24576        |
| value_loss         | 0.02977395   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0071206028 |
| clipfrac           | 0.09794922   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.66        |
| explained_variance | 0.555        |
| fps                | 2183         |
| n_updates          | 13           |
| policy_entropy     | 8.402502     |
| policy_loss        | -0.013107695 |
| serial_timesteps   | 3328         |
| time_elapsed       | 12.9         |
| total_timesteps    | 26624        |
| value_loss         | 0.06316877   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0072792387 |
| clipfrac           | 0.0987793    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.574        |
| fps                | 2171         |
| n_updates          | 14           |
| policy_entropy     | 8.383859     |
| policy_loss        | -0.009860018 |
| serial_timesteps   | 3584         |
| time_elapsed       | 13.8         |
| total_timesteps    | 28672        |
| value_loss         | 0.037640847  |
-------------------------------------
Eval num_timesteps=30000, episode_reward=-1.96 +/- 0.82
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.008498478  |
| clipfrac           | 0.11186524   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.774        |
| fps                | 1525         |
| n_updates          | 15           |
| policy_entropy     | 8.372251     |
| policy_loss        | -0.013385397 |
| serial_timesteps   | 3840         |
| time_elapsed       | 14.7         |
| total_timesteps    | 30720        |
| value_loss         | 0.02514596   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007787592  |
| clipfrac           | 0.10219727   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.553        |
| fps                | 2147         |
| n_updates          | 16           |
| policy_entropy     | 8.343309     |
| policy_loss        | -0.011245074 |
| serial_timesteps   | 4096         |
| time_elapsed       | 16.1         |
| total_timesteps    | 32768        |
| value_loss         | 0.044853475  |
-------------------------------------
--------------------------------------
| approxkl           | 0.006633503   |
| clipfrac           | 0.083300784   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.62         |
| explained_variance | 0.466         |
| fps                | 2183          |
| n_updates          | 17            |
| policy_entropy     | 8.316565      |
| policy_loss        | -0.0103287725 |
| serial_timesteps   | 4352          |
| time_elapsed       | 17            |
| total_timesteps    | 34816         |
| value_loss         | 0.071754344   |
--------------------------------------
-------------------------------------
| approxkl           | 0.006991645  |
| clipfrac           | 0.091748044  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.629        |
| fps                | 2108         |
| n_updates          | 18           |
| policy_entropy     | 8.30363      |
| policy_loss        | -0.010617804 |
| serial_timesteps   | 4608         |
| time_elapsed       | 18           |
| total_timesteps    | 36864        |
| value_loss         | 0.04454649   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007184041  |
| clipfrac           | 0.09633789   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.458        |
| fps                | 2142         |
| n_updates          | 19           |
| policy_entropy     | 8.315833     |
| policy_loss        | -0.013197106 |
| serial_timesteps   | 4864         |
| time_elapsed       | 19           |
| total_timesteps    | 38912        |
| value_loss         | 0.052232563  |
-------------------------------------
Eval num_timesteps=40000, episode_reward=-1.92 +/- 1.53
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.006622635  |
| clipfrac           | 0.08701172   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.68        |
| explained_variance | 0.718        |
| fps                | 1512         |
| n_updates          | 20           |
| policy_entropy     | 8.339899     |
| policy_loss        | -0.009789627 |
| serial_timesteps   | 5120         |
| time_elapsed       | 19.9         |
| total_timesteps    | 40960        |
| value_loss         | 0.033974536  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0058337227 |
| clipfrac           | 0.06894531   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.67        |
| explained_variance | 0.669        |
| fps                | 2080         |
| n_updates          | 21           |
| policy_entropy     | 8.330844     |
| policy_loss        | -0.00925985  |
| serial_timesteps   | 5376         |
| time_elapsed       | 21.3         |
| total_timesteps    | 43008        |
| value_loss         | 0.04976314   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008792324  |
| clipfrac           | 0.12270508   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | 0.735        |
| fps                | 2049         |
| n_updates          | 22           |
| policy_entropy     | 8.320247     |
| policy_loss        | -0.013118391 |
| serial_timesteps   | 5632         |
| time_elapsed       | 22.2         |
| total_timesteps    | 45056        |
| value_loss         | 0.02570098   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007025403  |
| clipfrac           | 0.093164064  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.665        |
| fps                | 2085         |
| n_updates          | 23           |
| policy_entropy     | 8.31517      |
| policy_loss        | -0.009548681 |
| serial_timesteps   | 5888         |
| time_elapsed       | 23.2         |
| total_timesteps    | 47104        |
| value_loss         | 0.03928121   |
-------------------------------------
------------------------------------
| approxkl           | 0.007871882 |
| clipfrac           | 0.101464845 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.48       |
| explained_variance | 0.671       |
| fps                | 2075        |
| n_updates          | 24          |
| policy_entropy     | 8.281662    |
| policy_loss        | -0.01138767 |
| serial_timesteps   | 6144        |
| time_elapsed       | 24.2        |
| total_timesteps    | 49152       |
| value_loss         | 0.030998562 |
------------------------------------
Eval num_timesteps=50000, episode_reward=-1.56 +/- 0.82
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.008678375  |
| clipfrac           | 0.11489258   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.644        |
| fps                | 1485         |
| n_updates          | 25           |
| policy_entropy     | 8.230571     |
| policy_loss        | -0.014086848 |
| serial_timesteps   | 6400         |
| time_elapsed       | 25.2         |
| total_timesteps    | 51200        |
| value_loss         | 0.042808153  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008561237  |
| clipfrac           | 0.11210938   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.584        |
| fps                | 2084         |
| n_updates          | 26           |
| policy_entropy     | 8.225889     |
| policy_loss        | -0.014876222 |
| serial_timesteps   | 6656         |
| time_elapsed       | 26.6         |
| total_timesteps    | 53248        |
| value_loss         | 0.049110938  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008171944  |
| clipfrac           | 0.11416016   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.635        |
| fps                | 2059         |
| n_updates          | 27           |
| policy_entropy     | 8.220186     |
| policy_loss        | -0.013799353 |
| serial_timesteps   | 6912         |
| time_elapsed       | 27.6         |
| total_timesteps    | 55296        |
| value_loss         | 0.0522378    |
-------------------------------------
--------------------------------------
| approxkl           | 0.007795798   |
| clipfrac           | 0.108105466   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.52         |
| explained_variance | 0.714         |
| fps                | 2095          |
| n_updates          | 28            |
| policy_entropy     | 8.20467       |
| policy_loss        | -0.0124558015 |
| serial_timesteps   | 7168          |
| time_elapsed       | 28.6          |
| total_timesteps    | 57344         |
| value_loss         | 0.039365996   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008481312  |
| clipfrac           | 0.117089845  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.755        |
| fps                | 2096         |
| n_updates          | 29           |
| policy_entropy     | 8.18276      |
| policy_loss        | -0.012729308 |
| serial_timesteps   | 7424         |
| time_elapsed       | 29.5         |
| total_timesteps    | 59392        |
| value_loss         | 0.034191396  |
-------------------------------------
Eval num_timesteps=60000, episode_reward=-2.56 +/- 1.30
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008814055  |
| clipfrac           | 0.12646484   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.67        |
| explained_variance | 0.703        |
| fps                | 1499         |
| n_updates          | 30           |
| policy_entropy     | 8.176451     |
| policy_loss        | -0.013012491 |
| serial_timesteps   | 7680         |
| time_elapsed       | 30.5         |
| total_timesteps    | 61440        |
| value_loss         | 0.043481298  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00925546   |
| clipfrac           | 0.12973633   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.779        |
| fps                | 2095         |
| n_updates          | 31           |
| policy_entropy     | 8.170316     |
| policy_loss        | -0.014238773 |
| serial_timesteps   | 7936         |
| time_elapsed       | 31.9         |
| total_timesteps    | 63488        |
| value_loss         | 0.025876144  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008962118  |
| clipfrac           | 0.124902345  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.64         |
| fps                | 2094         |
| n_updates          | 32           |
| policy_entropy     | 8.160692     |
| policy_loss        | -0.013394037 |
| serial_timesteps   | 8192         |
| time_elapsed       | 32.9         |
| total_timesteps    | 65536        |
| value_loss         | 0.059507817  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00887847   |
| clipfrac           | 0.12016602   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.679        |
| fps                | 2042         |
| n_updates          | 33           |
| policy_entropy     | 8.1370325    |
| policy_loss        | -0.012041835 |
| serial_timesteps   | 8448         |
| time_elapsed       | 33.8         |
| total_timesteps    | 67584        |
| value_loss         | 0.036396407  |
-------------------------------------
-------------------------------------
| approxkl           | 0.005964754  |
| clipfrac           | 0.07050781   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.78        |
| explained_variance | 0.547        |
| fps                | 2104         |
| n_updates          | 34           |
| policy_entropy     | 8.118741     |
| policy_loss        | -0.006886897 |
| serial_timesteps   | 8704         |
| time_elapsed       | 34.9         |
| total_timesteps    | 69632        |
| value_loss         | 0.07697521   |
-------------------------------------
Eval num_timesteps=70000, episode_reward=-2.06 +/- 0.42
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.00747218   |
| clipfrac           | 0.09794922   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.7         |
| explained_variance | 0.71         |
| fps                | 1504         |
| n_updates          | 35           |
| policy_entropy     | 8.100212     |
| policy_loss        | -0.011541688 |
| serial_timesteps   | 8960         |
| time_elapsed       | 35.8         |
| total_timesteps    | 71680        |
| value_loss         | 0.037824795  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007869987  |
| clipfrac           | 0.10595703   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.74        |
| explained_variance | 0.714        |
| fps                | 2076         |
| n_updates          | 36           |
| policy_entropy     | 8.077554     |
| policy_loss        | -0.010875479 |
| serial_timesteps   | 9216         |
| time_elapsed       | 37.2         |
| total_timesteps    | 73728        |
| value_loss         | 0.03419507   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009022297  |
| clipfrac           | 0.1222168    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.69        |
| explained_variance | 0.728        |
| fps                | 2086         |
| n_updates          | 37           |
| policy_entropy     | 8.045652     |
| policy_loss        | -0.013351327 |
| serial_timesteps   | 9472         |
| time_elapsed       | 38.2         |
| total_timesteps    | 75776        |
| value_loss         | 0.033047326  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008032292   |
| clipfrac           | 0.10942383    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.7          |
| explained_variance | 0.603         |
| fps                | 2100          |
| n_updates          | 38            |
| policy_entropy     | 8.027712      |
| policy_loss        | -0.0119210575 |
| serial_timesteps   | 9728          |
| time_elapsed       | 39.2          |
| total_timesteps    | 77824         |
| value_loss         | 0.048004113   |
--------------------------------------
-------------------------------------
| approxkl           | 0.007129729  |
| clipfrac           | 0.09458008   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.495        |
| fps                | 2125         |
| n_updates          | 39           |
| policy_entropy     | 8.025349     |
| policy_loss        | -0.010457946 |
| serial_timesteps   | 9984         |
| time_elapsed       | 40.1         |
| total_timesteps    | 79872        |
| value_loss         | 0.05870942   |
-------------------------------------
Eval num_timesteps=80000, episode_reward=-1.77 +/- 0.77
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.00679968    |
| clipfrac           | 0.08828125    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.69         |
| explained_variance | 0.605         |
| fps                | 1406          |
| n_updates          | 40            |
| policy_entropy     | 8.01988       |
| policy_loss        | -0.0103671225 |
| serial_timesteps   | 10240         |
| time_elapsed       | 41.1          |
| total_timesteps    | 81920         |
| value_loss         | 0.06732093    |
--------------------------------------
-------------------------------------
| approxkl           | 0.008210445  |
| clipfrac           | 0.11240234   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.74        |
| explained_variance | 0.637        |
| fps                | 2088         |
| n_updates          | 41           |
| policy_entropy     | 8.01243      |
| policy_loss        | -0.011683805 |
| serial_timesteps   | 10496        |
| time_elapsed       | 42.6         |
| total_timesteps    | 83968        |
| value_loss         | 0.058981933  |
-------------------------------------
------------------------------------
| approxkl           | 0.009270498 |
| clipfrac           | 0.12763672  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.85       |
| explained_variance | 0.618       |
| fps                | 2122        |
| n_updates          | 42          |
| policy_entropy     | 8.002853    |
| policy_loss        | -0.01500833 |
| serial_timesteps   | 10752       |
| time_elapsed       | 43.5        |
| total_timesteps    | 86016       |
| value_loss         | 0.06724569  |
------------------------------------
-------------------------------------
| approxkl           | 0.007918043  |
| clipfrac           | 0.10854492   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.668        |
| fps                | 2063         |
| n_updates          | 43           |
| policy_entropy     | 7.9694147    |
| policy_loss        | -0.012231102 |
| serial_timesteps   | 11008        |
| time_elapsed       | 44.5         |
| total_timesteps    | 88064        |
| value_loss         | 0.054397248  |
-------------------------------------
Eval num_timesteps=90000, episode_reward=-1.48 +/- 0.35
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.0076140864 |
| clipfrac           | 0.09643555   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.574        |
| fps                | 1482         |
| n_updates          | 44           |
| policy_entropy     | 7.9232836    |
| policy_loss        | -0.01386744  |
| serial_timesteps   | 11264        |
| time_elapsed       | 45.5         |
| total_timesteps    | 90112        |
| value_loss         | 0.04552216   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008947395  |
| clipfrac           | 0.12270508   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.8         |
| explained_variance | 0.667        |
| fps                | 2151         |
| n_updates          | 45           |
| policy_entropy     | 7.897991     |
| policy_loss        | -0.016577145 |
| serial_timesteps   | 11520        |
| time_elapsed       | 46.9         |
| total_timesteps    | 92160        |
| value_loss         | 0.052577566  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008521469  |
| clipfrac           | 0.12470703   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.92        |
| explained_variance | 0.721        |
| fps                | 2124         |
| n_updates          | 46           |
| policy_entropy     | 7.9025335    |
| policy_loss        | -0.014265092 |
| serial_timesteps   | 11776        |
| time_elapsed       | 47.8         |
| total_timesteps    | 94208        |
| value_loss         | 0.05181213   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0088513065 |
| clipfrac           | 0.12358399   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.77        |
| explained_variance | 0.804        |
| fps                | 2081         |
| n_updates          | 47           |
| policy_entropy     | 7.8728256    |
| policy_loss        | -0.015476873 |
| serial_timesteps   | 12032        |
| time_elapsed       | 48.8         |
| total_timesteps    | 96256        |
| value_loss         | 0.03182424   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009599103  |
| clipfrac           | 0.13549805   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.68        |
| explained_variance | 0.805        |
| fps                | 2106         |
| n_updates          | 48           |
| policy_entropy     | 7.8434343    |
| policy_loss        | -0.014078787 |
| serial_timesteps   | 12288        |
| time_elapsed       | 49.8         |
| total_timesteps    | 98304        |
| value_loss         | 0.022410255  |
-------------------------------------
Eval num_timesteps=100000, episode_reward=-2.82 +/- 1.21
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.00831362   |
| clipfrac           | 0.11357422   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.647        |
| fps                | 1471         |
| n_updates          | 49           |
| policy_entropy     | 7.826182     |
| policy_loss        | -0.012118651 |
| serial_timesteps   | 12544        |
| time_elapsed       | 50.7         |
| total_timesteps    | 100352       |
| value_loss         | 0.040664665  |
-------------------------------------
------------------------------------
| approxkl           | 0.007941486 |
| clipfrac           | 0.10668945  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.69       |
| explained_variance | 0.657       |
| fps                | 2153        |
| n_updates          | 50          |
| policy_entropy     | 7.827269    |
| policy_loss        | -0.01289616 |
| serial_timesteps   | 12800       |
| time_elapsed       | 52.1        |
| total_timesteps    | 102400      |
| value_loss         | 0.052144796 |
------------------------------------
-------------------------------------
| approxkl           | 0.009283389  |
| clipfrac           | 0.13154297   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.667        |
| fps                | 2138         |
| n_updates          | 51           |
| policy_entropy     | 7.8426147    |
| policy_loss        | -0.014843744 |
| serial_timesteps   | 13056        |
| time_elapsed       | 53.1         |
| total_timesteps    | 104448       |
| value_loss         | 0.04138549   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0087770065 |
| clipfrac           | 0.12529297   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.742        |
| fps                | 2099         |
| n_updates          | 52           |
| policy_entropy     | 7.8281336    |
| policy_loss        | -0.012635524 |
| serial_timesteps   | 13312        |
| time_elapsed       | 54           |
| total_timesteps    | 106496       |
| value_loss         | 0.03914858   |
-------------------------------------
------------------------------------
| approxkl           | 0.009698306 |
| clipfrac           | 0.14545898  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.53       |
| explained_variance | 0.635       |
| fps                | 2135        |
| n_updates          | 53          |
| policy_entropy     | 7.809645    |
| policy_loss        | -0.0125755  |
| serial_timesteps   | 13568       |
| time_elapsed       | 55          |
| total_timesteps    | 108544      |
| value_loss         | 0.03192713  |
------------------------------------
Eval num_timesteps=110000, episode_reward=-2.36 +/- 1.31
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008363422  |
| clipfrac           | 0.11538086   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.745        |
| fps                | 1510         |
| n_updates          | 54           |
| policy_entropy     | 7.7853913    |
| policy_loss        | -0.010610303 |
| serial_timesteps   | 13824        |
| time_elapsed       | 56           |
| total_timesteps    | 110592       |
| value_loss         | 0.034454964  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007911898  |
| clipfrac           | 0.107470706  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.685        |
| fps                | 2146         |
| n_updates          | 55           |
| policy_entropy     | 7.7516527    |
| policy_loss        | -0.008061436 |
| serial_timesteps   | 14080        |
| time_elapsed       | 57.3         |
| total_timesteps    | 112640       |
| value_loss         | 0.037431665  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007950276  |
| clipfrac           | 0.109472655  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.701        |
| fps                | 2097         |
| n_updates          | 56           |
| policy_entropy     | 7.7296433    |
| policy_loss        | -0.009690522 |
| serial_timesteps   | 14336        |
| time_elapsed       | 58.3         |
| total_timesteps    | 114688       |
| value_loss         | 0.043839596  |
-------------------------------------
--------------------------------------
| approxkl           | 0.006957832   |
| clipfrac           | 0.0902832     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.48         |
| explained_variance | 0.617         |
| fps                | 2121          |
| n_updates          | 57            |
| policy_entropy     | 7.747823      |
| policy_loss        | -0.0069208904 |
| serial_timesteps   | 14592         |
| time_elapsed       | 59.3          |
| total_timesteps    | 116736        |
| value_loss         | 0.040178742   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0076928535 |
| clipfrac           | 0.101904295  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.612        |
| fps                | 2104         |
| n_updates          | 58           |
| policy_entropy     | 7.746606     |
| policy_loss        | -0.009743387 |
| serial_timesteps   | 14848        |
| time_elapsed       | 60.2         |
| total_timesteps    | 118784       |
| value_loss         | 0.048093032  |
-------------------------------------
Eval num_timesteps=120000, episode_reward=-2.24 +/- 1.53
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009828007  |
| clipfrac           | 0.14155273   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.691        |
| fps                | 1532         |
| n_updates          | 59           |
| policy_entropy     | 7.7123895    |
| policy_loss        | -0.014098799 |
| serial_timesteps   | 15104        |
| time_elapsed       | 61.2         |
| total_timesteps    | 120832       |
| value_loss         | 0.034673844  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0071234824 |
| clipfrac           | 0.08920898   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.637        |
| fps                | 2157         |
| n_updates          | 60           |
| policy_entropy     | 7.6765647    |
| policy_loss        | -0.011371771 |
| serial_timesteps   | 15360        |
| time_elapsed       | 62.5         |
| total_timesteps    | 122880       |
| value_loss         | 0.04292699   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007871154  |
| clipfrac           | 0.10048828   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.637        |
| fps                | 2127         |
| n_updates          | 61           |
| policy_entropy     | 7.6937613    |
| policy_loss        | -0.013159191 |
| serial_timesteps   | 15616        |
| time_elapsed       | 63.5         |
| total_timesteps    | 124928       |
| value_loss         | 0.042523034  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0062524914  |
| clipfrac           | 0.07978515    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.56         |
| explained_variance | 0.709         |
| fps                | 2157          |
| n_updates          | 62            |
| policy_entropy     | 7.7189255     |
| policy_loss        | -0.0072242273 |
| serial_timesteps   | 15872         |
| time_elapsed       | 64.5          |
| total_timesteps    | 126976        |
| value_loss         | 0.03808313    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0065781316 |
| clipfrac           | 0.08276367   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.596        |
| fps                | 2130         |
| n_updates          | 63           |
| policy_entropy     | 7.71383      |
| policy_loss        | -0.011392656 |
| serial_timesteps   | 16128        |
| time_elapsed       | 65.4         |
| total_timesteps    | 129024       |
| value_loss         | 0.04882302   |
-------------------------------------
Eval num_timesteps=130000, episode_reward=-1.58 +/- 0.52
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.00798449   |
| clipfrac           | 0.10615234   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.671        |
| fps                | 1507         |
| n_updates          | 64           |
| policy_entropy     | 7.6877265    |
| policy_loss        | -0.011627777 |
| serial_timesteps   | 16384        |
| time_elapsed       | 66.4         |
| total_timesteps    | 131072       |
| value_loss         | 0.039013557  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0063592247 |
| clipfrac           | 0.07924805   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.735        |
| fps                | 2117         |
| n_updates          | 65           |
| policy_entropy     | 7.6556196    |
| policy_loss        | -0.00750942  |
| serial_timesteps   | 16640        |
| time_elapsed       | 67.7         |
| total_timesteps    | 133120       |
| value_loss         | 0.03152167   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007675781  |
| clipfrac           | 0.099365234  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.589        |
| fps                | 2115         |
| n_updates          | 66           |
| policy_entropy     | 7.644534     |
| policy_loss        | -0.010674585 |
| serial_timesteps   | 16896        |
| time_elapsed       | 68.7         |
| total_timesteps    | 135168       |
| value_loss         | 0.054558318  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008307391  |
| clipfrac           | 0.11464844   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.741        |
| fps                | 2069         |
| n_updates          | 67           |
| policy_entropy     | 7.6358147    |
| policy_loss        | -0.010679776 |
| serial_timesteps   | 17152        |
| time_elapsed       | 69.7         |
| total_timesteps    | 137216       |
| value_loss         | 0.041965682  |
-------------------------------------
-------------------------------------
| approxkl           | 0.006693603  |
| clipfrac           | 0.08540039   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.741        |
| fps                | 2171         |
| n_updates          | 68           |
| policy_entropy     | 7.642544     |
| policy_loss        | -0.011469215 |
| serial_timesteps   | 17408        |
| time_elapsed       | 70.7         |
| total_timesteps    | 139264       |
| value_loss         | 0.042493887  |
-------------------------------------
Eval num_timesteps=140000, episode_reward=-1.82 +/- 0.80
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0090222005 |
| clipfrac           | 0.12617187   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.68        |
| explained_variance | 0.788        |
| fps                | 1560         |
| n_updates          | 69           |
| policy_entropy     | 7.6451516    |
| policy_loss        | -0.012799208 |
| serial_timesteps   | 17664        |
| time_elapsed       | 71.6         |
| total_timesteps    | 141312       |
| value_loss         | 0.031829294  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008192947  |
| clipfrac           | 0.11533203   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.7         |
| explained_variance | 0.76         |
| fps                | 2163         |
| n_updates          | 70           |
| policy_entropy     | 7.639502     |
| policy_loss        | -0.011701351 |
| serial_timesteps   | 17920        |
| time_elapsed       | 72.9         |
| total_timesteps    | 143360       |
| value_loss         | 0.037479524  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008882493  |
| clipfrac           | 0.12685546   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.67        |
| explained_variance | 0.686        |
| fps                | 2117         |
| n_updates          | 71           |
| policy_entropy     | 7.641282     |
| policy_loss        | -0.010704691 |
| serial_timesteps   | 18176        |
| time_elapsed       | 73.9         |
| total_timesteps    | 145408       |
| value_loss         | 0.03631315   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007534948  |
| clipfrac           | 0.09746094   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.727        |
| fps                | 2148         |
| n_updates          | 72           |
| policy_entropy     | 7.6373153    |
| policy_loss        | -0.011579547 |
| serial_timesteps   | 18432        |
| time_elapsed       | 74.8         |
| total_timesteps    | 147456       |
| value_loss         | 0.0414142    |
-------------------------------------
-------------------------------------
| approxkl           | 0.006867853  |
| clipfrac           | 0.08803711   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | 0.604        |
| fps                | 2168         |
| n_updates          | 73           |
| policy_entropy     | 7.6320863    |
| policy_loss        | -0.010200812 |
| serial_timesteps   | 18688        |
| time_elapsed       | 75.8         |
| total_timesteps    | 149504       |
| value_loss         | 0.040663835  |
-------------------------------------
Eval num_timesteps=150000, episode_reward=-1.03 +/- 0.66
Episode length: 100.00 +/- 0.00
New best mean reward!
--------------------------------------
| approxkl           | 0.008284331   |
| clipfrac           | 0.1071289     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.48         |
| explained_variance | 0.758         |
| fps                | 1519          |
| n_updates          | 74            |
| policy_entropy     | 7.660241      |
| policy_loss        | -0.0126802595 |
| serial_timesteps   | 18944         |
| time_elapsed       | 76.7          |
| total_timesteps    | 151552        |
| value_loss         | 0.03460612    |
--------------------------------------
-------------------------------------
| approxkl           | 0.007889406  |
| clipfrac           | 0.1038086    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.657        |
| fps                | 2127         |
| n_updates          | 75           |
| policy_entropy     | 7.663511     |
| policy_loss        | -0.010967268 |
| serial_timesteps   | 19200        |
| time_elapsed       | 78.1         |
| total_timesteps    | 153600       |
| value_loss         | 0.041079838  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007479463  |
| clipfrac           | 0.09506836   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.624        |
| fps                | 2176         |
| n_updates          | 76           |
| policy_entropy     | 7.642578     |
| policy_loss        | -0.010194797 |
| serial_timesteps   | 19456        |
| time_elapsed       | 79           |
| total_timesteps    | 155648       |
| value_loss         | 0.047029547  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0078045405 |
| clipfrac           | 0.097558595  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.48         |
| fps                | 2155         |
| n_updates          | 77           |
| policy_entropy     | 7.6344023    |
| policy_loss        | -0.009830382 |
| serial_timesteps   | 19712        |
| time_elapsed       | 80           |
| total_timesteps    | 157696       |
| value_loss         | 0.08254666   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007676009  |
| clipfrac           | 0.099414065  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.632        |
| fps                | 2211         |
| n_updates          | 78           |
| policy_entropy     | 7.654227     |
| policy_loss        | -0.010937992 |
| serial_timesteps   | 19968        |
| time_elapsed       | 80.9         |
| total_timesteps    | 159744       |
| value_loss         | 0.04470169   |
-------------------------------------
Eval num_timesteps=160000, episode_reward=-1.65 +/- 1.21
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009447445  |
| clipfrac           | 0.1395996    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.665        |
| fps                | 1522         |
| n_updates          | 79           |
| policy_entropy     | 7.6419997    |
| policy_loss        | -0.011307837 |
| serial_timesteps   | 20224        |
| time_elapsed       | 81.9         |
| total_timesteps    | 161792       |
| value_loss         | 0.052120905  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008789901   |
| clipfrac           | 0.12216797    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.53         |
| explained_variance | 0.701         |
| fps                | 2200          |
| n_updates          | 80            |
| policy_entropy     | 7.599317      |
| policy_loss        | -0.0106941955 |
| serial_timesteps   | 20480         |
| time_elapsed       | 83.2          |
| total_timesteps    | 163840        |
| value_loss         | 0.037498437   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008005261  |
| clipfrac           | 0.09833984   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.641        |
| fps                | 2189         |
| n_updates          | 81           |
| policy_entropy     | 7.582995     |
| policy_loss        | -0.015056388 |
| serial_timesteps   | 20736        |
| time_elapsed       | 84.1         |
| total_timesteps    | 165888       |
| value_loss         | 0.03950558   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008071188  |
| clipfrac           | 0.104003906  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.669        |
| fps                | 2173         |
| n_updates          | 82           |
| policy_entropy     | 7.576152     |
| policy_loss        | -0.010595252 |
| serial_timesteps   | 20992        |
| time_elapsed       | 85.1         |
| total_timesteps    | 167936       |
| value_loss         | 0.037815187  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0060077608 |
| clipfrac           | 0.072460935  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.632        |
| fps                | 2148         |
| n_updates          | 83           |
| policy_entropy     | 7.552391     |
| policy_loss        | -0.006975314 |
| serial_timesteps   | 21248        |
| time_elapsed       | 86           |
| total_timesteps    | 169984       |
| value_loss         | 0.043264017  |
-------------------------------------
Eval num_timesteps=170000, episode_reward=-1.35 +/- 0.44
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.006101742  |
| clipfrac           | 0.07514648   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.765        |
| fps                | 1559         |
| n_updates          | 84           |
| policy_entropy     | 7.5386252    |
| policy_loss        | -0.008780386 |
| serial_timesteps   | 21504        |
| time_elapsed       | 87           |
| total_timesteps    | 172032       |
| value_loss         | 0.020602122  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008724166   |
| clipfrac           | 0.1203125     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.31         |
| explained_variance | 0.768         |
| fps                | 2195          |
| n_updates          | 85            |
| policy_entropy     | 7.554267      |
| policy_loss        | -0.0130127175 |
| serial_timesteps   | 21760         |
| time_elapsed       | 88.3          |
| total_timesteps    | 174080        |
| value_loss         | 0.022061655   |
--------------------------------------
------------------------------------
| approxkl           | 0.006385444 |
| clipfrac           | 0.07851563  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.26       |
| explained_variance | 0.69        |
| fps                | 2203        |
| n_updates          | 86          |
| policy_entropy     | 7.545491    |
| policy_loss        | -0.00587518 |
| serial_timesteps   | 22016       |
| time_elapsed       | 89.2        |
| total_timesteps    | 176128      |
| value_loss         | 0.028720502 |
------------------------------------
--------------------------------------
| approxkl           | 0.0068289144  |
| clipfrac           | 0.08916016    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.25         |
| explained_variance | 0.692         |
| fps                | 2146          |
| n_updates          | 87            |
| policy_entropy     | 7.5124526     |
| policy_loss        | -0.0101116905 |
| serial_timesteps   | 22272         |
| time_elapsed       | 90.1          |
| total_timesteps    | 178176        |
| value_loss         | 0.02845057    |
--------------------------------------
Eval num_timesteps=180000, episode_reward=-0.90 +/- 0.39
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.0072886897 |
| clipfrac           | 0.09038086   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.19        |
| explained_variance | 0.764        |
| fps                | 1549         |
| n_updates          | 88           |
| policy_entropy     | 7.4785337    |
| policy_loss        | -0.008105908 |
| serial_timesteps   | 22528        |
| time_elapsed       | 91.1         |
| total_timesteps    | 180224       |
| value_loss         | 0.02589863   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0067833313 |
| clipfrac           | 0.08754883   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.25        |
| explained_variance | 0.683        |
| fps                | 2245         |
| n_updates          | 89           |
| policy_entropy     | 7.437443     |
| policy_loss        | -0.009110125 |
| serial_timesteps   | 22784        |
| time_elapsed       | 92.4         |
| total_timesteps    | 182272       |
| value_loss         | 0.042020705  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008214023  |
| clipfrac           | 0.115234375  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.39        |
| explained_variance | 0.766        |
| fps                | 2242         |
| n_updates          | 90           |
| policy_entropy     | 7.390976     |
| policy_loss        | -0.010567008 |
| serial_timesteps   | 23040        |
| time_elapsed       | 93.3         |
| total_timesteps    | 184320       |
| value_loss         | 0.029920328  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0066825673 |
| clipfrac           | 0.085839845  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.691        |
| fps                | 2185         |
| n_updates          | 91           |
| policy_entropy     | 7.364386     |
| policy_loss        | -0.007061155 |
| serial_timesteps   | 23296        |
| time_elapsed       | 94.2         |
| total_timesteps    | 186368       |
| value_loss         | 0.03589996   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0070285434  |
| clipfrac           | 0.09047852    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.51         |
| explained_variance | 0.642         |
| fps                | 2211          |
| n_updates          | 92            |
| policy_entropy     | 7.3500924     |
| policy_loss        | -0.0085656615 |
| serial_timesteps   | 23552         |
| time_elapsed       | 95.2          |
| total_timesteps    | 188416        |
| value_loss         | 0.05923661    |
--------------------------------------
Eval num_timesteps=190000, episode_reward=-2.09 +/- 0.76
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0074220328 |
| clipfrac           | 0.09995117   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.748        |
| fps                | 1570         |
| n_updates          | 93           |
| policy_entropy     | 7.340001     |
| policy_loss        | -0.008760719 |
| serial_timesteps   | 23808        |
| time_elapsed       | 96.1         |
| total_timesteps    | 190464       |
| value_loss         | 0.03701895   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008660041  |
| clipfrac           | 0.11577149   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.817        |
| fps                | 2218         |
| n_updates          | 94           |
| policy_entropy     | 7.3281174    |
| policy_loss        | -0.013385194 |
| serial_timesteps   | 24064        |
| time_elapsed       | 97.4         |
| total_timesteps    | 192512       |
| value_loss         | 0.02694892   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008487145  |
| clipfrac           | 0.115673825  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.65        |
| explained_variance | 0.799        |
| fps                | 2165         |
| n_updates          | 95           |
| policy_entropy     | 7.3202705    |
| policy_loss        | -0.010961479 |
| serial_timesteps   | 24320        |
| time_elapsed       | 98.3         |
| total_timesteps    | 194560       |
| value_loss         | 0.03339852   |
-------------------------------------
------------------------------------
| approxkl           | 0.008979638 |
| clipfrac           | 0.13002929  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.78       |
| explained_variance | 0.509       |
| fps                | 2230        |
| n_updates          | 96          |
| policy_entropy     | 7.31691     |
| policy_loss        | -0.01097337 |
| serial_timesteps   | 24576       |
| time_elapsed       | 99.3        |
| total_timesteps    | 196608      |
| value_loss         | 0.064353205 |
------------------------------------
-------------------------------------
| approxkl           | 0.00890307   |
| clipfrac           | 0.12241211   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.78        |
| explained_variance | 0.685        |
| fps                | 2228         |
| n_updates          | 97           |
| policy_entropy     | 7.2818136    |
| policy_loss        | -0.009869097 |
| serial_timesteps   | 24832        |
| time_elapsed       | 100          |
| total_timesteps    | 198656       |
| value_loss         | 0.042983986  |
-------------------------------------
Eval num_timesteps=200000, episode_reward=-0.89 +/- 0.35
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.00815746   |
| clipfrac           | 0.10869141   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.83        |
| explained_variance | 0.495        |
| fps                | 1534         |
| n_updates          | 98           |
| policy_entropy     | 7.228615     |
| policy_loss        | -0.010739849 |
| serial_timesteps   | 25088        |
| time_elapsed       | 101          |
| total_timesteps    | 200704       |
| value_loss         | 0.08864238   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007971911  |
| clipfrac           | 0.111328125  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.81        |
| explained_variance | 0.762        |
| fps                | 2254         |
| n_updates          | 99           |
| policy_entropy     | 7.2340937    |
| policy_loss        | -0.010187397 |
| serial_timesteps   | 25344        |
| time_elapsed       | 102          |
| total_timesteps    | 202752       |
| value_loss         | 0.034699522  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008670198  |
| clipfrac           | 0.11782227   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.71        |
| explained_variance | 0.731        |
| fps                | 2227         |
| n_updates          | 100          |
| policy_entropy     | 7.2624497    |
| policy_loss        | -0.015851062 |
| serial_timesteps   | 25600        |
| time_elapsed       | 103          |
| total_timesteps    | 204800       |
| value_loss         | 0.040591292  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008012803  |
| clipfrac           | 0.10795899   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.68        |
| explained_variance | 0.685        |
| fps                | 2242         |
| n_updates          | 101          |
| policy_entropy     | 7.2628374    |
| policy_loss        | -0.013254245 |
| serial_timesteps   | 25856        |
| time_elapsed       | 104          |
| total_timesteps    | 206848       |
| value_loss         | 0.055362843  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008731629  |
| clipfrac           | 0.114550784  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.67        |
| explained_variance | 0.661        |
| fps                | 2204         |
| n_updates          | 102          |
| policy_entropy     | 7.2367873    |
| policy_loss        | -0.016406944 |
| serial_timesteps   | 26112        |
| time_elapsed       | 105          |
| total_timesteps    | 208896       |
| value_loss         | 0.055450797  |
-------------------------------------
Eval num_timesteps=210000, episode_reward=-0.76 +/- 0.61
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.009094689  |
| clipfrac           | 0.13066407   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.765        |
| fps                | 1556         |
| n_updates          | 103          |
| policy_entropy     | 7.225751     |
| policy_loss        | -0.012005815 |
| serial_timesteps   | 26368        |
| time_elapsed       | 106          |
| total_timesteps    | 210944       |
| value_loss         | 0.031627733  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007490609  |
| clipfrac           | 0.10244141   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.68        |
| explained_variance | 0.722        |
| fps                | 2238         |
| n_updates          | 104          |
| policy_entropy     | 7.194766     |
| policy_loss        | -0.006173563 |
| serial_timesteps   | 26624        |
| time_elapsed       | 107          |
| total_timesteps    | 212992       |
| value_loss         | 0.0457603    |
-------------------------------------
-------------------------------------
| approxkl           | 0.007857328  |
| clipfrac           | 0.107177734  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.65        |
| explained_variance | 0.697        |
| fps                | 2196         |
| n_updates          | 105          |
| policy_entropy     | 7.1570115    |
| policy_loss        | -0.010151355 |
| serial_timesteps   | 26880        |
| time_elapsed       | 108          |
| total_timesteps    | 215040       |
| value_loss         | 0.035767566  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008253935  |
| clipfrac           | 0.115722656  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.65        |
| explained_variance | 0.767        |
| fps                | 2121         |
| n_updates          | 106          |
| policy_entropy     | 7.1721597    |
| policy_loss        | -0.011448694 |
| serial_timesteps   | 27136        |
| time_elapsed       | 109          |
| total_timesteps    | 217088       |
| value_loss         | 0.03687226   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008032746  |
| clipfrac           | 0.11074219   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.763        |
| fps                | 2186         |
| n_updates          | 107          |
| policy_entropy     | 7.1931524    |
| policy_loss        | -0.008669689 |
| serial_timesteps   | 27392        |
| time_elapsed       | 110          |
| total_timesteps    | 219136       |
| value_loss         | 0.030650368  |
-------------------------------------
Eval num_timesteps=220000, episode_reward=-0.98 +/- 0.69
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0072272355 |
| clipfrac           | 0.09291992   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.763        |
| fps                | 1560         |
| n_updates          | 108          |
| policy_entropy     | 7.221883     |
| policy_loss        | -0.010608001 |
| serial_timesteps   | 27648        |
| time_elapsed       | 111          |
| total_timesteps    | 221184       |
| value_loss         | 0.037987165  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007713546  |
| clipfrac           | 0.10185547   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.75         |
| fps                | 2164         |
| n_updates          | 109          |
| policy_entropy     | 7.250431     |
| policy_loss        | -0.010599453 |
| serial_timesteps   | 27904        |
| time_elapsed       | 113          |
| total_timesteps    | 223232       |
| value_loss         | 0.03594077   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0076168245 |
| clipfrac           | 0.10317383   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.77         |
| fps                | 2106         |
| n_updates          | 110          |
| policy_entropy     | 7.2361956    |
| policy_loss        | -0.009566346 |
| serial_timesteps   | 28160        |
| time_elapsed       | 113          |
| total_timesteps    | 225280       |
| value_loss         | 0.034963395  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007371659  |
| clipfrac           | 0.09458008   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.701        |
| fps                | 2144         |
| n_updates          | 111          |
| policy_entropy     | 7.2132616    |
| policy_loss        | -0.007333348 |
| serial_timesteps   | 28416        |
| time_elapsed       | 114          |
| total_timesteps    | 227328       |
| value_loss         | 0.049162004  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009264406  |
| clipfrac           | 0.12910156   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.727        |
| fps                | 2198         |
| n_updates          | 112          |
| policy_entropy     | 7.2052255    |
| policy_loss        | -0.011998761 |
| serial_timesteps   | 28672        |
| time_elapsed       | 115          |
| total_timesteps    | 229376       |
| value_loss         | 0.044740114  |
-------------------------------------
Eval num_timesteps=230000, episode_reward=-1.14 +/- 0.47
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0073632733 |
| clipfrac           | 0.09633789   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.838        |
| fps                | 1551         |
| n_updates          | 113          |
| policy_entropy     | 7.176736     |
| policy_loss        | -0.008565611 |
| serial_timesteps   | 28928        |
| time_elapsed       | 116          |
| total_timesteps    | 231424       |
| value_loss         | 0.020007482  |
-------------------------------------
------------------------------------
| approxkl           | 0.007196953 |
| clipfrac           | 0.09394531  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.48       |
| explained_variance | 0.682       |
| fps                | 2134        |
| n_updates          | 114         |
| policy_entropy     | 7.159768    |
| policy_loss        | -0.00649105 |
| serial_timesteps   | 29184       |
| time_elapsed       | 118         |
| total_timesteps    | 233472      |
| value_loss         | 0.0404563   |
------------------------------------
-------------------------------------
| approxkl           | 0.00921588   |
| clipfrac           | 0.119384766  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.77         |
| fps                | 2159         |
| n_updates          | 115          |
| policy_entropy     | 7.1353006    |
| policy_loss        | -0.009894492 |
| serial_timesteps   | 29440        |
| time_elapsed       | 119          |
| total_timesteps    | 235520       |
| value_loss         | 0.03154193   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008791463  |
| clipfrac           | 0.12397461   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.39        |
| explained_variance | 0.637        |
| fps                | 2165         |
| n_updates          | 116          |
| policy_entropy     | 7.122327     |
| policy_loss        | -0.012122503 |
| serial_timesteps   | 29696        |
| time_elapsed       | 120          |
| total_timesteps    | 237568       |
| value_loss         | 0.046565976  |
-------------------------------------
--------------------------------------
| approxkl           | 0.006743513   |
| clipfrac           | 0.08710937    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.706         |
| fps                | 2174          |
| n_updates          | 117           |
| policy_entropy     | 7.1494384     |
| policy_loss        | -0.0092885485 |
| serial_timesteps   | 29952         |
| time_elapsed       | 120           |
| total_timesteps    | 239616        |
| value_loss         | 0.04245342    |
--------------------------------------
Eval num_timesteps=240000, episode_reward=-1.50 +/- 0.60
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007442     |
| clipfrac           | 0.095263675  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.785        |
| fps                | 1536         |
| n_updates          | 118          |
| policy_entropy     | 7.174411     |
| policy_loss        | -0.007734953 |
| serial_timesteps   | 30208        |
| time_elapsed       | 121          |
| total_timesteps    | 241664       |
| value_loss         | 0.031749535  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009665278  |
| clipfrac           | 0.13076171   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.78         |
| fps                | 2178         |
| n_updates          | 119          |
| policy_entropy     | 7.1485605    |
| policy_loss        | -0.013897667 |
| serial_timesteps   | 30464        |
| time_elapsed       | 123          |
| total_timesteps    | 243712       |
| value_loss         | 0.028163671  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0078156255 |
| clipfrac           | 0.10751953   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.751        |
| fps                | 2223         |
| n_updates          | 120          |
| policy_entropy     | 7.1098127    |
| policy_loss        | -0.00878719  |
| serial_timesteps   | 30720        |
| time_elapsed       | 124          |
| total_timesteps    | 245760       |
| value_loss         | 0.043322444  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008471599  |
| clipfrac           | 0.11430664   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.72         |
| fps                | 2270         |
| n_updates          | 121          |
| policy_entropy     | 7.103026     |
| policy_loss        | -0.009527435 |
| serial_timesteps   | 30976        |
| time_elapsed       | 125          |
| total_timesteps    | 247808       |
| value_loss         | 0.03918583   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008440504  |
| clipfrac           | 0.11987305   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.767        |
| fps                | 2247         |
| n_updates          | 122          |
| policy_entropy     | 7.096911     |
| policy_loss        | -0.009168263 |
| serial_timesteps   | 31232        |
| time_elapsed       | 126          |
| total_timesteps    | 249856       |
| value_loss         | 0.04310482   |
-------------------------------------
Eval num_timesteps=250000, episode_reward=-1.49 +/- 0.97
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.00973075   |
| clipfrac           | 0.14243165   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.726        |
| fps                | 1564         |
| n_updates          | 123          |
| policy_entropy     | 7.083481     |
| policy_loss        | -0.013675014 |
| serial_timesteps   | 31488        |
| time_elapsed       | 126          |
| total_timesteps    | 251904       |
| value_loss         | 0.03668095   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010398834  |
| clipfrac           | 0.14921875   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.727        |
| fps                | 2237         |
| n_updates          | 124          |
| policy_entropy     | 7.0671897    |
| policy_loss        | -0.016259687 |
| serial_timesteps   | 31744        |
| time_elapsed       | 128          |
| total_timesteps    | 253952       |
| value_loss         | 0.036158685  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077271955 |
| clipfrac           | 0.101904295  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.786        |
| fps                | 2241         |
| n_updates          | 125          |
| policy_entropy     | 7.051201     |
| policy_loss        | -0.00929657  |
| serial_timesteps   | 32000        |
| time_elapsed       | 129          |
| total_timesteps    | 256000       |
| value_loss         | 0.022630012  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010585309  |
| clipfrac           | 0.15981445   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.68         |
| fps                | 2225         |
| n_updates          | 126          |
| policy_entropy     | 7.0510397    |
| policy_loss        | -0.017203506 |
| serial_timesteps   | 32256        |
| time_elapsed       | 130          |
| total_timesteps    | 258048       |
| value_loss         | 0.03591971   |
-------------------------------------
Eval num_timesteps=260000, episode_reward=-0.90 +/- 0.23
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008292164  |
| clipfrac           | 0.113867186  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.754        |
| fps                | 1544         |
| n_updates          | 127          |
| policy_entropy     | 7.0535865    |
| policy_loss        | -0.011842737 |
| serial_timesteps   | 32512        |
| time_elapsed       | 130          |
| total_timesteps    | 260096       |
| value_loss         | 0.029039424  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009156475  |
| clipfrac           | 0.124414064  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.746        |
| fps                | 2204         |
| n_updates          | 128          |
| policy_entropy     | 7.0367446    |
| policy_loss        | -0.012467014 |
| serial_timesteps   | 32768        |
| time_elapsed       | 132          |
| total_timesteps    | 262144       |
| value_loss         | 0.033263326  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008555427  |
| clipfrac           | 0.114550784  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.751        |
| fps                | 2227         |
| n_updates          | 129          |
| policy_entropy     | 7.001287     |
| policy_loss        | -0.008470927 |
| serial_timesteps   | 33024        |
| time_elapsed       | 133          |
| total_timesteps    | 264192       |
| value_loss         | 0.03942577   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007925155  |
| clipfrac           | 0.10541992   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.61         |
| fps                | 2223         |
| n_updates          | 130          |
| policy_entropy     | 6.9788675    |
| policy_loss        | -0.010398943 |
| serial_timesteps   | 33280        |
| time_elapsed       | 134          |
| total_timesteps    | 266240       |
| value_loss         | 0.039743032  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009248208  |
| clipfrac           | 0.1199707    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.794        |
| fps                | 2222         |
| n_updates          | 131          |
| policy_entropy     | 6.960406     |
| policy_loss        | -0.011076839 |
| serial_timesteps   | 33536        |
| time_elapsed       | 135          |
| total_timesteps    | 268288       |
| value_loss         | 0.030059949  |
-------------------------------------
Eval num_timesteps=270000, episode_reward=-2.22 +/- 0.68
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0082717445 |
| clipfrac           | 0.109033205  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.763        |
| fps                | 1548         |
| n_updates          | 132          |
| policy_entropy     | 6.928067     |
| policy_loss        | -0.009993556 |
| serial_timesteps   | 33792        |
| time_elapsed       | 136          |
| total_timesteps    | 270336       |
| value_loss         | 0.029975617  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00982354   |
| clipfrac           | 0.14375      |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.722        |
| fps                | 2206         |
| n_updates          | 133          |
| policy_entropy     | 6.9036713    |
| policy_loss        | -0.013587782 |
| serial_timesteps   | 34048        |
| time_elapsed       | 137          |
| total_timesteps    | 272384       |
| value_loss         | 0.04772777   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0090539185 |
| clipfrac           | 0.119189456  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.644        |
| fps                | 2161         |
| n_updates          | 134          |
| policy_entropy     | 6.869802     |
| policy_loss        | -0.013161717 |
| serial_timesteps   | 34304        |
| time_elapsed       | 138          |
| total_timesteps    | 274432       |
| value_loss         | 0.061281182  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009540299  |
| clipfrac           | 0.13217774   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.803        |
| fps                | 2258         |
| n_updates          | 135          |
| policy_entropy     | 6.8448763    |
| policy_loss        | -0.013542983 |
| serial_timesteps   | 34560        |
| time_elapsed       | 139          |
| total_timesteps    | 276480       |
| value_loss         | 0.024310831  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009776303  |
| clipfrac           | 0.14780274   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.78         |
| fps                | 2232         |
| n_updates          | 136          |
| policy_entropy     | 6.836135     |
| policy_loss        | -0.016705098 |
| serial_timesteps   | 34816        |
| time_elapsed       | 140          |
| total_timesteps    | 278528       |
| value_loss         | 0.031511985  |
-------------------------------------
Eval num_timesteps=280000, episode_reward=-2.93 +/- 1.45
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009716846  |
| clipfrac           | 0.1274414    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.554        |
| fps                | 1555         |
| n_updates          | 137          |
| policy_entropy     | 6.8176003    |
| policy_loss        | -0.015905308 |
| serial_timesteps   | 35072        |
| time_elapsed       | 141          |
| total_timesteps    | 280576       |
| value_loss         | 0.06823429   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009386263  |
| clipfrac           | 0.13427734   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.758        |
| fps                | 2196         |
| n_updates          | 138          |
| policy_entropy     | 6.810298     |
| policy_loss        | -0.011071832 |
| serial_timesteps   | 35328        |
| time_elapsed       | 142          |
| total_timesteps    | 282624       |
| value_loss         | 0.035764895  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009648042  |
| clipfrac           | 0.13447265   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.751        |
| fps                | 2215         |
| n_updates          | 139          |
| policy_entropy     | 6.8224154    |
| policy_loss        | -0.012982416 |
| serial_timesteps   | 35584        |
| time_elapsed       | 143          |
| total_timesteps    | 284672       |
| value_loss         | 0.029578906  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009473541  |
| clipfrac           | 0.13569336   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.666        |
| fps                | 2225         |
| n_updates          | 140          |
| policy_entropy     | 6.8220735    |
| policy_loss        | -0.011073769 |
| serial_timesteps   | 35840        |
| time_elapsed       | 144          |
| total_timesteps    | 286720       |
| value_loss         | 0.06614018   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009898456  |
| clipfrac           | 0.14291993   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.694        |
| fps                | 2198         |
| n_updates          | 141          |
| policy_entropy     | 6.804685     |
| policy_loss        | -0.012058006 |
| serial_timesteps   | 36096        |
| time_elapsed       | 145          |
| total_timesteps    | 288768       |
| value_loss         | 0.03528459   |
-------------------------------------
Eval num_timesteps=290000, episode_reward=-2.32 +/- 1.49
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009420259  |
| clipfrac           | 0.13681641   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.704        |
| fps                | 1515         |
| n_updates          | 142          |
| policy_entropy     | 6.7861495    |
| policy_loss        | -0.012930835 |
| serial_timesteps   | 36352        |
| time_elapsed       | 146          |
| total_timesteps    | 290816       |
| value_loss         | 0.04124926   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008182316  |
| clipfrac           | 0.11054687   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.693        |
| fps                | 2102         |
| n_updates          | 143          |
| policy_entropy     | 6.7644053    |
| policy_loss        | -0.008393298 |
| serial_timesteps   | 36608        |
| time_elapsed       | 147          |
| total_timesteps    | 292864       |
| value_loss         | 0.04925621   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0117913885 |
| clipfrac           | 0.16386719   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.788        |
| fps                | 2119         |
| n_updates          | 144          |
| policy_entropy     | 6.7763886    |
| policy_loss        | -0.013916679 |
| serial_timesteps   | 36864        |
| time_elapsed       | 148          |
| total_timesteps    | 294912       |
| value_loss         | 0.031360455  |
-------------------------------------
------------------------------------
| approxkl           | 0.009564861 |
| clipfrac           | 0.12851563  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.47       |
| explained_variance | 0.729       |
| fps                | 2106        |
| n_updates          | 145         |
| policy_entropy     | 6.7921014   |
| policy_loss        | -0.01277521 |
| serial_timesteps   | 37120       |
| time_elapsed       | 149         |
| total_timesteps    | 296960      |
| value_loss         | 0.043189008 |
------------------------------------
------------------------------------
| approxkl           | 0.008204343 |
| clipfrac           | 0.10493164  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.49       |
| explained_variance | 0.751       |
| fps                | 2082        |
| n_updates          | 146         |
| policy_entropy     | 6.768243    |
| policy_loss        | -0.00869148 |
| serial_timesteps   | 37376       |
| time_elapsed       | 150         |
| total_timesteps    | 299008      |
| value_loss         | 0.03310914  |
------------------------------------
Eval num_timesteps=300000, episode_reward=-2.06 +/- 1.35
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010029717  |
| clipfrac           | 0.14770508   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.758        |
| fps                | 1496         |
| n_updates          | 147          |
| policy_entropy     | 6.738791     |
| policy_loss        | -0.010985604 |
| serial_timesteps   | 37632        |
| time_elapsed       | 151          |
| total_timesteps    | 301056       |
| value_loss         | 0.0404524    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0074452446 |
| clipfrac           | 0.09672852   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.717        |
| fps                | 2072         |
| n_updates          | 148          |
| policy_entropy     | 6.7101746    |
| policy_loss        | -0.00875066  |
| serial_timesteps   | 37888        |
| time_elapsed       | 152          |
| total_timesteps    | 303104       |
| value_loss         | 0.027014598  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007925976  |
| clipfrac           | 0.10458984   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.603        |
| fps                | 2128         |
| n_updates          | 149          |
| policy_entropy     | 6.6915984    |
| policy_loss        | -0.006110604 |
| serial_timesteps   | 38144        |
| time_elapsed       | 153          |
| total_timesteps    | 305152       |
| value_loss         | 0.072059445  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009449711  |
| clipfrac           | 0.13007812   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.658        |
| fps                | 2084         |
| n_updates          | 150          |
| policy_entropy     | 6.664346     |
| policy_loss        | -0.011687426 |
| serial_timesteps   | 38400        |
| time_elapsed       | 154          |
| total_timesteps    | 307200       |
| value_loss         | 0.055299807  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008111972  |
| clipfrac           | 0.109472655  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.656        |
| fps                | 2090         |
| n_updates          | 151          |
| policy_entropy     | 6.6339326    |
| policy_loss        | -0.009117758 |
| serial_timesteps   | 38656        |
| time_elapsed       | 155          |
| total_timesteps    | 309248       |
| value_loss         | 0.04466086   |
-------------------------------------
Eval num_timesteps=310000, episode_reward=-0.97 +/- 0.59
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.008992116 |
| clipfrac           | 0.123095706 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.57       |
| explained_variance | 0.644       |
| fps                | 1531        |
| n_updates          | 152         |
| policy_entropy     | 6.625268    |
| policy_loss        | -0.0114875  |
| serial_timesteps   | 38912       |
| time_elapsed       | 156         |
| total_timesteps    | 311296      |
| value_loss         | 0.05283717  |
------------------------------------
-------------------------------------
| approxkl           | 0.00891252   |
| clipfrac           | 0.12539062   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.61        |
| explained_variance | 0.604        |
| fps                | 2114         |
| n_updates          | 153          |
| policy_entropy     | 6.64392      |
| policy_loss        | -0.009901842 |
| serial_timesteps   | 39168        |
| time_elapsed       | 157          |
| total_timesteps    | 313344       |
| value_loss         | 0.051536284  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008238513  |
| clipfrac           | 0.11416016   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.711        |
| fps                | 2089         |
| n_updates          | 154          |
| policy_entropy     | 6.6504927    |
| policy_loss        | -0.007032501 |
| serial_timesteps   | 39424        |
| time_elapsed       | 158          |
| total_timesteps    | 315392       |
| value_loss         | 0.045034524  |
-------------------------------------
-------------------------------------
| approxkl           | 0.01010509   |
| clipfrac           | 0.13398437   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.632        |
| fps                | 2159         |
| n_updates          | 155          |
| policy_entropy     | 6.650496     |
| policy_loss        | -0.013032766 |
| serial_timesteps   | 39680        |
| time_elapsed       | 159          |
| total_timesteps    | 317440       |
| value_loss         | 0.05316971   |
-------------------------------------
--------------------------------------
| approxkl           | 0.007755953   |
| clipfrac           | 0.10498047    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.54         |
| explained_variance | 0.739         |
| fps                | 2155          |
| n_updates          | 156           |
| policy_entropy     | 6.6411734     |
| policy_loss        | -0.0053937566 |
| serial_timesteps   | 39936         |
| time_elapsed       | 160           |
| total_timesteps    | 319488        |
| value_loss         | 0.051837265   |
--------------------------------------
Eval num_timesteps=320000, episode_reward=-2.13 +/- 0.84
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.00997692   |
| clipfrac           | 0.14169922   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.713        |
| fps                | 1483         |
| n_updates          | 157          |
| policy_entropy     | 6.610668     |
| policy_loss        | -0.012659974 |
| serial_timesteps   | 40192        |
| time_elapsed       | 161          |
| total_timesteps    | 321536       |
| value_loss         | 0.041774005  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008073464  |
| clipfrac           | 0.11015625   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.761        |
| fps                | 2137         |
| n_updates          | 158          |
| policy_entropy     | 6.5722656    |
| policy_loss        | -0.007819666 |
| serial_timesteps   | 40448        |
| time_elapsed       | 163          |
| total_timesteps    | 323584       |
| value_loss         | 0.035248555  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0086019235 |
| clipfrac           | 0.12197266   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.37        |
| explained_variance | 0.779        |
| fps                | 2139         |
| n_updates          | 159          |
| policy_entropy     | 6.5413194    |
| policy_loss        | -0.008311648 |
| serial_timesteps   | 40704        |
| time_elapsed       | 164          |
| total_timesteps    | 325632       |
| value_loss         | 0.029369269  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009122542  |
| clipfrac           | 0.1324707    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.689        |
| fps                | 2127         |
| n_updates          | 160          |
| policy_entropy     | 6.518882     |
| policy_loss        | -0.009489882 |
| serial_timesteps   | 40960        |
| time_elapsed       | 165          |
| total_timesteps    | 327680       |
| value_loss         | 0.040408842  |
-------------------------------------
-------------------------------------
| approxkl           | 0.01019364   |
| clipfrac           | 0.1415039    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.72         |
| fps                | 2170         |
| n_updates          | 161          |
| policy_entropy     | 6.4986486    |
| policy_loss        | -0.012055197 |
| serial_timesteps   | 41216        |
| time_elapsed       | 166          |
| total_timesteps    | 329728       |
| value_loss         | 0.046568815  |
-------------------------------------
Eval num_timesteps=330000, episode_reward=-1.82 +/- 1.07
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008233374  |
| clipfrac           | 0.11254883   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.809        |
| fps                | 1573         |
| n_updates          | 162          |
| policy_entropy     | 6.4760857    |
| policy_loss        | -0.007697499 |
| serial_timesteps   | 41472        |
| time_elapsed       | 166          |
| total_timesteps    | 331776       |
| value_loss         | 0.02493573   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007889458  |
| clipfrac           | 0.10654297   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.784        |
| fps                | 2258         |
| n_updates          | 163          |
| policy_entropy     | 6.4673147    |
| policy_loss        | -0.007660945 |
| serial_timesteps   | 41728        |
| time_elapsed       | 168          |
| total_timesteps    | 333824       |
| value_loss         | 0.033818204  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009079962  |
| clipfrac           | 0.12890625   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.594        |
| fps                | 2251         |
| n_updates          | 164          |
| policy_entropy     | 6.4640913    |
| policy_loss        | -0.009241733 |
| serial_timesteps   | 41984        |
| time_elapsed       | 169          |
| total_timesteps    | 335872       |
| value_loss         | 0.06564595   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007754331  |
| clipfrac           | 0.10727539   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.706        |
| fps                | 2125         |
| n_updates          | 165          |
| policy_entropy     | 6.4421806    |
| policy_loss        | -0.009201021 |
| serial_timesteps   | 42240        |
| time_elapsed       | 170          |
| total_timesteps    | 337920       |
| value_loss         | 0.060841165  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008963691  |
| clipfrac           | 0.12792969   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.671        |
| fps                | 2200         |
| n_updates          | 166          |
| policy_entropy     | 6.4344506    |
| policy_loss        | -0.011183682 |
| serial_timesteps   | 42496        |
| time_elapsed       | 171          |
| total_timesteps    | 339968       |
| value_loss         | 0.05239399   |
-------------------------------------
Eval num_timesteps=340000, episode_reward=-1.38 +/- 0.61
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010566282   |
| clipfrac           | 0.15244141    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.6          |
| explained_variance | 0.821         |
| fps                | 1562          |
| n_updates          | 167           |
| policy_entropy     | 6.412748      |
| policy_loss        | -0.0135634495 |
| serial_timesteps   | 42752         |
| time_elapsed       | 171           |
| total_timesteps    | 342016        |
| value_loss         | 0.027592858   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008032453  |
| clipfrac           | 0.10888672   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.64        |
| explained_variance | 0.733        |
| fps                | 2193         |
| n_updates          | 168          |
| policy_entropy     | 6.3893156    |
| policy_loss        | -0.008972766 |
| serial_timesteps   | 43008        |
| time_elapsed       | 173          |
| total_timesteps    | 344064       |
| value_loss         | 0.053788774  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0078785615  |
| clipfrac           | 0.10771485    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.55         |
| explained_variance | 0.797         |
| fps                | 2207          |
| n_updates          | 169           |
| policy_entropy     | 6.394893      |
| policy_loss        | -0.0071306797 |
| serial_timesteps   | 43264         |
| time_elapsed       | 174           |
| total_timesteps    | 346112        |
| value_loss         | 0.033390343   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008500566  |
| clipfrac           | 0.11445312   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.823        |
| fps                | 2240         |
| n_updates          | 170          |
| policy_entropy     | 6.3815184    |
| policy_loss        | -0.007312271 |
| serial_timesteps   | 43520        |
| time_elapsed       | 175          |
| total_timesteps    | 348160       |
| value_loss         | 0.030446786  |
-------------------------------------
Eval num_timesteps=350000, episode_reward=-1.98 +/- 0.85
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.0071872375  |
| clipfrac           | 0.095751956   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.47         |
| explained_variance | 0.664         |
| fps                | 1570          |
| n_updates          | 171           |
| policy_entropy     | 6.3679504     |
| policy_loss        | -0.0065343278 |
| serial_timesteps   | 43776         |
| time_elapsed       | 176           |
| total_timesteps    | 350208        |
| value_loss         | 0.05074972    |
--------------------------------------
-------------------------------------
| approxkl           | 0.008712655  |
| clipfrac           | 0.124414064  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.809        |
| fps                | 2244         |
| n_updates          | 172          |
| policy_entropy     | 6.375567     |
| policy_loss        | -0.009060547 |
| serial_timesteps   | 44032        |
| time_elapsed       | 177          |
| total_timesteps    | 352256       |
| value_loss         | 0.03452619   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008229752  |
| clipfrac           | 0.1105957    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.737        |
| fps                | 2227         |
| n_updates          | 173          |
| policy_entropy     | 6.376631     |
| policy_loss        | -0.008142229 |
| serial_timesteps   | 44288        |
| time_elapsed       | 178          |
| total_timesteps    | 354304       |
| value_loss         | 0.036141098  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008563249  |
| clipfrac           | 0.12138672   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.693        |
| fps                | 2249         |
| n_updates          | 174          |
| policy_entropy     | 6.3642573    |
| policy_loss        | -0.011055951 |
| serial_timesteps   | 44544        |
| time_elapsed       | 179          |
| total_timesteps    | 356352       |
| value_loss         | 0.059891652  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008466358  |
| clipfrac           | 0.11508789   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.773        |
| fps                | 2200         |
| n_updates          | 175          |
| policy_entropy     | 6.3365045    |
| policy_loss        | -0.008625251 |
| serial_timesteps   | 44800        |
| time_elapsed       | 180          |
| total_timesteps    | 358400       |
| value_loss         | 0.038322337  |
-------------------------------------
Eval num_timesteps=360000, episode_reward=-2.83 +/- 1.27
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.00882796   |
| clipfrac           | 0.12636718   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.804        |
| fps                | 1574         |
| n_updates          | 176          |
| policy_entropy     | 6.3092055    |
| policy_loss        | -0.007556523 |
| serial_timesteps   | 45056        |
| time_elapsed       | 181          |
| total_timesteps    | 360448       |
| value_loss         | 0.031453244  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008546606   |
| clipfrac           | 0.1199707     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.52         |
| explained_variance | 0.766         |
| fps                | 2172          |
| n_updates          | 177           |
| policy_entropy     | 6.2901907     |
| policy_loss        | -0.0071468973 |
| serial_timesteps   | 45312         |
| time_elapsed       | 182           |
| total_timesteps    | 362496        |
| value_loss         | 0.04591457    |
--------------------------------------
--------------------------------------
| approxkl           | 0.008851027   |
| clipfrac           | 0.12246094    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.55         |
| explained_variance | 0.695         |
| fps                | 2235          |
| n_updates          | 178           |
| policy_entropy     | 6.2894135     |
| policy_loss        | -0.0081471335 |
| serial_timesteps   | 45568         |
| time_elapsed       | 183           |
| total_timesteps    | 364544        |
| value_loss         | 0.04251039    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0105796065 |
| clipfrac           | 0.15424804   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.796        |
| fps                | 2223         |
| n_updates          | 179          |
| policy_entropy     | 6.293645     |
| policy_loss        | -0.009102195 |
| serial_timesteps   | 45824        |
| time_elapsed       | 184          |
| total_timesteps    | 366592       |
| value_loss         | 0.034706287  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0075837946 |
| clipfrac           | 0.099804685  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.68         |
| fps                | 2266         |
| n_updates          | 180          |
| policy_entropy     | 6.2806754    |
| policy_loss        | -0.005485908 |
| serial_timesteps   | 46080        |
| time_elapsed       | 185          |
| total_timesteps    | 368640       |
| value_loss         | 0.048460044  |
-------------------------------------
Eval num_timesteps=370000, episode_reward=-2.16 +/- 1.07
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.007909861 |
| clipfrac           | 0.1065918   |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.53       |
| explained_variance | 0.796       |
| fps                | 1574        |
| n_updates          | 181         |
| policy_entropy     | 6.2570457   |
| policy_loss        | -0.00623857 |
| serial_timesteps   | 46336       |
| time_elapsed       | 186         |
| total_timesteps    | 370688      |
| value_loss         | 0.034226436 |
------------------------------------
-------------------------------------
| approxkl           | 0.008665535  |
| clipfrac           | 0.12192383   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.751        |
| fps                | 2256         |
| n_updates          | 182          |
| policy_entropy     | 6.22856      |
| policy_loss        | -0.008577135 |
| serial_timesteps   | 46592        |
| time_elapsed       | 187          |
| total_timesteps    | 372736       |
| value_loss         | 0.045098666  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009041952   |
| clipfrac           | 0.12734374    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.52         |
| explained_variance | 0.874         |
| fps                | 2243          |
| n_updates          | 183           |
| policy_entropy     | 6.1864343     |
| policy_loss        | -0.0089575695 |
| serial_timesteps   | 46848         |
| time_elapsed       | 188           |
| total_timesteps    | 374784        |
| value_loss         | 0.021928074   |
--------------------------------------
------------------------------------
| approxkl           | 0.009980651 |
| clipfrac           | 0.14379883  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.46       |
| explained_variance | 0.817       |
| fps                | 2211        |
| n_updates          | 184         |
| policy_entropy     | 6.150626    |
| policy_loss        | -0.00990618 |
| serial_timesteps   | 47104       |
| time_elapsed       | 189         |
| total_timesteps    | 376832      |
| value_loss         | 0.029500222 |
------------------------------------
-------------------------------------
| approxkl           | 0.007836674  |
| clipfrac           | 0.106738284  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.688        |
| fps                | 2156         |
| n_updates          | 185          |
| policy_entropy     | 6.1108747    |
| policy_loss        | -0.007793013 |
| serial_timesteps   | 47360        |
| time_elapsed       | 190          |
| total_timesteps    | 378880       |
| value_loss         | 0.051941574  |
-------------------------------------
Eval num_timesteps=380000, episode_reward=-1.77 +/- 0.89
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009681928  |
| clipfrac           | 0.14091797   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.769        |
| fps                | 1588         |
| n_updates          | 186          |
| policy_entropy     | 6.0769367    |
| policy_loss        | -0.009784663 |
| serial_timesteps   | 47616        |
| time_elapsed       | 191          |
| total_timesteps    | 380928       |
| value_loss         | 0.03585022   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00931452   |
| clipfrac           | 0.12954101   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.678        |
| fps                | 2241         |
| n_updates          | 187          |
| policy_entropy     | 6.058998     |
| policy_loss        | -0.009094812 |
| serial_timesteps   | 47872        |
| time_elapsed       | 192          |
| total_timesteps    | 382976       |
| value_loss         | 0.050608963  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008638722  |
| clipfrac           | 0.12319336   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.784        |
| fps                | 2274         |
| n_updates          | 188          |
| policy_entropy     | 6.050569     |
| policy_loss        | -0.007693925 |
| serial_timesteps   | 48128        |
| time_elapsed       | 193          |
| total_timesteps    | 385024       |
| value_loss         | 0.0342122    |
-------------------------------------
-------------------------------------
| approxkl           | 0.009196738  |
| clipfrac           | 0.12460937   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.724        |
| fps                | 2186         |
| n_updates          | 189          |
| policy_entropy     | 6.0147886    |
| policy_loss        | -0.008824279 |
| serial_timesteps   | 48384        |
| time_elapsed       | 194          |
| total_timesteps    | 387072       |
| value_loss         | 0.041243665  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0076733967 |
| clipfrac           | 0.10239258   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.843        |
| fps                | 2262         |
| n_updates          | 190          |
| policy_entropy     | 5.982266     |
| policy_loss        | -0.009634818 |
| serial_timesteps   | 48640        |
| time_elapsed       | 195          |
| total_timesteps    | 389120       |
| value_loss         | 0.023539107  |
-------------------------------------
Eval num_timesteps=390000, episode_reward=-1.63 +/- 0.50
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0106630195 |
| clipfrac           | 0.15078124   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.752        |
| fps                | 1591         |
| n_updates          | 191          |
| policy_entropy     | 5.965066     |
| policy_loss        | -0.010493352 |
| serial_timesteps   | 48896        |
| time_elapsed       | 195          |
| total_timesteps    | 391168       |
| value_loss         | 0.031621613  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010764474  |
| clipfrac           | 0.14882812   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.768        |
| fps                | 2219         |
| n_updates          | 192          |
| policy_entropy     | 5.9357634    |
| policy_loss        | -0.013700535 |
| serial_timesteps   | 49152        |
| time_elapsed       | 197          |
| total_timesteps    | 393216       |
| value_loss         | 0.034961127  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009323617  |
| clipfrac           | 0.13432617   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.778        |
| fps                | 2172         |
| n_updates          | 193          |
| policy_entropy     | 5.9096875    |
| policy_loss        | -0.007766761 |
| serial_timesteps   | 49408        |
| time_elapsed       | 198          |
| total_timesteps    | 395264       |
| value_loss         | 0.03616474   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0082725845  |
| clipfrac           | 0.11171875    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.53         |
| explained_variance | 0.713         |
| fps                | 2220          |
| n_updates          | 194           |
| policy_entropy     | 5.878544      |
| policy_loss        | -0.0056844014 |
| serial_timesteps   | 49664         |
| time_elapsed       | 199           |
| total_timesteps    | 397312        |
| value_loss         | 0.045966696   |
--------------------------------------
--------------------------------------
| approxkl           | 0.008691596   |
| clipfrac           | 0.11757813    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.51         |
| explained_variance | 0.839         |
| fps                | 2236          |
| n_updates          | 195           |
| policy_entropy     | 5.835593      |
| policy_loss        | -0.0057804575 |
| serial_timesteps   | 49920         |
| time_elapsed       | 200           |
| total_timesteps    | 399360        |
| value_loss         | 0.023474196   |
--------------------------------------
Eval num_timesteps=400000, episode_reward=-1.75 +/- 0.89
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.009559279 |
| clipfrac           | 0.1328125   |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.51       |
| explained_variance | 0.792       |
| fps                | 1577        |
| n_updates          | 196         |
| policy_entropy     | 5.817276    |
| policy_loss        | -0.01211329 |
| serial_timesteps   | 50176       |
| time_elapsed       | 200         |
| total_timesteps    | 401408      |
| value_loss         | 0.024179187 |
------------------------------------
-------------------------------------
| approxkl           | 0.009746793  |
| clipfrac           | 0.13847657   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.761        |
| fps                | 2144         |
| n_updates          | 197          |
| policy_entropy     | 5.8111963    |
| policy_loss        | -0.009500671 |
| serial_timesteps   | 50432        |
| time_elapsed       | 202          |
| total_timesteps    | 403456       |
| value_loss         | 0.042552363  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00942143   |
| clipfrac           | 0.13535157   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.838        |
| fps                | 2193         |
| n_updates          | 198          |
| policy_entropy     | 5.778662     |
| policy_loss        | -0.010710331 |
| serial_timesteps   | 50688        |
| time_elapsed       | 203          |
| total_timesteps    | 405504       |
| value_loss         | 0.02185441   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009886186  |
| clipfrac           | 0.1409668    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.793        |
| fps                | 2194         |
| n_updates          | 199          |
| policy_entropy     | 5.747321     |
| policy_loss        | -0.011410485 |
| serial_timesteps   | 50944        |
| time_elapsed       | 204          |
| total_timesteps    | 407552       |
| value_loss         | 0.03532877   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010138629  |
| clipfrac           | 0.1459961    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.796        |
| fps                | 2154         |
| n_updates          | 200          |
| policy_entropy     | 5.752136     |
| policy_loss        | -0.009639451 |
| serial_timesteps   | 51200        |
| time_elapsed       | 205          |
| total_timesteps    | 409600       |
| value_loss         | 0.029932017  |
-------------------------------------
Eval num_timesteps=410000, episode_reward=-1.52 +/- 1.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010118255  |
| clipfrac           | 0.14716797   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.81         |
| fps                | 1545         |
| n_updates          | 201          |
| policy_entropy     | 5.749747     |
| policy_loss        | -0.011910399 |
| serial_timesteps   | 51456        |
| time_elapsed       | 206          |
| total_timesteps    | 411648       |
| value_loss         | 0.028677404  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0117675485 |
| clipfrac           | 0.17055663   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.86         |
| fps                | 2220         |
| n_updates          | 202          |
| policy_entropy     | 5.734374     |
| policy_loss        | -0.010677585 |
| serial_timesteps   | 51712        |
| time_elapsed       | 207          |
| total_timesteps    | 413696       |
| value_loss         | 0.024709638  |
-------------------------------------
-------------------------------------
| approxkl           | 0.011136869  |
| clipfrac           | 0.15786132   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.789        |
| fps                | 2186         |
| n_updates          | 203          |
| policy_entropy     | 5.7032957    |
| policy_loss        | -0.010431984 |
| serial_timesteps   | 51968        |
| time_elapsed       | 208          |
| total_timesteps    | 415744       |
| value_loss         | 0.039538108  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010639156  |
| clipfrac           | 0.14858398   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.863        |
| fps                | 2266         |
| n_updates          | 204          |
| policy_entropy     | 5.688037     |
| policy_loss        | -0.011679563 |
| serial_timesteps   | 52224        |
| time_elapsed       | 209          |
| total_timesteps    | 417792       |
| value_loss         | 0.023400268  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009650873  |
| clipfrac           | 0.1383789    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.853        |
| fps                | 2102         |
| n_updates          | 205          |
| policy_entropy     | 5.6685333    |
| policy_loss        | -0.008550921 |
| serial_timesteps   | 52480        |
| time_elapsed       | 210          |
| total_timesteps    | 419840       |
| value_loss         | 0.01871319   |
-------------------------------------
Eval num_timesteps=420000, episode_reward=-1.72 +/- 0.54
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.012311427  |
| clipfrac           | 0.16381836   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.758        |
| fps                | 1514         |
| n_updates          | 206          |
| policy_entropy     | 5.655573     |
| policy_loss        | -0.013649966 |
| serial_timesteps   | 52736        |
| time_elapsed       | 211          |
| total_timesteps    | 421888       |
| value_loss         | 0.044282176  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010177839  |
| clipfrac           | 0.14013672   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.78         |
| fps                | 2121         |
| n_updates          | 207          |
| policy_entropy     | 5.6420007    |
| policy_loss        | -0.010565147 |
| serial_timesteps   | 52992        |
| time_elapsed       | 212          |
| total_timesteps    | 423936       |
| value_loss         | 0.04033946   |
-------------------------------------
--------------------------------------
| approxkl           | 0.007086599   |
| clipfrac           | 0.091552734   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.53         |
| explained_variance | 0.866         |
| fps                | 1968          |
| n_updates          | 208           |
| policy_entropy     | 5.615557      |
| policy_loss        | -0.0046571856 |
| serial_timesteps   | 53248         |
| time_elapsed       | 213           |
| total_timesteps    | 425984        |
| value_loss         | 0.02743188    |
--------------------------------------
--------------------------------------
| approxkl           | 0.008648416   |
| clipfrac           | 0.12138672    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.57         |
| explained_variance | 0.823         |
| fps                | 2054          |
| n_updates          | 209           |
| policy_entropy     | 5.581532      |
| policy_loss        | -0.0053917943 |
| serial_timesteps   | 53504         |
| time_elapsed       | 214           |
| total_timesteps    | 428032        |
| value_loss         | 0.03795524    |
--------------------------------------
Eval num_timesteps=430000, episode_reward=-1.95 +/- 0.61
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.008578778 |
| clipfrac           | 0.12104492  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.62       |
| explained_variance | 0.857       |
| fps                | 1537        |
| n_updates          | 210         |
| policy_entropy     | 5.567673    |
| policy_loss        | -0.00944263 |
| serial_timesteps   | 53760       |
| time_elapsed       | 215         |
| total_timesteps    | 430080      |
| value_loss         | 0.024509236 |
------------------------------------
------------------------------------
| approxkl           | 0.010205748 |
| clipfrac           | 0.14731446  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.63       |
| explained_variance | 0.861       |
| fps                | 2211        |
| n_updates          | 211         |
| policy_entropy     | 5.5642104   |
| policy_loss        | -0.00710844 |
| serial_timesteps   | 54016       |
| time_elapsed       | 216         |
| total_timesteps    | 432128      |
| value_loss         | 0.020026235 |
------------------------------------
------------------------------------
| approxkl           | 0.010369319 |
| clipfrac           | 0.14282227  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.57       |
| explained_variance | 0.676       |
| fps                | 2232        |
| n_updates          | 212         |
| policy_entropy     | 5.547073    |
| policy_loss        | -0.01145971 |
| serial_timesteps   | 54272       |
| time_elapsed       | 217         |
| total_timesteps    | 434176      |
| value_loss         | 0.042738736 |
------------------------------------
--------------------------------------
| approxkl           | 0.010526176   |
| clipfrac           | 0.15283203    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.53         |
| explained_variance | 0.834         |
| fps                | 2169          |
| n_updates          | 213           |
| policy_entropy     | 5.543763      |
| policy_loss        | -0.0075733922 |
| serial_timesteps   | 54528         |
| time_elapsed       | 218           |
| total_timesteps    | 436224        |
| value_loss         | 0.028482001   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010386732  |
| clipfrac           | 0.14956054   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.755        |
| fps                | 2265         |
| n_updates          | 214          |
| policy_entropy     | 5.534724     |
| policy_loss        | -0.008948227 |
| serial_timesteps   | 54784        |
| time_elapsed       | 219          |
| total_timesteps    | 438272       |
| value_loss         | 0.037379265  |
-------------------------------------
Eval num_timesteps=440000, episode_reward=-1.82 +/- 0.84
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009927085  |
| clipfrac           | 0.13803712   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.815        |
| fps                | 1575         |
| n_updates          | 215          |
| policy_entropy     | 5.519973     |
| policy_loss        | -0.006841323 |
| serial_timesteps   | 55040        |
| time_elapsed       | 220          |
| total_timesteps    | 440320       |
| value_loss         | 0.022824835  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008714432   |
| clipfrac           | 0.12319336    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.38         |
| explained_variance | 0.657         |
| fps                | 2210          |
| n_updates          | 216           |
| policy_entropy     | 5.52784       |
| policy_loss        | -0.0068948083 |
| serial_timesteps   | 55296         |
| time_elapsed       | 221           |
| total_timesteps    | 442368        |
| value_loss         | 0.049912393   |
--------------------------------------
------------------------------------
| approxkl           | 0.008582388 |
| clipfrac           | 0.11665039  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.51       |
| explained_variance | 0.715       |
| fps                | 2151        |
| n_updates          | 217         |
| policy_entropy     | 5.5334487   |
| policy_loss        | -0.00658065 |
| serial_timesteps   | 55552       |
| time_elapsed       | 222         |
| total_timesteps    | 444416      |
| value_loss         | 0.052329667 |
------------------------------------
--------------------------------------
| approxkl           | 0.009355234   |
| clipfrac           | 0.12773438    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.54         |
| explained_variance | 0.854         |
| fps                | 2178          |
| n_updates          | 218           |
| policy_entropy     | 5.5414352     |
| policy_loss        | -0.0064415773 |
| serial_timesteps   | 55808         |
| time_elapsed       | 223           |
| total_timesteps    | 446464        |
| value_loss         | 0.02355691    |
--------------------------------------
-------------------------------------
| approxkl           | 0.009035437  |
| clipfrac           | 0.12871094   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.755        |
| fps                | 2191         |
| n_updates          | 219          |
| policy_entropy     | 5.536969     |
| policy_loss        | -0.009772839 |
| serial_timesteps   | 56064        |
| time_elapsed       | 224          |
| total_timesteps    | 448512       |
| value_loss         | 0.03847976   |
-------------------------------------
Eval num_timesteps=450000, episode_reward=-1.42 +/- 0.74
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.008626998   |
| clipfrac           | 0.11826172    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.58         |
| explained_variance | 0.804         |
| fps                | 1520          |
| n_updates          | 220           |
| policy_entropy     | 5.51907       |
| policy_loss        | -0.0049964534 |
| serial_timesteps   | 56320         |
| time_elapsed       | 225           |
| total_timesteps    | 450560        |
| value_loss         | 0.040376842   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0096037015 |
| clipfrac           | 0.13125      |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.779        |
| fps                | 2214         |
| n_updates          | 221          |
| policy_entropy     | 5.5105114    |
| policy_loss        | -0.007634123 |
| serial_timesteps   | 56576        |
| time_elapsed       | 226          |
| total_timesteps    | 452608       |
| value_loss         | 0.029368928  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010242475  |
| clipfrac           | 0.14658204   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.854        |
| fps                | 2268         |
| n_updates          | 222          |
| policy_entropy     | 5.5242295    |
| policy_loss        | -0.010564399 |
| serial_timesteps   | 56832        |
| time_elapsed       | 227          |
| total_timesteps    | 454656       |
| value_loss         | 0.024626045  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010633358  |
| clipfrac           | 0.15170899   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.767        |
| fps                | 2202         |
| n_updates          | 223          |
| policy_entropy     | 5.535579     |
| policy_loss        | -0.010742693 |
| serial_timesteps   | 57088        |
| time_elapsed       | 228          |
| total_timesteps    | 456704       |
| value_loss         | 0.035197955  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009161248  |
| clipfrac           | 0.13002929   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.744        |
| fps                | 2226         |
| n_updates          | 224          |
| policy_entropy     | 5.544017     |
| policy_loss        | -0.010409315 |
| serial_timesteps   | 57344        |
| time_elapsed       | 229          |
| total_timesteps    | 458752       |
| value_loss         | 0.05546143   |
-------------------------------------
Eval num_timesteps=460000, episode_reward=-1.18 +/- 0.48
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010098921  |
| clipfrac           | 0.14072266   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.81         |
| fps                | 1568         |
| n_updates          | 225          |
| policy_entropy     | 5.5649695    |
| policy_loss        | -0.008850133 |
| serial_timesteps   | 57600        |
| time_elapsed       | 230          |
| total_timesteps    | 460800       |
| value_loss         | 0.029394325  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009794576   |
| clipfrac           | 0.13544922    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.48         |
| explained_variance | 0.843         |
| fps                | 2222          |
| n_updates          | 226           |
| policy_entropy     | 5.5739546     |
| policy_loss        | -0.0085962815 |
| serial_timesteps   | 57856         |
| time_elapsed       | 231           |
| total_timesteps    | 462848        |
| value_loss         | 0.024888737   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010277906  |
| clipfrac           | 0.14863281   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.872        |
| fps                | 2213         |
| n_updates          | 227          |
| policy_entropy     | 5.551961     |
| policy_loss        | -0.010624298 |
| serial_timesteps   | 58112        |
| time_elapsed       | 232          |
| total_timesteps    | 464896       |
| value_loss         | 0.020541968  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010731302  |
| clipfrac           | 0.16025391   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.816        |
| fps                | 2248         |
| n_updates          | 228          |
| policy_entropy     | 5.532113     |
| policy_loss        | -0.011180509 |
| serial_timesteps   | 58368        |
| time_elapsed       | 233          |
| total_timesteps    | 466944       |
| value_loss         | 0.027160242  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008994319  |
| clipfrac           | 0.120751955  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.679        |
| fps                | 2185         |
| n_updates          | 229          |
| policy_entropy     | 5.5423307    |
| policy_loss        | -0.006962929 |
| serial_timesteps   | 58624        |
| time_elapsed       | 234          |
| total_timesteps    | 468992       |
| value_loss         | 0.05148828   |
-------------------------------------
Eval num_timesteps=470000, episode_reward=-1.85 +/- 1.05
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0099692    |
| clipfrac           | 0.13969727   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.669        |
| fps                | 1564         |
| n_updates          | 230          |
| policy_entropy     | 5.5833716    |
| policy_loss        | -0.007984725 |
| serial_timesteps   | 58880        |
| time_elapsed       | 235          |
| total_timesteps    | 471040       |
| value_loss         | 0.04620011   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010018535  |
| clipfrac           | 0.13208008   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.816        |
| fps                | 2215         |
| n_updates          | 231          |
| policy_entropy     | 5.588645     |
| policy_loss        | -0.008229216 |
| serial_timesteps   | 59136        |
| time_elapsed       | 236          |
| total_timesteps    | 473088       |
| value_loss         | 0.035571463  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00912253   |
| clipfrac           | 0.12451172   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.744        |
| fps                | 2167         |
| n_updates          | 232          |
| policy_entropy     | 5.5524893    |
| policy_loss        | -0.007620269 |
| serial_timesteps   | 59392        |
| time_elapsed       | 237          |
| total_timesteps    | 475136       |
| value_loss         | 0.037707467  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0116791725 |
| clipfrac           | 0.16796875   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.705        |
| fps                | 2156         |
| n_updates          | 233          |
| policy_entropy     | 5.528814     |
| policy_loss        | -0.010353814 |
| serial_timesteps   | 59648        |
| time_elapsed       | 238          |
| total_timesteps    | 477184       |
| value_loss         | 0.05408001   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009826594  |
| clipfrac           | 0.13979492   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.728        |
| fps                | 2246         |
| n_updates          | 234          |
| policy_entropy     | 5.5072956    |
| policy_loss        | -0.008830117 |
| serial_timesteps   | 59904        |
| time_elapsed       | 239          |
| total_timesteps    | 479232       |
| value_loss         | 0.05322678   |
-------------------------------------
Eval num_timesteps=480000, episode_reward=-1.76 +/- 1.09
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010639809  |
| clipfrac           | 0.15249023   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.724        |
| fps                | 1579         |
| n_updates          | 235          |
| policy_entropy     | 5.4920716    |
| policy_loss        | -0.011348844 |
| serial_timesteps   | 60160        |
| time_elapsed       | 240          |
| total_timesteps    | 481280       |
| value_loss         | 0.03976421   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0113374805  |
| clipfrac           | 0.1652832     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.54         |
| explained_variance | 0.836         |
| fps                | 2210          |
| n_updates          | 236           |
| policy_entropy     | 5.4737782     |
| policy_loss        | -0.0100296065 |
| serial_timesteps   | 60416         |
| time_elapsed       | 241           |
| total_timesteps    | 483328        |
| value_loss         | 0.030351106   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009764081  |
| clipfrac           | 0.14208984   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.714        |
| fps                | 2184         |
| n_updates          | 237          |
| policy_entropy     | 5.467281     |
| policy_loss        | -0.008916697 |
| serial_timesteps   | 60672        |
| time_elapsed       | 242          |
| total_timesteps    | 485376       |
| value_loss         | 0.048503675  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008248031  |
| clipfrac           | 0.11411133   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.84         |
| fps                | 2277         |
| n_updates          | 238          |
| policy_entropy     | 5.472662     |
| policy_loss        | -0.002069632 |
| serial_timesteps   | 60928        |
| time_elapsed       | 243          |
| total_timesteps    | 487424       |
| value_loss         | 0.031747192  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010294399  |
| clipfrac           | 0.14667968   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.831        |
| fps                | 2247         |
| n_updates          | 239          |
| policy_entropy     | 5.4659657    |
| policy_loss        | -0.010115271 |
| serial_timesteps   | 61184        |
| time_elapsed       | 244          |
| total_timesteps    | 489472       |
| value_loss         | 0.022892848  |
-------------------------------------
Eval num_timesteps=490000, episode_reward=-2.00 +/- 0.93
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.011525184  |
| clipfrac           | 0.1649414    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.869        |
| fps                | 1527         |
| n_updates          | 240          |
| policy_entropy     | 5.4427533    |
| policy_loss        | -0.013440341 |
| serial_timesteps   | 61440        |
| time_elapsed       | 245          |
| total_timesteps    | 491520       |
| value_loss         | 0.02293628   |
-------------------------------------
-------------------------------------
| approxkl           | 0.011810611  |
| clipfrac           | 0.16821289   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.767        |
| fps                | 2238         |
| n_updates          | 241          |
| policy_entropy     | 5.441674     |
| policy_loss        | -0.010815553 |
| serial_timesteps   | 61696        |
| time_elapsed       | 246          |
| total_timesteps    | 493568       |
| value_loss         | 0.024781013  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010055327  |
| clipfrac           | 0.13979492   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.855        |
| fps                | 2260         |
| n_updates          | 242          |
| policy_entropy     | 5.449515     |
| policy_loss        | -0.010013868 |
| serial_timesteps   | 61952        |
| time_elapsed       | 247          |
| total_timesteps    | 495616       |
| value_loss         | 0.021330385  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009864001   |
| clipfrac           | 0.14033203    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.5          |
| explained_variance | 0.805         |
| fps                | 2230          |
| n_updates          | 243           |
| policy_entropy     | 5.435475      |
| policy_loss        | -0.0090421075 |
| serial_timesteps   | 62208         |
| time_elapsed       | 248           |
| total_timesteps    | 497664        |
| value_loss         | 0.034498617   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009236425  |
| clipfrac           | 0.12714843   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.757        |
| fps                | 2245         |
| n_updates          | 244          |
| policy_entropy     | 5.43201      |
| policy_loss        | -0.010910461 |
| serial_timesteps   | 62464        |
| time_elapsed       | 249          |
| total_timesteps    | 499712       |
| value_loss         | 0.05273234   |
-------------------------------------
Saving to logs/train_0.5M_widowx_reacher-v7_KAY/ppo2/widowx_reacher-v7_2
pybullet build time: May 18 2020 02:46:26
