[sonicgpu1.compute:29184] pml_ucx.c:285  Error: UCP worker does not support MPI_THREAD_MULTIPLE
WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:141: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/sac/policies.py:194: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:From /home/people/paumjaud/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:254: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/people/paumjaud/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:294: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:314: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

========== widowx_reacher-v5 ==========
Seed: 1
OrderedDict([('batch_size', 32),
             ('buffer_size', 100000),
             ('ent_coef', 0.0001),
             ('gamma', 0.95),
             ('gradient_steps', 1),
             ('learning_rate', 0.0014704926021044404),
             ('learning_starts', 0),
             ('n_timesteps', 60000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs', 'dict(layers=[256, 256])'),
             ('train_freq', 1)])
Using 1 environments
Overwriting n_timesteps with n=200000
Creating test environment
TRAINING ENV TYPE :  <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7fa8bdab0160>
EVAL ENV TYPE :  <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7fa8bdab7c50>
Log path: logs/train_0.2M_widowx_reacher-v5_SONIC/sac/widowx_reacher-v5_2
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -2.3116837    |
| ep_rewmean              | -3.62         |
| episodes                | 4             |
| eplenmean               | 100           |
| fps                     | 150           |
| mean 100 episode reward | -3.6          |
| n_updates               | 269           |
| policy_loss             | 0.20177911    |
| qf1_loss                | 0.00018188791 |
| qf2_loss                | 0.00015104172 |
| time_elapsed            | 1             |
| total timesteps         | 300           |
| value_loss              | 0.00041250317 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -3.6984994    |
| ep_rewmean              | -3.22         |
| episodes                | 8             |
| eplenmean               | 100           |
| fps                     | 176           |
| mean 100 episode reward | -3.2          |
| n_updates               | 669           |
| policy_loss             | 0.1647402     |
| qf1_loss                | 4.657084e-05  |
| qf2_loss                | 0.00011813592 |
| time_elapsed            | 3             |
| total timesteps         | 700           |
| value_loss              | 8.3956475e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -2.6221964    |
| ep_rewmean              | -2.49         |
| episodes                | 12            |
| eplenmean               | 100           |
| fps                     | 185           |
| mean 100 episode reward | -2.5          |
| n_updates               | 1069          |
| policy_loss             | 0.1797231     |
| qf1_loss                | 4.129571e-05  |
| qf2_loss                | 2.5525416e-05 |
| time_elapsed            | 5             |
| total timesteps         | 1100          |
| value_loss              | 0.00015329014 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -3.8604488    |
| ep_rewmean              | -2.3          |
| episodes                | 16            |
| eplenmean               | 100           |
| fps                     | 189           |
| mean 100 episode reward | -2.3          |
| n_updates               | 1469          |
| policy_loss             | 0.16576084    |
| qf1_loss                | 1.5253684e-05 |
| qf2_loss                | 2.1614975e-05 |
| time_elapsed            | 7             |
| total timesteps         | 1500          |
| value_loss              | 4.655111e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -0.7830845    |
| ep_rewmean              | -2.18         |
| episodes                | 20            |
| eplenmean               | 100           |
| fps                     | 191           |
| mean 100 episode reward | -2.2          |
| n_updates               | 1869          |
| policy_loss             | 0.17774835    |
| qf1_loss                | 4.3653672e-05 |
| qf2_loss                | 2.7658749e-05 |
| time_elapsed            | 9             |
| total timesteps         | 1900          |
| value_loss              | 7.227861e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | -3.4035249   |
| ep_rewmean              | -1.94        |
| episodes                | 24           |
| eplenmean               | 100          |
| fps                     | 192          |
| mean 100 episode reward | -1.9         |
| n_updates               | 2269         |
| policy_loss             | 0.13746572   |
| qf1_loss                | 7.599923e-05 |
| qf2_loss                | 8.332371e-05 |
| time_elapsed            | 11           |
| total timesteps         | 2300         |
| value_loss              | 8.933951e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -2.4773383    |
| ep_rewmean              | -1.78         |
| episodes                | 28            |
| eplenmean               | 100           |
| fps                     | 194           |
| mean 100 episode reward | -1.8          |
| n_updates               | 2669          |
| policy_loss             | 0.17544845    |
| qf1_loss                | 2.9240327e-05 |
| qf2_loss                | 1.7530612e-05 |
| time_elapsed            | 13            |
| total timesteps         | 2700          |
| value_loss              | 3.8346912e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -3.051301     |
| ep_rewmean              | -1.65         |
| episodes                | 32            |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.6          |
| n_updates               | 3069          |
| policy_loss             | 0.15677583    |
| qf1_loss                | 2.9496503e-05 |
| qf2_loss                | 3.850474e-05  |
| time_elapsed            | 15            |
| total timesteps         | 3100          |
| value_loss              | 0.00012310904 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -3.874739     |
| ep_rewmean              | -1.54         |
| episodes                | 36            |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.5          |
| n_updates               | 3469          |
| policy_loss             | 0.1709876     |
| qf1_loss                | 6.987918e-06  |
| qf2_loss                | 1.9133484e-05 |
| time_elapsed            | 17            |
| total timesteps         | 3500          |
| value_loss              | 7.157215e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -3.2412913    |
| ep_rewmean              | -1.41         |
| episodes                | 40            |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 3869          |
| policy_loss             | 0.13648082    |
| qf1_loss                | 9.020376e-06  |
| qf2_loss                | 8.661971e-06  |
| time_elapsed            | 19            |
| total timesteps         | 3900          |
| value_loss              | 3.3692082e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 1.7488859     |
| ep_rewmean              | -1.32         |
| episodes                | 44            |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 4269          |
| policy_loss             | 0.122248374   |
| qf1_loss                | 2.1936874e-05 |
| qf2_loss                | 2.2161817e-05 |
| time_elapsed            | 21            |
| total timesteps         | 4300          |
| value_loss              | 8.570314e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 1.1056018     |
| ep_rewmean              | -1.24         |
| episodes                | 48            |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 4669          |
| policy_loss             | 0.12307976    |
| qf1_loss                | 2.5842925e-05 |
| qf2_loss                | 3.576842e-05  |
| time_elapsed            | 23            |
| total timesteps         | 4700          |
| value_loss              | 9.259675e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -2.1556315    |
| ep_rewmean              | -1.16         |
| episodes                | 52            |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 5069          |
| policy_loss             | 0.13206948    |
| qf1_loss                | 6.648482e-06  |
| qf2_loss                | 1.0486083e-05 |
| time_elapsed            | 25            |
| total timesteps         | 5100          |
| value_loss              | 2.0611385e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -2.6232953    |
| ep_rewmean              | -1.09         |
| episodes                | 56            |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 5469          |
| policy_loss             | 0.12841523    |
| qf1_loss                | 1.4176754e-05 |
| qf2_loss                | 1.1456631e-05 |
| time_elapsed            | 27            |
| total timesteps         | 5500          |
| value_loss              | 1.5930553e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -3.3377533    |
| ep_rewmean              | -1.03         |
| episodes                | 60            |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 5869          |
| policy_loss             | 0.10621852    |
| qf1_loss                | 1.3957713e-05 |
| qf2_loss                | 1.0787436e-05 |
| time_elapsed            | 29            |
| total timesteps         | 5900          |
| value_loss              | 2.0035883e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -2.3597524    |
| ep_rewmean              | -0.993        |
| episodes                | 64            |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 6269          |
| policy_loss             | 0.090871535   |
| qf1_loss                | 5.5200504e-05 |
| qf2_loss                | 5.2805626e-05 |
| time_elapsed            | 31            |
| total timesteps         | 6300          |
| value_loss              | 6.460818e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -1.8451016    |
| ep_rewmean              | -0.944        |
| episodes                | 68            |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 6669          |
| policy_loss             | 0.08323476    |
| qf1_loss                | 1.2419007e-05 |
| qf2_loss                | 9.793992e-06  |
| time_elapsed            | 33            |
| total timesteps         | 6700          |
| value_loss              | 1.1209018e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -3.018664     |
| ep_rewmean              | -0.917        |
| episodes                | 72            |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 7069          |
| policy_loss             | 0.09448281    |
| qf1_loss                | 1.0878761e-05 |
| qf2_loss                | 1.0098443e-05 |
| time_elapsed            | 35            |
| total timesteps         | 7100          |
| value_loss              | 6.297594e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -2.1109462    |
| ep_rewmean              | -0.879        |
| episodes                | 76            |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 7469          |
| policy_loss             | 0.07725818    |
| qf1_loss                | 1.1241422e-05 |
| qf2_loss                | 1.5205031e-05 |
| time_elapsed            | 37            |
| total timesteps         | 7500          |
| value_loss              | 8.138655e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -2.5690367    |
| ep_rewmean              | -0.844        |
| episodes                | 80            |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 7869          |
| policy_loss             | 0.06977209    |
| qf1_loss                | 2.9663418e-06 |
| qf2_loss                | 3.5379448e-06 |
| time_elapsed            | 39            |
| total timesteps         | 7900          |
| value_loss              | 1.0932292e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -2.506044     |
| ep_rewmean              | -0.812        |
| episodes                | 84            |
| eplenmean               | 100           |
| fps                     | 198           |
| mean 100 episode reward | -0.8          |
| n_updates               | 8269          |
| policy_loss             | 0.07729027    |
| qf1_loss                | 3.6812038e-05 |
| qf2_loss                | 2.728518e-05  |
| time_elapsed            | 41            |
| total timesteps         | 8300          |
| value_loss              | 2.9914916e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -1.6160922    |
| ep_rewmean              | -0.784        |
| episodes                | 88            |
| eplenmean               | 100           |
| fps                     | 198           |
| mean 100 episode reward | -0.8          |
| n_updates               | 8669          |
| policy_loss             | 0.060421504   |
| qf1_loss                | 5.3736876e-06 |
| qf2_loss                | 7.5651933e-06 |
| time_elapsed            | 43            |
| total timesteps         | 8700          |
| value_loss              | 1.5464226e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -1.7849927    |
| ep_rewmean              | -0.77         |
| episodes                | 92            |
| eplenmean               | 100           |
| fps                     | 198           |
| mean 100 episode reward | -0.8          |
| n_updates               | 9069          |
| policy_loss             | 0.07232859    |
| qf1_loss                | 7.970271e-06  |
| qf2_loss                | 3.648568e-06  |
| time_elapsed            | 45            |
| total timesteps         | 9100          |
| value_loss              | 5.2020805e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | -0.7376001   |
| ep_rewmean              | -0.761       |
| episodes                | 96           |
| eplenmean               | 100          |
| fps                     | 198          |
| mean 100 episode reward | -0.8         |
| n_updates               | 9469         |
| policy_loss             | 0.07640092   |
| qf1_loss                | 6.357094e-05 |
| qf2_loss                | 6.433338e-05 |
| time_elapsed            | 47           |
| total timesteps         | 9500         |
| value_loss              | 5.802889e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.5798533     |
| ep_rewmean              | -0.751        |
| episodes                | 100           |
| eplenmean               | 100           |
| fps                     | 198           |
| mean 100 episode reward | -0.8          |
| n_updates               | 9869          |
| policy_loss             | 0.06245164    |
| qf1_loss                | 3.036966e-06  |
| qf2_loss                | 4.0184636e-06 |
| time_elapsed            | 49            |
| total timesteps         | 9900          |
| value_loss              | 2.4432552e-06 |
-------------------------------------------
Eval num_timesteps=10000, episode_reward=-0.43 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -0.3599649    |
| ep_rewmean              | -0.65         |
| episodes                | 104           |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 10269         |
| policy_loss             | 0.058382876   |
| qf1_loss                | 3.3983588e-06 |
| qf2_loss                | 4.3830582e-06 |
| time_elapsed            | 52            |
| total timesteps         | 10300         |
| value_loss              | 7.117247e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 1.3477355     |
| ep_rewmean              | -0.548        |
| episodes                | 108           |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 10669         |
| policy_loss             | 0.056816578   |
| qf1_loss                | 1.781787e-06  |
| qf2_loss                | 3.2377063e-06 |
| time_elapsed            | 54            |
| total timesteps         | 10700         |
| value_loss              | 6.785741e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.36535       |
| ep_rewmean              | -0.516        |
| episodes                | 112           |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 11069         |
| policy_loss             | 0.07574712    |
| qf1_loss                | 3.4776708e-06 |
| qf2_loss                | 3.1082864e-06 |
| time_elapsed            | 56            |
| total timesteps         | 11100         |
| value_loss              | 1.0994555e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 1.1625286     |
| ep_rewmean              | -0.457        |
| episodes                | 116           |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 11469         |
| policy_loss             | 0.06560715    |
| qf1_loss                | 4.307198e-06  |
| qf2_loss                | 2.3598755e-06 |
| time_elapsed            | 58            |
| total timesteps         | 11500         |
| value_loss              | 8.549428e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | -0.72287554   |
| ep_rewmean              | -0.399        |
| episodes                | 120           |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.4          |
| n_updates               | 11869         |
| policy_loss             | 0.06922187    |
| qf1_loss                | 3.4307361e-06 |
| qf2_loss                | 3.0519604e-06 |
| time_elapsed            | 60            |
| total timesteps         | 11900         |
| value_loss              | 8.166855e-06  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 2.5616474    |
| ep_rewmean              | -0.381       |
| episodes                | 124          |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.4         |
| n_updates               | 12269        |
| policy_loss             | 0.062133916  |
| qf1_loss                | 2.413526e-06 |
| qf2_loss                | 2.255917e-06 |
| time_elapsed            | 62           |
| total timesteps         | 12300        |
| value_loss              | 4.666568e-06 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 1.0390747     |
| ep_rewmean              | -0.366        |
| episodes                | 128           |
| eplenmean               | 100           |
| fps                     | 198           |
| mean 100 episode reward | -0.4          |
| n_updates               | 12669         |
| policy_loss             | 0.06643095    |
| qf1_loss                | 5.620045e-05  |
| qf2_loss                | 5.738377e-05  |
| time_elapsed            | 64            |
| total timesteps         | 12700         |
| value_loss              | 1.2108758e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.55273974    |
| ep_rewmean              | -0.35         |
| episodes                | 132           |
| eplenmean               | 100           |
| fps                     | 198           |
| mean 100 episode reward | -0.4          |
| n_updates               | 13069         |
| policy_loss             | 0.059668493   |
| qf1_loss                | 6.786924e-05  |
| qf2_loss                | 6.101882e-05  |
| time_elapsed            | 66            |
| total timesteps         | 13100         |
| value_loss              | 3.6877257e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 1.7189201     |
| ep_rewmean              | -0.358        |
| episodes                | 136           |
| eplenmean               | 100           |
| fps                     | 198           |
| mean 100 episode reward | -0.4          |
| n_updates               | 13469         |
| policy_loss             | 0.077713355   |
| qf1_loss                | 9.1001675e-06 |
| qf2_loss                | 8.2378665e-06 |
| time_elapsed            | 67            |
| total timesteps         | 13500         |
| value_loss              | 3.469835e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.209793      |
| ep_rewmean              | -0.36         |
| episodes                | 140           |
| eplenmean               | 100           |
| fps                     | 199           |
| mean 100 episode reward | -0.4          |
| n_updates               | 13869         |
| policy_loss             | 0.073878504   |
| qf1_loss                | 6.742831e-06  |
| qf2_loss                | 3.3315132e-06 |
| time_elapsed            | 69            |
| total timesteps         | 13900         |
| value_loss              | 1.979389e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 0.12099072    |
| ep_rewmean              | -0.364        |
| episodes                | 144           |
| eplenmean               | 100           |
| fps                     | 199           |
| mean 100 episode reward | -0.4          |
| n_updates               | 14269         |
| policy_loss             | 0.06550808    |
| qf1_loss                | 4.8544257e-06 |
| qf2_loss                | 2.642356e-06  |
| time_elapsed            | 71            |
| total timesteps         | 14300         |
| value_loss              | 4.540354e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.4670405     |
| ep_rewmean              | -0.36         |
| episodes                | 148           |
| eplenmean               | 100           |
| fps                     | 199           |
| mean 100 episode reward | -0.4          |
| n_updates               | 14669         |
| policy_loss             | 0.08359726    |
| qf1_loss                | 6.043054e-06  |
| qf2_loss                | 8.32516e-06   |
| time_elapsed            | 73            |
| total timesteps         | 14700         |
| value_loss              | 2.8390934e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.0334053     |
| ep_rewmean              | -0.36         |
| episodes                | 152           |
| eplenmean               | 100           |
| fps                     | 199           |
| mean 100 episode reward | -0.4          |
| n_updates               | 15069         |
| policy_loss             | 0.07036015    |
| qf1_loss                | 2.0099267e-06 |
| qf2_loss                | 2.3193165e-06 |
| time_elapsed            | 75            |
| total timesteps         | 15100         |
| value_loss              | 1.7915156e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 1.750932      |
| ep_rewmean              | -0.361        |
| episodes                | 156           |
| eplenmean               | 100           |
| fps                     | 199           |
| mean 100 episode reward | -0.4          |
| n_updates               | 15469         |
| policy_loss             | 0.06261137    |
| qf1_loss                | 1.3207439e-06 |
| qf2_loss                | 1.289915e-06  |
| time_elapsed            | 77            |
| total timesteps         | 15500         |
| value_loss              | 6.363489e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.444744      |
| ep_rewmean              | -0.36         |
| episodes                | 160           |
| eplenmean               | 100           |
| fps                     | 199           |
| mean 100 episode reward | -0.4          |
| n_updates               | 15869         |
| policy_loss             | 0.063027166   |
| qf1_loss                | 1.4862821e-06 |
| qf2_loss                | 1.2872882e-06 |
| time_elapsed            | 79            |
| total timesteps         | 15900         |
| value_loss              | 5.3823123e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.0566597     |
| ep_rewmean              | -0.354        |
| episodes                | 164           |
| eplenmean               | 100           |
| fps                     | 199           |
| mean 100 episode reward | -0.4          |
| n_updates               | 16269         |
| policy_loss             | 0.062061224   |
| qf1_loss                | 2.9655516e-06 |
| qf2_loss                | 3.4481077e-06 |
| time_elapsed            | 81            |
| total timesteps         | 16300         |
| value_loss              | 8.2169745e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.9654796     |
| ep_rewmean              | -0.364        |
| episodes                | 168           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.4          |
| n_updates               | 16669         |
| policy_loss             | 0.059584003   |
| qf1_loss                | 3.132909e-06  |
| qf2_loss                | 4.0454643e-06 |
| time_elapsed            | 83            |
| total timesteps         | 16700         |
| value_loss              | 6.706714e-06  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 2.8349972      |
| ep_rewmean              | -0.361         |
| episodes                | 172            |
| eplenmean               | 100            |
| fps                     | 200            |
| mean 100 episode reward | -0.4           |
| n_updates               | 17069          |
| policy_loss             | 0.058390513    |
| qf1_loss                | 0.000118911266 |
| qf2_loss                | 0.00011909944  |
| time_elapsed            | 85             |
| total timesteps         | 17100          |
| value_loss              | 8.933299e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.0332165     |
| ep_rewmean              | -0.391        |
| episodes                | 176           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.4          |
| n_updates               | 17469         |
| policy_loss             | 0.06335889    |
| qf1_loss                | 1.9987624e-06 |
| qf2_loss                | 1.1445038e-06 |
| time_elapsed            | 87            |
| total timesteps         | 17500         |
| value_loss              | 3.961971e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.4530036     |
| ep_rewmean              | -0.421        |
| episodes                | 180           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.4          |
| n_updates               | 17869         |
| policy_loss             | 0.060170628   |
| qf1_loss                | 4.448926e-06  |
| qf2_loss                | 3.4341815e-06 |
| time_elapsed            | 89            |
| total timesteps         | 17900         |
| value_loss              | 4.5452907e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.9003735     |
| ep_rewmean              | -0.431        |
| episodes                | 184           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.4          |
| n_updates               | 18269         |
| policy_loss             | 0.06262787    |
| qf1_loss                | 4.548521e-05  |
| qf2_loss                | 4.7753267e-05 |
| time_elapsed            | 91            |
| total timesteps         | 18300         |
| value_loss              | 9.593365e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.9562688     |
| ep_rewmean              | -0.442        |
| episodes                | 188           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.4          |
| n_updates               | 18669         |
| policy_loss             | 0.06478621    |
| qf1_loss                | 2.643706e-06  |
| qf2_loss                | 2.130551e-06  |
| time_elapsed            | 93            |
| total timesteps         | 18700         |
| value_loss              | 4.4285357e-06 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 2.5621157    |
| ep_rewmean              | -0.462       |
| episodes                | 192          |
| eplenmean               | 100          |
| fps                     | 200          |
| mean 100 episode reward | -0.5         |
| n_updates               | 19069        |
| policy_loss             | 0.05707922   |
| qf1_loss                | 5.230481e-05 |
| qf2_loss                | 5.197387e-05 |
| time_elapsed            | 95           |
| total timesteps         | 19100        |
| value_loss              | 2.682416e-06 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.7439766     |
| ep_rewmean              | -0.47         |
| episodes                | 196           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.5          |
| n_updates               | 19469         |
| policy_loss             | 0.0584308     |
| qf1_loss                | 1.9553709e-06 |
| qf2_loss                | 1.7992681e-06 |
| time_elapsed            | 97            |
| total timesteps         | 19500         |
| value_loss              | 5.857004e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.200019      |
| ep_rewmean              | -0.463        |
| episodes                | 200           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.5          |
| n_updates               | 19869         |
| policy_loss             | 0.070625305   |
| qf1_loss                | 2.3432503e-06 |
| qf2_loss                | 3.047601e-06  |
| time_elapsed            | 99            |
| total timesteps         | 19900         |
| value_loss              | 3.662976e-06  |
-------------------------------------------
Eval num_timesteps=20000, episode_reward=-0.82 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 1.6707737     |
| ep_rewmean              | -0.467        |
| episodes                | 204           |
| eplenmean               | 100           |
| fps                     | 199           |
| mean 100 episode reward | -0.5          |
| n_updates               | 20269         |
| policy_loss             | 0.05502609    |
| qf1_loss                | 1.1987908e-06 |
| qf2_loss                | 2.1848778e-06 |
| time_elapsed            | 101           |
| total timesteps         | 20300         |
| value_loss              | 2.577466e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.0892556     |
| ep_rewmean              | -0.477        |
| episodes                | 208           |
| eplenmean               | 100           |
| fps                     | 199           |
| mean 100 episode reward | -0.5          |
| n_updates               | 20669         |
| policy_loss             | 0.05600548    |
| qf1_loss                | 4.6624744e-05 |
| qf2_loss                | 4.8346556e-05 |
| time_elapsed            | 103           |
| total timesteps         | 20700         |
| value_loss              | 6.185022e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.2199504     |
| ep_rewmean              | -0.475        |
| episodes                | 212           |
| eplenmean               | 100           |
| fps                     | 199           |
| mean 100 episode reward | -0.5          |
| n_updates               | 21069         |
| policy_loss             | 0.05761364    |
| qf1_loss                | 4.2875695e-06 |
| qf2_loss                | 3.042665e-06  |
| time_elapsed            | 105           |
| total timesteps         | 21100         |
| value_loss              | 1.6786726e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.0829275     |
| ep_rewmean              | -0.475        |
| episodes                | 216           |
| eplenmean               | 100           |
| fps                     | 199           |
| mean 100 episode reward | -0.5          |
| n_updates               | 21469         |
| policy_loss             | 0.05725859    |
| qf1_loss                | 1.1174875e-05 |
| qf2_loss                | 7.750209e-06  |
| time_elapsed            | 107           |
| total timesteps         | 21500         |
| value_loss              | 5.139222e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.848747      |
| ep_rewmean              | -0.476        |
| episodes                | 220           |
| eplenmean               | 100           |
| fps                     | 199           |
| mean 100 episode reward | -0.5          |
| n_updates               | 21869         |
| policy_loss             | 0.06317718    |
| qf1_loss                | 1.2983122e-05 |
| qf2_loss                | 8.856063e-06  |
| time_elapsed            | 109           |
| total timesteps         | 21900         |
| value_loss              | 1.9006184e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.5120115     |
| ep_rewmean              | -0.475        |
| episodes                | 224           |
| eplenmean               | 100           |
| fps                     | 199           |
| mean 100 episode reward | -0.5          |
| n_updates               | 22269         |
| policy_loss             | 0.053929955   |
| qf1_loss                | 7.7861936e-05 |
| qf2_loss                | 7.972733e-05  |
| time_elapsed            | 111           |
| total timesteps         | 22300         |
| value_loss              | 3.6020565e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.2680488     |
| ep_rewmean              | -0.473        |
| episodes                | 228           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.5          |
| n_updates               | 22669         |
| policy_loss             | 0.047229856   |
| qf1_loss                | 1.6384802e-06 |
| qf2_loss                | 2.2286436e-06 |
| time_elapsed            | 113           |
| total timesteps         | 22700         |
| value_loss              | 2.8869304e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.1216455     |
| ep_rewmean              | -0.479        |
| episodes                | 232           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.5          |
| n_updates               | 23069         |
| policy_loss             | 0.05487325    |
| qf1_loss                | 2.1035642e-06 |
| qf2_loss                | 2.991329e-06  |
| time_elapsed            | 115           |
| total timesteps         | 23100         |
| value_loss              | 4.9029923e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.1017733     |
| ep_rewmean              | -0.459        |
| episodes                | 236           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.5          |
| n_updates               | 23469         |
| policy_loss             | 0.065924905   |
| qf1_loss                | 8.2276914e-05 |
| qf2_loss                | 7.857857e-05  |
| time_elapsed            | 117           |
| total timesteps         | 23500         |
| value_loss              | 8.097278e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.4087543     |
| ep_rewmean              | -0.464        |
| episodes                | 240           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.5          |
| n_updates               | 23869         |
| policy_loss             | 0.057295177   |
| qf1_loss                | 4.1073006e-05 |
| qf2_loss                | 4.4149645e-05 |
| time_elapsed            | 119           |
| total timesteps         | 23900         |
| value_loss              | 3.2254808e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.4763284     |
| ep_rewmean              | -0.459        |
| episodes                | 244           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.5          |
| n_updates               | 24269         |
| policy_loss             | 0.043946125   |
| qf1_loss                | 3.71416e-05   |
| qf2_loss                | 3.775182e-05  |
| time_elapsed            | 121           |
| total timesteps         | 24300         |
| value_loss              | 2.6413669e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.2931929     |
| ep_rewmean              | -0.456        |
| episodes                | 248           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.5          |
| n_updates               | 24669         |
| policy_loss             | 0.046488285   |
| qf1_loss                | 1.1494457e-06 |
| qf2_loss                | 2.0806851e-06 |
| time_elapsed            | 123           |
| total timesteps         | 24700         |
| value_loss              | 9.786489e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.7179985     |
| ep_rewmean              | -0.457        |
| episodes                | 252           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.5          |
| n_updates               | 25069         |
| policy_loss             | 0.054578476   |
| qf1_loss                | 2.2840046e-05 |
| qf2_loss                | 1.6441043e-05 |
| time_elapsed            | 125           |
| total timesteps         | 25100         |
| value_loss              | 4.3281427e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.7275403     |
| ep_rewmean              | -0.457        |
| episodes                | 256           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.5          |
| n_updates               | 25469         |
| policy_loss             | 0.04926347    |
| qf1_loss                | 3.15893e-05   |
| qf2_loss                | 3.2213222e-05 |
| time_elapsed            | 127           |
| total timesteps         | 25500         |
| value_loss              | 2.643522e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.2445264     |
| ep_rewmean              | -0.456        |
| episodes                | 260           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.5          |
| n_updates               | 25869         |
| policy_loss             | 0.045077454   |
| qf1_loss                | 4.2935237e-05 |
| qf2_loss                | 4.195617e-05  |
| time_elapsed            | 129           |
| total timesteps         | 25900         |
| value_loss              | 2.2032468e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 2.9760711     |
| ep_rewmean              | -0.458        |
| episodes                | 264           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.5          |
| n_updates               | 26269         |
| policy_loss             | 0.04090916    |
| qf1_loss                | 2.6327336e-05 |
| qf2_loss                | 2.519604e-05  |
| time_elapsed            | 131           |
| total timesteps         | 26300         |
| value_loss              | 4.132483e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.3834944     |
| ep_rewmean              | -0.457        |
| episodes                | 268           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.5          |
| n_updates               | 26669         |
| policy_loss             | 0.052286554   |
| qf1_loss                | 4.4858416e-06 |
| qf2_loss                | 7.607328e-06  |
| time_elapsed            | 132           |
| total timesteps         | 26700         |
| value_loss              | 9.875914e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.339705      |
| ep_rewmean              | -0.45         |
| episodes                | 272           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.4          |
| n_updates               | 27069         |
| policy_loss             | 0.0490424     |
| qf1_loss                | 2.0273467e-06 |
| qf2_loss                | 2.7123801e-06 |
| time_elapsed            | 134           |
| total timesteps         | 27100         |
| value_loss              | 2.2736626e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.0023623     |
| ep_rewmean              | -0.42         |
| episodes                | 276           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.4          |
| n_updates               | 27469         |
| policy_loss             | 0.04903983    |
| qf1_loss                | 3.6676279e-06 |
| qf2_loss                | 4.458436e-06  |
| time_elapsed            | 136           |
| total timesteps         | 27500         |
| value_loss              | 4.379003e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 3.588654      |
| ep_rewmean              | -0.393        |
| episodes                | 280           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.4          |
| n_updates               | 27869         |
| policy_loss             | 0.0397738     |
| qf1_loss                | 8.682438e-07  |
| qf2_loss                | 6.261846e-07  |
| time_elapsed            | 138           |
| total timesteps         | 27900         |
| value_loss              | 1.4518193e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.005127      |
| ep_rewmean              | -0.385        |
| episodes                | 284           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.4          |
| n_updates               | 28269         |
| policy_loss             | 0.040275767   |
| qf1_loss                | 9.592379e-07  |
| qf2_loss                | 1.2680262e-06 |
| time_elapsed            | 140           |
| total timesteps         | 28300         |
| value_loss              | 2.3175132e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.1880865     |
| ep_rewmean              | -0.375        |
| episodes                | 288           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.4          |
| n_updates               | 28669         |
| policy_loss             | 0.04859672    |
| qf1_loss                | 4.1947783e-06 |
| qf2_loss                | 4.4057806e-06 |
| time_elapsed            | 142           |
| total timesteps         | 28700         |
| value_loss              | 4.243487e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.3014603     |
| ep_rewmean              | -0.345        |
| episodes                | 292           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.3          |
| n_updates               | 29069         |
| policy_loss             | 0.04028353    |
| qf1_loss                | 3.5461994e-06 |
| qf2_loss                | 6.6041102e-06 |
| time_elapsed            | 144           |
| total timesteps         | 29100         |
| value_loss              | 8.269386e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.6323175     |
| ep_rewmean              | -0.325        |
| episodes                | 296           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.3          |
| n_updates               | 29469         |
| policy_loss             | 0.042643063   |
| qf1_loss                | 2.2416098e-05 |
| qf2_loss                | 2.1608772e-05 |
| time_elapsed            | 146           |
| total timesteps         | 29500         |
| value_loss              | 8.228462e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.127619      |
| ep_rewmean              | -0.321        |
| episodes                | 300           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.3          |
| n_updates               | 29869         |
| policy_loss             | 0.038288854   |
| qf1_loss                | 1.8939515e-06 |
| qf2_loss                | 1.6352597e-06 |
| time_elapsed            | 148           |
| total timesteps         | 29900         |
| value_loss              | 3.829181e-06  |
-------------------------------------------
Eval num_timesteps=30000, episode_reward=-0.30 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.6772118     |
| ep_rewmean              | -0.312        |
| episodes                | 304           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.3          |
| n_updates               | 30269         |
| policy_loss             | 0.04144402    |
| qf1_loss                | 2.0670636e-06 |
| qf2_loss                | 2.1813612e-06 |
| time_elapsed            | 151           |
| total timesteps         | 30300         |
| value_loss              | 2.7507976e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.0043616     |
| ep_rewmean              | -0.298        |
| episodes                | 308           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.3          |
| n_updates               | 30669         |
| policy_loss             | 0.047170505   |
| qf1_loss                | 9.560164e-06  |
| qf2_loss                | 2.9694214e-05 |
| time_elapsed            | 152           |
| total timesteps         | 30700         |
| value_loss              | 4.0950217e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.758624      |
| ep_rewmean              | -0.294        |
| episodes                | 312           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.3          |
| n_updates               | 31069         |
| policy_loss             | 0.039124385   |
| qf1_loss                | 1.8088176e-06 |
| qf2_loss                | 1.4970911e-06 |
| time_elapsed            | 154           |
| total timesteps         | 31100         |
| value_loss              | 7.1581944e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.4772606     |
| ep_rewmean              | -0.293        |
| episodes                | 316           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.3          |
| n_updates               | 31469         |
| policy_loss             | 0.038485724   |
| qf1_loss                | 3.167917e-06  |
| qf2_loss                | 2.4236165e-06 |
| time_elapsed            | 156           |
| total timesteps         | 31500         |
| value_loss              | 3.6939389e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.37689       |
| ep_rewmean              | -0.289        |
| episodes                | 320           |
| eplenmean               | 100           |
| fps                     | 200           |
| mean 100 episode reward | -0.3          |
| n_updates               | 31869         |
| policy_loss             | 0.03886309    |
| qf1_loss                | 4.251939e-05  |
| qf2_loss                | 6.204253e-05  |
| time_elapsed            | 158           |
| total timesteps         | 31900         |
| value_loss              | 1.0435879e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.435406      |
| ep_rewmean              | -0.283        |
| episodes                | 324           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.3          |
| n_updates               | 32269         |
| policy_loss             | 0.040717784   |
| qf1_loss                | 3.8695773e-05 |
| qf2_loss                | 3.9090453e-05 |
| time_elapsed            | 160           |
| total timesteps         | 32300         |
| value_loss              | 4.591843e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.438368      |
| ep_rewmean              | -0.274        |
| episodes                | 328           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.3          |
| n_updates               | 32669         |
| policy_loss             | 0.040519126   |
| qf1_loss                | 1.8443525e-06 |
| qf2_loss                | 3.4144964e-06 |
| time_elapsed            | 162           |
| total timesteps         | 32700         |
| value_loss              | 2.9208518e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.769747      |
| ep_rewmean              | -0.26         |
| episodes                | 332           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.3          |
| n_updates               | 33069         |
| policy_loss             | 0.037760504   |
| qf1_loss                | 9.579583e-07  |
| qf2_loss                | 1.7137238e-06 |
| time_elapsed            | 164           |
| total timesteps         | 33100         |
| value_loss              | 2.516324e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.109437      |
| ep_rewmean              | -0.252        |
| episodes                | 336           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.3          |
| n_updates               | 33469         |
| policy_loss             | 0.03670941    |
| qf1_loss                | 2.2253846e-06 |
| qf2_loss                | 1.2305484e-06 |
| time_elapsed            | 166           |
| total timesteps         | 33500         |
| value_loss              | 2.0138382e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.250585      |
| ep_rewmean              | -0.241        |
| episodes                | 340           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.2          |
| n_updates               | 33869         |
| policy_loss             | 0.048713513   |
| qf1_loss                | 5.021525e-06  |
| qf2_loss                | 6.3762545e-06 |
| time_elapsed            | 168           |
| total timesteps         | 33900         |
| value_loss              | 7.0622737e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.454921      |
| ep_rewmean              | -0.235        |
| episodes                | 344           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.2          |
| n_updates               | 34269         |
| policy_loss             | 0.039109536   |
| qf1_loss                | 1.5748301e-05 |
| qf2_loss                | 1.4813853e-05 |
| time_elapsed            | 170           |
| total timesteps         | 34300         |
| value_loss              | 1.2785908e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.8979454     |
| ep_rewmean              | -0.235        |
| episodes                | 348           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.2          |
| n_updates               | 34669         |
| policy_loss             | 0.03919804    |
| qf1_loss                | 5.234084e-07  |
| qf2_loss                | 9.840472e-07  |
| time_elapsed            | 172           |
| total timesteps         | 34700         |
| value_loss              | 1.4523407e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.2657924     |
| ep_rewmean              | -0.233        |
| episodes                | 352           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.2          |
| n_updates               | 35069         |
| policy_loss             | 0.036745477   |
| qf1_loss                | 1.6457188e-06 |
| qf2_loss                | 1.1482531e-06 |
| time_elapsed            | 174           |
| total timesteps         | 35100         |
| value_loss              | 1.6496708e-06 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 5.5126805      |
| ep_rewmean              | -0.235         |
| episodes                | 356            |
| eplenmean               | 100            |
| fps                     | 201            |
| mean 100 episode reward | -0.2           |
| n_updates               | 35469          |
| policy_loss             | 0.036489338    |
| qf1_loss                | 1.41657965e-05 |
| qf2_loss                | 1.352958e-05   |
| time_elapsed            | 176            |
| total timesteps         | 35500          |
| value_loss              | 4.140062e-06   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.5890465     |
| ep_rewmean              | -0.238        |
| episodes                | 360           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.2          |
| n_updates               | 35869         |
| policy_loss             | 0.032465316   |
| qf1_loss                | 2.6318935e-06 |
| qf2_loss                | 2.1330402e-06 |
| time_elapsed            | 178           |
| total timesteps         | 35900         |
| value_loss              | 2.5039517e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.616805      |
| ep_rewmean              | -0.238        |
| episodes                | 364           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.2          |
| n_updates               | 36269         |
| policy_loss             | 0.037356667   |
| qf1_loss                | 4.5189654e-06 |
| qf2_loss                | 4.2820166e-06 |
| time_elapsed            | 180           |
| total timesteps         | 36300         |
| value_loss              | 1.4034467e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.3052187     |
| ep_rewmean              | -0.23         |
| episodes                | 368           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.2          |
| n_updates               | 36669         |
| policy_loss             | 0.03384347    |
| qf1_loss                | 1.0744202e-06 |
| qf2_loss                | 1.6136373e-06 |
| time_elapsed            | 182           |
| total timesteps         | 36700         |
| value_loss              | 3.0982762e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.852312      |
| ep_rewmean              | -0.231        |
| episodes                | 372           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.2          |
| n_updates               | 37069         |
| policy_loss             | 0.03347186    |
| qf1_loss                | 4.0817645e-06 |
| qf2_loss                | 3.061868e-06  |
| time_elapsed            | 184           |
| total timesteps         | 37100         |
| value_loss              | 4.3017376e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.499194      |
| ep_rewmean              | -0.23         |
| episodes                | 376           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.2          |
| n_updates               | 37469         |
| policy_loss             | 0.04633041    |
| qf1_loss                | 1.2345331e-06 |
| qf2_loss                | 2.2174445e-06 |
| time_elapsed            | 185           |
| total timesteps         | 37500         |
| value_loss              | 1.7462697e-06 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 5.0740976      |
| ep_rewmean              | -0.229         |
| episodes                | 380            |
| eplenmean               | 100            |
| fps                     | 201            |
| mean 100 episode reward | -0.2           |
| n_updates               | 37869          |
| policy_loss             | 0.036135707    |
| qf1_loss                | 1.4356078e-05  |
| qf2_loss                | 1.28909915e-05 |
| time_elapsed            | 187            |
| total timesteps         | 37900          |
| value_loss              | 1.3173112e-06  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.0756006     |
| ep_rewmean              | -0.229        |
| episodes                | 384           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.2          |
| n_updates               | 38269         |
| policy_loss             | 0.036475144   |
| qf1_loss                | 1.5611078e-05 |
| qf2_loss                | 1.344948e-05  |
| time_elapsed            | 189           |
| total timesteps         | 38300         |
| value_loss              | 3.0409124e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.1898355     |
| ep_rewmean              | -0.232        |
| episodes                | 388           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.2          |
| n_updates               | 38669         |
| policy_loss             | 0.029515246   |
| qf1_loss                | 2.4715437e-05 |
| qf2_loss                | 2.5128153e-05 |
| time_elapsed            | 191           |
| total timesteps         | 38700         |
| value_loss              | 9.97035e-06   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.293708      |
| ep_rewmean              | -0.237        |
| episodes                | 392           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.2          |
| n_updates               | 39069         |
| policy_loss             | 0.03295604    |
| qf1_loss                | 1.0827211e-05 |
| qf2_loss                | 1.059398e-05  |
| time_elapsed            | 193           |
| total timesteps         | 39100         |
| value_loss              | 8.784956e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.043149      |
| ep_rewmean              | -0.241        |
| episodes                | 396           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.2          |
| n_updates               | 39469         |
| policy_loss             | 0.033195972   |
| qf1_loss                | 1.6449885e-06 |
| qf2_loss                | 3.9234437e-06 |
| time_elapsed            | 195           |
| total timesteps         | 39500         |
| value_loss              | 7.9184764e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.870598      |
| ep_rewmean              | -0.251        |
| episodes                | 400           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 39869         |
| policy_loss             | 0.037879992   |
| qf1_loss                | 1.8210196e-06 |
| qf2_loss                | 1.5938504e-06 |
| time_elapsed            | 197           |
| total timesteps         | 39900         |
| value_loss              | 8.54359e-06   |
-------------------------------------------
Eval num_timesteps=40000, episode_reward=-0.44 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.7358894     |
| ep_rewmean              | -0.252        |
| episodes                | 404           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.3          |
| n_updates               | 40269         |
| policy_loss             | 0.03295761    |
| qf1_loss                | 1.9491602e-06 |
| qf2_loss                | 1.5534056e-06 |
| time_elapsed            | 199           |
| total timesteps         | 40300         |
| value_loss              | 1.0732308e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.3355093     |
| ep_rewmean              | -0.253        |
| episodes                | 408           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.3          |
| n_updates               | 40669         |
| policy_loss             | 0.030239752   |
| qf1_loss                | 8.572042e-07  |
| qf2_loss                | 4.1900427e-07 |
| time_elapsed            | 201           |
| total timesteps         | 40700         |
| value_loss              | 1.3983188e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.14376       |
| ep_rewmean              | -0.261        |
| episodes                | 412           |
| eplenmean               | 100           |
| fps                     | 201           |
| mean 100 episode reward | -0.3          |
| n_updates               | 41069         |
| policy_loss             | 0.042136244   |
| qf1_loss                | 1.3291763e-06 |
| qf2_loss                | 1.811189e-06  |
| time_elapsed            | 203           |
| total timesteps         | 41100         |
| value_loss              | 8.915686e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.509717      |
| ep_rewmean              | -0.261        |
| episodes                | 416           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 41469         |
| policy_loss             | 0.030543867   |
| qf1_loss                | 1.8856383e-05 |
| qf2_loss                | 2.5736597e-05 |
| time_elapsed            | 205           |
| total timesteps         | 41500         |
| value_loss              | 3.3161718e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.414145      |
| ep_rewmean              | -0.268        |
| episodes                | 420           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 41869         |
| policy_loss             | 0.03657327    |
| qf1_loss                | 3.3848614e-06 |
| qf2_loss                | 2.3250343e-06 |
| time_elapsed            | 207           |
| total timesteps         | 41900         |
| value_loss              | 1.0938569e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.215766      |
| ep_rewmean              | -0.274        |
| episodes                | 424           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 42269         |
| policy_loss             | 0.03289779    |
| qf1_loss                | 1.1740301e-06 |
| qf2_loss                | 8.748666e-07  |
| time_elapsed            | 209           |
| total timesteps         | 42300         |
| value_loss              | 2.1465744e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.8637404     |
| ep_rewmean              | -0.278        |
| episodes                | 428           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 42669         |
| policy_loss             | 0.03669519    |
| qf1_loss                | 3.390714e-06  |
| qf2_loss                | 3.1666723e-06 |
| time_elapsed            | 211           |
| total timesteps         | 42700         |
| value_loss              | 1.9223937e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 4.683346      |
| ep_rewmean              | -0.283        |
| episodes                | 432           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 43069         |
| policy_loss             | 0.032042027   |
| qf1_loss                | 3.321267e-06  |
| qf2_loss                | 2.467443e-06  |
| time_elapsed            | 213           |
| total timesteps         | 43100         |
| value_loss              | 1.1047549e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.3362455     |
| ep_rewmean              | -0.283        |
| episodes                | 436           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 43469         |
| policy_loss             | 0.036587212   |
| qf1_loss                | 4.4860474e-07 |
| qf2_loss                | 1.1295728e-06 |
| time_elapsed            | 215           |
| total timesteps         | 43500         |
| value_loss              | 2.4100225e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.334         |
| ep_rewmean              | -0.285        |
| episodes                | 440           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 43869         |
| policy_loss             | 0.033465505   |
| qf1_loss                | 1.8746273e-06 |
| qf2_loss                | 2.0167192e-06 |
| time_elapsed            | 217           |
| total timesteps         | 43900         |
| value_loss              | 1.2978662e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.485679      |
| ep_rewmean              | -0.287        |
| episodes                | 444           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 44269         |
| policy_loss             | 0.030502588   |
| qf1_loss                | 1.2756014e-05 |
| qf2_loss                | 1.2931609e-05 |
| time_elapsed            | 219           |
| total timesteps         | 44300         |
| value_loss              | 2.2399602e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.4123597     |
| ep_rewmean              | -0.287        |
| episodes                | 448           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 44669         |
| policy_loss             | 0.039562333   |
| qf1_loss                | 2.0960792e-06 |
| qf2_loss                | 8.000056e-06  |
| time_elapsed            | 221           |
| total timesteps         | 44700         |
| value_loss              | 4.5352563e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.2417574     |
| ep_rewmean              | -0.29         |
| episodes                | 452           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 45069         |
| policy_loss             | 0.029677497   |
| qf1_loss                | 1.252133e-05  |
| qf2_loss                | 1.2723983e-05 |
| time_elapsed            | 223           |
| total timesteps         | 45100         |
| value_loss              | 8.849564e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.82075       |
| ep_rewmean              | -0.289        |
| episodes                | 456           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 45469         |
| policy_loss             | 0.03158283    |
| qf1_loss                | 1.8709056e-06 |
| qf2_loss                | 1.9070095e-06 |
| time_elapsed            | 225           |
| total timesteps         | 45500         |
| value_loss              | 2.2783352e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.607236      |
| ep_rewmean              | -0.288        |
| episodes                | 460           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 45869         |
| policy_loss             | 0.036626227   |
| qf1_loss                | 2.2328493e-06 |
| qf2_loss                | 1.7777351e-06 |
| time_elapsed            | 227           |
| total timesteps         | 45900         |
| value_loss              | 1.0581144e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.929503      |
| ep_rewmean              | -0.287        |
| episodes                | 464           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 46269         |
| policy_loss             | 0.027951015   |
| qf1_loss                | 2.3348557e-06 |
| qf2_loss                | 1.5877131e-06 |
| time_elapsed            | 229           |
| total timesteps         | 46300         |
| value_loss              | 5.8161877e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.4517        |
| ep_rewmean              | -0.289        |
| episodes                | 468           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 46669         |
| policy_loss             | 0.040780198   |
| qf1_loss                | 1.2266187e-06 |
| qf2_loss                | 8.723287e-07  |
| time_elapsed            | 231           |
| total timesteps         | 46700         |
| value_loss              | 3.1070467e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.8402805     |
| ep_rewmean              | -0.293        |
| episodes                | 472           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 47069         |
| policy_loss             | 0.028927531   |
| qf1_loss                | 9.7682105e-06 |
| qf2_loss                | 1.0623451e-05 |
| time_elapsed            | 232           |
| total timesteps         | 47100         |
| value_loss              | 7.693137e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.6765046     |
| ep_rewmean              | -0.296        |
| episodes                | 476           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 47469         |
| policy_loss             | 0.030580994   |
| qf1_loss                | 1.0060027e-06 |
| qf2_loss                | 7.5095306e-07 |
| time_elapsed            | 234           |
| total timesteps         | 47500         |
| value_loss              | 4.961114e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.222416      |
| ep_rewmean              | -0.294        |
| episodes                | 480           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 47869         |
| policy_loss             | 0.035080295   |
| qf1_loss                | 1.3812477e-05 |
| qf2_loss                | 1.3011302e-05 |
| time_elapsed            | 236           |
| total timesteps         | 47900         |
| value_loss              | 1.1026386e-06 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 5.5501065      |
| ep_rewmean              | -0.295         |
| episodes                | 484            |
| eplenmean               | 100            |
| fps                     | 202            |
| mean 100 episode reward | -0.3           |
| n_updates               | 48269          |
| policy_loss             | 0.034933716    |
| qf1_loss                | 1.18483495e-05 |
| qf2_loss                | 9.464934e-06   |
| time_elapsed            | 238            |
| total timesteps         | 48300          |
| value_loss              | 1.8935763e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.3001795     |
| ep_rewmean              | -0.292        |
| episodes                | 488           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 48669         |
| policy_loss             | 0.036420185   |
| qf1_loss                | 1.4553208e-06 |
| qf2_loss                | 1.2576654e-06 |
| time_elapsed            | 240           |
| total timesteps         | 48700         |
| value_loss              | 3.4716202e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.371945      |
| ep_rewmean              | -0.284        |
| episodes                | 492           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 49069         |
| policy_loss             | 0.032657843   |
| qf1_loss                | 2.857755e-06  |
| qf2_loss                | 2.5481368e-06 |
| time_elapsed            | 242           |
| total timesteps         | 49100         |
| value_loss              | 9.194968e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.46237       |
| ep_rewmean              | -0.281        |
| episodes                | 496           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 49469         |
| policy_loss             | 0.03411124    |
| qf1_loss                | 1.348354e-06  |
| qf2_loss                | 1.7313423e-06 |
| time_elapsed            | 244           |
| total timesteps         | 49500         |
| value_loss              | 2.3286827e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.827427      |
| ep_rewmean              | -0.272        |
| episodes                | 500           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 49869         |
| policy_loss             | 0.03115296    |
| qf1_loss                | 3.2069074e-06 |
| qf2_loss                | 1.8556252e-06 |
| time_elapsed            | 246           |
| total timesteps         | 49900         |
| value_loss              | 2.2463253e-06 |
-------------------------------------------
Eval num_timesteps=50000, episode_reward=-0.31 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.5214615     |
| ep_rewmean              | -0.269        |
| episodes                | 504           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 50269         |
| policy_loss             | 0.038000196   |
| qf1_loss                | 9.219331e-07  |
| qf2_loss                | 1.3819441e-06 |
| time_elapsed            | 248           |
| total timesteps         | 50300         |
| value_loss              | 3.657243e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.5582743     |
| ep_rewmean              | -0.265        |
| episodes                | 508           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 50669         |
| policy_loss             | 0.03617068    |
| qf1_loss                | 1.5775414e-06 |
| qf2_loss                | 1.3699436e-06 |
| time_elapsed            | 250           |
| total timesteps         | 50700         |
| value_loss              | 4.433056e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.0036306     |
| ep_rewmean              | -0.254        |
| episodes                | 512           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 51069         |
| policy_loss             | 0.037303597   |
| qf1_loss                | 5.491919e-07  |
| qf2_loss                | 1.0042816e-06 |
| time_elapsed            | 252           |
| total timesteps         | 51100         |
| value_loss              | 7.8283415e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.5641565     |
| ep_rewmean              | -0.249        |
| episodes                | 516           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 51469         |
| policy_loss             | 0.02860451    |
| qf1_loss                | 7.4719696e-07 |
| qf2_loss                | 9.80345e-07   |
| time_elapsed            | 254           |
| total timesteps         | 51500         |
| value_loss              | 1.8405282e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.441677      |
| ep_rewmean              | -0.243        |
| episodes                | 520           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 51869         |
| policy_loss             | 0.029919207   |
| qf1_loss                | 4.2214206e-06 |
| qf2_loss                | 5.208563e-06  |
| time_elapsed            | 256           |
| total timesteps         | 51900         |
| value_loss              | 2.1096033e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.5416145     |
| ep_rewmean              | -0.239        |
| episodes                | 524           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 52269         |
| policy_loss             | 0.025195722   |
| qf1_loss                | 1.5581196e-06 |
| qf2_loss                | 1.9549232e-06 |
| time_elapsed            | 258           |
| total timesteps         | 52300         |
| value_loss              | 6.3484786e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.325695      |
| ep_rewmean              | -0.236        |
| episodes                | 528           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 52669         |
| policy_loss             | 0.03570748    |
| qf1_loss                | 1.0824851e-06 |
| qf2_loss                | 1.6757243e-06 |
| time_elapsed            | 260           |
| total timesteps         | 52700         |
| value_loss              | 3.1652717e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.745556      |
| ep_rewmean              | -0.233        |
| episodes                | 532           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 53069         |
| policy_loss             | 0.03367487    |
| qf1_loss                | 2.8445427e-06 |
| qf2_loss                | 2.167283e-06  |
| time_elapsed            | 262           |
| total timesteps         | 53100         |
| value_loss              | 1.2968852e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.0560226     |
| ep_rewmean              | -0.233        |
| episodes                | 536           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 53469         |
| policy_loss             | 0.032031827   |
| qf1_loss                | 3.360295e-05  |
| qf2_loss                | 3.4116747e-05 |
| time_elapsed            | 264           |
| total timesteps         | 53500         |
| value_loss              | 3.0984331e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.1964817     |
| ep_rewmean              | -0.233        |
| episodes                | 540           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 53869         |
| policy_loss             | 0.030276984   |
| qf1_loss                | 1.5966351e-06 |
| qf2_loss                | 1.0300931e-06 |
| time_elapsed            | 266           |
| total timesteps         | 53900         |
| value_loss              | 2.0869743e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.189372      |
| ep_rewmean              | -0.233        |
| episodes                | 544           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 54269         |
| policy_loss             | 0.037855446   |
| qf1_loss                | 2.0894344e-05 |
| qf2_loss                | 2.1590273e-05 |
| time_elapsed            | 268           |
| total timesteps         | 54300         |
| value_loss              | 4.0742034e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.8259344     |
| ep_rewmean              | -0.232        |
| episodes                | 548           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 54669         |
| policy_loss             | 0.028938677   |
| qf1_loss                | 1.130795e-05  |
| qf2_loss                | 9.152038e-06  |
| time_elapsed            | 270           |
| total timesteps         | 54700         |
| value_loss              | 1.0805761e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.7470574     |
| ep_rewmean              | -0.23         |
| episodes                | 552           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 55069         |
| policy_loss             | 0.03359814    |
| qf1_loss                | 9.828732e-07  |
| qf2_loss                | 1.4024433e-06 |
| time_elapsed            | 272           |
| total timesteps         | 55100         |
| value_loss              | 2.8380887e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.8805904     |
| ep_rewmean              | -0.228        |
| episodes                | 556           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 55469         |
| policy_loss             | 0.03356259    |
| qf1_loss                | 3.2332496e-06 |
| qf2_loss                | 2.6278983e-06 |
| time_elapsed            | 273           |
| total timesteps         | 55500         |
| value_loss              | 3.346533e-06  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 6.0989685    |
| ep_rewmean              | -0.227       |
| episodes                | 560          |
| eplenmean               | 100          |
| fps                     | 202          |
| mean 100 episode reward | -0.2         |
| n_updates               | 55869        |
| policy_loss             | 0.038542803  |
| qf1_loss                | 4.150674e-06 |
| qf2_loss                | 2.471609e-06 |
| time_elapsed            | 275          |
| total timesteps         | 55900        |
| value_loss              | 5.622377e-06 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.18855       |
| ep_rewmean              | -0.226        |
| episodes                | 564           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 56269         |
| policy_loss             | 0.031364985   |
| qf1_loss                | 5.1526627e-07 |
| qf2_loss                | 1.3726437e-06 |
| time_elapsed            | 277           |
| total timesteps         | 56300         |
| value_loss              | 1.1631217e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.706396      |
| ep_rewmean              | -0.225        |
| episodes                | 568           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 56669         |
| policy_loss             | 0.02797155    |
| qf1_loss                | 1.5695118e-06 |
| qf2_loss                | 9.2788605e-07 |
| time_elapsed            | 279           |
| total timesteps         | 56700         |
| value_loss              | 1.6606763e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.145613      |
| ep_rewmean              | -0.219        |
| episodes                | 572           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 57069         |
| policy_loss             | 0.030347206   |
| qf1_loss                | 1.1434089e-05 |
| qf2_loss                | 1.1940211e-05 |
| time_elapsed            | 281           |
| total timesteps         | 57100         |
| value_loss              | 1.694958e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5523725     |
| ep_rewmean              | -0.22         |
| episodes                | 576           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 57469         |
| policy_loss             | 0.030796962   |
| qf1_loss                | 1.4508199e-06 |
| qf2_loss                | 2.079721e-06  |
| time_elapsed            | 283           |
| total timesteps         | 57500         |
| value_loss              | 1.8715698e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.427078      |
| ep_rewmean              | -0.226        |
| episodes                | 580           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 57869         |
| policy_loss             | 0.028432297   |
| qf1_loss                | 4.1237886e-06 |
| qf2_loss                | 4.3283426e-06 |
| time_elapsed            | 285           |
| total timesteps         | 57900         |
| value_loss              | 1.1976374e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.6748657     |
| ep_rewmean              | -0.225        |
| episodes                | 584           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 58269         |
| policy_loss             | 0.028399732   |
| qf1_loss                | 7.0130045e-07 |
| qf2_loss                | 6.552419e-07  |
| time_elapsed            | 287           |
| total timesteps         | 58300         |
| value_loss              | 7.86839e-07   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.322441      |
| ep_rewmean              | -0.226        |
| episodes                | 588           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 58669         |
| policy_loss             | 0.027563337   |
| qf1_loss                | 6.250568e-07  |
| qf2_loss                | 5.9920933e-07 |
| time_elapsed            | 289           |
| total timesteps         | 58700         |
| value_loss              | 1.0892842e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7896843     |
| ep_rewmean              | -0.23         |
| episodes                | 592           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 59069         |
| policy_loss             | 0.03454616    |
| qf1_loss                | 6.02329e-05   |
| qf2_loss                | 4.6715282e-05 |
| time_elapsed            | 291           |
| total timesteps         | 59100         |
| value_loss              | 1.9680683e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.0582647     |
| ep_rewmean              | -0.23         |
| episodes                | 596           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 59469         |
| policy_loss             | 0.026616571   |
| qf1_loss                | 9.878091e-07  |
| qf2_loss                | 1.1844724e-06 |
| time_elapsed            | 293           |
| total timesteps         | 59500         |
| value_loss              | 8.936765e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.0835824     |
| ep_rewmean              | -0.229        |
| episodes                | 600           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 59869         |
| policy_loss             | 0.024064876   |
| qf1_loss                | 2.9450368e-06 |
| qf2_loss                | 2.875067e-06  |
| time_elapsed            | 295           |
| total timesteps         | 59900         |
| value_loss              | 3.0102985e-06 |
-------------------------------------------
Eval num_timesteps=60000, episode_reward=-0.17 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.2098737     |
| ep_rewmean              | -0.228        |
| episodes                | 604           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 60269         |
| policy_loss             | 0.030783452   |
| qf1_loss                | 8.8767916e-07 |
| qf2_loss                | 7.4198704e-07 |
| time_elapsed            | 297           |
| total timesteps         | 60300         |
| value_loss              | 9.4049994e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.208635      |
| ep_rewmean              | -0.228        |
| episodes                | 608           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 60669         |
| policy_loss             | 0.026119022   |
| qf1_loss                | 3.5421756e-06 |
| qf2_loss                | 2.408107e-06  |
| time_elapsed            | 299           |
| total timesteps         | 60700         |
| value_loss              | 4.4239947e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.3034306     |
| ep_rewmean              | -0.233        |
| episodes                | 612           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 61069         |
| policy_loss             | 0.031699922   |
| qf1_loss                | 1.7475004e-06 |
| qf2_loss                | 1.6069434e-06 |
| time_elapsed            | 301           |
| total timesteps         | 61100         |
| value_loss              | 3.0558042e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.436655      |
| ep_rewmean              | -0.234        |
| episodes                | 616           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 61469         |
| policy_loss             | 0.037458036   |
| qf1_loss                | 1.1062987e-06 |
| qf2_loss                | 1.9740614e-06 |
| time_elapsed            | 303           |
| total timesteps         | 61500         |
| value_loss              | 3.3077188e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4406214     |
| ep_rewmean              | -0.235        |
| episodes                | 620           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 61869         |
| policy_loss             | 0.03196024    |
| qf1_loss                | 2.3451146e-06 |
| qf2_loss                | 1.739862e-06  |
| time_elapsed            | 305           |
| total timesteps         | 61900         |
| value_loss              | 3.4179811e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.5670195     |
| ep_rewmean              | -0.239        |
| episodes                | 624           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 62269         |
| policy_loss             | 0.032897938   |
| qf1_loss                | 1.0214666e-05 |
| qf2_loss                | 1.0389467e-05 |
| time_elapsed            | 307           |
| total timesteps         | 62300         |
| value_loss              | 8.51841e-06   |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 6.0244465    |
| ep_rewmean              | -0.241       |
| episodes                | 628          |
| eplenmean               | 100          |
| fps                     | 202          |
| mean 100 episode reward | -0.2         |
| n_updates               | 62669        |
| policy_loss             | 0.034104668  |
| qf1_loss                | 1.075277e-06 |
| qf2_loss                | 2.230664e-06 |
| time_elapsed            | 309          |
| total timesteps         | 62700        |
| value_loss              | 4.606056e-06 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6606846     |
| ep_rewmean              | -0.244        |
| episodes                | 632           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 63069         |
| policy_loss             | 0.030835457   |
| qf1_loss                | 1.0404326e-06 |
| qf2_loss                | 7.693557e-07  |
| time_elapsed            | 311           |
| total timesteps         | 63100         |
| value_loss              | 1.8785363e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.0236616     |
| ep_rewmean              | -0.244        |
| episodes                | 636           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 63469         |
| policy_loss             | 0.032514535   |
| qf1_loss                | 2.1817466e-06 |
| qf2_loss                | 1.0884755e-06 |
| time_elapsed            | 313           |
| total timesteps         | 63500         |
| value_loss              | 9.555758e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.290396      |
| ep_rewmean              | -0.245        |
| episodes                | 640           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 63869         |
| policy_loss             | 0.03538325    |
| qf1_loss                | 1.5672974e-06 |
| qf2_loss                | 2.7349838e-06 |
| time_elapsed            | 315           |
| total timesteps         | 63900         |
| value_loss              | 1.0481828e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.8238516     |
| ep_rewmean              | -0.25         |
| episodes                | 644           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 64269         |
| policy_loss             | 0.028349262   |
| qf1_loss                | 8.641964e-07  |
| qf2_loss                | 8.3369275e-07 |
| time_elapsed            | 316           |
| total timesteps         | 64300         |
| value_loss              | 9.359318e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.439993      |
| ep_rewmean              | -0.248        |
| episodes                | 648           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.2          |
| n_updates               | 64669         |
| policy_loss             | 0.037877563   |
| qf1_loss                | 1.2411222e-05 |
| qf2_loss                | 8.181519e-06  |
| time_elapsed            | 318           |
| total timesteps         | 64700         |
| value_loss              | 2.2697645e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.135025      |
| ep_rewmean              | -0.265        |
| episodes                | 652           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 65069         |
| policy_loss             | 0.031692322   |
| qf1_loss                | 8.9763057e-07 |
| qf2_loss                | 1.3109516e-06 |
| time_elapsed            | 320           |
| total timesteps         | 65100         |
| value_loss              | 1.1645084e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.900265      |
| ep_rewmean              | -0.273        |
| episodes                | 656           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 65469         |
| policy_loss             | 0.037074722   |
| qf1_loss                | 5.024037e-06  |
| qf2_loss                | 1.7643996e-06 |
| time_elapsed            | 322           |
| total timesteps         | 65500         |
| value_loss              | 2.194904e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.1496553     |
| ep_rewmean              | -0.275        |
| episodes                | 660           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 65869         |
| policy_loss             | 0.036756523   |
| qf1_loss                | 1.9285148e-05 |
| qf2_loss                | 1.6395948e-05 |
| time_elapsed            | 324           |
| total timesteps         | 65900         |
| value_loss              | 3.3745296e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.825973      |
| ep_rewmean              | -0.282        |
| episodes                | 664           |
| eplenmean               | 100           |
| fps                     | 202           |
| mean 100 episode reward | -0.3          |
| n_updates               | 66269         |
| policy_loss             | 0.03400294    |
| qf1_loss                | 8.410043e-06  |
| qf2_loss                | 9.616134e-06  |
| time_elapsed            | 326           |
| total timesteps         | 66300         |
| value_loss              | 4.4137564e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.2780004     |
| ep_rewmean              | -0.282        |
| episodes                | 668           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 66669         |
| policy_loss             | 0.02541272    |
| qf1_loss                | 1.5872563e-05 |
| qf2_loss                | 1.612285e-05  |
| time_elapsed            | 328           |
| total timesteps         | 66700         |
| value_loss              | 7.209765e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.216322      |
| ep_rewmean              | -0.283        |
| episodes                | 672           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 67069         |
| policy_loss             | 0.035235267   |
| qf1_loss                | 1.1224208e-06 |
| qf2_loss                | 1.1734176e-06 |
| time_elapsed            | 330           |
| total timesteps         | 67100         |
| value_loss              | 2.9153316e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.1352644     |
| ep_rewmean              | -0.279        |
| episodes                | 676           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 67469         |
| policy_loss             | 0.03178823    |
| qf1_loss                | 1.0008007e-06 |
| qf2_loss                | 7.054333e-07  |
| time_elapsed            | 332           |
| total timesteps         | 67500         |
| value_loss              | 1.5116746e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.277883      |
| ep_rewmean              | -0.273        |
| episodes                | 680           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 67869         |
| policy_loss             | 0.02606723    |
| qf1_loss                | 1.1339539e-06 |
| qf2_loss                | 9.747497e-07  |
| time_elapsed            | 334           |
| total timesteps         | 67900         |
| value_loss              | 1.0034898e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.674874      |
| ep_rewmean              | -0.27         |
| episodes                | 684           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 68269         |
| policy_loss             | 0.03308825    |
| qf1_loss                | 1.112937e-05  |
| qf2_loss                | 1.0022296e-05 |
| time_elapsed            | 336           |
| total timesteps         | 68300         |
| value_loss              | 1.2725752e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.445422      |
| ep_rewmean              | -0.267        |
| episodes                | 688           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 68669         |
| policy_loss             | 0.023972228   |
| qf1_loss                | 5.063642e-06  |
| qf2_loss                | 3.5116186e-06 |
| time_elapsed            | 338           |
| total timesteps         | 68700         |
| value_loss              | 4.575673e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.138399      |
| ep_rewmean              | -0.263        |
| episodes                | 692           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 69069         |
| policy_loss             | 0.034909476   |
| qf1_loss                | 5.0337053e-07 |
| qf2_loss                | 6.411785e-07  |
| time_elapsed            | 340           |
| total timesteps         | 69100         |
| value_loss              | 1.6657716e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7639337     |
| ep_rewmean              | -0.261        |
| episodes                | 696           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 69469         |
| policy_loss             | 0.031856656   |
| qf1_loss                | 2.0161785e-06 |
| qf2_loss                | 1.5566422e-06 |
| time_elapsed            | 341           |
| total timesteps         | 69500         |
| value_loss              | 2.8387674e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.56525       |
| ep_rewmean              | -0.26         |
| episodes                | 700           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 69869         |
| policy_loss             | 0.032545224   |
| qf1_loss                | 1.0984759e-06 |
| qf2_loss                | 9.3236656e-07 |
| time_elapsed            | 343           |
| total timesteps         | 69900         |
| value_loss              | 5.931023e-06  |
-------------------------------------------
Eval num_timesteps=70000, episode_reward=-0.20 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6663494     |
| ep_rewmean              | -0.259        |
| episodes                | 704           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 70269         |
| policy_loss             | 0.03267552    |
| qf1_loss                | 8.56556e-07   |
| qf2_loss                | 7.731744e-07  |
| time_elapsed            | 346           |
| total timesteps         | 70300         |
| value_loss              | 2.5534825e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.651618      |
| ep_rewmean              | -0.26         |
| episodes                | 708           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 70669         |
| policy_loss             | 0.03778328    |
| qf1_loss                | 1.0202604e-05 |
| qf2_loss                | 1.0736518e-05 |
| time_elapsed            | 347           |
| total timesteps         | 70700         |
| value_loss              | 1.2698246e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.588235      |
| ep_rewmean              | -0.258        |
| episodes                | 712           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 71069         |
| policy_loss             | 0.03265218    |
| qf1_loss                | 2.3548632e-06 |
| qf2_loss                | 4.189954e-06  |
| time_elapsed            | 349           |
| total timesteps         | 71100         |
| value_loss              | 3.0409735e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.1822414     |
| ep_rewmean              | -0.256        |
| episodes                | 716           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 71469         |
| policy_loss             | 0.034123734   |
| qf1_loss                | 4.7117433e-07 |
| qf2_loss                | 1.305816e-06  |
| time_elapsed            | 351           |
| total timesteps         | 71500         |
| value_loss              | 2.111359e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.54461       |
| ep_rewmean              | -0.254        |
| episodes                | 720           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 71869         |
| policy_loss             | 0.024589662   |
| qf1_loss                | 4.4894523e-07 |
| qf2_loss                | 1.0017942e-06 |
| time_elapsed            | 353           |
| total timesteps         | 71900         |
| value_loss              | 8.0707116e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.110166      |
| ep_rewmean              | -0.249        |
| episodes                | 724           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 72269         |
| policy_loss             | 0.027288945   |
| qf1_loss                | 2.155888e-06  |
| qf2_loss                | 1.6752741e-06 |
| time_elapsed            | 355           |
| total timesteps         | 72300         |
| value_loss              | 2.2622153e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.53494       |
| ep_rewmean              | -0.246        |
| episodes                | 728           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 72669         |
| policy_loss             | 0.02542465    |
| qf1_loss                | 8.5194773e-07 |
| qf2_loss                | 3.4595223e-06 |
| time_elapsed            | 357           |
| total timesteps         | 72700         |
| value_loss              | 7.3398346e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.284309      |
| ep_rewmean              | -0.242        |
| episodes                | 732           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 73069         |
| policy_loss             | 0.028226173   |
| qf1_loss                | 8.473717e-06  |
| qf2_loss                | 1.0530242e-05 |
| time_elapsed            | 359           |
| total timesteps         | 73100         |
| value_loss              | 2.4131854e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4932604     |
| ep_rewmean              | -0.241        |
| episodes                | 736           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 73469         |
| policy_loss             | 0.023499964   |
| qf1_loss                | 4.687238e-07  |
| qf2_loss                | 7.538e-07     |
| time_elapsed            | 361           |
| total timesteps         | 73500         |
| value_loss              | 4.3388732e-07 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 6.064375       |
| ep_rewmean              | -0.241         |
| episodes                | 740            |
| eplenmean               | 100            |
| fps                     | 203            |
| mean 100 episode reward | -0.2           |
| n_updates               | 73869          |
| policy_loss             | 0.023963945    |
| qf1_loss                | 1.32813275e-05 |
| qf2_loss                | 1.3528019e-05  |
| time_elapsed            | 363            |
| total timesteps         | 73900          |
| value_loss              | 4.3937732e-07  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.3494463     |
| ep_rewmean              | -0.235        |
| episodes                | 744           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 74269         |
| policy_loss             | 0.028016096   |
| qf1_loss                | 3.311702e-06  |
| qf2_loss                | 1.5158712e-06 |
| time_elapsed            | 365           |
| total timesteps         | 74300         |
| value_loss              | 3.1840166e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.130576      |
| ep_rewmean              | -0.236        |
| episodes                | 748           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 74669         |
| policy_loss             | 0.02419198    |
| qf1_loss                | 2.5832683e-06 |
| qf2_loss                | 1.0758063e-06 |
| time_elapsed            | 367           |
| total timesteps         | 74700         |
| value_loss              | 1.6439897e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8230267     |
| ep_rewmean              | -0.217        |
| episodes                | 752           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 75069         |
| policy_loss             | 0.023701884   |
| qf1_loss                | 1.3126407e-05 |
| qf2_loss                | 1.5682695e-05 |
| time_elapsed            | 369           |
| total timesteps         | 75100         |
| value_loss              | 2.0124196e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7125125     |
| ep_rewmean              | -0.211        |
| episodes                | 756           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 75469         |
| policy_loss             | 0.02300228    |
| qf1_loss                | 9.373786e-06  |
| qf2_loss                | 6.3522666e-06 |
| time_elapsed            | 371           |
| total timesteps         | 75500         |
| value_loss              | 9.228289e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7779665     |
| ep_rewmean              | -0.208        |
| episodes                | 760           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 75869         |
| policy_loss             | 0.024662105   |
| qf1_loss                | 7.1645536e-07 |
| qf2_loss                | 6.094474e-07  |
| time_elapsed            | 373           |
| total timesteps         | 75900         |
| value_loss              | 5.3544693e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.044847      |
| ep_rewmean              | -0.2          |
| episodes                | 764           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 76269         |
| policy_loss             | 0.023592941   |
| qf1_loss                | 1.6948675e-06 |
| qf2_loss                | 1.9742936e-06 |
| time_elapsed            | 375           |
| total timesteps         | 76300         |
| value_loss              | 6.9954176e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.489448      |
| ep_rewmean              | -0.199        |
| episodes                | 768           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 76669         |
| policy_loss             | 0.020499926   |
| qf1_loss                | 9.414835e-07  |
| qf2_loss                | 2.3011737e-07 |
| time_elapsed            | 377           |
| total timesteps         | 76700         |
| value_loss              | 4.517638e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.0908904     |
| ep_rewmean              | -0.2          |
| episodes                | 772           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 77069         |
| policy_loss             | 0.025951598   |
| qf1_loss                | 3.4364498e-06 |
| qf2_loss                | 3.7046148e-06 |
| time_elapsed            | 379           |
| total timesteps         | 77100         |
| value_loss              | 6.3608295e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.885784      |
| ep_rewmean              | -0.2          |
| episodes                | 776           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 77469         |
| policy_loss             | 0.025166318   |
| qf1_loss                | 1.5856733e-06 |
| qf2_loss                | 2.5159193e-06 |
| time_elapsed            | 381           |
| total timesteps         | 77500         |
| value_loss              | 1.119527e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4581966     |
| ep_rewmean              | -0.201        |
| episodes                | 780           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 77869         |
| policy_loss             | 0.02631887    |
| qf1_loss                | 5.6646445e-07 |
| qf2_loss                | 7.5289904e-07 |
| time_elapsed            | 383           |
| total timesteps         | 77900         |
| value_loss              | 2.1505966e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.3079715     |
| ep_rewmean              | -0.202        |
| episodes                | 784           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 78269         |
| policy_loss             | 0.0218485     |
| qf1_loss                | 1.9021155e-07 |
| qf2_loss                | 3.1102394e-07 |
| time_elapsed            | 384           |
| total timesteps         | 78300         |
| value_loss              | 4.4374792e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.0445967     |
| ep_rewmean              | -0.203        |
| episodes                | 788           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 78669         |
| policy_loss             | 0.02318003    |
| qf1_loss                | 6.187712e-07  |
| qf2_loss                | 6.5770644e-07 |
| time_elapsed            | 386           |
| total timesteps         | 78700         |
| value_loss              | 2.345544e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.506608      |
| ep_rewmean              | -0.205        |
| episodes                | 792           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 79069         |
| policy_loss             | 0.03143889    |
| qf1_loss                | 3.3957078e-06 |
| qf2_loss                | 3.534773e-06  |
| time_elapsed            | 388           |
| total timesteps         | 79100         |
| value_loss              | 8.0936695e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8554406     |
| ep_rewmean              | -0.208        |
| episodes                | 796           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 79469         |
| policy_loss             | 0.026012827   |
| qf1_loss                | 3.1955494e-06 |
| qf2_loss                | 1.522413e-05  |
| time_elapsed            | 390           |
| total timesteps         | 79500         |
| value_loss              | 6.4087753e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8793907     |
| ep_rewmean              | -0.21         |
| episodes                | 800           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 79869         |
| policy_loss             | 0.029784005   |
| qf1_loss                | 3.4739853e-06 |
| qf2_loss                | 5.395155e-06  |
| time_elapsed            | 392           |
| total timesteps         | 79900         |
| value_loss              | 1.1385983e-05 |
-------------------------------------------
Eval num_timesteps=80000, episode_reward=-0.17 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7860146     |
| ep_rewmean              | -0.211        |
| episodes                | 804           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 80269         |
| policy_loss             | 0.024917653   |
| qf1_loss                | 3.8010367e-06 |
| qf2_loss                | 5.417309e-06  |
| time_elapsed            | 394           |
| total timesteps         | 80300         |
| value_loss              | 4.362148e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5824        |
| ep_rewmean              | -0.212        |
| episodes                | 808           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 80669         |
| policy_loss             | 0.02397147    |
| qf1_loss                | 1.2376177e-06 |
| qf2_loss                | 8.786478e-07  |
| time_elapsed            | 396           |
| total timesteps         | 80700         |
| value_loss              | 3.3139218e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.987866      |
| ep_rewmean              | -0.212        |
| episodes                | 812           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 81069         |
| policy_loss             | 0.027939236   |
| qf1_loss                | 1.2136167e-06 |
| qf2_loss                | 5.811245e-07  |
| time_elapsed            | 398           |
| total timesteps         | 81100         |
| value_loss              | 1.2663382e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.932497      |
| ep_rewmean              | -0.213        |
| episodes                | 816           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 81469         |
| policy_loss             | 0.024152465   |
| qf1_loss                | 3.987924e-07  |
| qf2_loss                | 4.46584e-07   |
| time_elapsed            | 400           |
| total timesteps         | 81500         |
| value_loss              | 4.7430382e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1070375     |
| ep_rewmean              | -0.216        |
| episodes                | 820           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 81869         |
| policy_loss             | 0.023959143   |
| qf1_loss                | 5.4471224e-07 |
| qf2_loss                | 7.6066965e-07 |
| time_elapsed            | 402           |
| total timesteps         | 81900         |
| value_loss              | 7.619971e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9020205     |
| ep_rewmean              | -0.218        |
| episodes                | 824           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 82269         |
| policy_loss             | 0.025433231   |
| qf1_loss                | 3.0674921e-06 |
| qf2_loss                | 2.4847377e-06 |
| time_elapsed            | 404           |
| total timesteps         | 82300         |
| value_loss              | 4.578946e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.809698      |
| ep_rewmean              | -0.22         |
| episodes                | 828           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 82669         |
| policy_loss             | 0.023509106   |
| qf1_loss                | 3.775932e-07  |
| qf2_loss                | 5.8084385e-07 |
| time_elapsed            | 406           |
| total timesteps         | 82700         |
| value_loss              | 3.158942e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.877923      |
| ep_rewmean              | -0.221        |
| episodes                | 832           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 83069         |
| policy_loss             | 0.024366528   |
| qf1_loss                | 8.400792e-07  |
| qf2_loss                | 5.930381e-07  |
| time_elapsed            | 408           |
| total timesteps         | 83100         |
| value_loss              | 4.2421132e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.226421      |
| ep_rewmean              | -0.225        |
| episodes                | 836           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 83469         |
| policy_loss             | 0.028583134   |
| qf1_loss                | 4.6245523e-06 |
| qf2_loss                | 3.7217035e-06 |
| time_elapsed            | 410           |
| total timesteps         | 83500         |
| value_loss              | 4.0712416e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9744477     |
| ep_rewmean              | -0.23         |
| episodes                | 840           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 83869         |
| policy_loss             | 0.026510872   |
| qf1_loss                | 1.3212705e-06 |
| qf2_loss                | 1.6950244e-06 |
| time_elapsed            | 412           |
| total timesteps         | 83900         |
| value_loss              | 2.5677364e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.1129456     |
| ep_rewmean              | -0.232        |
| episodes                | 844           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 84269         |
| policy_loss             | 0.031180533   |
| qf1_loss                | 8.352229e-07  |
| qf2_loss                | 8.3229645e-07 |
| time_elapsed            | 414           |
| total timesteps         | 84300         |
| value_loss              | 3.525169e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9695144     |
| ep_rewmean              | -0.232        |
| episodes                | 848           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 84669         |
| policy_loss             | 0.027317662   |
| qf1_loss                | 2.390971e-06  |
| qf2_loss                | 1.2501904e-06 |
| time_elapsed            | 416           |
| total timesteps         | 84700         |
| value_loss              | 2.3991265e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6017184     |
| ep_rewmean              | -0.235        |
| episodes                | 852           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 85069         |
| policy_loss             | 0.027021084   |
| qf1_loss                | 7.702592e-07  |
| qf2_loss                | 1.5125772e-06 |
| time_elapsed            | 417           |
| total timesteps         | 85100         |
| value_loss              | 4.8299553e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.774123      |
| ep_rewmean              | -0.236        |
| episodes                | 856           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 85469         |
| policy_loss             | 0.030380612   |
| qf1_loss                | 1.2430653e-06 |
| qf2_loss                | 1.0163144e-06 |
| time_elapsed            | 419           |
| total timesteps         | 85500         |
| value_loss              | 9.949084e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.3205233     |
| ep_rewmean              | -0.24         |
| episodes                | 860           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 85869         |
| policy_loss             | 0.023060981   |
| qf1_loss                | 8.409697e-06  |
| qf2_loss                | 8.184879e-06  |
| time_elapsed            | 421           |
| total timesteps         | 85900         |
| value_loss              | 1.8124567e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 5.8644676     |
| ep_rewmean              | -0.243        |
| episodes                | 864           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 86269         |
| policy_loss             | 0.02560437    |
| qf1_loss                | 1.519805e-06  |
| qf2_loss                | 2.4993044e-06 |
| time_elapsed            | 423           |
| total timesteps         | 86300         |
| value_loss              | 1.2064902e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7532763     |
| ep_rewmean              | -0.246        |
| episodes                | 868           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 86669         |
| policy_loss             | 0.020257654   |
| qf1_loss                | 3.3947883e-06 |
| qf2_loss                | 3.344806e-06  |
| time_elapsed            | 425           |
| total timesteps         | 86700         |
| value_loss              | 9.2367845e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.812011      |
| ep_rewmean              | -0.249        |
| episodes                | 872           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 87069         |
| policy_loss             | 0.02170043    |
| qf1_loss                | 9.271007e-07  |
| qf2_loss                | 1.2165804e-06 |
| time_elapsed            | 427           |
| total timesteps         | 87100         |
| value_loss              | 2.1468916e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8812118     |
| ep_rewmean              | -0.249        |
| episodes                | 876           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 87469         |
| policy_loss             | 0.024202831   |
| qf1_loss                | 7.610061e-07  |
| qf2_loss                | 2.730527e-07  |
| time_elapsed            | 429           |
| total timesteps         | 87500         |
| value_loss              | 7.6550026e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2856493     |
| ep_rewmean              | -0.25         |
| episodes                | 880           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 87869         |
| policy_loss             | 0.02530101    |
| qf1_loss                | 2.7665e-06    |
| qf2_loss                | 9.859313e-06  |
| time_elapsed            | 431           |
| total timesteps         | 87900         |
| value_loss              | 4.5846873e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5047154     |
| ep_rewmean              | -0.252        |
| episodes                | 884           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 88269         |
| policy_loss             | 0.029858068   |
| qf1_loss                | 1.9287659e-06 |
| qf2_loss                | 9.239553e-07  |
| time_elapsed            | 433           |
| total timesteps         | 88300         |
| value_loss              | 2.2722388e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.1786013     |
| ep_rewmean              | -0.253        |
| episodes                | 888           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 88669         |
| policy_loss             | 0.02642856    |
| qf1_loss                | 3.037284e-06  |
| qf2_loss                | 2.47945e-06   |
| time_elapsed            | 435           |
| total timesteps         | 88700         |
| value_loss              | 3.1341353e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.298788      |
| ep_rewmean              | -0.255        |
| episodes                | 892           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 89069         |
| policy_loss             | 0.023996547   |
| qf1_loss                | 5.409835e-07  |
| qf2_loss                | 6.0244736e-07 |
| time_elapsed            | 437           |
| total timesteps         | 89100         |
| value_loss              | 8.5097327e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1245146     |
| ep_rewmean              | -0.256        |
| episodes                | 896           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 89469         |
| policy_loss             | 0.027218701   |
| qf1_loss                | 8.109123e-07  |
| qf2_loss                | 7.43693e-07   |
| time_elapsed            | 439           |
| total timesteps         | 89500         |
| value_loss              | 9.1144875e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.820197      |
| ep_rewmean              | -0.257        |
| episodes                | 900           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 89869         |
| policy_loss             | 0.026577367   |
| qf1_loss                | 7.09847e-07   |
| qf2_loss                | 5.997289e-07  |
| time_elapsed            | 441           |
| total timesteps         | 89900         |
| value_loss              | 1.6298895e-06 |
-------------------------------------------
Eval num_timesteps=90000, episode_reward=-0.22 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.879306      |
| ep_rewmean              | -0.26         |
| episodes                | 904           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 90269         |
| policy_loss             | 0.023879835   |
| qf1_loss                | 1.6546928e-06 |
| qf2_loss                | 5.9363447e-07 |
| time_elapsed            | 443           |
| total timesteps         | 90300         |
| value_loss              | 1.264007e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.1952295     |
| ep_rewmean              | -0.261        |
| episodes                | 908           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 90669         |
| policy_loss             | 0.022763014   |
| qf1_loss                | 9.709076e-06  |
| qf2_loss                | 8.413697e-06  |
| time_elapsed            | 445           |
| total timesteps         | 90700         |
| value_loss              | 6.3022558e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4246454     |
| ep_rewmean              | -0.263        |
| episodes                | 912           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 91069         |
| policy_loss             | 0.027739447   |
| qf1_loss                | 7.1875743e-06 |
| qf2_loss                | 7.520747e-06  |
| time_elapsed            | 447           |
| total timesteps         | 91100         |
| value_loss              | 2.7575174e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.110557      |
| ep_rewmean              | -0.264        |
| episodes                | 916           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 91469         |
| policy_loss             | 0.029046318   |
| qf1_loss                | 7.456508e-07  |
| qf2_loss                | 8.523116e-07  |
| time_elapsed            | 449           |
| total timesteps         | 91500         |
| value_loss              | 1.0924629e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9790535     |
| ep_rewmean              | -0.263        |
| episodes                | 920           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 91869         |
| policy_loss             | 0.024900423   |
| qf1_loss                | 1.0915478e-06 |
| qf2_loss                | 6.3187235e-07 |
| time_elapsed            | 451           |
| total timesteps         | 91900         |
| value_loss              | 1.534641e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.609778      |
| ep_rewmean              | -0.265        |
| episodes                | 924           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 92269         |
| policy_loss             | 0.02192248    |
| qf1_loss                | 4.3242665e-07 |
| qf2_loss                | 1.0535277e-06 |
| time_elapsed            | 453           |
| total timesteps         | 92300         |
| value_loss              | 3.7367352e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1415534     |
| ep_rewmean              | -0.263        |
| episodes                | 928           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 92669         |
| policy_loss             | 0.021188058   |
| qf1_loss                | 4.660606e-07  |
| qf2_loss                | 5.2852056e-07 |
| time_elapsed            | 455           |
| total timesteps         | 92700         |
| value_loss              | 1.5257431e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5846605     |
| ep_rewmean              | -0.266        |
| episodes                | 932           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 93069         |
| policy_loss             | 0.026876215   |
| qf1_loss                | 5.839645e-06  |
| qf2_loss                | 9.352244e-07  |
| time_elapsed            | 457           |
| total timesteps         | 93100         |
| value_loss              | 2.6050591e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.798007      |
| ep_rewmean              | -0.262        |
| episodes                | 936           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 93469         |
| policy_loss             | 0.02495013    |
| qf1_loss                | 4.2147394e-06 |
| qf2_loss                | 2.9776838e-06 |
| time_elapsed            | 459           |
| total timesteps         | 93500         |
| value_loss              | 7.82185e-06   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.947625      |
| ep_rewmean              | -0.257        |
| episodes                | 940           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 93869         |
| policy_loss             | 0.02371109    |
| qf1_loss                | 2.996093e-07  |
| qf2_loss                | 5.7769597e-07 |
| time_elapsed            | 460           |
| total timesteps         | 93900         |
| value_loss              | 1.264083e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.61759       |
| ep_rewmean              | -0.256        |
| episodes                | 944           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 94269         |
| policy_loss             | 0.027840033   |
| qf1_loss                | 7.520544e-07  |
| qf2_loss                | 6.0485456e-07 |
| time_elapsed            | 462           |
| total timesteps         | 94300         |
| value_loss              | 1.4806852e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9214263     |
| ep_rewmean              | -0.257        |
| episodes                | 948           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 94669         |
| policy_loss             | 0.028782163   |
| qf1_loss                | 3.7444502e-07 |
| qf2_loss                | 4.6455563e-07 |
| time_elapsed            | 464           |
| total timesteps         | 94700         |
| value_loss              | 3.329938e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.3200026     |
| ep_rewmean              | -0.256        |
| episodes                | 952           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 95069         |
| policy_loss             | 0.027161535   |
| qf1_loss                | 9.981316e-07  |
| qf2_loss                | 1.7519664e-06 |
| time_elapsed            | 466           |
| total timesteps         | 95100         |
| value_loss              | 8.5732665e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.1495676     |
| ep_rewmean              | -0.257        |
| episodes                | 956           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 95469         |
| policy_loss             | 0.02584283    |
| qf1_loss                | 3.7120394e-06 |
| qf2_loss                | 6.6813336e-06 |
| time_elapsed            | 468           |
| total timesteps         | 95500         |
| value_loss              | 7.1891573e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.48298       |
| ep_rewmean              | -0.259        |
| episodes                | 960           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 95869         |
| policy_loss             | 0.03183144    |
| qf1_loss                | 7.71078e-06   |
| qf2_loss                | 7.105553e-06  |
| time_elapsed            | 470           |
| total timesteps         | 95900         |
| value_loss              | 1.7115694e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4863653     |
| ep_rewmean              | -0.263        |
| episodes                | 964           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 96269         |
| policy_loss             | 0.026707496   |
| qf1_loss                | 7.845283e-06  |
| qf2_loss                | 7.926877e-06  |
| time_elapsed            | 472           |
| total timesteps         | 96300         |
| value_loss              | 1.6971403e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.202217      |
| ep_rewmean              | -0.259        |
| episodes                | 968           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 96669         |
| policy_loss             | 0.029054288   |
| qf1_loss                | 1.007662e-06  |
| qf2_loss                | 7.9756944e-07 |
| time_elapsed            | 474           |
| total timesteps         | 96700         |
| value_loss              | 1.9878842e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.704569      |
| ep_rewmean              | -0.257        |
| episodes                | 972           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 97069         |
| policy_loss             | 0.023207061   |
| qf1_loss                | 9.133174e-07  |
| qf2_loss                | 1.1684217e-06 |
| time_elapsed            | 476           |
| total timesteps         | 97100         |
| value_loss              | 1.1372117e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7937407     |
| ep_rewmean              | -0.26         |
| episodes                | 976           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 97469         |
| policy_loss             | 0.029296257   |
| qf1_loss                | 2.8297238e-06 |
| qf2_loss                | 1.0952774e-06 |
| time_elapsed            | 478           |
| total timesteps         | 97500         |
| value_loss              | 4.019378e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4351225     |
| ep_rewmean              | -0.264        |
| episodes                | 980           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 97869         |
| policy_loss             | 0.031436842   |
| qf1_loss                | 1.2749426e-06 |
| qf2_loss                | 7.1275235e-07 |
| time_elapsed            | 480           |
| total timesteps         | 97900         |
| value_loss              | 5.2348555e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.551613      |
| ep_rewmean              | -0.263        |
| episodes                | 984           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 98269         |
| policy_loss             | 0.030292992   |
| qf1_loss                | 1.5955106e-06 |
| qf2_loss                | 1.7008422e-06 |
| time_elapsed            | 482           |
| total timesteps         | 98300         |
| value_loss              | 1.9791598e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.2993264     |
| ep_rewmean              | -0.261        |
| episodes                | 988           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 98669         |
| policy_loss             | 0.036951303   |
| qf1_loss                | 2.097629e-06  |
| qf2_loss                | 2.2114464e-06 |
| time_elapsed            | 483           |
| total timesteps         | 98700         |
| value_loss              | 4.177235e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7867923     |
| ep_rewmean              | -0.261        |
| episodes                | 992           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 99069         |
| policy_loss             | 0.027599545   |
| qf1_loss                | 1.070341e-06  |
| qf2_loss                | 6.001795e-07  |
| time_elapsed            | 485           |
| total timesteps         | 99100         |
| value_loss              | 4.1454595e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.107025      |
| ep_rewmean              | -0.257        |
| episodes                | 996           |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 99469         |
| policy_loss             | 0.02787238    |
| qf1_loss                | 8.27975e-07   |
| qf2_loss                | 1.2676e-06    |
| time_elapsed            | 487           |
| total timesteps         | 99500         |
| value_loss              | 1.1683068e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.335745      |
| ep_rewmean              | -0.255        |
| episodes                | 1000          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 99869         |
| policy_loss             | 0.022706743   |
| qf1_loss                | 7.8424443e-07 |
| qf2_loss                | 8.703133e-07  |
| time_elapsed            | 489           |
| total timesteps         | 99900         |
| value_loss              | 1.9684524e-06 |
-------------------------------------------
Eval num_timesteps=100000, episode_reward=-0.14 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.140992      |
| ep_rewmean              | -0.251        |
| episodes                | 1004          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 100269        |
| policy_loss             | 0.026637264   |
| qf1_loss                | 7.2926355e-07 |
| qf2_loss                | 4.5792123e-07 |
| time_elapsed            | 492           |
| total timesteps         | 100300        |
| value_loss              | 7.0849114e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.285292      |
| ep_rewmean              | -0.25         |
| episodes                | 1008          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 100669        |
| policy_loss             | 0.025784962   |
| qf1_loss                | 1.3724091e-06 |
| qf2_loss                | 1.1016905e-06 |
| time_elapsed            | 494           |
| total timesteps         | 100700        |
| value_loss              | 1.7408375e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.967674      |
| ep_rewmean              | -0.248        |
| episodes                | 1012          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 101069        |
| policy_loss             | 0.024268905   |
| qf1_loss                | 1.1737435e-05 |
| qf2_loss                | 1.337029e-05  |
| time_elapsed            | 495           |
| total timesteps         | 101100        |
| value_loss              | 1.5491362e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.618067      |
| ep_rewmean              | -0.249        |
| episodes                | 1016          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 101469        |
| policy_loss             | 0.028280916   |
| qf1_loss                | 1.2310203e-06 |
| qf2_loss                | 1.0962165e-06 |
| time_elapsed            | 497           |
| total timesteps         | 101500        |
| value_loss              | 7.1472635e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.3153477     |
| ep_rewmean              | -0.251        |
| episodes                | 1020          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 101869        |
| policy_loss             | 0.023354338   |
| qf1_loss                | 1.8501485e-06 |
| qf2_loss                | 8.6262963e-07 |
| time_elapsed            | 499           |
| total timesteps         | 101900        |
| value_loss              | 4.2841966e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.883873      |
| ep_rewmean              | -0.251        |
| episodes                | 1024          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 102269        |
| policy_loss             | 0.026078008   |
| qf1_loss                | 8.777022e-07  |
| qf2_loss                | 6.474081e-07  |
| time_elapsed            | 501           |
| total timesteps         | 102300        |
| value_loss              | 2.2843224e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.20335       |
| ep_rewmean              | -0.253        |
| episodes                | 1028          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 102669        |
| policy_loss             | 0.024995927   |
| qf1_loss                | 8.217681e-07  |
| qf2_loss                | 7.5128094e-07 |
| time_elapsed            | 503           |
| total timesteps         | 102700        |
| value_loss              | 4.2328554e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.965637      |
| ep_rewmean              | -0.251        |
| episodes                | 1032          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 103069        |
| policy_loss             | 0.029781349   |
| qf1_loss                | 7.7017444e-07 |
| qf2_loss                | 1.3785422e-06 |
| time_elapsed            | 505           |
| total timesteps         | 103100        |
| value_loss              | 8.8624813e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.915638      |
| ep_rewmean              | -0.255        |
| episodes                | 1036          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 103469        |
| policy_loss             | 0.029602448   |
| qf1_loss                | 1.9125673e-05 |
| qf2_loss                | 2.0305715e-05 |
| time_elapsed            | 507           |
| total timesteps         | 103500        |
| value_loss              | 1.0816616e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.826071      |
| ep_rewmean              | -0.256        |
| episodes                | 1040          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 103869        |
| policy_loss             | 0.027749013   |
| qf1_loss                | 6.9273465e-06 |
| qf2_loss                | 7.1276704e-06 |
| time_elapsed            | 509           |
| total timesteps         | 103900        |
| value_loss              | 1.6650829e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.846344      |
| ep_rewmean              | -0.265        |
| episodes                | 1044          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 104269        |
| policy_loss             | 0.02146554    |
| qf1_loss                | 2.5781505e-06 |
| qf2_loss                | 1.7706832e-06 |
| time_elapsed            | 511           |
| total timesteps         | 104300        |
| value_loss              | 9.893054e-07  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 6.8554153    |
| ep_rewmean              | -0.27        |
| episodes                | 1048         |
| eplenmean               | 100          |
| fps                     | 203          |
| mean 100 episode reward | -0.3         |
| n_updates               | 104669       |
| policy_loss             | 0.023130357  |
| qf1_loss                | 2.457437e-07 |
| qf2_loss                | 2.315958e-07 |
| time_elapsed            | 513          |
| total timesteps         | 104700       |
| value_loss              | 7.813653e-07 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.551387      |
| ep_rewmean              | -0.269        |
| episodes                | 1052          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 105069        |
| policy_loss             | 0.031940825   |
| qf1_loss                | 8.204371e-07  |
| qf2_loss                | 4.913867e-07  |
| time_elapsed            | 515           |
| total timesteps         | 105100        |
| value_loss              | 1.0466006e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.975236      |
| ep_rewmean              | -0.268        |
| episodes                | 1056          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 105469        |
| policy_loss             | 0.02314685    |
| qf1_loss                | 2.4716928e-07 |
| qf2_loss                | 4.1591161e-07 |
| time_elapsed            | 517           |
| total timesteps         | 105500        |
| value_loss              | 1.320617e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8942537     |
| ep_rewmean              | -0.261        |
| episodes                | 1060          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 105869        |
| policy_loss             | 0.02290006    |
| qf1_loss                | 4.8008593e-07 |
| qf2_loss                | 8.203635e-07  |
| time_elapsed            | 519           |
| total timesteps         | 105900        |
| value_loss              | 1.0469726e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.487741      |
| ep_rewmean              | -0.255        |
| episodes                | 1064          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 106269        |
| policy_loss             | 0.031791195   |
| qf1_loss                | 1.114035e-05  |
| qf2_loss                | 1.172684e-05  |
| time_elapsed            | 521           |
| total timesteps         | 106300        |
| value_loss              | 3.2755408e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6654434     |
| ep_rewmean              | -0.255        |
| episodes                | 1068          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 106669        |
| policy_loss             | 0.029932875   |
| qf1_loss                | 3.197467e-07  |
| qf2_loss                | 4.692442e-07  |
| time_elapsed            | 523           |
| total timesteps         | 106700        |
| value_loss              | 1.0214025e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.853076      |
| ep_rewmean              | -0.255        |
| episodes                | 1072          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 107069        |
| policy_loss             | 0.024949849   |
| qf1_loss                | 2.366177e-07  |
| qf2_loss                | 6.515571e-07  |
| time_elapsed            | 525           |
| total timesteps         | 107100        |
| value_loss              | 1.7742886e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8578987     |
| ep_rewmean              | -0.257        |
| episodes                | 1076          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.3          |
| n_updates               | 107469        |
| policy_loss             | 0.023756966   |
| qf1_loss                | 1.1154157e-06 |
| qf2_loss                | 1.2222731e-06 |
| time_elapsed            | 526           |
| total timesteps         | 107500        |
| value_loss              | 4.8228264e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5341477     |
| ep_rewmean              | -0.254        |
| episodes                | 1080          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.3          |
| n_updates               | 107869        |
| policy_loss             | 0.025191471   |
| qf1_loss                | 3.6075727e-07 |
| qf2_loss                | 2.909194e-07  |
| time_elapsed            | 528           |
| total timesteps         | 107900        |
| value_loss              | 2.2411135e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7808533     |
| ep_rewmean              | -0.254        |
| episodes                | 1084          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.3          |
| n_updates               | 108269        |
| policy_loss             | 0.026131261   |
| qf1_loss                | 7.9234263e-07 |
| qf2_loss                | 6.8256657e-07 |
| time_elapsed            | 530           |
| total timesteps         | 108300        |
| value_loss              | 4.3396485e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7699237     |
| ep_rewmean              | -0.255        |
| episodes                | 1088          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.3          |
| n_updates               | 108669        |
| policy_loss             | 0.030840946   |
| qf1_loss                | 1.0187482e-06 |
| qf2_loss                | 1.185959e-06  |
| time_elapsed            | 532           |
| total timesteps         | 108700        |
| value_loss              | 5.7890946e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4726434     |
| ep_rewmean              | -0.252        |
| episodes                | 1092          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.3          |
| n_updates               | 109069        |
| policy_loss             | 0.029045852   |
| qf1_loss                | 1.2679487e-06 |
| qf2_loss                | 1.113096e-06  |
| time_elapsed            | 534           |
| total timesteps         | 109100        |
| value_loss              | 8.051372e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.5410824     |
| ep_rewmean              | -0.253        |
| episodes                | 1096          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.3          |
| n_updates               | 109469        |
| policy_loss             | 0.03351597    |
| qf1_loss                | 4.5271256e-07 |
| qf2_loss                | 3.0256393e-07 |
| time_elapsed            | 536           |
| total timesteps         | 109500        |
| value_loss              | 2.4322173e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7002316     |
| ep_rewmean              | -0.252        |
| episodes                | 1100          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.3          |
| n_updates               | 109869        |
| policy_loss             | 0.028970435   |
| qf1_loss                | 6.849503e-06  |
| qf2_loss                | 6.373436e-06  |
| time_elapsed            | 538           |
| total timesteps         | 109900        |
| value_loss              | 9.4647436e-07 |
-------------------------------------------
Eval num_timesteps=110000, episode_reward=-0.20 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.101583      |
| ep_rewmean              | -0.252        |
| episodes                | 1104          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 110269        |
| policy_loss             | 0.02690737    |
| qf1_loss                | 1.6779632e-06 |
| qf2_loss                | 1.3731233e-06 |
| time_elapsed            | 540           |
| total timesteps         | 110300        |
| value_loss              | 8.637431e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0916915     |
| ep_rewmean              | -0.25         |
| episodes                | 1108          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.3          |
| n_updates               | 110669        |
| policy_loss             | 0.025615955   |
| qf1_loss                | 3.780556e-07  |
| qf2_loss                | 8.057656e-07  |
| time_elapsed            | 542           |
| total timesteps         | 110700        |
| value_loss              | 2.1908697e-06 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 6.6238947      |
| ep_rewmean              | -0.249         |
| episodes                | 1112           |
| eplenmean               | 100            |
| fps                     | 204            |
| mean 100 episode reward | -0.2           |
| n_updates               | 111069         |
| policy_loss             | 0.02284126     |
| qf1_loss                | 1.5899745e-05  |
| qf2_loss                | 1.31668085e-05 |
| time_elapsed            | 544            |
| total timesteps         | 111100         |
| value_loss              | 6.5362474e-06  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1208234     |
| ep_rewmean              | -0.247        |
| episodes                | 1116          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 111469        |
| policy_loss             | 0.022535525   |
| qf1_loss                | 4.6305897e-07 |
| qf2_loss                | 5.6576187e-07 |
| time_elapsed            | 546           |
| total timesteps         | 111500        |
| value_loss              | 1.1593359e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.940489      |
| ep_rewmean              | -0.244        |
| episodes                | 1120          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 111869        |
| policy_loss             | 0.021378905   |
| qf1_loss                | 2.223622e-06  |
| qf2_loss                | 1.4473528e-06 |
| time_elapsed            | 548           |
| total timesteps         | 111900        |
| value_loss              | 2.888553e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.951415      |
| ep_rewmean              | -0.243        |
| episodes                | 1124          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 112269        |
| policy_loss             | 0.025293672   |
| qf1_loss                | 5.2529194e-06 |
| qf2_loss                | 5.030143e-06  |
| time_elapsed            | 550           |
| total timesteps         | 112300        |
| value_loss              | 3.7007248e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.991542      |
| ep_rewmean              | -0.241        |
| episodes                | 1128          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 112669        |
| policy_loss             | 0.021531474   |
| qf1_loss                | 2.8691267e-07 |
| qf2_loss                | 5.5619023e-07 |
| time_elapsed            | 552           |
| total timesteps         | 112700        |
| value_loss              | 1.0298223e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.104765      |
| ep_rewmean              | -0.239        |
| episodes                | 1132          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 113069        |
| policy_loss             | 0.02233823    |
| qf1_loss                | 4.2738358e-07 |
| qf2_loss                | 3.7198654e-07 |
| time_elapsed            | 554           |
| total timesteps         | 113100        |
| value_loss              | 6.749655e-07  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 6.839595     |
| ep_rewmean              | -0.234       |
| episodes                | 1136         |
| eplenmean               | 100          |
| fps                     | 204          |
| mean 100 episode reward | -0.2         |
| n_updates               | 113469       |
| policy_loss             | 0.022540705  |
| qf1_loss                | 6.035896e-06 |
| qf2_loss                | 6.288518e-06 |
| time_elapsed            | 556          |
| total timesteps         | 113500       |
| value_loss              | 3.751326e-07 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8345613     |
| ep_rewmean              | -0.232        |
| episodes                | 1140          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 113869        |
| policy_loss             | 0.021871243   |
| qf1_loss                | 8.7667985e-07 |
| qf2_loss                | 6.7278745e-07 |
| time_elapsed            | 557           |
| total timesteps         | 113900        |
| value_loss              | 5.438518e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1497507     |
| ep_rewmean              | -0.219        |
| episodes                | 1144          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 114269        |
| policy_loss             | 0.027641388   |
| qf1_loss                | 8.9550986e-07 |
| qf2_loss                | 3.118671e-07  |
| time_elapsed            | 559           |
| total timesteps         | 114300        |
| value_loss              | 8.841633e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9846287     |
| ep_rewmean              | -0.211        |
| episodes                | 1148          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 114669        |
| policy_loss             | 0.0253991     |
| qf1_loss                | 5.506778e-07  |
| qf2_loss                | 5.404815e-07  |
| time_elapsed            | 561           |
| total timesteps         | 114700        |
| value_loss              | 3.8000994e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.142105      |
| ep_rewmean              | -0.212        |
| episodes                | 1152          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 115069        |
| policy_loss             | 0.021281932   |
| qf1_loss                | 1.8170798e-05 |
| qf2_loss                | 1.8139594e-05 |
| time_elapsed            | 563           |
| total timesteps         | 115100        |
| value_loss              | 3.4847537e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.649884      |
| ep_rewmean              | -0.211        |
| episodes                | 1156          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 115469        |
| policy_loss             | 0.024407957   |
| qf1_loss                | 5.060802e-06  |
| qf2_loss                | 5.426695e-06  |
| time_elapsed            | 565           |
| total timesteps         | 115500        |
| value_loss              | 1.0331199e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8756933     |
| ep_rewmean              | -0.212        |
| episodes                | 1160          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 115869        |
| policy_loss             | 0.024073794   |
| qf1_loss                | 4.9775754e-06 |
| qf2_loss                | 5.6958147e-06 |
| time_elapsed            | 567           |
| total timesteps         | 115900        |
| value_loss              | 2.093447e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.36271       |
| ep_rewmean              | -0.213        |
| episodes                | 1164          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 116269        |
| policy_loss             | 0.026886145   |
| qf1_loss                | 6.0231478e-06 |
| qf2_loss                | 6.6457937e-06 |
| time_elapsed            | 569           |
| total timesteps         | 116300        |
| value_loss              | 1.3669651e-06 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 6.300653     |
| ep_rewmean              | -0.212       |
| episodes                | 1168         |
| eplenmean               | 100          |
| fps                     | 204          |
| mean 100 episode reward | -0.2         |
| n_updates               | 116669       |
| policy_loss             | 0.025337748  |
| qf1_loss                | 9.164563e-06 |
| qf2_loss                | 9.312798e-06 |
| time_elapsed            | 571          |
| total timesteps         | 116700       |
| value_loss              | 8.267105e-07 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9718        |
| ep_rewmean              | -0.211        |
| episodes                | 1172          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 117069        |
| policy_loss             | 0.025490785   |
| qf1_loss                | 3.618281e-06  |
| qf2_loss                | 1.4015038e-06 |
| time_elapsed            | 573           |
| total timesteps         | 117100        |
| value_loss              | 1.7329483e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1358595     |
| ep_rewmean              | -0.206        |
| episodes                | 1176          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 117469        |
| policy_loss             | 0.019377252   |
| qf1_loss                | 1.6411866e-07 |
| qf2_loss                | 2.587832e-07  |
| time_elapsed            | 575           |
| total timesteps         | 117500        |
| value_loss              | 8.979023e-07  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 6.848791     |
| ep_rewmean              | -0.206       |
| episodes                | 1180         |
| eplenmean               | 100          |
| fps                     | 204          |
| mean 100 episode reward | -0.2         |
| n_updates               | 117869       |
| policy_loss             | 0.02417263   |
| qf1_loss                | 5.087285e-07 |
| qf2_loss                | 8.791456e-07 |
| time_elapsed            | 577          |
| total timesteps         | 117900       |
| value_loss              | 3.41035e-07  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.794096      |
| ep_rewmean              | -0.206        |
| episodes                | 1184          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 118269        |
| policy_loss             | 0.022526108   |
| qf1_loss                | 4.9989757e-07 |
| qf2_loss                | 4.886566e-07  |
| time_elapsed            | 579           |
| total timesteps         | 118300        |
| value_loss              | 1.4409492e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.027568      |
| ep_rewmean              | -0.206        |
| episodes                | 1188          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 118669        |
| policy_loss             | 0.024595538   |
| qf1_loss                | 9.2811297e-07 |
| qf2_loss                | 9.716734e-07  |
| time_elapsed            | 581           |
| total timesteps         | 118700        |
| value_loss              | 2.1848336e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.954912      |
| ep_rewmean              | -0.206        |
| episodes                | 1192          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 119069        |
| policy_loss             | 0.02213965    |
| qf1_loss                | 8.2746936e-07 |
| qf2_loss                | 4.4259588e-07 |
| time_elapsed            | 583           |
| total timesteps         | 119100        |
| value_loss              | 1.7387041e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.002591      |
| ep_rewmean              | -0.205        |
| episodes                | 1196          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 119469        |
| policy_loss             | 0.027737344   |
| qf1_loss                | 1.9322508e-07 |
| qf2_loss                | 1.852161e-07  |
| time_elapsed            | 585           |
| total timesteps         | 119500        |
| value_loss              | 3.6285527e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7026625     |
| ep_rewmean              | -0.205        |
| episodes                | 1200          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 119869        |
| policy_loss             | 0.024376411   |
| qf1_loss                | 2.732327e-07  |
| qf2_loss                | 3.620459e-07  |
| time_elapsed            | 587           |
| total timesteps         | 119900        |
| value_loss              | 2.0281661e-06 |
-------------------------------------------
Eval num_timesteps=120000, episode_reward=-0.14 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.214652      |
| ep_rewmean              | -0.203        |
| episodes                | 1204          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 120269        |
| policy_loss             | 0.01895117    |
| qf1_loss                | 1.2126553e-07 |
| qf2_loss                | 1.3051248e-07 |
| time_elapsed            | 589           |
| total timesteps         | 120300        |
| value_loss              | 3.956975e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0316763     |
| ep_rewmean              | -0.204        |
| episodes                | 1208          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 120669        |
| policy_loss             | 0.020266276   |
| qf1_loss                | 3.15688e-07   |
| qf2_loss                | 2.3633088e-07 |
| time_elapsed            | 591           |
| total timesteps         | 120700        |
| value_loss              | 2.7661667e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.570166      |
| ep_rewmean              | -0.204        |
| episodes                | 1212          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 121069        |
| policy_loss             | 0.028622542   |
| qf1_loss                | 4.1283857e-07 |
| qf2_loss                | 5.9683606e-07 |
| time_elapsed            | 593           |
| total timesteps         | 121100        |
| value_loss              | 1.6930022e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1549015     |
| ep_rewmean              | -0.204        |
| episodes                | 1216          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 121469        |
| policy_loss             | 0.018955976   |
| qf1_loss                | 5.681216e-06  |
| qf2_loss                | 5.682073e-06  |
| time_elapsed            | 595           |
| total timesteps         | 121500        |
| value_loss              | 1.1220321e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.858418      |
| ep_rewmean              | -0.205        |
| episodes                | 1220          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 121869        |
| policy_loss             | 0.020278381   |
| qf1_loss                | 5.569403e-07  |
| qf2_loss                | 5.240636e-07  |
| time_elapsed            | 597           |
| total timesteps         | 121900        |
| value_loss              | 2.0073035e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1134458     |
| ep_rewmean              | -0.204        |
| episodes                | 1224          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 122269        |
| policy_loss             | 0.023839168   |
| qf1_loss                | 3.2208052e-07 |
| qf2_loss                | 4.1520593e-07 |
| time_elapsed            | 599           |
| total timesteps         | 122300        |
| value_loss              | 1.0937925e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.958235      |
| ep_rewmean              | -0.203        |
| episodes                | 1228          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 122669        |
| policy_loss             | 0.023123192   |
| qf1_loss                | 4.5760362e-07 |
| qf2_loss                | 7.913673e-07  |
| time_elapsed            | 601           |
| total timesteps         | 122700        |
| value_loss              | 8.1235635e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.733988      |
| ep_rewmean              | -0.202        |
| episodes                | 1232          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 123069        |
| policy_loss             | 0.025163682   |
| qf1_loss                | 3.9446337e-07 |
| qf2_loss                | 4.935986e-07  |
| time_elapsed            | 603           |
| total timesteps         | 123100        |
| value_loss              | 5.5726485e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.823527      |
| ep_rewmean              | -0.202        |
| episodes                | 1236          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 123469        |
| policy_loss             | 0.019382495   |
| qf1_loss                | 4.0490627e-07 |
| qf2_loss                | 3.906198e-07  |
| time_elapsed            | 604           |
| total timesteps         | 123500        |
| value_loss              | 1.6839476e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.415039      |
| ep_rewmean              | -0.202        |
| episodes                | 1240          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 123869        |
| policy_loss             | 0.022622073   |
| qf1_loss                | 1.104553e-06  |
| qf2_loss                | 4.6124137e-07 |
| time_elapsed            | 606           |
| total timesteps         | 123900        |
| value_loss              | 1.7767545e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4814024     |
| ep_rewmean              | -0.202        |
| episodes                | 1244          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 124269        |
| policy_loss             | 0.023716759   |
| qf1_loss                | 3.2698154e-07 |
| qf2_loss                | 2.285655e-07  |
| time_elapsed            | 608           |
| total timesteps         | 124300        |
| value_loss              | 4.940892e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1948547     |
| ep_rewmean              | -0.202        |
| episodes                | 1248          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 124669        |
| policy_loss             | 0.026160885   |
| qf1_loss                | 6.8232436e-07 |
| qf2_loss                | 6.9549367e-07 |
| time_elapsed            | 610           |
| total timesteps         | 124700        |
| value_loss              | 2.1619253e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9431877     |
| ep_rewmean              | -0.199        |
| episodes                | 1252          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 125069        |
| policy_loss             | 0.020890865   |
| qf1_loss                | 2.7739688e-07 |
| qf2_loss                | 1.6610598e-07 |
| time_elapsed            | 612           |
| total timesteps         | 125100        |
| value_loss              | 3.5369573e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.851368      |
| ep_rewmean              | -0.198        |
| episodes                | 1256          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 125469        |
| policy_loss             | 0.018932488   |
| qf1_loss                | 4.737031e-07  |
| qf2_loss                | 2.2430551e-07 |
| time_elapsed            | 614           |
| total timesteps         | 125500        |
| value_loss              | 1.6163717e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.847416      |
| ep_rewmean              | -0.196        |
| episodes                | 1260          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 125869        |
| policy_loss             | 0.021710169   |
| qf1_loss                | 2.648552e-07  |
| qf2_loss                | 6.1925175e-07 |
| time_elapsed            | 616           |
| total timesteps         | 125900        |
| value_loss              | 2.0740642e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.866012      |
| ep_rewmean              | -0.194        |
| episodes                | 1264          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 126269        |
| policy_loss             | 0.019614574   |
| qf1_loss                | 1.6257384e-07 |
| qf2_loss                | 3.431009e-07  |
| time_elapsed            | 618           |
| total timesteps         | 126300        |
| value_loss              | 2.3142333e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.4201317     |
| ep_rewmean              | -0.195        |
| episodes                | 1268          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 126669        |
| policy_loss             | 0.018341439   |
| qf1_loss                | 1.4757985e-07 |
| qf2_loss                | 2.9247587e-07 |
| time_elapsed            | 620           |
| total timesteps         | 126700        |
| value_loss              | 6.423366e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0277615     |
| ep_rewmean              | -0.194        |
| episodes                | 1272          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 127069        |
| policy_loss             | 0.025675282   |
| qf1_loss                | 3.4624097e-06 |
| qf2_loss                | 3.589376e-06  |
| time_elapsed            | 622           |
| total timesteps         | 127100        |
| value_loss              | 6.277094e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.275392      |
| ep_rewmean              | -0.191        |
| episodes                | 1276          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 127469        |
| policy_loss             | 0.020237427   |
| qf1_loss                | 4.7672322e-07 |
| qf2_loss                | 5.1014405e-07 |
| time_elapsed            | 624           |
| total timesteps         | 127500        |
| value_loss              | 3.5076397e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.142806      |
| ep_rewmean              | -0.189        |
| episodes                | 1280          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 127869        |
| policy_loss             | 0.016288789   |
| qf1_loss                | 7.547329e-06  |
| qf2_loss                | 7.900366e-06  |
| time_elapsed            | 626           |
| total timesteps         | 127900        |
| value_loss              | 2.0664939e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7853775     |
| ep_rewmean              | -0.189        |
| episodes                | 1284          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 128269        |
| policy_loss             | 0.02761515    |
| qf1_loss                | 4.4596607e-07 |
| qf2_loss                | 4.4073127e-07 |
| time_elapsed            | 628           |
| total timesteps         | 128300        |
| value_loss              | 4.530966e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.342392      |
| ep_rewmean              | -0.187        |
| episodes                | 1288          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 128669        |
| policy_loss             | 0.020222887   |
| qf1_loss                | 2.9122478e-07 |
| qf2_loss                | 3.1335972e-07 |
| time_elapsed            | 630           |
| total timesteps         | 128700        |
| value_loss              | 8.5157365e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.078747      |
| ep_rewmean              | -0.187        |
| episodes                | 1292          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 129069        |
| policy_loss             | 0.020937055   |
| qf1_loss                | 8.644103e-06  |
| qf2_loss                | 7.6849265e-06 |
| time_elapsed            | 632           |
| total timesteps         | 129100        |
| value_loss              | 6.1643465e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.223996      |
| ep_rewmean              | -0.187        |
| episodes                | 1296          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 129469        |
| policy_loss             | 0.01611508    |
| qf1_loss                | 6.350796e-06  |
| qf2_loss                | 6.8802856e-06 |
| time_elapsed            | 634           |
| total timesteps         | 129500        |
| value_loss              | 6.6624796e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0508394     |
| ep_rewmean              | -0.188        |
| episodes                | 1300          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 129869        |
| policy_loss             | 0.018626202   |
| qf1_loss                | 2.0488885e-07 |
| qf2_loss                | 3.8876126e-07 |
| time_elapsed            | 636           |
| total timesteps         | 129900        |
| value_loss              | 8.1157555e-07 |
-------------------------------------------
Eval num_timesteps=130000, episode_reward=-0.13 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.734047      |
| ep_rewmean              | -0.188        |
| episodes                | 1304          |
| eplenmean               | 100           |
| fps                     | 203           |
| mean 100 episode reward | -0.2          |
| n_updates               | 130269        |
| policy_loss             | 0.025661714   |
| qf1_loss                | 1.2332269e-07 |
| qf2_loss                | 3.732027e-07  |
| time_elapsed            | 638           |
| total timesteps         | 130300        |
| value_loss              | 3.7238817e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.110927      |
| ep_rewmean              | -0.186        |
| episodes                | 1308          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 130669        |
| policy_loss             | 0.022458728   |
| qf1_loss                | 4.810285e-06  |
| qf2_loss                | 3.960572e-06  |
| time_elapsed            | 640           |
| total timesteps         | 130700        |
| value_loss              | 1.6915164e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7344484     |
| ep_rewmean              | -0.186        |
| episodes                | 1312          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 131069        |
| policy_loss             | 0.024724942   |
| qf1_loss                | 2.7085264e-07 |
| qf2_loss                | 2.1044534e-07 |
| time_elapsed            | 642           |
| total timesteps         | 131100        |
| value_loss              | 3.260526e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1034107     |
| ep_rewmean              | -0.184        |
| episodes                | 1316          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 131469        |
| policy_loss             | 0.016352402   |
| qf1_loss                | 6.785608e-07  |
| qf2_loss                | 7.6026697e-07 |
| time_elapsed            | 644           |
| total timesteps         | 131500        |
| value_loss              | 4.8191987e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8328204     |
| ep_rewmean              | -0.183        |
| episodes                | 1320          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 131869        |
| policy_loss             | 0.018431045   |
| qf1_loss                | 1.6809487e-07 |
| qf2_loss                | 3.5784484e-07 |
| time_elapsed            | 646           |
| total timesteps         | 131900        |
| value_loss              | 5.8579695e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1334953     |
| ep_rewmean              | -0.182        |
| episodes                | 1324          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 132269        |
| policy_loss             | 0.02036554    |
| qf1_loss                | 4.6494284e-07 |
| qf2_loss                | 3.7766551e-07 |
| time_elapsed            | 648           |
| total timesteps         | 132300        |
| value_loss              | 2.554938e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.095634      |
| ep_rewmean              | -0.182        |
| episodes                | 1328          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 132669        |
| policy_loss             | 0.019195795   |
| qf1_loss                | 5.741151e-07  |
| qf2_loss                | 4.771026e-07  |
| time_elapsed            | 650           |
| total timesteps         | 132700        |
| value_loss              | 2.5173579e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1981173     |
| ep_rewmean              | -0.182        |
| episodes                | 1332          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 133069        |
| policy_loss             | 0.020326383   |
| qf1_loss                | 5.9166535e-07 |
| qf2_loss                | 2.5571782e-07 |
| time_elapsed            | 652           |
| total timesteps         | 133100        |
| value_loss              | 2.2689662e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.056957      |
| ep_rewmean              | -0.183        |
| episodes                | 1336          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 133469        |
| policy_loss             | 0.015544956   |
| qf1_loss                | 1.8109914e-07 |
| qf2_loss                | 1.5810272e-07 |
| time_elapsed            | 654           |
| total timesteps         | 133500        |
| value_loss              | 3.9051739e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0511866     |
| ep_rewmean              | -0.183        |
| episodes                | 1340          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 133869        |
| policy_loss             | 0.016715975   |
| qf1_loss                | 3.4302393e-06 |
| qf2_loss                | 2.9513442e-06 |
| time_elapsed            | 656           |
| total timesteps         | 133900        |
| value_loss              | 1.7884985e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.318568      |
| ep_rewmean              | -0.181        |
| episodes                | 1344          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 134269        |
| policy_loss             | 0.020539057   |
| qf1_loss                | 5.066771e-07  |
| qf2_loss                | 3.4963927e-07 |
| time_elapsed            | 657           |
| total timesteps         | 134300        |
| value_loss              | 2.502279e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.044356      |
| ep_rewmean              | -0.181        |
| episodes                | 1348          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 134669        |
| policy_loss             | 0.021457445   |
| qf1_loss                | 2.2600837e-07 |
| qf2_loss                | 5.001407e-07  |
| time_elapsed            | 659           |
| total timesteps         | 134700        |
| value_loss              | 3.8426617e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2791758     |
| ep_rewmean              | -0.181        |
| episodes                | 1352          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 135069        |
| policy_loss             | 0.019992372   |
| qf1_loss                | 6.0181196e-07 |
| qf2_loss                | 3.959412e-07  |
| time_elapsed            | 661           |
| total timesteps         | 135100        |
| value_loss              | 7.885675e-07  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 7.125252     |
| ep_rewmean              | -0.181       |
| episodes                | 1356         |
| eplenmean               | 100          |
| fps                     | 204          |
| mean 100 episode reward | -0.2         |
| n_updates               | 135469       |
| policy_loss             | 0.01742385   |
| qf1_loss                | 3.422991e-06 |
| qf2_loss                | 3.28563e-06  |
| time_elapsed            | 663          |
| total timesteps         | 135500       |
| value_loss              | 3.524619e-07 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1655083     |
| ep_rewmean              | -0.18         |
| episodes                | 1360          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 135869        |
| policy_loss             | 0.018630369   |
| qf1_loss                | 2.795275e-06  |
| qf2_loss                | 2.4324834e-06 |
| time_elapsed            | 665           |
| total timesteps         | 135900        |
| value_loss              | 6.422879e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.866649      |
| ep_rewmean              | -0.18         |
| episodes                | 1364          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 136269        |
| policy_loss             | 0.015434847   |
| qf1_loss                | 1.4674677e-07 |
| qf2_loss                | 1.7524395e-07 |
| time_elapsed            | 667           |
| total timesteps         | 136300        |
| value_loss              | 5.1037745e-07 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 6.4300756    |
| ep_rewmean              | -0.179       |
| episodes                | 1368         |
| eplenmean               | 100          |
| fps                     | 204          |
| mean 100 episode reward | -0.2         |
| n_updates               | 136669       |
| policy_loss             | 0.017151255  |
| qf1_loss                | 5.817187e-07 |
| qf2_loss                | 3.99389e-07  |
| time_elapsed            | 669          |
| total timesteps         | 136700       |
| value_loss              | 1.037758e-06 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.78467       |
| ep_rewmean              | -0.179        |
| episodes                | 1372          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 137069        |
| policy_loss             | 0.02108966    |
| qf1_loss                | 1.2597229e-07 |
| qf2_loss                | 3.0701193e-07 |
| time_elapsed            | 671           |
| total timesteps         | 137100        |
| value_loss              | 5.670636e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.883703      |
| ep_rewmean              | -0.18         |
| episodes                | 1376          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 137469        |
| policy_loss             | 0.018792382   |
| qf1_loss                | 7.0599316e-07 |
| qf2_loss                | 1.4820063e-07 |
| time_elapsed            | 673           |
| total timesteps         | 137500        |
| value_loss              | 1.8256336e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.924857      |
| ep_rewmean              | -0.178        |
| episodes                | 1380          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 137869        |
| policy_loss             | 0.020536423   |
| qf1_loss                | 2.7420572e-07 |
| qf2_loss                | 3.3931582e-07 |
| time_elapsed            | 675           |
| total timesteps         | 137900        |
| value_loss              | 3.0129854e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.902441      |
| ep_rewmean              | -0.177        |
| episodes                | 1384          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 138269        |
| policy_loss             | 0.017213872   |
| qf1_loss                | 3.178413e-07  |
| qf2_loss                | 1.4232364e-07 |
| time_elapsed            | 677           |
| total timesteps         | 138300        |
| value_loss              | 2.482336e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.859458      |
| ep_rewmean              | -0.177        |
| episodes                | 1388          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 138669        |
| policy_loss             | 0.019874977   |
| qf1_loss                | 3.5355737e-07 |
| qf2_loss                | 3.56754e-07   |
| time_elapsed            | 679           |
| total timesteps         | 138700        |
| value_loss              | 1.2416989e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.7726054     |
| ep_rewmean              | -0.176        |
| episodes                | 1392          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 139069        |
| policy_loss             | 0.019724885   |
| qf1_loss                | 2.2901656e-07 |
| qf2_loss                | 1.3512417e-07 |
| time_elapsed            | 681           |
| total timesteps         | 139100        |
| value_loss              | 1.9741337e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0636377     |
| ep_rewmean              | -0.175        |
| episodes                | 1396          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 139469        |
| policy_loss             | 0.019373426   |
| qf1_loss                | 4.6696964e-06 |
| qf2_loss                | 3.993509e-06  |
| time_elapsed            | 683           |
| total timesteps         | 139500        |
| value_loss              | 3.2538563e-07 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 6.7796164      |
| ep_rewmean              | -0.173         |
| episodes                | 1400           |
| eplenmean               | 100            |
| fps                     | 204            |
| mean 100 episode reward | -0.2           |
| n_updates               | 139869         |
| policy_loss             | 0.017345684    |
| qf1_loss                | 2.8197496e-07  |
| qf2_loss                | 1.07716744e-07 |
| time_elapsed            | 685            |
| total timesteps         | 139900         |
| value_loss              | 4.994845e-07   |
--------------------------------------------
Eval num_timesteps=140000, episode_reward=-0.15 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.838014      |
| ep_rewmean              | -0.172        |
| episodes                | 1404          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 140269        |
| policy_loss             | 0.020464346   |
| qf1_loss                | 3.0325677e-06 |
| qf2_loss                | 3.0394551e-06 |
| time_elapsed            | 687           |
| total timesteps         | 140300        |
| value_loss              | 5.598572e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9510603     |
| ep_rewmean              | -0.172        |
| episodes                | 1408          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 140669        |
| policy_loss             | 0.016875805   |
| qf1_loss                | 3.5817234e-07 |
| qf2_loss                | 2.3039834e-07 |
| time_elapsed            | 689           |
| total timesteps         | 140700        |
| value_loss              | 5.824992e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.920145      |
| ep_rewmean              | -0.171        |
| episodes                | 1412          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 141069        |
| policy_loss             | 0.019919174   |
| qf1_loss                | 2.6713008e-06 |
| qf2_loss                | 2.754652e-06  |
| time_elapsed            | 691           |
| total timesteps         | 141100        |
| value_loss              | 3.653318e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2576394     |
| ep_rewmean              | -0.171        |
| episodes                | 1416          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 141469        |
| policy_loss             | 0.018097918   |
| qf1_loss                | 3.0642716e-06 |
| qf2_loss                | 2.7797369e-06 |
| time_elapsed            | 693           |
| total timesteps         | 141500        |
| value_loss              | 2.671791e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2259903     |
| ep_rewmean              | -0.171        |
| episodes                | 1420          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 141869        |
| policy_loss             | 0.014058076   |
| qf1_loss                | 2.2756768e-07 |
| qf2_loss                | 1.3281468e-07 |
| time_elapsed            | 695           |
| total timesteps         | 141900        |
| value_loss              | 8.3567244e-08 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0719166     |
| ep_rewmean              | -0.169        |
| episodes                | 1424          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 142269        |
| policy_loss             | 0.017163942   |
| qf1_loss                | 2.2253822e-07 |
| qf2_loss                | 5.422446e-07  |
| time_elapsed            | 697           |
| total timesteps         | 142300        |
| value_loss              | 2.3443995e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0094137     |
| ep_rewmean              | -0.169        |
| episodes                | 1428          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 142669        |
| policy_loss             | 0.014173905   |
| qf1_loss                | 1.3396534e-07 |
| qf2_loss                | 9.120224e-08  |
| time_elapsed            | 698           |
| total timesteps         | 142700        |
| value_loss              | 2.802564e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8415127     |
| ep_rewmean              | -0.168        |
| episodes                | 1432          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 143069        |
| policy_loss             | 0.021643106   |
| qf1_loss                | 9.869443e-07  |
| qf2_loss                | 4.8009355e-07 |
| time_elapsed            | 700           |
| total timesteps         | 143100        |
| value_loss              | 2.1112983e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.209363      |
| ep_rewmean              | -0.168        |
| episodes                | 1436          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 143469        |
| policy_loss             | 0.01566693    |
| qf1_loss                | 3.051722e-07  |
| qf2_loss                | 1.954185e-07  |
| time_elapsed            | 702           |
| total timesteps         | 143500        |
| value_loss              | 6.7873873e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.3738985     |
| ep_rewmean              | -0.167        |
| episodes                | 1440          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 143869        |
| policy_loss             | 0.013449066   |
| qf1_loss                | 1.2215764e-07 |
| qf2_loss                | 1.4226322e-07 |
| time_elapsed            | 704           |
| total timesteps         | 143900        |
| value_loss              | 1.4751205e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9938784     |
| ep_rewmean              | -0.168        |
| episodes                | 1444          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 144269        |
| policy_loss             | 0.013944487   |
| qf1_loss                | 1.6999515e-07 |
| qf2_loss                | 3.5313275e-07 |
| time_elapsed            | 706           |
| total timesteps         | 144300        |
| value_loss              | 6.101297e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.240632      |
| ep_rewmean              | -0.167        |
| episodes                | 1448          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 144669        |
| policy_loss             | 0.0148378415  |
| qf1_loss                | 7.371138e-08  |
| qf2_loss                | 1.2179208e-07 |
| time_elapsed            | 708           |
| total timesteps         | 144700        |
| value_loss              | 2.4090107e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.165947      |
| ep_rewmean              | -0.166        |
| episodes                | 1452          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 145069        |
| policy_loss             | 0.015109991   |
| qf1_loss                | 4.0978992e-07 |
| qf2_loss                | 8.0974417e-07 |
| time_elapsed            | 710           |
| total timesteps         | 145100        |
| value_loss              | 6.0625746e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0737925     |
| ep_rewmean              | -0.166        |
| episodes                | 1456          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 145469        |
| policy_loss             | 0.014060498   |
| qf1_loss                | 2.6280404e-07 |
| qf2_loss                | 1.316492e-07  |
| time_elapsed            | 712           |
| total timesteps         | 145500        |
| value_loss              | 2.2091369e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.056245      |
| ep_rewmean              | -0.166        |
| episodes                | 1460          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 145869        |
| policy_loss             | 0.014752928   |
| qf1_loss                | 2.6538053e-06 |
| qf2_loss                | 2.5409818e-06 |
| time_elapsed            | 714           |
| total timesteps         | 145900        |
| value_loss              | 6.840818e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0250626     |
| ep_rewmean              | -0.165        |
| episodes                | 1464          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 146269        |
| policy_loss             | 0.016633205   |
| qf1_loss                | 3.0472953e-07 |
| qf2_loss                | 2.4201273e-07 |
| time_elapsed            | 716           |
| total timesteps         | 146300        |
| value_loss              | 3.1244295e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2479362     |
| ep_rewmean              | -0.167        |
| episodes                | 1468          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 146669        |
| policy_loss             | 0.012279157   |
| qf1_loss                | 2.6405216e-06 |
| qf2_loss                | 2.5647664e-06 |
| time_elapsed            | 718           |
| total timesteps         | 146700        |
| value_loss              | 1.0176428e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.20056       |
| ep_rewmean              | -0.168        |
| episodes                | 1472          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 147069        |
| policy_loss             | 0.015992118   |
| qf1_loss                | 1.0957007e-07 |
| qf2_loss                | 1.3592222e-07 |
| time_elapsed            | 720           |
| total timesteps         | 147100        |
| value_loss              | 5.061641e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.404789      |
| ep_rewmean              | -0.167        |
| episodes                | 1476          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 147469        |
| policy_loss             | 0.013223376   |
| qf1_loss                | 1.8422846e-06 |
| qf2_loss                | 1.96239e-06   |
| time_elapsed            | 722           |
| total timesteps         | 147500        |
| value_loss              | 1.512966e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0095415     |
| ep_rewmean              | -0.167        |
| episodes                | 1480          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 147869        |
| policy_loss             | 0.014293633   |
| qf1_loss                | 2.4473684e-06 |
| qf2_loss                | 2.5122515e-06 |
| time_elapsed            | 724           |
| total timesteps         | 147900        |
| value_loss              | 5.4091583e-07 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 7.141759       |
| ep_rewmean              | -0.167         |
| episodes                | 1484           |
| eplenmean               | 100            |
| fps                     | 204            |
| mean 100 episode reward | -0.2           |
| n_updates               | 148269         |
| policy_loss             | 0.018108262    |
| qf1_loss                | 1.16047644e-07 |
| qf2_loss                | 1.4336102e-07  |
| time_elapsed            | 726            |
| total timesteps         | 148300         |
| value_loss              | 2.6407304e-07  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.215886      |
| ep_rewmean              | -0.166        |
| episodes                | 1488          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 148669        |
| policy_loss             | 0.0147643285  |
| qf1_loss                | 2.4696737e-07 |
| qf2_loss                | 2.104327e-07  |
| time_elapsed            | 728           |
| total timesteps         | 148700        |
| value_loss              | 7.840078e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.943763      |
| ep_rewmean              | -0.166        |
| episodes                | 1492          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 149069        |
| policy_loss             | 0.01610924    |
| qf1_loss                | 3.6848175e-07 |
| qf2_loss                | 2.5372378e-07 |
| time_elapsed            | 730           |
| total timesteps         | 149100        |
| value_loss              | 7.026871e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1854153     |
| ep_rewmean              | -0.167        |
| episodes                | 1496          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 149469        |
| policy_loss             | 0.013562028   |
| qf1_loss                | 1.1372665e-07 |
| qf2_loss                | 2.6660963e-08 |
| time_elapsed            | 732           |
| total timesteps         | 149500        |
| value_loss              | 3.4226406e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0488787     |
| ep_rewmean              | -0.168        |
| episodes                | 1500          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 149869        |
| policy_loss             | 0.01642727    |
| qf1_loss                | 1.3580704e-07 |
| qf2_loss                | 3.6228244e-07 |
| time_elapsed            | 734           |
| total timesteps         | 149900        |
| value_loss              | 3.333054e-07  |
-------------------------------------------
Eval num_timesteps=150000, episode_reward=-0.14 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.351148      |
| ep_rewmean              | -0.168        |
| episodes                | 1504          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 150269        |
| policy_loss             | 0.016282786   |
| qf1_loss                | 4.888989e-07  |
| qf2_loss                | 1.261902e-06  |
| time_elapsed            | 736           |
| total timesteps         | 150300        |
| value_loss              | 4.1376012e-07 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 7.1529236      |
| ep_rewmean              | -0.168         |
| episodes                | 1508           |
| eplenmean               | 100            |
| fps                     | 204            |
| mean 100 episode reward | -0.2           |
| n_updates               | 150669         |
| policy_loss             | 0.012555555    |
| qf1_loss                | 7.570253e-08   |
| qf2_loss                | 1.18502925e-07 |
| time_elapsed            | 738            |
| total timesteps         | 150700         |
| value_loss              | 2.8739325e-07  |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 7.14412        |
| ep_rewmean              | -0.168         |
| episodes                | 1512           |
| eplenmean               | 100            |
| fps                     | 204            |
| mean 100 episode reward | -0.2           |
| n_updates               | 151069         |
| policy_loss             | 0.015031133    |
| qf1_loss                | 1.1297976e-07  |
| qf2_loss                | 1.11569754e-07 |
| time_elapsed            | 740            |
| total timesteps         | 151100         |
| value_loss              | 6.770525e-07   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2660875     |
| ep_rewmean              | -0.169        |
| episodes                | 1516          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 151469        |
| policy_loss             | 0.015114357   |
| qf1_loss                | 2.7858113e-07 |
| qf2_loss                | 1.4046319e-07 |
| time_elapsed            | 742           |
| total timesteps         | 151500        |
| value_loss              | 6.853002e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0406046     |
| ep_rewmean              | -0.17         |
| episodes                | 1520          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 151869        |
| policy_loss             | 0.015269844   |
| qf1_loss                | 2.574123e-07  |
| qf2_loss                | 1.3057006e-07 |
| time_elapsed            | 744           |
| total timesteps         | 151900        |
| value_loss              | 2.3737151e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0469794     |
| ep_rewmean              | -0.17         |
| episodes                | 1524          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 152269        |
| policy_loss             | 0.018569646   |
| qf1_loss                | 2.306586e-06  |
| qf2_loss                | 2.2173226e-06 |
| time_elapsed            | 745           |
| total timesteps         | 152300        |
| value_loss              | 3.2490513e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2207384     |
| ep_rewmean              | -0.171        |
| episodes                | 1528          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 152669        |
| policy_loss             | 0.012434681   |
| qf1_loss                | 2.1406174e-06 |
| qf2_loss                | 2.1346177e-06 |
| time_elapsed            | 747           |
| total timesteps         | 152700        |
| value_loss              | 2.5142023e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9141703     |
| ep_rewmean              | -0.172        |
| episodes                | 1532          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 153069        |
| policy_loss             | 0.01529178    |
| qf1_loss                | 1.2574395e-07 |
| qf2_loss                | 1.5863864e-07 |
| time_elapsed            | 749           |
| total timesteps         | 153100        |
| value_loss              | 4.5224377e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2868376     |
| ep_rewmean              | -0.171        |
| episodes                | 1536          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 153469        |
| policy_loss             | 0.014289769   |
| qf1_loss                | 2.2365227e-06 |
| qf2_loss                | 2.1233016e-06 |
| time_elapsed            | 751           |
| total timesteps         | 153500        |
| value_loss              | 2.919714e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.09412       |
| ep_rewmean              | -0.172        |
| episodes                | 1540          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 153869        |
| policy_loss             | 0.015629347   |
| qf1_loss                | 6.9270925e-07 |
| qf2_loss                | 7.134954e-07  |
| time_elapsed            | 753           |
| total timesteps         | 153900        |
| value_loss              | 1.6285692e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8641853     |
| ep_rewmean              | -0.173        |
| episodes                | 1544          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 154269        |
| policy_loss             | 0.01689526    |
| qf1_loss                | 2.1827586e-06 |
| qf2_loss                | 2.2645604e-06 |
| time_elapsed            | 755           |
| total timesteps         | 154300        |
| value_loss              | 9.797405e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0527325     |
| ep_rewmean              | -0.174        |
| episodes                | 1548          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 154669        |
| policy_loss             | 0.013241041   |
| qf1_loss                | 1.5527641e-07 |
| qf2_loss                | 4.700409e-07  |
| time_elapsed            | 757           |
| total timesteps         | 154700        |
| value_loss              | 9.0237415e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0050764     |
| ep_rewmean              | -0.175        |
| episodes                | 1552          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 155069        |
| policy_loss             | 0.016971752   |
| qf1_loss                | 2.0272142e-07 |
| qf2_loss                | 1.2541652e-07 |
| time_elapsed            | 759           |
| total timesteps         | 155100        |
| value_loss              | 6.8120397e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.6635246     |
| ep_rewmean              | -0.175        |
| episodes                | 1556          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 155469        |
| policy_loss             | 0.018869992   |
| qf1_loss                | 4.2712898e-07 |
| qf2_loss                | 2.8517113e-07 |
| time_elapsed            | 761           |
| total timesteps         | 155500        |
| value_loss              | 1.7444153e-06 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.00147      |
| entropy                 | 7.0432096    |
| ep_rewmean              | -0.175       |
| episodes                | 1560         |
| eplenmean               | 100          |
| fps                     | 204          |
| mean 100 episode reward | -0.2         |
| n_updates               | 155869       |
| policy_loss             | 0.012100189  |
| qf1_loss                | 2.524038e-07 |
| qf2_loss                | 5.677664e-07 |
| time_elapsed            | 763          |
| total timesteps         | 155900       |
| value_loss              | 3.341455e-07 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9792347     |
| ep_rewmean              | -0.175        |
| episodes                | 1564          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 156269        |
| policy_loss             | 0.01875718    |
| qf1_loss                | 3.909076e-06  |
| qf2_loss                | 4.1585063e-06 |
| time_elapsed            | 765           |
| total timesteps         | 156300        |
| value_loss              | 1.8083805e-06 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 7.0911007      |
| ep_rewmean              | -0.174         |
| episodes                | 1568           |
| eplenmean               | 100            |
| fps                     | 204            |
| mean 100 episode reward | -0.2           |
| n_updates               | 156669         |
| policy_loss             | 0.016730908    |
| qf1_loss                | 1.08288596e-07 |
| qf2_loss                | 1.3136145e-07  |
| time_elapsed            | 767            |
| total timesteps         | 156700         |
| value_loss              | 5.338379e-07   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1646504     |
| ep_rewmean              | -0.172        |
| episodes                | 1572          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 157069        |
| policy_loss             | 0.015864277   |
| qf1_loss                | 1.4000086e-07 |
| qf2_loss                | 2.6218493e-07 |
| time_elapsed            | 769           |
| total timesteps         | 157100        |
| value_loss              | 4.943091e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.3052025     |
| ep_rewmean              | -0.173        |
| episodes                | 1576          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 157469        |
| policy_loss             | 0.018382465   |
| qf1_loss                | 1.8416024e-07 |
| qf2_loss                | 8.296097e-08  |
| time_elapsed            | 771           |
| total timesteps         | 157500        |
| value_loss              | 1.8890698e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.3176293     |
| ep_rewmean              | -0.175        |
| episodes                | 1580          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 157869        |
| policy_loss             | 0.013427671   |
| qf1_loss                | 2.9168817e-07 |
| qf2_loss                | 2.382353e-07  |
| time_elapsed            | 773           |
| total timesteps         | 157900        |
| value_loss              | 6.373192e-07  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 7.2165084      |
| ep_rewmean              | -0.175         |
| episodes                | 1584           |
| eplenmean               | 100            |
| fps                     | 204            |
| mean 100 episode reward | -0.2           |
| n_updates               | 158269         |
| policy_loss             | 0.015004863    |
| qf1_loss                | 2.1133135e-07  |
| qf2_loss                | 1.15035945e-07 |
| time_elapsed            | 775            |
| total timesteps         | 158300         |
| value_loss              | 4.1625475e-07  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1558027     |
| ep_rewmean              | -0.176        |
| episodes                | 1588          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 158669        |
| policy_loss             | 0.018379778   |
| qf1_loss                | 1.9035673e-06 |
| qf2_loss                | 1.7104534e-06 |
| time_elapsed            | 776           |
| total timesteps         | 158700        |
| value_loss              | 2.7311114e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1056247     |
| ep_rewmean              | -0.176        |
| episodes                | 1592          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 159069        |
| policy_loss             | 0.015172983   |
| qf1_loss                | 5.5975796e-08 |
| qf2_loss                | 5.538883e-08  |
| time_elapsed            | 778           |
| total timesteps         | 159100        |
| value_loss              | 2.6406144e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.12226       |
| ep_rewmean              | -0.176        |
| episodes                | 1596          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 159469        |
| policy_loss             | 0.014435806   |
| qf1_loss                | 2.3937603e-06 |
| qf2_loss                | 2.0478415e-06 |
| time_elapsed            | 780           |
| total timesteps         | 159500        |
| value_loss              | 4.3300236e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0270023     |
| ep_rewmean              | -0.175        |
| episodes                | 1600          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 159869        |
| policy_loss             | 0.0149268545  |
| qf1_loss                | 3.4949883e-06 |
| qf2_loss                | 3.2464116e-06 |
| time_elapsed            | 782           |
| total timesteps         | 159900        |
| value_loss              | 3.4249518e-07 |
-------------------------------------------
Eval num_timesteps=160000, episode_reward=-0.14 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.27569       |
| ep_rewmean              | -0.175        |
| episodes                | 1604          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 160269        |
| policy_loss             | 0.011542016   |
| qf1_loss                | 1.8794773e-07 |
| qf2_loss                | 6.697144e-08  |
| time_elapsed            | 785           |
| total timesteps         | 160300        |
| value_loss              | 4.4709464e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.136909      |
| ep_rewmean              | -0.177        |
| episodes                | 1608          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 160669        |
| policy_loss             | 0.017011268   |
| qf1_loss                | 6.737013e-07  |
| qf2_loss                | 4.7473011e-07 |
| time_elapsed            | 787           |
| total timesteps         | 160700        |
| value_loss              | 4.1993863e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.330415      |
| ep_rewmean              | -0.176        |
| episodes                | 1612          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 161069        |
| policy_loss             | 0.0150776515  |
| qf1_loss                | 3.4644177e-06 |
| qf2_loss                | 3.1734749e-06 |
| time_elapsed            | 788           |
| total timesteps         | 161100        |
| value_loss              | 2.1218406e-07 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 7.0286694      |
| ep_rewmean              | -0.176         |
| episodes                | 1616           |
| eplenmean               | 100            |
| fps                     | 204            |
| mean 100 episode reward | -0.2           |
| n_updates               | 161469         |
| policy_loss             | 0.012526993    |
| qf1_loss                | 1.15673046e-07 |
| qf2_loss                | 1.1519275e-07  |
| time_elapsed            | 790            |
| total timesteps         | 161500         |
| value_loss              | 3.9119266e-07  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.252967      |
| ep_rewmean              | -0.176        |
| episodes                | 1620          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 161869        |
| policy_loss             | 0.018169878   |
| qf1_loss                | 1.3683348e-07 |
| qf2_loss                | 9.895015e-08  |
| time_elapsed            | 792           |
| total timesteps         | 161900        |
| value_loss              | 6.392537e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.5822477     |
| ep_rewmean              | -0.177        |
| episodes                | 1624          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 162269        |
| policy_loss             | 0.011508087   |
| qf1_loss                | 2.213757e-06  |
| qf2_loss                | 1.9760434e-06 |
| time_elapsed            | 794           |
| total timesteps         | 162300        |
| value_loss              | 5.137501e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.77485       |
| ep_rewmean              | -0.176        |
| episodes                | 1628          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 162669        |
| policy_loss             | 0.018158797   |
| qf1_loss                | 3.1488793e-07 |
| qf2_loss                | 1.0305557e-07 |
| time_elapsed            | 796           |
| total timesteps         | 162700        |
| value_loss              | 1.1129637e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0782213     |
| ep_rewmean              | -0.176        |
| episodes                | 1632          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 163069        |
| policy_loss             | 0.018746093   |
| qf1_loss                | 3.5783677e-07 |
| qf2_loss                | 2.8360657e-07 |
| time_elapsed            | 798           |
| total timesteps         | 163100        |
| value_loss              | 1.0689657e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2541275     |
| ep_rewmean              | -0.176        |
| episodes                | 1636          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 163469        |
| policy_loss             | 0.010938512   |
| qf1_loss                | 1.6338486e-06 |
| qf2_loss                | 1.6740269e-06 |
| time_elapsed            | 800           |
| total timesteps         | 163500        |
| value_loss              | 1.0826107e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.150611      |
| ep_rewmean              | -0.174        |
| episodes                | 1640          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 163869        |
| policy_loss             | 0.01434314    |
| qf1_loss                | 1.5296314e-07 |
| qf2_loss                | 2.4652022e-07 |
| time_elapsed            | 802           |
| total timesteps         | 163900        |
| value_loss              | 3.5115926e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.367829      |
| ep_rewmean              | -0.173        |
| episodes                | 1644          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 164269        |
| policy_loss             | 0.020353764   |
| qf1_loss                | 1.9489148e-06 |
| qf2_loss                | 1.6568289e-06 |
| time_elapsed            | 804           |
| total timesteps         | 164300        |
| value_loss              | 4.4277604e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.20267       |
| ep_rewmean              | -0.173        |
| episodes                | 1648          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 164669        |
| policy_loss             | 0.010644664   |
| qf1_loss                | 1.7374413e-06 |
| qf2_loss                | 1.7080804e-06 |
| time_elapsed            | 806           |
| total timesteps         | 164700        |
| value_loss              | 1.8145847e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.991535      |
| ep_rewmean              | -0.173        |
| episodes                | 1652          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 165069        |
| policy_loss             | 0.015819535   |
| qf1_loss                | 1.331882e-06  |
| qf2_loss                | 1.5656284e-06 |
| time_elapsed            | 808           |
| total timesteps         | 165100        |
| value_loss              | 3.273756e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9983325     |
| ep_rewmean              | -0.173        |
| episodes                | 1656          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 165469        |
| policy_loss             | 0.012903044   |
| qf1_loss                | 1.0127076e-07 |
| qf2_loss                | 1.1326474e-07 |
| time_elapsed            | 810           |
| total timesteps         | 165500        |
| value_loss              | 4.1756323e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1750507     |
| ep_rewmean              | -0.174        |
| episodes                | 1660          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 165869        |
| policy_loss             | 0.012954563   |
| qf1_loss                | 2.2858802e-07 |
| qf2_loss                | 2.4743133e-07 |
| time_elapsed            | 812           |
| total timesteps         | 165900        |
| value_loss              | 4.2362467e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.995116      |
| ep_rewmean              | -0.176        |
| episodes                | 1664          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 166269        |
| policy_loss             | 0.014339394   |
| qf1_loss                | 1.2125042e-07 |
| qf2_loss                | 5.2504234e-08 |
| time_elapsed            | 813           |
| total timesteps         | 166300        |
| value_loss              | 2.2734694e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.144491      |
| ep_rewmean              | -0.177        |
| episodes                | 1668          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 166669        |
| policy_loss             | 0.018894851   |
| qf1_loss                | 7.8499724e-08 |
| qf2_loss                | 5.3747158e-08 |
| time_elapsed            | 815           |
| total timesteps         | 166700        |
| value_loss              | 1.8177184e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.8081965     |
| ep_rewmean              | -0.179        |
| episodes                | 1672          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 167069        |
| policy_loss             | 0.015031843   |
| qf1_loss                | 4.962251e-07  |
| qf2_loss                | 3.442336e-07  |
| time_elapsed            | 817           |
| total timesteps         | 167100        |
| value_loss              | 1.2952496e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9791174     |
| ep_rewmean              | -0.178        |
| episodes                | 1676          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 167469        |
| policy_loss             | 0.012938658   |
| qf1_loss                | 1.6819169e-07 |
| qf2_loss                | 1.2060906e-07 |
| time_elapsed            | 819           |
| total timesteps         | 167500        |
| value_loss              | 3.001466e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0382648     |
| ep_rewmean              | -0.177        |
| episodes                | 1680          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 167869        |
| policy_loss             | 0.013667889   |
| qf1_loss                | 1.9746206e-07 |
| qf2_loss                | 2.1836232e-07 |
| time_elapsed            | 821           |
| total timesteps         | 167900        |
| value_loss              | 3.5379213e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.4653425     |
| ep_rewmean              | -0.176        |
| episodes                | 1684          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 168269        |
| policy_loss             | 0.013535472   |
| qf1_loss                | 1.6310545e-06 |
| qf2_loss                | 1.5630908e-06 |
| time_elapsed            | 823           |
| total timesteps         | 168300        |
| value_loss              | 3.5201754e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.726081      |
| ep_rewmean              | -0.176        |
| episodes                | 1688          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 168669        |
| policy_loss             | 0.01781709    |
| qf1_loss                | 3.1210627e-06 |
| qf2_loss                | 3.7152818e-06 |
| time_elapsed            | 825           |
| total timesteps         | 168700        |
| value_loss              | 3.8256894e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2129745     |
| ep_rewmean              | -0.175        |
| episodes                | 1692          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 169069        |
| policy_loss             | 0.010315067   |
| qf1_loss                | 1.6875039e-06 |
| qf2_loss                | 1.5787517e-06 |
| time_elapsed            | 827           |
| total timesteps         | 169100        |
| value_loss              | 2.7408615e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2771735     |
| ep_rewmean              | -0.175        |
| episodes                | 1696          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 169469        |
| policy_loss             | 0.015093681   |
| qf1_loss                | 3.5298302e-07 |
| qf2_loss                | 1.3424582e-07 |
| time_elapsed            | 829           |
| total timesteps         | 169500        |
| value_loss              | 1.8322294e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.076507      |
| ep_rewmean              | -0.175        |
| episodes                | 1700          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 169869        |
| policy_loss             | 0.013825109   |
| qf1_loss                | 1.0179031e-07 |
| qf2_loss                | 8.6502745e-08 |
| time_elapsed            | 831           |
| total timesteps         | 169900        |
| value_loss              | 4.284056e-07  |
-------------------------------------------
Eval num_timesteps=170000, episode_reward=-0.15 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1405687     |
| ep_rewmean              | -0.175        |
| episodes                | 1704          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 170269        |
| policy_loss             | 0.0108652515  |
| qf1_loss                | 2.0438375e-07 |
| qf2_loss                | 1.0509038e-07 |
| time_elapsed            | 833           |
| total timesteps         | 170300        |
| value_loss              | 2.0977612e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0161276     |
| ep_rewmean              | -0.173        |
| episodes                | 1708          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 170669        |
| policy_loss             | 0.014209814   |
| qf1_loss                | 1.4445531e-07 |
| qf2_loss                | 1.5425587e-07 |
| time_elapsed            | 835           |
| total timesteps         | 170700        |
| value_loss              | 3.6095372e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.18863       |
| ep_rewmean              | -0.172        |
| episodes                | 1712          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 171069        |
| policy_loss             | 0.012407946   |
| qf1_loss                | 2.3014235e-07 |
| qf2_loss                | 7.52986e-08   |
| time_elapsed            | 837           |
| total timesteps         | 171100        |
| value_loss              | 3.1024166e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1278906     |
| ep_rewmean              | -0.172        |
| episodes                | 1716          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 171469        |
| policy_loss             | 0.013060787   |
| qf1_loss                | 2.059109e-06  |
| qf2_loss                | 1.7173888e-06 |
| time_elapsed            | 839           |
| total timesteps         | 171500        |
| value_loss              | 1.4301871e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0527134     |
| ep_rewmean              | -0.171        |
| episodes                | 1720          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 171869        |
| policy_loss             | 0.013244046   |
| qf1_loss                | 5.658849e-07  |
| qf2_loss                | 2.5344409e-07 |
| time_elapsed            | 841           |
| total timesteps         | 171900        |
| value_loss              | 6.6176557e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.237156      |
| ep_rewmean              | -0.17         |
| episodes                | 1724          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 172269        |
| policy_loss             | 0.010346091   |
| qf1_loss                | 2.7923528e-07 |
| qf2_loss                | 5.7146178e-08 |
| time_elapsed            | 843           |
| total timesteps         | 172300        |
| value_loss              | 2.1778392e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.930946      |
| ep_rewmean              | -0.171        |
| episodes                | 1728          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 172669        |
| policy_loss             | 0.013422626   |
| qf1_loss                | 1.6752348e-07 |
| qf2_loss                | 1.7844199e-06 |
| time_elapsed            | 845           |
| total timesteps         | 172700        |
| value_loss              | 6.254054e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.088227      |
| ep_rewmean              | -0.172        |
| episodes                | 1732          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 173069        |
| policy_loss             | 0.017820453   |
| qf1_loss                | 1.7384542e-06 |
| qf2_loss                | 1.8945257e-06 |
| time_elapsed            | 847           |
| total timesteps         | 173100        |
| value_loss              | 8.6168774e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0617228     |
| ep_rewmean              | -0.172        |
| episodes                | 1736          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 173469        |
| policy_loss             | 0.0143813     |
| qf1_loss                | 1.9701723e-07 |
| qf2_loss                | 8.67365e-08   |
| time_elapsed            | 849           |
| total timesteps         | 173500        |
| value_loss              | 6.341236e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.3103676     |
| ep_rewmean              | -0.171        |
| episodes                | 1740          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 173869        |
| policy_loss             | 0.0129364235  |
| qf1_loss                | 1.1956952e-07 |
| qf2_loss                | 3.550152e-08  |
| time_elapsed            | 851           |
| total timesteps         | 173900        |
| value_loss              | 5.7193284e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.03427       |
| ep_rewmean              | -0.171        |
| episodes                | 1744          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 174269        |
| policy_loss             | 0.014948024   |
| qf1_loss                | 2.828992e-06  |
| qf2_loss                | 1.3200847e-07 |
| time_elapsed            | 853           |
| total timesteps         | 174300        |
| value_loss              | 1.2031481e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1825895     |
| ep_rewmean              | -0.171        |
| episodes                | 1748          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 174669        |
| policy_loss             | 0.012980713   |
| qf1_loss                | 1.4650979e-07 |
| qf2_loss                | 3.0570625e-08 |
| time_elapsed            | 854           |
| total timesteps         | 174700        |
| value_loss              | 2.7027883e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.251693      |
| ep_rewmean              | -0.171        |
| episodes                | 1752          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 175069        |
| policy_loss             | 0.011566566   |
| qf1_loss                | 1.387429e-07  |
| qf2_loss                | 2.0877263e-07 |
| time_elapsed            | 856           |
| total timesteps         | 175100        |
| value_loss              | 1.8882581e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1287446     |
| ep_rewmean              | -0.171        |
| episodes                | 1756          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 175469        |
| policy_loss             | 0.013043009   |
| qf1_loss                | 1.8476802e-06 |
| qf2_loss                | 1.3442049e-06 |
| time_elapsed            | 858           |
| total timesteps         | 175500        |
| value_loss              | 6.44214e-07   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2602196     |
| ep_rewmean              | -0.171        |
| episodes                | 1760          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 175869        |
| policy_loss             | 0.013638971   |
| qf1_loss                | 5.4882685e-07 |
| qf2_loss                | 3.383424e-07  |
| time_elapsed            | 860           |
| total timesteps         | 175900        |
| value_loss              | 8.1929824e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.360754      |
| ep_rewmean              | -0.171        |
| episodes                | 1764          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 176269        |
| policy_loss             | 0.012883375   |
| qf1_loss                | 1.7379183e-06 |
| qf2_loss                | 1.5457442e-06 |
| time_elapsed            | 862           |
| total timesteps         | 176300        |
| value_loss              | 2.2386816e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.152952      |
| ep_rewmean              | -0.17         |
| episodes                | 1768          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 176669        |
| policy_loss             | 0.016761297   |
| qf1_loss                | 2.8404733e-07 |
| qf2_loss                | 1.3585921e-07 |
| time_elapsed            | 864           |
| total timesteps         | 176700        |
| value_loss              | 7.429293e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9561834     |
| ep_rewmean              | -0.169        |
| episodes                | 1772          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 177069        |
| policy_loss             | 0.0167989     |
| qf1_loss                | 6.70829e-07   |
| qf2_loss                | 1.3233845e-06 |
| time_elapsed            | 866           |
| total timesteps         | 177100        |
| value_loss              | 1.9792155e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9064007     |
| ep_rewmean              | -0.169        |
| episodes                | 1776          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 177469        |
| policy_loss             | 0.015512047   |
| qf1_loss                | 4.3479554e-07 |
| qf2_loss                | 3.0632447e-07 |
| time_elapsed            | 868           |
| total timesteps         | 177500        |
| value_loss              | 1.4641419e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.086404      |
| ep_rewmean              | -0.169        |
| episodes                | 1780          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 177869        |
| policy_loss             | 0.010884307   |
| qf1_loss                | 2.973201e-07  |
| qf2_loss                | 3.286742e-07  |
| time_elapsed            | 870           |
| total timesteps         | 177900        |
| value_loss              | 3.3291863e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.257474      |
| ep_rewmean              | -0.169        |
| episodes                | 1784          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 178269        |
| policy_loss             | 0.012571195   |
| qf1_loss                | 3.7526155e-07 |
| qf2_loss                | 4.633225e-07  |
| time_elapsed            | 872           |
| total timesteps         | 178300        |
| value_loss              | 5.040007e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2828574     |
| ep_rewmean              | -0.17         |
| episodes                | 1788          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 178669        |
| policy_loss             | 0.009956019   |
| qf1_loss                | 1.485214e-07  |
| qf2_loss                | 1.0475182e-07 |
| time_elapsed            | 874           |
| total timesteps         | 178700        |
| value_loss              | 2.865941e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.093731      |
| ep_rewmean              | -0.17         |
| episodes                | 1792          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 179069        |
| policy_loss             | 0.018277839   |
| qf1_loss                | 2.8310643e-07 |
| qf2_loss                | 1.1291117e-07 |
| time_elapsed            | 875           |
| total timesteps         | 179100        |
| value_loss              | 7.530867e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.116577      |
| ep_rewmean              | -0.172        |
| episodes                | 1796          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 179469        |
| policy_loss             | 0.016984995   |
| qf1_loss                | 1.7819731e-07 |
| qf2_loss                | 1.2124687e-07 |
| time_elapsed            | 877           |
| total timesteps         | 179500        |
| value_loss              | 1.6049964e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.984994      |
| ep_rewmean              | -0.171        |
| episodes                | 1800          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 179869        |
| policy_loss             | 0.015011491   |
| qf1_loss                | 2.5190107e-07 |
| qf2_loss                | 8.7030116e-07 |
| time_elapsed            | 879           |
| total timesteps         | 179900        |
| value_loss              | 1.1907055e-06 |
-------------------------------------------
Eval num_timesteps=180000, episode_reward=-0.17 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.202154      |
| ep_rewmean              | -0.172        |
| episodes                | 1804          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 180269        |
| policy_loss             | 0.012391269   |
| qf1_loss                | 4.7004863e-07 |
| qf2_loss                | 4.891539e-08  |
| time_elapsed            | 882           |
| total timesteps         | 180300        |
| value_loss              | 2.5820327e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.133963      |
| ep_rewmean              | -0.173        |
| episodes                | 1808          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 180669        |
| policy_loss             | 0.010510946   |
| qf1_loss                | 1.6519875e-06 |
| qf2_loss                | 1.3280071e-06 |
| time_elapsed            | 883           |
| total timesteps         | 180700        |
| value_loss              | 2.1331786e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.931469      |
| ep_rewmean              | -0.173        |
| episodes                | 1812          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 181069        |
| policy_loss             | 0.01560756    |
| qf1_loss                | 1.2557709e-07 |
| qf2_loss                | 7.63964e-08   |
| time_elapsed            | 885           |
| total timesteps         | 181100        |
| value_loss              | 3.2398128e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0227504     |
| ep_rewmean              | -0.173        |
| episodes                | 1816          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 181469        |
| policy_loss             | 0.019631078   |
| qf1_loss                | 3.388347e-06  |
| qf2_loss                | 3.062445e-06  |
| time_elapsed            | 887           |
| total timesteps         | 181500        |
| value_loss              | 3.0296994e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0294642     |
| ep_rewmean              | -0.174        |
| episodes                | 1820          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 181869        |
| policy_loss             | 0.013614785   |
| qf1_loss                | 1.2852709e-07 |
| qf2_loss                | 1.3244086e-07 |
| time_elapsed            | 889           |
| total timesteps         | 181900        |
| value_loss              | 2.6457465e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0142145     |
| ep_rewmean              | -0.173        |
| episodes                | 1824          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 182269        |
| policy_loss             | 0.02081682    |
| qf1_loss                | 2.1922112e-06 |
| qf2_loss                | 2.2289623e-06 |
| time_elapsed            | 891           |
| total timesteps         | 182300        |
| value_loss              | 1.0591748e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0727186     |
| ep_rewmean              | -0.172        |
| episodes                | 1828          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 182669        |
| policy_loss             | 0.01350761    |
| qf1_loss                | 1.367757e-06  |
| qf2_loss                | 1.3291202e-06 |
| time_elapsed            | 893           |
| total timesteps         | 182700        |
| value_loss              | 3.0209006e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.3999095     |
| ep_rewmean              | -0.171        |
| episodes                | 1832          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 183069        |
| policy_loss             | 0.010194955   |
| qf1_loss                | 2.295754e-07  |
| qf2_loss                | 1.2105217e-07 |
| time_elapsed            | 895           |
| total timesteps         | 183100        |
| value_loss              | 6.537734e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.067024      |
| ep_rewmean              | -0.172        |
| episodes                | 1836          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 183469        |
| policy_loss             | 0.01723925    |
| qf1_loss                | 1.7369596e-06 |
| qf2_loss                | 1.5433865e-06 |
| time_elapsed            | 897           |
| total timesteps         | 183500        |
| value_loss              | 4.3594622e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.320795      |
| ep_rewmean              | -0.172        |
| episodes                | 1840          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 183869        |
| policy_loss             | 0.01081757    |
| qf1_loss                | 3.5979995e-06 |
| qf2_loss                | 3.6794959e-06 |
| time_elapsed            | 899           |
| total timesteps         | 183900        |
| value_loss              | 2.892804e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.405694      |
| ep_rewmean              | -0.173        |
| episodes                | 1844          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 184269        |
| policy_loss             | 0.015185066   |
| qf1_loss                | 1.5877972e-06 |
| qf2_loss                | 1.3967854e-06 |
| time_elapsed            | 901           |
| total timesteps         | 184300        |
| value_loss              | 7.449461e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.9733825     |
| ep_rewmean              | -0.172        |
| episodes                | 1848          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 184669        |
| policy_loss             | 0.013533022   |
| qf1_loss                | 1.5987942e-07 |
| qf2_loss                | 1.406396e-07  |
| time_elapsed            | 903           |
| total timesteps         | 184700        |
| value_loss              | 3.6125098e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.3856955     |
| ep_rewmean              | -0.172        |
| episodes                | 1852          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 185069        |
| policy_loss             | 0.009343293   |
| qf1_loss                | 3.200238e-07  |
| qf2_loss                | 7.8412e-08    |
| time_elapsed            | 905           |
| total timesteps         | 185100        |
| value_loss              | 3.2918865e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.302292      |
| ep_rewmean              | -0.173        |
| episodes                | 1856          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 185469        |
| policy_loss             | 0.013042163   |
| qf1_loss                | 1.4294075e-06 |
| qf2_loss                | 1.4772852e-06 |
| time_elapsed            | 907           |
| total timesteps         | 185500        |
| value_loss              | 4.081365e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.406596      |
| ep_rewmean              | -0.173        |
| episodes                | 1860          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 185869        |
| policy_loss             | 0.01366755    |
| qf1_loss                | 6.6185504e-07 |
| qf2_loss                | 3.1349686e-08 |
| time_elapsed            | 909           |
| total timesteps         | 185900        |
| value_loss              | 5.117562e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2298493     |
| ep_rewmean              | -0.172        |
| episodes                | 1864          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 186269        |
| policy_loss             | 0.010990068   |
| qf1_loss                | 1.3656625e-06 |
| qf2_loss                | 1.4871982e-06 |
| time_elapsed            | 910           |
| total timesteps         | 186300        |
| value_loss              | 3.7306086e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.5856905     |
| ep_rewmean              | -0.172        |
| episodes                | 1868          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 186669        |
| policy_loss             | 0.011452988   |
| qf1_loss                | 7.978907e-08  |
| qf2_loss                | 1.9045252e-08 |
| time_elapsed            | 912           |
| total timesteps         | 186700        |
| value_loss              | 4.3588017e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.3480873     |
| ep_rewmean              | -0.172        |
| episodes                | 1872          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 187069        |
| policy_loss             | 0.016303131   |
| qf1_loss                | 1.6195376e-06 |
| qf2_loss                | 1.4277842e-06 |
| time_elapsed            | 914           |
| total timesteps         | 187100        |
| value_loss              | 3.8913458e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.250323      |
| ep_rewmean              | -0.173        |
| episodes                | 1876          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 187469        |
| policy_loss             | 0.018449293   |
| qf1_loss                | 2.7102726e-07 |
| qf2_loss                | 2.2233908e-07 |
| time_elapsed            | 916           |
| total timesteps         | 187500        |
| value_loss              | 1.9348983e-07 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 7.3728724      |
| ep_rewmean              | -0.174         |
| episodes                | 1880           |
| eplenmean               | 100            |
| fps                     | 204            |
| mean 100 episode reward | -0.2           |
| n_updates               | 187869         |
| policy_loss             | 0.011912283    |
| qf1_loss                | 1.7019788e-07  |
| qf2_loss                | 1.07534476e-07 |
| time_elapsed            | 918            |
| total timesteps         | 187900         |
| value_loss              | 1.1548991e-06  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.279688      |
| ep_rewmean              | -0.175        |
| episodes                | 1884          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 188269        |
| policy_loss             | 0.012668316   |
| qf1_loss                | 1.5907435e-06 |
| qf2_loss                | 1.460665e-06  |
| time_elapsed            | 920           |
| total timesteps         | 188300        |
| value_loss              | 1.4419791e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.163213      |
| ep_rewmean              | -0.175        |
| episodes                | 1888          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 188669        |
| policy_loss             | 0.01700613    |
| qf1_loss                | 1.4710607e-06 |
| qf2_loss                | 1.3348639e-06 |
| time_elapsed            | 922           |
| total timesteps         | 188700        |
| value_loss              | 1.6582214e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1583314     |
| ep_rewmean              | -0.174        |
| episodes                | 1892          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 189069        |
| policy_loss             | 0.014813462   |
| qf1_loss                | 7.0681917e-06 |
| qf2_loss                | 6.5794866e-06 |
| time_elapsed            | 924           |
| total timesteps         | 189100        |
| value_loss              | 6.7147425e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.404233      |
| ep_rewmean              | -0.174        |
| episodes                | 1896          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 189469        |
| policy_loss             | 0.010091067   |
| qf1_loss                | 1.278355e-07  |
| qf2_loss                | 3.7850516e-08 |
| time_elapsed            | 926           |
| total timesteps         | 189500        |
| value_loss              | 4.802805e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.336114      |
| ep_rewmean              | -0.175        |
| episodes                | 1900          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 189869        |
| policy_loss             | 0.013608718   |
| qf1_loss                | 1.5243459e-06 |
| qf2_loss                | 1.3510833e-06 |
| time_elapsed            | 928           |
| total timesteps         | 189900        |
| value_loss              | 2.246675e-07  |
-------------------------------------------
Eval num_timesteps=190000, episode_reward=-0.16 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.431404      |
| ep_rewmean              | -0.174        |
| episodes                | 1904          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 190269        |
| policy_loss             | 0.009191047   |
| qf1_loss                | 1.8175383e-07 |
| qf2_loss                | 1.0955861e-07 |
| time_elapsed            | 930           |
| total timesteps         | 190300        |
| value_loss              | 2.7976142e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.274521      |
| ep_rewmean              | -0.173        |
| episodes                | 1908          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 190669        |
| policy_loss             | 0.014024898   |
| qf1_loss                | 1.4212354e-06 |
| qf2_loss                | 1.3592462e-06 |
| time_elapsed            | 932           |
| total timesteps         | 190700        |
| value_loss              | 8.7055497e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.218251      |
| ep_rewmean              | -0.174        |
| episodes                | 1912          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 191069        |
| policy_loss             | 0.011338442   |
| qf1_loss                | 1.5945133e-06 |
| qf2_loss                | 1.3887403e-06 |
| time_elapsed            | 934           |
| total timesteps         | 191100        |
| value_loss              | 6.176233e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.0413237     |
| ep_rewmean              | -0.173        |
| episodes                | 1916          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 191469        |
| policy_loss             | 0.0181664     |
| qf1_loss                | 1.4409509e-06 |
| qf2_loss                | 1.3243057e-06 |
| time_elapsed            | 936           |
| total timesteps         | 191500        |
| value_loss              | 2.5082585e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.090353      |
| ep_rewmean              | -0.173        |
| episodes                | 1920          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 191869        |
| policy_loss             | 0.015586602   |
| qf1_loss                | 1.1850686e-07 |
| qf2_loss                | 1.6646476e-07 |
| time_elapsed            | 938           |
| total timesteps         | 191900        |
| value_loss              | 2.3704784e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.284381      |
| ep_rewmean              | -0.173        |
| episodes                | 1924          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 192269        |
| policy_loss             | 0.016643066   |
| qf1_loss                | 1.3587901e-06 |
| qf2_loss                | 1.4244673e-06 |
| time_elapsed            | 940           |
| total timesteps         | 192300        |
| value_loss              | 9.503467e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.254444      |
| ep_rewmean              | -0.174        |
| episodes                | 1928          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 192669        |
| policy_loss             | 0.010587363   |
| qf1_loss                | 2.9943152e-07 |
| qf2_loss                | 9.072297e-08  |
| time_elapsed            | 942           |
| total timesteps         | 192700        |
| value_loss              | 1.6269738e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.268268      |
| ep_rewmean              | -0.173        |
| episodes                | 1932          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 193069        |
| policy_loss             | 0.010272215   |
| qf1_loss                | 1.9589208e-06 |
| qf2_loss                | 2.3280004e-06 |
| time_elapsed            | 944           |
| total timesteps         | 193100        |
| value_loss              | 3.0801057e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.186844      |
| ep_rewmean              | -0.173        |
| episodes                | 1936          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 193469        |
| policy_loss             | 0.013624606   |
| qf1_loss                | 1.9526593e-07 |
| qf2_loss                | 7.4904236e-08 |
| time_elapsed            | 946           |
| total timesteps         | 193500        |
| value_loss              | 3.6897166e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.2356405     |
| ep_rewmean              | -0.173        |
| episodes                | 1940          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 193869        |
| policy_loss             | 0.010890536   |
| qf1_loss                | 2.8921886e-06 |
| qf2_loss                | 2.7086028e-06 |
| time_elapsed            | 948           |
| total timesteps         | 193900        |
| value_loss              | 5.1697e-07    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.359536      |
| ep_rewmean              | -0.171        |
| episodes                | 1944          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 194269        |
| policy_loss             | 0.01154258    |
| qf1_loss                | 1.993375e-07  |
| qf2_loss                | 1.2311577e-07 |
| time_elapsed            | 950           |
| total timesteps         | 194300        |
| value_loss              | 4.95632e-07   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.183958      |
| ep_rewmean              | -0.173        |
| episodes                | 1948          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 194669        |
| policy_loss             | 0.014744783   |
| qf1_loss                | 1.4515451e-06 |
| qf2_loss                | 1.3826028e-06 |
| time_elapsed            | 952           |
| total timesteps         | 194700        |
| value_loss              | 4.684379e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.3656626     |
| ep_rewmean              | -0.173        |
| episodes                | 1952          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 195069        |
| policy_loss             | 0.012413191   |
| qf1_loss                | 9.1528517e-07 |
| qf2_loss                | 1.1016856e-07 |
| time_elapsed            | 954           |
| total timesteps         | 195100        |
| value_loss              | 1.4410583e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.161558      |
| ep_rewmean              | -0.172        |
| episodes                | 1956          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 195469        |
| policy_loss             | 0.014013044   |
| qf1_loss                | 1.801082e-07  |
| qf2_loss                | 2.7810097e-07 |
| time_elapsed            | 956           |
| total timesteps         | 195500        |
| value_loss              | 1.4304297e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.365501      |
| ep_rewmean              | -0.172        |
| episodes                | 1960          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 195869        |
| policy_loss             | 0.011055711   |
| qf1_loss                | 1.465365e-07  |
| qf2_loss                | 3.3556887e-08 |
| time_elapsed            | 958           |
| total timesteps         | 195900        |
| value_loss              | 2.0346492e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.5365086     |
| ep_rewmean              | -0.173        |
| episodes                | 1964          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 196269        |
| policy_loss             | 0.008774331   |
| qf1_loss                | 1.3117079e-06 |
| qf2_loss                | 1.1851182e-06 |
| time_elapsed            | 960           |
| total timesteps         | 196300        |
| value_loss              | 3.339971e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1543403     |
| ep_rewmean              | -0.174        |
| episodes                | 1968          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 196669        |
| policy_loss             | 0.017423807   |
| qf1_loss                | 1.5446858e-06 |
| qf2_loss                | 1.3290353e-06 |
| time_elapsed            | 962           |
| total timesteps         | 196700        |
| value_loss              | 7.06275e-07   |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.00147        |
| entropy                 | 7.3684616      |
| ep_rewmean              | -0.173         |
| episodes                | 1972           |
| eplenmean               | 100            |
| fps                     | 204            |
| mean 100 episode reward | -0.2           |
| n_updates               | 197069         |
| policy_loss             | 0.016355338    |
| qf1_loss                | 8.517612e-08   |
| qf2_loss                | 1.09071024e-07 |
| time_elapsed            | 964            |
| total timesteps         | 197100         |
| value_loss              | 4.8000203e-07  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.4789677     |
| ep_rewmean              | -0.173        |
| episodes                | 1976          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 197469        |
| policy_loss             | 0.013090208   |
| qf1_loss                | 3.5151518e-07 |
| qf2_loss                | 2.6550276e-07 |
| time_elapsed            | 966           |
| total timesteps         | 197500        |
| value_loss              | 5.079121e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.3483534     |
| ep_rewmean              | -0.172        |
| episodes                | 1980          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 197869        |
| policy_loss             | 0.0098692905  |
| qf1_loss                | 2.3731848e-06 |
| qf2_loss                | 2.3171472e-06 |
| time_elapsed            | 968           |
| total timesteps         | 197900        |
| value_loss              | 3.8877516e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.196148      |
| ep_rewmean              | -0.173        |
| episodes                | 1984          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 198269        |
| policy_loss             | 0.01344493    |
| qf1_loss                | 2.6141745e-07 |
| qf2_loss                | 1.319394e-07  |
| time_elapsed            | 970           |
| total timesteps         | 198300        |
| value_loss              | 1.5699524e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1805277     |
| ep_rewmean              | -0.173        |
| episodes                | 1988          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 198669        |
| policy_loss             | 0.01290144    |
| qf1_loss                | 8.93253e-07   |
| qf2_loss                | 1.1873801e-06 |
| time_elapsed            | 972           |
| total timesteps         | 198700        |
| value_loss              | 3.560533e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.1201935     |
| ep_rewmean              | -0.173        |
| episodes                | 1992          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 199069        |
| policy_loss             | 0.02295014    |
| qf1_loss                | 1.4912491e-06 |
| qf2_loss                | 1.3799722e-06 |
| time_elapsed            | 974           |
| total timesteps         | 199100        |
| value_loss              | 8.400846e-07  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 7.5973835     |
| ep_rewmean              | -0.173        |
| episodes                | 1996          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 199469        |
| policy_loss             | 0.010415867   |
| qf1_loss                | 1.3868137e-06 |
| qf2_loss                | 1.1734569e-06 |
| time_elapsed            | 976           |
| total timesteps         | 199500        |
| value_loss              | 2.9704924e-07 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.00147       |
| entropy                 | 6.948037      |
| ep_rewmean              | -0.172        |
| episodes                | 2000          |
| eplenmean               | 100           |
| fps                     | 204           |
| mean 100 episode reward | -0.2          |
| n_updates               | 199869        |
| policy_loss             | 0.011250765   |
| qf1_loss                | 2.004258e-07  |
| qf2_loss                | 1.7010032e-07 |
| time_elapsed            | 978           |
| total timesteps         | 199900        |
| value_loss              | 3.279612e-07  |
-------------------------------------------
/home/people/paumjaud/WidowX-reacher/stable-baselines/stable_baselines/common/callbacks.py:285: UserWarning: Training and eval env are not of the same type<stable_baselines.common.base_class._UnvecWrapper object at 0x7fa8bdab7cc0> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7fa8bdab7c50>
  "{} != {}".format(self.training_env, self.eval_env))
Eval num_timesteps=200000, episode_reward=-0.13 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
Saving to logs/train_0.2M_widowx_reacher-v5_SONIC/sac/widowx_reacher-v5_2
pybullet build time: May 18 2020 02:46:26
