--------------------------------------------------------------------------
WARNING: There was an error initializing an OpenFabrics device.

  Local host:   n371
  Local device: hfi1_0
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Warning: Open MPI has detected that you are running in an environment with CUDA
devices present and that you are using Intel(r) Ompi-Path networking. However,
the environment variable PSM2_CUDA was not set, meaning that the PSM2 Omni-Path
networking library was not told how to handle CUDA support.

If your application uses CUDA buffers, you should set the environment variable
PSM2_CUDA to 1; otherwise, set it to 0. Setting the variable to the wrong value
can have performance implications on your application, or even cause it to
crash.

Since it was not set, Open MPI has defaulted to setting the PSM2_CUDA
environment variable to 1.

Local hostname: n371
--------------------------------------------------------------------------
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:141: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/sac/policies.py:194: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:232: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:294: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:314: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

========== widowx_reacher-v5 ==========
Seed: 1
OrderedDict([('n_timesteps', 60000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs', 'dict(layers=[256, 256])')])
Using 1 environments
Overwriting n_timesteps with n=500000
Creating test environment
TRAINING ENV TYPE :  <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f2887e234e0>
EVAL ENV TYPE :  <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f288578dc50>
Log path: logs/train_0.5M_widowx_reacher-v5_KAY/sac/widowx_reacher-v5_2
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.9416694    |
| ent_coef_loss           | -0.6071314   |
| entropy                 | 7.724169     |
| ep_rewmean              | -1.51        |
| episodes                | 4            |
| eplenmean               | 100          |
| fps                     | 182          |
| mean 100 episode reward | -1.5         |
| n_updates               | 201          |
| policy_loss             | -6.441253    |
| qf1_loss                | 0.0027198438 |
| qf2_loss                | 0.0024642788 |
| time_elapsed            | 1            |
| total timesteps         | 300          |
| value_loss              | 0.0412922    |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.8351787   |
| ent_coef_loss           | -1.8138472  |
| entropy                 | 7.8378887   |
| ep_rewmean              | -1.51       |
| episodes                | 8           |
| eplenmean               | 100         |
| fps                     | 189         |
| mean 100 episode reward | -1.5        |
| n_updates               | 601         |
| policy_loss             | -11.728632  |
| qf1_loss                | 0.01935008  |
| qf2_loss                | 0.020082578 |
| time_elapsed            | 3           |
| total timesteps         | 700         |
| value_loss              | 0.07544789  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.74085546 |
| ent_coef_loss           | -3.0255046 |
| entropy                 | 7.8820953  |
| ep_rewmean              | -1.48      |
| episodes                | 12         |
| eplenmean               | 100        |
| fps                     | 191        |
| mean 100 episode reward | -1.5       |
| n_updates               | 1001       |
| policy_loss             | -16.433054 |
| qf1_loss                | 2.1526256  |
| qf2_loss                | 2.0130746  |
| time_elapsed            | 5          |
| total timesteps         | 1100       |
| value_loss              | 0.12542339 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.6572428  |
| ent_coef_loss           | -4.199976  |
| entropy                 | 7.6998234  |
| ep_rewmean              | -1.39      |
| episodes                | 16         |
| eplenmean               | 100        |
| fps                     | 192        |
| mean 100 episode reward | -1.4       |
| n_updates               | 1401       |
| policy_loss             | -20.606302 |
| qf1_loss                | 1.9364353  |
| qf2_loss                | 1.8183202  |
| time_elapsed            | 7          |
| total timesteps         | 1500       |
| value_loss              | 0.57020426 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.5832038  |
| ent_coef_loss           | -5.413966  |
| entropy                 | 7.887177   |
| ep_rewmean              | -1.37      |
| episodes                | 20         |
| eplenmean               | 100        |
| fps                     | 192        |
| mean 100 episode reward | -1.4       |
| n_updates               | 1801       |
| policy_loss             | -24.362324 |
| qf1_loss                | 5.5470686  |
| qf2_loss                | 4.926921   |
| time_elapsed            | 9          |
| total timesteps         | 1900       |
| value_loss              | 0.4171037  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.51752794 |
| ent_coef_loss           | -6.5005302 |
| entropy                 | 8.019324   |
| ep_rewmean              | -1.35      |
| episodes                | 24         |
| eplenmean               | 100        |
| fps                     | 192        |
| mean 100 episode reward | -1.3       |
| n_updates               | 2201       |
| policy_loss             | -27.02568  |
| qf1_loss                | 0.8177863  |
| qf2_loss                | 0.74256766 |
| time_elapsed            | 11         |
| total timesteps         | 2300       |
| value_loss              | 0.20298931 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.4595223  |
| ent_coef_loss           | -7.5364466 |
| entropy                 | 7.597664   |
| ep_rewmean              | -1.3       |
| episodes                | 28         |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1.3       |
| n_updates               | 2601       |
| policy_loss             | -29.951296 |
| qf1_loss                | 8.186616   |
| qf2_loss                | 8.185259   |
| time_elapsed            | 13         |
| total timesteps         | 2700       |
| value_loss              | 0.46273446 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.4083406  |
| ent_coef_loss           | -8.923605  |
| entropy                 | 7.818456   |
| ep_rewmean              | -1.25      |
| episodes                | 32         |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1.2       |
| n_updates               | 3001       |
| policy_loss             | -31.76166  |
| qf1_loss                | 6.949181   |
| qf2_loss                | 6.9966373  |
| time_elapsed            | 16         |
| total timesteps         | 3100       |
| value_loss              | 0.38979518 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.36296937 |
| ent_coef_loss           | -10.054489 |
| entropy                 | 7.575139   |
| ep_rewmean              | -1.2       |
| episodes                | 36         |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1.2       |
| n_updates               | 3401       |
| policy_loss             | -33.790962 |
| qf1_loss                | 5.660448   |
| qf2_loss                | 4.73726    |
| time_elapsed            | 18         |
| total timesteps         | 3500       |
| value_loss              | 0.29552114 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.322802   |
| ent_coef_loss           | -10.362507 |
| entropy                 | 7.160221   |
| ep_rewmean              | -1.16      |
| episodes                | 40         |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1.2       |
| n_updates               | 3801       |
| policy_loss             | -35.242188 |
| qf1_loss                | 6.163854   |
| qf2_loss                | 5.617602   |
| time_elapsed            | 20         |
| total timesteps         | 3900       |
| value_loss              | 0.38017964 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.28780085 |
| ent_coef_loss           | -11.428374 |
| entropy                 | 7.071797   |
| ep_rewmean              | -1.11      |
| episodes                | 44         |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1.1       |
| n_updates               | 4201       |
| policy_loss             | -35.91439  |
| qf1_loss                | 8.011874   |
| qf2_loss                | 8.006347   |
| time_elapsed            | 22         |
| total timesteps         | 4300       |
| value_loss              | 0.19041772 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.2566887  |
| ent_coef_loss           | -12.177901 |
| entropy                 | 6.999256   |
| ep_rewmean              | -1.08      |
| episodes                | 48         |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1.1       |
| n_updates               | 4601       |
| policy_loss             | -36.8926   |
| qf1_loss                | 4.7262096  |
| qf2_loss                | 3.947077   |
| time_elapsed            | 24         |
| total timesteps         | 4700       |
| value_loss              | 0.39627248 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.22936119 |
| ent_coef_loss           | -13.028561 |
| entropy                 | 6.779167   |
| ep_rewmean              | -1.05      |
| episodes                | 52         |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1         |
| n_updates               | 5001       |
| policy_loss             | -36.379898 |
| qf1_loss                | 7.4648504  |
| qf2_loss                | 7.081842   |
| time_elapsed            | 26         |
| total timesteps         | 5100       |
| value_loss              | 0.9412679  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.20522271 |
| ent_coef_loss           | -13.886675 |
| entropy                 | 6.4690943  |
| ep_rewmean              | -1.02      |
| episodes                | 56         |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1         |
| n_updates               | 5401       |
| policy_loss             | -37.919598 |
| qf1_loss                | 0.34826592 |
| qf2_loss                | 0.46057642 |
| time_elapsed            | 28         |
| total timesteps         | 5500       |
| value_loss              | 1.6378112  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.18397588 |
| ent_coef_loss           | -14.660766 |
| entropy                 | 5.9732704  |
| ep_rewmean              | -0.992     |
| episodes                | 60         |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1         |
| n_updates               | 5801       |
| policy_loss             | -37.423874 |
| qf1_loss                | 0.32416624 |
| qf2_loss                | 0.3831386  |
| time_elapsed            | 30         |
| total timesteps         | 5900       |
| value_loss              | 0.3721878  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.16458194 |
| ent_coef_loss           | -13.127392 |
| entropy                 | 5.574417   |
| ep_rewmean              | -0.979     |
| episodes                | 64         |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1         |
| n_updates               | 6201       |
| policy_loss             | -36.939407 |
| qf1_loss                | 0.6627091  |
| qf2_loss                | 0.5999229  |
| time_elapsed            | 32         |
| total timesteps         | 6300       |
| value_loss              | 0.2543366  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.14815848 |
| ent_coef_loss           | -11.816302 |
| entropy                 | 5.4624753  |
| ep_rewmean              | -0.959     |
| episodes                | 68         |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1         |
| n_updates               | 6601       |
| policy_loss             | -37.0204   |
| qf1_loss                | 0.375292   |
| qf2_loss                | 0.47821423 |
| time_elapsed            | 34         |
| total timesteps         | 6700       |
| value_loss              | 0.3777079  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.13387829 |
| ent_coef_loss           | -12.24365  |
| entropy                 | 5.356628   |
| ep_rewmean              | -0.973     |
| episodes                | 72         |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1         |
| n_updates               | 7001       |
| policy_loss             | -36.47708  |
| qf1_loss                | 0.37983912 |
| qf2_loss                | 0.32349437 |
| time_elapsed            | 36         |
| total timesteps         | 7100       |
| value_loss              | 0.29308337 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.12183998 |
| ent_coef_loss           | -13.857536 |
| entropy                 | 4.7070904  |
| ep_rewmean              | -1.02      |
| episodes                | 76         |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1         |
| n_updates               | 7401       |
| policy_loss             | -36.06976  |
| qf1_loss                | 12.179378  |
| qf2_loss                | 12.002652  |
| time_elapsed            | 38         |
| total timesteps         | 7500       |
| value_loss              | 0.17982614 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.11030627  |
| ent_coef_loss           | -14.0655575 |
| entropy                 | 4.451063    |
| ep_rewmean              | -1.03       |
| episodes                | 80          |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -1          |
| n_updates               | 7801        |
| policy_loss             | -34.089867  |
| qf1_loss                | 1.6476377   |
| qf2_loss                | 1.6316252   |
| time_elapsed            | 40          |
| total timesteps         | 7900        |
| value_loss              | 0.58197594  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.1001309  |
| ent_coef_loss           | -13.477888 |
| entropy                 | 4.4984426  |
| ep_rewmean              | -1.02      |
| episodes                | 84         |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1         |
| n_updates               | 8201       |
| policy_loss             | -34.7969   |
| qf1_loss                | 0.3097676  |
| qf2_loss                | 0.3242343  |
| time_elapsed            | 42         |
| total timesteps         | 8300       |
| value_loss              | 0.2342768  |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.091492996 |
| ent_coef_loss           | -10.138561  |
| entropy                 | 2.5880234   |
| ep_rewmean              | -1.01       |
| episodes                | 88          |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -1          |
| n_updates               | 8601        |
| policy_loss             | -34.583595  |
| qf1_loss                | 0.12494148  |
| qf2_loss                | 0.1537405   |
| time_elapsed            | 44          |
| total timesteps         | 8700        |
| value_loss              | 0.17043427  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.08462697 |
| ent_coef_loss           | -7.622804  |
| entropy                 | 1.6392912  |
| ep_rewmean              | -1.05      |
| episodes                | 92         |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1         |
| n_updates               | 9001       |
| policy_loss             | -34.57318  |
| qf1_loss                | 0.29765707 |
| qf2_loss                | 0.35045636 |
| time_elapsed            | 46         |
| total timesteps         | 9100       |
| value_loss              | 0.5295694  |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.079770245 |
| ent_coef_loss           | -4.5039563  |
| entropy                 | 0.7385837   |
| ep_rewmean              | -1.11       |
| episodes                | 96          |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -1.1        |
| n_updates               | 9401        |
| policy_loss             | -33.40857   |
| qf1_loss                | 0.2511242   |
| qf2_loss                | 0.27324593  |
| time_elapsed            | 49          |
| total timesteps         | 9500        |
| value_loss              | 0.23791677  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.077911906 |
| ent_coef_loss           | -0.08479932 |
| entropy                 | 0.9921341   |
| ep_rewmean              | -1.16       |
| episodes                | 100         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -1.2        |
| n_updates               | 9801        |
| policy_loss             | -33.05858   |
| qf1_loss                | 7.7151375   |
| qf2_loss                | 7.9764276   |
| time_elapsed            | 51          |
| total timesteps         | 9900        |
| value_loss              | 0.20593852  |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=-1.95 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.07768715  |
| ent_coef_loss           | 0.042397916 |
| entropy                 | 1.0008605   |
| ep_rewmean              | -1.19       |
| episodes                | 104         |
| eplenmean               | 100         |
| fps                     | 192         |
| mean 100 episode reward | -1.2        |
| n_updates               | 10201       |
| policy_loss             | -31.376223  |
| qf1_loss                | 0.2049798   |
| qf2_loss                | 0.28139812  |
| time_elapsed            | 53          |
| total timesteps         | 10300       |
| value_loss              | 0.17596714  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.07661234 |
| ent_coef_loss           | -4.173306  |
| entropy                 | 1.3293927  |
| ep_rewmean              | -1.2       |
| episodes                | 108        |
| eplenmean               | 100        |
| fps                     | 192        |
| mean 100 episode reward | -1.2       |
| n_updates               | 10601      |
| policy_loss             | -31.090183 |
| qf1_loss                | 7.832441   |
| qf2_loss                | 7.5204415  |
| time_elapsed            | 55         |
| total timesteps         | 10700      |
| value_loss              | 0.23065767 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.073944956 |
| ent_coef_loss           | -0.2944715  |
| entropy                 | 1.3543617   |
| ep_rewmean              | -1.18       |
| episodes                | 112         |
| eplenmean               | 100         |
| fps                     | 192         |
| mean 100 episode reward | -1.2        |
| n_updates               | 11001       |
| policy_loss             | -30.08852   |
| qf1_loss                | 0.43694958  |
| qf2_loss                | 0.906026    |
| time_elapsed            | 57          |
| total timesteps         | 11100       |
| value_loss              | 0.18048654  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.070836686 |
| ent_coef_loss           | 1.851743    |
| entropy                 | 0.77302337  |
| ep_rewmean              | -1.2        |
| episodes                | 116         |
| eplenmean               | 100         |
| fps                     | 192         |
| mean 100 episode reward | -1.2        |
| n_updates               | 11401       |
| policy_loss             | -30.035952  |
| qf1_loss                | 0.27459663  |
| qf2_loss                | 0.2200659   |
| time_elapsed            | 59          |
| total timesteps         | 11500       |
| value_loss              | 0.15131041  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.06820812 |
| ent_coef_loss           | 1.3847654  |
| entropy                 | 0.5138246  |
| ep_rewmean              | -1.23      |
| episodes                | 120        |
| eplenmean               | 100        |
| fps                     | 192        |
| mean 100 episode reward | -1.2       |
| n_updates               | 11801      |
| policy_loss             | -29.507755 |
| qf1_loss                | 0.24411893 |
| qf2_loss                | 0.27042124 |
| time_elapsed            | 61         |
| total timesteps         | 11900      |
| value_loss              | 0.198572   |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.06673848 |
| ent_coef_loss           | -2.2027705 |
| entropy                 | 0.5462341  |
| ep_rewmean              | -1.29      |
| episodes                | 124        |
| eplenmean               | 100        |
| fps                     | 192        |
| mean 100 episode reward | -1.3       |
| n_updates               | 12201      |
| policy_loss             | -30.131176 |
| qf1_loss                | 12.012382  |
| qf2_loss                | 10.691196  |
| time_elapsed            | 63         |
| total timesteps         | 12300      |
| value_loss              | 0.455792   |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.0669961  |
| ent_coef_loss           | -1.0658262 |
| entropy                 | 1.629363   |
| ep_rewmean              | -1.38      |
| episodes                | 128        |
| eplenmean               | 100        |
| fps                     | 192        |
| mean 100 episode reward | -1.4       |
| n_updates               | 12601      |
| policy_loss             | -29.164886 |
| qf1_loss                | 0.2873808  |
| qf2_loss                | 0.18365976 |
| time_elapsed            | 65         |
| total timesteps         | 12700      |
| value_loss              | 0.41118878 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.070671156 |
| ent_coef_loss           | 1.9717832   |
| entropy                 | 1.830715    |
| ep_rewmean              | -1.47       |
| episodes                | 132         |
| eplenmean               | 100         |
| fps                     | 192         |
| mean 100 episode reward | -1.5        |
| n_updates               | 13001       |
| policy_loss             | -28.392944  |
| qf1_loss                | 6.8110595   |
| qf2_loss                | 6.713056    |
| time_elapsed            | 67          |
| total timesteps         | 13100       |
| value_loss              | 0.28490224  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.069797605 |
| ent_coef_loss           | -1.7375329  |
| entropy                 | 1.7830404   |
| ep_rewmean              | -1.54       |
| episodes                | 136         |
| eplenmean               | 100         |
| fps                     | 192         |
| mean 100 episode reward | -1.5        |
| n_updates               | 13401       |
| policy_loss             | -27.92916   |
| qf1_loss                | 0.24914989  |
| qf2_loss                | 0.22577862  |
| time_elapsed            | 69          |
| total timesteps         | 13500       |
| value_loss              | 0.21266538  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.065589495 |
| ent_coef_loss           | -2.4938262  |
| entropy                 | 1.5025084   |
| ep_rewmean              | -1.61       |
| episodes                | 140         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -1.6        |
| n_updates               | 13801       |
| policy_loss             | -27.79292   |
| qf1_loss                | 4.2213006   |
| qf2_loss                | 4.200991    |
| time_elapsed            | 72          |
| total timesteps         | 13900       |
| value_loss              | 0.29296166  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.058999408 |
| ent_coef_loss           | -1.8312948  |
| entropy                 | 0.30788076  |
| ep_rewmean              | -1.69       |
| episodes                | 144         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -1.7        |
| n_updates               | 14201       |
| policy_loss             | -27.614555  |
| qf1_loss                | 7.4390306   |
| qf2_loss                | 7.306181    |
| time_elapsed            | 74          |
| total timesteps         | 14300       |
| value_loss              | 0.15004483  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.05612757 |
| ent_coef_loss           | -3.8792315 |
| entropy                 | 0.12262668 |
| ep_rewmean              | -1.77      |
| episodes                | 148        |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1.8       |
| n_updates               | 14601      |
| policy_loss             | -27.75704  |
| qf1_loss                | 5.830586   |
| qf2_loss                | 5.509213   |
| time_elapsed            | 76         |
| total timesteps         | 14700      |
| value_loss              | 0.13505808 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.06677689 |
| ent_coef_loss           | 2.6380703  |
| entropy                 | 1.9192522  |
| ep_rewmean              | -1.81      |
| episodes                | 152        |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1.8       |
| n_updates               | 15001      |
| policy_loss             | -27.818848 |
| qf1_loss                | 11.830982  |
| qf2_loss                | 12.217406  |
| time_elapsed            | 78         |
| total timesteps         | 15100      |
| value_loss              | 0.22720441 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.07737166  |
| ent_coef_loss           | 4.150124    |
| entropy                 | 1.8788942   |
| ep_rewmean              | -1.86       |
| episodes                | 156         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -1.9        |
| n_updates               | 15401       |
| policy_loss             | -24.979088  |
| qf1_loss                | 0.42772967  |
| qf2_loss                | 0.5470878   |
| time_elapsed            | 80          |
| total timesteps         | 15500       |
| value_loss              | 0.110348836 |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.07927513 |
| ent_coef_loss           | -0.7514882 |
| entropy                 | 1.8019083  |
| ep_rewmean              | -1.92      |
| episodes                | 160        |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -1.9       |
| n_updates               | 15801      |
| policy_loss             | -23.78757  |
| qf1_loss                | 0.19776283 |
| qf2_loss                | 0.22739764 |
| time_elapsed            | 82         |
| total timesteps         | 15900      |
| value_loss              | 0.38540998 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.077766985 |
| ent_coef_loss           | -3.3318262  |
| entropy                 | 1.9052279   |
| ep_rewmean              | -1.97       |
| episodes                | 164         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2          |
| n_updates               | 16201       |
| policy_loss             | -23.94561   |
| qf1_loss                | 2.2028112   |
| qf2_loss                | 2.4002244   |
| time_elapsed            | 84          |
| total timesteps         | 16300       |
| value_loss              | 0.26396233  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.07443638 |
| ent_coef_loss           | -1.6882619 |
| entropy                 | 1.5379486  |
| ep_rewmean              | -2.11      |
| episodes                | 168        |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -2.1       |
| n_updates               | 16601      |
| policy_loss             | -23.443222 |
| qf1_loss                | 1.9234319  |
| qf2_loss                | 2.0875554  |
| time_elapsed            | 86         |
| total timesteps         | 16700      |
| value_loss              | 0.2308961  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.07080172 |
| ent_coef_loss           | -1.1329576 |
| entropy                 | 0.7933694  |
| ep_rewmean              | -2.23      |
| episodes                | 172        |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -2.2       |
| n_updates               | 17001      |
| policy_loss             | -23.106794 |
| qf1_loss                | 7.219274   |
| qf2_loss                | 7.023011   |
| time_elapsed            | 88         |
| total timesteps         | 17100      |
| value_loss              | 0.34768397 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.066381186 |
| ent_coef_loss           | -1.3117326  |
| entropy                 | 1.1211601   |
| ep_rewmean              | -2.33       |
| episodes                | 176         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2.3        |
| n_updates               | 17401       |
| policy_loss             | -22.053728  |
| qf1_loss                | 0.48667896  |
| qf2_loss                | 0.4796641   |
| time_elapsed            | 90          |
| total timesteps         | 17500       |
| value_loss              | 0.12778114  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.06362876  |
| ent_coef_loss           | -2.4169743  |
| entropy                 | 1.009129    |
| ep_rewmean              | -2.44       |
| episodes                | 180         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2.4        |
| n_updates               | 17801       |
| policy_loss             | -23.007133  |
| qf1_loss                | 0.122664385 |
| qf2_loss                | 0.16695413  |
| time_elapsed            | 92          |
| total timesteps         | 17900       |
| value_loss              | 0.11170203  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.05896071  |
| ent_coef_loss           | -3.2427528  |
| entropy                 | 0.69759476  |
| ep_rewmean              | -2.55       |
| episodes                | 184         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2.6        |
| n_updates               | 18201       |
| policy_loss             | -22.097374  |
| qf1_loss                | 0.09968638  |
| qf2_loss                | 0.121414244 |
| time_elapsed            | 94          |
| total timesteps         | 18300       |
| value_loss              | 0.10406643  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.053781226 |
| ent_coef_loss           | -2.3718     |
| entropy                 | 1.2018306   |
| ep_rewmean              | -2.66       |
| episodes                | 188         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2.7        |
| n_updates               | 18601       |
| policy_loss             | -21.133293  |
| qf1_loss                | 0.09073041  |
| qf2_loss                | 0.11805998  |
| time_elapsed            | 96          |
| total timesteps         | 18700       |
| value_loss              | 0.11110534  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.04864043 |
| ent_coef_loss           | -2.2981706 |
| entropy                 | 1.0293145  |
| ep_rewmean              | -2.73      |
| episodes                | 192        |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -2.7       |
| n_updates               | 19001      |
| policy_loss             | -20.983341 |
| qf1_loss                | 6.1108108  |
| qf2_loss                | 5.506366   |
| time_elapsed            | 98         |
| total timesteps         | 19100      |
| value_loss              | 0.14331427 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.045997124 |
| ent_coef_loss           | -1.7774609  |
| entropy                 | 0.8838698   |
| ep_rewmean              | -2.73       |
| episodes                | 196         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2.7        |
| n_updates               | 19401       |
| policy_loss             | -21.594006  |
| qf1_loss                | 2.2995238   |
| qf2_loss                | 2.1646385   |
| time_elapsed            | 100         |
| total timesteps         | 19500       |
| value_loss              | 0.07829933  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.04730509 |
| ent_coef_loss           | 1.4867756  |
| entropy                 | 1.260598   |
| ep_rewmean              | -2.7       |
| episodes                | 200        |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -2.7       |
| n_updates               | 19801      |
| policy_loss             | -21.078928 |
| qf1_loss                | 0.16981193 |
| qf2_loss                | 0.26335898 |
| time_elapsed            | 102        |
| total timesteps         | 19900      |
| value_loss              | 0.1612551  |
----------------------------------------
Eval num_timesteps=20000, episode_reward=-1.04 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.054782245 |
| ent_coef_loss           | 4.928592    |
| entropy                 | 2.0901654   |
| ep_rewmean              | -2.65       |
| episodes                | 204         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2.7        |
| n_updates               | 20201       |
| policy_loss             | -21.357883  |
| qf1_loss                | 0.20322292  |
| qf2_loss                | 0.1899299   |
| time_elapsed            | 104         |
| total timesteps         | 20300       |
| value_loss              | 0.1872356   |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.057578836 |
| ent_coef_loss           | 0.44635516  |
| entropy                 | 1.9583249   |
| ep_rewmean              | -2.65       |
| episodes                | 208         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2.6        |
| n_updates               | 20601       |
| policy_loss             | -20.668098  |
| qf1_loss                | 0.12139515  |
| qf2_loss                | 0.14428842  |
| time_elapsed            | 107         |
| total timesteps         | 20700       |
| value_loss              | 0.24985108  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.055018622 |
| ent_coef_loss           | -4.6324673  |
| entropy                 | 1.9693053   |
| ep_rewmean              | -2.66       |
| episodes                | 212         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2.7        |
| n_updates               | 21001       |
| policy_loss             | -21.29366   |
| qf1_loss                | 0.14626375  |
| qf2_loss                | 0.11226021  |
| time_elapsed            | 109         |
| total timesteps         | 21100       |
| value_loss              | 0.35996398  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.05197364 |
| ent_coef_loss           | -5.6675253 |
| entropy                 | 2.0992055  |
| ep_rewmean              | -2.64      |
| episodes                | 216        |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -2.6       |
| n_updates               | 21401      |
| policy_loss             | -20.743341 |
| qf1_loss                | 0.1415151  |
| qf2_loss                | 0.15835747 |
| time_elapsed            | 111        |
| total timesteps         | 21500      |
| value_loss              | 0.14185259 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.04975058  |
| ent_coef_loss           | -1.3368965  |
| entropy                 | 1.3691676   |
| ep_rewmean              | -2.58       |
| episodes                | 220         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2.6        |
| n_updates               | 21801       |
| policy_loss             | -20.671593  |
| qf1_loss                | 4.85591     |
| qf2_loss                | 4.941743    |
| time_elapsed            | 113         |
| total timesteps         | 21900       |
| value_loss              | 0.121079855 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.049408656 |
| ent_coef_loss           | -1.8356183  |
| entropy                 | 1.7473747   |
| ep_rewmean              | -2.5        |
| episodes                | 224         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2.5        |
| n_updates               | 22201       |
| policy_loss             | -20.650455  |
| qf1_loss                | 0.08671025  |
| qf2_loss                | 0.10563145  |
| time_elapsed            | 115         |
| total timesteps         | 22300       |
| value_loss              | 0.09661153  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.05228717 |
| ent_coef_loss           | 0.6102092  |
| entropy                 | 1.7006786  |
| ep_rewmean              | -2.4       |
| episodes                | 228        |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -2.4       |
| n_updates               | 22601      |
| policy_loss             | -21.158545 |
| qf1_loss                | 0.13812552 |
| qf2_loss                | 0.16046454 |
| time_elapsed            | 117        |
| total timesteps         | 22700      |
| value_loss              | 0.33248958 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.0481618  |
| ent_coef_loss           | -3.033618  |
| entropy                 | 1.9257399  |
| ep_rewmean              | -2.31      |
| episodes                | 232        |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -2.3       |
| n_updates               | 23001      |
| policy_loss             | -20.002352 |
| qf1_loss                | 0.25131735 |
| qf2_loss                | 0.2865923  |
| time_elapsed            | 119        |
| total timesteps         | 23100      |
| value_loss              | 0.13097116 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.04480991  |
| ent_coef_loss           | -1.7103113  |
| entropy                 | 1.7670989   |
| ep_rewmean              | -2.25       |
| episodes                | 236         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2.3        |
| n_updates               | 23401       |
| policy_loss             | -20.498207  |
| qf1_loss                | 0.1400209   |
| qf2_loss                | 0.18302086  |
| time_elapsed            | 121         |
| total timesteps         | 23500       |
| value_loss              | 0.096649215 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.041564904 |
| ent_coef_loss           | -1.2303662  |
| entropy                 | 1.6883445   |
| ep_rewmean              | -2.2        |
| episodes                | 240         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2.2        |
| n_updates               | 23801       |
| policy_loss             | -20.303633  |
| qf1_loss                | 0.18539585  |
| qf2_loss                | 0.13188145  |
| time_elapsed            | 123         |
| total timesteps         | 23900       |
| value_loss              | 0.08564256  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.03911527 |
| ent_coef_loss           | -3.2675698 |
| entropy                 | 1.3916345  |
| ep_rewmean              | -2.14      |
| episodes                | 244        |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -2.1       |
| n_updates               | 24201      |
| policy_loss             | -19.963745 |
| qf1_loss                | 1.3294301  |
| qf2_loss                | 1.5325876  |
| time_elapsed            | 125        |
| total timesteps         | 24300      |
| value_loss              | 0.26080847 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.037790745 |
| ent_coef_loss           | -0.87822586 |
| entropy                 | 1.3420415   |
| ep_rewmean              | -2.1        |
| episodes                | 248         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2.1        |
| n_updates               | 24601       |
| policy_loss             | -19.999609  |
| qf1_loss                | 0.14660555  |
| qf2_loss                | 0.17600566  |
| time_elapsed            | 127         |
| total timesteps         | 24700       |
| value_loss              | 0.06227967  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.037426766 |
| ent_coef_loss           | -0.677833   |
| entropy                 | 1.3686725   |
| ep_rewmean              | -2.07       |
| episodes                | 252         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2.1        |
| n_updates               | 25001       |
| policy_loss             | -19.462711  |
| qf1_loss                | 0.18297493  |
| qf2_loss                | 0.18015388  |
| time_elapsed            | 129         |
| total timesteps         | 25100       |
| value_loss              | 0.16192548  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.039522305 |
| ent_coef_loss           | 2.1935406   |
| entropy                 | 1.3319919   |
| ep_rewmean              | -2.04       |
| episodes                | 256         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2          |
| n_updates               | 25401       |
| policy_loss             | -18.85999   |
| qf1_loss                | 0.1688761   |
| qf2_loss                | 0.15422086  |
| time_elapsed            | 131         |
| total timesteps         | 25500       |
| value_loss              | 0.12130727  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.04148435 |
| ent_coef_loss           | -1.1005393 |
| entropy                 | 1.0384319  |
| ep_rewmean              | -2.02      |
| episodes                | 260        |
| eplenmean               | 100        |
| fps                     | 193        |
| mean 100 episode reward | -2         |
| n_updates               | 25801      |
| policy_loss             | -19.097725 |
| qf1_loss                | 0.1652233  |
| qf2_loss                | 0.17275241 |
| time_elapsed            | 133        |
| total timesteps         | 25900      |
| value_loss              | 0.09385842 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.042595636 |
| ent_coef_loss           | 0.04894668  |
| entropy                 | 0.8048583   |
| ep_rewmean              | -2.04       |
| episodes                | 264         |
| eplenmean               | 100         |
| fps                     | 193         |
| mean 100 episode reward | -2          |
| n_updates               | 26201       |
| policy_loss             | -18.713814  |
| qf1_loss                | 0.1851408   |
| qf2_loss                | 0.12571047  |
| time_elapsed            | 135         |
| total timesteps         | 26300       |
| value_loss              | 0.2346806   |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.04247439  |
| ent_coef_loss           | -1.9997015  |
| entropy                 | 0.58514154  |
| ep_rewmean              | -2          |
| episodes                | 268         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2          |
| n_updates               | 26601       |
| policy_loss             | -18.55196   |
| qf1_loss                | 0.067992784 |
| qf2_loss                | 0.059866123 |
| time_elapsed            | 137         |
| total timesteps         | 26700       |
| value_loss              | 0.11916517  |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.038855866  |
| ent_coef_loss           | -3.316977    |
| entropy                 | -0.024682753 |
| ep_rewmean              | -1.93        |
| episodes                | 272          |
| eplenmean               | 100          |
| fps                     | 194          |
| mean 100 episode reward | -1.9         |
| n_updates               | 27001        |
| policy_loss             | -18.379017   |
| qf1_loss                | 1.9866438    |
| qf2_loss                | 2.0381172    |
| time_elapsed            | 139          |
| total timesteps         | 27100        |
| value_loss              | 0.10808702   |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.035540186 |
| ent_coef_loss           | 0.8426825   |
| entropy                 | -0.2648739  |
| ep_rewmean              | -1.86       |
| episodes                | 276         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.9        |
| n_updates               | 27401       |
| policy_loss             | -17.564098  |
| qf1_loss                | 3.7875524   |
| qf2_loss                | 4.034017    |
| time_elapsed            | 141         |
| total timesteps         | 27500       |
| value_loss              | 0.09283309  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.035765726 |
| ent_coef_loss           | -1.1545905  |
| entropy                 | -1.0837725  |
| ep_rewmean              | -1.8        |
| episodes                | 280         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.8        |
| n_updates               | 27801       |
| policy_loss             | -17.840681  |
| qf1_loss                | 0.070764184 |
| qf2_loss                | 0.05624003  |
| time_elapsed            | 143         |
| total timesteps         | 27900       |
| value_loss              | 0.084547594 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.035711244 |
| ent_coef_loss           | 1.5607048   |
| entropy                 | -1.2701612  |
| ep_rewmean              | -1.79       |
| episodes                | 284         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.8        |
| n_updates               | 28201       |
| policy_loss             | -17.044342  |
| qf1_loss                | 2.6903749   |
| qf2_loss                | 2.711116    |
| time_elapsed            | 145         |
| total timesteps         | 28300       |
| value_loss              | 0.079535104 |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.03671041 |
| ent_coef_loss           | 0.12492126 |
| entropy                 | -0.6041001 |
| ep_rewmean              | -1.79      |
| episodes                | 288        |
| eplenmean               | 100        |
| fps                     | 194        |
| mean 100 episode reward | -1.8       |
| n_updates               | 28601      |
| policy_loss             | -16.861479 |
| qf1_loss                | 0.08529627 |
| qf2_loss                | 0.08884691 |
| time_elapsed            | 147        |
| total timesteps         | 28700      |
| value_loss              | 0.07472399 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.037149962 |
| ent_coef_loss           | 0.21571198  |
| entropy                 | -1.0208077  |
| ep_rewmean              | -1.76       |
| episodes                | 292         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.8        |
| n_updates               | 29001       |
| policy_loss             | -16.86411   |
| qf1_loss                | 3.209562    |
| qf2_loss                | 3.244881    |
| time_elapsed            | 149         |
| total timesteps         | 29100       |
| value_loss              | 0.08341976  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.03779697  |
| ent_coef_loss           | -1.9166946  |
| entropy                 | -0.5467054  |
| ep_rewmean              | -1.76       |
| episodes                | 296         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.8        |
| n_updates               | 29401       |
| policy_loss             | -16.01116   |
| qf1_loss                | 1.7718537   |
| qf2_loss                | 1.8564773   |
| time_elapsed            | 151         |
| total timesteps         | 29500       |
| value_loss              | 0.061851446 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.03854617  |
| ent_coef_loss           | 3.1929843   |
| entropy                 | -0.26786238 |
| ep_rewmean              | -1.8        |
| episodes                | 300         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.8        |
| n_updates               | 29801       |
| policy_loss             | -15.79362   |
| qf1_loss                | 1.4256371   |
| qf2_loss                | 0.98710555  |
| time_elapsed            | 153         |
| total timesteps         | 29900       |
| value_loss              | 0.10010029  |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-2.91 +/- 0.00
Episode length: 100.00 +/- 0.00
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.037715405 |
| ent_coef_loss           | 1.216342    |
| entropy                 | -0.39038646 |
| ep_rewmean              | -1.86       |
| episodes                | 304         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.9        |
| n_updates               | 30201       |
| policy_loss             | -15.63415   |
| qf1_loss                | 0.048219603 |
| qf2_loss                | 0.035143718 |
| time_elapsed            | 156         |
| total timesteps         | 30300       |
| value_loss              | 0.07129941  |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.03610081   |
| ent_coef_loss           | -1.1580914   |
| entropy                 | -0.049101967 |
| ep_rewmean              | -1.9         |
| episodes                | 308          |
| eplenmean               | 100          |
| fps                     | 194          |
| mean 100 episode reward | -1.9         |
| n_updates               | 30601        |
| policy_loss             | -15.662063   |
| qf1_loss                | 0.048147947  |
| qf2_loss                | 0.06075186   |
| time_elapsed            | 158          |
| total timesteps         | 30700        |
| value_loss              | 0.062849976  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.03601651  |
| ent_coef_loss           | 1.2936592   |
| entropy                 | -0.2843264  |
| ep_rewmean              | -2.02       |
| episodes                | 312         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2          |
| n_updates               | 31001       |
| policy_loss             | -15.239075  |
| qf1_loss                | 0.069720425 |
| qf2_loss                | 0.069266565 |
| time_elapsed            | 160         |
| total timesteps         | 31100       |
| value_loss              | 0.11878133  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.035898425 |
| ent_coef_loss           | 0.746421    |
| entropy                 | -0.03435997 |
| ep_rewmean              | -2.16       |
| episodes                | 316         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.2        |
| n_updates               | 31401       |
| policy_loss             | -14.449139  |
| qf1_loss                | 0.07002632  |
| qf2_loss                | 0.047612272 |
| time_elapsed            | 162         |
| total timesteps         | 31500       |
| value_loss              | 0.046010546 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.035208642 |
| ent_coef_loss           | 1.4890802   |
| entropy                 | 0.2718954   |
| ep_rewmean              | -2.26       |
| episodes                | 320         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.3        |
| n_updates               | 31801       |
| policy_loss             | -14.387144  |
| qf1_loss                | 0.042197004 |
| qf2_loss                | 0.031438597 |
| time_elapsed            | 164         |
| total timesteps         | 31900       |
| value_loss              | 0.07488402  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.039471984 |
| ent_coef_loss           | 3.3577914   |
| entropy                 | 1.2293727   |
| ep_rewmean              | -2.32       |
| episodes                | 324         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.3        |
| n_updates               | 32201       |
| policy_loss             | -14.634272  |
| qf1_loss                | 2.4748707   |
| qf2_loss                | 2.4748626   |
| time_elapsed            | 166         |
| total timesteps         | 32300       |
| value_loss              | 0.063821346 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.04508635  |
| ent_coef_loss           | 0.3305416   |
| entropy                 | 1.4298521   |
| ep_rewmean              | -2.37       |
| episodes                | 328         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.4        |
| n_updates               | 32601       |
| policy_loss             | -13.474047  |
| qf1_loss                | 0.062345438 |
| qf2_loss                | 0.04930742  |
| time_elapsed            | 168         |
| total timesteps         | 32700       |
| value_loss              | 0.0466465   |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.04444901  |
| ent_coef_loss           | -2.6127129  |
| entropy                 | 1.688428    |
| ep_rewmean              | -2.44       |
| episodes                | 332         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.4        |
| n_updates               | 33001       |
| policy_loss             | -13.205589  |
| qf1_loss                | 0.08854988  |
| qf2_loss                | 0.06298368  |
| time_elapsed            | 170         |
| total timesteps         | 33100       |
| value_loss              | 0.102109246 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.044226017 |
| ent_coef_loss           | 3.0337195   |
| entropy                 | 0.93831724  |
| ep_rewmean              | -2.5        |
| episodes                | 336         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.5        |
| n_updates               | 33401       |
| policy_loss             | -14.383898  |
| qf1_loss                | 3.040389    |
| qf2_loss                | 3.1015625   |
| time_elapsed            | 172         |
| total timesteps         | 33500       |
| value_loss              | 0.05450716  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.047276832 |
| ent_coef_loss           | -0.27709818 |
| entropy                 | 1.557004    |
| ep_rewmean              | -2.54       |
| episodes                | 340         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.5        |
| n_updates               | 33801       |
| policy_loss             | -13.005556  |
| qf1_loss                | 0.059716403 |
| qf2_loss                | 0.06559755  |
| time_elapsed            | 174         |
| total timesteps         | 33900       |
| value_loss              | 0.04945853  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.047423456 |
| ent_coef_loss           | 2.1974783   |
| entropy                 | 1.4687576   |
| ep_rewmean              | -2.58       |
| episodes                | 344         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.6        |
| n_updates               | 34201       |
| policy_loss             | -12.984643  |
| qf1_loss                | 0.042481966 |
| qf2_loss                | 0.033652116 |
| time_elapsed            | 176         |
| total timesteps         | 34300       |
| value_loss              | 0.042249687 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.04596714  |
| ent_coef_loss           | 2.0902858   |
| entropy                 | 1.4506791   |
| ep_rewmean              | -2.62       |
| episodes                | 348         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.6        |
| n_updates               | 34601       |
| policy_loss             | -13.416958  |
| qf1_loss                | 0.05280654  |
| qf2_loss                | 0.07464841  |
| time_elapsed            | 178         |
| total timesteps         | 34700       |
| value_loss              | 0.107394725 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.045515575 |
| ent_coef_loss           | -1.4236408  |
| entropy                 | 1.5778939   |
| ep_rewmean              | -2.65       |
| episodes                | 352         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.7        |
| n_updates               | 35001       |
| policy_loss             | -12.92164   |
| qf1_loss                | 0.040806174 |
| qf2_loss                | 0.04124946  |
| time_elapsed            | 180         |
| total timesteps         | 35100       |
| value_loss              | 0.046070073 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.044826023 |
| ent_coef_loss           | -0.7721914  |
| entropy                 | 1.592893    |
| ep_rewmean              | -2.65       |
| episodes                | 356         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.7        |
| n_updates               | 35401       |
| policy_loss             | -12.721508  |
| qf1_loss                | 1.559653    |
| qf2_loss                | 1.5785997   |
| time_elapsed            | 182         |
| total timesteps         | 35500       |
| value_loss              | 0.03595919  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.044927146 |
| ent_coef_loss           | -0.24114758 |
| entropy                 | 1.6926584   |
| ep_rewmean              | -2.62       |
| episodes                | 360         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.6        |
| n_updates               | 35801       |
| policy_loss             | -13.243306  |
| qf1_loss                | 1.2213084   |
| qf2_loss                | 1.2510628   |
| time_elapsed            | 184         |
| total timesteps         | 35900       |
| value_loss              | 0.047434095 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.042875435 |
| ent_coef_loss           | -0.3253616  |
| entropy                 | 1.6873672   |
| ep_rewmean              | -2.54       |
| episodes                | 364         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.5        |
| n_updates               | 36201       |
| policy_loss             | -12.4724865 |
| qf1_loss                | 0.056580916 |
| qf2_loss                | 0.048614576 |
| time_elapsed            | 186         |
| total timesteps         | 36300       |
| value_loss              | 0.041208923 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.039668053 |
| ent_coef_loss           | -1.6131569  |
| entropy                 | 1.5559329   |
| ep_rewmean              | -2.47       |
| episodes                | 368         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.5        |
| n_updates               | 36601       |
| policy_loss             | -12.002165  |
| qf1_loss                | 3.4277594   |
| qf2_loss                | 3.4306254   |
| time_elapsed            | 188         |
| total timesteps         | 36700       |
| value_loss              | 0.06368093  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.037415847 |
| ent_coef_loss           | -1.9421968  |
| entropy                 | 1.4644172   |
| ep_rewmean              | -2.41       |
| episodes                | 372         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.4        |
| n_updates               | 37001       |
| policy_loss             | -11.4205    |
| qf1_loss                | 0.03249737  |
| qf2_loss                | 0.028864319 |
| time_elapsed            | 190         |
| total timesteps         | 37100       |
| value_loss              | 0.04386509  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.0358313  |
| ent_coef_loss           | 1.6914101  |
| entropy                 | 1.4420837  |
| ep_rewmean              | -2.36      |
| episodes                | 376        |
| eplenmean               | 100        |
| fps                     | 194        |
| mean 100 episode reward | -2.4       |
| n_updates               | 37401      |
| policy_loss             | -11.760907 |
| qf1_loss                | 1.6127452  |
| qf2_loss                | 1.5954872  |
| time_elapsed            | 192        |
| total timesteps         | 37500      |
| value_loss              | 0.11219764 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.03328304  |
| ent_coef_loss           | 0.16234064  |
| entropy                 | 1.3393619   |
| ep_rewmean              | -2.29       |
| episodes                | 380         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.3        |
| n_updates               | 37801       |
| policy_loss             | -11.572727  |
| qf1_loss                | 0.043957517 |
| qf2_loss                | 0.0422389   |
| time_elapsed            | 194         |
| total timesteps         | 37900       |
| value_loss              | 0.044276558 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.032159742 |
| ent_coef_loss           | -0.8062357  |
| entropy                 | 0.97326124  |
| ep_rewmean              | -2.18       |
| episodes                | 384         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.2        |
| n_updates               | 38201       |
| policy_loss             | -11.556736  |
| qf1_loss                | 2.9843895   |
| qf2_loss                | 3.0825286   |
| time_elapsed            | 196         |
| total timesteps         | 38300       |
| value_loss              | 0.03825042  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.031120762 |
| ent_coef_loss           | 0.6813973   |
| entropy                 | 0.94313955  |
| ep_rewmean              | -2.11       |
| episodes                | 388         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2.1        |
| n_updates               | 38601       |
| policy_loss             | -11.009119  |
| qf1_loss                | 0.046916433 |
| qf2_loss                | 0.03941135  |
| time_elapsed            | 198         |
| total timesteps         | 38700       |
| value_loss              | 0.02411964  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.029791627 |
| ent_coef_loss           | 1.5855742   |
| entropy                 | 0.8118917   |
| ep_rewmean              | -2.05       |
| episodes                | 392         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2          |
| n_updates               | 39001       |
| policy_loss             | -11.449837  |
| qf1_loss                | 2.958001    |
| qf2_loss                | 2.2264087   |
| time_elapsed            | 200         |
| total timesteps         | 39100       |
| value_loss              | 0.07465443  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.028443784 |
| ent_coef_loss           | -1.4371014  |
| entropy                 | 0.4552563   |
| ep_rewmean              | -1.99       |
| episodes                | 396         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2          |
| n_updates               | 39401       |
| policy_loss             | -10.455757  |
| qf1_loss                | 2.0064197   |
| qf2_loss                | 1.8194655   |
| time_elapsed            | 202         |
| total timesteps         | 39500       |
| value_loss              | 0.12542036  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.027582118 |
| ent_coef_loss           | -0.05654639 |
| entropy                 | 0.36900765  |
| ep_rewmean              | -1.95       |
| episodes                | 400         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -2          |
| n_updates               | 39801       |
| policy_loss             | -10.491806  |
| qf1_loss                | 0.58419055  |
| qf2_loss                | 0.62584746  |
| time_elapsed            | 204         |
| total timesteps         | 39900       |
| value_loss              | 0.03372442  |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-1.51 +/- 0.00
Episode length: 100.00 +/- 0.00
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.027274104 |
| ent_coef_loss           | -1.5030622  |
| entropy                 | 0.43703216  |
| ep_rewmean              | -1.92       |
| episodes                | 404         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.9        |
| n_updates               | 40201       |
| policy_loss             | -11.393915  |
| qf1_loss                | 0.029936187 |
| qf2_loss                | 0.044101372 |
| time_elapsed            | 207         |
| total timesteps         | 40300       |
| value_loss              | 0.32470632  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.026669983 |
| ent_coef_loss           | -0.20267522 |
| entropy                 | 0.67900085  |
| ep_rewmean              | -1.85       |
| episodes                | 408         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.8        |
| n_updates               | 40601       |
| policy_loss             | -11.505963  |
| qf1_loss                | 2.2122538   |
| qf2_loss                | 2.1996703   |
| time_elapsed            | 209         |
| total timesteps         | 40700       |
| value_loss              | 0.078609824 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.026526166 |
| ent_coef_loss           | 0.27897552  |
| entropy                 | 0.3105235   |
| ep_rewmean              | -1.73       |
| episodes                | 412         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.7        |
| n_updates               | 41001       |
| policy_loss             | -9.787666   |
| qf1_loss                | 1.8645861   |
| qf2_loss                | 1.8751762   |
| time_elapsed            | 211         |
| total timesteps         | 41100       |
| value_loss              | 0.054474786 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.026466677 |
| ent_coef_loss           | -1.8892574  |
| entropy                 | 0.5940085   |
| ep_rewmean              | -1.59       |
| episodes                | 416         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.6        |
| n_updates               | 41401       |
| policy_loss             | -11.242484  |
| qf1_loss                | 0.02878559  |
| qf2_loss                | 0.03801112  |
| time_elapsed            | 213         |
| total timesteps         | 41500       |
| value_loss              | 0.022421679 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.024869781 |
| ent_coef_loss           | 0.2453649   |
| entropy                 | 0.2594893   |
| ep_rewmean              | -1.51       |
| episodes                | 420         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.5        |
| n_updates               | 41801       |
| policy_loss             | -10.579868  |
| qf1_loss                | 1.623072    |
| qf2_loss                | 1.6345043   |
| time_elapsed            | 215         |
| total timesteps         | 41900       |
| value_loss              | 0.04616631  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.024984274 |
| ent_coef_loss           | 0.54156184  |
| entropy                 | 0.6672162   |
| ep_rewmean              | -1.49       |
| episodes                | 424         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.5        |
| n_updates               | 42201       |
| policy_loss             | -10.317663  |
| qf1_loss                | 0.035653364 |
| qf2_loss                | 0.04163131  |
| time_elapsed            | 217         |
| total timesteps         | 42300       |
| value_loss              | 0.035147876 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.027186219 |
| ent_coef_loss           | 0.17661327  |
| entropy                 | 0.75277466  |
| ep_rewmean              | -1.53       |
| episodes                | 428         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.5        |
| n_updates               | 42601       |
| policy_loss             | -9.646307   |
| qf1_loss                | 0.85476714  |
| qf2_loss                | 0.8709399   |
| time_elapsed            | 219         |
| total timesteps         | 42700       |
| value_loss              | 0.14531684  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.026959963 |
| ent_coef_loss           | 0.6967763   |
| entropy                 | 0.111279696 |
| ep_rewmean              | -1.52       |
| episodes                | 432         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.5        |
| n_updates               | 43001       |
| policy_loss             | -10.350887  |
| qf1_loss                | 0.041081868 |
| qf2_loss                | 0.033912856 |
| time_elapsed            | 221         |
| total timesteps         | 43100       |
| value_loss              | 0.028296554 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.026112543 |
| ent_coef_loss           | 0.5449832   |
| entropy                 | 0.37103695  |
| ep_rewmean              | -1.51       |
| episodes                | 436         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.5        |
| n_updates               | 43401       |
| policy_loss             | -10.428936  |
| qf1_loss                | 0.22233735  |
| qf2_loss                | 0.2381045   |
| time_elapsed            | 223         |
| total timesteps         | 43500       |
| value_loss              | 0.023799455 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.025539339 |
| ent_coef_loss           | 2.5446491   |
| entropy                 | 0.49156952  |
| ep_rewmean              | -1.48       |
| episodes                | 440         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.5        |
| n_updates               | 43801       |
| policy_loss             | -10.765616  |
| qf1_loss                | 0.031907357 |
| qf2_loss                | 0.06793215  |
| time_elapsed            | 225         |
| total timesteps         | 43900       |
| value_loss              | 0.03189687  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.025760416 |
| ent_coef_loss           | 2.0753477   |
| entropy                 | 0.8734336   |
| ep_rewmean              | -1.45       |
| episodes                | 444         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.4        |
| n_updates               | 44201       |
| policy_loss             | -10.241756  |
| qf1_loss                | 0.051004756 |
| qf2_loss                | 0.054928012 |
| time_elapsed            | 227         |
| total timesteps         | 44300       |
| value_loss              | 0.073110186 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.024987742 |
| ent_coef_loss           | -3.1683936  |
| entropy                 | 1.1793164   |
| ep_rewmean              | -1.41       |
| episodes                | 448         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.4        |
| n_updates               | 44601       |
| policy_loss             | -9.77183    |
| qf1_loss                | 0.027943794 |
| qf2_loss                | 0.01954031  |
| time_elapsed            | 229         |
| total timesteps         | 44700       |
| value_loss              | 0.061498847 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.024814805 |
| ent_coef_loss           | 1.7267705   |
| entropy                 | 0.9085336   |
| ep_rewmean              | -1.4        |
| episodes                | 452         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.4        |
| n_updates               | 45001       |
| policy_loss             | -9.764178   |
| qf1_loss                | 0.02379639  |
| qf2_loss                | 0.021635197 |
| time_elapsed            | 231         |
| total timesteps         | 45100       |
| value_loss              | 0.038130958 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.025364889 |
| ent_coef_loss           | 0.16037685  |
| entropy                 | 1.1556201   |
| ep_rewmean              | -1.42       |
| episodes                | 456         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.4        |
| n_updates               | 45401       |
| policy_loss             | -9.833817   |
| qf1_loss                | 0.039976977 |
| qf2_loss                | 0.038777836 |
| time_elapsed            | 233         |
| total timesteps         | 45500       |
| value_loss              | 0.03641941  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.02511496  |
| ent_coef_loss           | -2.1132982  |
| entropy                 | 0.8399957   |
| ep_rewmean              | -1.47       |
| episodes                | 460         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.5        |
| n_updates               | 45801       |
| policy_loss             | -9.396971   |
| qf1_loss                | 0.04462882  |
| qf2_loss                | 0.03230884  |
| time_elapsed            | 235         |
| total timesteps         | 45900       |
| value_loss              | 0.019696962 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.024379093 |
| ent_coef_loss           | -2.0943725  |
| entropy                 | 1.0016012   |
| ep_rewmean              | -1.5        |
| episodes                | 464         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.5        |
| n_updates               | 46201       |
| policy_loss             | -9.489853   |
| qf1_loss                | 0.01741764  |
| qf2_loss                | 0.014824897 |
| time_elapsed            | 237         |
| total timesteps         | 46300       |
| value_loss              | 0.019521693 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.02367524  |
| ent_coef_loss           | 0.6047976   |
| entropy                 | 0.928127    |
| ep_rewmean              | -1.5        |
| episodes                | 468         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.5        |
| n_updates               | 46601       |
| policy_loss             | -8.985699   |
| qf1_loss                | 0.047220685 |
| qf2_loss                | 0.050393123 |
| time_elapsed            | 239         |
| total timesteps         | 46700       |
| value_loss              | 0.060506716 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.02287488  |
| ent_coef_loss           | -1.5894113  |
| entropy                 | 0.74628264  |
| ep_rewmean              | -1.48       |
| episodes                | 472         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.5        |
| n_updates               | 47001       |
| policy_loss             | -8.841604   |
| qf1_loss                | 0.04284022  |
| qf2_loss                | 0.034955673 |
| time_elapsed            | 241         |
| total timesteps         | 47100       |
| value_loss              | 0.023105258 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.022353526 |
| ent_coef_loss           | 3.6004367   |
| entropy                 | 0.84787416  |
| ep_rewmean              | -1.48       |
| episodes                | 476         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.5        |
| n_updates               | 47401       |
| policy_loss             | -8.576534   |
| qf1_loss                | 0.019032855 |
| qf2_loss                | 0.022273969 |
| time_elapsed            | 243         |
| total timesteps         | 47500       |
| value_loss              | 0.04220436  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.021703955 |
| ent_coef_loss           | -3.7690387  |
| entropy                 | 1.0687608   |
| ep_rewmean              | -1.49       |
| episodes                | 480         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.5        |
| n_updates               | 47801       |
| policy_loss             | -8.671694   |
| qf1_loss                | 0.19555311  |
| qf2_loss                | 0.20593123  |
| time_elapsed            | 245         |
| total timesteps         | 47900       |
| value_loss              | 0.01738842  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.021069307 |
| ent_coef_loss           | -0.8565109  |
| entropy                 | 1.1579058   |
| ep_rewmean              | -1.5        |
| episodes                | 484         |
| eplenmean               | 100         |
| fps                     | 195         |
| mean 100 episode reward | -1.5        |
| n_updates               | 48201       |
| policy_loss             | -7.991618   |
| qf1_loss                | 0.6712701   |
| qf2_loss                | 0.7098441   |
| time_elapsed            | 247         |
| total timesteps         | 48300       |
| value_loss              | 0.019565072 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.02026187  |
| ent_coef_loss           | -0.263793   |
| entropy                 | 1.2185762   |
| ep_rewmean              | -1.46       |
| episodes                | 488         |
| eplenmean               | 100         |
| fps                     | 195         |
| mean 100 episode reward | -1.5        |
| n_updates               | 48601       |
| policy_loss             | -8.042971   |
| qf1_loss                | 0.037117206 |
| qf2_loss                | 0.033996888 |
| time_elapsed            | 249         |
| total timesteps         | 48700       |
| value_loss              | 0.050846655 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.019627992 |
| ent_coef_loss           | 0.28374237  |
| entropy                 | 1.4048151   |
| ep_rewmean              | -1.44       |
| episodes                | 492         |
| eplenmean               | 100         |
| fps                     | 195         |
| mean 100 episode reward | -1.4        |
| n_updates               | 49001       |
| policy_loss             | -7.886016   |
| qf1_loss                | 0.027498499 |
| qf2_loss                | 0.016407415 |
| time_elapsed            | 251         |
| total timesteps         | 49100       |
| value_loss              | 0.046355426 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.019202145 |
| ent_coef_loss           | -2.4250808  |
| entropy                 | 0.9651722   |
| ep_rewmean              | -1.47       |
| episodes                | 496         |
| eplenmean               | 100         |
| fps                     | 195         |
| mean 100 episode reward | -1.5        |
| n_updates               | 49401       |
| policy_loss             | -7.6009064  |
| qf1_loss                | 0.860039    |
| qf2_loss                | 0.87087834  |
| time_elapsed            | 253         |
| total timesteps         | 49500       |
| value_loss              | 0.015905604 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.01804103  |
| ent_coef_loss           | -2.620146   |
| entropy                 | 0.90576947  |
| ep_rewmean              | -1.47       |
| episodes                | 500         |
| eplenmean               | 100         |
| fps                     | 195         |
| mean 100 episode reward | -1.5        |
| n_updates               | 49801       |
| policy_loss             | -7.222516   |
| qf1_loss                | 0.16754973  |
| qf2_loss                | 0.18184258  |
| time_elapsed            | 255         |
| total timesteps         | 49900       |
| value_loss              | 0.023096468 |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-0.51 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.01808839   |
| ent_coef_loss           | 3.4231496    |
| entropy                 | 0.9263116    |
| ep_rewmean              | -1.43        |
| episodes                | 504          |
| eplenmean               | 100          |
| fps                     | 194          |
| mean 100 episode reward | -1.4         |
| n_updates               | 50201        |
| policy_loss             | -6.311251    |
| qf1_loss                | 0.025747456  |
| qf2_loss                | 0.0146511    |
| time_elapsed            | 258          |
| total timesteps         | 50300        |
| value_loss              | 0.0139812725 |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.018200405 |
| ent_coef_loss           | -2.4546463  |
| entropy                 | 0.8259602   |
| ep_rewmean              | -1.46       |
| episodes                | 508         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.5        |
| n_updates               | 50601       |
| policy_loss             | -6.4742703  |
| qf1_loss                | 0.46022388  |
| qf2_loss                | 0.47477657  |
| time_elapsed            | 260         |
| total timesteps         | 50700       |
| value_loss              | 0.02826991  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.017920207 |
| ent_coef_loss           | 0.12092176  |
| entropy                 | 0.8663478   |
| ep_rewmean              | -1.48       |
| episodes                | 512         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.5        |
| n_updates               | 51001       |
| policy_loss             | -6.0842543  |
| qf1_loss                | 0.1013602   |
| qf2_loss                | 0.1031347   |
| time_elapsed            | 262         |
| total timesteps         | 51100       |
| value_loss              | 0.047450107 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.017923456 |
| ent_coef_loss           | -2.7326849  |
| entropy                 | 0.7583041   |
| ep_rewmean              | -1.48       |
| episodes                | 516         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.5        |
| n_updates               | 51401       |
| policy_loss             | -5.48537    |
| qf1_loss                | 0.01212047  |
| qf2_loss                | 0.014137783 |
| time_elapsed            | 264         |
| total timesteps         | 51500       |
| value_loss              | 0.013996964 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.018077947 |
| ent_coef_loss           | 0.743794    |
| entropy                 | 0.8524864   |
| ep_rewmean              | -1.47       |
| episodes                | 520         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.5        |
| n_updates               | 51801       |
| policy_loss             | -5.098215   |
| qf1_loss                | 0.01221272  |
| qf2_loss                | 0.008750994 |
| time_elapsed            | 266         |
| total timesteps         | 51900       |
| value_loss              | 0.013154179 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.016813716 |
| ent_coef_loss           | -1.4855055  |
| entropy                 | 0.81912416  |
| ep_rewmean              | -1.43       |
| episodes                | 524         |
| eplenmean               | 100         |
| fps                     | 194         |
| mean 100 episode reward | -1.4        |
| n_updates               | 52201       |
| policy_loss             | -4.874074   |
| qf1_loss                | 0.24819368  |
| qf2_loss                | 0.22880295  |
| time_elapsed            | 268         |
| total timesteps         | 52300       |
| value_loss              | 0.017696885 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.015878975 |
| ent_coef_loss           | 1.6576434   |
| entropy                 | 0.68418604  |
| ep_rewmean              | -1.36       |
| episodes                | 528         |
| eplenmean               | 100         |
| fps                     | 195         |
| mean 100 episode reward | -1.4        |
| n_updates               | 52601       |
| policy_loss             | -4.8845625  |
| qf1_loss                | 0.6423928   |
| qf2_loss                | 0.6259352   |
| time_elapsed            | 270         |
| total timesteps         | 52700       |
| value_loss              | 0.007958882 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.015986431 |
| ent_coef_loss           | -1.9195322  |
| entropy                 | 0.97157043  |
| ep_rewmean              | -1.3        |
| episodes                | 532         |
| eplenmean               | 100         |
| fps                     | 195         |
| mean 100 episode reward | -1.3        |
| n_updates               | 53001       |
| policy_loss             | -4.4612017  |
| qf1_loss                | 0.06873749  |
| qf2_loss                | 0.07262917  |
| time_elapsed            | 272         |
| total timesteps         | 53100       |
| value_loss              | 0.005932059 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0152035635 |
| ent_coef_loss           | -1.6201305   |
| entropy                 | 0.7792828    |
| ep_rewmean              | -1.25        |
| episodes                | 536          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.2         |
| n_updates               | 53401        |
| policy_loss             | -4.430749    |
| qf1_loss                | 0.09373408   |
| qf2_loss                | 0.09522831   |
| time_elapsed            | 274          |
| total timesteps         | 53500        |
| value_loss              | 0.040521264  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0142162265 |
| ent_coef_loss           | -0.6805543   |
| entropy                 | 1.0652092    |
| ep_rewmean              | -1.21        |
| episodes                | 540          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.2         |
| n_updates               | 53801        |
| policy_loss             | -3.995278    |
| qf1_loss                | 0.053913765  |
| qf2_loss                | 0.059641767  |
| time_elapsed            | 276          |
| total timesteps         | 53900        |
| value_loss              | 0.011309616  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.013302653 |
| ent_coef_loss           | -1.9175618  |
| entropy                 | 0.7633701   |
| ep_rewmean              | -1.18       |
| episodes                | 544         |
| eplenmean               | 100         |
| fps                     | 195         |
| mean 100 episode reward | -1.2        |
| n_updates               | 54201       |
| policy_loss             | -4.3608932  |
| qf1_loss                | 0.01288615  |
| qf2_loss                | 0.008862147 |
| time_elapsed            | 278         |
| total timesteps         | 54300       |
| value_loss              | 0.006881699 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.012556244  |
| ent_coef_loss           | 1.8167269    |
| entropy                 | 0.7471931    |
| ep_rewmean              | -1.14        |
| episodes                | 548          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.1         |
| n_updates               | 54601        |
| policy_loss             | -3.7817848   |
| qf1_loss                | 0.0073319566 |
| qf2_loss                | 0.01092435   |
| time_elapsed            | 280          |
| total timesteps         | 54700        |
| value_loss              | 0.009182645  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.012344189 |
| ent_coef_loss           | 2.7696605   |
| entropy                 | 0.61608577  |
| ep_rewmean              | -1.09       |
| episodes                | 552         |
| eplenmean               | 100         |
| fps                     | 195         |
| mean 100 episode reward | -1.1        |
| n_updates               | 55001       |
| policy_loss             | -3.8115387  |
| qf1_loss                | 0.032204363 |
| qf2_loss                | 0.0293739   |
| time_elapsed            | 282         |
| total timesteps         | 55100       |
| value_loss              | 0.008548522 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.012276027 |
| ent_coef_loss           | 3.800319    |
| entropy                 | 1.1193458   |
| ep_rewmean              | -1.05       |
| episodes                | 556         |
| eplenmean               | 100         |
| fps                     | 195         |
| mean 100 episode reward | -1.1        |
| n_updates               | 55401       |
| policy_loss             | -3.2075381  |
| qf1_loss                | 0.040634386 |
| qf2_loss                | 0.051885698 |
| time_elapsed            | 284         |
| total timesteps         | 55500       |
| value_loss              | 0.009829308 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.013100649  |
| ent_coef_loss           | -4.32716     |
| entropy                 | 1.0608573    |
| ep_rewmean              | -1.01        |
| episodes                | 560          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1           |
| n_updates               | 55801        |
| policy_loss             | -3.2340949   |
| qf1_loss                | 0.0067410087 |
| qf2_loss                | 0.007856752  |
| time_elapsed            | 286          |
| total timesteps         | 55900        |
| value_loss              | 0.025862822  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.013044386 |
| ent_coef_loss           | -3.0715933  |
| entropy                 | 1.006113    |
| ep_rewmean              | -0.986      |
| episodes                | 564         |
| eplenmean               | 100         |
| fps                     | 195         |
| mean 100 episode reward | -1          |
| n_updates               | 56201       |
| policy_loss             | -3.3487737  |
| qf1_loss                | 0.10557565  |
| qf2_loss                | 0.12096241  |
| time_elapsed            | 288         |
| total timesteps         | 56300       |
| value_loss              | 0.06433461  |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.012942146  |
| ent_coef_loss           | -2.0032985   |
| entropy                 | 0.76747894   |
| ep_rewmean              | -0.98        |
| episodes                | 568          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1           |
| n_updates               | 56601        |
| policy_loss             | -3.147108    |
| qf1_loss                | 0.13177274   |
| qf2_loss                | 0.12100554   |
| time_elapsed            | 290          |
| total timesteps         | 56700        |
| value_loss              | 0.0049214126 |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.012052149 |
| ent_coef_loss           | 0.49724054  |
| entropy                 | 1.2458063   |
| ep_rewmean              | -1.01       |
| episodes                | 572         |
| eplenmean               | 100         |
| fps                     | 195         |
| mean 100 episode reward | -1          |
| n_updates               | 57001       |
| policy_loss             | -2.7501583  |
| qf1_loss                | 0.11934794  |
| qf2_loss                | 0.09807204  |
| time_elapsed            | 292         |
| total timesteps         | 57100       |
| value_loss              | 0.012569301 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.011632623 |
| ent_coef_loss           | -3.5476754  |
| entropy                 | 0.8155788   |
| ep_rewmean              | -1.06       |
| episodes                | 576         |
| eplenmean               | 100         |
| fps                     | 195         |
| mean 100 episode reward | -1.1        |
| n_updates               | 57401       |
| policy_loss             | -2.743516   |
| qf1_loss                | 0.007017199 |
| qf2_loss                | 0.004900179 |
| time_elapsed            | 294         |
| total timesteps         | 57500       |
| value_loss              | 0.008983122 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.011361777  |
| ent_coef_loss           | -2.3616178   |
| entropy                 | 0.9681879    |
| ep_rewmean              | -1.11        |
| episodes                | 580          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.1         |
| n_updates               | 57801        |
| policy_loss             | -2.2729928   |
| qf1_loss                | 0.0055259764 |
| qf2_loss                | 0.0040793917 |
| time_elapsed            | 296          |
| total timesteps         | 57900        |
| value_loss              | 0.047600143  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.010644665 |
| ent_coef_loss           | -1.3834072  |
| entropy                 | 0.82191193  |
| ep_rewmean              | -1.13       |
| episodes                | 584         |
| eplenmean               | 100         |
| fps                     | 195         |
| mean 100 episode reward | -1.1        |
| n_updates               | 58201       |
| policy_loss             | -2.3468819  |
| qf1_loss                | 0.028740777 |
| qf2_loss                | 0.02713057  |
| time_elapsed            | 298         |
| total timesteps         | 58300       |
| value_loss              | 0.003626467 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.010058857  |
| ent_coef_loss           | -1.50859     |
| entropy                 | 1.3264841    |
| ep_rewmean              | -1.17        |
| episodes                | 588          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.2         |
| n_updates               | 58601        |
| policy_loss             | -2.2034588   |
| qf1_loss                | 0.03174558   |
| qf2_loss                | 0.029220527  |
| time_elapsed            | 300          |
| total timesteps         | 58700        |
| value_loss              | 0.0030130898 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.00968646   |
| ent_coef_loss           | -1.0648229   |
| entropy                 | 1.1702892    |
| ep_rewmean              | -1.21        |
| episodes                | 592          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.2         |
| n_updates               | 59001        |
| policy_loss             | -2.132414    |
| qf1_loss                | 0.055260763  |
| qf2_loss                | 0.053962942  |
| time_elapsed            | 302          |
| total timesteps         | 59100        |
| value_loss              | 0.0029207282 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.009749717  |
| ent_coef_loss           | -0.6800782   |
| entropy                 | 2.1049976    |
| ep_rewmean              | -1.2         |
| episodes                | 596          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.2         |
| n_updates               | 59401        |
| policy_loss             | -1.9303368   |
| qf1_loss                | 0.0034230663 |
| qf2_loss                | 0.003506168  |
| time_elapsed            | 304          |
| total timesteps         | 59500        |
| value_loss              | 0.0073988046 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.010254286  |
| ent_coef_loss           | 6.1906996    |
| entropy                 | 2.4343104    |
| ep_rewmean              | -1.19        |
| episodes                | 600          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.2         |
| n_updates               | 59801        |
| policy_loss             | -2.0943146   |
| qf1_loss                | 0.002502807  |
| qf2_loss                | 0.0021963106 |
| time_elapsed            | 306          |
| total timesteps         | 59900        |
| value_loss              | 0.0038139452 |
------------------------------------------
Eval num_timesteps=60000, episode_reward=-1.15 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.010833251  |
| ent_coef_loss           | 1.4349427    |
| entropy                 | 2.7071702    |
| ep_rewmean              | -1.2         |
| episodes                | 604          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.2         |
| n_updates               | 60201        |
| policy_loss             | -1.5012606   |
| qf1_loss                | 0.0040098918 |
| qf2_loss                | 0.0035543307 |
| time_elapsed            | 308          |
| total timesteps         | 60300        |
| value_loss              | 0.0064458824 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.010366743  |
| ent_coef_loss           | -4.206456    |
| entropy                 | 2.2387114    |
| ep_rewmean              | -1.18        |
| episodes                | 608          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.2         |
| n_updates               | 60601        |
| policy_loss             | -1.5020854   |
| qf1_loss                | 0.0012365466 |
| qf2_loss                | 0.0009334709 |
| time_elapsed            | 310          |
| total timesteps         | 60700        |
| value_loss              | 0.0143932495 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.009586006  |
| ent_coef_loss           | -0.14799225  |
| entropy                 | 2.1206374    |
| ep_rewmean              | -1.16        |
| episodes                | 612          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.2         |
| n_updates               | 61001        |
| policy_loss             | -1.1486928   |
| qf1_loss                | 0.0027783024 |
| qf2_loss                | 0.0033234009 |
| time_elapsed            | 312          |
| total timesteps         | 61100        |
| value_loss              | 0.002693933  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.008676256  |
| ent_coef_loss           | -1.0274494   |
| entropy                 | 2.124661     |
| ep_rewmean              | -1.16        |
| episodes                | 616          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.2         |
| n_updates               | 61401        |
| policy_loss             | -0.91152084  |
| qf1_loss                | 0.0022410634 |
| qf2_loss                | 0.0017236177 |
| time_elapsed            | 314          |
| total timesteps         | 61500        |
| value_loss              | 0.005214771  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.008029671  |
| ent_coef_loss           | -2.6736465   |
| entropy                 | 2.0858808    |
| ep_rewmean              | -1.17        |
| episodes                | 620          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.2         |
| n_updates               | 61801        |
| policy_loss             | -0.7330041   |
| qf1_loss                | 0.0016528991 |
| qf2_loss                | 0.0011085963 |
| time_elapsed            | 316          |
| total timesteps         | 61900        |
| value_loss              | 0.006396636  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.007299186  |
| ent_coef_loss           | -6.6802816   |
| entropy                 | 1.4958885    |
| ep_rewmean              | -1.19        |
| episodes                | 624          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.2         |
| n_updates               | 62201        |
| policy_loss             | -0.7008435   |
| qf1_loss                | 0.0010069518 |
| qf2_loss                | 0.0006937159 |
| time_elapsed            | 318          |
| total timesteps         | 62300        |
| value_loss              | 0.0016110239 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0068151876  |
| ent_coef_loss           | 1.0373933     |
| entropy                 | 1.4675553     |
| ep_rewmean              | -1.2          |
| episodes                | 628           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.2          |
| n_updates               | 62601         |
| policy_loss             | -0.48912266   |
| qf1_loss                | 0.00081003876 |
| qf2_loss                | 0.0007624765  |
| time_elapsed            | 320           |
| total timesteps         | 62700         |
| value_loss              | 0.0026056897  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0063775107 |
| ent_coef_loss           | 4.616976     |
| entropy                 | 1.4187802    |
| ep_rewmean              | -1.22        |
| episodes                | 632          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.2         |
| n_updates               | 63001        |
| policy_loss             | -0.3522073   |
| qf1_loss                | 0.0011243805 |
| qf2_loss                | 0.0009449415 |
| time_elapsed            | 322          |
| total timesteps         | 63100        |
| value_loss              | 0.0016407717 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0059190597 |
| ent_coef_loss           | -2.7423623   |
| entropy                 | 1.5365177    |
| ep_rewmean              | -1.23        |
| episodes                | 636          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.2         |
| n_updates               | 63401        |
| policy_loss             | -0.35680446  |
| qf1_loss                | 0.010745728  |
| qf2_loss                | 0.0119148325 |
| time_elapsed            | 324          |
| total timesteps         | 63500        |
| value_loss              | 0.0009779686 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.005349223  |
| ent_coef_loss           | 1.8977034    |
| entropy                 | 1.5871243    |
| ep_rewmean              | -1.24        |
| episodes                | 640          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.2         |
| n_updates               | 63801        |
| policy_loss             | -0.29842666  |
| qf1_loss                | 0.0009900723 |
| qf2_loss                | 0.0006334587 |
| time_elapsed            | 326          |
| total timesteps         | 63900        |
| value_loss              | 0.001166218  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.004811198   |
| ent_coef_loss           | -1.594936     |
| entropy                 | 1.5544614     |
| ep_rewmean              | -1.28         |
| episodes                | 644           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.3          |
| n_updates               | 64201         |
| policy_loss             | -0.21176855   |
| qf1_loss                | 0.00068060483 |
| qf2_loss                | 0.00045459426 |
| time_elapsed            | 328           |
| total timesteps         | 64300         |
| value_loss              | 0.00084315566 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0042769588 |
| ent_coef_loss           | 1.2261426    |
| entropy                 | 1.8968948    |
| ep_rewmean              | -1.32        |
| episodes                | 648          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.3         |
| n_updates               | 64601        |
| policy_loss             | -0.07503943  |
| qf1_loss                | 0.0022049556 |
| qf2_loss                | 0.0018275292 |
| time_elapsed            | 330          |
| total timesteps         | 64700        |
| value_loss              | 0.0010001431 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0040224683 |
| ent_coef_loss           | -3.356289    |
| entropy                 | 1.4636908    |
| ep_rewmean              | -1.36        |
| episodes                | 652          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.4         |
| n_updates               | 65001        |
| policy_loss             | -0.15176597  |
| qf1_loss                | 0.0011042667 |
| qf2_loss                | 0.0014323028 |
| time_elapsed            | 332          |
| total timesteps         | 65100        |
| value_loss              | 0.0006663218 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0038855958  |
| ent_coef_loss           | -3.9533038    |
| entropy                 | 1.6953173     |
| ep_rewmean              | -1.39         |
| episodes                | 656           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.4          |
| n_updates               | 65401         |
| policy_loss             | 0.0024430393  |
| qf1_loss                | 0.00048725196 |
| qf2_loss                | 0.00043825645 |
| time_elapsed            | 334           |
| total timesteps         | 65500         |
| value_loss              | 0.0007939875  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0036369371  |
| ent_coef_loss           | -4.102199     |
| entropy                 | 1.4917567     |
| ep_rewmean              | -1.43         |
| episodes                | 660           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.4          |
| n_updates               | 65801         |
| policy_loss             | 0.06985791    |
| qf1_loss                | 0.00038953772 |
| qf2_loss                | 0.00045315202 |
| time_elapsed            | 336           |
| total timesteps         | 65900         |
| value_loss              | 0.00062497746 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0033916086  |
| ent_coef_loss           | -7.0739827    |
| entropy                 | 2.1330366     |
| ep_rewmean              | -1.5          |
| episodes                | 664           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.5          |
| n_updates               | 66201         |
| policy_loss             | 0.109143294   |
| qf1_loss                | 0.00029099776 |
| qf2_loss                | 0.00021468184 |
| time_elapsed            | 338           |
| total timesteps         | 66300         |
| value_loss              | 0.0009595931  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0031576448 |
| ent_coef_loss           | -5.3780065   |
| entropy                 | 2.3201442    |
| ep_rewmean              | -1.57        |
| episodes                | 668          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.6         |
| n_updates               | 66601        |
| policy_loss             | 0.23268569   |
| qf1_loss                | 0.005326525  |
| qf2_loss                | 0.004915392  |
| time_elapsed            | 340          |
| total timesteps         | 66700        |
| value_loss              | 0.0006361174 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0030641886  |
| ent_coef_loss           | 1.1027787     |
| entropy                 | 2.3508        |
| ep_rewmean              | -1.61         |
| episodes                | 672           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.6          |
| n_updates               | 67001         |
| policy_loss             | 0.20561284    |
| qf1_loss                | 0.0003104936  |
| qf2_loss                | 0.00027530806 |
| time_elapsed            | 342           |
| total timesteps         | 67100         |
| value_loss              | 0.00061835075 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0028931831  |
| ent_coef_loss           | 1.660575      |
| entropy                 | 2.6017299     |
| ep_rewmean              | -1.62         |
| episodes                | 676           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.6          |
| n_updates               | 67401         |
| policy_loss             | 0.32722318    |
| qf1_loss                | 0.001405465   |
| qf2_loss                | 0.00085551874 |
| time_elapsed            | 344           |
| total timesteps         | 67500         |
| value_loss              | 0.00048944104 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0027660946  |
| ent_coef_loss           | 4.3208327     |
| entropy                 | 3.084548      |
| ep_rewmean              | -1.65         |
| episodes                | 680           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.6          |
| n_updates               | 67801         |
| policy_loss             | 0.325977      |
| qf1_loss                | 0.00084274827 |
| qf2_loss                | 0.00089634064 |
| time_elapsed            | 346           |
| total timesteps         | 67900         |
| value_loss              | 0.00034629484 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002763193   |
| ent_coef_loss           | 0.6118062     |
| entropy                 | 2.7131839     |
| ep_rewmean              | -1.68         |
| episodes                | 684           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.7          |
| n_updates               | 68201         |
| policy_loss             | 0.39567497    |
| qf1_loss                | 0.0002868172  |
| qf2_loss                | 0.0001432721  |
| time_elapsed            | 348           |
| total timesteps         | 68300         |
| value_loss              | 0.00040433466 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0025555517  |
| ent_coef_loss           | -3.873106     |
| entropy                 | 2.8275957     |
| ep_rewmean              | -1.7          |
| episodes                | 688           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.7          |
| n_updates               | 68601         |
| policy_loss             | 0.39987004    |
| qf1_loss                | 0.00021785178 |
| qf2_loss                | 0.00024724012 |
| time_elapsed            | 350           |
| total timesteps         | 68700         |
| value_loss              | 0.0002831372  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0024284616  |
| ent_coef_loss           | -3.5858526    |
| entropy                 | 2.6728132     |
| ep_rewmean              | -1.71         |
| episodes                | 692           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.7          |
| n_updates               | 69001         |
| policy_loss             | 0.4624868     |
| qf1_loss                | 0.0015789382  |
| qf2_loss                | 0.0015683523  |
| time_elapsed            | 352           |
| total timesteps         | 69100         |
| value_loss              | 0.00039463793 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022813743  |
| ent_coef_loss           | -5.2292647    |
| entropy                 | 2.8421078     |
| ep_rewmean              | -1.73         |
| episodes                | 696           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.7          |
| n_updates               | 69401         |
| policy_loss             | 0.47915715    |
| qf1_loss                | 0.00215374    |
| qf2_loss                | 0.0023985826  |
| time_elapsed            | 354           |
| total timesteps         | 69500         |
| value_loss              | 0.00035997655 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0022136134 |
| ent_coef_loss           | -1.6246679   |
| entropy                 | 2.4449534    |
| ep_rewmean              | -1.76        |
| episodes                | 700          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.8         |
| n_updates               | 69801        |
| policy_loss             | 0.5164926    |
| qf1_loss                | 0.007907894  |
| qf2_loss                | 0.0068731187 |
| time_elapsed            | 356          |
| total timesteps         | 69900        |
| value_loss              | 0.0002507744 |
------------------------------------------
Eval num_timesteps=70000, episode_reward=-1.93 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022073386  |
| ent_coef_loss           | -5.808051     |
| entropy                 | 2.4781613     |
| ep_rewmean              | -1.81         |
| episodes                | 704           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.8          |
| n_updates               | 70201         |
| policy_loss             | 0.5307527     |
| qf1_loss                | 0.002457398   |
| qf2_loss                | 0.0023257884  |
| time_elapsed            | 359           |
| total timesteps         | 70300         |
| value_loss              | 0.00030431137 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019150678  |
| ent_coef_loss           | -4.5149317    |
| entropy                 | 2.3938842     |
| ep_rewmean              | -1.82         |
| episodes                | 708           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.8          |
| n_updates               | 70601         |
| policy_loss             | 0.5235801     |
| qf1_loss                | 0.0029332393  |
| qf2_loss                | 0.002971395   |
| time_elapsed            | 361           |
| total timesteps         | 70700         |
| value_loss              | 0.00026733556 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018384062  |
| ent_coef_loss           | 4.5947175     |
| entropy                 | 2.0312958     |
| ep_rewmean              | -1.82         |
| episodes                | 712           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.8          |
| n_updates               | 71001         |
| policy_loss             | 0.54934835    |
| qf1_loss                | 0.0014716748  |
| qf2_loss                | 0.00033073567 |
| time_elapsed            | 363           |
| total timesteps         | 71100         |
| value_loss              | 0.00035507375 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017187467  |
| ent_coef_loss           | -6.4672475    |
| entropy                 | 2.457041      |
| ep_rewmean              | -1.83         |
| episodes                | 716           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.8          |
| n_updates               | 71401         |
| policy_loss             | 0.59355605    |
| qf1_loss                | 0.00021918939 |
| qf2_loss                | 0.00015061579 |
| time_elapsed            | 365           |
| total timesteps         | 71500         |
| value_loss              | 0.00034785664 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018572159  |
| ent_coef_loss           | -4.656955     |
| entropy                 | 2.7496428     |
| ep_rewmean              | -1.81         |
| episodes                | 720           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.8          |
| n_updates               | 71801         |
| policy_loss             | 0.6108337     |
| qf1_loss                | 0.000271782   |
| qf2_loss                | 0.0003340512  |
| time_elapsed            | 367           |
| total timesteps         | 71900         |
| value_loss              | 0.00075471005 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018028534  |
| ent_coef_loss           | 6.8759604     |
| entropy                 | 2.9776888     |
| ep_rewmean              | -1.81         |
| episodes                | 724           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.8          |
| n_updates               | 72201         |
| policy_loss             | 0.60620666    |
| qf1_loss                | 0.00025869437 |
| qf2_loss                | 0.00031883438 |
| time_elapsed            | 369           |
| total timesteps         | 72300         |
| value_loss              | 0.00030203498 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017744323  |
| ent_coef_loss           | 7.585001      |
| entropy                 | 2.216278      |
| ep_rewmean              | -1.86         |
| episodes                | 728           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.9          |
| n_updates               | 72601         |
| policy_loss             | 0.6327757     |
| qf1_loss                | 0.003748413   |
| qf2_loss                | 0.003886393   |
| time_elapsed            | 371           |
| total timesteps         | 72700         |
| value_loss              | 0.00028390676 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017725524 |
| ent_coef_loss           | 7.641438     |
| entropy                 | 1.3993019    |
| ep_rewmean              | -1.89        |
| episodes                | 732          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.9         |
| n_updates               | 73001        |
| policy_loss             | 0.63934314   |
| qf1_loss                | 0.022674097  |
| qf2_loss                | 0.022484086  |
| time_elapsed            | 373          |
| total timesteps         | 73100        |
| value_loss              | 0.0006257879 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019424913  |
| ent_coef_loss           | 0.468019      |
| entropy                 | 2.181308      |
| ep_rewmean              | -1.91         |
| episodes                | 736           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.9          |
| n_updates               | 73401         |
| policy_loss             | 0.6817063     |
| qf1_loss                | 0.00029611174 |
| qf2_loss                | 0.00029634638 |
| time_elapsed            | 375           |
| total timesteps         | 73500         |
| value_loss              | 0.00031833502 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020430263  |
| ent_coef_loss           | -6.209402     |
| entropy                 | 3.5792735     |
| ep_rewmean              | -1.94         |
| episodes                | 740           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.9          |
| n_updates               | 73801         |
| policy_loss             | 0.7147593     |
| qf1_loss                | 0.00025645233 |
| qf2_loss                | 0.00017989613 |
| time_elapsed            | 377           |
| total timesteps         | 73900         |
| value_loss              | 0.00024445198 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018302237  |
| ent_coef_loss           | -4.5596       |
| entropy                 | 3.5958667     |
| ep_rewmean              | -1.94         |
| episodes                | 744           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.9          |
| n_updates               | 74201         |
| policy_loss             | 0.67379856    |
| qf1_loss                | 0.000317378   |
| qf2_loss                | 0.00030094583 |
| time_elapsed            | 379           |
| total timesteps         | 74300         |
| value_loss              | 0.0005302089  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017634197  |
| ent_coef_loss           | 8.93651       |
| entropy                 | 4.2486773     |
| ep_rewmean              | -1.94         |
| episodes                | 748           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.9          |
| n_updates               | 74601         |
| policy_loss             | 0.6622864     |
| qf1_loss                | 0.00031949638 |
| qf2_loss                | 0.00038861364 |
| time_elapsed            | 381           |
| total timesteps         | 74700         |
| value_loss              | 0.015963566   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018966423  |
| ent_coef_loss           | 5.0383453     |
| entropy                 | 3.5029435     |
| ep_rewmean              | -1.96         |
| episodes                | 752           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -2            |
| n_updates               | 75001         |
| policy_loss             | 0.6643584     |
| qf1_loss                | 0.0005618036  |
| qf2_loss                | 0.00048300796 |
| time_elapsed            | 383           |
| total timesteps         | 75100         |
| value_loss              | 0.0010214049  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021356568  |
| ent_coef_loss           | 10.414304     |
| entropy                 | 3.7858803     |
| ep_rewmean              | -1.99         |
| episodes                | 756           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -2            |
| n_updates               | 75401         |
| policy_loss             | 0.6584177     |
| qf1_loss                | 0.0024674223  |
| qf2_loss                | 0.0025269361  |
| time_elapsed            | 385           |
| total timesteps         | 75500         |
| value_loss              | 0.00051399326 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0023183925 |
| ent_coef_loss           | -2.604998    |
| entropy                 | 3.86825      |
| ep_rewmean              | -2           |
| episodes                | 760          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -2           |
| n_updates               | 75801        |
| policy_loss             | 0.70052576   |
| qf1_loss                | 0.004333453  |
| qf2_loss                | 0.004344454  |
| time_elapsed            | 387          |
| total timesteps         | 75900        |
| value_loss              | 0.0033663465 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022636193  |
| ent_coef_loss           | -2.3082728    |
| entropy                 | 3.6003304     |
| ep_rewmean              | -1.99         |
| episodes                | 764           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -2            |
| n_updates               | 76201         |
| policy_loss             | 0.6845086     |
| qf1_loss                | 0.00054853276 |
| qf2_loss                | 0.000460885   |
| time_elapsed            | 389           |
| total timesteps         | 76300         |
| value_loss              | 0.000741582   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022256759  |
| ent_coef_loss           | 9.562982      |
| entropy                 | 2.8919532     |
| ep_rewmean              | -1.95         |
| episodes                | 768           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.9          |
| n_updates               | 76601         |
| policy_loss             | 0.635822      |
| qf1_loss                | 0.00023685776 |
| qf2_loss                | 0.0002854101  |
| time_elapsed            | 391           |
| total timesteps         | 76700         |
| value_loss              | 0.0009266569  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0020646737 |
| ent_coef_loss           | -1.0591657   |
| entropy                 | 2.5733082    |
| ep_rewmean              | -1.88        |
| episodes                | 772          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.9         |
| n_updates               | 77001        |
| policy_loss             | 0.6554276    |
| qf1_loss                | 0.00572868   |
| qf2_loss                | 0.005361022  |
| time_elapsed            | 393          |
| total timesteps         | 77100        |
| value_loss              | 0.0030645789 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020042711  |
| ent_coef_loss           | 4.8836403     |
| entropy                 | 3.1933265     |
| ep_rewmean              | -1.82         |
| episodes                | 776           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.8          |
| n_updates               | 77401         |
| policy_loss             | 0.64732796    |
| qf1_loss                | 0.00042034622 |
| qf2_loss                | 0.00024208412 |
| time_elapsed            | 395           |
| total timesteps         | 77500         |
| value_loss              | 0.0041687866  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019436161  |
| ent_coef_loss           | 7.1991262     |
| entropy                 | 2.3053155     |
| ep_rewmean              | -1.8          |
| episodes                | 780           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.8          |
| n_updates               | 77801         |
| policy_loss             | 0.6155734     |
| qf1_loss                | 0.0004943324  |
| qf2_loss                | 0.00036727614 |
| time_elapsed            | 397           |
| total timesteps         | 77900         |
| value_loss              | 0.0008464117  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001909663   |
| ent_coef_loss           | -6.898884     |
| entropy                 | 2.756922      |
| ep_rewmean              | -1.75         |
| episodes                | 784           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.7          |
| n_updates               | 78201         |
| policy_loss             | 0.6540544     |
| qf1_loss                | 0.0005590734  |
| qf2_loss                | 0.00028969167 |
| time_elapsed            | 399           |
| total timesteps         | 78300         |
| value_loss              | 0.0030445412  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017469989 |
| ent_coef_loss           | -0.20624846  |
| entropy                 | 1.1925244    |
| ep_rewmean              | -1.75        |
| episodes                | 788          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.8         |
| n_updates               | 78601        |
| policy_loss             | 0.63046354   |
| qf1_loss                | 0.01224181   |
| qf2_loss                | 0.012172744  |
| time_elapsed            | 401          |
| total timesteps         | 78700        |
| value_loss              | 0.000839995  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001670895   |
| ent_coef_loss           | 2.5399666     |
| entropy                 | 2.5242276     |
| ep_rewmean              | -1.73         |
| episodes                | 792           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.7          |
| n_updates               | 79001         |
| policy_loss             | 0.6732993     |
| qf1_loss                | 0.0003842638  |
| qf2_loss                | 0.00027316314 |
| time_elapsed            | 403           |
| total timesteps         | 79100         |
| value_loss              | 0.0023312168  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001702996   |
| ent_coef_loss           | -2.3837187    |
| entropy                 | 2.8041086     |
| ep_rewmean              | -1.75         |
| episodes                | 796           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.7          |
| n_updates               | 79401         |
| policy_loss             | 0.6378491     |
| qf1_loss                | 0.0013737854  |
| qf2_loss                | 0.00091347547 |
| time_elapsed            | 405           |
| total timesteps         | 79500         |
| value_loss              | 0.002874092   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018877297  |
| ent_coef_loss           | 9.673417      |
| entropy                 | 2.7249713     |
| ep_rewmean              | -1.78         |
| episodes                | 800           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.8          |
| n_updates               | 79801         |
| policy_loss             | 0.6614605     |
| qf1_loss                | 0.00052315847 |
| qf2_loss                | 0.0003011416  |
| time_elapsed            | 407           |
| total timesteps         | 79900         |
| value_loss              | 0.0027364115  |
-------------------------------------------
Eval num_timesteps=80000, episode_reward=-3.12 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020262054  |
| ent_coef_loss           | 3.9879837     |
| entropy                 | 3.199608      |
| ep_rewmean              | -1.83         |
| episodes                | 804           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.8          |
| n_updates               | 80201         |
| policy_loss             | 0.64837754    |
| qf1_loss                | 0.0006145633  |
| qf2_loss                | 0.00037869823 |
| time_elapsed            | 410           |
| total timesteps         | 80300         |
| value_loss              | 0.0005973318  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018968196  |
| ent_coef_loss           | -7.3686585    |
| entropy                 | 2.7035055     |
| ep_rewmean              | -1.82         |
| episodes                | 808           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.8          |
| n_updates               | 80601         |
| policy_loss             | 0.6631217     |
| qf1_loss                | 0.005523478   |
| qf2_loss                | 0.0050941207  |
| time_elapsed            | 412           |
| total timesteps         | 80700         |
| value_loss              | 0.00040183318 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017340071  |
| ent_coef_loss           | 5.3037887     |
| entropy                 | 2.8297753     |
| ep_rewmean              | -1.85         |
| episodes                | 812           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.9          |
| n_updates               | 81001         |
| policy_loss             | 0.65872574    |
| qf1_loss                | 0.0073278216  |
| qf2_loss                | 0.006726755   |
| time_elapsed            | 414           |
| total timesteps         | 81100         |
| value_loss              | 0.00018455458 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001628323   |
| ent_coef_loss           | -3.8483963    |
| entropy                 | 2.477829      |
| ep_rewmean              | -1.91         |
| episodes                | 816           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.9          |
| n_updates               | 81401         |
| policy_loss             | 0.6820585     |
| qf1_loss                | 0.003564879   |
| qf2_loss                | 0.0038804563  |
| time_elapsed            | 416           |
| total timesteps         | 81500         |
| value_loss              | 0.00032706244 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014541763 |
| ent_coef_loss           | -10.754564   |
| entropy                 | 2.2253203    |
| ep_rewmean              | -1.96        |
| episodes                | 820          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -2           |
| n_updates               | 81801        |
| policy_loss             | 0.64975023   |
| qf1_loss                | 0.0035389573 |
| qf2_loss                | 0.0034559662 |
| time_elapsed            | 418          |
| total timesteps         | 81900        |
| value_loss              | 0.0006402999 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001348888  |
| ent_coef_loss           | 4.2890596    |
| entropy                 | 1.5482147    |
| ep_rewmean              | -2           |
| episodes                | 824          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -2           |
| n_updates               | 82201        |
| policy_loss             | 0.6447511    |
| qf1_loss                | 0.0059305783 |
| qf2_loss                | 0.006003507  |
| time_elapsed            | 420          |
| total timesteps         | 82300        |
| value_loss              | 0.0028915831 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012917613 |
| ent_coef_loss           | -8.000302    |
| entropy                 | 2.1780348    |
| ep_rewmean              | -2.01        |
| episodes                | 828          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -2           |
| n_updates               | 82601        |
| policy_loss             | 0.6179084    |
| qf1_loss                | 0.0018347597 |
| qf2_loss                | 0.0016086705 |
| time_elapsed            | 422          |
| total timesteps         | 82700        |
| value_loss              | 0.0004668545 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012408438  |
| ent_coef_loss           | -0.09763384   |
| entropy                 | 1.9877232     |
| ep_rewmean              | -2.02         |
| episodes                | 832           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -2            |
| n_updates               | 83001         |
| policy_loss             | 0.6173737     |
| qf1_loss                | 0.000421562   |
| qf2_loss                | 0.0003376432  |
| time_elapsed            | 424           |
| total timesteps         | 83100         |
| value_loss              | 0.00038940617 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011696944  |
| ent_coef_loss           | -5.8160243    |
| entropy                 | 1.8584228     |
| ep_rewmean              | -2.05         |
| episodes                | 836           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -2            |
| n_updates               | 83401         |
| policy_loss             | 0.6383966     |
| qf1_loss                | 0.003069951   |
| qf2_loss                | 0.0031388695  |
| time_elapsed            | 426           |
| total timesteps         | 83500         |
| value_loss              | 0.00020479006 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001167269   |
| ent_coef_loss           | 9.764941      |
| entropy                 | 1.6601954     |
| ep_rewmean              | -2.04         |
| episodes                | 840           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -2            |
| n_updates               | 83801         |
| policy_loss             | 0.66558325    |
| qf1_loss                | 0.0003052163  |
| qf2_loss                | 0.00024021513 |
| time_elapsed            | 428           |
| total timesteps         | 83900         |
| value_loss              | 0.00017092022 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001226705  |
| ent_coef_loss           | 0.68582284   |
| entropy                 | 1.84055      |
| ep_rewmean              | -2.06        |
| episodes                | 844          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -2.1         |
| n_updates               | 84201        |
| policy_loss             | 0.65579826   |
| qf1_loss                | 0.0023589113 |
| qf2_loss                | 0.0020902553 |
| time_elapsed            | 430          |
| total timesteps         | 84300        |
| value_loss              | 0.0002296323 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001255459   |
| ent_coef_loss           | -3.7239928    |
| entropy                 | 2.010576      |
| ep_rewmean              | -2.03         |
| episodes                | 848           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -2            |
| n_updates               | 84601         |
| policy_loss             | 0.6458678     |
| qf1_loss                | 0.0002289428  |
| qf2_loss                | 0.00017728437 |
| time_elapsed            | 432           |
| total timesteps         | 84700         |
| value_loss              | 0.00024212127 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012433811 |
| ent_coef_loss           | 1.4916077    |
| entropy                 | 2.7020206    |
| ep_rewmean              | -1.99        |
| episodes                | 852          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -2           |
| n_updates               | 85001        |
| policy_loss             | 0.66256714   |
| qf1_loss                | 0.0058259526 |
| qf2_loss                | 0.0057277186 |
| time_elapsed            | 434          |
| total timesteps         | 85100        |
| value_loss              | 0.0006282213 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012425602  |
| ent_coef_loss           | -5.3191967    |
| entropy                 | 2.5248904     |
| ep_rewmean              | -1.95         |
| episodes                | 856           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.9          |
| n_updates               | 85401         |
| policy_loss             | 0.6804751     |
| qf1_loss                | 0.00030348462 |
| qf2_loss                | 0.0001877525  |
| time_elapsed            | 436           |
| total timesteps         | 85500         |
| value_loss              | 0.00020006932 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014639918  |
| ent_coef_loss           | 14.593497     |
| entropy                 | 3.1911218     |
| ep_rewmean              | -1.9          |
| episodes                | 860           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.9          |
| n_updates               | 85801         |
| policy_loss             | 0.6379047     |
| qf1_loss                | 0.007854701   |
| qf2_loss                | 0.0076261098  |
| time_elapsed            | 438           |
| total timesteps         | 85900         |
| value_loss              | 0.00019009266 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015632779  |
| ent_coef_loss           | -2.6752846    |
| entropy                 | 3.4235566     |
| ep_rewmean              | -1.84         |
| episodes                | 864           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.8          |
| n_updates               | 86201         |
| policy_loss             | 0.7020624     |
| qf1_loss                | 0.00017028116 |
| qf2_loss                | 0.00018227115 |
| time_elapsed            | 440           |
| total timesteps         | 86300         |
| value_loss              | 0.00013760099 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013806771  |
| ent_coef_loss           | -4.6414285    |
| entropy                 | 2.2251294     |
| ep_rewmean              | -1.83         |
| episodes                | 868           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.8          |
| n_updates               | 86601         |
| policy_loss             | 0.67100084    |
| qf1_loss                | 0.00020866736 |
| qf2_loss                | 0.00020199775 |
| time_elapsed            | 442           |
| total timesteps         | 86700         |
| value_loss              | 0.0003201795  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012709827  |
| ent_coef_loss           | 2.2477694     |
| entropy                 | 2.5698647     |
| ep_rewmean              | -1.82         |
| episodes                | 872           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.8          |
| n_updates               | 87001         |
| policy_loss             | 0.68189085    |
| qf1_loss                | 0.0002447683  |
| qf2_loss                | 0.0001551863  |
| time_elapsed            | 444           |
| total timesteps         | 87100         |
| value_loss              | 0.00018884768 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011668304  |
| ent_coef_loss           | -3.4881818    |
| entropy                 | 1.7516955     |
| ep_rewmean              | -1.79         |
| episodes                | 876           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.8          |
| n_updates               | 87401         |
| policy_loss             | 0.66594636    |
| qf1_loss                | 0.00442893    |
| qf2_loss                | 0.004347458   |
| time_elapsed            | 446           |
| total timesteps         | 87500         |
| value_loss              | 0.00035815386 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011227529  |
| ent_coef_loss           | -0.6594858    |
| entropy                 | 2.1583936     |
| ep_rewmean              | -1.76         |
| episodes                | 880           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.8          |
| n_updates               | 87801         |
| policy_loss             | 0.6485173     |
| qf1_loss                | 0.00015398025 |
| qf2_loss                | 0.0002358269  |
| time_elapsed            | 448           |
| total timesteps         | 87900         |
| value_loss              | 0.00023169017 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010693866  |
| ent_coef_loss           | -9.892156     |
| entropy                 | 1.818291      |
| ep_rewmean              | -1.73         |
| episodes                | 884           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.7          |
| n_updates               | 88201         |
| policy_loss             | 0.6897071     |
| qf1_loss                | 0.00040750025 |
| qf2_loss                | 0.00027676622 |
| time_elapsed            | 450           |
| total timesteps         | 88300         |
| value_loss              | 0.00044148345 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010478954 |
| ent_coef_loss           | 2.4270864    |
| entropy                 | 1.3779984    |
| ep_rewmean              | -1.67        |
| episodes                | 888          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.7         |
| n_updates               | 88601        |
| policy_loss             | 0.6823529    |
| qf1_loss                | 0.0025321676 |
| qf2_loss                | 0.0025256064 |
| time_elapsed            | 452          |
| total timesteps         | 88700        |
| value_loss              | 0.0003159412 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00107737    |
| ent_coef_loss           | 0.48268723    |
| entropy                 | 1.8456641     |
| ep_rewmean              | -1.65         |
| episodes                | 892           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.6          |
| n_updates               | 89001         |
| policy_loss             | 0.6730179     |
| qf1_loss                | 0.00025117677 |
| qf2_loss                | 0.00023885592 |
| time_elapsed            | 454           |
| total timesteps         | 89100         |
| value_loss              | 0.0004647839  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011077122 |
| ent_coef_loss           | -5.7913346   |
| entropy                 | 1.1417626    |
| ep_rewmean              | -1.59        |
| episodes                | 896          |
| eplenmean               | 100          |
| fps                     | 195          |
| mean 100 episode reward | -1.6         |
| n_updates               | 89401        |
| policy_loss             | 0.7014736    |
| qf1_loss                | 7.863171e-05 |
| qf2_loss                | 9.861885e-05 |
| time_elapsed            | 456          |
| total timesteps         | 89500        |
| value_loss              | 0.0002800494 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011949214  |
| ent_coef_loss           | 4.693612      |
| entropy                 | 1.5758978     |
| ep_rewmean              | -1.52         |
| episodes                | 900           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.5          |
| n_updates               | 89801         |
| policy_loss             | 0.68464506    |
| qf1_loss                | 0.00012805674 |
| qf2_loss                | 0.00013271933 |
| time_elapsed            | 458           |
| total timesteps         | 89900         |
| value_loss              | 0.00014478846 |
-------------------------------------------
Eval num_timesteps=90000, episode_reward=-0.80 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012322734  |
| ent_coef_loss           | 1.8019516     |
| entropy                 | 1.8960103     |
| ep_rewmean              | -1.43         |
| episodes                | 904           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.4          |
| n_updates               | 90201         |
| policy_loss             | 0.676445      |
| qf1_loss                | 9.233465e-05  |
| qf2_loss                | 7.007172e-05  |
| time_elapsed            | 461           |
| total timesteps         | 90300         |
| value_loss              | 0.00017600361 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012633934  |
| ent_coef_loss           | -2.6756659    |
| entropy                 | 1.5021241     |
| ep_rewmean              | -1.44         |
| episodes                | 908           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.4          |
| n_updates               | 90601         |
| policy_loss             | 0.6757344     |
| qf1_loss                | 0.00014686427 |
| qf2_loss                | 9.9238634e-05 |
| time_elapsed            | 463           |
| total timesteps         | 90700         |
| value_loss              | 0.0001497202  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013137632  |
| ent_coef_loss           | -3.5486372    |
| entropy                 | 2.563417      |
| ep_rewmean              | -1.43         |
| episodes                | 912           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.4          |
| n_updates               | 91001         |
| policy_loss             | 0.6544726     |
| qf1_loss                | 0.0002736472  |
| qf2_loss                | 0.00020463039 |
| time_elapsed            | 465           |
| total timesteps         | 91100         |
| value_loss              | 0.042554762   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013325216  |
| ent_coef_loss           | -1.5651107    |
| entropy                 | 2.718945      |
| ep_rewmean              | -1.39         |
| episodes                | 916           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.4          |
| n_updates               | 91401         |
| policy_loss             | 0.68061936    |
| qf1_loss                | 0.00013284324 |
| qf2_loss                | 0.00014345995 |
| time_elapsed            | 467           |
| total timesteps         | 91500         |
| value_loss              | 0.00019598374 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013161283  |
| ent_coef_loss           | 3.710855      |
| entropy                 | 2.8535564     |
| ep_rewmean              | -1.35         |
| episodes                | 920           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.3          |
| n_updates               | 91801         |
| policy_loss             | 0.6753007     |
| qf1_loss                | 0.00015751686 |
| qf2_loss                | 0.00014542455 |
| time_elapsed            | 469           |
| total timesteps         | 91900         |
| value_loss              | 0.00036957566 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013360151  |
| ent_coef_loss           | 0.64912224    |
| entropy                 | 2.4715564     |
| ep_rewmean              | -1.32         |
| episodes                | 924           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.3          |
| n_updates               | 92201         |
| policy_loss             | 0.67171824    |
| qf1_loss                | 0.00012409844 |
| qf2_loss                | 0.0001369254  |
| time_elapsed            | 471           |
| total timesteps         | 92300         |
| value_loss              | 0.00027027423 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013549638  |
| ent_coef_loss           | -1.4846109    |
| entropy                 | 2.3007348     |
| ep_rewmean              | -1.24         |
| episodes                | 928           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.2          |
| n_updates               | 92601         |
| policy_loss             | 0.64335364    |
| qf1_loss                | 0.0043289154  |
| qf2_loss                | 0.0042037284  |
| time_elapsed            | 473           |
| total timesteps         | 92700         |
| value_loss              | 0.00010984347 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001423522   |
| ent_coef_loss           | 1.6147645     |
| entropy                 | 2.5110857     |
| ep_rewmean              | -1.18         |
| episodes                | 932           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.2          |
| n_updates               | 93001         |
| policy_loss             | 0.65960765    |
| qf1_loss                | 0.00015468706 |
| qf2_loss                | 0.00012448936 |
| time_elapsed            | 475           |
| total timesteps         | 93100         |
| value_loss              | 0.00016706108 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014290403  |
| ent_coef_loss           | 1.5008829     |
| entropy                 | 2.528048      |
| ep_rewmean              | -1.12         |
| episodes                | 936           |
| eplenmean               | 100           |
| fps                     | 195           |
| mean 100 episode reward | -1.1          |
| n_updates               | 93401         |
| policy_loss             | 0.66707695    |
| qf1_loss                | 0.0001342106  |
| qf2_loss                | 8.193351e-05  |
| time_elapsed            | 477           |
| total timesteps         | 93500         |
| value_loss              | 0.00020047373 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.001357161    |
| ent_coef_loss           | 1.7486973      |
| entropy                 | 2.3216674      |
| ep_rewmean              | -1.09          |
| episodes                | 940            |
| eplenmean               | 100            |
| fps                     | 195            |
| mean 100 episode reward | -1.1           |
| n_updates               | 93801          |
| policy_loss             | 0.6638706      |
| qf1_loss                | 0.00012137591  |
| qf2_loss                | 0.00011192936  |
| time_elapsed            | 479            |
| total timesteps         | 93900          |
| value_loss              | 0.000117475225 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012579405  |
| ent_coef_loss           | -4.346154     |
| entropy                 | 1.7526741     |
| ep_rewmean              | -1.06         |
| episodes                | 944           |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 94201         |
| policy_loss             | 0.68660724    |
| qf1_loss                | 0.0033767375  |
| qf2_loss                | 0.0033447805  |
| time_elapsed            | 481           |
| total timesteps         | 94300         |
| value_loss              | 0.00044180965 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012411776  |
| ent_coef_loss           | -10.467958    |
| entropy                 | 2.0242653     |
| ep_rewmean              | -1.03         |
| episodes                | 948           |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 94601         |
| policy_loss             | 0.6503997     |
| qf1_loss                | 0.014102688   |
| qf2_loss                | 0.01415614    |
| time_elapsed            | 483           |
| total timesteps         | 94700         |
| value_loss              | 0.00015417824 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011511208  |
| ent_coef_loss           | -5.422487     |
| entropy                 | 1.7249348     |
| ep_rewmean              | -1.03         |
| episodes                | 952           |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 95001         |
| policy_loss             | 0.67949456    |
| qf1_loss                | 7.735227e-05  |
| qf2_loss                | 7.986644e-05  |
| time_elapsed            | 485           |
| total timesteps         | 95100         |
| value_loss              | 0.00044666062 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011215784  |
| ent_coef_loss           | -10.952347    |
| entropy                 | 1.6994267     |
| ep_rewmean              | -1.02         |
| episodes                | 956           |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 95401         |
| policy_loss             | 0.6171198     |
| qf1_loss                | 0.0075568156  |
| qf2_loss                | 0.007838376   |
| time_elapsed            | 487           |
| total timesteps         | 95500         |
| value_loss              | 0.00028837117 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010556666  |
| ent_coef_loss           | 2.9871497     |
| entropy                 | 1.1930792     |
| ep_rewmean              | -1.05         |
| episodes                | 960           |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 95801         |
| policy_loss             | 0.6462151     |
| qf1_loss                | 0.0006920204  |
| qf2_loss                | 0.0011605703  |
| time_elapsed            | 489           |
| total timesteps         | 95900         |
| value_loss              | 0.00014543816 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009906762  |
| ent_coef_loss           | -2.8579917    |
| entropy                 | 0.76571435    |
| ep_rewmean              | -1.07         |
| episodes                | 964           |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 96201         |
| policy_loss             | 0.64682376    |
| qf1_loss                | 9.8535544e-05 |
| qf2_loss                | 9.209088e-05  |
| time_elapsed            | 491           |
| total timesteps         | 96300         |
| value_loss              | 0.00015435269 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009704452  |
| ent_coef_loss           | 2.166542      |
| entropy                 | 0.4770748     |
| ep_rewmean              | -1.08         |
| episodes                | 968           |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 96601         |
| policy_loss             | 0.65285945    |
| qf1_loss                | 0.00016525932 |
| qf2_loss                | 0.00016157387 |
| time_elapsed            | 493           |
| total timesteps         | 96700         |
| value_loss              | 0.00043274215 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009837202  |
| ent_coef_loss           | -4.4981146    |
| entropy                 | 0.54225576    |
| ep_rewmean              | -1.08         |
| episodes                | 972           |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 97001         |
| policy_loss             | 0.641347      |
| qf1_loss                | 0.0027102835  |
| qf2_loss                | 0.0026119505  |
| time_elapsed            | 495           |
| total timesteps         | 97100         |
| value_loss              | 0.00020336412 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009193995  |
| ent_coef_loss           | -1.773103     |
| entropy                 | 0.7866043     |
| ep_rewmean              | -1.09         |
| episodes                | 976           |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 97401         |
| policy_loss             | 0.63239753    |
| qf1_loss                | 0.00011076461 |
| qf2_loss                | 0.0001075467  |
| time_elapsed            | 497           |
| total timesteps         | 97500         |
| value_loss              | 0.00013579256 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011339716  |
| ent_coef_loss           | 25.570206     |
| entropy                 | 1.9860129     |
| ep_rewmean              | -1.1          |
| episodes                | 980           |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 97801         |
| policy_loss             | 0.58162975    |
| qf1_loss                | 0.00040890631 |
| qf2_loss                | 0.00044628364 |
| time_elapsed            | 499           |
| total timesteps         | 97900         |
| value_loss              | 0.0011664529  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012904697  |
| ent_coef_loss           | 5.9424767     |
| entropy                 | 2.5120144     |
| ep_rewmean              | -1.16         |
| episodes                | 984           |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 98201         |
| policy_loss             | 0.61345005    |
| qf1_loss                | 0.0001831449  |
| qf2_loss                | 0.00010591594 |
| time_elapsed            | 501           |
| total timesteps         | 98300         |
| value_loss              | 0.0002583487  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013277209 |
| ent_coef_loss           | 2.3589532    |
| entropy                 | 1.9351554    |
| ep_rewmean              | -1.18        |
| episodes                | 988          |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.2         |
| n_updates               | 98601        |
| policy_loss             | 0.60349286   |
| qf1_loss                | 0.00421672   |
| qf2_loss                | 0.004315597  |
| time_elapsed            | 503          |
| total timesteps         | 98700        |
| value_loss              | 0.0005066029 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013096795  |
| ent_coef_loss           | -3.2504578    |
| entropy                 | 1.3171171     |
| ep_rewmean              | -1.2          |
| episodes                | 992           |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 99001         |
| policy_loss             | 0.58833295    |
| qf1_loss                | 0.0037369707  |
| qf2_loss                | 0.003490405   |
| time_elapsed            | 505           |
| total timesteps         | 99100         |
| value_loss              | 0.00016478778 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012674736  |
| ent_coef_loss           | 2.6385732     |
| entropy                 | 1.596216      |
| ep_rewmean              | -1.22         |
| episodes                | 996           |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 99401         |
| policy_loss             | 0.5875355     |
| qf1_loss                | 0.0001771876  |
| qf2_loss                | 0.00019089508 |
| time_elapsed            | 507           |
| total timesteps         | 99500         |
| value_loss              | 0.0003646423  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012354782  |
| ent_coef_loss           | -6.4390335    |
| entropy                 | 0.9849573     |
| ep_rewmean              | -1.25         |
| episodes                | 1000          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 99801         |
| policy_loss             | 0.5778958     |
| qf1_loss                | 0.00011229367 |
| qf2_loss                | 0.00013861434 |
| time_elapsed            | 509           |
| total timesteps         | 99900         |
| value_loss              | 0.00017703537 |
-------------------------------------------
Eval num_timesteps=100000, episode_reward=-2.75 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011897414  |
| ent_coef_loss           | 0.39393336    |
| entropy                 | 1.1185912     |
| ep_rewmean              | -1.27         |
| episodes                | 1004          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 100201        |
| policy_loss             | 0.5381002     |
| qf1_loss                | 0.00022385347 |
| qf2_loss                | 0.00029171415 |
| time_elapsed            | 511           |
| total timesteps         | 100300        |
| value_loss              | 0.00015712576 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011661458 |
| ent_coef_loss           | -0.022336423 |
| entropy                 | 0.8835628    |
| ep_rewmean              | -1.28        |
| episodes                | 1008         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.3         |
| n_updates               | 100601       |
| policy_loss             | 0.5673388    |
| qf1_loss                | 0.0001001115 |
| qf2_loss                | 8.569661e-05 |
| time_elapsed            | 513          |
| total timesteps         | 100700       |
| value_loss              | 0.0002420625 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001111369  |
| ent_coef_loss           | 9.671339     |
| entropy                 | 0.73003185   |
| ep_rewmean              | -1.28        |
| episodes                | 1012         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.3         |
| n_updates               | 101001       |
| policy_loss             | 0.5571322    |
| qf1_loss                | 0.0032702626 |
| qf2_loss                | 0.00314211   |
| time_elapsed            | 515          |
| total timesteps         | 101100       |
| value_loss              | 0.002819243  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011216949  |
| ent_coef_loss           | -8.315197     |
| entropy                 | 0.3694308     |
| ep_rewmean              | -1.28         |
| episodes                | 1016          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 101401        |
| policy_loss             | 0.574952      |
| qf1_loss                | 0.00013859838 |
| qf2_loss                | 0.00015797155 |
| time_elapsed            | 517           |
| total timesteps         | 101500        |
| value_loss              | 0.00016415477 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010780263  |
| ent_coef_loss           | -1.8763335    |
| entropy                 | 1.2086914     |
| ep_rewmean              | -1.29         |
| episodes                | 1020          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 101801        |
| policy_loss             | 0.5410484     |
| qf1_loss                | 0.00062080834 |
| qf2_loss                | 0.0005722359  |
| time_elapsed            | 519           |
| total timesteps         | 101900        |
| value_loss              | 0.0034333423  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011668482  |
| ent_coef_loss           | -2.3879485    |
| entropy                 | 1.4183178     |
| ep_rewmean              | -1.27         |
| episodes                | 1024          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 102201        |
| policy_loss             | 0.58487517    |
| qf1_loss                | 0.0049465504  |
| qf2_loss                | 0.004953893   |
| time_elapsed            | 521           |
| total timesteps         | 102300        |
| value_loss              | 0.00060247217 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011949704 |
| ent_coef_loss           | -3.3827834   |
| entropy                 | 1.5843344    |
| ep_rewmean              | -1.28        |
| episodes                | 1028         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.3         |
| n_updates               | 102601       |
| policy_loss             | 0.5899135    |
| qf1_loss                | 0.0006502982 |
| qf2_loss                | 0.0007342358 |
| time_elapsed            | 523          |
| total timesteps         | 102700       |
| value_loss              | 0.0005381759 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011310636  |
| ent_coef_loss           | -2.6651702    |
| entropy                 | 1.713948      |
| ep_rewmean              | -1.31         |
| episodes                | 1032          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 103001        |
| policy_loss             | 0.5952958     |
| qf1_loss                | 0.00013700202 |
| qf2_loss                | 0.00020465543 |
| time_elapsed            | 525           |
| total timesteps         | 103100        |
| value_loss              | 0.0004802868  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010544918  |
| ent_coef_loss           | -1.6354324    |
| entropy                 | 1.5809972     |
| ep_rewmean              | -1.29         |
| episodes                | 1036          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 103401        |
| policy_loss             | 0.5792552     |
| qf1_loss                | 0.00018878988 |
| qf2_loss                | 0.00015400369 |
| time_elapsed            | 527           |
| total timesteps         | 103500        |
| value_loss              | 0.00026565773 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010731277  |
| ent_coef_loss           | 2.3994877     |
| entropy                 | 1.5157478     |
| ep_rewmean              | -1.29         |
| episodes                | 1040          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 103801        |
| policy_loss             | 0.5692696     |
| qf1_loss                | 0.0014096814  |
| qf2_loss                | 0.0013940432  |
| time_elapsed            | 529           |
| total timesteps         | 103900        |
| value_loss              | 0.00038065243 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010459914  |
| ent_coef_loss           | -6.450879     |
| entropy                 | 1.6108305     |
| ep_rewmean              | -1.27         |
| episodes                | 1044          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 104201        |
| policy_loss             | 0.5977508     |
| qf1_loss                | 0.00017812109 |
| qf2_loss                | 0.00015596714 |
| time_elapsed            | 531           |
| total timesteps         | 104300        |
| value_loss              | 0.00025180227 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011484217  |
| ent_coef_loss           | 10.832809     |
| entropy                 | 2.5332992     |
| ep_rewmean              | -1.31         |
| episodes                | 1048          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 104601        |
| policy_loss             | 0.58817697    |
| qf1_loss                | 0.003447481   |
| qf2_loss                | 0.0034375265  |
| time_elapsed            | 533           |
| total timesteps         | 104700        |
| value_loss              | 0.00050222164 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013396391  |
| ent_coef_loss           | 8.2030735     |
| entropy                 | 2.2874846     |
| ep_rewmean              | -1.35         |
| episodes                | 1052          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 105001        |
| policy_loss             | 0.5533744     |
| qf1_loss                | 0.005236538   |
| qf2_loss                | 0.0049740807  |
| time_elapsed            | 535           |
| total timesteps         | 105100        |
| value_loss              | 0.00018504984 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001589916   |
| ent_coef_loss           | 6.7389183     |
| entropy                 | 3.09515       |
| ep_rewmean              | -1.39         |
| episodes                | 1056          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 105401        |
| policy_loss             | 0.52709335    |
| qf1_loss                | 0.00031860708 |
| qf2_loss                | 0.00023322747 |
| time_elapsed            | 537           |
| total timesteps         | 105500        |
| value_loss              | 0.00024764356 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017683043  |
| ent_coef_loss           | 0.46752155    |
| entropy                 | 3.133745      |
| ep_rewmean              | -1.4          |
| episodes                | 1060          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 105801        |
| policy_loss             | 0.55145097    |
| qf1_loss                | 0.00029288995 |
| qf2_loss                | 0.00020750858 |
| time_elapsed            | 539           |
| total timesteps         | 105900        |
| value_loss              | 0.00029042386 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001804997  |
| ent_coef_loss           | 14.078277    |
| entropy                 | 3.8566823    |
| ep_rewmean              | -1.41        |
| episodes                | 1064         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.4         |
| n_updates               | 106201       |
| policy_loss             | 0.53796214   |
| qf1_loss                | 0.00543557   |
| qf2_loss                | 0.0052438336 |
| time_elapsed            | 541          |
| total timesteps         | 106300       |
| value_loss              | 0.0007212779 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017844335  |
| ent_coef_loss           | -8.423246     |
| entropy                 | 2.614243      |
| ep_rewmean              | -1.46         |
| episodes                | 1068          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.5          |
| n_updates               | 106601        |
| policy_loss             | 0.5474089     |
| qf1_loss                | 0.00030952977 |
| qf2_loss                | 0.00042469555 |
| time_elapsed            | 543           |
| total timesteps         | 106700        |
| value_loss              | 0.0008004368  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017092203  |
| ent_coef_loss           | -3.743985     |
| entropy                 | 3.0442286     |
| ep_rewmean              | -1.49         |
| episodes                | 1072          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.5          |
| n_updates               | 107001        |
| policy_loss             | 0.5345096     |
| qf1_loss                | 0.0029346582  |
| qf2_loss                | 0.0029700738  |
| time_elapsed            | 545           |
| total timesteps         | 107100        |
| value_loss              | 0.00028307462 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015700102  |
| ent_coef_loss           | -9.473521     |
| entropy                 | 3.443703      |
| ep_rewmean              | -1.55         |
| episodes                | 1076          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.6          |
| n_updates               | 107401        |
| policy_loss             | 0.55007267    |
| qf1_loss                | 0.0010710611  |
| qf2_loss                | 0.000996365   |
| time_elapsed            | 547           |
| total timesteps         | 107500        |
| value_loss              | 0.00039186113 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013985904  |
| ent_coef_loss           | -2.0002909    |
| entropy                 | 2.6956348     |
| ep_rewmean              | -1.6          |
| episodes                | 1080          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.6          |
| n_updates               | 107801        |
| policy_loss             | 0.49102736    |
| qf1_loss                | 0.0012940131  |
| qf2_loss                | 0.0013269044  |
| time_elapsed            | 549           |
| total timesteps         | 107900        |
| value_loss              | 0.00036937854 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001304627   |
| ent_coef_loss           | 1.1969857     |
| entropy                 | 2.4516602     |
| ep_rewmean              | -1.59         |
| episodes                | 1084          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.6          |
| n_updates               | 108201        |
| policy_loss             | 0.52396977    |
| qf1_loss                | 0.0019488109  |
| qf2_loss                | 0.0020454836  |
| time_elapsed            | 551           |
| total timesteps         | 108300        |
| value_loss              | 0.00023132825 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013342821  |
| ent_coef_loss           | 9.87065       |
| entropy                 | 2.5388598     |
| ep_rewmean              | -1.63         |
| episodes                | 1088          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.6          |
| n_updates               | 108601        |
| policy_loss             | 0.52707183    |
| qf1_loss                | 0.00019223805 |
| qf2_loss                | 0.00031397163 |
| time_elapsed            | 553           |
| total timesteps         | 108700        |
| value_loss              | 0.00022689151 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013546951  |
| ent_coef_loss           | 4.774475      |
| entropy                 | 2.2469423     |
| ep_rewmean              | -1.66         |
| episodes                | 1092          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 109001        |
| policy_loss             | 0.5289539     |
| qf1_loss                | 0.00033232427 |
| qf2_loss                | 0.0003828669  |
| time_elapsed            | 555           |
| total timesteps         | 109100        |
| value_loss              | 0.0005569825  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013744375  |
| ent_coef_loss           | 2.2273736     |
| entropy                 | 2.9022489     |
| ep_rewmean              | -1.67         |
| episodes                | 1096          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 109401        |
| policy_loss             | 0.5213194     |
| qf1_loss                | 0.00053242396 |
| qf2_loss                | 0.00051912456 |
| time_elapsed            | 557           |
| total timesteps         | 109500        |
| value_loss              | 0.0002569083  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013800295  |
| ent_coef_loss           | -1.2891059    |
| entropy                 | 2.8038044     |
| ep_rewmean              | -1.65         |
| episodes                | 1100          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.6          |
| n_updates               | 109801        |
| policy_loss             | 0.5392044     |
| qf1_loss                | 0.008177077   |
| qf2_loss                | 0.008387207   |
| time_elapsed            | 559           |
| total timesteps         | 109900        |
| value_loss              | 0.00027769455 |
-------------------------------------------
Eval num_timesteps=110000, episode_reward=-1.25 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013229571  |
| ent_coef_loss           | -1.9086659    |
| entropy                 | 2.8746467     |
| ep_rewmean              | -1.64         |
| episodes                | 1104          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.6          |
| n_updates               | 110201        |
| policy_loss             | 0.5705795     |
| qf1_loss                | 0.00020454123 |
| qf2_loss                | 0.00019981715 |
| time_elapsed            | 561           |
| total timesteps         | 110300        |
| value_loss              | 0.00016209739 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001283732   |
| ent_coef_loss           | 0.8767177     |
| entropy                 | 2.9523792     |
| ep_rewmean              | -1.63         |
| episodes                | 1108          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.6          |
| n_updates               | 110601        |
| policy_loss             | 0.5626008     |
| qf1_loss                | 0.00028886175 |
| qf2_loss                | 0.00040867645 |
| time_elapsed            | 563           |
| total timesteps         | 110700        |
| value_loss              | 0.00059454574 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011731553  |
| ent_coef_loss           | 1.6219714     |
| entropy                 | 3.0786436     |
| ep_rewmean              | -1.65         |
| episodes                | 1112          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.6          |
| n_updates               | 111001        |
| policy_loss             | 0.57642925    |
| qf1_loss                | 0.0040599955  |
| qf2_loss                | 0.0041769426  |
| time_elapsed            | 565           |
| total timesteps         | 111100        |
| value_loss              | 0.00033533314 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011397155  |
| ent_coef_loss           | -7.513152     |
| entropy                 | 2.8943808     |
| ep_rewmean              | -1.66         |
| episodes                | 1116          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 111401        |
| policy_loss             | 0.5597726     |
| qf1_loss                | 0.003745582   |
| qf2_loss                | 0.0036013606  |
| time_elapsed            | 567           |
| total timesteps         | 111500        |
| value_loss              | 0.00016259338 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011944566  |
| ent_coef_loss           | 9.616923      |
| entropy                 | 2.2906249     |
| ep_rewmean              | -1.67         |
| episodes                | 1120          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 111801        |
| policy_loss             | 0.5538386     |
| qf1_loss                | 0.0018042133  |
| qf2_loss                | 0.0019207922  |
| time_elapsed            | 569           |
| total timesteps         | 111900        |
| value_loss              | 0.00021810997 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013353253  |
| ent_coef_loss           | -3.745954     |
| entropy                 | 2.7468247     |
| ep_rewmean              | -1.67         |
| episodes                | 1124          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 112201        |
| policy_loss             | 0.5549836     |
| qf1_loss                | 0.00014550355 |
| qf2_loss                | 9.800987e-05  |
| time_elapsed            | 571           |
| total timesteps         | 112300        |
| value_loss              | 0.00019930919 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012969637  |
| ent_coef_loss           | -6.343021     |
| entropy                 | 2.701858      |
| ep_rewmean              | -1.68         |
| episodes                | 1128          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 112601        |
| policy_loss             | 0.5379554     |
| qf1_loss                | 0.00013990651 |
| qf2_loss                | 0.00023861896 |
| time_elapsed            | 573           |
| total timesteps         | 112700        |
| value_loss              | 0.00019747161 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012904783  |
| ent_coef_loss           | -4.988154     |
| entropy                 | 2.6268315     |
| ep_rewmean              | -1.71         |
| episodes                | 1132          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 113001        |
| policy_loss             | 0.57040656    |
| qf1_loss                | 0.0006707303  |
| qf2_loss                | 0.0008159964  |
| time_elapsed            | 575           |
| total timesteps         | 113100        |
| value_loss              | 0.00025885768 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012889599  |
| ent_coef_loss           | 0.8150407     |
| entropy                 | 3.1117697     |
| ep_rewmean              | -1.76         |
| episodes                | 1136          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.8          |
| n_updates               | 113401        |
| policy_loss             | 0.55596006    |
| qf1_loss                | 0.0001437672  |
| qf2_loss                | 0.00017789904 |
| time_elapsed            | 577           |
| total timesteps         | 113500        |
| value_loss              | 0.00015737857 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013355406  |
| ent_coef_loss           | -0.45204258   |
| entropy                 | 2.2654521     |
| ep_rewmean              | -1.82         |
| episodes                | 1140          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.8          |
| n_updates               | 113801        |
| policy_loss             | 0.50300944    |
| qf1_loss                | 0.00015143605 |
| qf2_loss                | 0.00014787854 |
| time_elapsed            | 579           |
| total timesteps         | 113900        |
| value_loss              | 0.00021228779 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013742868  |
| ent_coef_loss           | 10.031269     |
| entropy                 | 2.9099112     |
| ep_rewmean              | -1.83         |
| episodes                | 1144          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.8          |
| n_updates               | 114201        |
| policy_loss             | 0.51853275    |
| qf1_loss                | 0.0068656993  |
| qf2_loss                | 0.0071085156  |
| time_elapsed            | 581           |
| total timesteps         | 114300        |
| value_loss              | 0.00035151126 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013292279  |
| ent_coef_loss           | 1.2026134     |
| entropy                 | 2.8314364     |
| ep_rewmean              | -1.8          |
| episodes                | 1148          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.8          |
| n_updates               | 114601        |
| policy_loss             | 0.50498515    |
| qf1_loss                | 0.0011203946  |
| qf2_loss                | 0.0008150757  |
| time_elapsed            | 583           |
| total timesteps         | 114700        |
| value_loss              | 0.00031570066 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012185891  |
| ent_coef_loss           | 0.34223127    |
| entropy                 | 2.1265242     |
| ep_rewmean              | -1.78         |
| episodes                | 1152          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.8          |
| n_updates               | 115001        |
| policy_loss             | 0.48530102    |
| qf1_loss                | 0.00038976717 |
| qf2_loss                | 0.00034908002 |
| time_elapsed            | 585           |
| total timesteps         | 115100        |
| value_loss              | 0.0003310184  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011565202 |
| ent_coef_loss           | -4.808004    |
| entropy                 | 2.354371     |
| ep_rewmean              | -1.74        |
| episodes                | 1156         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.7         |
| n_updates               | 115401       |
| policy_loss             | 0.49357516   |
| qf1_loss                | 0.001994169  |
| qf2_loss                | 0.0020290771 |
| time_elapsed            | 587          |
| total timesteps         | 115500       |
| value_loss              | 0.0002377234 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010874189  |
| ent_coef_loss           | -2.3291888    |
| entropy                 | 2.388609      |
| ep_rewmean              | -1.74         |
| episodes                | 1160          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 115801        |
| policy_loss             | 0.52525353    |
| qf1_loss                | 0.00013123339 |
| qf2_loss                | 0.00011771842 |
| time_elapsed            | 589           |
| total timesteps         | 115900        |
| value_loss              | 0.0001762475  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001097985   |
| ent_coef_loss           | -10.655979    |
| entropy                 | 1.7777063     |
| ep_rewmean              | -1.75         |
| episodes                | 1164          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 116201        |
| policy_loss             | 0.51968396    |
| qf1_loss                | 0.0011024675  |
| qf2_loss                | 0.0010272838  |
| time_elapsed            | 591           |
| total timesteps         | 116300        |
| value_loss              | 0.00022373667 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011172435  |
| ent_coef_loss           | -1.9570706    |
| entropy                 | 0.32176048    |
| ep_rewmean              | -1.73         |
| episodes                | 1168          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 116601        |
| policy_loss             | 0.5494963     |
| qf1_loss                | 0.0014721276  |
| qf2_loss                | 0.0014893257  |
| time_elapsed            | 593           |
| total timesteps         | 116700        |
| value_loss              | 0.00022921701 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011543831  |
| ent_coef_loss           | -0.8212664    |
| entropy                 | 0.34510517    |
| ep_rewmean              | -1.72         |
| episodes                | 1172          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 117001        |
| policy_loss             | 0.47257298    |
| qf1_loss                | 0.00018164371 |
| qf2_loss                | 0.00015864364 |
| time_elapsed            | 595           |
| total timesteps         | 117100        |
| value_loss              | 0.00022398809 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012231772  |
| ent_coef_loss           | 8.050449      |
| entropy                 | 1.2193193     |
| ep_rewmean              | -1.68         |
| episodes                | 1176          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 117401        |
| policy_loss             | 0.5038347     |
| qf1_loss                | 0.007066224   |
| qf2_loss                | 0.0067545506  |
| time_elapsed            | 597           |
| total timesteps         | 117500        |
| value_loss              | 0.00024988112 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012918056  |
| ent_coef_loss           | 8.814727      |
| entropy                 | 1.493109      |
| ep_rewmean              | -1.67         |
| episodes                | 1180          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 117801        |
| policy_loss             | 0.49599633    |
| qf1_loss                | 0.0008755219  |
| qf2_loss                | 0.0007986401  |
| time_elapsed            | 599           |
| total timesteps         | 117900        |
| value_loss              | 0.00062474865 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0013287647   |
| ent_coef_loss           | 3.1173215      |
| entropy                 | 2.2131014      |
| ep_rewmean              | -1.68          |
| episodes                | 1184           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -1.7           |
| n_updates               | 118201         |
| policy_loss             | 0.48457336     |
| qf1_loss                | 0.00011475141  |
| qf2_loss                | 0.000113289156 |
| time_elapsed            | 601            |
| total timesteps         | 118300         |
| value_loss              | 0.00015777638  |
--------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013916333 |
| ent_coef_loss           | -3.7415047   |
| entropy                 | 1.7737427    |
| ep_rewmean              | -1.71        |
| episodes                | 1188         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.7         |
| n_updates               | 118601       |
| policy_loss             | 0.45629156   |
| qf1_loss                | 0.0027185304 |
| qf2_loss                | 0.0028854085 |
| time_elapsed            | 603          |
| total timesteps         | 118700       |
| value_loss              | 0.0003109821 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013220471  |
| ent_coef_loss           | 0.58489335    |
| entropy                 | 2.2782242     |
| ep_rewmean              | -1.71         |
| episodes                | 1192          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 119001        |
| policy_loss             | 0.48890704    |
| qf1_loss                | 0.0022836898  |
| qf2_loss                | 0.0022274356  |
| time_elapsed            | 605           |
| total timesteps         | 119100        |
| value_loss              | 0.00021750518 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012519654  |
| ent_coef_loss           | 2.2265332     |
| entropy                 | 2.6842399     |
| ep_rewmean              | -1.69         |
| episodes                | 1196          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 119401        |
| policy_loss             | 0.51394063    |
| qf1_loss                | 0.0013631232  |
| qf2_loss                | 0.0014327882  |
| time_elapsed            | 607           |
| total timesteps         | 119500        |
| value_loss              | 0.00022565007 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012088304  |
| ent_coef_loss           | -10.52846     |
| entropy                 | 2.275878      |
| ep_rewmean              | -1.68         |
| episodes                | 1200          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 119801        |
| policy_loss             | 0.44423896    |
| qf1_loss                | 0.0009072126  |
| qf2_loss                | 0.00087828824 |
| time_elapsed            | 609           |
| total timesteps         | 119900        |
| value_loss              | 0.0002594886  |
-------------------------------------------
Eval num_timesteps=120000, episode_reward=-0.86 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011233682  |
| ent_coef_loss           | -2.1400747    |
| entropy                 | 2.645075      |
| ep_rewmean              | -1.66         |
| episodes                | 1204          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.7          |
| n_updates               | 120201        |
| policy_loss             | 0.44838804    |
| qf1_loss                | 0.0009985948  |
| qf2_loss                | 0.0012152748  |
| time_elapsed            | 612           |
| total timesteps         | 120300        |
| value_loss              | 0.00031328722 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011691306  |
| ent_coef_loss           | -0.36806238   |
| entropy                 | 2.678363      |
| ep_rewmean              | -1.62         |
| episodes                | 1208          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.6          |
| n_updates               | 120601        |
| policy_loss             | 0.4201001     |
| qf1_loss                | 0.00010966662 |
| qf2_loss                | 0.0001109402  |
| time_elapsed            | 614           |
| total timesteps         | 120700        |
| value_loss              | 0.00016359631 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011362422  |
| ent_coef_loss           | 2.0174537     |
| entropy                 | 2.5884998     |
| ep_rewmean              | -1.57         |
| episodes                | 1212          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.6          |
| n_updates               | 121001        |
| policy_loss             | 0.41510648    |
| qf1_loss                | 0.00030767143 |
| qf2_loss                | 0.00018545672 |
| time_elapsed            | 616           |
| total timesteps         | 121100        |
| value_loss              | 0.00042796094 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011542152  |
| ent_coef_loss           | 3.05203       |
| entropy                 | 2.2469392     |
| ep_rewmean              | -1.52         |
| episodes                | 1216          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.5          |
| n_updates               | 121401        |
| policy_loss             | 0.37605703    |
| qf1_loss                | 0.00014855184 |
| qf2_loss                | 0.00020483068 |
| time_elapsed            | 618           |
| total timesteps         | 121500        |
| value_loss              | 0.00029996395 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012443165  |
| ent_coef_loss           | 2.4974148     |
| entropy                 | 2.5989265     |
| ep_rewmean              | -1.46         |
| episodes                | 1220          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.5          |
| n_updates               | 121801        |
| policy_loss             | 0.39542672    |
| qf1_loss                | 0.0032115816  |
| qf2_loss                | 0.0031529304  |
| time_elapsed            | 620           |
| total timesteps         | 121900        |
| value_loss              | 0.00015152634 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012804852  |
| ent_coef_loss           | 2.0134194     |
| entropy                 | 2.7074146     |
| ep_rewmean              | -1.45         |
| episodes                | 1224          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 122201        |
| policy_loss             | 0.40559506    |
| qf1_loss                | 9.534322e-05  |
| qf2_loss                | 5.616929e-05  |
| time_elapsed            | 622           |
| total timesteps         | 122300        |
| value_loss              | 0.00015218157 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013221574  |
| ent_coef_loss           | 12.537024     |
| entropy                 | 2.48974       |
| ep_rewmean              | -1.41         |
| episodes                | 1228          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 122601        |
| policy_loss             | 0.3982301     |
| qf1_loss                | 0.0001290542  |
| qf2_loss                | 0.00017066477 |
| time_elapsed            | 624           |
| total timesteps         | 122700        |
| value_loss              | 0.00017678959 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013921543  |
| ent_coef_loss           | 3.1353197     |
| entropy                 | 2.6828637     |
| ep_rewmean              | -1.35         |
| episodes                | 1232          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 123001        |
| policy_loss             | 0.40005672    |
| qf1_loss                | 9.587111e-05  |
| qf2_loss                | 0.00019483738 |
| time_elapsed            | 626           |
| total timesteps         | 123100        |
| value_loss              | 0.00015901704 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001322252   |
| ent_coef_loss           | -5.9938316    |
| entropy                 | 2.5095816     |
| ep_rewmean              | -1.3          |
| episodes                | 1236          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 123401        |
| policy_loss             | 0.42301005    |
| qf1_loss                | 0.00010892004 |
| qf2_loss                | 9.725326e-05  |
| time_elapsed            | 628           |
| total timesteps         | 123500        |
| value_loss              | 0.00020480895 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011824055  |
| ent_coef_loss           | 2.1496096     |
| entropy                 | 2.620812      |
| ep_rewmean              | -1.24         |
| episodes                | 1240          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 123801        |
| policy_loss             | 0.40074706    |
| qf1_loss                | 9.4748495e-05 |
| qf2_loss                | 5.5930734e-05 |
| time_elapsed            | 630           |
| total timesteps         | 123900        |
| value_loss              | 0.00013973145 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011290067  |
| ent_coef_loss           | -10.691888    |
| entropy                 | 2.414555      |
| ep_rewmean              | -1.23         |
| episodes                | 1244          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 124201        |
| policy_loss             | 0.42699814    |
| qf1_loss                | 0.00013267726 |
| qf2_loss                | 0.00016156893 |
| time_elapsed            | 632           |
| total timesteps         | 124300        |
| value_loss              | 0.00026727963 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010909042  |
| ent_coef_loss           | 3.7386072     |
| entropy                 | 2.0638635     |
| ep_rewmean              | -1.22         |
| episodes                | 1248          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 124601        |
| policy_loss             | 0.40798023    |
| qf1_loss                | 0.00012741322 |
| qf2_loss                | 8.796049e-05  |
| time_elapsed            | 634           |
| total timesteps         | 124700        |
| value_loss              | 0.00020230017 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012055977 |
| ent_coef_loss           | 6.5931473    |
| entropy                 | 2.2227464    |
| ep_rewmean              | -1.21        |
| episodes                | 1252         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.2         |
| n_updates               | 125001       |
| policy_loss             | 0.38212252   |
| qf1_loss                | 0.0010501776 |
| qf2_loss                | 0.0009733434 |
| time_elapsed            | 636          |
| total timesteps         | 125100       |
| value_loss              | 9.368582e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012737219  |
| ent_coef_loss           | 6.3579726     |
| entropy                 | 2.325282      |
| ep_rewmean              | -1.22         |
| episodes                | 1256          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 125401        |
| policy_loss             | 0.41260678    |
| qf1_loss                | 7.332465e-05  |
| qf2_loss                | 6.190274e-05  |
| time_elapsed            | 638           |
| total timesteps         | 125500        |
| value_loss              | 0.00017407017 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013357692  |
| ent_coef_loss           | 5.3009286     |
| entropy                 | 2.3543189     |
| ep_rewmean              | -1.19         |
| episodes                | 1260          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 125801        |
| policy_loss             | 0.39660504    |
| qf1_loss                | 0.00035747304 |
| qf2_loss                | 0.00031328673 |
| time_elapsed            | 640           |
| total timesteps         | 125900        |
| value_loss              | 0.00016134148 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013093017  |
| ent_coef_loss           | -7.9711275    |
| entropy                 | 2.4555383     |
| ep_rewmean              | -1.15         |
| episodes                | 1264          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 126201        |
| policy_loss             | 0.45588672    |
| qf1_loss                | 6.706059e-05  |
| qf2_loss                | 8.8560664e-05 |
| time_elapsed            | 642           |
| total timesteps         | 126300        |
| value_loss              | 0.0001582779  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011663059  |
| ent_coef_loss           | -8.261778     |
| entropy                 | 1.8599656     |
| ep_rewmean              | -1.11         |
| episodes                | 1268          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 126601        |
| policy_loss             | 0.41051823    |
| qf1_loss                | 0.00015967949 |
| qf2_loss                | 0.00015707572 |
| time_elapsed            | 644           |
| total timesteps         | 126700        |
| value_loss              | 0.00014501787 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010625465  |
| ent_coef_loss           | -3.195447     |
| entropy                 | 1.7961504     |
| ep_rewmean              | -1.09         |
| episodes                | 1272          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 127001        |
| policy_loss             | 0.4185479     |
| qf1_loss                | 0.00012908623 |
| qf2_loss                | 0.0001435722  |
| time_elapsed            | 646           |
| total timesteps         | 127100        |
| value_loss              | 0.00017651971 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010732578  |
| ent_coef_loss           | 4.08084       |
| entropy                 | 2.007511      |
| ep_rewmean              | -1.09         |
| episodes                | 1276          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 127401        |
| policy_loss             | 0.42584193    |
| qf1_loss                | 0.0001160026  |
| qf2_loss                | 0.00013168537 |
| time_elapsed            | 648           |
| total timesteps         | 127500        |
| value_loss              | 0.00015576418 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010869    |
| ent_coef_loss           | -0.7937226   |
| entropy                 | 2.17006      |
| ep_rewmean              | -1.08        |
| episodes                | 1280         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.1         |
| n_updates               | 127801       |
| policy_loss             | 0.40602624   |
| qf1_loss                | 0.0029477314 |
| qf2_loss                | 0.0028438945 |
| time_elapsed            | 650          |
| total timesteps         | 127900       |
| value_loss              | 0.0001054303 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0011391091   |
| ent_coef_loss           | 4.0964823      |
| entropy                 | 1.8440768      |
| ep_rewmean              | -1.02          |
| episodes                | 1284           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -1             |
| n_updates               | 128201         |
| policy_loss             | 0.42832112     |
| qf1_loss                | 9.5747004e-05  |
| qf2_loss                | 0.000106754655 |
| time_elapsed            | 652            |
| total timesteps         | 128300         |
| value_loss              | 0.00013849573  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011806629  |
| ent_coef_loss           | 6.1574836     |
| entropy                 | 2.0124676     |
| ep_rewmean              | -0.949        |
| episodes                | 1288          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 128601        |
| policy_loss             | 0.4455104     |
| qf1_loss                | 9.473283e-05  |
| qf2_loss                | 8.2661354e-05 |
| time_elapsed            | 654           |
| total timesteps         | 128700        |
| value_loss              | 0.00022247198 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012018943  |
| ent_coef_loss           | 8.667965      |
| entropy                 | 2.0248208     |
| ep_rewmean              | -0.918        |
| episodes                | 1292          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 129001        |
| policy_loss             | 0.45041472    |
| qf1_loss                | 0.0051965937  |
| qf2_loss                | 0.0051473323  |
| time_elapsed            | 656           |
| total timesteps         | 129100        |
| value_loss              | 0.00010683833 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012021803  |
| ent_coef_loss           | 7.3655047     |
| entropy                 | 1.9672557     |
| ep_rewmean              | -0.925        |
| episodes                | 1296          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 129401        |
| policy_loss             | 0.48608667    |
| qf1_loss                | 0.0020320374  |
| qf2_loss                | 0.0017385117  |
| time_elapsed            | 658           |
| total timesteps         | 129500        |
| value_loss              | 9.7203796e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001136841   |
| ent_coef_loss           | -5.959195     |
| entropy                 | 1.6461732     |
| ep_rewmean              | -0.937        |
| episodes                | 1300          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 129801        |
| policy_loss             | 0.4793956     |
| qf1_loss                | 0.0060893847  |
| qf2_loss                | 0.006248411   |
| time_elapsed            | 660           |
| total timesteps         | 129900        |
| value_loss              | 0.00011835394 |
-------------------------------------------
Eval num_timesteps=130000, episode_reward=-1.57 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010713602  |
| ent_coef_loss           | -2.600934     |
| entropy                 | 1.5961113     |
| ep_rewmean              | -0.949        |
| episodes                | 1304          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 130201        |
| policy_loss             | 0.42699215    |
| qf1_loss                | 0.00015361041 |
| qf2_loss                | 0.00016081214 |
| time_elapsed            | 662           |
| total timesteps         | 130300        |
| value_loss              | 0.0002067278  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010226979  |
| ent_coef_loss           | -5.8100004    |
| entropy                 | 1.7769458     |
| ep_rewmean              | -0.963        |
| episodes                | 1308          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 130601        |
| policy_loss             | 0.44321722    |
| qf1_loss                | 0.00012085651 |
| qf2_loss                | 0.00012828465 |
| time_elapsed            | 664           |
| total timesteps         | 130700        |
| value_loss              | 0.00016147202 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010125376  |
| ent_coef_loss           | 8.429955      |
| entropy                 | 1.7535262     |
| ep_rewmean              | -0.979        |
| episodes                | 1312          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 131001        |
| policy_loss             | 0.41207275    |
| qf1_loss                | 0.00032026976 |
| qf2_loss                | 0.00027206892 |
| time_elapsed            | 666           |
| total timesteps         | 131100        |
| value_loss              | 0.00011141383 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011350064  |
| ent_coef_loss           | 8.098933      |
| entropy                 | 1.492511      |
| ep_rewmean              | -1.02         |
| episodes                | 1316          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 131401        |
| policy_loss             | 0.4829406     |
| qf1_loss                | 9.104057e-05  |
| qf2_loss                | 0.00010472469 |
| time_elapsed            | 668           |
| total timesteps         | 131500        |
| value_loss              | 0.00032449618 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011918077 |
| ent_coef_loss           | -7.473898    |
| entropy                 | 2.186791     |
| ep_rewmean              | -1.05        |
| episodes                | 1320         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.1         |
| n_updates               | 131801       |
| policy_loss             | 0.4641177    |
| qf1_loss                | 0.0002592545 |
| qf2_loss                | 0.0002262858 |
| time_elapsed            | 670          |
| total timesteps         | 131900       |
| value_loss              | 0.0004704101 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0011995524   |
| ent_coef_loss           | -3.6463635     |
| entropy                 | 2.3348773      |
| ep_rewmean              | -1.08          |
| episodes                | 1324           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -1.1           |
| n_updates               | 132201         |
| policy_loss             | 0.5137527      |
| qf1_loss                | 0.00012434505  |
| qf2_loss                | 8.3380924e-05  |
| time_elapsed            | 672            |
| total timesteps         | 132300         |
| value_loss              | 0.000114928516 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012955439  |
| ent_coef_loss           | 2.9539309     |
| entropy                 | 1.8025656     |
| ep_rewmean              | -1.11         |
| episodes                | 1328          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 132601        |
| policy_loss             | 0.5147857     |
| qf1_loss                | 0.0034282042  |
| qf2_loss                | 0.003452752   |
| time_elapsed            | 674           |
| total timesteps         | 132700        |
| value_loss              | 0.00033514068 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013272892  |
| ent_coef_loss           | -4.224331     |
| entropy                 | 2.5429626     |
| ep_rewmean              | -1.14         |
| episodes                | 1332          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 133001        |
| policy_loss             | 0.4978124     |
| qf1_loss                | 0.0027741757  |
| qf2_loss                | 0.0027476188  |
| time_elapsed            | 676           |
| total timesteps         | 133100        |
| value_loss              | 0.00014417109 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012825836  |
| ent_coef_loss           | -7.994622     |
| entropy                 | 2.0946236     |
| ep_rewmean              | -1.19         |
| episodes                | 1336          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 133401        |
| policy_loss             | 0.47647375    |
| qf1_loss                | 0.00011071995 |
| qf2_loss                | 0.00014850235 |
| time_elapsed            | 678           |
| total timesteps         | 133500        |
| value_loss              | 0.00017779089 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011991945  |
| ent_coef_loss           | 2.4039712     |
| entropy                 | 2.0719757     |
| ep_rewmean              | -1.24         |
| episodes                | 1340          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 133801        |
| policy_loss             | 0.452456      |
| qf1_loss                | 5.7599515e-05 |
| qf2_loss                | 5.211637e-05  |
| time_elapsed            | 680           |
| total timesteps         | 133900        |
| value_loss              | 0.00019199558 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011040578 |
| ent_coef_loss           | -9.56347     |
| entropy                 | 2.0832915    |
| ep_rewmean              | -1.31        |
| episodes                | 1344         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.3         |
| n_updates               | 134201       |
| policy_loss             | 0.51778954   |
| qf1_loss                | 0.0032215747 |
| qf2_loss                | 0.0032456089 |
| time_elapsed            | 682          |
| total timesteps         | 134300       |
| value_loss              | 0.000132361  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010680524  |
| ent_coef_loss           | 6.608243      |
| entropy                 | 1.7673726     |
| ep_rewmean              | -1.4          |
| episodes                | 1348          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 134601        |
| policy_loss             | 0.47854018    |
| qf1_loss                | 0.004199669   |
| qf2_loss                | 0.0035745557  |
| time_elapsed            | 684           |
| total timesteps         | 134700        |
| value_loss              | 0.00011662673 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010331149  |
| ent_coef_loss           | -0.99544156   |
| entropy                 | 2.166031      |
| ep_rewmean              | -1.4          |
| episodes                | 1352          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 135001        |
| policy_loss             | 0.5072479     |
| qf1_loss                | 0.00017065262 |
| qf2_loss                | 0.00019070928 |
| time_elapsed            | 686           |
| total timesteps         | 135100        |
| value_loss              | 0.00018877312 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010858168  |
| ent_coef_loss           | 18.936289     |
| entropy                 | 1.8501427     |
| ep_rewmean              | -1.39         |
| episodes                | 1356          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 135401        |
| policy_loss             | 0.4214159     |
| qf1_loss                | 0.00021647036 |
| qf2_loss                | 0.00013190813 |
| time_elapsed            | 688           |
| total timesteps         | 135500        |
| value_loss              | 0.00027322932 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0012109858   |
| ent_coef_loss           | 7.1493144      |
| entropy                 | 2.0811212      |
| ep_rewmean              | -1.38          |
| episodes                | 1360           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -1.4           |
| n_updates               | 135801         |
| policy_loss             | 0.5090841      |
| qf1_loss                | 0.00013775479  |
| qf2_loss                | 0.000117200165 |
| time_elapsed            | 690            |
| total timesteps         | 135900         |
| value_loss              | 0.00017881292  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012559476  |
| ent_coef_loss           | 1.3756664     |
| entropy                 | 1.4837308     |
| ep_rewmean              | -1.39         |
| episodes                | 1364          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 136201        |
| policy_loss             | 0.44871563    |
| qf1_loss                | 8.136254e-05  |
| qf2_loss                | 8.0982034e-05 |
| time_elapsed            | 692           |
| total timesteps         | 136300        |
| value_loss              | 0.00028303772 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.001236624    |
| ent_coef_loss           | -6.3837295     |
| entropy                 | 2.0588229      |
| ep_rewmean              | -1.4           |
| episodes                | 1368           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -1.4           |
| n_updates               | 136601         |
| policy_loss             | 0.5293094      |
| qf1_loss                | 0.000111112306 |
| qf2_loss                | 0.00011505093  |
| time_elapsed            | 694            |
| total timesteps         | 136700         |
| value_loss              | 0.00012651464  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012612873  |
| ent_coef_loss           | 0.7492937     |
| entropy                 | 2.1624346     |
| ep_rewmean              | -1.41         |
| episodes                | 1372          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 137001        |
| policy_loss             | 0.4636153     |
| qf1_loss                | 0.00010664056 |
| qf2_loss                | 0.00012056065 |
| time_elapsed            | 696           |
| total timesteps         | 137100        |
| value_loss              | 0.00012157299 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0012564197   |
| ent_coef_loss           | 5.130149       |
| entropy                 | 2.4785652      |
| ep_rewmean              | -1.4           |
| episodes                | 1376           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -1.4           |
| n_updates               | 137401         |
| policy_loss             | 0.473625       |
| qf1_loss                | 0.000111804795 |
| qf2_loss                | 0.00011893107  |
| time_elapsed            | 698            |
| total timesteps         | 137500         |
| value_loss              | 0.0003037816   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012943503  |
| ent_coef_loss           | 4.4066834     |
| entropy                 | 1.8353331     |
| ep_rewmean              | -1.39         |
| episodes                | 1380          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 137801        |
| policy_loss             | 0.49385196    |
| qf1_loss                | 0.0012153643  |
| qf2_loss                | 0.0011699414  |
| time_elapsed            | 700           |
| total timesteps         | 137900        |
| value_loss              | 0.00029054043 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012384097  |
| ent_coef_loss           | 3.452575      |
| entropy                 | 2.4246392     |
| ep_rewmean              | -1.37         |
| episodes                | 1384          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 138201        |
| policy_loss             | 0.56051993    |
| qf1_loss                | 0.0015463161  |
| qf2_loss                | 0.0015886044  |
| time_elapsed            | 702           |
| total timesteps         | 138300        |
| value_loss              | 0.00022516912 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012503624  |
| ent_coef_loss           | -0.6155413    |
| entropy                 | 2.5638256     |
| ep_rewmean              | -1.34         |
| episodes                | 1388          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 138601        |
| policy_loss             | 0.50804424    |
| qf1_loss                | 0.0002454501  |
| qf2_loss                | 0.00023909398 |
| time_elapsed            | 704           |
| total timesteps         | 138700        |
| value_loss              | 7.418336e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001278895   |
| ent_coef_loss           | -2.0764604    |
| entropy                 | 2.3867898     |
| ep_rewmean              | -1.31         |
| episodes                | 1392          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 139001        |
| policy_loss             | 0.51800156    |
| qf1_loss                | 0.00015689325 |
| qf2_loss                | 0.00020652637 |
| time_elapsed            | 706           |
| total timesteps         | 139100        |
| value_loss              | 0.00029927006 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012281947  |
| ent_coef_loss           | 1.2190424     |
| entropy                 | 2.2324533     |
| ep_rewmean              | -1.27         |
| episodes                | 1396          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 139401        |
| policy_loss             | 0.4659177     |
| qf1_loss                | 0.00047801234 |
| qf2_loss                | 0.0005207937  |
| time_elapsed            | 708           |
| total timesteps         | 139500        |
| value_loss              | 0.0002029484  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011961688  |
| ent_coef_loss           | -4.29844      |
| entropy                 | 2.5873442     |
| ep_rewmean              | -1.25         |
| episodes                | 1400          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 139801        |
| policy_loss             | 0.46314055    |
| qf1_loss                | 0.0024512678  |
| qf2_loss                | 0.002354585   |
| time_elapsed            | 710           |
| total timesteps         | 139900        |
| value_loss              | 0.00019321192 |
-------------------------------------------
Eval num_timesteps=140000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011878838  |
| ent_coef_loss           | 5.8349        |
| entropy                 | 3.1889675     |
| ep_rewmean              | -1.22         |
| episodes                | 1404          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 140201        |
| policy_loss             | 0.4970383     |
| qf1_loss                | 0.00085027603 |
| qf2_loss                | 0.0008731346  |
| time_elapsed            | 712           |
| total timesteps         | 140300        |
| value_loss              | 0.0003277774  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012460841  |
| ent_coef_loss           | -1.889174     |
| entropy                 | 2.331161      |
| ep_rewmean              | -1.2          |
| episodes                | 1408          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 140601        |
| policy_loss             | 0.4877715     |
| qf1_loss                | 0.0002629334  |
| qf2_loss                | 0.00027813885 |
| time_elapsed            | 714           |
| total timesteps         | 140700        |
| value_loss              | 0.0005232931  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012604076  |
| ent_coef_loss           | -2.5596433    |
| entropy                 | 2.6401353     |
| ep_rewmean              | -1.2          |
| episodes                | 1412          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 141001        |
| policy_loss             | 0.45464146    |
| qf1_loss                | 0.00021176889 |
| qf2_loss                | 0.00025008735 |
| time_elapsed            | 716           |
| total timesteps         | 141100        |
| value_loss              | 0.0002974277  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0012754565   |
| ent_coef_loss           | 4.5696526      |
| entropy                 | 2.6416984      |
| ep_rewmean              | -1.19          |
| episodes                | 1416           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -1.2           |
| n_updates               | 141401         |
| policy_loss             | 0.42408293     |
| qf1_loss                | 0.000115339295 |
| qf2_loss                | 9.544425e-05   |
| time_elapsed            | 718            |
| total timesteps         | 141500         |
| value_loss              | 0.0004824478   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001258505   |
| ent_coef_loss           | -5.5619216    |
| entropy                 | 2.4131217     |
| ep_rewmean              | -1.18         |
| episodes                | 1420          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 141801        |
| policy_loss             | 0.4670831     |
| qf1_loss                | 0.00014525974 |
| qf2_loss                | 0.0002063469  |
| time_elapsed            | 720           |
| total timesteps         | 141900        |
| value_loss              | 0.0001571567  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012347786  |
| ent_coef_loss           | 0.3399942     |
| entropy                 | 1.7166703     |
| ep_rewmean              | -1.19         |
| episodes                | 1424          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 142201        |
| policy_loss             | 0.4732492     |
| qf1_loss                | 0.005428183   |
| qf2_loss                | 0.0061275484  |
| time_elapsed            | 722           |
| total timesteps         | 142300        |
| value_loss              | 0.00023838205 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012251829  |
| ent_coef_loss           | -0.86805546   |
| entropy                 | 2.0636175     |
| ep_rewmean              | -1.19         |
| episodes                | 1428          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 142601        |
| policy_loss             | 0.44164282    |
| qf1_loss                | 0.00012820568 |
| qf2_loss                | 0.00017524557 |
| time_elapsed            | 724           |
| total timesteps         | 142700        |
| value_loss              | 0.00019568035 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012637959  |
| ent_coef_loss           | -2.20537      |
| entropy                 | 2.0431962     |
| ep_rewmean              | -1.19         |
| episodes                | 1432          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 143001        |
| policy_loss             | 0.4476108     |
| qf1_loss                | 0.00046736433 |
| qf2_loss                | 0.00042092224 |
| time_elapsed            | 726           |
| total timesteps         | 143100        |
| value_loss              | 0.00021675549 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013960598  |
| ent_coef_loss           | 0.6739073     |
| entropy                 | 2.688857      |
| ep_rewmean              | -1.16         |
| episodes                | 1436          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 143401        |
| policy_loss             | 0.45822453    |
| qf1_loss                | 9.926064e-05  |
| qf2_loss                | 0.00012109976 |
| time_elapsed            | 728           |
| total timesteps         | 143500        |
| value_loss              | 0.00027467136 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015383674  |
| ent_coef_loss           | -1.9827406    |
| entropy                 | 3.004087      |
| ep_rewmean              | -1.11         |
| episodes                | 1440          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 143801        |
| policy_loss             | 0.47372755    |
| qf1_loss                | 0.00019251116 |
| qf2_loss                | 0.00016138298 |
| time_elapsed            | 730           |
| total timesteps         | 143900        |
| value_loss              | 0.00021990207 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015469997  |
| ent_coef_loss           | -1.5134115    |
| entropy                 | 2.355215      |
| ep_rewmean              | -1.1          |
| episodes                | 1444          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 144201        |
| policy_loss             | 0.4453042     |
| qf1_loss                | 0.002107974   |
| qf2_loss                | 0.0019691512  |
| time_elapsed            | 732           |
| total timesteps         | 144300        |
| value_loss              | 0.00034367648 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001504713   |
| ent_coef_loss           | -3.4880095    |
| entropy                 | 2.7769868     |
| ep_rewmean              | -1.03         |
| episodes                | 1448          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 144601        |
| policy_loss             | 0.48222905    |
| qf1_loss                | 0.0036636277  |
| qf2_loss                | 0.0039773835  |
| time_elapsed            | 734           |
| total timesteps         | 144700        |
| value_loss              | 0.00020370158 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015382507  |
| ent_coef_loss           | -3.3801713    |
| entropy                 | 3.1980126     |
| ep_rewmean              | -1.05         |
| episodes                | 1452          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 145001        |
| policy_loss             | 0.44167006    |
| qf1_loss                | 0.00015757291 |
| qf2_loss                | 0.00015505814 |
| time_elapsed            | 736           |
| total timesteps         | 145100        |
| value_loss              | 0.00036522647 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015655188  |
| ent_coef_loss           | 0.9702909     |
| entropy                 | 2.9089503     |
| ep_rewmean              | -1.05         |
| episodes                | 1456          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 145401        |
| policy_loss             | 0.38666043    |
| qf1_loss                | 0.0001372684  |
| qf2_loss                | 0.00014451183 |
| time_elapsed            | 738           |
| total timesteps         | 145500        |
| value_loss              | 0.00019683164 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017183116  |
| ent_coef_loss           | 1.5678744     |
| entropy                 | 2.814289      |
| ep_rewmean              | -1.07         |
| episodes                | 1460          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 145801        |
| policy_loss             | 0.47221076    |
| qf1_loss                | 0.003458425   |
| qf2_loss                | 0.0035881086  |
| time_elapsed            | 740           |
| total timesteps         | 145900        |
| value_loss              | 0.00016673813 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017855051  |
| ent_coef_loss           | 7.373442      |
| entropy                 | 2.991505      |
| ep_rewmean              | -1.05         |
| episodes                | 1464          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 146201        |
| policy_loss             | 0.41976538    |
| qf1_loss                | 0.00013466505 |
| qf2_loss                | 0.00012555436 |
| time_elapsed            | 742           |
| total timesteps         | 146300        |
| value_loss              | 0.00017458496 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018266909  |
| ent_coef_loss           | -3.9545634    |
| entropy                 | 3.5203319     |
| ep_rewmean              | -1.02         |
| episodes                | 1468          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 146601        |
| policy_loss             | 0.35429347    |
| qf1_loss                | 0.00012911927 |
| qf2_loss                | 0.0001683707  |
| time_elapsed            | 744           |
| total timesteps         | 146700        |
| value_loss              | 0.00032472864 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001874527   |
| ent_coef_loss           | 4.90835       |
| entropy                 | 3.2602062     |
| ep_rewmean              | -0.985        |
| episodes                | 1472          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 147001        |
| policy_loss             | 0.36438248    |
| qf1_loss                | 0.0018543822  |
| qf2_loss                | 0.001780666   |
| time_elapsed            | 746           |
| total timesteps         | 147100        |
| value_loss              | 0.00032114278 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019917665  |
| ent_coef_loss           | -3.4195886    |
| entropy                 | 3.4196057     |
| ep_rewmean              | -0.944        |
| episodes                | 1476          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 147401        |
| policy_loss             | 0.39825964    |
| qf1_loss                | 0.0016578385  |
| qf2_loss                | 0.0016103457  |
| time_elapsed            | 748           |
| total timesteps         | 147500        |
| value_loss              | 0.00093550823 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020020036  |
| ent_coef_loss           | -6.632574     |
| entropy                 | 3.596826      |
| ep_rewmean              | -0.92         |
| episodes                | 1480          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 147801        |
| policy_loss             | 0.42119735    |
| qf1_loss                | 0.00016061612 |
| qf2_loss                | 0.00012531242 |
| time_elapsed            | 750           |
| total timesteps         | 147900        |
| value_loss              | 0.00021064519 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019512799  |
| ent_coef_loss           | 2.5965648     |
| entropy                 | 3.35959       |
| ep_rewmean              | -0.918        |
| episodes                | 1484          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 148201        |
| policy_loss             | 0.3991658     |
| qf1_loss                | 0.0028066917  |
| qf2_loss                | 0.0027180074  |
| time_elapsed            | 752           |
| total timesteps         | 148300        |
| value_loss              | 0.00035674972 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019977915  |
| ent_coef_loss           | -3.5944831    |
| entropy                 | 3.4855766     |
| ep_rewmean              | -0.919        |
| episodes                | 1488          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 148601        |
| policy_loss             | 0.41891223    |
| qf1_loss                | 0.00016118478 |
| qf2_loss                | 0.00018489742 |
| time_elapsed            | 754           |
| total timesteps         | 148700        |
| value_loss              | 0.00036029075 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018413356  |
| ent_coef_loss           | -1.6419854    |
| entropy                 | 3.41205       |
| ep_rewmean              | -0.928        |
| episodes                | 1492          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 149001        |
| policy_loss             | 0.39788324    |
| qf1_loss                | 0.0001989092  |
| qf2_loss                | 0.00022123683 |
| time_elapsed            | 756           |
| total timesteps         | 149100        |
| value_loss              | 0.00020338452 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017106179  |
| ent_coef_loss           | -4.8774796    |
| entropy                 | 3.441442      |
| ep_rewmean              | -0.929        |
| episodes                | 1496          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 149401        |
| policy_loss             | 0.42623082    |
| qf1_loss                | 0.0001308626  |
| qf2_loss                | 0.00011155719 |
| time_elapsed            | 758           |
| total timesteps         | 149500        |
| value_loss              | 0.00015469792 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017197673  |
| ent_coef_loss           | 4.3944206     |
| entropy                 | 3.389567      |
| ep_rewmean              | -0.92         |
| episodes                | 1500          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 149801        |
| policy_loss             | 0.41421902    |
| qf1_loss                | 0.008221768   |
| qf2_loss                | 0.007799321   |
| time_elapsed            | 760           |
| total timesteps         | 149900        |
| value_loss              | 0.00046437094 |
-------------------------------------------
Eval num_timesteps=150000, episode_reward=-0.54 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017344371  |
| ent_coef_loss           | -5.623061     |
| entropy                 | 3.0326736     |
| ep_rewmean              | -0.92         |
| episodes                | 1504          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 150201        |
| policy_loss             | 0.41771322    |
| qf1_loss                | 0.00019303542 |
| qf2_loss                | 0.00024587678 |
| time_elapsed            | 763           |
| total timesteps         | 150300        |
| value_loss              | 0.00025465517 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001739866  |
| ent_coef_loss           | 9.00057      |
| entropy                 | 3.0249767    |
| ep_rewmean              | -0.92        |
| episodes                | 1508         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -0.9         |
| n_updates               | 150601       |
| policy_loss             | 0.39261606   |
| qf1_loss                | 0.0015234165 |
| qf2_loss                | 0.0014955653 |
| time_elapsed            | 765          |
| total timesteps         | 150700       |
| value_loss              | 0.0002119042 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0017729928   |
| ent_coef_loss           | -1.2532363     |
| entropy                 | 3.4173334      |
| ep_rewmean              | -0.925         |
| episodes                | 1512           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.9           |
| n_updates               | 151001         |
| policy_loss             | 0.41857642     |
| qf1_loss                | 0.000106545376 |
| qf2_loss                | 0.0001324788   |
| time_elapsed            | 767            |
| total timesteps         | 151100         |
| value_loss              | 0.00023852871  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017319974  |
| ent_coef_loss           | 1.550211      |
| entropy                 | 3.1232202     |
| ep_rewmean              | -0.914        |
| episodes                | 1516          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 151401        |
| policy_loss             | 0.389807      |
| qf1_loss                | 0.00047696693 |
| qf2_loss                | 0.00048088556 |
| time_elapsed            | 769           |
| total timesteps         | 151500        |
| value_loss              | 0.00033725498 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016257697  |
| ent_coef_loss           | 4.1483674     |
| entropy                 | 2.692029      |
| ep_rewmean              | -0.889        |
| episodes                | 1520          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 151801        |
| policy_loss             | 0.39135373    |
| qf1_loss                | 0.00085995934 |
| qf2_loss                | 0.0007391005  |
| time_elapsed            | 771           |
| total timesteps         | 151900        |
| value_loss              | 0.00023174862 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016031439  |
| ent_coef_loss           | -3.200769     |
| entropy                 | 2.552651      |
| ep_rewmean              | -0.867        |
| episodes                | 1524          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 152201        |
| policy_loss             | 0.3570322     |
| qf1_loss                | 0.00022837277 |
| qf2_loss                | 0.00022841987 |
| time_elapsed            | 773           |
| total timesteps         | 152300        |
| value_loss              | 0.0002397128  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015151124  |
| ent_coef_loss           | -2.4064226    |
| entropy                 | 2.686581      |
| ep_rewmean              | -0.859        |
| episodes                | 1528          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 152601        |
| policy_loss             | 0.37209773    |
| qf1_loss                | 0.00022515711 |
| qf2_loss                | 0.00010551898 |
| time_elapsed            | 775           |
| total timesteps         | 152700        |
| value_loss              | 0.00018455189 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015977126  |
| ent_coef_loss           | -6.5218573    |
| entropy                 | 2.5937996     |
| ep_rewmean              | -0.862        |
| episodes                | 1532          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 153001        |
| policy_loss             | 0.4174875     |
| qf1_loss                | 0.0020703122  |
| qf2_loss                | 0.0020064493  |
| time_elapsed            | 777           |
| total timesteps         | 153100        |
| value_loss              | 0.00017153798 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014858386 |
| ent_coef_loss           | -3.9008245   |
| entropy                 | 1.954676     |
| ep_rewmean              | -0.848       |
| episodes                | 1536         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -0.8         |
| n_updates               | 153401       |
| policy_loss             | 0.4431966    |
| qf1_loss                | 0.007202773  |
| qf2_loss                | 0.007091434  |
| time_elapsed            | 779          |
| total timesteps         | 153500       |
| value_loss              | 0.000137497  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001332901  |
| ent_coef_loss           | -1.0016552   |
| entropy                 | 2.3369303    |
| ep_rewmean              | -0.848       |
| episodes                | 1540         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.8         |
| n_updates               | 153801       |
| policy_loss             | 0.45834014   |
| qf1_loss                | 0.0005198816 |
| qf2_loss                | 0.0005379444 |
| time_elapsed            | 781          |
| total timesteps         | 153900       |
| value_loss              | 0.0002186246 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013263244  |
| ent_coef_loss           | -2.2273855    |
| entropy                 | 1.5869159     |
| ep_rewmean              | -0.805        |
| episodes                | 1544          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 154201        |
| policy_loss             | 0.43473452    |
| qf1_loss                | 0.00017707824 |
| qf2_loss                | 0.00012699963 |
| time_elapsed            | 783           |
| total timesteps         | 154300        |
| value_loss              | 0.00011643322 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001366196   |
| ent_coef_loss           | 8.8186455     |
| entropy                 | 2.1297748     |
| ep_rewmean              | -0.792        |
| episodes                | 1548          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 154601        |
| policy_loss             | 0.4344113     |
| qf1_loss                | 0.0015053549  |
| qf2_loss                | 0.0017424559  |
| time_elapsed            | 785           |
| total timesteps         | 154700        |
| value_loss              | 0.00023594755 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014173394 |
| ent_coef_loss           | -2.3400226   |
| entropy                 | 2.0135062    |
| ep_rewmean              | -0.763       |
| episodes                | 1552         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.8         |
| n_updates               | 155001       |
| policy_loss             | 0.43447632   |
| qf1_loss                | 7.419803e-05 |
| qf2_loss                | 8.395866e-05 |
| time_elapsed            | 787          |
| total timesteps         | 155100       |
| value_loss              | 0.0001740341 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014502465  |
| ent_coef_loss           | 6.7329535     |
| entropy                 | 2.5722098     |
| ep_rewmean              | -0.748        |
| episodes                | 1556          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 155401        |
| policy_loss             | 0.42704704    |
| qf1_loss                | 0.0024297482  |
| qf2_loss                | 0.0025066787  |
| time_elapsed            | 789           |
| total timesteps         | 155500        |
| value_loss              | 0.00025708557 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014343188  |
| ent_coef_loss           | 12.073347     |
| entropy                 | 2.4944324     |
| ep_rewmean              | -0.739        |
| episodes                | 1560          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 155801        |
| policy_loss             | 0.41814375    |
| qf1_loss                | 9.649453e-05  |
| qf2_loss                | 9.107226e-05  |
| time_elapsed            | 791           |
| total timesteps         | 155900        |
| value_loss              | 0.00015078718 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015538315  |
| ent_coef_loss           | -2.5751758    |
| entropy                 | 3.2691789     |
| ep_rewmean              | -0.747        |
| episodes                | 1564          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 156201        |
| policy_loss             | 0.46540487    |
| qf1_loss                | 0.0033080801  |
| qf2_loss                | 0.003387933   |
| time_elapsed            | 793           |
| total timesteps         | 156300        |
| value_loss              | 0.00021219958 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001563325   |
| ent_coef_loss           | 5.1185575     |
| entropy                 | 3.2886667     |
| ep_rewmean              | -0.76         |
| episodes                | 1568          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 156601        |
| policy_loss             | 0.4595452     |
| qf1_loss                | 9.874231e-05  |
| qf2_loss                | 7.8831785e-05 |
| time_elapsed            | 795           |
| total timesteps         | 156700        |
| value_loss              | 0.00016169675 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016386068  |
| ent_coef_loss           | -0.08602095   |
| entropy                 | 3.25704       |
| ep_rewmean              | -0.769        |
| episodes                | 1572          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 157001        |
| policy_loss             | 0.49215811    |
| qf1_loss                | 0.00015067635 |
| qf2_loss                | 0.00017407464 |
| time_elapsed            | 797           |
| total timesteps         | 157100        |
| value_loss              | 0.0001907033  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016732184  |
| ent_coef_loss           | 0.34134722    |
| entropy                 | 3.809957      |
| ep_rewmean              | -0.771        |
| episodes                | 1576          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 157401        |
| policy_loss             | 0.44709378    |
| qf1_loss                | 0.00012556108 |
| qf2_loss                | 0.00011733303 |
| time_elapsed            | 799           |
| total timesteps         | 157500        |
| value_loss              | 0.00013432882 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016498056  |
| ent_coef_loss           | -1.9443097    |
| entropy                 | 3.4134722     |
| ep_rewmean              | -0.776        |
| episodes                | 1580          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 157801        |
| policy_loss             | 0.50080353    |
| qf1_loss                | 0.004563538   |
| qf2_loss                | 0.00436993    |
| time_elapsed            | 801           |
| total timesteps         | 157900        |
| value_loss              | 0.00013376013 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016342269  |
| ent_coef_loss           | 4.0069346     |
| entropy                 | 3.0518656     |
| ep_rewmean              | -0.778        |
| episodes                | 1584          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 158201        |
| policy_loss             | 0.45874757    |
| qf1_loss                | 0.00037225426 |
| qf2_loss                | 0.00037089514 |
| time_elapsed            | 803           |
| total timesteps         | 158300        |
| value_loss              | 0.00013224487 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016274676  |
| ent_coef_loss           | -7.17649      |
| entropy                 | 3.4109023     |
| ep_rewmean              | -0.778        |
| episodes                | 1588          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 158601        |
| policy_loss             | 0.4677877     |
| qf1_loss                | 0.0005754579  |
| qf2_loss                | 0.0006173559  |
| time_elapsed            | 805           |
| total timesteps         | 158700        |
| value_loss              | 0.00022856556 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015010324  |
| ent_coef_loss           | -0.90568805   |
| entropy                 | 3.5366797     |
| ep_rewmean              | -0.77         |
| episodes                | 1592          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 159001        |
| policy_loss             | 0.48885864    |
| qf1_loss                | 0.0023462363  |
| qf2_loss                | 0.00236074    |
| time_elapsed            | 807           |
| total timesteps         | 159100        |
| value_loss              | 0.00017869404 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013745752  |
| ent_coef_loss           | 0.16508532    |
| entropy                 | 3.1257985     |
| ep_rewmean              | -0.771        |
| episodes                | 1596          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 159401        |
| policy_loss             | 0.5094693     |
| qf1_loss                | 0.005333476   |
| qf2_loss                | 0.005270914   |
| time_elapsed            | 809           |
| total timesteps         | 159500        |
| value_loss              | 0.00033427405 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013210162  |
| ent_coef_loss           | -4.5006075    |
| entropy                 | 3.0298438     |
| ep_rewmean              | -0.774        |
| episodes                | 1600          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 159801        |
| policy_loss             | 0.49449134    |
| qf1_loss                | 0.0002578277  |
| qf2_loss                | 0.0002794234  |
| time_elapsed            | 811           |
| total timesteps         | 159900        |
| value_loss              | 0.00017992724 |
-------------------------------------------
Eval num_timesteps=160000, episode_reward=-0.69 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012572539 |
| ent_coef_loss           | -0.27023458  |
| entropy                 | 2.7929802    |
| ep_rewmean              | -0.774       |
| episodes                | 1604         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.8         |
| n_updates               | 160201       |
| policy_loss             | 0.50248206   |
| qf1_loss                | 0.0012422531 |
| qf2_loss                | 0.001157075  |
| time_elapsed            | 813          |
| total timesteps         | 160300       |
| value_loss              | 9.971972e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012406113  |
| ent_coef_loss           | -0.48713934   |
| entropy                 | 2.4142737     |
| ep_rewmean              | -0.784        |
| episodes                | 1608          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 160601        |
| policy_loss             | 0.48069793    |
| qf1_loss                | 9.277742e-05  |
| qf2_loss                | 8.005185e-05  |
| time_elapsed            | 815           |
| total timesteps         | 160700        |
| value_loss              | 0.00017371491 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012242321  |
| ent_coef_loss           | -9.97786      |
| entropy                 | 2.6415362     |
| ep_rewmean              | -0.76         |
| episodes                | 1612          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 161001        |
| policy_loss             | 0.5033466     |
| qf1_loss                | 7.353727e-05  |
| qf2_loss                | 5.323559e-05  |
| time_elapsed            | 817           |
| total timesteps         | 161100        |
| value_loss              | 0.00013884765 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012076228  |
| ent_coef_loss           | -0.23668247   |
| entropy                 | 2.5973659     |
| ep_rewmean              | -0.746        |
| episodes                | 1616          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 161401        |
| policy_loss             | 0.46829605    |
| qf1_loss                | 7.483546e-05  |
| qf2_loss                | 0.00011647405 |
| time_elapsed            | 819           |
| total timesteps         | 161500        |
| value_loss              | 0.00015671342 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011563256  |
| ent_coef_loss           | 7.9502406     |
| entropy                 | 3.0057201     |
| ep_rewmean              | -0.737        |
| episodes                | 1620          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 161801        |
| policy_loss             | 0.5046076     |
| qf1_loss                | 0.012220643   |
| qf2_loss                | 0.011946613   |
| time_elapsed            | 821           |
| total timesteps         | 161900        |
| value_loss              | 0.00017050507 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011878345  |
| ent_coef_loss           | -0.88650316   |
| entropy                 | 2.5694954     |
| ep_rewmean              | -0.717        |
| episodes                | 1624          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 162201        |
| policy_loss             | 0.5100613     |
| qf1_loss                | 0.00015171879 |
| qf2_loss                | 0.00012339864 |
| time_elapsed            | 823           |
| total timesteps         | 162300        |
| value_loss              | 8.565431e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012327224  |
| ent_coef_loss           | 10.066082     |
| entropy                 | 2.9772828     |
| ep_rewmean              | -0.692        |
| episodes                | 1628          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 162601        |
| policy_loss             | 0.50500906    |
| qf1_loss                | 9.815856e-05  |
| qf2_loss                | 0.00012774479 |
| time_elapsed            | 825           |
| total timesteps         | 162700        |
| value_loss              | 0.00011128365 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013290042  |
| ent_coef_loss           | 8.6474        |
| entropy                 | 2.8002748     |
| ep_rewmean              | -0.651        |
| episodes                | 1632          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 163001        |
| policy_loss             | 0.43899006    |
| qf1_loss                | 0.0016479003  |
| qf2_loss                | 0.0021440634  |
| time_elapsed            | 827           |
| total timesteps         | 163100        |
| value_loss              | 0.00019270123 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013539408  |
| ent_coef_loss           | 0.41891778    |
| entropy                 | 3.319531      |
| ep_rewmean              | -0.635        |
| episodes                | 1636          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 163401        |
| policy_loss             | 0.46330005    |
| qf1_loss                | 0.0006114221  |
| qf2_loss                | 0.00070377457 |
| time_elapsed            | 829           |
| total timesteps         | 163500        |
| value_loss              | 0.00012844864 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013135484  |
| ent_coef_loss           | 0.78978086    |
| entropy                 | 2.8336034     |
| ep_rewmean              | -0.621        |
| episodes                | 1640          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 163801        |
| policy_loss             | 0.4525682     |
| qf1_loss                | 0.0013692146  |
| qf2_loss                | 0.0013294314  |
| time_elapsed            | 831           |
| total timesteps         | 163900        |
| value_loss              | 0.00011857034 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012649824  |
| ent_coef_loss           | -5.885879     |
| entropy                 | 2.7948437     |
| ep_rewmean              | -0.6          |
| episodes                | 1644          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 164201        |
| policy_loss             | 0.46717155    |
| qf1_loss                | 9.828262e-05  |
| qf2_loss                | 0.00010181908 |
| time_elapsed            | 833           |
| total timesteps         | 164300        |
| value_loss              | 0.00012108041 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0013109035   |
| ent_coef_loss           | -1.0186706     |
| entropy                 | 2.6969209      |
| ep_rewmean              | -0.587         |
| episodes                | 1648           |
| eplenmean               | 100            |
| fps                     | 197            |
| mean 100 episode reward | -0.6           |
| n_updates               | 164601         |
| policy_loss             | 0.44152635     |
| qf1_loss                | 5.8731574e-05  |
| qf2_loss                | 5.4360837e-05  |
| time_elapsed            | 835            |
| total timesteps         | 164700         |
| value_loss              | 0.000115059476 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014171043  |
| ent_coef_loss           | -3.7923136    |
| entropy                 | 3.1596847     |
| ep_rewmean              | -0.588        |
| episodes                | 1652          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 165001        |
| policy_loss             | 0.47601452    |
| qf1_loss                | 0.0026486157  |
| qf2_loss                | 0.0028176857  |
| time_elapsed            | 837           |
| total timesteps         | 165100        |
| value_loss              | 0.00016642643 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001447305   |
| ent_coef_loss           | 1.8575298     |
| entropy                 | 3.2127316     |
| ep_rewmean              | -0.586        |
| episodes                | 1656          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 165401        |
| policy_loss             | 0.49975932    |
| qf1_loss                | 9.057401e-05  |
| qf2_loss                | 0.0001381289  |
| time_elapsed            | 839           |
| total timesteps         | 165500        |
| value_loss              | 0.00013989379 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014523192  |
| ent_coef_loss           | -0.5331606    |
| entropy                 | 2.7399025     |
| ep_rewmean              | -0.575        |
| episodes                | 1660          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 165801        |
| policy_loss             | 0.533636      |
| qf1_loss                | 0.0019435608  |
| qf2_loss                | 0.0019594936  |
| time_elapsed            | 841           |
| total timesteps         | 165900        |
| value_loss              | 0.00016530725 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014512392  |
| ent_coef_loss           | 6.988858      |
| entropy                 | 2.5544353     |
| ep_rewmean              | -0.558        |
| episodes                | 1664          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 166201        |
| policy_loss             | 0.5161084     |
| qf1_loss                | 0.007577709   |
| qf2_loss                | 0.007410011   |
| time_elapsed            | 843           |
| total timesteps         | 166300        |
| value_loss              | 0.00023810938 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018094471  |
| ent_coef_loss           | 13.394126     |
| entropy                 | 3.1667275     |
| ep_rewmean              | -0.567        |
| episodes                | 1668          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 166601        |
| policy_loss             | 0.48792952    |
| qf1_loss                | 0.00013695395 |
| qf2_loss                | 0.00013483879 |
| time_elapsed            | 845           |
| total timesteps         | 166700        |
| value_loss              | 0.00030860485 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018194678  |
| ent_coef_loss           | -8.279959     |
| entropy                 | 3.493455      |
| ep_rewmean              | -0.56         |
| episodes                | 1672          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 167001        |
| policy_loss             | 0.49737632    |
| qf1_loss                | 0.00582744    |
| qf2_loss                | 0.0056764404  |
| time_elapsed            | 847           |
| total timesteps         | 167100        |
| value_loss              | 0.00021656054 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017446197  |
| ent_coef_loss           | -2.736683     |
| entropy                 | 2.8340855     |
| ep_rewmean              | -0.556        |
| episodes                | 1676          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 167401        |
| policy_loss             | 0.49033326    |
| qf1_loss                | 0.00015582706 |
| qf2_loss                | 0.00016419071 |
| time_elapsed            | 849           |
| total timesteps         | 167500        |
| value_loss              | 0.00035976575 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015367031  |
| ent_coef_loss           | -8.59794      |
| entropy                 | 3.381441      |
| ep_rewmean              | -0.556        |
| episodes                | 1680          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 167801        |
| policy_loss             | 0.5397887     |
| qf1_loss                | 0.0002718687  |
| qf2_loss                | 0.0001983439  |
| time_elapsed            | 851           |
| total timesteps         | 167900        |
| value_loss              | 0.00015452105 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014583302  |
| ent_coef_loss           | 0.49633288    |
| entropy                 | 3.1108022     |
| ep_rewmean              | -0.565        |
| episodes                | 1684          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 168201        |
| policy_loss             | 0.49977583    |
| qf1_loss                | 0.00086099125 |
| qf2_loss                | 0.00077471894 |
| time_elapsed            | 853           |
| total timesteps         | 168300        |
| value_loss              | 0.00015019585 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014802039  |
| ent_coef_loss           | -5.4176955    |
| entropy                 | 2.7571259     |
| ep_rewmean              | -0.581        |
| episodes                | 1688          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 168601        |
| policy_loss             | 0.47553015    |
| qf1_loss                | 6.8951624e-05 |
| qf2_loss                | 7.8878176e-05 |
| time_elapsed            | 855           |
| total timesteps         | 168700        |
| value_loss              | 0.00027037924 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014615903  |
| ent_coef_loss           | 7.315803      |
| entropy                 | 2.6428494     |
| ep_rewmean              | -0.593        |
| episodes                | 1692          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 169001        |
| policy_loss             | 0.51354575    |
| qf1_loss                | 0.00013012881 |
| qf2_loss                | 0.00010560686 |
| time_elapsed            | 857           |
| total timesteps         | 169100        |
| value_loss              | 0.00013910605 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014382101 |
| ent_coef_loss           | -6.2791405   |
| entropy                 | 2.620205     |
| ep_rewmean              | -0.599       |
| episodes                | 1696         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.6         |
| n_updates               | 169401       |
| policy_loss             | 0.48192757   |
| qf1_loss                | 0.0048170774 |
| qf2_loss                | 0.0052321916 |
| time_elapsed            | 859          |
| total timesteps         | 169500       |
| value_loss              | 0.0001677064 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015222061  |
| ent_coef_loss           | 8.430974      |
| entropy                 | 3.0082521     |
| ep_rewmean              | -0.61         |
| episodes                | 1700          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 169801        |
| policy_loss             | 0.5186913     |
| qf1_loss                | 0.001714188   |
| qf2_loss                | 0.001615394   |
| time_elapsed            | 861           |
| total timesteps         | 169900        |
| value_loss              | 0.00036971588 |
-------------------------------------------
Eval num_timesteps=170000, episode_reward=-0.85 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015577938  |
| ent_coef_loss           | -3.371471     |
| entropy                 | 2.8760664     |
| ep_rewmean              | -0.617        |
| episodes                | 1704          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 170201        |
| policy_loss             | 0.4822827     |
| qf1_loss                | 0.00305237    |
| qf2_loss                | 0.00272155    |
| time_elapsed            | 863           |
| total timesteps         | 170300        |
| value_loss              | 0.00017941475 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014974715  |
| ent_coef_loss           | -7.164131     |
| entropy                 | 2.832274      |
| ep_rewmean              | -0.608        |
| episodes                | 1708          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 170601        |
| policy_loss             | 0.5147928     |
| qf1_loss                | 0.001340396   |
| qf2_loss                | 0.00084011303 |
| time_elapsed            | 865           |
| total timesteps         | 170700        |
| value_loss              | 0.00015719997 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014488276  |
| ent_coef_loss           | 2.743843      |
| entropy                 | 2.5242472     |
| ep_rewmean              | -0.605        |
| episodes                | 1712          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 171001        |
| policy_loss             | 0.49303272    |
| qf1_loss                | 0.0001622811  |
| qf2_loss                | 8.662601e-05  |
| time_elapsed            | 867           |
| total timesteps         | 171100        |
| value_loss              | 0.00011498835 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014904573  |
| ent_coef_loss           | 7.071184      |
| entropy                 | 2.80374       |
| ep_rewmean              | -0.603        |
| episodes                | 1716          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 171401        |
| policy_loss             | 0.53437054    |
| qf1_loss                | 0.00020076628 |
| qf2_loss                | 0.00013410795 |
| time_elapsed            | 869           |
| total timesteps         | 171500        |
| value_loss              | 0.00027034996 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015731981  |
| ent_coef_loss           | 4.2537065     |
| entropy                 | 2.9206493     |
| ep_rewmean              | -0.604        |
| episodes                | 1720          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 171801        |
| policy_loss             | 0.4719792     |
| qf1_loss                | 0.00023129898 |
| qf2_loss                | 0.0002641609  |
| time_elapsed            | 871           |
| total timesteps         | 171900        |
| value_loss              | 0.00019326038 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016107382 |
| ent_coef_loss           | 1.3066034    |
| entropy                 | 3.0726151    |
| ep_rewmean              | -0.61        |
| episodes                | 1724         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.6         |
| n_updates               | 172201       |
| policy_loss             | 0.5041268    |
| qf1_loss                | 0.013428945  |
| qf2_loss                | 0.014459117  |
| time_elapsed            | 873          |
| total timesteps         | 172300       |
| value_loss              | 0.0001914121 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016169584  |
| ent_coef_loss           | 6.7586594     |
| entropy                 | 2.7473435     |
| ep_rewmean              | -0.613        |
| episodes                | 1728          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 172601        |
| policy_loss             | 0.5500866     |
| qf1_loss                | 0.00012212092 |
| qf2_loss                | 8.593017e-05  |
| time_elapsed            | 875           |
| total timesteps         | 172700        |
| value_loss              | 0.00021090773 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016143214  |
| ent_coef_loss           | 3.9993978     |
| entropy                 | 2.6293597     |
| ep_rewmean              | -0.637        |
| episodes                | 1732          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 173001        |
| policy_loss             | 0.5026256     |
| qf1_loss                | 0.000259349   |
| qf2_loss                | 0.00026310753 |
| time_elapsed            | 877           |
| total timesteps         | 173100        |
| value_loss              | 0.00021350128 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015714581  |
| ent_coef_loss           | -0.7966199    |
| entropy                 | 2.4886014     |
| ep_rewmean              | -0.69         |
| episodes                | 1736          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 173401        |
| policy_loss             | 0.4954687     |
| qf1_loss                | 7.211256e-05  |
| qf2_loss                | 7.612217e-05  |
| time_elapsed            | 879           |
| total timesteps         | 173500        |
| value_loss              | 0.00015692094 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014595928  |
| ent_coef_loss           | -18.3503      |
| entropy                 | 2.4898908     |
| ep_rewmean              | -0.724        |
| episodes                | 1740          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 173801        |
| policy_loss             | 0.46155837    |
| qf1_loss                | 0.0001342425  |
| qf2_loss                | 0.00016579728 |
| time_elapsed            | 881           |
| total timesteps         | 173900        |
| value_loss              | 0.00031232883 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014222681  |
| ent_coef_loss           | 4.177638      |
| entropy                 | 2.5762749     |
| ep_rewmean              | -0.752        |
| episodes                | 1744          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 174201        |
| policy_loss             | 0.5419121     |
| qf1_loss                | 8.050715e-05  |
| qf2_loss                | 0.00010651542 |
| time_elapsed            | 883           |
| total timesteps         | 174300        |
| value_loss              | 0.00014530864 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014731183  |
| ent_coef_loss           | 3.530158      |
| entropy                 | 2.7114882     |
| ep_rewmean              | -0.796        |
| episodes                | 1748          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 174601        |
| policy_loss             | 0.49538392    |
| qf1_loss                | 0.00012100447 |
| qf2_loss                | 9.696699e-05  |
| time_elapsed            | 885           |
| total timesteps         | 174700        |
| value_loss              | 0.00016945074 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001461338   |
| ent_coef_loss           | -4.946364     |
| entropy                 | 2.623342      |
| ep_rewmean              | -0.804        |
| episodes                | 1752          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 175001        |
| policy_loss             | 0.5355982     |
| qf1_loss                | 0.0013083969  |
| qf2_loss                | 0.0011827893  |
| time_elapsed            | 887           |
| total timesteps         | 175100        |
| value_loss              | 0.00023108268 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001387588   |
| ent_coef_loss           | -9.394948     |
| entropy                 | 2.7119586     |
| ep_rewmean              | -0.815        |
| episodes                | 1756          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 175401        |
| policy_loss             | 0.505368      |
| qf1_loss                | 0.00015101669 |
| qf2_loss                | 0.00022765403 |
| time_elapsed            | 889           |
| total timesteps         | 175500        |
| value_loss              | 0.00031410003 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013333847  |
| ent_coef_loss           | -0.4670006    |
| entropy                 | 2.9352822     |
| ep_rewmean              | -0.829        |
| episodes                | 1760          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 175801        |
| policy_loss             | 0.5099422     |
| qf1_loss                | 0.0021577072  |
| qf2_loss                | 0.0021253363  |
| time_elapsed            | 891           |
| total timesteps         | 175900        |
| value_loss              | 0.00013113502 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0012964864   |
| ent_coef_loss           | 4.238779       |
| entropy                 | 2.7500057      |
| ep_rewmean              | -0.833         |
| episodes                | 1764           |
| eplenmean               | 100            |
| fps                     | 197            |
| mean 100 episode reward | -0.8           |
| n_updates               | 176201         |
| policy_loss             | 0.46760327     |
| qf1_loss                | 0.000118487485 |
| qf2_loss                | 0.00010456645  |
| time_elapsed            | 893            |
| total timesteps         | 176300         |
| value_loss              | 0.00015271478  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012563759  |
| ent_coef_loss           | -3.4021783    |
| entropy                 | 2.6339116     |
| ep_rewmean              | -0.817        |
| episodes                | 1768          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 176601        |
| policy_loss             | 0.45976716    |
| qf1_loss                | 0.00033081125 |
| qf2_loss                | 0.00029057945 |
| time_elapsed            | 895           |
| total timesteps         | 176700        |
| value_loss              | 0.0002575913  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012310436  |
| ent_coef_loss           | 1.4988544     |
| entropy                 | 2.4759226     |
| ep_rewmean              | -0.819        |
| episodes                | 1772          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 177001        |
| policy_loss             | 0.48311564    |
| qf1_loss                | 0.0012519297  |
| qf2_loss                | 0.0012517277  |
| time_elapsed            | 897           |
| total timesteps         | 177100        |
| value_loss              | 8.4233354e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012836923  |
| ent_coef_loss           | 3.4261358     |
| entropy                 | 2.4124498     |
| ep_rewmean              | -0.824        |
| episodes                | 1776          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 177401        |
| policy_loss             | 0.4411325     |
| qf1_loss                | 0.0031281284  |
| qf2_loss                | 0.0033152304  |
| time_elapsed            | 899           |
| total timesteps         | 177500        |
| value_loss              | 0.00015623057 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013210741  |
| ent_coef_loss           | 9.247503      |
| entropy                 | 2.5422716     |
| ep_rewmean              | -0.816        |
| episodes                | 1780          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 177801        |
| policy_loss             | 0.4881644     |
| qf1_loss                | 0.00012479624 |
| qf2_loss                | 0.0001440976  |
| time_elapsed            | 901           |
| total timesteps         | 177900        |
| value_loss              | 0.00014697167 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013518848  |
| ent_coef_loss           | -3.0202293    |
| entropy                 | 2.4694598     |
| ep_rewmean              | -0.801        |
| episodes                | 1784          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 178201        |
| policy_loss             | 0.4504823     |
| qf1_loss                | 0.0010459597  |
| qf2_loss                | 0.0010767614  |
| time_elapsed            | 903           |
| total timesteps         | 178300        |
| value_loss              | 0.00013157711 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013066093  |
| ent_coef_loss           | -7.556579     |
| entropy                 | 2.9028635     |
| ep_rewmean              | -0.778        |
| episodes                | 1788          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 178601        |
| policy_loss             | 0.44857       |
| qf1_loss                | 8.415244e-05  |
| qf2_loss                | 8.6212356e-05 |
| time_elapsed            | 905           |
| total timesteps         | 178700        |
| value_loss              | 0.00016118784 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001320785   |
| ent_coef_loss           | -2.9993365    |
| entropy                 | 2.6362903     |
| ep_rewmean              | -0.759        |
| episodes                | 1792          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 179001        |
| policy_loss             | 0.4473977     |
| qf1_loss                | 0.00017794823 |
| qf2_loss                | 0.00010101309 |
| time_elapsed            | 907           |
| total timesteps         | 179100        |
| value_loss              | 0.00018966605 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013846811  |
| ent_coef_loss           | 5.493274      |
| entropy                 | 2.920896      |
| ep_rewmean              | -0.748        |
| episodes                | 1796          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 179401        |
| policy_loss             | 0.4750855     |
| qf1_loss                | 0.00022480809 |
| qf2_loss                | 0.00026087303 |
| time_elapsed            | 909           |
| total timesteps         | 179500        |
| value_loss              | 0.00013857202 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015286048  |
| ent_coef_loss           | 3.046256      |
| entropy                 | 2.2780724     |
| ep_rewmean              | -0.745        |
| episodes                | 1800          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 179801        |
| policy_loss             | 0.43445638    |
| qf1_loss                | 8.8955014e-05 |
| qf2_loss                | 9.1020396e-05 |
| time_elapsed            | 911           |
| total timesteps         | 179900        |
| value_loss              | 0.00025946196 |
-------------------------------------------
Eval num_timesteps=180000, episode_reward=-0.98 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001693507   |
| ent_coef_loss           | 0.59581065    |
| entropy                 | 2.6594899     |
| ep_rewmean              | -0.745        |
| episodes                | 1804          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 180201        |
| policy_loss             | 0.47708258    |
| qf1_loss                | 0.00011786772 |
| qf2_loss                | 9.658341e-05  |
| time_elapsed            | 914           |
| total timesteps         | 180300        |
| value_loss              | 0.00018051412 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018234213  |
| ent_coef_loss           | -1.5421313    |
| entropy                 | 2.7381449     |
| ep_rewmean              | -0.764        |
| episodes                | 1808          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 180601        |
| policy_loss             | 0.49244475    |
| qf1_loss                | 0.00014650008 |
| qf2_loss                | 0.0002076962  |
| time_elapsed            | 916           |
| total timesteps         | 180700        |
| value_loss              | 0.00018222613 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018212403  |
| ent_coef_loss           | -3.4645178    |
| entropy                 | 2.8281314     |
| ep_rewmean              | -0.784        |
| episodes                | 1812          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 181001        |
| policy_loss             | 0.4825316     |
| qf1_loss                | 0.00020681611 |
| qf2_loss                | 0.00019796056 |
| time_elapsed            | 918           |
| total timesteps         | 181100        |
| value_loss              | 0.00016413686 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001793043   |
| ent_coef_loss           | -7.937263     |
| entropy                 | 3.0424728     |
| ep_rewmean              | -0.798        |
| episodes                | 1816          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 181401        |
| policy_loss             | 0.49847418    |
| qf1_loss                | 0.0013887164  |
| qf2_loss                | 0.0014126382  |
| time_elapsed            | 920           |
| total timesteps         | 181500        |
| value_loss              | 0.00011455339 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00171632    |
| ent_coef_loss           | 0.5922363     |
| entropy                 | 3.2791624     |
| ep_rewmean              | -0.812        |
| episodes                | 1820          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 181801        |
| policy_loss             | 0.5213231     |
| qf1_loss                | 9.1678194e-05 |
| qf2_loss                | 0.00011954605 |
| time_elapsed            | 922           |
| total timesteps         | 181900        |
| value_loss              | 0.0001818816  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015952956  |
| ent_coef_loss           | 0.011043072   |
| entropy                 | 3.3908355     |
| ep_rewmean              | -0.819        |
| episodes                | 1824          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 182201        |
| policy_loss             | 0.5004235     |
| qf1_loss                | 0.00015166154 |
| qf2_loss                | 0.00019449063 |
| time_elapsed            | 924           |
| total timesteps         | 182300        |
| value_loss              | 0.00022207596 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014584839 |
| ent_coef_loss           | -5.285641    |
| entropy                 | 3.445579     |
| ep_rewmean              | -0.827       |
| episodes                | 1828         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.8         |
| n_updates               | 182601       |
| policy_loss             | 0.5353626    |
| qf1_loss                | 0.002106749  |
| qf2_loss                | 0.0019746162 |
| time_elapsed            | 926          |
| total timesteps         | 182700       |
| value_loss              | 0.0001706351 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001245998   |
| ent_coef_loss           | -12.927837    |
| entropy                 | 2.9235728     |
| ep_rewmean              | -0.826        |
| episodes                | 1832          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 183001        |
| policy_loss             | 0.5038145     |
| qf1_loss                | 0.0015890301  |
| qf2_loss                | 0.0015031404  |
| time_elapsed            | 928           |
| total timesteps         | 183100        |
| value_loss              | 0.00012956101 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011358343  |
| ent_coef_loss           | -0.097215176  |
| entropy                 | 1.159816      |
| ep_rewmean              | -0.838        |
| episodes                | 1836          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 183401        |
| policy_loss             | 0.49655342    |
| qf1_loss                | 9.2514216e-05 |
| qf2_loss                | 8.3552026e-05 |
| time_elapsed            | 930           |
| total timesteps         | 183500        |
| value_loss              | 0.00016983924 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010639697  |
| ent_coef_loss           | -7.118025     |
| entropy                 | 2.5184832     |
| ep_rewmean              | -0.92         |
| episodes                | 1840          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 183801        |
| policy_loss             | 0.49607235    |
| qf1_loss                | 0.0020394474  |
| qf2_loss                | 0.0020809986  |
| time_elapsed            | 932           |
| total timesteps         | 183900        |
| value_loss              | 0.00018046774 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009778915  |
| ent_coef_loss           | -3.076644     |
| entropy                 | 2.5764647     |
| ep_rewmean              | -0.969        |
| episodes                | 1844          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 184201        |
| policy_loss             | 0.47922516    |
| qf1_loss                | 5.990847e-05  |
| qf2_loss                | 7.815797e-05  |
| time_elapsed            | 934           |
| total timesteps         | 184300        |
| value_loss              | 9.0149566e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0011107      |
| ent_coef_loss           | 10.278191      |
| entropy                 | 2.6401854      |
| ep_rewmean              | -0.994         |
| episodes                | 1848           |
| eplenmean               | 100            |
| fps                     | 197            |
| mean 100 episode reward | -1             |
| n_updates               | 184601         |
| policy_loss             | 0.46828407     |
| qf1_loss                | 0.0013553217   |
| qf2_loss                | 0.0013653598   |
| time_elapsed            | 936            |
| total timesteps         | 184700         |
| value_loss              | 0.000119364166 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012666803  |
| ent_coef_loss           | 10.883965     |
| entropy                 | 2.5792398     |
| ep_rewmean              | -1.04         |
| episodes                | 1852          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 185001        |
| policy_loss             | 0.47847492    |
| qf1_loss                | 7.781092e-05  |
| qf2_loss                | 8.169062e-05  |
| time_elapsed            | 938           |
| total timesteps         | 185100        |
| value_loss              | 0.00013769479 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0013208613   |
| ent_coef_loss           | 3.6397872      |
| entropy                 | 2.546155       |
| ep_rewmean              | -1.08          |
| episodes                | 1856           |
| eplenmean               | 100            |
| fps                     | 197            |
| mean 100 episode reward | -1.1           |
| n_updates               | 185401         |
| policy_loss             | 0.45892978     |
| qf1_loss                | 0.000103688624 |
| qf2_loss                | 0.00012458336  |
| time_elapsed            | 940            |
| total timesteps         | 185500         |
| value_loss              | 0.00010273915  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013792578  |
| ent_coef_loss           | -2.0230803    |
| entropy                 | 1.9308898     |
| ep_rewmean              | -1.14         |
| episodes                | 1860          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.1          |
| n_updates               | 185801        |
| policy_loss             | 0.48720324    |
| qf1_loss                | 0.00018158171 |
| qf2_loss                | 0.00017824551 |
| time_elapsed            | 942           |
| total timesteps         | 185900        |
| value_loss              | 0.00024992286 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014109833  |
| ent_coef_loss           | 0.8673292     |
| entropy                 | 1.6347145     |
| ep_rewmean              | -1.17         |
| episodes                | 1864          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 186201        |
| policy_loss             | 0.42880616    |
| qf1_loss                | 0.001470231   |
| qf2_loss                | 0.0014535647  |
| time_elapsed            | 944           |
| total timesteps         | 186300        |
| value_loss              | 0.00015703129 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013785161  |
| ent_coef_loss           | 4.6753626     |
| entropy                 | 1.8992386     |
| ep_rewmean              | -1.19         |
| episodes                | 1868          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 186601        |
| policy_loss             | 0.475931      |
| qf1_loss                | 0.00479553    |
| qf2_loss                | 0.004721003   |
| time_elapsed            | 946           |
| total timesteps         | 186700        |
| value_loss              | 0.00035786274 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013306745  |
| ent_coef_loss           | 1.8189224     |
| entropy                 | 1.8245023     |
| ep_rewmean              | -1.22         |
| episodes                | 1872          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 187001        |
| policy_loss             | 0.48146957    |
| qf1_loss                | 0.0005938906  |
| qf2_loss                | 0.00051009876 |
| time_elapsed            | 948           |
| total timesteps         | 187100        |
| value_loss              | 0.00013414276 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012805774  |
| ent_coef_loss           | 1.7255044     |
| entropy                 | 1.7097714     |
| ep_rewmean              | -1.23         |
| episodes                | 1876          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 187401        |
| policy_loss             | 0.5021351     |
| qf1_loss                | 0.0037285064  |
| qf2_loss                | 0.0043261675  |
| time_elapsed            | 950           |
| total timesteps         | 187500        |
| value_loss              | 0.00018265856 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012458257  |
| ent_coef_loss           | -7.1839857    |
| entropy                 | 1.2160978     |
| ep_rewmean              | -1.26         |
| episodes                | 1880          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.3          |
| n_updates               | 187801        |
| policy_loss             | 0.47959453    |
| qf1_loss                | 6.558218e-05  |
| qf2_loss                | 7.177149e-05  |
| time_elapsed            | 952           |
| total timesteps         | 187900        |
| value_loss              | 0.00015990488 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010983725  |
| ent_coef_loss           | -13.629278    |
| entropy                 | 2.05285       |
| ep_rewmean              | -1.27         |
| episodes                | 1884          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.3          |
| n_updates               | 188201        |
| policy_loss             | 0.44972354    |
| qf1_loss                | 0.00010067904 |
| qf2_loss                | 9.806648e-05  |
| time_elapsed            | 954           |
| total timesteps         | 188300        |
| value_loss              | 6.419657e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010190926  |
| ent_coef_loss           | -6.575763     |
| entropy                 | 1.6718324     |
| ep_rewmean              | -1.27         |
| episodes                | 1888          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.3          |
| n_updates               | 188601        |
| policy_loss             | 0.43455905    |
| qf1_loss                | 0.00011197051 |
| qf2_loss                | 9.948971e-05  |
| time_elapsed            | 956           |
| total timesteps         | 188700        |
| value_loss              | 0.00024017919 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009986457  |
| ent_coef_loss           | -4.9665513    |
| entropy                 | 1.5036495     |
| ep_rewmean              | -1.28         |
| episodes                | 1892          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.3          |
| n_updates               | 189001        |
| policy_loss             | 0.40806693    |
| qf1_loss                | 7.642649e-05  |
| qf2_loss                | 0.00010823383 |
| time_elapsed            | 958           |
| total timesteps         | 189100        |
| value_loss              | 0.00014573633 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009965531  |
| ent_coef_loss           | 3.2298598     |
| entropy                 | 1.7521459     |
| ep_rewmean              | -1.29         |
| episodes                | 1896          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.3          |
| n_updates               | 189401        |
| policy_loss             | 0.41281235    |
| qf1_loss                | 0.0017314558  |
| qf2_loss                | 0.0017710708  |
| time_elapsed            | 960           |
| total timesteps         | 189500        |
| value_loss              | 0.00012018673 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009917911  |
| ent_coef_loss           | -3.4324322    |
| entropy                 | 2.5892153     |
| ep_rewmean              | -1.3          |
| episodes                | 1900          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.3          |
| n_updates               | 189801        |
| policy_loss             | 0.39263406    |
| qf1_loss                | 0.0018097133  |
| qf2_loss                | 0.0018100733  |
| time_elapsed            | 962           |
| total timesteps         | 189900        |
| value_loss              | 0.00010327043 |
-------------------------------------------
Eval num_timesteps=190000, episode_reward=-0.47 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0009707854   |
| ent_coef_loss           | 1.5800424      |
| entropy                 | 2.7638469      |
| ep_rewmean              | -1.29          |
| episodes                | 1904           |
| eplenmean               | 100            |
| fps                     | 197            |
| mean 100 episode reward | -1.3           |
| n_updates               | 190201         |
| policy_loss             | 0.36782455     |
| qf1_loss                | 0.000105560444 |
| qf2_loss                | 0.00014019794  |
| time_elapsed            | 964            |
| total timesteps         | 190300         |
| value_loss              | 0.00015314009  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00092776655 |
| ent_coef_loss           | -4.2318687    |
| entropy                 | 2.4854698     |
| ep_rewmean              | -1.27         |
| episodes                | 1908          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.3          |
| n_updates               | 190601        |
| policy_loss             | 0.37280422    |
| qf1_loss                | 0.00067754247 |
| qf2_loss                | 0.0007211594  |
| time_elapsed            | 966           |
| total timesteps         | 190700        |
| value_loss              | 0.00015733819 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008949962  |
| ent_coef_loss           | 1.1561637     |
| entropy                 | 2.717218      |
| ep_rewmean              | -1.24         |
| episodes                | 1912          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 191001        |
| policy_loss             | 0.4173167     |
| qf1_loss                | 9.385515e-05  |
| qf2_loss                | 9.845502e-05  |
| time_elapsed            | 968           |
| total timesteps         | 191100        |
| value_loss              | 0.00016411341 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00089051365 |
| ent_coef_loss           | -2.694265     |
| entropy                 | 3.0887876     |
| ep_rewmean              | -1.22         |
| episodes                | 1916          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 191401        |
| policy_loss             | 0.35878977    |
| qf1_loss                | 9.1842696e-05 |
| qf2_loss                | 0.00014558286 |
| time_elapsed            | 970           |
| total timesteps         | 191500        |
| value_loss              | 9.278493e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00083380705 |
| ent_coef_loss           | -2.4583387    |
| entropy                 | 2.5654044     |
| ep_rewmean              | -1.21         |
| episodes                | 1920          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 191801        |
| policy_loss             | 0.3455063     |
| qf1_loss                | 5.5497112e-05 |
| qf2_loss                | 6.023777e-05  |
| time_elapsed            | 972           |
| total timesteps         | 191900        |
| value_loss              | 0.00012996633 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00082434877  |
| ent_coef_loss           | -2.357842      |
| entropy                 | 2.3302402      |
| ep_rewmean              | -1.2           |
| episodes                | 1924           |
| eplenmean               | 100            |
| fps                     | 197            |
| mean 100 episode reward | -1.2           |
| n_updates               | 192201         |
| policy_loss             | 0.3179439      |
| qf1_loss                | 8.550224e-05   |
| qf2_loss                | 0.000100736215 |
| time_elapsed            | 974            |
| total timesteps         | 192300         |
| value_loss              | 0.00011522096  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00078802195 |
| ent_coef_loss           | -4.3047028    |
| entropy                 | 2.277924      |
| ep_rewmean              | -1.19         |
| episodes                | 1928          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 192601        |
| policy_loss             | 0.34020013    |
| qf1_loss                | 4.1212264e-05 |
| qf2_loss                | 5.609944e-05  |
| time_elapsed            | 976           |
| total timesteps         | 192700        |
| value_loss              | 8.503075e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0008107183   |
| ent_coef_loss           | -1.7949061     |
| entropy                 | 2.762782       |
| ep_rewmean              | -1.17          |
| episodes                | 1932           |
| eplenmean               | 100            |
| fps                     | 197            |
| mean 100 episode reward | -1.2           |
| n_updates               | 193001         |
| policy_loss             | 0.33875614     |
| qf1_loss                | 5.681664e-05   |
| qf2_loss                | 7.011151e-05   |
| time_elapsed            | 978            |
| total timesteps         | 193100         |
| value_loss              | 0.000110155546 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00079473207 |
| ent_coef_loss           | -1.830265     |
| entropy                 | 2.6168299     |
| ep_rewmean              | -1.11         |
| episodes                | 1936          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.1          |
| n_updates               | 193401        |
| policy_loss             | 0.3246736     |
| qf1_loss                | 0.0012578163  |
| qf2_loss                | 0.0011816405  |
| time_elapsed            | 980           |
| total timesteps         | 193500        |
| value_loss              | 0.0001046197  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007466511  |
| ent_coef_loss           | -5.9844923    |
| entropy                 | 3.2514367     |
| ep_rewmean              | -0.992        |
| episodes                | 1940          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 193801        |
| policy_loss             | 0.30039456    |
| qf1_loss                | 0.00077297486 |
| qf2_loss                | 0.0007020138  |
| time_elapsed            | 982           |
| total timesteps         | 193900        |
| value_loss              | 6.567525e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006955579  |
| ent_coef_loss           | -4.1950073    |
| entropy                 | 2.583065      |
| ep_rewmean              | -0.914        |
| episodes                | 1944          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 194201        |
| policy_loss             | 0.27954692    |
| qf1_loss                | 7.07874e-05   |
| qf2_loss                | 5.4613974e-05 |
| time_elapsed            | 984           |
| total timesteps         | 194300        |
| value_loss              | 7.1715025e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00065931864 |
| ent_coef_loss           | -11.183609    |
| entropy                 | 2.1516762     |
| ep_rewmean              | -0.847        |
| episodes                | 1948          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 194601        |
| policy_loss             | 0.30482018    |
| qf1_loss                | 0.0004960478  |
| qf2_loss                | 0.00044303294 |
| time_elapsed            | 986           |
| total timesteps         | 194700        |
| value_loss              | 7.4065436e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00062932033  |
| ent_coef_loss           | -1.9202089     |
| entropy                 | 2.9577432      |
| ep_rewmean              | -0.783         |
| episodes                | 1952           |
| eplenmean               | 100            |
| fps                     | 197            |
| mean 100 episode reward | -0.8           |
| n_updates               | 195001         |
| policy_loss             | 0.3202203      |
| qf1_loss                | 0.00011361029  |
| qf2_loss                | 5.747078e-05   |
| time_elapsed            | 988            |
| total timesteps         | 195100         |
| value_loss              | 0.000110038825 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00058089744 |
| ent_coef_loss           | -5.097829     |
| entropy                 | 2.8686376     |
| ep_rewmean              | -0.732        |
| episodes                | 1956          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 195401        |
| policy_loss             | 0.27828884    |
| qf1_loss                | 0.00023005296 |
| qf2_loss                | 0.00030291974 |
| time_elapsed            | 990           |
| total timesteps         | 195500        |
| value_loss              | 0.00010197767 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005519178  |
| ent_coef_loss           | -3.5149794    |
| entropy                 | 1.8273823     |
| ep_rewmean              | -0.667        |
| episodes                | 1960          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 195801        |
| policy_loss             | 0.25814205    |
| qf1_loss                | 0.00039759753 |
| qf2_loss                | 0.00037046443 |
| time_elapsed            | 992           |
| total timesteps         | 195900        |
| value_loss              | 7.280152e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000575984   |
| ent_coef_loss           | 1.0773988     |
| entropy                 | 1.3095251     |
| ep_rewmean              | -0.639        |
| episodes                | 1964          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 196201        |
| policy_loss             | 0.26748815    |
| qf1_loss                | 5.15148e-05   |
| qf2_loss                | 5.313803e-05  |
| time_elapsed            | 994           |
| total timesteps         | 196300        |
| value_loss              | 4.9162874e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00062020036 |
| ent_coef_loss           | 0.014239311   |
| entropy                 | 0.92007756    |
| ep_rewmean              | -0.621        |
| episodes                | 1968          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 196601        |
| policy_loss             | 0.2729543     |
| qf1_loss                | 2.9003273e-05 |
| qf2_loss                | 5.623294e-05  |
| time_elapsed            | 996           |
| total timesteps         | 196700        |
| value_loss              | 4.7657384e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005766064  |
| ent_coef_loss           | -7.849374     |
| entropy                 | 1.8657439     |
| ep_rewmean              | -0.596        |
| episodes                | 1972          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 197001        |
| policy_loss             | 0.268018      |
| qf1_loss                | 5.06738e-05   |
| qf2_loss                | 6.4468615e-05 |
| time_elapsed            | 998           |
| total timesteps         | 197100        |
| value_loss              | 6.273976e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005793268  |
| ent_coef_loss           | 17.481201     |
| entropy                 | 0.6223643     |
| ep_rewmean              | -0.62         |
| episodes                | 1976          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 197401        |
| policy_loss             | 0.25450954    |
| qf1_loss                | 0.0004686841  |
| qf2_loss                | 0.00044950043 |
| time_elapsed            | 1000          |
| total timesteps         | 197500        |
| value_loss              | 0.00014495765 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006735104  |
| ent_coef_loss           | 7.085834      |
| entropy                 | 1.8171328     |
| ep_rewmean              | -0.734        |
| episodes                | 1980          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 197801        |
| policy_loss             | 0.23789617    |
| qf1_loss                | 3.9391016e-05 |
| qf2_loss                | 3.3440425e-05 |
| time_elapsed            | 1002          |
| total timesteps         | 197900        |
| value_loss              | 7.400874e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0006884214 |
| ent_coef_loss           | -6.639556    |
| entropy                 | 1.6414483    |
| ep_rewmean              | -0.772       |
| episodes                | 1984         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.8         |
| n_updates               | 198201       |
| policy_loss             | 0.23903556   |
| qf1_loss                | 5.604938e-05 |
| qf2_loss                | 5.320156e-05 |
| time_elapsed            | 1004         |
| total timesteps         | 198300       |
| value_loss              | 6.963874e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006629914  |
| ent_coef_loss           | -1.9766932    |
| entropy                 | 1.669637      |
| ep_rewmean              | -0.796        |
| episodes                | 1988          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 198601        |
| policy_loss             | 0.22574866    |
| qf1_loss                | 0.00029828498 |
| qf2_loss                | 0.00026047137 |
| time_elapsed            | 1006          |
| total timesteps         | 198700        |
| value_loss              | 9.492035e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00063368335 |
| ent_coef_loss           | -7.3487673    |
| entropy                 | 2.365714      |
| ep_rewmean              | -0.809        |
| episodes                | 1992          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 199001        |
| policy_loss             | 0.21766973    |
| qf1_loss                | 0.0012031237  |
| qf2_loss                | 0.001210223   |
| time_elapsed            | 1008          |
| total timesteps         | 199100        |
| value_loss              | 7.082046e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000621353   |
| ent_coef_loss           | -0.37138557   |
| entropy                 | 2.527678      |
| ep_rewmean              | -0.831        |
| episodes                | 1996          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 199401        |
| policy_loss             | 0.20082551    |
| qf1_loss                | 0.0007066467  |
| qf2_loss                | 0.0006353101  |
| time_elapsed            | 1010          |
| total timesteps         | 199500        |
| value_loss              | 5.4002063e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006179403  |
| ent_coef_loss           | 3.6026626     |
| entropy                 | 2.9417357     |
| ep_rewmean              | -0.842        |
| episodes                | 2000          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 199801        |
| policy_loss             | 0.21403745    |
| qf1_loss                | 4.2772823e-05 |
| qf2_loss                | 3.582835e-05  |
| time_elapsed            | 1012          |
| total timesteps         | 199900        |
| value_loss              | 6.444551e-05  |
-------------------------------------------
Eval num_timesteps=200000, episode_reward=-1.34 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00060876226 |
| ent_coef_loss           | 2.2816186     |
| entropy                 | 2.9684544     |
| ep_rewmean              | -0.891        |
| episodes                | 2004          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 200201        |
| policy_loss             | 0.19004166    |
| qf1_loss                | 5.5429893e-05 |
| qf2_loss                | 0.00019956376 |
| time_elapsed            | 1014          |
| total timesteps         | 200300        |
| value_loss              | 6.4319e-05    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005919983  |
| ent_coef_loss           | -8.373085     |
| entropy                 | 3.0535517     |
| ep_rewmean              | -0.951        |
| episodes                | 2008          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 200601        |
| policy_loss             | 0.20418698    |
| qf1_loss                | 5.8058315e-05 |
| qf2_loss                | 6.172134e-05  |
| time_elapsed            | 1016          |
| total timesteps         | 200700        |
| value_loss              | 8.705081e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006453468  |
| ent_coef_loss           | -0.59269536   |
| entropy                 | 3.5567813     |
| ep_rewmean              | -1.01         |
| episodes                | 2012          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 201001        |
| policy_loss             | 0.20477897    |
| qf1_loss                | 3.7831593e-05 |
| qf2_loss                | 3.1608895e-05 |
| time_elapsed            | 1018          |
| total timesteps         | 201100        |
| value_loss              | 2.6559544e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00065154536 |
| ent_coef_loss           | 1.2678072     |
| entropy                 | 3.361989      |
| ep_rewmean              | -1.02         |
| episodes                | 2016          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 201401        |
| policy_loss             | 0.18421417    |
| qf1_loss                | 0.00016784381 |
| qf2_loss                | 0.00021816834 |
| time_elapsed            | 1020          |
| total timesteps         | 201500        |
| value_loss              | 3.6679157e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006546412  |
| ent_coef_loss           | -12.795691    |
| entropy                 | 3.5633497     |
| ep_rewmean              | -1.02         |
| episodes                | 2020          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 201801        |
| policy_loss             | 0.18687224    |
| qf1_loss                | 0.00013279032 |
| qf2_loss                | 0.00013908016 |
| time_elapsed            | 1022          |
| total timesteps         | 201900        |
| value_loss              | 8.0273945e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00064272113 |
| ent_coef_loss           | 18.304413     |
| entropy                 | 3.243307      |
| ep_rewmean              | -1.02         |
| episodes                | 2024          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 202201        |
| policy_loss             | 0.21195978    |
| qf1_loss                | 0.0002560932  |
| qf2_loss                | 0.00024089753 |
| time_elapsed            | 1024          |
| total timesteps         | 202300        |
| value_loss              | 4.7435962e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00062115747 |
| ent_coef_loss           | 4.7159033     |
| entropy                 | 3.0123537     |
| ep_rewmean              | -1.05         |
| episodes                | 2028          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 202601        |
| policy_loss             | 0.20267393    |
| qf1_loss                | 0.00093782844 |
| qf2_loss                | 0.000894045   |
| time_elapsed            | 1026          |
| total timesteps         | 202700        |
| value_loss              | 6.0974104e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005973041  |
| ent_coef_loss           | 0.102041245   |
| entropy                 | 2.5823717     |
| ep_rewmean              | -1.11         |
| episodes                | 2032          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.1          |
| n_updates               | 203001        |
| policy_loss             | 0.18902421    |
| qf1_loss                | 5.61794e-05   |
| qf2_loss                | 4.514905e-05  |
| time_elapsed            | 1029          |
| total timesteps         | 203100        |
| value_loss              | 6.0092178e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0005574775   |
| ent_coef_loss           | 2.4425254      |
| entropy                 | 3.219523       |
| ep_rewmean              | -1.13          |
| episodes                | 2036           |
| eplenmean               | 100            |
| fps                     | 197            |
| mean 100 episode reward | -1.1           |
| n_updates               | 203401         |
| policy_loss             | 0.19557026     |
| qf1_loss                | 0.00013613599  |
| qf2_loss                | 0.000118823715 |
| time_elapsed            | 1031           |
| total timesteps         | 203500         |
| value_loss              | 3.55071e-05    |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00050965906 |
| ent_coef_loss           | -18.263208    |
| entropy                 | 3.1384852     |
| ep_rewmean              | -1.13         |
| episodes                | 2040          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.1          |
| n_updates               | 203801        |
| policy_loss             | 0.18444636    |
| qf1_loss                | 0.00030785153 |
| qf2_loss                | 0.0003415799  |
| time_elapsed            | 1033          |
| total timesteps         | 203900        |
| value_loss              | 2.5149102e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00048483614 |
| ent_coef_loss           | 7.8472385     |
| entropy                 | 3.3760176     |
| ep_rewmean              | -1.17         |
| episodes                | 2044          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 204201        |
| policy_loss             | 0.20580432    |
| qf1_loss                | 0.00032581095 |
| qf2_loss                | 0.0003116413  |
| time_elapsed            | 1035          |
| total timesteps         | 204300        |
| value_loss              | 4.7314934e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00045601054 |
| ent_coef_loss           | 4.2715874     |
| entropy                 | 3.2591481     |
| ep_rewmean              | -1.18         |
| episodes                | 2048          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 204601        |
| policy_loss             | 0.18927298    |
| qf1_loss                | 1.95344e-05   |
| qf2_loss                | 1.8264709e-05 |
| time_elapsed            | 1037          |
| total timesteps         | 204700        |
| value_loss              | 3.8325838e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00045472512 |
| ent_coef_loss           | -0.30571938   |
| entropy                 | 3.1991131     |
| ep_rewmean              | -1.18         |
| episodes                | 2052          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 205001        |
| policy_loss             | 0.17736438    |
| qf1_loss                | 0.0003445249  |
| qf2_loss                | 0.00035532677 |
| time_elapsed            | 1039          |
| total timesteps         | 205100        |
| value_loss              | 3.891214e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00045891348 |
| ent_coef_loss           | 1.8083158     |
| entropy                 | 2.7395124     |
| ep_rewmean              | -1.19         |
| episodes                | 2056          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 205401        |
| policy_loss             | 0.18286762    |
| qf1_loss                | 0.0022986773  |
| qf2_loss                | 0.0024372968  |
| time_elapsed            | 1041          |
| total timesteps         | 205500        |
| value_loss              | 3.526998e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00047317086 |
| ent_coef_loss           | -12.966146    |
| entropy                 | 4.084926      |
| ep_rewmean              | -1.18         |
| episodes                | 2060          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 205801        |
| policy_loss             | 0.19817398    |
| qf1_loss                | 5.6006524e-05 |
| qf2_loss                | 5.013122e-05  |
| time_elapsed            | 1043          |
| total timesteps         | 205900        |
| value_loss              | 3.5970144e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00044438188 |
| ent_coef_loss           | 20.545706     |
| entropy                 | 2.5764208     |
| ep_rewmean              | -1.18         |
| episodes                | 2064          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 206201        |
| policy_loss             | 0.18865395    |
| qf1_loss                | 2.2438035e-05 |
| qf2_loss                | 2.7694754e-05 |
| time_elapsed            | 1045          |
| total timesteps         | 206300        |
| value_loss              | 7.315695e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004920799  |
| ent_coef_loss           | 3.7321908     |
| entropy                 | 2.233416      |
| ep_rewmean              | -1.18         |
| episodes                | 2068          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 206601        |
| policy_loss             | 0.19903326    |
| qf1_loss                | 0.00017004342 |
| qf2_loss                | 0.00015514523 |
| time_elapsed            | 1047          |
| total timesteps         | 206700        |
| value_loss              | 3.5284305e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00050384627 |
| ent_coef_loss           | 4.3351765     |
| entropy                 | 2.3903065     |
| ep_rewmean              | -1.18         |
| episodes                | 2072          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 207001        |
| policy_loss             | 0.19436648    |
| qf1_loss                | 2.7176688e-05 |
| qf2_loss                | 3.79952e-05   |
| time_elapsed            | 1049          |
| total timesteps         | 207100        |
| value_loss              | 4.0754e-05    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00047801895 |
| ent_coef_loss           | 9.38472       |
| entropy                 | 3.892587      |
| ep_rewmean              | -1.14         |
| episodes                | 2076          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.1          |
| n_updates               | 207401        |
| policy_loss             | 0.19689526    |
| qf1_loss                | 2.4973495e-05 |
| qf2_loss                | 2.0525524e-05 |
| time_elapsed            | 1051          |
| total timesteps         | 207500        |
| value_loss              | 2.1538133e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00050007075 |
| ent_coef_loss           | -6.5648527    |
| entropy                 | 3.6322517     |
| ep_rewmean              | -1            |
| episodes                | 2080          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 207801        |
| policy_loss             | 0.18114826    |
| qf1_loss                | 1.6108052e-05 |
| qf2_loss                | 1.5680092e-05 |
| time_elapsed            | 1053          |
| total timesteps         | 207900        |
| value_loss              | 4.7723435e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00048557282 |
| ent_coef_loss           | 6.076616      |
| entropy                 | 3.498746      |
| ep_rewmean              | -0.948        |
| episodes                | 2084          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 208201        |
| policy_loss             | 0.19432753    |
| qf1_loss                | 3.5440793e-05 |
| qf2_loss                | 2.4745477e-05 |
| time_elapsed            | 1055          |
| total timesteps         | 208300        |
| value_loss              | 4.2373533e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004409842  |
| ent_coef_loss           | -10.058952    |
| entropy                 | 3.9771183     |
| ep_rewmean              | -0.922        |
| episodes                | 2088          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 208601        |
| policy_loss             | 0.19458681    |
| qf1_loss                | 1.859941e-05  |
| qf2_loss                | 2.0908083e-05 |
| time_elapsed            | 1057          |
| total timesteps         | 208700        |
| value_loss              | 3.0275247e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00040100238 |
| ent_coef_loss           | -9.565962     |
| entropy                 | 3.3848128     |
| ep_rewmean              | -0.905        |
| episodes                | 2092          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 209001        |
| policy_loss             | 0.17123497    |
| qf1_loss                | 4.017447e-05  |
| qf2_loss                | 3.178875e-05  |
| time_elapsed            | 1059          |
| total timesteps         | 209100        |
| value_loss              | 4.876759e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003918985  |
| ent_coef_loss           | 4.1683536     |
| entropy                 | 3.6648173     |
| ep_rewmean              | -0.877        |
| episodes                | 2096          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 209401        |
| policy_loss             | 0.20987338    |
| qf1_loss                | 0.0006724896  |
| qf2_loss                | 0.0006887699  |
| time_elapsed            | 1061          |
| total timesteps         | 209500        |
| value_loss              | 5.2866548e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00037414086 |
| ent_coef_loss           | -0.011357307  |
| entropy                 | 2.5707219     |
| ep_rewmean              | -0.848        |
| episodes                | 2100          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 209801        |
| policy_loss             | 0.17834163    |
| qf1_loss                | 3.63012e-05   |
| qf2_loss                | 1.980172e-05  |
| time_elapsed            | 1063          |
| total timesteps         | 209900        |
| value_loss              | 3.4379653e-05 |
-------------------------------------------
Eval num_timesteps=210000, episode_reward=-0.76 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00037883662 |
| ent_coef_loss           | -3.9279318    |
| entropy                 | 3.0552135     |
| ep_rewmean              | -0.811        |
| episodes                | 2104          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 210201        |
| policy_loss             | 0.18163402    |
| qf1_loss                | 1.5958023e-05 |
| qf2_loss                | 2.1546244e-05 |
| time_elapsed            | 1065          |
| total timesteps         | 210300        |
| value_loss              | 3.2346186e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00037676867 |
| ent_coef_loss           | 4.124111      |
| entropy                 | 2.8269725     |
| ep_rewmean              | -0.759        |
| episodes                | 2108          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 210601        |
| policy_loss             | 0.1795748     |
| qf1_loss                | 0.0008079597  |
| qf2_loss                | 0.00083735504 |
| time_elapsed            | 1067          |
| total timesteps         | 210700        |
| value_loss              | 2.0755466e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00038237212 |
| ent_coef_loss           | -7.165461     |
| entropy                 | 2.2943978     |
| ep_rewmean              | -0.702        |
| episodes                | 2112          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 211001        |
| policy_loss             | 0.18900305    |
| qf1_loss                | 5.8579273e-05 |
| qf2_loss                | 3.7374455e-05 |
| time_elapsed            | 1069          |
| total timesteps         | 211100        |
| value_loss              | 6.1330335e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003873804  |
| ent_coef_loss           | -8.371506     |
| entropy                 | 2.3715103     |
| ep_rewmean              | -0.704        |
| episodes                | 2116          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 211401        |
| policy_loss             | 0.19131342    |
| qf1_loss                | 0.00029186995 |
| qf2_loss                | 0.00030410942 |
| time_elapsed            | 1071          |
| total timesteps         | 211500        |
| value_loss              | 2.637088e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00038597375 |
| ent_coef_loss           | -2.8219283    |
| entropy                 | 2.3490162     |
| ep_rewmean              | -0.703        |
| episodes                | 2120          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 211801        |
| policy_loss             | 0.182043      |
| qf1_loss                | 2.7743856e-05 |
| qf2_loss                | 2.1590698e-05 |
| time_elapsed            | 1073          |
| total timesteps         | 211900        |
| value_loss              | 1.8207247e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00038263766 |
| ent_coef_loss           | -16.87465     |
| entropy                 | 3.137855      |
| ep_rewmean              | -0.698        |
| episodes                | 2124          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 212201        |
| policy_loss             | 0.1916905     |
| qf1_loss                | 2.793225e-05  |
| qf2_loss                | 2.7491249e-05 |
| time_elapsed            | 1075          |
| total timesteps         | 212300        |
| value_loss              | 2.8298022e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00039473685 |
| ent_coef_loss           | 10.960794     |
| entropy                 | 1.9937071     |
| ep_rewmean              | -0.671        |
| episodes                | 2128          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 212601        |
| policy_loss             | 0.19462977    |
| qf1_loss                | 2.4779914e-05 |
| qf2_loss                | 2.2432168e-05 |
| time_elapsed            | 1077          |
| total timesteps         | 212700        |
| value_loss              | 3.3160853e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004157868  |
| ent_coef_loss           | 5.0186696     |
| entropy                 | 2.3047662     |
| ep_rewmean              | -0.622        |
| episodes                | 2132          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 213001        |
| policy_loss             | 0.19149882    |
| qf1_loss                | 0.00026206498 |
| qf2_loss                | 0.00026172338 |
| time_elapsed            | 1079          |
| total timesteps         | 213100        |
| value_loss              | 3.4505658e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004305758  |
| ent_coef_loss           | -0.405609     |
| entropy                 | 2.8486447     |
| ep_rewmean              | -0.604        |
| episodes                | 2136          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 213401        |
| policy_loss             | 0.21169236    |
| qf1_loss                | 0.00023450074 |
| qf2_loss                | 0.00024943548 |
| time_elapsed            | 1081          |
| total timesteps         | 213500        |
| value_loss              | 1.816533e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00042419677 |
| ent_coef_loss           | 6.4311543     |
| entropy                 | 1.8017054     |
| ep_rewmean              | -0.593        |
| episodes                | 2140          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 213801        |
| policy_loss             | 0.20221463    |
| qf1_loss                | 4.7052166e-05 |
| qf2_loss                | 4.4155237e-05 |
| time_elapsed            | 1083          |
| total timesteps         | 213900        |
| value_loss              | 2.1236756e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00042054456 |
| ent_coef_loss           | 9.997168      |
| entropy                 | 2.5443091     |
| ep_rewmean              | -0.559        |
| episodes                | 2144          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 214201        |
| policy_loss             | 0.21052614    |
| qf1_loss                | 3.6426514e-05 |
| qf2_loss                | 4.526114e-05  |
| time_elapsed            | 1085          |
| total timesteps         | 214300        |
| value_loss              | 4.6667425e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004229072  |
| ent_coef_loss           | 9.072766      |
| entropy                 | 2.3767061     |
| ep_rewmean              | -0.553        |
| episodes                | 2148          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 214601        |
| policy_loss             | 0.22086957    |
| qf1_loss                | 0.0005176014  |
| qf2_loss                | 0.00053145905 |
| time_elapsed            | 1087          |
| total timesteps         | 214700        |
| value_loss              | 3.4832596e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00041924193 |
| ent_coef_loss           | -3.8627062    |
| entropy                 | 2.4092088     |
| ep_rewmean              | -0.55         |
| episodes                | 2152          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 215001        |
| policy_loss             | 0.21961738    |
| qf1_loss                | 0.0006209656  |
| qf2_loss                | 0.00055064727 |
| time_elapsed            | 1089          |
| total timesteps         | 215100        |
| value_loss              | 2.4640372e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004241298  |
| ent_coef_loss           | -0.19300178   |
| entropy                 | 2.8672233     |
| ep_rewmean              | -0.557        |
| episodes                | 2156          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 215401        |
| policy_loss             | 0.2364409     |
| qf1_loss                | 3.87491e-05   |
| qf2_loss                | 3.281366e-05  |
| time_elapsed            | 1091          |
| total timesteps         | 215500        |
| value_loss              | 2.7971024e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00045574602 |
| ent_coef_loss           | -5.7474174    |
| entropy                 | 3.663821      |
| ep_rewmean              | -0.565        |
| episodes                | 2160          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 215801        |
| policy_loss             | 0.23780203    |
| qf1_loss                | 0.00032874162 |
| qf2_loss                | 0.00032375797 |
| time_elapsed            | 1093          |
| total timesteps         | 215900        |
| value_loss              | 2.3478531e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00046383528 |
| ent_coef_loss           | 1.5349514     |
| entropy                 | 3.4422739     |
| ep_rewmean              | -0.565        |
| episodes                | 2164          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 216201        |
| policy_loss             | 0.2194605     |
| qf1_loss                | 1.9521643e-05 |
| qf2_loss                | 1.9437255e-05 |
| time_elapsed            | 1095          |
| total timesteps         | 216300        |
| value_loss              | 3.4835015e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000492879   |
| ent_coef_loss           | -2.6128504    |
| entropy                 | 3.919598      |
| ep_rewmean              | -0.558        |
| episodes                | 2168          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 216601        |
| policy_loss             | 0.22804052    |
| qf1_loss                | 4.0847524e-05 |
| qf2_loss                | 3.0685827e-05 |
| time_elapsed            | 1097          |
| total timesteps         | 216700        |
| value_loss              | 5.563473e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005662703  |
| ent_coef_loss           | 15.513958     |
| entropy                 | 3.0344925     |
| ep_rewmean              | -0.591        |
| episodes                | 2172          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 217001        |
| policy_loss             | 0.23945233    |
| qf1_loss                | 2.0287258e-05 |
| qf2_loss                | 2.5404908e-05 |
| time_elapsed            | 1099          |
| total timesteps         | 217100        |
| value_loss              | 8.735739e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00063843594 |
| ent_coef_loss           | 2.9156055     |
| entropy                 | 3.5669541     |
| ep_rewmean              | -0.636        |
| episodes                | 2176          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 217401        |
| policy_loss             | 0.25736886    |
| qf1_loss                | 0.0005265159  |
| qf2_loss                | 0.000501692   |
| time_elapsed            | 1101          |
| total timesteps         | 217500        |
| value_loss              | 3.7919774e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006431773  |
| ent_coef_loss           | -1.9776127    |
| entropy                 | 3.5230334     |
| ep_rewmean              | -0.686        |
| episodes                | 2180          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 217801        |
| policy_loss             | 0.2816307     |
| qf1_loss                | 3.8543796e-05 |
| qf2_loss                | 3.0840638e-05 |
| time_elapsed            | 1103          |
| total timesteps         | 217900        |
| value_loss              | 3.2885997e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00065448263 |
| ent_coef_loss           | 10.697649     |
| entropy                 | 3.7930255     |
| ep_rewmean              | -0.72         |
| episodes                | 2184          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 218201        |
| policy_loss             | 0.29052603    |
| qf1_loss                | 0.0009605902  |
| qf2_loss                | 0.0010213807  |
| time_elapsed            | 1105          |
| total timesteps         | 218300        |
| value_loss              | 2.4826306e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00069575594 |
| ent_coef_loss           | 1.5014676     |
| entropy                 | 4.002287      |
| ep_rewmean              | -0.773        |
| episodes                | 2188          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 218601        |
| policy_loss             | 0.32517588    |
| qf1_loss                | 0.0010416985  |
| qf2_loss                | 0.001057389   |
| time_elapsed            | 1107          |
| total timesteps         | 218700        |
| value_loss              | 4.8672748e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006682694  |
| ent_coef_loss           | 5.059374      |
| entropy                 | 4.04443       |
| ep_rewmean              | -0.816        |
| episodes                | 2192          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 219001        |
| policy_loss             | 0.33430058    |
| qf1_loss                | 4.7115383e-05 |
| qf2_loss                | 6.861559e-05  |
| time_elapsed            | 1109          |
| total timesteps         | 219100        |
| value_loss              | 3.2792817e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00061481167 |
| ent_coef_loss           | -1.7657177    |
| entropy                 | 3.5029674     |
| ep_rewmean              | -0.877        |
| episodes                | 2196          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 219401        |
| policy_loss             | 0.34748513    |
| qf1_loss                | 3.8950206e-05 |
| qf2_loss                | 2.5979483e-05 |
| time_elapsed            | 1111          |
| total timesteps         | 219500        |
| value_loss              | 7.059764e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005913265  |
| ent_coef_loss           | -9.0586195    |
| entropy                 | 3.7550707     |
| ep_rewmean              | -0.962        |
| episodes                | 2200          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 219801        |
| policy_loss             | 0.35887703    |
| qf1_loss                | 0.0016109544  |
| qf2_loss                | 0.0015647598  |
| time_elapsed            | 1113          |
| total timesteps         | 219900        |
| value_loss              | 4.1675332e-05 |
-------------------------------------------
Eval num_timesteps=220000, episode_reward=-2.68 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006179483  |
| ent_coef_loss           | 9.787593      |
| entropy                 | 3.295683      |
| ep_rewmean              | -1.01         |
| episodes                | 2204          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 220201        |
| policy_loss             | 0.3483191     |
| qf1_loss                | 0.0009828719  |
| qf2_loss                | 0.0009873728  |
| time_elapsed            | 1116          |
| total timesteps         | 220300        |
| value_loss              | 3.0580923e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006451945  |
| ent_coef_loss           | -1.5156808    |
| entropy                 | 2.6088614     |
| ep_rewmean              | -1.04         |
| episodes                | 2208          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 220601        |
| policy_loss             | 0.3765652     |
| qf1_loss                | 0.0023159832  |
| qf2_loss                | 0.0023156346  |
| time_elapsed            | 1118          |
| total timesteps         | 220700        |
| value_loss              | 3.5529352e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00058373105 |
| ent_coef_loss           | -18.722115    |
| entropy                 | 2.8169332     |
| ep_rewmean              | -1.08         |
| episodes                | 2212          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.1          |
| n_updates               | 221001        |
| policy_loss             | 0.3905014     |
| qf1_loss                | 2.8957638e-05 |
| qf2_loss                | 2.3743105e-05 |
| time_elapsed            | 1120          |
| total timesteps         | 221100        |
| value_loss              | 3.25904e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00055238116 |
| ent_coef_loss           | 3.0431273     |
| entropy                 | 2.366053      |
| ep_rewmean              | -1.15         |
| episodes                | 2216          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.1          |
| n_updates               | 221401        |
| policy_loss             | 0.35915273    |
| qf1_loss                | 0.0010438724  |
| qf2_loss                | 0.0010320053  |
| time_elapsed            | 1122          |
| total timesteps         | 221500        |
| value_loss              | 4.9782386e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00054713804 |
| ent_coef_loss           | 7.3281646     |
| entropy                 | 2.6786199     |
| ep_rewmean              | -1.19         |
| episodes                | 2220          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 221801        |
| policy_loss             | 0.3751598     |
| qf1_loss                | 0.0009967581  |
| qf2_loss                | 0.000990019   |
| time_elapsed            | 1124          |
| total timesteps         | 221900        |
| value_loss              | 3.895528e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0005424623 |
| ent_coef_loss           | -8.507885    |
| entropy                 | 2.1107152    |
| ep_rewmean              | -1.22        |
| episodes                | 2224         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -1.2         |
| n_updates               | 222201       |
| policy_loss             | 0.376252     |
| qf1_loss                | 0.0012276911 |
| qf2_loss                | 0.0012081179 |
| time_elapsed            | 1126         |
| total timesteps         | 222300       |
| value_loss              | 3.153361e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00053485646 |
| ent_coef_loss           | -10.454183    |
| entropy                 | 2.6752286     |
| ep_rewmean              | -1.25         |
| episodes                | 2228          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.3          |
| n_updates               | 222601        |
| policy_loss             | 0.3648516     |
| qf1_loss                | 3.613408e-05  |
| qf2_loss                | 4.7437086e-05 |
| time_elapsed            | 1128          |
| total timesteps         | 222700        |
| value_loss              | 6.0582894e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005479952  |
| ent_coef_loss           | 12.9144535    |
| entropy                 | 2.3271685     |
| ep_rewmean              | -1.24         |
| episodes                | 2232          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 223001        |
| policy_loss             | 0.38741726    |
| qf1_loss                | 0.0009422971  |
| qf2_loss                | 0.00095433695 |
| time_elapsed            | 1130          |
| total timesteps         | 223100        |
| value_loss              | 0.0002333898  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005759741  |
| ent_coef_loss           | 3.2244406     |
| entropy                 | 2.168974      |
| ep_rewmean              | -1.25         |
| episodes                | 2236          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.3          |
| n_updates               | 223401        |
| policy_loss             | 0.39488548    |
| qf1_loss                | 0.00083756476 |
| qf2_loss                | 0.00082952576 |
| time_elapsed            | 1132          |
| total timesteps         | 223500        |
| value_loss              | 3.8269376e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0005677406 |
| ent_coef_loss           | -3.6847706   |
| entropy                 | 2.2728403    |
| ep_rewmean              | -1.26        |
| episodes                | 2240         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -1.3         |
| n_updates               | 223801       |
| policy_loss             | 0.36234266   |
| qf1_loss                | 3.381711e-05 |
| qf2_loss                | 4.274199e-05 |
| time_elapsed            | 1134         |
| total timesteps         | 223900       |
| value_loss              | 3.64706e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005454186  |
| ent_coef_loss           | 7.2115774     |
| entropy                 | 1.9463098     |
| ep_rewmean              | -1.27         |
| episodes                | 2244          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.3          |
| n_updates               | 224201        |
| policy_loss             | 0.38054514    |
| qf1_loss                | 4.5581874e-05 |
| qf2_loss                | 5.1917843e-05 |
| time_elapsed            | 1136          |
| total timesteps         | 224300        |
| value_loss              | 3.1713374e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00053365936 |
| ent_coef_loss           | 6.1423063     |
| entropy                 | 2.4715743     |
| ep_rewmean              | -1.27         |
| episodes                | 2248          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.3          |
| n_updates               | 224601        |
| policy_loss             | 0.36317903    |
| qf1_loss                | 0.0015817994  |
| qf2_loss                | 0.0016609587  |
| time_elapsed            | 1138          |
| total timesteps         | 224700        |
| value_loss              | 4.3880602e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00055422116 |
| ent_coef_loss           | -1.3063817    |
| entropy                 | 3.3513968     |
| ep_rewmean              | -1.27         |
| episodes                | 2252          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.3          |
| n_updates               | 225001        |
| policy_loss             | 0.36185893    |
| qf1_loss                | 2.8872546e-05 |
| qf2_loss                | 3.7472797e-05 |
| time_elapsed            | 1140          |
| total timesteps         | 225100        |
| value_loss              | 9.774223e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005892257  |
| ent_coef_loss           | 0.63115716    |
| entropy                 | 3.0301726     |
| ep_rewmean              | -1.26         |
| episodes                | 2256          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.3          |
| n_updates               | 225401        |
| policy_loss             | 0.34111184    |
| qf1_loss                | 3.7864203e-05 |
| qf2_loss                | 2.990001e-05  |
| time_elapsed            | 1142          |
| total timesteps         | 225500        |
| value_loss              | 3.768035e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005872899  |
| ent_coef_loss           | 2.309775      |
| entropy                 | 2.7595081     |
| ep_rewmean              | -1.25         |
| episodes                | 2260          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.3          |
| n_updates               | 225801        |
| policy_loss             | 0.3427918     |
| qf1_loss                | 4.5811183e-05 |
| qf2_loss                | 3.809328e-05  |
| time_elapsed            | 1144          |
| total timesteps         | 225900        |
| value_loss              | 4.4237117e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005672954  |
| ent_coef_loss           | -6.335324     |
| entropy                 | 2.722539      |
| ep_rewmean              | -1.25         |
| episodes                | 2264          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 226201        |
| policy_loss             | 0.35422516    |
| qf1_loss                | 2.4278894e-05 |
| qf2_loss                | 3.442276e-05  |
| time_elapsed            | 1146          |
| total timesteps         | 226300        |
| value_loss              | 4.301526e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00060755585 |
| ent_coef_loss           | 12.272854     |
| entropy                 | 2.5527368     |
| ep_rewmean              | -1.27         |
| episodes                | 2268          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.3          |
| n_updates               | 226601        |
| policy_loss             | 0.35727465    |
| qf1_loss                | 0.00063089345 |
| qf2_loss                | 0.0006421451  |
| time_elapsed            | 1148          |
| total timesteps         | 226700        |
| value_loss              | 3.104841e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006395984  |
| ent_coef_loss           | -17.98858     |
| entropy                 | 3.3563278     |
| ep_rewmean              | -1.28         |
| episodes                | 2272          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.3          |
| n_updates               | 227001        |
| policy_loss             | 0.35950336    |
| qf1_loss                | 7.5528784e-05 |
| qf2_loss                | 5.1580268e-05 |
| time_elapsed            | 1150          |
| total timesteps         | 227100        |
| value_loss              | 4.8668386e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00062961754 |
| ent_coef_loss           | -10.069109    |
| entropy                 | 2.1580021     |
| ep_rewmean              | -1.24         |
| episodes                | 2276          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 227401        |
| policy_loss             | 0.35355216    |
| qf1_loss                | 0.00011172627 |
| qf2_loss                | 6.681008e-05  |
| time_elapsed            | 1152          |
| total timesteps         | 227500        |
| value_loss              | 4.4966153e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00063575595 |
| ent_coef_loss           | -5.0515885    |
| entropy                 | 1.827168      |
| ep_rewmean              | -1.21         |
| episodes                | 2280          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 227801        |
| policy_loss             | 0.32598662    |
| qf1_loss                | 2.3306497e-05 |
| qf2_loss                | 4.9365764e-05 |
| time_elapsed            | 1154          |
| total timesteps         | 227900        |
| value_loss              | 2.6860855e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00062880025 |
| ent_coef_loss           | -2.098256     |
| entropy                 | 1.7308602     |
| ep_rewmean              | -1.18         |
| episodes                | 2284          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.2          |
| n_updates               | 228201        |
| policy_loss             | 0.3200452     |
| qf1_loss                | 6.683823e-05  |
| qf2_loss                | 6.543145e-05  |
| time_elapsed            | 1156          |
| total timesteps         | 228300        |
| value_loss              | 7.631327e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006069562  |
| ent_coef_loss           | -9.696161     |
| entropy                 | 1.2993305     |
| ep_rewmean              | -1.13         |
| episodes                | 2288          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.1          |
| n_updates               | 228601        |
| policy_loss             | 0.33978486    |
| qf1_loss                | 0.0012260387  |
| qf2_loss                | 0.0011907734  |
| time_elapsed            | 1158          |
| total timesteps         | 228700        |
| value_loss              | 6.0372146e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006039744  |
| ent_coef_loss           | 2.3118415     |
| entropy                 | 1.516198      |
| ep_rewmean              | -1.08         |
| episodes                | 2292          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.1          |
| n_updates               | 229001        |
| policy_loss             | 0.3274252     |
| qf1_loss                | 7.8060315e-05 |
| qf2_loss                | 7.007207e-05  |
| time_elapsed            | 1160          |
| total timesteps         | 229100        |
| value_loss              | 4.3648128e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00058197515 |
| ent_coef_loss           | 3.0345466     |
| entropy                 | 1.9824157     |
| ep_rewmean              | -1.02         |
| episodes                | 2296          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 229401        |
| policy_loss             | 0.34322736    |
| qf1_loss                | 3.307375e-05  |
| qf2_loss                | 3.125961e-05  |
| time_elapsed            | 1162          |
| total timesteps         | 229500        |
| value_loss              | 6.420912e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00058517215 |
| ent_coef_loss           | -6.2049494    |
| entropy                 | 1.9683079     |
| ep_rewmean              | -0.945        |
| episodes                | 2300          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 229801        |
| policy_loss             | 0.31285897    |
| qf1_loss                | 2.8309041e-05 |
| qf2_loss                | 1.6713315e-05 |
| time_elapsed            | 1164          |
| total timesteps         | 229900        |
| value_loss              | 5.6543115e-05 |
-------------------------------------------
Eval num_timesteps=230000, episode_reward=-0.71 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005804965  |
| ent_coef_loss           | -6.1232862    |
| entropy                 | 1.7898802     |
| ep_rewmean              | -0.902        |
| episodes                | 2304          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 230201        |
| policy_loss             | 0.31635806    |
| qf1_loss                | 0.00058234745 |
| qf2_loss                | 0.0007098378  |
| time_elapsed            | 1166          |
| total timesteps         | 230300        |
| value_loss              | 0.00013058443 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006038906  |
| ent_coef_loss           | -0.45723367   |
| entropy                 | 2.1765485     |
| ep_rewmean              | -0.877        |
| episodes                | 2308          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 230601        |
| policy_loss             | 0.3239899     |
| qf1_loss                | 8.395949e-05  |
| qf2_loss                | 6.239951e-05  |
| time_elapsed            | 1168          |
| total timesteps         | 230700        |
| value_loss              | 3.2147535e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005984407  |
| ent_coef_loss           | -1.3335283    |
| entropy                 | 1.8633995     |
| ep_rewmean              | -0.841        |
| episodes                | 2312          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 231001        |
| policy_loss             | 0.34517217    |
| qf1_loss                | 0.00059744646 |
| qf2_loss                | 0.000610666   |
| time_elapsed            | 1170          |
| total timesteps         | 231100        |
| value_loss              | 8.338699e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0005974627 |
| ent_coef_loss           | 10.992008    |
| entropy                 | 1.8690281    |
| ep_rewmean              | -0.776       |
| episodes                | 2316         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.8         |
| n_updates               | 231401       |
| policy_loss             | 0.33948314   |
| qf1_loss                | 0.0005474596 |
| qf2_loss                | 0.000527933  |
| time_elapsed            | 1172         |
| total timesteps         | 231500       |
| value_loss              | 7.091052e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006512425  |
| ent_coef_loss           | -1.1911025    |
| entropy                 | 1.5895951     |
| ep_rewmean              | -0.738        |
| episodes                | 2320          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 231801        |
| policy_loss             | 0.31415838    |
| qf1_loss                | 0.00077436096 |
| qf2_loss                | 0.00078844035 |
| time_elapsed            | 1174          |
| total timesteps         | 231900        |
| value_loss              | 2.617393e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00066749234 |
| ent_coef_loss           | 5.0842667     |
| entropy                 | 2.6115732     |
| ep_rewmean              | -0.716        |
| episodes                | 2324          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 232201        |
| policy_loss             | 0.31850788    |
| qf1_loss                | 5.7649508e-05 |
| qf2_loss                | 4.188707e-05  |
| time_elapsed            | 1176          |
| total timesteps         | 232300        |
| value_loss              | 3.728851e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006939839  |
| ent_coef_loss           | -13.806324    |
| entropy                 | 2.8435159     |
| ep_rewmean              | -0.69         |
| episodes                | 2328          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 232601        |
| policy_loss             | 0.32798678    |
| qf1_loss                | 0.00093427894 |
| qf2_loss                | 0.0009379833  |
| time_elapsed            | 1178          |
| total timesteps         | 232700        |
| value_loss              | 3.0496656e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006308105  |
| ent_coef_loss           | 4.71947       |
| entropy                 | 2.369607      |
| ep_rewmean              | -0.689        |
| episodes                | 2332          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 233001        |
| policy_loss             | 0.33673856    |
| qf1_loss                | 0.001500734   |
| qf2_loss                | 0.0015384299  |
| time_elapsed            | 1180          |
| total timesteps         | 233100        |
| value_loss              | 4.6585348e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00061592524 |
| ent_coef_loss           | -5.338106     |
| entropy                 | 2.7801218     |
| ep_rewmean              | -0.684        |
| episodes                | 2336          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 233401        |
| policy_loss             | 0.35474223    |
| qf1_loss                | 0.00054642477 |
| qf2_loss                | 0.000526214   |
| time_elapsed            | 1182          |
| total timesteps         | 233500        |
| value_loss              | 6.645304e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00064598134 |
| ent_coef_loss           | -4.91166      |
| entropy                 | 2.8942614     |
| ep_rewmean              | -0.677        |
| episodes                | 2340          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 233801        |
| policy_loss             | 0.3094025     |
| qf1_loss                | 0.00043774632 |
| qf2_loss                | 0.00042976713 |
| time_elapsed            | 1184          |
| total timesteps         | 233900        |
| value_loss              | 4.1233743e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00069804984 |
| ent_coef_loss           | 7.2333126     |
| entropy                 | 2.6804848     |
| ep_rewmean              | -0.677        |
| episodes                | 2344          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 234201        |
| policy_loss             | 0.3129421     |
| qf1_loss                | 0.0005547493  |
| qf2_loss                | 0.00052083505 |
| time_elapsed            | 1186          |
| total timesteps         | 234300        |
| value_loss              | 0.00011323822 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00069363724 |
| ent_coef_loss           | -3.3202004    |
| entropy                 | 2.728281      |
| ep_rewmean              | -0.683        |
| episodes                | 2348          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 234601        |
| policy_loss             | 0.29284543    |
| qf1_loss                | 0.0018280668  |
| qf2_loss                | 0.001904837   |
| time_elapsed            | 1188          |
| total timesteps         | 234700        |
| value_loss              | 8.903738e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006852074  |
| ent_coef_loss           | -4.4331617    |
| entropy                 | 2.6540852     |
| ep_rewmean              | -0.703        |
| episodes                | 2352          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 235001        |
| policy_loss             | 0.2964723     |
| qf1_loss                | 0.00079515105 |
| qf2_loss                | 0.00082201883 |
| time_elapsed            | 1190          |
| total timesteps         | 235100        |
| value_loss              | 5.2844116e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006821908  |
| ent_coef_loss           | -0.22827148   |
| entropy                 | 3.1446571     |
| ep_rewmean              | -0.704        |
| episodes                | 2356          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 235401        |
| policy_loss             | 0.31838435    |
| qf1_loss                | 1.982255e-05  |
| qf2_loss                | 2.1861735e-05 |
| time_elapsed            | 1192          |
| total timesteps         | 235500        |
| value_loss              | 8.908691e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00065930164 |
| ent_coef_loss           | -12.951838    |
| entropy                 | 2.369762      |
| ep_rewmean              | -0.705        |
| episodes                | 2360          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 235801        |
| policy_loss             | 0.27808633    |
| qf1_loss                | 2.4157838e-05 |
| qf2_loss                | 2.0190662e-05 |
| time_elapsed            | 1194          |
| total timesteps         | 235900        |
| value_loss              | 2.8309914e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00061224535 |
| ent_coef_loss           | -7.110593     |
| entropy                 | 2.0694814     |
| ep_rewmean              | -0.715        |
| episodes                | 2364          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 236201        |
| policy_loss             | 0.28895643    |
| qf1_loss                | 0.00053212664 |
| qf2_loss                | 0.00050296297 |
| time_elapsed            | 1196          |
| total timesteps         | 236300        |
| value_loss              | 4.4913242e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00059897     |
| ent_coef_loss           | 2.8029385      |
| entropy                 | 2.1627498      |
| ep_rewmean              | -0.693         |
| episodes                | 2368           |
| eplenmean               | 100            |
| fps                     | 197            |
| mean 100 episode reward | -0.7           |
| n_updates               | 236601         |
| policy_loss             | 0.28149152     |
| qf1_loss                | 0.00010285827  |
| qf2_loss                | 0.000105586805 |
| time_elapsed            | 1198           |
| total timesteps         | 236700         |
| value_loss              | 8.65463e-05    |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00058178284 |
| ent_coef_loss           | 0.17248034    |
| entropy                 | 1.8028708     |
| ep_rewmean              | -0.645        |
| episodes                | 2372          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 237001        |
| policy_loss             | 0.3069225     |
| qf1_loss                | 0.0007614521  |
| qf2_loss                | 0.0008027906  |
| time_elapsed            | 1200          |
| total timesteps         | 237100        |
| value_loss              | 5.0260354e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005921307  |
| ent_coef_loss           | 3.799557      |
| entropy                 | 2.5621343     |
| ep_rewmean              | -0.643        |
| episodes                | 2376          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 237401        |
| policy_loss             | 0.295003      |
| qf1_loss                | 0.00081273925 |
| qf2_loss                | 0.0008333576  |
| time_elapsed            | 1202          |
| total timesteps         | 237500        |
| value_loss              | 5.2361906e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005886881  |
| ent_coef_loss           | 9.183432      |
| entropy                 | 2.4195611     |
| ep_rewmean              | -0.623        |
| episodes                | 2380          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 237801        |
| policy_loss             | 0.31095305    |
| qf1_loss                | 0.00045070332 |
| qf2_loss                | 0.00041839856 |
| time_elapsed            | 1204          |
| total timesteps         | 237900        |
| value_loss              | 6.8923524e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006107941  |
| ent_coef_loss           | 0.8023343     |
| entropy                 | 2.3059192     |
| ep_rewmean              | -0.618        |
| episodes                | 2384          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 238201        |
| policy_loss             | 0.29561475    |
| qf1_loss                | 2.59695e-05   |
| qf2_loss                | 1.8935376e-05 |
| time_elapsed            | 1206          |
| total timesteps         | 238300        |
| value_loss              | 3.3393193e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006370587  |
| ent_coef_loss           | 6.9702063     |
| entropy                 | 2.9190288     |
| ep_rewmean              | -0.617        |
| episodes                | 2388          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 238601        |
| policy_loss             | 0.28544968    |
| qf1_loss                | 4.281835e-05  |
| qf2_loss                | 3.7198708e-05 |
| time_elapsed            | 1208          |
| total timesteps         | 238700        |
| value_loss              | 0.00011735812 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006007067  |
| ent_coef_loss           | 11.66112      |
| entropy                 | 2.7589457     |
| ep_rewmean              | -0.612        |
| episodes                | 2392          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 239001        |
| policy_loss             | 0.2996015     |
| qf1_loss                | 5.720442e-05  |
| qf2_loss                | 4.1241714e-05 |
| time_elapsed            | 1210          |
| total timesteps         | 239100        |
| value_loss              | 4.872976e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0005781308 |
| ent_coef_loss           | -7.2358675   |
| entropy                 | 2.8986692    |
| ep_rewmean              | -0.603       |
| episodes                | 2396         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.6         |
| n_updates               | 239401       |
| policy_loss             | 0.29838654   |
| qf1_loss                | 0.0010380461 |
| qf2_loss                | 0.0010508838 |
| time_elapsed            | 1212         |
| total timesteps         | 239500       |
| value_loss              | 5.527943e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005605598  |
| ent_coef_loss           | -7.493107     |
| entropy                 | 2.0843072     |
| ep_rewmean              | -0.599        |
| episodes                | 2400          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 239801        |
| policy_loss             | 0.31282538    |
| qf1_loss                | 0.0008627146  |
| qf2_loss                | 0.00076292054 |
| time_elapsed            | 1214          |
| total timesteps         | 239900        |
| value_loss              | 6.874085e-05  |
-------------------------------------------
Eval num_timesteps=240000, episode_reward=-0.79 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000608515   |
| ent_coef_loss           | -6.83312      |
| entropy                 | 2.6850667     |
| ep_rewmean              | -0.59         |
| episodes                | 2404          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 240201        |
| policy_loss             | 0.29731345    |
| qf1_loss                | 0.0012004433  |
| qf2_loss                | 0.0012160375  |
| time_elapsed            | 1216          |
| total timesteps         | 240300        |
| value_loss              | 5.9869257e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005779814  |
| ent_coef_loss           | -4.7528796    |
| entropy                 | 1.8952345     |
| ep_rewmean              | -0.58         |
| episodes                | 2408          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 240601        |
| policy_loss             | 0.2951917     |
| qf1_loss                | 0.00054491486 |
| qf2_loss                | 0.00055805827 |
| time_elapsed            | 1218          |
| total timesteps         | 240700        |
| value_loss              | 2.0306921e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000572206   |
| ent_coef_loss           | 11.13339      |
| entropy                 | 2.6737957     |
| ep_rewmean              | -0.568        |
| episodes                | 2412          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 241001        |
| policy_loss             | 0.3116304     |
| qf1_loss                | 0.0010534535  |
| qf2_loss                | 0.0010945756  |
| time_elapsed            | 1220          |
| total timesteps         | 241100        |
| value_loss              | 4.2312106e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005494775  |
| ent_coef_loss           | -1.679441     |
| entropy                 | 2.3753667     |
| ep_rewmean              | -0.558        |
| episodes                | 2416          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 241401        |
| policy_loss             | 0.28761485    |
| qf1_loss                | 5.577231e-05  |
| qf2_loss                | 3.0629166e-05 |
| time_elapsed            | 1222          |
| total timesteps         | 241500        |
| value_loss              | 2.915929e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00055767    |
| ent_coef_loss           | -2.8722124    |
| entropy                 | 2.7214358     |
| ep_rewmean              | -0.549        |
| episodes                | 2420          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 241801        |
| policy_loss             | 0.30282807    |
| qf1_loss                | 5.8136728e-05 |
| qf2_loss                | 7.132814e-05  |
| time_elapsed            | 1224          |
| total timesteps         | 241900        |
| value_loss              | 4.5315515e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005504352  |
| ent_coef_loss           | -0.17114353   |
| entropy                 | 1.9740539     |
| ep_rewmean              | -0.552        |
| episodes                | 2424          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 242201        |
| policy_loss             | 0.29788086    |
| qf1_loss                | 2.5214158e-05 |
| qf2_loss                | 2.9761053e-05 |
| time_elapsed            | 1226          |
| total timesteps         | 242300        |
| value_loss              | 7.337506e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005248519  |
| ent_coef_loss           | -6.39253      |
| entropy                 | 1.7798456     |
| ep_rewmean              | -0.565        |
| episodes                | 2428          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 242601        |
| policy_loss             | 0.30289686    |
| qf1_loss                | 8.9421184e-05 |
| qf2_loss                | 0.00010485946 |
| time_elapsed            | 1228          |
| total timesteps         | 242700        |
| value_loss              | 6.500677e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0004984253 |
| ent_coef_loss           | -5.1124687   |
| entropy                 | 1.4755206    |
| ep_rewmean              | -0.563       |
| episodes                | 2432         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.6         |
| n_updates               | 243001       |
| policy_loss             | 0.30394337   |
| qf1_loss                | 0.0007633602 |
| qf2_loss                | 0.0007862843 |
| time_elapsed            | 1230         |
| total timesteps         | 243100       |
| value_loss              | 2.458225e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005111454  |
| ent_coef_loss           | -2.043317     |
| entropy                 | 1.4402764     |
| ep_rewmean              | -0.565        |
| episodes                | 2436          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 243401        |
| policy_loss             | 0.28871667    |
| qf1_loss                | 0.0006064093  |
| qf2_loss                | 0.0005940741  |
| time_elapsed            | 1232          |
| total timesteps         | 243500        |
| value_loss              | 2.1831705e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005450556  |
| ent_coef_loss           | 5.9142222     |
| entropy                 | 1.0452683     |
| ep_rewmean              | -0.568        |
| episodes                | 2440          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 243801        |
| policy_loss             | 0.31363657    |
| qf1_loss                | 0.0020091285  |
| qf2_loss                | 0.0020812075  |
| time_elapsed            | 1234          |
| total timesteps         | 243900        |
| value_loss              | 3.6135374e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00056579855 |
| ent_coef_loss           | 0.33646345    |
| entropy                 | 2.0973654     |
| ep_rewmean              | -0.576        |
| episodes                | 2444          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 244201        |
| policy_loss             | 0.29550236    |
| qf1_loss                | 3.764603e-05  |
| qf2_loss                | 4.0296847e-05 |
| time_elapsed            | 1236          |
| total timesteps         | 244300        |
| value_loss              | 4.347526e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00057697855 |
| ent_coef_loss           | -1.0273347    |
| entropy                 | 2.0068026     |
| ep_rewmean              | -0.573        |
| episodes                | 2448          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 244601        |
| policy_loss             | 0.29121315    |
| qf1_loss                | 0.0010262239  |
| qf2_loss                | 0.0012815639  |
| time_elapsed            | 1238          |
| total timesteps         | 244700        |
| value_loss              | 5.2611613e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006316238  |
| ent_coef_loss           | 23.722546     |
| entropy                 | 1.720374      |
| ep_rewmean              | -0.578        |
| episodes                | 2452          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 245001        |
| policy_loss             | 0.2737381     |
| qf1_loss                | 0.00049301627 |
| qf2_loss                | 0.0005035627  |
| time_elapsed            | 1240          |
| total timesteps         | 245100        |
| value_loss              | 0.00015775379 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000740319   |
| ent_coef_loss           | 1.932801      |
| entropy                 | 1.6315595     |
| ep_rewmean              | -0.604        |
| episodes                | 2456          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 245401        |
| policy_loss             | 0.3069342     |
| qf1_loss                | 0.0009780638  |
| qf2_loss                | 0.0009947099  |
| time_elapsed            | 1242          |
| total timesteps         | 245500        |
| value_loss              | 3.4473076e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007995289  |
| ent_coef_loss           | 1.3239839     |
| entropy                 | 2.0809178     |
| ep_rewmean              | -0.617        |
| episodes                | 2460          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 245801        |
| policy_loss             | 0.27725354    |
| qf1_loss                | 0.000416267   |
| qf2_loss                | 0.00038517456 |
| time_elapsed            | 1244          |
| total timesteps         | 245900        |
| value_loss              | 2.8503619e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000793515   |
| ent_coef_loss           | -12.417259    |
| entropy                 | 2.185359      |
| ep_rewmean              | -0.624        |
| episodes                | 2464          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 246201        |
| policy_loss             | 0.28414887    |
| qf1_loss                | 3.9985338e-05 |
| qf2_loss                | 2.9842762e-05 |
| time_elapsed            | 1246          |
| total timesteps         | 246300        |
| value_loss              | 2.8927589e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00075317954 |
| ent_coef_loss           | 3.0194008     |
| entropy                 | 2.662335      |
| ep_rewmean              | -0.63         |
| episodes                | 2468          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 246601        |
| policy_loss             | 0.3205441     |
| qf1_loss                | 2.3673434e-05 |
| qf2_loss                | 3.0189178e-05 |
| time_elapsed            | 1248          |
| total timesteps         | 246700        |
| value_loss              | 4.55327e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00071503856 |
| ent_coef_loss           | 0.47972393    |
| entropy                 | 1.6926435     |
| ep_rewmean              | -0.635        |
| episodes                | 2472          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 247001        |
| policy_loss             | 0.2942819     |
| qf1_loss                | 3.7517482e-05 |
| qf2_loss                | 3.337104e-05  |
| time_elapsed            | 1251          |
| total timesteps         | 247100        |
| value_loss              | 6.8815425e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00073970505 |
| ent_coef_loss           | 6.1598444     |
| entropy                 | 2.4149542     |
| ep_rewmean              | -0.64         |
| episodes                | 2476          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 247401        |
| policy_loss             | 0.28175914    |
| qf1_loss                | 4.026648e-05  |
| qf2_loss                | 4.0532672e-05 |
| time_elapsed            | 1253          |
| total timesteps         | 247500        |
| value_loss              | 7.619379e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00080048986 |
| ent_coef_loss           | 8.318379      |
| entropy                 | 2.4679387     |
| ep_rewmean              | -0.64         |
| episodes                | 2480          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 247801        |
| policy_loss             | 0.30660543    |
| qf1_loss                | 0.0007107064  |
| qf2_loss                | 0.00064758805 |
| time_elapsed            | 1255          |
| total timesteps         | 247900        |
| value_loss              | 0.00012706431 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00091135036 |
| ent_coef_loss           | 6.6997337     |
| entropy                 | 2.795111      |
| ep_rewmean              | -0.648        |
| episodes                | 2484          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 248201        |
| policy_loss             | 0.3535285     |
| qf1_loss                | 6.9834496e-05 |
| qf2_loss                | 5.9348815e-05 |
| time_elapsed            | 1257          |
| total timesteps         | 248300        |
| value_loss              | 0.00013022678 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010144354  |
| ent_coef_loss           | 5.0759344     |
| entropy                 | 3.2583642     |
| ep_rewmean              | -0.653        |
| episodes                | 2488          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 248601        |
| policy_loss             | 0.3433956     |
| qf1_loss                | 8.0897174e-05 |
| qf2_loss                | 7.7443015e-05 |
| time_elapsed            | 1259          |
| total timesteps         | 248700        |
| value_loss              | 0.00031918386 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010142685  |
| ent_coef_loss           | -1.8195367    |
| entropy                 | 2.7797027     |
| ep_rewmean              | -0.656        |
| episodes                | 2492          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 249001        |
| policy_loss             | 0.3762357     |
| qf1_loss                | 0.005638686   |
| qf2_loss                | 0.005309848   |
| time_elapsed            | 1261          |
| total timesteps         | 249100        |
| value_loss              | 0.00011631458 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001041683   |
| ent_coef_loss           | 3.4409082     |
| entropy                 | 2.445631      |
| ep_rewmean              | -0.661        |
| episodes                | 2496          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 249401        |
| policy_loss             | 0.36852115    |
| qf1_loss                | 5.3763717e-05 |
| qf2_loss                | 5.0564242e-05 |
| time_elapsed            | 1263          |
| total timesteps         | 249500        |
| value_loss              | 0.00016594795 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010643984  |
| ent_coef_loss           | 4.8733835     |
| entropy                 | 2.5545404     |
| ep_rewmean              | -0.661        |
| episodes                | 2500          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 249801        |
| policy_loss             | 0.3427463     |
| qf1_loss                | 6.681539e-05  |
| qf2_loss                | 3.0711875e-05 |
| time_elapsed            | 1264          |
| total timesteps         | 249900        |
| value_loss              | 6.698519e-05  |
-------------------------------------------
Eval num_timesteps=250000, episode_reward=-0.46 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010410583  |
| ent_coef_loss           | 0.47395444    |
| entropy                 | 2.3377304     |
| ep_rewmean              | -0.658        |
| episodes                | 2504          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 250201        |
| policy_loss             | 0.36771476    |
| qf1_loss                | 3.9154736e-05 |
| qf2_loss                | 3.9092123e-05 |
| time_elapsed            | 1267          |
| total timesteps         | 250300        |
| value_loss              | 8.9712594e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010437166  |
| ent_coef_loss           | 3.3435907     |
| entropy                 | 2.5156693     |
| ep_rewmean              | -0.656        |
| episodes                | 2508          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 250601        |
| policy_loss             | 0.35261106    |
| qf1_loss                | 0.0012302068  |
| qf2_loss                | 0.0012184934  |
| time_elapsed            | 1269          |
| total timesteps         | 250700        |
| value_loss              | 4.8534996e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010667942  |
| ent_coef_loss           | -2.2995756    |
| entropy                 | 3.1114964     |
| ep_rewmean              | -0.663        |
| episodes                | 2512          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 251001        |
| policy_loss             | 0.3749882     |
| qf1_loss                | 0.00079210545 |
| qf2_loss                | 0.0007214582  |
| time_elapsed            | 1271          |
| total timesteps         | 251100        |
| value_loss              | 0.00013449539 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00096436864 |
| ent_coef_loss           | -3.286762     |
| entropy                 | 2.602591      |
| ep_rewmean              | -0.667        |
| episodes                | 2516          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 251401        |
| policy_loss             | 0.3845746     |
| qf1_loss                | 7.157594e-05  |
| qf2_loss                | 6.8374684e-05 |
| time_elapsed            | 1273          |
| total timesteps         | 251500        |
| value_loss              | 0.00010506429 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00094540045 |
| ent_coef_loss           | -4.4040465    |
| entropy                 | 2.7870927     |
| ep_rewmean              | -0.672        |
| episodes                | 2520          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 251801        |
| policy_loss             | 0.35682666    |
| qf1_loss                | 0.001224837   |
| qf2_loss                | 0.0011383096  |
| time_elapsed            | 1275          |
| total timesteps         | 251900        |
| value_loss              | 9.27582e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009603845  |
| ent_coef_loss           | -3.289202     |
| entropy                 | 2.502833      |
| ep_rewmean              | -0.666        |
| episodes                | 2524          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 252201        |
| policy_loss             | 0.34175736    |
| qf1_loss                | 0.00065788015 |
| qf2_loss                | 0.0006446518  |
| time_elapsed            | 1277          |
| total timesteps         | 252300        |
| value_loss              | 0.00015449821 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010156091  |
| ent_coef_loss           | 10.302462     |
| entropy                 | 2.8817163     |
| ep_rewmean              | -0.656        |
| episodes                | 2528          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 252601        |
| policy_loss             | 0.37116444    |
| qf1_loss                | 3.413909e-05  |
| qf2_loss                | 4.1462907e-05 |
| time_elapsed            | 1279          |
| total timesteps         | 252700        |
| value_loss              | 5.6519515e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009800219  |
| ent_coef_loss           | -2.4426486    |
| entropy                 | 2.5039377     |
| ep_rewmean              | -0.659        |
| episodes                | 2532          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 253001        |
| policy_loss             | 0.34981203    |
| qf1_loss                | 5.7941823e-05 |
| qf2_loss                | 4.926233e-05  |
| time_elapsed            | 1281          |
| total timesteps         | 253100        |
| value_loss              | 7.964965e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0009289122 |
| ent_coef_loss           | 5.1840925    |
| entropy                 | 2.760439     |
| ep_rewmean              | -0.673       |
| episodes                | 2536         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.7         |
| n_updates               | 253401       |
| policy_loss             | 0.39150333   |
| qf1_loss                | 0.0007812935 |
| qf2_loss                | 0.0008236428 |
| time_elapsed            | 1283         |
| total timesteps         | 253500       |
| value_loss              | 8.137288e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00090994866 |
| ent_coef_loss           | -8.697327     |
| entropy                 | 2.3634977     |
| ep_rewmean              | -0.683        |
| episodes                | 2540          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 253801        |
| policy_loss             | 0.37150848    |
| qf1_loss                | 0.0013336826  |
| qf2_loss                | 0.0013090367  |
| time_elapsed            | 1285          |
| total timesteps         | 253900        |
| value_loss              | 0.00014163236 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0008907769 |
| ent_coef_loss           | -8.712276    |
| entropy                 | 2.4383404    |
| ep_rewmean              | -0.678       |
| episodes                | 2544         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.7         |
| n_updates               | 254201       |
| policy_loss             | 0.38733488   |
| qf1_loss                | 0.0014137835 |
| qf2_loss                | 0.0014295116 |
| time_elapsed            | 1287         |
| total timesteps         | 254300       |
| value_loss              | 0.0001276535 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008036382  |
| ent_coef_loss           | -9.181051     |
| entropy                 | 2.1472344     |
| ep_rewmean              | -0.671        |
| episodes                | 2548          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 254601        |
| policy_loss             | 0.3800711     |
| qf1_loss                | 0.00072325475 |
| qf2_loss                | 0.0007254676  |
| time_elapsed            | 1289          |
| total timesteps         | 254700        |
| value_loss              | 5.457257e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007942358  |
| ent_coef_loss           | -0.04007125   |
| entropy                 | 1.8345022     |
| ep_rewmean              | -0.657        |
| episodes                | 2552          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 255001        |
| policy_loss             | 0.36338747    |
| qf1_loss                | 3.8417027e-05 |
| qf2_loss                | 2.9935674e-05 |
| time_elapsed            | 1291          |
| total timesteps         | 255100        |
| value_loss              | 8.102697e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00081024715 |
| ent_coef_loss           | 3.0868325     |
| entropy                 | 2.0147848     |
| ep_rewmean              | -0.635        |
| episodes                | 2556          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 255401        |
| policy_loss             | 0.3802292     |
| qf1_loss                | 0.0016441518  |
| qf2_loss                | 0.0016702306  |
| time_elapsed            | 1293          |
| total timesteps         | 255500        |
| value_loss              | 5.8533813e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008484562  |
| ent_coef_loss           | 1.1495347     |
| entropy                 | 2.5498183     |
| ep_rewmean              | -0.623        |
| episodes                | 2560          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 255801        |
| policy_loss             | 0.37439483    |
| qf1_loss                | 2.9795425e-05 |
| qf2_loss                | 3.9934668e-05 |
| time_elapsed            | 1295          |
| total timesteps         | 255900        |
| value_loss              | 8.2209895e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008893441  |
| ent_coef_loss           | -11.185898    |
| entropy                 | 2.3029563     |
| ep_rewmean              | -0.615        |
| episodes                | 2564          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 256201        |
| policy_loss             | 0.37185347    |
| qf1_loss                | 0.0017454564  |
| qf2_loss                | 0.0017043331  |
| time_elapsed            | 1297          |
| total timesteps         | 256300        |
| value_loss              | 4.6999103e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009040939  |
| ent_coef_loss           | 9.85791       |
| entropy                 | 2.342692      |
| ep_rewmean              | -0.614        |
| episodes                | 2568          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 256601        |
| policy_loss             | 0.3692016     |
| qf1_loss                | 5.1284813e-05 |
| qf2_loss                | 4.083926e-05  |
| time_elapsed            | 1299          |
| total timesteps         | 256700        |
| value_loss              | 5.9637463e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00091098103 |
| ent_coef_loss           | -0.79603887   |
| entropy                 | 2.6931715     |
| ep_rewmean              | -0.616        |
| episodes                | 2572          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 257001        |
| policy_loss             | 0.36817944    |
| qf1_loss                | 7.489729e-05  |
| qf2_loss                | 9.288234e-05  |
| time_elapsed            | 1301          |
| total timesteps         | 257100        |
| value_loss              | 9.514497e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00092634844 |
| ent_coef_loss           | -4.904171     |
| entropy                 | 2.3978424     |
| ep_rewmean              | -0.625        |
| episodes                | 2576          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 257401        |
| policy_loss             | 0.3472646     |
| qf1_loss                | 6.9479414e-05 |
| qf2_loss                | 6.483731e-05  |
| time_elapsed            | 1303          |
| total timesteps         | 257500        |
| value_loss              | 0.000172259   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009001364  |
| ent_coef_loss           | -6.801384     |
| entropy                 | 1.9936314     |
| ep_rewmean              | -0.639        |
| episodes                | 2580          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 257801        |
| policy_loss             | 0.36536598    |
| qf1_loss                | 6.1034025e-05 |
| qf2_loss                | 7.1064074e-05 |
| time_elapsed            | 1305          |
| total timesteps         | 257900        |
| value_loss              | 0.0001468346  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008594168  |
| ent_coef_loss           | -0.2907772    |
| entropy                 | 1.7284846     |
| ep_rewmean              | -0.647        |
| episodes                | 2584          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 258201        |
| policy_loss             | 0.33235797    |
| qf1_loss                | 0.00072983274 |
| qf2_loss                | 0.0007279014  |
| time_elapsed            | 1307          |
| total timesteps         | 258300        |
| value_loss              | 9.668582e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008751834  |
| ent_coef_loss           | 1.2150583     |
| entropy                 | 1.9939843     |
| ep_rewmean              | -0.648        |
| episodes                | 2588          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 258601        |
| policy_loss             | 0.3616339     |
| qf1_loss                | 3.1085463e-05 |
| qf2_loss                | 4.181931e-05  |
| time_elapsed            | 1309          |
| total timesteps         | 258700        |
| value_loss              | 7.0402086e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00083236705 |
| ent_coef_loss           | -11.068697    |
| entropy                 | 2.0170002     |
| ep_rewmean              | -0.646        |
| episodes                | 2592          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 259001        |
| policy_loss             | 0.3497405     |
| qf1_loss                | 0.0006955357  |
| qf2_loss                | 0.00072633586 |
| time_elapsed            | 1311          |
| total timesteps         | 259100        |
| value_loss              | 0.00010199097 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0008333762 |
| ent_coef_loss           | 9.05992      |
| entropy                 | 1.8113573    |
| ep_rewmean              | -0.648       |
| episodes                | 2596         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.6         |
| n_updates               | 259401       |
| policy_loss             | 0.34442952   |
| qf1_loss                | 0.000744664  |
| qf2_loss                | 0.0007521142 |
| time_elapsed            | 1313         |
| total timesteps         | 259500       |
| value_loss              | 6.461769e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008129399  |
| ent_coef_loss           | -6.699287     |
| entropy                 | 1.9303205     |
| ep_rewmean              | -0.651        |
| episodes                | 2600          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 259801        |
| policy_loss             | 0.36233103    |
| qf1_loss                | 0.00077413605 |
| qf2_loss                | 0.00081633055 |
| time_elapsed            | 1315          |
| total timesteps         | 259900        |
| value_loss              | 0.00014421629 |
-------------------------------------------
Eval num_timesteps=260000, episode_reward=-0.53 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00080115814 |
| ent_coef_loss           | 4.0901833     |
| entropy                 | 1.173593      |
| ep_rewmean              | -0.654        |
| episodes                | 2604          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 260201        |
| policy_loss             | 0.34365356    |
| qf1_loss                | 5.4195007e-05 |
| qf2_loss                | 6.467335e-05  |
| time_elapsed            | 1317          |
| total timesteps         | 260300        |
| value_loss              | 5.6394143e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007494087  |
| ent_coef_loss           | -1.7834041    |
| entropy                 | 0.96665406    |
| ep_rewmean              | -0.652        |
| episodes                | 2608          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 260601        |
| policy_loss             | 0.35261017    |
| qf1_loss                | 2.5577418e-05 |
| qf2_loss                | 2.7256216e-05 |
| time_elapsed            | 1319          |
| total timesteps         | 260700        |
| value_loss              | 7.8132885e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006886391  |
| ent_coef_loss           | -5.119584     |
| entropy                 | 1.0955212     |
| ep_rewmean              | -0.648        |
| episodes                | 2612          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 261001        |
| policy_loss             | 0.35095662    |
| qf1_loss                | 0.0013311222  |
| qf2_loss                | 0.0012285862  |
| time_elapsed            | 1321          |
| total timesteps         | 261100        |
| value_loss              | 3.6567726e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00066921907 |
| ent_coef_loss           | -3.2308712    |
| entropy                 | 0.8036861     |
| ep_rewmean              | -0.644        |
| episodes                | 2616          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 261401        |
| policy_loss             | 0.34196505    |
| qf1_loss                | 0.0030754686  |
| qf2_loss                | 0.003046183   |
| time_elapsed            | 1323          |
| total timesteps         | 261500        |
| value_loss              | 4.314392e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00065662386 |
| ent_coef_loss           | -3.7476776    |
| entropy                 | 0.64097154    |
| ep_rewmean              | -0.643        |
| episodes                | 2620          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 261801        |
| policy_loss             | 0.30493534    |
| qf1_loss                | 0.00028727626 |
| qf2_loss                | 0.00030138472 |
| time_elapsed            | 1325          |
| total timesteps         | 261900        |
| value_loss              | 0.00025409885 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00063907285 |
| ent_coef_loss           | -1.4187813    |
| entropy                 | 1.0739379     |
| ep_rewmean              | -0.637        |
| episodes                | 2624          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 262201        |
| policy_loss             | 0.31735432    |
| qf1_loss                | 7.881977e-05  |
| qf2_loss                | 6.3335756e-05 |
| time_elapsed            | 1327          |
| total timesteps         | 262300        |
| value_loss              | 6.860259e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00061128853 |
| ent_coef_loss           | 0.26981777    |
| entropy                 | 1.1749498     |
| ep_rewmean              | -0.633        |
| episodes                | 2628          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 262601        |
| policy_loss             | 0.34055942    |
| qf1_loss                | 2.7688406e-05 |
| qf2_loss                | 3.585822e-05  |
| time_elapsed            | 1329          |
| total timesteps         | 262700        |
| value_loss              | 4.9723418e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0005970902 |
| ent_coef_loss           | 11.120252    |
| entropy                 | 0.66859686   |
| ep_rewmean              | -0.635       |
| episodes                | 2632         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.6         |
| n_updates               | 263001       |
| policy_loss             | 0.30864048   |
| qf1_loss                | 0.0009443591 |
| qf2_loss                | 0.0010086531 |
| time_elapsed            | 1331         |
| total timesteps         | 263100       |
| value_loss              | 6.979193e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006546131  |
| ent_coef_loss           | 8.47916       |
| entropy                 | 0.6685164     |
| ep_rewmean              | -0.657        |
| episodes                | 2636          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 263401        |
| policy_loss             | 0.31284875    |
| qf1_loss                | 5.466569e-05  |
| qf2_loss                | 4.910142e-05  |
| time_elapsed            | 1333          |
| total timesteps         | 263500        |
| value_loss              | 0.00011921233 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007090686  |
| ent_coef_loss           | 7.9450493     |
| entropy                 | 1.7240188     |
| ep_rewmean              | -0.725        |
| episodes                | 2640          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 263801        |
| policy_loss             | 0.31100538    |
| qf1_loss                | 0.001613497   |
| qf2_loss                | 0.0015739868  |
| time_elapsed            | 1335          |
| total timesteps         | 263900        |
| value_loss              | 0.00012380024 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000679865   |
| ent_coef_loss           | 3.011085      |
| entropy                 | 0.57031965    |
| ep_rewmean              | -0.804        |
| episodes                | 2644          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 264201        |
| policy_loss             | 0.2769686     |
| qf1_loss                | 3.1963555e-05 |
| qf2_loss                | 4.221841e-05  |
| time_elapsed            | 1337          |
| total timesteps         | 264300        |
| value_loss              | 5.084854e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00067624834 |
| ent_coef_loss           | 0.52160007    |
| entropy                 | 0.4191778     |
| ep_rewmean              | -0.897        |
| episodes                | 2648          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 264601        |
| policy_loss             | 0.2708706     |
| qf1_loss                | 0.0007773028  |
| qf2_loss                | 0.0007133252  |
| time_elapsed            | 1339          |
| total timesteps         | 264700        |
| value_loss              | 6.118674e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00072193955 |
| ent_coef_loss           | 12.208446     |
| entropy                 | 0.85824543    |
| ep_rewmean              | -0.919        |
| episodes                | 2652          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 265001        |
| policy_loss             | 0.26568148    |
| qf1_loss                | 3.9039693e-05 |
| qf2_loss                | 3.555359e-05  |
| time_elapsed            | 1341          |
| total timesteps         | 265100        |
| value_loss              | 6.68066e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008091371  |
| ent_coef_loss           | 3.272861      |
| entropy                 | 1.186269      |
| ep_rewmean              | -0.93         |
| episodes                | 2656          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 265401        |
| policy_loss             | 0.22815877    |
| qf1_loss                | 0.00017683717 |
| qf2_loss                | 0.00018132286 |
| time_elapsed            | 1343          |
| total timesteps         | 265500        |
| value_loss              | 7.78965e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00088066986 |
| ent_coef_loss           | 7.9574113     |
| entropy                 | 1.7552342     |
| ep_rewmean              | -0.942        |
| episodes                | 2660          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 265801        |
| policy_loss             | 0.20755544    |
| qf1_loss                | 0.00011968633 |
| qf2_loss                | 8.27896e-05   |
| time_elapsed            | 1345          |
| total timesteps         | 265900        |
| value_loss              | 0.00011931549 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009237231  |
| ent_coef_loss           | -1.5412141    |
| entropy                 | 2.2643433     |
| ep_rewmean              | -0.944        |
| episodes                | 2664          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 266201        |
| policy_loss             | 0.1340147     |
| qf1_loss                | 0.0007367813  |
| qf2_loss                | 0.0009797697  |
| time_elapsed            | 1347          |
| total timesteps         | 266300        |
| value_loss              | 0.00012941158 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0009640431 |
| ent_coef_loss           | -0.83096945  |
| entropy                 | 2.0668843    |
| ep_rewmean              | -0.937       |
| episodes                | 2668         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.9         |
| n_updates               | 266601       |
| policy_loss             | 0.15718745   |
| qf1_loss                | 6.856247e-05 |
| qf2_loss                | 4.824948e-05 |
| time_elapsed            | 1349         |
| total timesteps         | 266700       |
| value_loss              | 6.429224e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009828833  |
| ent_coef_loss           | -1.8383355    |
| entropy                 | 2.54361       |
| ep_rewmean              | -0.961        |
| episodes                | 2672          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 267001        |
| policy_loss             | 0.16062623    |
| qf1_loss                | 0.0017383405  |
| qf2_loss                | 0.0012474407  |
| time_elapsed            | 1351          |
| total timesteps         | 267100        |
| value_loss              | 0.00015574138 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009802     |
| ent_coef_loss           | 1.9025327     |
| entropy                 | 2.3652902     |
| ep_rewmean              | -0.978        |
| episodes                | 2676          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 267401        |
| policy_loss             | 0.17272606    |
| qf1_loss                | 4.595353e-05  |
| qf2_loss                | 6.537858e-05  |
| time_elapsed            | 1353          |
| total timesteps         | 267500        |
| value_loss              | 0.00012230163 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00089452096 |
| ent_coef_loss           | -5.2210817    |
| entropy                 | 2.4892304     |
| ep_rewmean              | -0.967        |
| episodes                | 2680          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 267801        |
| policy_loss             | 0.125631      |
| qf1_loss                | 0.0006082051  |
| qf2_loss                | 0.00056953984 |
| time_elapsed            | 1355          |
| total timesteps         | 267900        |
| value_loss              | 4.379359e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008094698  |
| ent_coef_loss           | -5.4554815    |
| entropy                 | 2.3634543     |
| ep_rewmean              | -0.952        |
| episodes                | 2684          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 268201        |
| policy_loss             | 0.07674683    |
| qf1_loss                | 4.3720196e-05 |
| qf2_loss                | 4.0872597e-05 |
| time_elapsed            | 1357          |
| total timesteps         | 268300        |
| value_loss              | 3.8534065e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007771377  |
| ent_coef_loss           | 4.7110257     |
| entropy                 | 2.8915272     |
| ep_rewmean              | -0.948        |
| episodes                | 2688          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 268601        |
| policy_loss             | 0.09030749    |
| qf1_loss                | 5.3758966e-05 |
| qf2_loss                | 5.5916065e-05 |
| time_elapsed            | 1359          |
| total timesteps         | 268700        |
| value_loss              | 4.525677e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007524835  |
| ent_coef_loss           | 6.378108      |
| entropy                 | 2.728074      |
| ep_rewmean              | -0.951        |
| episodes                | 2692          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 269001        |
| policy_loss             | 0.08026287    |
| qf1_loss                | 3.0246367e-05 |
| qf2_loss                | 3.9875515e-05 |
| time_elapsed            | 1361          |
| total timesteps         | 269100        |
| value_loss              | 4.096941e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00074795814 |
| ent_coef_loss           | -5.8311563    |
| entropy                 | 3.34267       |
| ep_rewmean              | -0.952        |
| episodes                | 2696          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 269401        |
| policy_loss             | 0.06557757    |
| qf1_loss                | 0.0004000824  |
| qf2_loss                | 0.00036745323 |
| time_elapsed            | 1363          |
| total timesteps         | 269500        |
| value_loss              | 7.90668e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00076099636 |
| ent_coef_loss           | 4.5855436     |
| entropy                 | 3.2322807     |
| ep_rewmean              | -0.953        |
| episodes                | 2700          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 269801        |
| policy_loss             | 0.05339061    |
| qf1_loss                | 2.4637553e-05 |
| qf2_loss                | 2.8319619e-05 |
| time_elapsed            | 1365          |
| total timesteps         | 269900        |
| value_loss              | 8.518316e-05  |
-------------------------------------------
Eval num_timesteps=270000, episode_reward=-0.62 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008605203  |
| ent_coef_loss           | 6.44516       |
| entropy                 | 3.414421      |
| ep_rewmean              | -0.956        |
| episodes                | 2704          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 270201        |
| policy_loss             | 0.06529773    |
| qf1_loss                | 2.4898754e-05 |
| qf2_loss                | 2.2049102e-05 |
| time_elapsed            | 1368          |
| total timesteps         | 270300        |
| value_loss              | 5.9381324e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008825692  |
| ent_coef_loss           | 5.157037      |
| entropy                 | 3.091355      |
| ep_rewmean              | -0.967        |
| episodes                | 2708          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 270601        |
| policy_loss             | 0.10727951    |
| qf1_loss                | 0.00028157767 |
| qf2_loss                | 0.00042120603 |
| time_elapsed            | 1370          |
| total timesteps         | 270700        |
| value_loss              | 9.396981e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00081951043 |
| ent_coef_loss           | -9.98148      |
| entropy                 | 3.4077008     |
| ep_rewmean              | -0.988        |
| episodes                | 2712          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 271001        |
| policy_loss             | 0.1043345     |
| qf1_loss                | 2.0235642e-05 |
| qf2_loss                | 2.142597e-05  |
| time_elapsed            | 1372          |
| total timesteps         | 271100        |
| value_loss              | 8.521292e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00070258573 |
| ent_coef_loss           | -17.244316    |
| entropy                 | 3.4778702     |
| ep_rewmean              | -1.02         |
| episodes                | 2716          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 271401        |
| policy_loss             | 0.089968175   |
| qf1_loss                | 1.4788991e-05 |
| qf2_loss                | 2.956757e-05  |
| time_elapsed            | 1374          |
| total timesteps         | 271500        |
| value_loss              | 4.7159392e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0006125336 |
| ent_coef_loss           | -10.6041355  |
| entropy                 | 2.9854417    |
| ep_rewmean              | -1.04        |
| episodes                | 2720         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -1           |
| n_updates               | 271801       |
| policy_loss             | 0.11663337   |
| qf1_loss                | 0.0010081339 |
| qf2_loss                | 0.0010174421 |
| time_elapsed            | 1376         |
| total timesteps         | 271900       |
| value_loss              | 4.074318e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00053376803 |
| ent_coef_loss           | -5.835203     |
| entropy                 | 2.6756082     |
| ep_rewmean              | -1.06         |
| episodes                | 2724          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.1          |
| n_updates               | 272201        |
| policy_loss             | 0.11574895    |
| qf1_loss                | 5.1142735e-05 |
| qf2_loss                | 3.6607806e-05 |
| time_elapsed            | 1378          |
| total timesteps         | 272300        |
| value_loss              | 3.0917436e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004764256  |
| ent_coef_loss           | -2.4272892    |
| entropy                 | 2.3955708     |
| ep_rewmean              | -1.07         |
| episodes                | 2728          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.1          |
| n_updates               | 272601        |
| policy_loss             | 0.11627812    |
| qf1_loss                | 2.106457e-05  |
| qf2_loss                | 1.8830598e-05 |
| time_elapsed            | 1380          |
| total timesteps         | 272700        |
| value_loss              | 2.782406e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000427375   |
| ent_coef_loss           | 1.8695188     |
| entropy                 | 2.144789      |
| ep_rewmean              | -1.08         |
| episodes                | 2732          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1.1          |
| n_updates               | 273001        |
| policy_loss             | 0.12940687    |
| qf1_loss                | 3.785696e-05  |
| qf2_loss                | 2.3375374e-05 |
| time_elapsed            | 1382          |
| total timesteps         | 273100        |
| value_loss              | 2.055133e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00041712722 |
| ent_coef_loss           | 8.781998      |
| entropy                 | 2.4809532     |
| ep_rewmean              | -1.04         |
| episodes                | 2736          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 273401        |
| policy_loss             | 0.12812582    |
| qf1_loss                | 5.1067247e-05 |
| qf2_loss                | 5.2393098e-05 |
| time_elapsed            | 1384          |
| total timesteps         | 273500        |
| value_loss              | 5.9831735e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00041863185 |
| ent_coef_loss           | -3.7119076    |
| entropy                 | 3.1029468     |
| ep_rewmean              | -0.957        |
| episodes                | 2740          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -1            |
| n_updates               | 273801        |
| policy_loss             | 0.13272724    |
| qf1_loss                | 0.0011432803  |
| qf2_loss                | 0.0011348247  |
| time_elapsed            | 1386          |
| total timesteps         | 273900        |
| value_loss              | 4.3944627e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004191318  |
| ent_coef_loss           | 11.320427     |
| entropy                 | 2.6023533     |
| ep_rewmean              | -0.872        |
| episodes                | 2744          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.9          |
| n_updates               | 274201        |
| policy_loss             | 0.13912584    |
| qf1_loss                | 2.8827988e-05 |
| qf2_loss                | 2.8992974e-05 |
| time_elapsed            | 1388          |
| total timesteps         | 274300        |
| value_loss              | 4.1771236e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00051386486  |
| ent_coef_loss           | 10.682167      |
| entropy                 | 2.877822       |
| ep_rewmean              | -0.787         |
| episodes                | 2748           |
| eplenmean               | 100            |
| fps                     | 197            |
| mean 100 episode reward | -0.8           |
| n_updates               | 274601         |
| policy_loss             | 0.15426907     |
| qf1_loss                | 0.000110692046 |
| qf2_loss                | 0.00012778968  |
| time_elapsed            | 1390           |
| total timesteps         | 274700         |
| value_loss              | 3.3884484e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00053170964 |
| ent_coef_loss           | -7.0447083    |
| entropy                 | 3.0621264     |
| ep_rewmean              | -0.759        |
| episodes                | 2752          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.8          |
| n_updates               | 275001        |
| policy_loss             | 0.17748213    |
| qf1_loss                | 2.157966e-05  |
| qf2_loss                | 2.1924465e-05 |
| time_elapsed            | 1392          |
| total timesteps         | 275100        |
| value_loss              | 3.9716022e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005451518  |
| ent_coef_loss           | -8.471058     |
| entropy                 | 3.2366757     |
| ep_rewmean              | -0.739        |
| episodes                | 2756          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 275401        |
| policy_loss             | 0.17105246    |
| qf1_loss                | 2.9772975e-05 |
| qf2_loss                | 2.984093e-05  |
| time_elapsed            | 1394          |
| total timesteps         | 275500        |
| value_loss              | 2.445374e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005469445  |
| ent_coef_loss           | 7.1915407     |
| entropy                 | 3.2911851     |
| ep_rewmean              | -0.726        |
| episodes                | 2760          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 275801        |
| policy_loss             | 0.19079798    |
| qf1_loss                | 1.844448e-05  |
| qf2_loss                | 2.4790768e-05 |
| time_elapsed            | 1396          |
| total timesteps         | 275900        |
| value_loss              | 3.6583107e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005531448  |
| ent_coef_loss           | -14.478584    |
| entropy                 | 3.5575404     |
| ep_rewmean              | -0.727        |
| episodes                | 2764          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 276201        |
| policy_loss             | 0.20868756    |
| qf1_loss                | 0.00030573833 |
| qf2_loss                | 0.0003122078  |
| time_elapsed            | 1398          |
| total timesteps         | 276300        |
| value_loss              | 5.0494917e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005212194  |
| ent_coef_loss           | 1.6638517     |
| entropy                 | 2.8602905     |
| ep_rewmean              | -0.73         |
| episodes                | 2768          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 276601        |
| policy_loss             | 0.2155928     |
| qf1_loss                | 0.0012086787  |
| qf2_loss                | 0.0011825331  |
| time_elapsed            | 1400          |
| total timesteps         | 276700        |
| value_loss              | 4.4471533e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00048886065 |
| ent_coef_loss           | -1.7642094    |
| entropy                 | 2.4558787     |
| ep_rewmean              | -0.704        |
| episodes                | 2772          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 277001        |
| policy_loss             | 0.2235224     |
| qf1_loss                | 0.00070057425 |
| qf2_loss                | 0.0006872658  |
| time_elapsed            | 1402          |
| total timesteps         | 277100        |
| value_loss              | 5.6698154e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00046224115 |
| ent_coef_loss           | -2.3236265    |
| entropy                 | 2.36382       |
| ep_rewmean              | -0.672        |
| episodes                | 2776          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 277401        |
| policy_loss             | 0.21605995    |
| qf1_loss                | 0.0002294862  |
| qf2_loss                | 0.00022899342 |
| time_elapsed            | 1404          |
| total timesteps         | 277500        |
| value_loss              | 1.5976932e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004485492  |
| ent_coef_loss           | 0.33338428    |
| entropy                 | 2.3208728     |
| ep_rewmean              | -0.669        |
| episodes                | 2780          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 277801        |
| policy_loss             | 0.2331501     |
| qf1_loss                | 0.0013053024  |
| qf2_loss                | 0.0012423747  |
| time_elapsed            | 1406          |
| total timesteps         | 277900        |
| value_loss              | 3.9071136e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.000475173  |
| ent_coef_loss           | 8.027089     |
| entropy                 | 1.9648883    |
| ep_rewmean              | -0.684       |
| episodes                | 2784         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.7         |
| n_updates               | 278201       |
| policy_loss             | 0.24383618   |
| qf1_loss                | 6.246221e-05 |
| qf2_loss                | 6.537483e-05 |
| time_elapsed            | 1408         |
| total timesteps         | 278300       |
| value_loss              | 8.585685e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005273181  |
| ent_coef_loss           | 0.7367954     |
| entropy                 | 2.2786126     |
| ep_rewmean              | -0.718        |
| episodes                | 2788          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 278601        |
| policy_loss             | 0.24138594    |
| qf1_loss                | 3.320852e-05  |
| qf2_loss                | 2.4808245e-05 |
| time_elapsed            | 1410          |
| total timesteps         | 278700        |
| value_loss              | 1.4573595e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005314085  |
| ent_coef_loss           | -3.8372202    |
| entropy                 | 2.8264296     |
| ep_rewmean              | -0.726        |
| episodes                | 2792          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 279001        |
| policy_loss             | 0.25278965    |
| qf1_loss                | 2.5099882e-05 |
| qf2_loss                | 2.6783697e-05 |
| time_elapsed            | 1412          |
| total timesteps         | 279100        |
| value_loss              | 9.8375174e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005386167  |
| ent_coef_loss           | -1.3659568    |
| entropy                 | 3.7787628     |
| ep_rewmean              | -0.725        |
| episodes                | 2796          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 279401        |
| policy_loss             | 0.25035533    |
| qf1_loss                | 0.0020758647  |
| qf2_loss                | 0.001976568   |
| time_elapsed            | 1414          |
| total timesteps         | 279500        |
| value_loss              | 0.00016485478 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000511377   |
| ent_coef_loss           | -3.6785614    |
| entropy                 | 3.6945205     |
| ep_rewmean              | -0.719        |
| episodes                | 2800          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 279801        |
| policy_loss             | 0.24516678    |
| qf1_loss                | 0.00039869727 |
| qf2_loss                | 0.00038051285 |
| time_elapsed            | 1416          |
| total timesteps         | 279900        |
| value_loss              | 2.89382e-05   |
-------------------------------------------
Eval num_timesteps=280000, episode_reward=-1.19 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0004361986 |
| ent_coef_loss           | -16.840494   |
| entropy                 | 2.741198     |
| ep_rewmean              | -0.724       |
| episodes                | 2804         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.7         |
| n_updates               | 280201       |
| policy_loss             | 0.24158075   |
| qf1_loss                | 3.953637e-05 |
| qf2_loss                | 3.526258e-05 |
| time_elapsed            | 1419         |
| total timesteps         | 280300       |
| value_loss              | 2.61358e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00042123717 |
| ent_coef_loss           | -1.1269022    |
| entropy                 | 2.7662137     |
| ep_rewmean              | -0.71         |
| episodes                | 2808          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 280601        |
| policy_loss             | 0.23687637    |
| qf1_loss                | 2.792598e-05  |
| qf2_loss                | 3.076382e-05  |
| time_elapsed            | 1421          |
| total timesteps         | 280700        |
| value_loss              | 2.108763e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0004192985 |
| ent_coef_loss           | -1.574002    |
| entropy                 | 2.4631977    |
| ep_rewmean              | -0.686       |
| episodes                | 2812         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.7         |
| n_updates               | 281001       |
| policy_loss             | 0.22563514   |
| qf1_loss                | 0.0014869747 |
| qf2_loss                | 0.0014857533 |
| time_elapsed            | 1423         |
| total timesteps         | 281100       |
| value_loss              | 1.695921e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00041576856 |
| ent_coef_loss           | 10.132495     |
| entropy                 | 2.4256294     |
| ep_rewmean              | -0.655        |
| episodes                | 2816          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 281401        |
| policy_loss             | 0.24402604    |
| qf1_loss                | 0.00057600887 |
| qf2_loss                | 0.0005771316  |
| time_elapsed            | 1425          |
| total timesteps         | 281500        |
| value_loss              | 3.851336e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004375946  |
| ent_coef_loss           | -1.5720086    |
| entropy                 | 2.0147376     |
| ep_rewmean              | -0.628        |
| episodes                | 2820          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 281801        |
| policy_loss             | 0.21505746    |
| qf1_loss                | 0.0003948783  |
| qf2_loss                | 0.00041436925 |
| time_elapsed            | 1427          |
| total timesteps         | 281900        |
| value_loss              | 1.8591869e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00045467677 |
| ent_coef_loss           | 4.0943265     |
| entropy                 | 2.503428      |
| ep_rewmean              | -0.606        |
| episodes                | 2824          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 282201        |
| policy_loss             | 0.22928467    |
| qf1_loss                | 2.0536567e-05 |
| qf2_loss                | 2.2552704e-05 |
| time_elapsed            | 1429          |
| total timesteps         | 282300        |
| value_loss              | 4.5756322e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00044711353 |
| ent_coef_loss           | 5.7377005     |
| entropy                 | 2.8065748     |
| ep_rewmean              | -0.603        |
| episodes                | 2828          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 282601        |
| policy_loss             | 0.2191669     |
| qf1_loss                | 3.265464e-05  |
| qf2_loss                | 3.561812e-05  |
| time_elapsed            | 1431          |
| total timesteps         | 282700        |
| value_loss              | 3.4458077e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00041717058 |
| ent_coef_loss           | -15.58461     |
| entropy                 | 2.7631512     |
| ep_rewmean              | -0.597        |
| episodes                | 2832          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 283001        |
| policy_loss             | 0.20625016    |
| qf1_loss                | 4.9312475e-05 |
| qf2_loss                | 4.128815e-05  |
| time_elapsed            | 1433          |
| total timesteps         | 283100        |
| value_loss              | 2.8318278e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00039492623 |
| ent_coef_loss           | -12.359459    |
| entropy                 | 3.376491      |
| ep_rewmean              | -0.596        |
| episodes                | 2836          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 283401        |
| policy_loss             | 0.19981854    |
| qf1_loss                | 0.00038006523 |
| qf2_loss                | 0.0003732849  |
| time_elapsed            | 1435          |
| total timesteps         | 283500        |
| value_loss              | 1.5282822e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000378222   |
| ent_coef_loss           | -8.750987     |
| entropy                 | 3.0308213     |
| ep_rewmean              | -0.594        |
| episodes                | 2840          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 283801        |
| policy_loss             | 0.19795296    |
| qf1_loss                | 0.0002628541  |
| qf2_loss                | 0.0002622914  |
| time_elapsed            | 1437          |
| total timesteps         | 283900        |
| value_loss              | 3.2675234e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003662801  |
| ent_coef_loss           | -1.673427     |
| entropy                 | 2.397707      |
| ep_rewmean              | -0.594        |
| episodes                | 2844          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 284201        |
| policy_loss             | 0.20622794    |
| qf1_loss                | 0.0004842941  |
| qf2_loss                | 0.00049354904 |
| time_elapsed            | 1439          |
| total timesteps         | 284300        |
| value_loss              | 2.5902533e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003677286  |
| ent_coef_loss           | -1.5390267    |
| entropy                 | 2.400074      |
| ep_rewmean              | -0.582        |
| episodes                | 2848          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 284601        |
| policy_loss             | 0.18439993    |
| qf1_loss                | 0.00012781883 |
| qf2_loss                | 0.00012413604 |
| time_elapsed            | 1441          |
| total timesteps         | 284700        |
| value_loss              | 4.4139753e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00037195982 |
| ent_coef_loss           | -8.609488     |
| entropy                 | 2.9188461     |
| ep_rewmean              | -0.576        |
| episodes                | 2852          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 285001        |
| policy_loss             | 0.18673559    |
| qf1_loss                | 0.0007813027  |
| qf2_loss                | 0.00080708246 |
| time_elapsed            | 1443          |
| total timesteps         | 285100        |
| value_loss              | 2.0521744e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003698153  |
| ent_coef_loss           | -4.163377     |
| entropy                 | 3.0079784     |
| ep_rewmean              | -0.571        |
| episodes                | 2856          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 285401        |
| policy_loss             | 0.19805758    |
| qf1_loss                | 0.00026583337 |
| qf2_loss                | 0.00025444696 |
| time_elapsed            | 1445          |
| total timesteps         | 285500        |
| value_loss              | 2.1108823e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00035896566 |
| ent_coef_loss           | 2.6915815     |
| entropy                 | 2.3681223     |
| ep_rewmean              | -0.566        |
| episodes                | 2860          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 285801        |
| policy_loss             | 0.19139442    |
| qf1_loss                | 0.0002273048  |
| qf2_loss                | 0.00021465894 |
| time_elapsed            | 1447          |
| total timesteps         | 285900        |
| value_loss              | 1.9179035e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00036434774 |
| ent_coef_loss           | 14.330357     |
| entropy                 | 2.6676188     |
| ep_rewmean              | -0.555        |
| episodes                | 2864          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 286201        |
| policy_loss             | 0.20221785    |
| qf1_loss                | 0.00027615033 |
| qf2_loss                | 0.00027509392 |
| time_elapsed            | 1449          |
| total timesteps         | 286300        |
| value_loss              | 1.9487501e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00038746593 |
| ent_coef_loss           | -8.720749     |
| entropy                 | 2.7358465     |
| ep_rewmean              | -0.557        |
| episodes                | 2868          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 286601        |
| policy_loss             | 0.18870719    |
| qf1_loss                | 2.032157e-05  |
| qf2_loss                | 2.3883833e-05 |
| time_elapsed            | 1451          |
| total timesteps         | 286700        |
| value_loss              | 2.4296512e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003823331  |
| ent_coef_loss           | -7.258853     |
| entropy                 | 2.7622662     |
| ep_rewmean              | -0.55         |
| episodes                | 2872          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 287001        |
| policy_loss             | 0.1969631     |
| qf1_loss                | 1.5474223e-05 |
| qf2_loss                | 1.0446651e-05 |
| time_elapsed            | 1453          |
| total timesteps         | 287100        |
| value_loss              | 1.52759e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00037462055 |
| ent_coef_loss           | 6.6128654     |
| entropy                 | 3.2097232     |
| ep_rewmean              | -0.551        |
| episodes                | 2876          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 287401        |
| policy_loss             | 0.21436775    |
| qf1_loss                | 2.717134e-05  |
| qf2_loss                | 1.208588e-05  |
| time_elapsed            | 1455          |
| total timesteps         | 287500        |
| value_loss              | 2.987474e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0003693816   |
| ent_coef_loss           | -10.823679     |
| entropy                 | 2.583236       |
| ep_rewmean              | -0.549         |
| episodes                | 2880           |
| eplenmean               | 100            |
| fps                     | 197            |
| mean 100 episode reward | -0.5           |
| n_updates               | 287801         |
| policy_loss             | 0.20102216     |
| qf1_loss                | 1.48378895e-05 |
| qf2_loss                | 1.1355251e-05  |
| time_elapsed            | 1457           |
| total timesteps         | 287900         |
| value_loss              | 1.1132181e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000354067   |
| ent_coef_loss           | -1.9295292    |
| entropy                 | 2.265968      |
| ep_rewmean              | -0.532        |
| episodes                | 2884          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 288201        |
| policy_loss             | 0.20641962    |
| qf1_loss                | 0.00038260486 |
| qf2_loss                | 0.00036423374 |
| time_elapsed            | 1459          |
| total timesteps         | 288300        |
| value_loss              | 1.6331813e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00034230488 |
| ent_coef_loss           | -5.3558354    |
| entropy                 | 2.5098248     |
| ep_rewmean              | -0.497        |
| episodes                | 2888          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 288601        |
| policy_loss             | 0.20425788    |
| qf1_loss                | 2.243805e-05  |
| qf2_loss                | 1.5967438e-05 |
| time_elapsed            | 1461          |
| total timesteps         | 288700        |
| value_loss              | 3.1663905e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003297645  |
| ent_coef_loss           | 9.707922      |
| entropy                 | 2.3733506     |
| ep_rewmean              | -0.489        |
| episodes                | 2892          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 289001        |
| policy_loss             | 0.21005775    |
| qf1_loss                | 3.7514787e-05 |
| qf2_loss                | 2.7272285e-05 |
| time_elapsed            | 1463          |
| total timesteps         | 289100        |
| value_loss              | 5.1671483e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00031296836 |
| ent_coef_loss           | 0.3081684     |
| entropy                 | 2.3771145     |
| ep_rewmean              | -0.483        |
| episodes                | 2896          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 289401        |
| policy_loss             | 0.20820013    |
| qf1_loss                | 0.0005164133  |
| qf2_loss                | 0.00048604948 |
| time_elapsed            | 1465          |
| total timesteps         | 289500        |
| value_loss              | 2.7578528e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00031003452 |
| ent_coef_loss           | 3.1752334     |
| entropy                 | 1.6575372     |
| ep_rewmean              | -0.48         |
| episodes                | 2900          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 289801        |
| policy_loss             | 0.22465885    |
| qf1_loss                | 0.0004233702  |
| qf2_loss                | 0.000439961   |
| time_elapsed            | 1467          |
| total timesteps         | 289900        |
| value_loss              | 1.5140724e-05 |
-------------------------------------------
Eval num_timesteps=290000, episode_reward=-0.42 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003132625  |
| ent_coef_loss           | -10.27914     |
| entropy                 | 2.0781507     |
| ep_rewmean              | -0.464        |
| episodes                | 2904          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 290201        |
| policy_loss             | 0.20911327    |
| qf1_loss                | 0.0007172798  |
| qf2_loss                | 0.00072105235 |
| time_elapsed            | 1469          |
| total timesteps         | 290300        |
| value_loss              | 1.5049989e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00029497774 |
| ent_coef_loss           | -12.073124    |
| entropy                 | 1.6736766     |
| ep_rewmean              | -0.465        |
| episodes                | 2908          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 290601        |
| policy_loss             | 0.2174719     |
| qf1_loss                | 1.2249114e-05 |
| qf2_loss                | 1.3458448e-05 |
| time_elapsed            | 1471          |
| total timesteps         | 290700        |
| value_loss              | 1.7473067e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00028577712 |
| ent_coef_loss           | 15.67872      |
| entropy                 | 1.0390332     |
| ep_rewmean              | -0.467        |
| episodes                | 2912          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 291001        |
| policy_loss             | 0.2149955     |
| qf1_loss                | 2.6093328e-05 |
| qf2_loss                | 3.370759e-05  |
| time_elapsed            | 1473          |
| total timesteps         | 291100        |
| value_loss              | 1.727456e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00029821217 |
| ent_coef_loss           | 3.9469204     |
| entropy                 | 0.37586045    |
| ep_rewmean              | -0.473        |
| episodes                | 2916          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 291401        |
| policy_loss             | 0.21121672    |
| qf1_loss                | 0.0007670473  |
| qf2_loss                | 0.0007940925  |
| time_elapsed            | 1476          |
| total timesteps         | 291500        |
| value_loss              | 2.4148596e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003237995  |
| ent_coef_loss           | 7.010182      |
| entropy                 | 1.1212152     |
| ep_rewmean              | -0.491        |
| episodes                | 2920          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 291801        |
| policy_loss             | 0.21319345    |
| qf1_loss                | 1.7898481e-05 |
| qf2_loss                | 1.2673355e-05 |
| time_elapsed            | 1478          |
| total timesteps         | 291900        |
| value_loss              | 3.6150785e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003340229  |
| ent_coef_loss           | 2.9543219     |
| entropy                 | 1.5027313     |
| ep_rewmean              | -0.499        |
| episodes                | 2924          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 292201        |
| policy_loss             | 0.22393435    |
| qf1_loss                | 1.5603091e-05 |
| qf2_loss                | 1.5132909e-05 |
| time_elapsed            | 1480          |
| total timesteps         | 292300        |
| value_loss              | 2.562819e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033898413 |
| ent_coef_loss           | -1.6118064    |
| entropy                 | 1.990387      |
| ep_rewmean              | -0.492        |
| episodes                | 2928          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 292601        |
| policy_loss             | 0.21252243    |
| qf1_loss                | 6.038855e-05  |
| qf2_loss                | 6.289003e-05  |
| time_elapsed            | 1482          |
| total timesteps         | 292700        |
| value_loss              | 4.437795e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00032635682 |
| ent_coef_loss           | -11.116562    |
| entropy                 | 1.7922496     |
| ep_rewmean              | -0.487        |
| episodes                | 2932          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 293001        |
| policy_loss             | 0.2046175     |
| qf1_loss                | 1.8099841e-05 |
| qf2_loss                | 1.5186839e-05 |
| time_elapsed            | 1484          |
| total timesteps         | 293100        |
| value_loss              | 2.1889098e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00034009415  |
| ent_coef_loss           | -2.1724186     |
| entropy                 | 1.8323312      |
| ep_rewmean              | -0.493         |
| episodes                | 2936           |
| eplenmean               | 100            |
| fps                     | 197            |
| mean 100 episode reward | -0.5           |
| n_updates               | 293401         |
| policy_loss             | 0.20920557     |
| qf1_loss                | 1.1016142e-05  |
| qf2_loss                | 1.34141055e-05 |
| time_elapsed            | 1486           |
| total timesteps         | 293500         |
| value_loss              | 2.6850215e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00034611137 |
| ent_coef_loss           | 4.054554      |
| entropy                 | 1.7272698     |
| ep_rewmean              | -0.501        |
| episodes                | 2940          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 293801        |
| policy_loss             | 0.20542145    |
| qf1_loss                | 0.0001600896  |
| qf2_loss                | 0.00016172077 |
| time_elapsed            | 1488          |
| total timesteps         | 293900        |
| value_loss              | 1.9097026e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0003553699 |
| ent_coef_loss           | -2.3165848   |
| entropy                 | 2.7595687    |
| ep_rewmean              | -0.504       |
| episodes                | 2944         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.5         |
| n_updates               | 294201       |
| policy_loss             | 0.20682399   |
| qf1_loss                | 0.0006237047 |
| qf2_loss                | 0.0006225342 |
| time_elapsed            | 1490         |
| total timesteps         | 294300       |
| value_loss              | 3.062139e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000344824   |
| ent_coef_loss           | -0.622571     |
| entropy                 | 1.6110175     |
| ep_rewmean              | -0.505        |
| episodes                | 2948          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 294601        |
| policy_loss             | 0.19133817    |
| qf1_loss                | 0.0005016448  |
| qf2_loss                | 0.0004983719  |
| time_elapsed            | 1492          |
| total timesteps         | 294700        |
| value_loss              | 3.9758936e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00032418416 |
| ent_coef_loss           | -3.5498633    |
| entropy                 | 1.5469934     |
| ep_rewmean              | -0.509        |
| episodes                | 2952          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 295001        |
| policy_loss             | 0.19369435    |
| qf1_loss                | 0.00034224192 |
| qf2_loss                | 0.00036043866 |
| time_elapsed            | 1494          |
| total timesteps         | 295100        |
| value_loss              | 1.9157782e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0002958624  |
| ent_coef_loss           | -5.144028     |
| entropy                 | 1.5024371     |
| ep_rewmean              | -0.517        |
| episodes                | 2956          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 295401        |
| policy_loss             | 0.20543158    |
| qf1_loss                | 2.8675806e-05 |
| qf2_loss                | 1.9415196e-05 |
| time_elapsed            | 1496          |
| total timesteps         | 295500        |
| value_loss              | 2.1280277e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00027328453  |
| ent_coef_loss           | -10.263162     |
| entropy                 | 1.998111       |
| ep_rewmean              | -0.519         |
| episodes                | 2960           |
| eplenmean               | 100            |
| fps                     | 197            |
| mean 100 episode reward | -0.5           |
| n_updates               | 295801         |
| policy_loss             | 0.1913963      |
| qf1_loss                | 0.00025408407  |
| qf2_loss                | 0.00023353111  |
| time_elapsed            | 1499           |
| total timesteps         | 295900         |
| value_loss              | 1.51682225e-05 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00026208482 |
| ent_coef_loss           | -2.1637905    |
| entropy                 | 1.7229495     |
| ep_rewmean              | -0.521        |
| episodes                | 2964          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 296201        |
| policy_loss             | 0.19368097    |
| qf1_loss                | 2.1446534e-05 |
| qf2_loss                | 2.2198834e-05 |
| time_elapsed            | 1501          |
| total timesteps         | 296300        |
| value_loss              | 1.8757532e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00025209066 |
| ent_coef_loss           | 9.929381      |
| entropy                 | 1.0665609     |
| ep_rewmean              | -0.515        |
| episodes                | 2968          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 296601        |
| policy_loss             | 0.19925585    |
| qf1_loss                | 1.2677478e-05 |
| qf2_loss                | 1.2360326e-05 |
| time_elapsed            | 1503          |
| total timesteps         | 296700        |
| value_loss              | 1.5994872e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00028684802 |
| ent_coef_loss           | 9.891828      |
| entropy                 | 0.8195847     |
| ep_rewmean              | -0.524        |
| episodes                | 2972          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 297001        |
| policy_loss             | 0.18886977    |
| qf1_loss                | 3.0792253e-05 |
| qf2_loss                | 3.107202e-05  |
| time_elapsed            | 1505          |
| total timesteps         | 297100        |
| value_loss              | 1.2772577e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00030517433 |
| ent_coef_loss           | 11.984257     |
| entropy                 | 1.3497694     |
| ep_rewmean              | -0.533        |
| episodes                | 2976          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 297401        |
| policy_loss             | 0.17335549    |
| qf1_loss                | 0.00083924155 |
| qf2_loss                | 0.00083057355 |
| time_elapsed            | 1507          |
| total timesteps         | 297500        |
| value_loss              | 3.9369777e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003358586  |
| ent_coef_loss           | 6.770824      |
| entropy                 | 1.3922092     |
| ep_rewmean              | -0.542        |
| episodes                | 2980          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 297801        |
| policy_loss             | 0.18596268    |
| qf1_loss                | 0.00028186827 |
| qf2_loss                | 0.00027352557 |
| time_elapsed            | 1509          |
| total timesteps         | 297900        |
| value_loss              | 4.5465422e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00034500752 |
| ent_coef_loss           | 4.1019564     |
| entropy                 | 1.8485608     |
| ep_rewmean              | -0.543        |
| episodes                | 2984          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 298201        |
| policy_loss             | 0.18137103    |
| qf1_loss                | 0.00017653554 |
| qf2_loss                | 0.000173623   |
| time_elapsed            | 1511          |
| total timesteps         | 298300        |
| value_loss              | 1.4015128e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033754425 |
| ent_coef_loss           | -4.143848     |
| entropy                 | 2.4759748     |
| ep_rewmean              | -0.541        |
| episodes                | 2988          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 298601        |
| policy_loss             | 0.17304254    |
| qf1_loss                | 7.6423385e-06 |
| qf2_loss                | 1.0115729e-05 |
| time_elapsed            | 1513          |
| total timesteps         | 298700        |
| value_loss              | 1.548721e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003274105  |
| ent_coef_loss           | -0.019357443  |
| entropy                 | 1.8240722     |
| ep_rewmean              | -0.536        |
| episodes                | 2992          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 299001        |
| policy_loss             | 0.1732867     |
| qf1_loss                | 0.00013157431 |
| qf2_loss                | 0.00013887798 |
| time_elapsed            | 1515          |
| total timesteps         | 299100        |
| value_loss              | 1.8492594e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0003065336 |
| ent_coef_loss           | 1.2032819    |
| entropy                 | 2.377617     |
| ep_rewmean              | -0.533       |
| episodes                | 2996         |
| eplenmean               | 100          |
| fps                     | 197          |
| mean 100 episode reward | -0.5         |
| n_updates               | 299401       |
| policy_loss             | 0.1825367    |
| qf1_loss                | 0.0008188306 |
| qf2_loss                | 0.0008095908 |
| time_elapsed            | 1517         |
| total timesteps         | 299500       |
| value_loss              | 2.291101e-05 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00027918504  |
| ent_coef_loss           | -2.5281765     |
| entropy                 | 2.6522043      |
| ep_rewmean              | -0.537         |
| episodes                | 3000           |
| eplenmean               | 100            |
| fps                     | 197            |
| mean 100 episode reward | -0.5           |
| n_updates               | 299801         |
| policy_loss             | 0.17840019     |
| qf1_loss                | 8.490277e-06   |
| qf2_loss                | 8.633995e-06   |
| time_elapsed            | 1520           |
| total timesteps         | 299900         |
| value_loss              | 1.18216085e-05 |
--------------------------------------------
Eval num_timesteps=300000, episode_reward=-0.53 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000285618   |
| ent_coef_loss           | 7.2354584     |
| entropy                 | 2.5023556     |
| ep_rewmean              | -0.541        |
| episodes                | 3004          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 300201        |
| policy_loss             | 0.16910592    |
| qf1_loss                | 1.0186091e-05 |
| qf2_loss                | 8.627713e-06  |
| time_elapsed            | 1522          |
| total timesteps         | 300300        |
| value_loss              | 2.3046789e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00032815197 |
| ent_coef_loss           | -3.5632894    |
| entropy                 | 3.1736383     |
| ep_rewmean              | -0.545        |
| episodes                | 3008          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 300601        |
| policy_loss             | 0.17521818    |
| qf1_loss                | 0.00019813591 |
| qf2_loss                | 0.00020306396 |
| time_elapsed            | 1524          |
| total timesteps         | 300700        |
| value_loss              | 3.2685595e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00032044764 |
| ent_coef_loss           | -4.0492783    |
| entropy                 | 2.8538082     |
| ep_rewmean              | -0.542        |
| episodes                | 3012          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 301001        |
| policy_loss             | 0.15856406    |
| qf1_loss                | 1.9645078e-05 |
| qf2_loss                | 8.093324e-06  |
| time_elapsed            | 1526          |
| total timesteps         | 301100        |
| value_loss              | 8.626537e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0002724843  |
| ent_coef_loss           | -14.734332    |
| entropy                 | 3.085101      |
| ep_rewmean              | -0.537        |
| episodes                | 3016          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 301401        |
| policy_loss             | 0.16184334    |
| qf1_loss                | 0.00034093185 |
| qf2_loss                | 0.00034594655 |
| time_elapsed            | 1528          |
| total timesteps         | 301500        |
| value_loss              | 1.0129921e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0002442049  |
| ent_coef_loss           | -20.348759    |
| entropy                 | 3.145092      |
| ep_rewmean              | -0.519        |
| episodes                | 3020          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 301801        |
| policy_loss             | 0.1459881     |
| qf1_loss                | 6.592881e-06  |
| qf2_loss                | 6.3304874e-06 |
| time_elapsed            | 1530          |
| total timesteps         | 301900        |
| value_loss              | 4.82529e-06   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00022507166 |
| ent_coef_loss           | -8.948006     |
| entropy                 | 2.8566852     |
| ep_rewmean              | -0.507        |
| episodes                | 3024          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 302201        |
| policy_loss             | 0.15663114    |
| qf1_loss                | 0.00014931858 |
| qf2_loss                | 0.00015578447 |
| time_elapsed            | 1533          |
| total timesteps         | 302300        |
| value_loss              | 5.7885336e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0002161636  |
| ent_coef_loss           | 4.599556      |
| entropy                 | 2.7374868     |
| ep_rewmean              | -0.507        |
| episodes                | 3028          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.5          |
| n_updates               | 302601        |
| policy_loss             | 0.15491238    |
| qf1_loss                | 0.00016182946 |
| qf2_loss                | 0.00016343988 |
| time_elapsed            | 1535          |
| total timesteps         | 302700        |
| value_loss              | 5.2657538e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0002546862  |
| ent_coef_loss           | 17.09505      |
| entropy                 | 0.63801813    |
| ep_rewmean              | -0.574        |
| episodes                | 3032          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 303001        |
| policy_loss             | 0.16465701    |
| qf1_loss                | 8.68738e-05   |
| qf2_loss                | 9.449417e-05  |
| time_elapsed            | 1537          |
| total timesteps         | 303100        |
| value_loss              | 1.8333003e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00028935433 |
| ent_coef_loss           | 22.333248     |
| entropy                 | 0.8536431     |
| ep_rewmean              | -0.638        |
| episodes                | 3036          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.6          |
| n_updates               | 303401        |
| policy_loss             | 0.18431693    |
| qf1_loss                | 0.00018068866 |
| qf2_loss                | 0.00017994054 |
| time_elapsed            | 1539          |
| total timesteps         | 303500        |
| value_loss              | 4.7010886e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00031821872 |
| ent_coef_loss           | 16.96454      |
| entropy                 | 1.4502096     |
| ep_rewmean              | -0.693        |
| episodes                | 3040          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 303801        |
| policy_loss             | 0.19040242    |
| qf1_loss                | 8.219227e-06  |
| qf2_loss                | 8.806098e-06  |
| time_elapsed            | 1541          |
| total timesteps         | 303900        |
| value_loss              | 1.5518466e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003389405  |
| ent_coef_loss           | 28.912443     |
| entropy                 | 5.2207346     |
| ep_rewmean              | -0.727        |
| episodes                | 3044          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 304201        |
| policy_loss             | 0.22364646    |
| qf1_loss                | 0.0016314406  |
| qf2_loss                | 0.0015050079  |
| time_elapsed            | 1543          |
| total timesteps         | 304300        |
| value_loss              | 3.9983926e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033528352 |
| ent_coef_loss           | -3.8077965    |
| entropy                 | 3.0849962     |
| ep_rewmean              | -0.743        |
| episodes                | 3048          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 304601        |
| policy_loss             | 0.20650491    |
| qf1_loss                | 0.00031277764 |
| qf2_loss                | 0.00029783807 |
| time_elapsed            | 1546          |
| total timesteps         | 304700        |
| value_loss              | 1.7513494e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00031134268 |
| ent_coef_loss           | -12.89963     |
| entropy                 | 2.5146925     |
| ep_rewmean              | -0.747        |
| episodes                | 3052          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 305001        |
| policy_loss             | 0.20364179    |
| qf1_loss                | 1.760304e-05  |
| qf2_loss                | 1.5945425e-05 |
| time_elapsed            | 1548          |
| total timesteps         | 305100        |
| value_loss              | 3.5793986e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0002926102  |
| ent_coef_loss           | -12.269651    |
| entropy                 | 2.6224585     |
| ep_rewmean              | -0.746        |
| episodes                | 3056          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 305401        |
| policy_loss             | 0.18722475    |
| qf1_loss                | 0.0001958851  |
| qf2_loss                | 0.00020248693 |
| time_elapsed            | 1550          |
| total timesteps         | 305500        |
| value_loss              | 5.1787433e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0002890603  |
| ent_coef_loss           | -2.9899247    |
| entropy                 | 2.2632701     |
| ep_rewmean              | -0.745        |
| episodes                | 3060          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 305801        |
| policy_loss             | 0.18455568    |
| qf1_loss                | 1.2087539e-05 |
| qf2_loss                | 1.0531079e-05 |
| time_elapsed            | 1552          |
| total timesteps         | 305900        |
| value_loss              | 1.3417025e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00028959283 |
| ent_coef_loss           | 9.255152      |
| entropy                 | 3.0338664     |
| ep_rewmean              | -0.741        |
| episodes                | 3064          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 306201        |
| policy_loss             | 0.18476315    |
| qf1_loss                | 1.9071222e-05 |
| qf2_loss                | 9.575392e-06  |
| time_elapsed            | 1554          |
| total timesteps         | 306300        |
| value_loss              | 2.1245422e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00031320934 |
| ent_coef_loss           | 2.6924353     |
| entropy                 | 3.217937      |
| ep_rewmean              | -0.74         |
| episodes                | 3068          |
| eplenmean               | 100           |
| fps                     | 197           |
| mean 100 episode reward | -0.7          |
| n_updates               | 306601        |
| policy_loss             | 0.19634095    |
| qf1_loss                | 0.00018554328 |
| qf2_loss                | 0.00018211684 |
| time_elapsed            | 1556          |
| total timesteps         | 306700        |
| value_loss              | 3.8554914e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00034259568 |
| ent_coef_loss           | 18.183794     |
| entropy                 | 3.04313       |
| ep_rewmean              | -0.73         |
| episodes                | 3072          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 307001        |
| policy_loss             | 0.15953417    |
| qf1_loss                | 0.00021504343 |
| qf2_loss                | 0.0002626557  |
| time_elapsed            | 1558          |
| total timesteps         | 307100        |
| value_loss              | 1.711343e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003080484  |
| ent_coef_loss           | -10.549795    |
| entropy                 | 2.8731658     |
| ep_rewmean              | -0.725        |
| episodes                | 3076          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 307401        |
| policy_loss             | 0.1897322     |
| qf1_loss                | 1.2062529e-05 |
| qf2_loss                | 1.0356072e-05 |
| time_elapsed            | 1561          |
| total timesteps         | 307500        |
| value_loss              | 3.0939824e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0002831384  |
| ent_coef_loss           | 6.904565      |
| entropy                 | 2.8109164     |
| ep_rewmean              | -0.723        |
| episodes                | 3080          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 307801        |
| policy_loss             | 0.16533895    |
| qf1_loss                | 1.732259e-05  |
| qf2_loss                | 2.0968488e-05 |
| time_elapsed            | 1563          |
| total timesteps         | 307900        |
| value_loss              | 7.647626e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00026791185 |
| ent_coef_loss           | 1.0168402     |
| entropy                 | 2.545544      |
| ep_rewmean              | -0.723        |
| episodes                | 3084          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 308201        |
| policy_loss             | 0.18299292    |
| qf1_loss                | 0.00029505088 |
| qf2_loss                | 0.00027095905 |
| time_elapsed            | 1565          |
| total timesteps         | 308300        |
| value_loss              | 1.2198805e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00031154315 |
| ent_coef_loss           | 19.717632     |
| entropy                 | 2.6099672     |
| ep_rewmean              | -0.726        |
| episodes                | 3088          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 308601        |
| policy_loss             | 0.16974446    |
| qf1_loss                | 0.0006250559  |
| qf2_loss                | 0.0006915867  |
| time_elapsed            | 1567          |
| total timesteps         | 308700        |
| value_loss              | 1.9080593e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00034847614 |
| ent_coef_loss           | 1.4988911     |
| entropy                 | 2.6528554     |
| ep_rewmean              | -0.74         |
| episodes                | 3092          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 309001        |
| policy_loss             | 0.15558803    |
| qf1_loss                | 0.00014653153 |
| qf2_loss                | 0.00014005323 |
| time_elapsed            | 1569          |
| total timesteps         | 309100        |
| value_loss              | 1.3623101e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033386968 |
| ent_coef_loss           | -4.3171473    |
| entropy                 | 2.3507364     |
| ep_rewmean              | -0.746        |
| episodes                | 3096          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 309401        |
| policy_loss             | 0.16696696    |
| qf1_loss                | 1.4571931e-05 |
| qf2_loss                | 1.4389323e-05 |
| time_elapsed            | 1571          |
| total timesteps         | 309500        |
| value_loss              | 1.9042323e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00032406734 |
| ent_coef_loss           | -4.1222525    |
| entropy                 | 2.3024893     |
| ep_rewmean              | -0.754        |
| episodes                | 3100          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 309801        |
| policy_loss             | 0.17099072    |
| qf1_loss                | 1.1192633e-05 |
| qf2_loss                | 1.2865643e-05 |
| time_elapsed            | 1573          |
| total timesteps         | 309900        |
| value_loss              | 8.432808e-06  |
-------------------------------------------
Eval num_timesteps=310000, episode_reward=-0.52 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00030505008 |
| ent_coef_loss           | -5.851328     |
| entropy                 | 2.4168847     |
| ep_rewmean              | -0.755        |
| episodes                | 3104          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 310201        |
| policy_loss             | 0.17021649    |
| qf1_loss                | 0.00022662779 |
| qf2_loss                | 0.00019832526 |
| time_elapsed            | 1576          |
| total timesteps         | 310300        |
| value_loss              | 4.1941006e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00028814818 |
| ent_coef_loss           | 43.32189      |
| entropy                 | 2.692472      |
| ep_rewmean              | -0.751        |
| episodes                | 3108          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 310601        |
| policy_loss             | 0.17325798    |
| qf1_loss                | 0.00013628036 |
| qf2_loss                | 0.00012940953 |
| time_elapsed            | 1578          |
| total timesteps         | 310700        |
| value_loss              | 2.0367093e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00035372662 |
| ent_coef_loss           | 12.231888     |
| entropy                 | 3.3738902     |
| ep_rewmean              | -0.793        |
| episodes                | 3112          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 311001        |
| policy_loss             | 0.15856391    |
| qf1_loss                | 1.8931487e-05 |
| qf2_loss                | 2.9812545e-05 |
| time_elapsed            | 1580          |
| total timesteps         | 311100        |
| value_loss              | 5.013091e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004111407  |
| ent_coef_loss           | 20.090496     |
| entropy                 | 2.882421      |
| ep_rewmean              | -0.799        |
| episodes                | 3116          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 311401        |
| policy_loss             | 0.18778393    |
| qf1_loss                | 0.00034442314 |
| qf2_loss                | 0.0003467743  |
| time_elapsed            | 1582          |
| total timesteps         | 311500        |
| value_loss              | 3.699575e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00043830986 |
| ent_coef_loss           | -6.58588      |
| entropy                 | 3.7902815     |
| ep_rewmean              | -0.801        |
| episodes                | 3120          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 311801        |
| policy_loss             | 0.18127619    |
| qf1_loss                | 0.00027470148 |
| qf2_loss                | 0.00028790106 |
| time_elapsed            | 1584          |
| total timesteps         | 311900        |
| value_loss              | 5.1255764e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00040515873 |
| ent_coef_loss           | -9.401178     |
| entropy                 | 3.2149942     |
| ep_rewmean              | -0.808        |
| episodes                | 3124          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 312201        |
| policy_loss             | 0.18527289    |
| qf1_loss                | 2.3912246e-05 |
| qf2_loss                | 2.2499084e-05 |
| time_elapsed            | 1586          |
| total timesteps         | 312300        |
| value_loss              | 3.7475016e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00037562812 |
| ent_coef_loss           | -2.9998198    |
| entropy                 | 3.0196357     |
| ep_rewmean              | -0.809        |
| episodes                | 3128          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 312601        |
| policy_loss             | 0.19090381    |
| qf1_loss                | 0.00030652253 |
| qf2_loss                | 0.00029947638 |
| time_elapsed            | 1588          |
| total timesteps         | 312700        |
| value_loss              | 1.5140175e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00040920032 |
| ent_coef_loss           | 25.593624     |
| entropy                 | 3.3494241     |
| ep_rewmean              | -0.742        |
| episodes                | 3132          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 313001        |
| policy_loss             | 0.17351836    |
| qf1_loss                | 0.00043064152 |
| qf2_loss                | 0.00042838685 |
| time_elapsed            | 1590          |
| total timesteps         | 313100        |
| value_loss              | 2.2888633e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00041489836 |
| ent_coef_loss           | -13.246771    |
| entropy                 | 3.898963      |
| ep_rewmean              | -0.671        |
| episodes                | 3136          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 313401        |
| policy_loss             | 0.18908583    |
| qf1_loss                | 0.00022963264 |
| qf2_loss                | 0.00023041484 |
| time_elapsed            | 1592          |
| total timesteps         | 313500        |
| value_loss              | 1.8213603e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0003908579 |
| ent_coef_loss           | -0.97100544  |
| entropy                 | 4.1297626    |
| ep_rewmean              | -0.608       |
| episodes                | 3140         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -0.6         |
| n_updates               | 313801       |
| policy_loss             | 0.20772232   |
| qf1_loss                | 8.371919e-06 |
| qf2_loss                | 9.632757e-06 |
| time_elapsed            | 1594         |
| total timesteps         | 313900       |
| value_loss              | 2.550273e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00039241405 |
| ent_coef_loss           | -12.004083    |
| entropy                 | 4.172986      |
| ep_rewmean              | -0.569        |
| episodes                | 3144          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 314201        |
| policy_loss             | 0.19281806    |
| qf1_loss                | 0.00027731608 |
| qf2_loss                | 0.00028574312 |
| time_elapsed            | 1596          |
| total timesteps         | 314300        |
| value_loss              | 2.387794e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00037915775 |
| ent_coef_loss           | 36.46247      |
| entropy                 | 3.649132      |
| ep_rewmean              | -0.552        |
| episodes                | 3148          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 314601        |
| policy_loss             | 0.1847664     |
| qf1_loss                | 8.366611e-06  |
| qf2_loss                | 7.0235174e-06 |
| time_elapsed            | 1598          |
| total timesteps         | 314700        |
| value_loss              | 2.1379768e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00040445614 |
| ent_coef_loss           | 20.420012     |
| entropy                 | 4.2938557     |
| ep_rewmean              | -0.542        |
| episodes                | 3152          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 315001        |
| policy_loss             | 0.18554015    |
| qf1_loss                | 0.00024098741 |
| qf2_loss                | 0.0002462054  |
| time_elapsed            | 1600          |
| total timesteps         | 315100        |
| value_loss              | 4.450248e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00043579796 |
| ent_coef_loss           | 6.819681      |
| entropy                 | 4.2612524     |
| ep_rewmean              | -0.534        |
| episodes                | 3156          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 315401        |
| policy_loss             | 0.18895765    |
| qf1_loss                | 9.698864e-06  |
| qf2_loss                | 6.238266e-06  |
| time_elapsed            | 1602          |
| total timesteps         | 315500        |
| value_loss              | 1.9025241e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00043313648 |
| ent_coef_loss           | -10.020585    |
| entropy                 | 4.5411034     |
| ep_rewmean              | -0.532        |
| episodes                | 3160          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 315801        |
| policy_loss             | 0.2036722     |
| qf1_loss                | 0.00027265385 |
| qf2_loss                | 0.00027146435 |
| time_elapsed            | 1604          |
| total timesteps         | 315900        |
| value_loss              | 1.4472083e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00038154106 |
| ent_coef_loss           | -10.584225    |
| entropy                 | 3.5191822     |
| ep_rewmean              | -0.535        |
| episodes                | 3164          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 316201        |
| policy_loss             | 0.2016788     |
| qf1_loss                | 1.7507506e-05 |
| qf2_loss                | 2.970787e-05  |
| time_elapsed            | 1606          |
| total timesteps         | 316300        |
| value_loss              | 4.6070803e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00035020438 |
| ent_coef_loss           | -9.370389     |
| entropy                 | 3.0228007     |
| ep_rewmean              | -0.537        |
| episodes                | 3168          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 316601        |
| policy_loss             | 0.19139887    |
| qf1_loss                | 1.265967e-05  |
| qf2_loss                | 9.730471e-06  |
| time_elapsed            | 1608          |
| total timesteps         | 316700        |
| value_loss              | 5.5002933e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003248567  |
| ent_coef_loss           | -9.803221     |
| entropy                 | 3.6881397     |
| ep_rewmean              | -0.541        |
| episodes                | 3172          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 317001        |
| policy_loss             | 0.1893369     |
| qf1_loss                | 1.1747556e-05 |
| qf2_loss                | 1.5485597e-05 |
| time_elapsed            | 1610          |
| total timesteps         | 317100        |
| value_loss              | 1.8922834e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00031084602 |
| ent_coef_loss           | -8.978922     |
| entropy                 | 3.5138156     |
| ep_rewmean              | -0.54         |
| episodes                | 3176          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 317401        |
| policy_loss             | 0.19210745    |
| qf1_loss                | 5.3904173e-06 |
| qf2_loss                | 1.0864914e-05 |
| time_elapsed            | 1612          |
| total timesteps         | 317500        |
| value_loss              | 1.8543224e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00036589484 |
| ent_coef_loss           | 38.60851      |
| entropy                 | 4.5821443     |
| ep_rewmean              | -0.555        |
| episodes                | 3180          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 317801        |
| policy_loss             | 0.20577542    |
| qf1_loss                | 8.4183475e-06 |
| qf2_loss                | 9.68689e-06   |
| time_elapsed            | 1614          |
| total timesteps         | 317900        |
| value_loss              | 9.781985e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00043168364 |
| ent_coef_loss           | 10.661484     |
| entropy                 | 4.3570433     |
| ep_rewmean              | -0.554        |
| episodes                | 3184          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 318201        |
| policy_loss             | 0.19420782    |
| qf1_loss                | 4.8451075e-06 |
| qf2_loss                | 5.478768e-06  |
| time_elapsed            | 1616          |
| total timesteps         | 318300        |
| value_loss              | 4.788956e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00046798863 |
| ent_coef_loss           | 2.2108002     |
| entropy                 | 3.8521686     |
| ep_rewmean              | -0.548        |
| episodes                | 3188          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 318601        |
| policy_loss             | 0.19684055    |
| qf1_loss                | 0.00034277284 |
| qf2_loss                | 0.00036948815 |
| time_elapsed            | 1619          |
| total timesteps         | 318700        |
| value_loss              | 1.6040813e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00045478452 |
| ent_coef_loss           | 3.2968016     |
| entropy                 | 4.463328      |
| ep_rewmean              | -0.536        |
| episodes                | 3192          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 319001        |
| policy_loss             | 0.20064837    |
| qf1_loss                | 1.0304206e-05 |
| qf2_loss                | 1.5371466e-05 |
| time_elapsed            | 1621          |
| total timesteps         | 319100        |
| value_loss              | 1.2745824e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00042568202 |
| ent_coef_loss           | -7.3572726    |
| entropy                 | 3.8235788     |
| ep_rewmean              | -0.533        |
| episodes                | 3196          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 319401        |
| policy_loss             | 0.20110065    |
| qf1_loss                | 0.00048349085 |
| qf2_loss                | 0.00048327848 |
| time_elapsed            | 1623          |
| total timesteps         | 319500        |
| value_loss              | 1.8642339e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003962257  |
| ent_coef_loss           | -16.232279    |
| entropy                 | 2.924684      |
| ep_rewmean              | -0.52         |
| episodes                | 3200          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 319801        |
| policy_loss             | 0.18986914    |
| qf1_loss                | 0.00076540554 |
| qf2_loss                | 0.00080576446 |
| time_elapsed            | 1625          |
| total timesteps         | 319900        |
| value_loss              | 8.172439e-06  |
-------------------------------------------
Eval num_timesteps=320000, episode_reward=-0.35 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003641883  |
| ent_coef_loss           | -7.4502115    |
| entropy                 | 2.8886085     |
| ep_rewmean              | -0.512        |
| episodes                | 3204          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 320201        |
| policy_loss             | 0.18920664    |
| qf1_loss                | 1.3712233e-05 |
| qf2_loss                | 1.934949e-05  |
| time_elapsed            | 1627          |
| total timesteps         | 320300        |
| value_loss              | 1.2955507e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033420898 |
| ent_coef_loss           | -6.856624     |
| entropy                 | 3.1012502     |
| ep_rewmean              | -0.51         |
| episodes                | 3208          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 320601        |
| policy_loss             | 0.18951817    |
| qf1_loss                | 0.0004474921  |
| qf2_loss                | 0.00044059276 |
| time_elapsed            | 1629          |
| total timesteps         | 320700        |
| value_loss              | 1.1798796e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00031740192 |
| ent_coef_loss           | -7.1400337    |
| entropy                 | 2.6103952     |
| ep_rewmean              | -0.467        |
| episodes                | 3212          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 321001        |
| policy_loss             | 0.18704112    |
| qf1_loss                | 0.0008702852  |
| qf2_loss                | 0.00086980546 |
| time_elapsed            | 1631          |
| total timesteps         | 321100        |
| value_loss              | 2.3039276e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00029780093 |
| ent_coef_loss           | -5.0895877    |
| entropy                 | 2.39848       |
| ep_rewmean              | -0.457        |
| episodes                | 3216          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 321401        |
| policy_loss             | 0.18252979    |
| qf1_loss                | 0.0004215797  |
| qf2_loss                | 0.0004233715  |
| time_elapsed            | 1633          |
| total timesteps         | 321500        |
| value_loss              | 7.866465e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0002629957  |
| ent_coef_loss           | -12.107378    |
| entropy                 | 1.9222696     |
| ep_rewmean              | -0.453        |
| episodes                | 3220          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 321801        |
| policy_loss             | 0.19161513    |
| qf1_loss                | 0.0005349515  |
| qf2_loss                | 0.00053185516 |
| time_elapsed            | 1635          |
| total timesteps         | 321900        |
| value_loss              | 5.3993044e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00028259185 |
| ent_coef_loss           | 28.828033     |
| entropy                 | 4.441308      |
| ep_rewmean              | -0.445        |
| episodes                | 3224          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 322201        |
| policy_loss             | 0.1838752     |
| qf1_loss                | 4.630075e-06  |
| qf2_loss                | 7.1920867e-06 |
| time_elapsed            | 1637          |
| total timesteps         | 322300        |
| value_loss              | 1.9888355e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00031776808 |
| ent_coef_loss           | 14.867901     |
| entropy                 | 2.9074059     |
| ep_rewmean              | -0.439        |
| episodes                | 3228          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 322601        |
| policy_loss             | 0.17375705    |
| qf1_loss                | 1.4092016e-05 |
| qf2_loss                | 1.108466e-05  |
| time_elapsed            | 1639          |
| total timesteps         | 322700        |
| value_loss              | 7.115269e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033809352 |
| ent_coef_loss           | -4.6871967    |
| entropy                 | 2.689899      |
| ep_rewmean              | -0.436        |
| episodes                | 3232          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 323001        |
| policy_loss             | 0.183116      |
| qf1_loss                | 0.00017661083 |
| qf2_loss                | 0.00017982078 |
| time_elapsed            | 1641          |
| total timesteps         | 323100        |
| value_loss              | 9.593019e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003075294  |
| ent_coef_loss           | -21.166779    |
| entropy                 | 2.8055267     |
| ep_rewmean              | -0.432        |
| episodes                | 3236          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 323401        |
| policy_loss             | 0.18698695    |
| qf1_loss                | 5.6774284e-06 |
| qf2_loss                | 1.7678354e-05 |
| time_elapsed            | 1643          |
| total timesteps         | 323500        |
| value_loss              | 1.5757387e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00027700159 |
| ent_coef_loss           | -4.2805634    |
| entropy                 | 2.8396058     |
| ep_rewmean              | -0.429        |
| episodes                | 3240          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 323801        |
| policy_loss             | 0.18886808    |
| qf1_loss                | 0.00021134401 |
| qf2_loss                | 0.00021247978 |
| time_elapsed            | 1645          |
| total timesteps         | 323900        |
| value_loss              | 9.552641e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00025512645 |
| ent_coef_loss           | -18.375141    |
| entropy                 | 2.4948716     |
| ep_rewmean              | -0.428        |
| episodes                | 3244          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 324201        |
| policy_loss             | 0.17892832    |
| qf1_loss                | 1.0464182e-05 |
| qf2_loss                | 4.1513263e-06 |
| time_elapsed            | 1648          |
| total timesteps         | 324300        |
| value_loss              | 2.3109124e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00023811309 |
| ent_coef_loss           | -4.9321537    |
| entropy                 | 2.2587478     |
| ep_rewmean              | -0.426        |
| episodes                | 3248          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 324601        |
| policy_loss             | 0.17304862    |
| qf1_loss                | 0.00016081476 |
| qf2_loss                | 0.00015837791 |
| time_elapsed            | 1650          |
| total timesteps         | 324700        |
| value_loss              | 2.0356933e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00021787478 |
| ent_coef_loss           | -0.9787622    |
| entropy                 | 1.7216842     |
| ep_rewmean              | -0.426        |
| episodes                | 3252          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 325001        |
| policy_loss             | 0.17922974    |
| qf1_loss                | 2.2197313e-05 |
| qf2_loss                | 1.4706795e-05 |
| time_elapsed            | 1652          |
| total timesteps         | 325100        |
| value_loss              | 3.8088154e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000200101   |
| ent_coef_loss           | -5.3443904    |
| entropy                 | 1.584626      |
| ep_rewmean              | -0.427        |
| episodes                | 3256          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 325401        |
| policy_loss             | 0.17494869    |
| qf1_loss                | 1.2184319e-05 |
| qf2_loss                | 9.37987e-06   |
| time_elapsed            | 1654          |
| total timesteps         | 325500        |
| value_loss              | 5.238502e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00019539708 |
| ent_coef_loss           | -4.4251146    |
| entropy                 | 2.0114646     |
| ep_rewmean              | -0.427        |
| episodes                | 3260          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 325801        |
| policy_loss             | 0.16953263    |
| qf1_loss                | 0.0003431589  |
| qf2_loss                | 0.0003378169  |
| time_elapsed            | 1656          |
| total timesteps         | 325900        |
| value_loss              | 9.868099e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00019582202 |
| ent_coef_loss           | 29.300718     |
| entropy                 | -0.77988327   |
| ep_rewmean              | -0.426        |
| episodes                | 3264          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 326201        |
| policy_loss             | 0.16517815    |
| qf1_loss                | 0.00043229156 |
| qf2_loss                | 0.0004212493  |
| time_elapsed            | 1658          |
| total timesteps         | 326300        |
| value_loss              | 1.3406562e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00026312287 |
| ent_coef_loss           | 58.92979      |
| entropy                 | 0.9200825     |
| ep_rewmean              | -0.476        |
| episodes                | 3268          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 326601        |
| policy_loss             | 0.17202044    |
| qf1_loss                | 0.00017906426 |
| qf2_loss                | 0.00017675517 |
| time_elapsed            | 1660          |
| total timesteps         | 326700        |
| value_loss              | 7.1717122e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00030498113 |
| ent_coef_loss           | 38.088276     |
| entropy                 | 0.93085176    |
| ep_rewmean              | -0.525        |
| episodes                | 3272          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 327001        |
| policy_loss             | 0.20016864    |
| qf1_loss                | 1.3444075e-05 |
| qf2_loss                | 8.953562e-06  |
| time_elapsed            | 1662          |
| total timesteps         | 327100        |
| value_loss              | 1.382678e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033224345 |
| ent_coef_loss           | 10.789522     |
| entropy                 | 1.3149194     |
| ep_rewmean              | -0.579        |
| episodes                | 3276          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 327401        |
| policy_loss             | 0.22379744    |
| qf1_loss                | 0.0006404571  |
| qf2_loss                | 0.0006281776  |
| time_elapsed            | 1664          |
| total timesteps         | 327500        |
| value_loss              | 1.807091e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003518835  |
| ent_coef_loss           | 7.2021494     |
| entropy                 | 1.3094325     |
| ep_rewmean              | -0.593        |
| episodes                | 3280          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 327801        |
| policy_loss             | 0.2424168     |
| qf1_loss                | 9.045349e-06  |
| qf2_loss                | 1.0763906e-05 |
| time_elapsed            | 1666          |
| total timesteps         | 327900        |
| value_loss              | 1.7902039e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00036513893 |
| ent_coef_loss           | 27.671503     |
| entropy                 | 1.1667397     |
| ep_rewmean              | -0.619        |
| episodes                | 3284          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 328201        |
| policy_loss             | 0.23768368    |
| qf1_loss                | 0.0003317959  |
| qf2_loss                | 0.00033524862 |
| time_elapsed            | 1668          |
| total timesteps         | 328300        |
| value_loss              | 1.3166461e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00039661658 |
| ent_coef_loss           | 0.91952515    |
| entropy                 | 2.290959      |
| ep_rewmean              | -0.653        |
| episodes                | 3288          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 328601        |
| policy_loss             | 0.2673578     |
| qf1_loss                | 2.126829e-05  |
| qf2_loss                | 2.4068715e-05 |
| time_elapsed            | 1670          |
| total timesteps         | 328700        |
| value_loss              | 2.1886586e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00040933536 |
| ent_coef_loss           | -1.1530063    |
| entropy                 | 2.0949364     |
| ep_rewmean              | -0.68         |
| episodes                | 3292          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 329001        |
| policy_loss             | 0.2724789     |
| qf1_loss                | 0.00048882107 |
| qf2_loss                | 0.0004565194  |
| time_elapsed            | 1672          |
| total timesteps         | 329100        |
| value_loss              | 1.6430637e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003912435  |
| ent_coef_loss           | -12.38084     |
| entropy                 | 3.1654534     |
| ep_rewmean              | -0.697        |
| episodes                | 3296          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 329401        |
| policy_loss             | 0.28668582    |
| qf1_loss                | 3.6756413e-05 |
| qf2_loss                | 5.6595858e-05 |
| time_elapsed            | 1674          |
| total timesteps         | 329500        |
| value_loss              | 4.165755e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000358344   |
| ent_coef_loss           | -17.161879    |
| entropy                 | 1.6559136     |
| ep_rewmean              | -0.715        |
| episodes                | 3300          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 329801        |
| policy_loss             | 0.27945986    |
| qf1_loss                | 8.621265e-06  |
| qf2_loss                | 1.7179518e-05 |
| time_elapsed            | 1676          |
| total timesteps         | 329900        |
| value_loss              | 1.3568165e-05 |
-------------------------------------------
Eval num_timesteps=330000, episode_reward=-0.75 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033449402 |
| ent_coef_loss           | -0.59744203   |
| entropy                 | 0.89776844    |
| ep_rewmean              | -0.735        |
| episodes                | 3304          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 330201        |
| policy_loss             | 0.27665016    |
| qf1_loss                | 0.0003484644  |
| qf2_loss                | 0.00034473304 |
| time_elapsed            | 1679          |
| total timesteps         | 330300        |
| value_loss              | 4.9321538e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033433203 |
| ent_coef_loss           | 9.750433      |
| entropy                 | 0.80862606    |
| ep_rewmean              | -0.754        |
| episodes                | 3308          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 330601        |
| policy_loss             | 0.26564503    |
| qf1_loss                | 0.0011345836  |
| qf2_loss                | 0.001160104   |
| time_elapsed            | 1681          |
| total timesteps         | 330700        |
| value_loss              | 2.0122548e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033912656 |
| ent_coef_loss           | 1.0156882     |
| entropy                 | 0.79243803    |
| ep_rewmean              | -0.795        |
| episodes                | 3312          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 331001        |
| policy_loss             | 0.2708916     |
| qf1_loss                | 1.7698654e-05 |
| qf2_loss                | 1.8237053e-05 |
| time_elapsed            | 1683          |
| total timesteps         | 331100        |
| value_loss              | 1.050524e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00034106124 |
| ent_coef_loss           | -1.3635883    |
| entropy                 | 0.9078316     |
| ep_rewmean              | -0.843        |
| episodes                | 3316          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 331401        |
| policy_loss             | 0.2725698     |
| qf1_loss                | 0.0011546903  |
| qf2_loss                | 0.0011638589  |
| time_elapsed            | 1685          |
| total timesteps         | 331500        |
| value_loss              | 1.1410784e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00035318846  |
| ent_coef_loss           | 2.5489602      |
| entropy                 | 0.31845513     |
| ep_rewmean              | -0.883         |
| episodes                | 3320           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.9           |
| n_updates               | 331801         |
| policy_loss             | 0.25039428     |
| qf1_loss                | 3.301879e-05   |
| qf2_loss                | 4.219138e-05   |
| time_elapsed            | 1687           |
| total timesteps         | 331900         |
| value_loss              | 0.000103920975 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00037023932 |
| ent_coef_loss           | 3.4864664     |
| entropy                 | 0.09900601    |
| ep_rewmean              | -0.907        |
| episodes                | 3324          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 332201        |
| policy_loss             | 0.22588888    |
| qf1_loss                | 0.00056268525 |
| qf2_loss                | 0.0005834335  |
| time_elapsed            | 1689          |
| total timesteps         | 332300        |
| value_loss              | 3.3755678e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003703311  |
| ent_coef_loss           | -1.16186      |
| entropy                 | 0.59094435    |
| ep_rewmean              | -0.926        |
| episodes                | 3328          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 332601        |
| policy_loss             | 0.22909588    |
| qf1_loss                | 0.00047992502 |
| qf2_loss                | 0.0004725055  |
| time_elapsed            | 1691          |
| total timesteps         | 332700        |
| value_loss              | 2.0215257e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033126833 |
| ent_coef_loss           | -3.8664236    |
| entropy                 | 1.4156778     |
| ep_rewmean              | -0.941        |
| episodes                | 3332          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 333001        |
| policy_loss             | 0.23893       |
| qf1_loss                | 1.0721387e-05 |
| qf2_loss                | 9.147498e-06  |
| time_elapsed            | 1693          |
| total timesteps         | 333100        |
| value_loss              | 2.1812635e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00032245193 |
| ent_coef_loss           | 4.3979125     |
| entropy                 | 1.6857342     |
| ep_rewmean              | -0.95         |
| episodes                | 3336          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 333401        |
| policy_loss             | 0.2266344     |
| qf1_loss                | 6.560697e-06  |
| qf2_loss                | 1.841822e-05  |
| time_elapsed            | 1695          |
| total timesteps         | 333500        |
| value_loss              | 3.6143083e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033880782 |
| ent_coef_loss           | 3.7062218     |
| entropy                 | 0.546733      |
| ep_rewmean              | -0.961        |
| episodes                | 3340          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 333801        |
| policy_loss             | 0.22068973    |
| qf1_loss                | 1.7416354e-05 |
| qf2_loss                | 1.5681975e-05 |
| time_elapsed            | 1697          |
| total timesteps         | 333900        |
| value_loss              | 2.9701052e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00034836848 |
| ent_coef_loss           | 7.518538      |
| entropy                 | 0.28852195    |
| ep_rewmean              | -0.972        |
| episodes                | 3344          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 334201        |
| policy_loss             | 0.22003981    |
| qf1_loss                | 0.00044386263 |
| qf2_loss                | 0.00041311685 |
| time_elapsed            | 1699          |
| total timesteps         | 334300        |
| value_loss              | 2.0796693e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00037401938 |
| ent_coef_loss           | 4.6841154     |
| entropy                 | 0.9549136     |
| ep_rewmean              | -0.982        |
| episodes                | 3348          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 334601        |
| policy_loss             | 0.22907683    |
| qf1_loss                | 1.8924322e-05 |
| qf2_loss                | 2.1734555e-05 |
| time_elapsed            | 1701          |
| total timesteps         | 334700        |
| value_loss              | 1.5120254e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00037210103 |
| ent_coef_loss           | -7.676037     |
| entropy                 | 2.5383277     |
| ep_rewmean              | -0.995        |
| episodes                | 3352          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 335001        |
| policy_loss             | 0.2372609     |
| qf1_loss                | 0.00050268916 |
| qf2_loss                | 0.00046065648 |
| time_elapsed            | 1703          |
| total timesteps         | 335100        |
| value_loss              | 1.8423498e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00042860868 |
| ent_coef_loss           | 29.275705     |
| entropy                 | 2.9614804     |
| ep_rewmean              | -1.01         |
| episodes                | 3356          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 335401        |
| policy_loss             | 0.23001963    |
| qf1_loss                | 2.4598463e-05 |
| qf2_loss                | 2.2059652e-05 |
| time_elapsed            | 1705          |
| total timesteps         | 335500        |
| value_loss              | 1.9236064e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005040282  |
| ent_coef_loss           | 30.315718     |
| entropy                 | 3.305983      |
| ep_rewmean              | -1.04         |
| episodes                | 3360          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 335801        |
| policy_loss             | 0.25529692    |
| qf1_loss                | 0.00051748636 |
| qf2_loss                | 0.00051396183 |
| time_elapsed            | 1707          |
| total timesteps         | 335900        |
| value_loss              | 3.3394193e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005634637  |
| ent_coef_loss           | 26.044914     |
| entropy                 | 3.8123398     |
| ep_rewmean              | -1.1          |
| episodes                | 3364          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 336201        |
| policy_loss             | 0.27758408    |
| qf1_loss                | 2.8772683e-05 |
| qf2_loss                | 2.1430042e-05 |
| time_elapsed            | 1709          |
| total timesteps         | 336300        |
| value_loss              | 2.8614308e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00062233297 |
| ent_coef_loss           | 13.166782     |
| entropy                 | 3.6925662     |
| ep_rewmean              | -1.1          |
| episodes                | 3368          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 336601        |
| policy_loss             | 0.2938965     |
| qf1_loss                | 2.691505e-05  |
| qf2_loss                | 3.7190774e-05 |
| time_elapsed            | 1711          |
| total timesteps         | 336700        |
| value_loss              | 2.833303e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006631577  |
| ent_coef_loss           | 6.7121215     |
| entropy                 | 4.022104      |
| ep_rewmean              | -1.08         |
| episodes                | 3372          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 337001        |
| policy_loss             | 0.31886142    |
| qf1_loss                | 0.00073619693 |
| qf2_loss                | 0.0007494214  |
| time_elapsed            | 1713          |
| total timesteps         | 337100        |
| value_loss              | 3.0462654e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006813966  |
| ent_coef_loss           | 8.7685795     |
| entropy                 | 4.108732      |
| ep_rewmean              | -1.05         |
| episodes                | 3376          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 337401        |
| policy_loss             | 0.32073152    |
| qf1_loss                | 0.00077989756 |
| qf2_loss                | 0.0007904036  |
| time_elapsed            | 1715          |
| total timesteps         | 337500        |
| value_loss              | 2.6499081e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000659065   |
| ent_coef_loss           | -5.375772     |
| entropy                 | 4.1776304     |
| ep_rewmean              | -1.03         |
| episodes                | 3380          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 337801        |
| policy_loss             | 0.3378445     |
| qf1_loss                | 0.0008808704  |
| qf2_loss                | 0.0008743644  |
| time_elapsed            | 1718          |
| total timesteps         | 337900        |
| value_loss              | 6.5215754e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00065213593 |
| ent_coef_loss           | 2.882193      |
| entropy                 | 3.8422956     |
| ep_rewmean              | -1.02         |
| episodes                | 3384          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 338201        |
| policy_loss             | 0.3557009     |
| qf1_loss                | 0.0008606866  |
| qf2_loss                | 0.0008817931  |
| time_elapsed            | 1720          |
| total timesteps         | 338300        |
| value_loss              | 2.1851196e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006659552  |
| ent_coef_loss           | -3.195834     |
| entropy                 | 3.4236965     |
| ep_rewmean              | -1.01         |
| episodes                | 3388          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 338601        |
| policy_loss             | 0.35919988    |
| qf1_loss                | 2.8317745e-05 |
| qf2_loss                | 9.496901e-05  |
| time_elapsed            | 1722          |
| total timesteps         | 338700        |
| value_loss              | 5.42966e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00068238634 |
| ent_coef_loss           | -2.5404048    |
| entropy                 | 3.8828592     |
| ep_rewmean              | -1.01         |
| episodes                | 3392          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 339001        |
| policy_loss             | 0.38798395    |
| qf1_loss                | 1.7855498e-05 |
| qf2_loss                | 1.3956246e-05 |
| time_elapsed            | 1724          |
| total timesteps         | 339100        |
| value_loss              | 5.4321245e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00070407783 |
| ent_coef_loss           | -2.585802     |
| entropy                 | 3.764558      |
| ep_rewmean              | -1.01         |
| episodes                | 3396          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 339401        |
| policy_loss             | 0.37772015    |
| qf1_loss                | 4.7652517e-05 |
| qf2_loss                | 4.2322907e-05 |
| time_elapsed            | 1726          |
| total timesteps         | 339500        |
| value_loss              | 3.161717e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006911468  |
| ent_coef_loss           | 1.2077564     |
| entropy                 | 4.1803718     |
| ep_rewmean              | -1.03         |
| episodes                | 3400          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 339801        |
| policy_loss             | 0.39883995    |
| qf1_loss                | 1.7672442e-05 |
| qf2_loss                | 2.4072595e-05 |
| time_elapsed            | 1728          |
| total timesteps         | 339900        |
| value_loss              | 3.472955e-05  |
-------------------------------------------
Eval num_timesteps=340000, episode_reward=-1.02 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00070056075 |
| ent_coef_loss           | 3.7212362     |
| entropy                 | 3.9126348     |
| ep_rewmean              | -1.06         |
| episodes                | 3404          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 340201        |
| policy_loss             | 0.4088931     |
| qf1_loss                | 0.0024190345  |
| qf2_loss                | 0.0023554661  |
| time_elapsed            | 1730          |
| total timesteps         | 340300        |
| value_loss              | 3.7511363e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007483981  |
| ent_coef_loss           | 2.5726516     |
| entropy                 | 4.0146904     |
| ep_rewmean              | -1.17         |
| episodes                | 3408          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 340601        |
| policy_loss             | 0.42437395    |
| qf1_loss                | 0.0016192043  |
| qf2_loss                | 0.0015592829  |
| time_elapsed            | 1732          |
| total timesteps         | 340700        |
| value_loss              | 5.4232565e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00076993444 |
| ent_coef_loss           | -2.687816     |
| entropy                 | 4.0996213     |
| ep_rewmean              | -1.22         |
| episodes                | 3412          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 341001        |
| policy_loss             | 0.43463904    |
| qf1_loss                | 0.002354718   |
| qf2_loss                | 0.0023448595  |
| time_elapsed            | 1734          |
| total timesteps         | 341100        |
| value_loss              | 6.840419e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007869315  |
| ent_coef_loss           | -1.738781     |
| entropy                 | 4.208602      |
| ep_rewmean              | -1.31         |
| episodes                | 3416          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 341401        |
| policy_loss             | 0.43660125    |
| qf1_loss                | 4.32385e-05   |
| qf2_loss                | 4.0149338e-05 |
| time_elapsed            | 1736          |
| total timesteps         | 341500        |
| value_loss              | 6.372321e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00069971546 |
| ent_coef_loss           | -0.28988504   |
| entropy                 | 3.2557316     |
| ep_rewmean              | -1.31         |
| episodes                | 3420          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 341801        |
| policy_loss             | 0.43662292    |
| qf1_loss                | 0.00010230241 |
| qf2_loss                | 9.71315e-05   |
| time_elapsed            | 1738          |
| total timesteps         | 341900        |
| value_loss              | 5.867285e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006626147  |
| ent_coef_loss           | -1.0765052    |
| entropy                 | 3.5964954     |
| ep_rewmean              | -1.32         |
| episodes                | 3424          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 342201        |
| policy_loss             | 0.45966431    |
| qf1_loss                | 0.005857092   |
| qf2_loss                | 0.005895766   |
| time_elapsed            | 1740          |
| total timesteps         | 342300        |
| value_loss              | 0.00010327928 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00062951515 |
| ent_coef_loss           | 1.788759      |
| entropy                 | 4.0115204     |
| ep_rewmean              | -1.34         |
| episodes                | 3428          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 342601        |
| policy_loss             | 0.4564035     |
| qf1_loss                | 4.0301653e-05 |
| qf2_loss                | 4.4141892e-05 |
| time_elapsed            | 1742          |
| total timesteps         | 342700        |
| value_loss              | 4.5630688e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006546075  |
| ent_coef_loss           | 4.64847       |
| entropy                 | 3.0557451     |
| ep_rewmean              | -1.35         |
| episodes                | 3432          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 343001        |
| policy_loss             | 0.44841152    |
| qf1_loss                | 7.361405e-05  |
| qf2_loss                | 8.4393454e-05 |
| time_elapsed            | 1744          |
| total timesteps         | 343100        |
| value_loss              | 6.337455e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006385803  |
| ent_coef_loss           | 5.0122404     |
| entropy                 | 2.8595293     |
| ep_rewmean              | -1.38         |
| episodes                | 3436          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 343401        |
| policy_loss             | 0.4590687     |
| qf1_loss                | 2.6358362e-05 |
| qf2_loss                | 2.5041209e-05 |
| time_elapsed            | 1746          |
| total timesteps         | 343500        |
| value_loss              | 2.4276302e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0006324761 |
| ent_coef_loss           | 1.9096537    |
| entropy                 | 3.9106867    |
| ep_rewmean              | -1.39        |
| episodes                | 3440         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.4         |
| n_updates               | 343801       |
| policy_loss             | 0.44651037   |
| qf1_loss                | 7.368437e-05 |
| qf2_loss                | 6.610812e-05 |
| time_elapsed            | 1748         |
| total timesteps         | 343900       |
| value_loss              | 4.662668e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006245784  |
| ent_coef_loss           | -6.329571     |
| entropy                 | 4.228776      |
| ep_rewmean              | -1.4          |
| episodes                | 3444          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 344201        |
| policy_loss             | 0.47902513    |
| qf1_loss                | 5.703553e-05  |
| qf2_loss                | 5.1184725e-05 |
| time_elapsed            | 1750          |
| total timesteps         | 344300        |
| value_loss              | 7.120949e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0006930061 |
| ent_coef_loss           | 12.570524    |
| entropy                 | 3.0137484    |
| ep_rewmean              | -1.41        |
| episodes                | 3448         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.4         |
| n_updates               | 344601       |
| policy_loss             | 0.43558463   |
| qf1_loss                | 0.0016554786 |
| qf2_loss                | 0.0016150682 |
| time_elapsed            | 1753         |
| total timesteps         | 344700       |
| value_loss              | 9.741075e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00077369425 |
| ent_coef_loss           | -2.6233702    |
| entropy                 | 3.09448       |
| ep_rewmean              | -1.43         |
| episodes                | 3452          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 345001        |
| policy_loss             | 0.46591395    |
| qf1_loss                | 7.169075e-05  |
| qf2_loss                | 5.730036e-05  |
| time_elapsed            | 1755          |
| total timesteps         | 345100        |
| value_loss              | 0.0001233004  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00070280285 |
| ent_coef_loss           | -10.483965    |
| entropy                 | 3.723782      |
| ep_rewmean              | -1.42         |
| episodes                | 3456          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 345401        |
| policy_loss             | 0.4688694     |
| qf1_loss                | 6.737212e-05  |
| qf2_loss                | 5.400712e-05  |
| time_elapsed            | 1757          |
| total timesteps         | 345500        |
| value_loss              | 5.444137e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000619509   |
| ent_coef_loss           | -19.221481    |
| entropy                 | 3.6022234     |
| ep_rewmean              | -1.41         |
| episodes                | 3460          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 345801        |
| policy_loss             | 0.45476097    |
| qf1_loss                | 3.221596e-05  |
| qf2_loss                | 3.166693e-05  |
| time_elapsed            | 1759          |
| total timesteps         | 345900        |
| value_loss              | 6.5386186e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000564167   |
| ent_coef_loss           | -8.585033     |
| entropy                 | 2.7163808     |
| ep_rewmean              | -1.37         |
| episodes                | 3464          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 346201        |
| policy_loss             | 0.43616194    |
| qf1_loss                | 0.0013463609  |
| qf2_loss                | 0.0013432683  |
| time_elapsed            | 1761          |
| total timesteps         | 346300        |
| value_loss              | 3.8068833e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0005211632 |
| ent_coef_loss           | -10.760973   |
| entropy                 | 2.4789894    |
| ep_rewmean              | -1.34        |
| episodes                | 3468         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.3         |
| n_updates               | 346601       |
| policy_loss             | 0.44868296   |
| qf1_loss                | 0.0005185399 |
| qf2_loss                | 0.0005748231 |
| time_elapsed            | 1763         |
| total timesteps         | 346700       |
| value_loss              | 4.181165e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00048950047 |
| ent_coef_loss           | -13.639067    |
| entropy                 | 2.5537431     |
| ep_rewmean              | -1.32         |
| episodes                | 3472          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 347001        |
| policy_loss             | 0.4329019     |
| qf1_loss                | 3.7664406e-05 |
| qf2_loss                | 3.0587962e-05 |
| time_elapsed            | 1765          |
| total timesteps         | 347100        |
| value_loss              | 4.0392744e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00045167268 |
| ent_coef_loss           | 7.3104362     |
| entropy                 | 3.4761858     |
| ep_rewmean              | -1.3          |
| episodes                | 3476          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 347401        |
| policy_loss             | 0.4259656     |
| qf1_loss                | 0.0017732994  |
| qf2_loss                | 0.0016753911  |
| time_elapsed            | 1767          |
| total timesteps         | 347500        |
| value_loss              | 6.4298256e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005426222  |
| ent_coef_loss           | 12.384822     |
| entropy                 | 3.53493       |
| ep_rewmean              | -1.28         |
| episodes                | 3480          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 347801        |
| policy_loss             | 0.41641065    |
| qf1_loss                | 2.3039527e-05 |
| qf2_loss                | 3.7600636e-05 |
| time_elapsed            | 1769          |
| total timesteps         | 347900        |
| value_loss              | 3.5723726e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00061716407 |
| ent_coef_loss           | 0.42963648    |
| entropy                 | 3.8643556     |
| ep_rewmean              | -1.26         |
| episodes                | 3484          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 348201        |
| policy_loss             | 0.39825702    |
| qf1_loss                | 3.729168e-05  |
| qf2_loss                | 3.0374878e-05 |
| time_elapsed            | 1771          |
| total timesteps         | 348300        |
| value_loss              | 3.912187e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006745048  |
| ent_coef_loss           | 5.338307      |
| entropy                 | 3.784564      |
| ep_rewmean              | -1.25         |
| episodes                | 3488          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 348601        |
| policy_loss             | 0.39847934    |
| qf1_loss                | 0.0036624915  |
| qf2_loss                | 0.0035678816  |
| time_elapsed            | 1773          |
| total timesteps         | 348700        |
| value_loss              | 3.4606375e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00072837103 |
| ent_coef_loss           | 1.7964023     |
| entropy                 | 3.201508      |
| ep_rewmean              | -1.23         |
| episodes                | 3492          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 349001        |
| policy_loss             | 0.40713736    |
| qf1_loss                | 8.9435205e-05 |
| qf2_loss                | 3.3503136e-05 |
| time_elapsed            | 1775          |
| total timesteps         | 349100        |
| value_loss              | 5.9895327e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007329924  |
| ent_coef_loss           | -6.133203     |
| entropy                 | 3.2620258     |
| ep_rewmean              | -1.21         |
| episodes                | 3496          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 349401        |
| policy_loss             | 0.37364697    |
| qf1_loss                | 3.5054836e-05 |
| qf2_loss                | 2.3772984e-05 |
| time_elapsed            | 1777          |
| total timesteps         | 349500        |
| value_loss              | 6.4346066e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0007216002 |
| ent_coef_loss           | -6.007527    |
| entropy                 | 3.0803394    |
| ep_rewmean              | -1.19        |
| episodes                | 3500         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.2         |
| n_updates               | 349801       |
| policy_loss             | 0.36459285   |
| qf1_loss                | 0.0006537124 |
| qf2_loss                | 0.0006273418 |
| time_elapsed            | 1779         |
| total timesteps         | 349900       |
| value_loss              | 3.82434e-05  |
------------------------------------------
Eval num_timesteps=350000, episode_reward=-0.97 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00066367054 |
| ent_coef_loss           | -3.1894314    |
| entropy                 | 3.5850072     |
| ep_rewmean              | -1.15         |
| episodes                | 3504          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 350201        |
| policy_loss             | 0.36282003    |
| qf1_loss                | 6.7581685e-05 |
| qf2_loss                | 4.8658007e-05 |
| time_elapsed            | 1781          |
| total timesteps         | 350300        |
| value_loss              | 4.9306032e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00058977946 |
| ent_coef_loss           | 5.97535       |
| entropy                 | 3.132983      |
| ep_rewmean              | -1.05         |
| episodes                | 3508          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 350601        |
| policy_loss             | 0.34880158    |
| qf1_loss                | 0.0008718482  |
| qf2_loss                | 0.0008840632  |
| time_elapsed            | 1783          |
| total timesteps         | 350700        |
| value_loss              | 6.579272e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00060137425 |
| ent_coef_loss           | -1.9311384    |
| entropy                 | 2.767148      |
| ep_rewmean              | -0.978        |
| episodes                | 3512          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 351001        |
| policy_loss             | 0.32430404    |
| qf1_loss                | 7.255816e-05  |
| qf2_loss                | 3.5470453e-05 |
| time_elapsed            | 1785          |
| total timesteps         | 351100        |
| value_loss              | 8.808079e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0005781705 |
| ent_coef_loss           | -4.641452    |
| entropy                 | 2.6057074    |
| ep_rewmean              | -0.841       |
| episodes                | 3516         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -0.8         |
| n_updates               | 351401       |
| policy_loss             | 0.3341301    |
| qf1_loss                | 0.0006934384 |
| qf2_loss                | 0.0006884268 |
| time_elapsed            | 1788         |
| total timesteps         | 351500       |
| value_loss              | 6.805624e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006141442  |
| ent_coef_loss           | 5.243617      |
| entropy                 | 2.344759      |
| ep_rewmean              | -0.816        |
| episodes                | 3520          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 351801        |
| policy_loss             | 0.29874805    |
| qf1_loss                | 9.304991e-05  |
| qf2_loss                | 6.3332904e-05 |
| time_elapsed            | 1790          |
| total timesteps         | 351900        |
| value_loss              | 6.4389795e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006974972  |
| ent_coef_loss           | 19.470978     |
| entropy                 | 1.2283024     |
| ep_rewmean              | -0.797        |
| episodes                | 3524          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 352201        |
| policy_loss             | 0.31511205    |
| qf1_loss                | 6.346741e-05  |
| qf2_loss                | 6.753272e-05  |
| time_elapsed            | 1792          |
| total timesteps         | 352300        |
| value_loss              | 4.7986505e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008180405  |
| ent_coef_loss           | 12.643364     |
| entropy                 | 1.7474704     |
| ep_rewmean              | -0.785        |
| episodes                | 3528          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 352601        |
| policy_loss             | 0.32692003    |
| qf1_loss                | 6.896951e-05  |
| qf2_loss                | 5.1446063e-05 |
| time_elapsed            | 1794          |
| total timesteps         | 352700        |
| value_loss              | 7.8478915e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009476291  |
| ent_coef_loss           | 7.6477194     |
| entropy                 | 1.943834      |
| ep_rewmean              | -0.768        |
| episodes                | 3532          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 353001        |
| policy_loss             | 0.28354543    |
| qf1_loss                | 0.0006812268  |
| qf2_loss                | 0.0006921003  |
| time_elapsed            | 1796          |
| total timesteps         | 353100        |
| value_loss              | 6.0498423e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000979891   |
| ent_coef_loss           | 10.033185     |
| entropy                 | 2.1130626     |
| ep_rewmean              | -0.745        |
| episodes                | 3536          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 353401        |
| policy_loss             | 0.28686544    |
| qf1_loss                | 0.0013004531  |
| qf2_loss                | 0.0013106483  |
| time_elapsed            | 1798          |
| total timesteps         | 353500        |
| value_loss              | 3.6476173e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010071729  |
| ent_coef_loss           | -4.3248606    |
| entropy                 | 2.3197446     |
| ep_rewmean              | -0.734        |
| episodes                | 3540          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 353801        |
| policy_loss             | 0.3125528     |
| qf1_loss                | 0.0018453444  |
| qf2_loss                | 0.0017816555  |
| time_elapsed            | 1800          |
| total timesteps         | 353900        |
| value_loss              | 5.4919656e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009539172  |
| ent_coef_loss           | -7.709593     |
| entropy                 | 2.6402955     |
| ep_rewmean              | -0.728        |
| episodes                | 3544          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 354201        |
| policy_loss             | 0.27008677    |
| qf1_loss                | 4.121633e-05  |
| qf2_loss                | 3.41594e-05   |
| time_elapsed            | 1802          |
| total timesteps         | 354300        |
| value_loss              | 5.6018427e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008634558  |
| ent_coef_loss           | -2.665812     |
| entropy                 | 3.1550505     |
| ep_rewmean              | -0.723        |
| episodes                | 3548          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 354601        |
| policy_loss             | 0.24311864    |
| qf1_loss                | 3.0051506e-05 |
| qf2_loss                | 6.3695144e-05 |
| time_elapsed            | 1804          |
| total timesteps         | 354700        |
| value_loss              | 6.744836e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000852497   |
| ent_coef_loss           | -0.32005966   |
| entropy                 | 3.0803442     |
| ep_rewmean              | -0.733        |
| episodes                | 3552          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 355001        |
| policy_loss             | 0.3101078     |
| qf1_loss                | 5.6335382e-05 |
| qf2_loss                | 6.9314076e-05 |
| time_elapsed            | 1806          |
| total timesteps         | 355100        |
| value_loss              | 0.00014014351 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008658488  |
| ent_coef_loss           | -1.2074742    |
| entropy                 | 3.334849      |
| ep_rewmean              | -0.767        |
| episodes                | 3556          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 355401        |
| policy_loss             | 0.30301762    |
| qf1_loss                | 0.002044328   |
| qf2_loss                | 0.0020884776  |
| time_elapsed            | 1808          |
| total timesteps         | 355500        |
| value_loss              | 3.5724657e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009348541  |
| ent_coef_loss           | 6.4091663     |
| entropy                 | 2.5069726     |
| ep_rewmean              | -0.759        |
| episodes                | 3560          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 355801        |
| policy_loss             | 0.28601027    |
| qf1_loss                | 0.0013288566  |
| qf2_loss                | 0.0012183561  |
| time_elapsed            | 1810          |
| total timesteps         | 355900        |
| value_loss              | 0.00010098197 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0010548972   |
| ent_coef_loss           | 13.345322      |
| entropy                 | 2.2393248      |
| ep_rewmean              | -0.75          |
| episodes                | 3564           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.7           |
| n_updates               | 356201         |
| policy_loss             | 0.29851508     |
| qf1_loss                | 5.0346047e-05  |
| qf2_loss                | 7.563102e-05   |
| time_elapsed            | 1812           |
| total timesteps         | 356300         |
| value_loss              | 0.000102279475 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001150933   |
| ent_coef_loss           | 8.664909      |
| entropy                 | 3.119326      |
| ep_rewmean              | -0.74         |
| episodes                | 3568          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 356601        |
| policy_loss             | 0.26620913    |
| qf1_loss                | 6.314033e-05  |
| qf2_loss                | 4.3251828e-05 |
| time_elapsed            | 1814          |
| total timesteps         | 356700        |
| value_loss              | 6.521582e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011605027 |
| ent_coef_loss           | -0.43371356  |
| entropy                 | 2.8257184    |
| ep_rewmean              | -0.734       |
| episodes                | 3572         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -0.7         |
| n_updates               | 357001       |
| policy_loss             | 0.30807334   |
| qf1_loss                | 4.770101e-05 |
| qf2_loss                | 4.474585e-05 |
| time_elapsed            | 1816         |
| total timesteps         | 357100       |
| value_loss              | 8.683477e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010134404  |
| ent_coef_loss           | -20.45166     |
| entropy                 | 3.6502514     |
| ep_rewmean              | -0.738        |
| episodes                | 3576          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 357401        |
| policy_loss             | 0.28319088    |
| qf1_loss                | 5.1932868e-05 |
| qf2_loss                | 5.689259e-05  |
| time_elapsed            | 1818          |
| total timesteps         | 357500        |
| value_loss              | 5.2406984e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008678432  |
| ent_coef_loss           | -9.602898     |
| entropy                 | 3.184775      |
| ep_rewmean              | -0.743        |
| episodes                | 3580          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 357801        |
| policy_loss             | 0.25755736    |
| qf1_loss                | 5.0319166e-05 |
| qf2_loss                | 6.892596e-05  |
| time_elapsed            | 1820          |
| total timesteps         | 357900        |
| value_loss              | 7.3040166e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00081302365 |
| ent_coef_loss           | -0.4633708    |
| entropy                 | 2.552517      |
| ep_rewmean              | -0.755        |
| episodes                | 3584          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 358201        |
| policy_loss             | 0.2903759     |
| qf1_loss                | 0.0008341472  |
| qf2_loss                | 0.0008155411  |
| time_elapsed            | 1822          |
| total timesteps         | 358300        |
| value_loss              | 6.03477e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00081833894 |
| ent_coef_loss           | 1.0673299     |
| entropy                 | 2.4770625     |
| ep_rewmean              | -0.77         |
| episodes                | 3588          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 358601        |
| policy_loss             | 0.2876582     |
| qf1_loss                | 3.658956e-05  |
| qf2_loss                | 2.4595967e-05 |
| time_elapsed            | 1824          |
| total timesteps         | 358700        |
| value_loss              | 6.071001e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00085377356 |
| ent_coef_loss           | -0.5177865    |
| entropy                 | 2.988215      |
| ep_rewmean              | -0.775        |
| episodes                | 3592          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 359001        |
| policy_loss             | 0.2594459     |
| qf1_loss                | 4.7034067e-05 |
| qf2_loss                | 5.0602794e-05 |
| time_elapsed            | 1826          |
| total timesteps         | 359100        |
| value_loss              | 9.207469e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0008855373 |
| ent_coef_loss           | 1.0075127    |
| entropy                 | 3.0551057    |
| ep_rewmean              | -0.776       |
| episodes                | 3596         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -0.8         |
| n_updates               | 359401       |
| policy_loss             | 0.27438977   |
| qf1_loss                | 0.0015051889 |
| qf2_loss                | 0.0015611348 |
| time_elapsed            | 1828         |
| total timesteps         | 359500       |
| value_loss              | 7.592105e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008988775  |
| ent_coef_loss           | 1.3233061     |
| entropy                 | 3.2779741     |
| ep_rewmean              | -0.775        |
| episodes                | 3600          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 359801        |
| policy_loss             | 0.26899       |
| qf1_loss                | 6.407247e-05  |
| qf2_loss                | 9.20868e-05   |
| time_elapsed            | 1830          |
| total timesteps         | 359900        |
| value_loss              | 5.7188074e-05 |
-------------------------------------------
Eval num_timesteps=360000, episode_reward=-0.61 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000883012   |
| ent_coef_loss           | -6.094122     |
| entropy                 | 3.1243887     |
| ep_rewmean              | -0.768        |
| episodes                | 3604          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 360201        |
| policy_loss             | 0.2511537     |
| qf1_loss                | 3.7857277e-05 |
| qf2_loss                | 5.922198e-05  |
| time_elapsed            | 1833          |
| total timesteps         | 360300        |
| value_loss              | 0.00013646932 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00092772546 |
| ent_coef_loss           | -0.76850367   |
| entropy                 | 2.663029      |
| ep_rewmean              | -0.752        |
| episodes                | 3608          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 360601        |
| policy_loss             | 0.23087169    |
| qf1_loss                | 6.009168e-05  |
| qf2_loss                | 4.5800625e-05 |
| time_elapsed            | 1835          |
| total timesteps         | 360700        |
| value_loss              | 9.692606e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009589444  |
| ent_coef_loss           | 5.4555907     |
| entropy                 | 2.8278792     |
| ep_rewmean              | -0.749        |
| episodes                | 3612          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 361001        |
| policy_loss             | 0.29086596    |
| qf1_loss                | 0.002167969   |
| qf2_loss                | 0.0021953022  |
| time_elapsed            | 1837          |
| total timesteps         | 361100        |
| value_loss              | 5.6343903e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000980827   |
| ent_coef_loss           | -0.09707761   |
| entropy                 | 2.8659678     |
| ep_rewmean              | -0.757        |
| episodes                | 3616          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 361401        |
| policy_loss             | 0.29136962    |
| qf1_loss                | 4.5471643e-05 |
| qf2_loss                | 7.327475e-05  |
| time_elapsed            | 1839          |
| total timesteps         | 361500        |
| value_loss              | 4.207418e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009937349  |
| ent_coef_loss           | -4.667689     |
| entropy                 | 3.523024      |
| ep_rewmean              | -0.76         |
| episodes                | 3620          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 361801        |
| policy_loss             | 0.2692122     |
| qf1_loss                | 4.2077583e-05 |
| qf2_loss                | 2.7635826e-05 |
| time_elapsed            | 1841          |
| total timesteps         | 361900        |
| value_loss              | 4.4121552e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010224127  |
| ent_coef_loss           | -0.54937863   |
| entropy                 | 3.1964355     |
| ep_rewmean              | -0.752        |
| episodes                | 3624          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 362201        |
| policy_loss             | 0.2979653     |
| qf1_loss                | 0.00081240915 |
| qf2_loss                | 0.00080032274 |
| time_elapsed            | 1843          |
| total timesteps         | 362300        |
| value_loss              | 7.798975e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009898206  |
| ent_coef_loss           | -1.688309     |
| entropy                 | 3.0559182     |
| ep_rewmean              | -0.739        |
| episodes                | 3628          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 362601        |
| policy_loss             | 0.29195714    |
| qf1_loss                | 4.5472203e-05 |
| qf2_loss                | 8.4786545e-05 |
| time_elapsed            | 1845          |
| total timesteps         | 362700        |
| value_loss              | 5.597479e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009955405  |
| ent_coef_loss           | -12.417268    |
| entropy                 | 3.4344847     |
| ep_rewmean              | -0.734        |
| episodes                | 3632          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 363001        |
| policy_loss             | 0.27251863    |
| qf1_loss                | 0.00024000605 |
| qf2_loss                | 0.0002631376  |
| time_elapsed            | 1847          |
| total timesteps         | 363100        |
| value_loss              | 8.173644e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009769476  |
| ent_coef_loss           | -0.94177675   |
| entropy                 | 3.0547934     |
| ep_rewmean              | -0.735        |
| episodes                | 3636          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 363401        |
| policy_loss             | 0.29823202    |
| qf1_loss                | 3.067882e-05  |
| qf2_loss                | 4.5391207e-05 |
| time_elapsed            | 1849          |
| total timesteps         | 363500        |
| value_loss              | 6.0738254e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0009857172 |
| ent_coef_loss           | -5.2105308   |
| entropy                 | 3.514958     |
| ep_rewmean              | -0.73        |
| episodes                | 3640         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -0.7         |
| n_updates               | 363801       |
| policy_loss             | 0.31129226   |
| qf1_loss                | 0.0015529266 |
| qf2_loss                | 0.0015692599 |
| time_elapsed            | 1851         |
| total timesteps         | 363900       |
| value_loss              | 8.79087e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009910981  |
| ent_coef_loss           | -9.100559     |
| entropy                 | 3.7408288     |
| ep_rewmean              | -0.727        |
| episodes                | 3644          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 364201        |
| policy_loss             | 0.30316108    |
| qf1_loss                | 5.4207594e-05 |
| qf2_loss                | 6.451321e-05  |
| time_elapsed            | 1853          |
| total timesteps         | 364300        |
| value_loss              | 0.00013284151 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0009876217 |
| ent_coef_loss           | -4.395677    |
| entropy                 | 4.0163717    |
| ep_rewmean              | -0.724       |
| episodes                | 3648         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -0.7         |
| n_updates               | 364601       |
| policy_loss             | 0.32680148   |
| qf1_loss                | 0.0014862259 |
| qf2_loss                | 0.0014662421 |
| time_elapsed            | 1855         |
| total timesteps         | 364700       |
| value_loss              | 8.270747e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010125603  |
| ent_coef_loss           | 0.07255173    |
| entropy                 | 4.36071       |
| ep_rewmean              | -0.697        |
| episodes                | 3652          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 365001        |
| policy_loss             | 0.31778085    |
| qf1_loss                | 0.0010880205  |
| qf2_loss                | 0.0010555213  |
| time_elapsed            | 1857          |
| total timesteps         | 365100        |
| value_loss              | 0.00015134308 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010364455 |
| ent_coef_loss           | -3.299327    |
| entropy                 | 4.215267     |
| ep_rewmean              | -0.66        |
| episodes                | 3656         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -0.7         |
| n_updates               | 365401       |
| policy_loss             | 0.33499676   |
| qf1_loss                | 0.0040581757 |
| qf2_loss                | 0.004005191  |
| time_elapsed            | 1859         |
| total timesteps         | 365500       |
| value_loss              | 6.9776e-05   |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001059421   |
| ent_coef_loss           | 3.8031569     |
| entropy                 | 4.043889      |
| ep_rewmean              | -0.664        |
| episodes                | 3660          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 365801        |
| policy_loss             | 0.35334533    |
| qf1_loss                | 3.5631296e-05 |
| qf2_loss                | 5.669157e-05  |
| time_elapsed            | 1861          |
| total timesteps         | 365900        |
| value_loss              | 8.693669e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010908424  |
| ent_coef_loss           | 8.817692      |
| entropy                 | 3.687268      |
| ep_rewmean              | -0.676        |
| episodes                | 3664          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 366201        |
| policy_loss             | 0.33425757    |
| qf1_loss                | 0.0015979966  |
| qf2_loss                | 0.0015884853  |
| time_elapsed            | 1863          |
| total timesteps         | 366300        |
| value_loss              | 0.00010552342 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010985485  |
| ent_coef_loss           | -4.6535163    |
| entropy                 | 4.1757708     |
| ep_rewmean              | -0.687        |
| episodes                | 3668          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 366601        |
| policy_loss             | 0.3305685     |
| qf1_loss                | 0.00042783815 |
| qf2_loss                | 0.00045533638 |
| time_elapsed            | 1865          |
| total timesteps         | 366700        |
| value_loss              | 0.00018383538 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010859488  |
| ent_coef_loss           | -1.8278894    |
| entropy                 | 3.3804266     |
| ep_rewmean              | -0.695        |
| episodes                | 3672          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 367001        |
| policy_loss             | 0.36016533    |
| qf1_loss                | 5.4844066e-05 |
| qf2_loss                | 7.800258e-05  |
| time_elapsed            | 1867          |
| total timesteps         | 367100        |
| value_loss              | 0.00010635183 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010582324  |
| ent_coef_loss           | -7.4117374    |
| entropy                 | 4.2744856     |
| ep_rewmean              | -0.707        |
| episodes                | 3676          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 367401        |
| policy_loss             | 0.3518504     |
| qf1_loss                | 5.9504237e-05 |
| qf2_loss                | 3.7408143e-05 |
| time_elapsed            | 1869          |
| total timesteps         | 367500        |
| value_loss              | 0.00011757184 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010715406  |
| ent_coef_loss           | 2.839587      |
| entropy                 | 4.1934423     |
| ep_rewmean              | -0.717        |
| episodes                | 3680          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 367801        |
| policy_loss             | 0.3787527     |
| qf1_loss                | 0.0012919907  |
| qf2_loss                | 0.0012519201  |
| time_elapsed            | 1871          |
| total timesteps         | 367900        |
| value_loss              | 0.00013321012 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011406131  |
| ent_coef_loss           | 5.167126      |
| entropy                 | 3.561349      |
| ep_rewmean              | -0.735        |
| episodes                | 3684          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 368201        |
| policy_loss             | 0.39742565    |
| qf1_loss                | 0.0017234547  |
| qf2_loss                | 0.0016306611  |
| time_elapsed            | 1873          |
| total timesteps         | 368300        |
| value_loss              | 7.1633476e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012139031  |
| ent_coef_loss           | 17.887224     |
| entropy                 | 3.6931336     |
| ep_rewmean              | -0.754        |
| episodes                | 3688          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 368601        |
| policy_loss             | 0.42244703    |
| qf1_loss                | 0.0011026168  |
| qf2_loss                | 0.0010793175  |
| time_elapsed            | 1876          |
| total timesteps         | 368700        |
| value_loss              | 8.4938074e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012498497 |
| ent_coef_loss           | 3.1210465    |
| entropy                 | 3.618691     |
| ep_rewmean              | -0.777       |
| episodes                | 3692         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -0.8         |
| n_updates               | 369001       |
| policy_loss             | 0.4331287    |
| qf1_loss                | 0.001509893  |
| qf2_loss                | 0.0014394026 |
| time_elapsed            | 1878         |
| total timesteps         | 369100       |
| value_loss              | 8.777895e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012534031  |
| ent_coef_loss           | 2.246628      |
| entropy                 | 3.956791      |
| ep_rewmean              | -0.827        |
| episodes                | 3696          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 369401        |
| policy_loss             | 0.42927933    |
| qf1_loss                | 6.419196e-05  |
| qf2_loss                | 5.0437324e-05 |
| time_elapsed            | 1880          |
| total timesteps         | 369500        |
| value_loss              | 9.419897e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001263538   |
| ent_coef_loss           | -3.4985313    |
| entropy                 | 3.8450089     |
| ep_rewmean              | -0.878        |
| episodes                | 3700          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 369801        |
| policy_loss             | 0.4247865     |
| qf1_loss                | 0.001879794   |
| qf2_loss                | 0.0019028559  |
| time_elapsed            | 1882          |
| total timesteps         | 369900        |
| value_loss              | 7.7887344e-05 |
-------------------------------------------
Eval num_timesteps=370000, episode_reward=-2.85 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011133968 |
| ent_coef_loss           | -15.297184   |
| entropy                 | 4.0984373    |
| ep_rewmean              | -0.965       |
| episodes                | 3704         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1           |
| n_updates               | 370201       |
| policy_loss             | 0.46201366   |
| qf1_loss                | 0.0010593754 |
| qf2_loss                | 0.0010585404 |
| time_elapsed            | 1884         |
| total timesteps         | 370300       |
| value_loss              | 8.840159e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009698087  |
| ent_coef_loss           | -7.483394     |
| entropy                 | 3.0839999     |
| ep_rewmean              | -1.03         |
| episodes                | 3708          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 370601        |
| policy_loss             | 0.46681798    |
| qf1_loss                | 9.287792e-05  |
| qf2_loss                | 0.00011367284 |
| time_elapsed            | 1886          |
| total timesteps         | 370700        |
| value_loss              | 0.00014890506 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0009002806 |
| ent_coef_loss           | -12.03837    |
| entropy                 | 3.520277     |
| ep_rewmean              | -1.11        |
| episodes                | 3712         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.1         |
| n_updates               | 371001       |
| policy_loss             | 0.41657677   |
| qf1_loss                | 7.088708e-05 |
| qf2_loss                | 5.321908e-05 |
| time_elapsed            | 1888         |
| total timesteps         | 371100       |
| value_loss              | 6.420436e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008470992  |
| ent_coef_loss           | -3.3337996    |
| entropy                 | 4.174138      |
| ep_rewmean              | -1.17         |
| episodes                | 3716          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 371401        |
| policy_loss             | 0.42571032    |
| qf1_loss                | 3.2693046e-05 |
| qf2_loss                | 3.498581e-05  |
| time_elapsed            | 1890          |
| total timesteps         | 371500        |
| value_loss              | 5.6075394e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0007911152 |
| ent_coef_loss           | -7.6762676   |
| entropy                 | 2.9554768    |
| ep_rewmean              | -1.17        |
| episodes                | 3720         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.2         |
| n_updates               | 371801       |
| policy_loss             | 0.43468678   |
| qf1_loss                | 0.0014278231 |
| qf2_loss                | 0.0014493652 |
| time_elapsed            | 1892         |
| total timesteps         | 371900       |
| value_loss              | 9.325419e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00076622254 |
| ent_coef_loss           | 2.7596538     |
| entropy                 | 3.0846543     |
| ep_rewmean              | -1.16         |
| episodes                | 3724          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 372201        |
| policy_loss             | 0.45105642    |
| qf1_loss                | 0.0001748174  |
| qf2_loss                | 0.00023156253 |
| time_elapsed            | 1894          |
| total timesteps         | 372300        |
| value_loss              | 7.6447366e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0007610617 |
| ent_coef_loss           | 3.999464     |
| entropy                 | 2.582238     |
| ep_rewmean              | -1.16        |
| episodes                | 3728         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.2         |
| n_updates               | 372601       |
| policy_loss             | 0.47880715   |
| qf1_loss                | 7.847546e-05 |
| qf2_loss                | 9.979631e-05 |
| time_elapsed            | 1896         |
| total timesteps         | 372700       |
| value_loss              | 0.0002570451 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007417275  |
| ent_coef_loss           | -5.715104     |
| entropy                 | 2.2482557     |
| ep_rewmean              | -1.16         |
| episodes                | 3732          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 373001        |
| policy_loss             | 0.467139      |
| qf1_loss                | 0.00013400908 |
| qf2_loss                | 0.00016775115 |
| time_elapsed            | 1898          |
| total timesteps         | 373100        |
| value_loss              | 0.00013191457 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006644644  |
| ent_coef_loss           | 2.6013036     |
| entropy                 | 2.7002861     |
| ep_rewmean              | -1.16         |
| episodes                | 3736          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 373401        |
| policy_loss             | 0.5003752     |
| qf1_loss                | 0.0040360205  |
| qf2_loss                | 0.0036971467  |
| time_elapsed            | 1900          |
| total timesteps         | 373500        |
| value_loss              | 0.00013690992 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006145452  |
| ent_coef_loss           | 4.4202223     |
| entropy                 | 2.5824099     |
| ep_rewmean              | -1.17         |
| episodes                | 3740          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 373801        |
| policy_loss             | 0.46934307    |
| qf1_loss                | 0.0010222     |
| qf2_loss                | 0.00086143153 |
| time_elapsed            | 1902          |
| total timesteps         | 373900        |
| value_loss              | 0.00022931542 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00059945974 |
| ent_coef_loss           | 4.9160233     |
| entropy                 | 2.5704174     |
| ep_rewmean              | -1.19         |
| episodes                | 3744          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 374201        |
| policy_loss             | 0.47570983    |
| qf1_loss                | 7.151149e-05  |
| qf2_loss                | 0.0001236959  |
| time_elapsed            | 1904          |
| total timesteps         | 374300        |
| value_loss              | 0.00023323752 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005809459  |
| ent_coef_loss           | 7.1264777     |
| entropy                 | 2.9586143     |
| ep_rewmean              | -1.2          |
| episodes                | 3748          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 374601        |
| policy_loss             | 0.49848893    |
| qf1_loss                | 8.524631e-05  |
| qf2_loss                | 0.00013518895 |
| time_elapsed            | 1906          |
| total timesteps         | 374700        |
| value_loss              | 7.964633e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0006332979 |
| ent_coef_loss           | -8.225558    |
| entropy                 | 2.8809605    |
| ep_rewmean              | -1.23        |
| episodes                | 3752         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.2         |
| n_updates               | 375001       |
| policy_loss             | 0.4550314    |
| qf1_loss                | 0.0014822666 |
| qf2_loss                | 0.0015418631 |
| time_elapsed            | 1909         |
| total timesteps         | 375100       |
| value_loss              | 0.0001359464 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006733839  |
| ent_coef_loss           | 1.9093158     |
| entropy                 | 2.842579      |
| ep_rewmean              | -1.25         |
| episodes                | 3756          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 375401        |
| policy_loss             | 0.45829904    |
| qf1_loss                | 0.0001431946  |
| qf2_loss                | 0.00011515949 |
| time_elapsed            | 1911          |
| total timesteps         | 375500        |
| value_loss              | 0.00014040738 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007026531  |
| ent_coef_loss           | -1.3654776    |
| entropy                 | 3.4913507     |
| ep_rewmean              | -1.27         |
| episodes                | 3760          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 375801        |
| policy_loss             | 0.40996075    |
| qf1_loss                | 0.0006884459  |
| qf2_loss                | 0.0006462728  |
| time_elapsed            | 1913          |
| total timesteps         | 375900        |
| value_loss              | 0.00021464794 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00069791306  |
| ent_coef_loss           | 3.6133502      |
| entropy                 | 4.249322       |
| ep_rewmean              | -1.27          |
| episodes                | 3764           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -1.3           |
| n_updates               | 376201         |
| policy_loss             | 0.4643712      |
| qf1_loss                | 0.000114235576 |
| qf2_loss                | 0.0001396212   |
| time_elapsed            | 1915           |
| total timesteps         | 376300         |
| value_loss              | 7.6345576e-05  |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0006966556   |
| ent_coef_loss           | 5.279893       |
| entropy                 | 3.478078       |
| ep_rewmean              | -1.26          |
| episodes                | 3768           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -1.3           |
| n_updates               | 376601         |
| policy_loss             | 0.43542317     |
| qf1_loss                | 0.000108279244 |
| qf2_loss                | 6.0832113e-05  |
| time_elapsed            | 1917           |
| total timesteps         | 376700         |
| value_loss              | 8.1097314e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006835646  |
| ent_coef_loss           | 7.372301      |
| entropy                 | 3.5618224     |
| ep_rewmean              | -1.24         |
| episodes                | 3772          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 377001        |
| policy_loss             | 0.43797016    |
| qf1_loss                | 0.0030929032  |
| qf2_loss                | 0.0031594778  |
| time_elapsed            | 1919          |
| total timesteps         | 377100        |
| value_loss              | 0.00012515057 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006768142  |
| ent_coef_loss           | -4.2600145    |
| entropy                 | 3.3281906     |
| ep_rewmean              | -1.22         |
| episodes                | 3776          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 377401        |
| policy_loss             | 0.396914      |
| qf1_loss                | 0.0001425634  |
| qf2_loss                | 0.00011383235 |
| time_elapsed            | 1921          |
| total timesteps         | 377500        |
| value_loss              | 9.8499535e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00064596994 |
| ent_coef_loss           | -0.47803116   |
| entropy                 | 3.3401544     |
| ep_rewmean              | -1.22         |
| episodes                | 3780          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 377801        |
| policy_loss             | 0.40461907    |
| qf1_loss                | 0.00054361706 |
| qf2_loss                | 0.00066044036 |
| time_elapsed            | 1923          |
| total timesteps         | 377900        |
| value_loss              | 9.794255e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0006457738 |
| ent_coef_loss           | -8.423407    |
| entropy                 | 2.9483447    |
| ep_rewmean              | -1.27        |
| episodes                | 3784         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.3         |
| n_updates               | 378201       |
| policy_loss             | 0.37408352   |
| qf1_loss                | 0.0001661332 |
| qf2_loss                | 6.574651e-05 |
| time_elapsed            | 1925         |
| total timesteps         | 378300       |
| value_loss              | 9.340531e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006341083  |
| ent_coef_loss           | -2.6524386    |
| entropy                 | 3.510444      |
| ep_rewmean              | -1.31         |
| episodes                | 3788          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 378601        |
| policy_loss             | 0.3729287     |
| qf1_loss                | 0.0006014977  |
| qf2_loss                | 0.0006089528  |
| time_elapsed            | 1927          |
| total timesteps         | 378700        |
| value_loss              | 0.00010889195 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.000637644  |
| ent_coef_loss           | -11.654725   |
| entropy                 | 4.161186     |
| ep_rewmean              | -1.34        |
| episodes                | 3792         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.3         |
| n_updates               | 379001       |
| policy_loss             | 0.38156766   |
| qf1_loss                | 0.0007722826 |
| qf2_loss                | 0.0007711402 |
| time_elapsed            | 1929         |
| total timesteps         | 379100       |
| value_loss              | 8.499295e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00070770696 |
| ent_coef_loss           | -3.5248427    |
| entropy                 | 4.084511      |
| ep_rewmean              | -1.36         |
| episodes                | 3796          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.4          |
| n_updates               | 379401        |
| policy_loss             | 0.37227643    |
| qf1_loss                | 0.0019181595  |
| qf2_loss                | 0.0018511178  |
| time_elapsed            | 1931          |
| total timesteps         | 379500        |
| value_loss              | 0.00016657966 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0007335134   |
| ent_coef_loss           | -10.525412     |
| entropy                 | 4.371802       |
| ep_rewmean              | -1.35          |
| episodes                | 3800           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -1.4           |
| n_updates               | 379801         |
| policy_loss             | 0.3452206      |
| qf1_loss                | 7.44016e-05    |
| qf2_loss                | 7.369312e-05   |
| time_elapsed            | 1933           |
| total timesteps         | 379900         |
| value_loss              | 0.000112598056 |
--------------------------------------------
Eval num_timesteps=380000, episode_reward=-2.11 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00069357536 |
| ent_coef_loss           | -4.8188343    |
| entropy                 | 3.88171       |
| ep_rewmean              | -1.31         |
| episodes                | 3804          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 380201        |
| policy_loss             | 0.37949604    |
| qf1_loss                | 0.00044094928 |
| qf2_loss                | 0.00048229925 |
| time_elapsed            | 1936          |
| total timesteps         | 380300        |
| value_loss              | 6.5456785e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00064446946 |
| ent_coef_loss           | -2.8458738    |
| entropy                 | 3.7758322     |
| ep_rewmean              | -1.26         |
| episodes                | 3808          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 380601        |
| policy_loss             | 0.40158033    |
| qf1_loss                | 0.0005473313  |
| qf2_loss                | 0.0005394988  |
| time_elapsed            | 1938          |
| total timesteps         | 380700        |
| value_loss              | 5.312426e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0006377246 |
| ent_coef_loss           | -4.4158053   |
| entropy                 | 3.6480825    |
| ep_rewmean              | -1.19        |
| episodes                | 3812         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -1.2         |
| n_updates               | 381001       |
| policy_loss             | 0.38159025   |
| qf1_loss                | 7.45836e-05  |
| qf2_loss                | 9.50959e-05  |
| time_elapsed            | 1940         |
| total timesteps         | 381100       |
| value_loss              | 6.261844e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00063483015 |
| ent_coef_loss           | 1.4932423     |
| entropy                 | 3.5986717     |
| ep_rewmean              | -1.12         |
| episodes                | 3816          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 381401        |
| policy_loss             | 0.3960625     |
| qf1_loss                | 0.00019334164 |
| qf2_loss                | 0.00017274366 |
| time_elapsed            | 1942          |
| total timesteps         | 381500        |
| value_loss              | 6.533443e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006120116  |
| ent_coef_loss           | -6.9446917    |
| entropy                 | 3.3314056     |
| ep_rewmean              | -1.12         |
| episodes                | 3820          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 381801        |
| policy_loss             | 0.3867188     |
| qf1_loss                | 9.732742e-05  |
| qf2_loss                | 7.625735e-05  |
| time_elapsed            | 1944          |
| total timesteps         | 381900        |
| value_loss              | 0.00011513069 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00057121855 |
| ent_coef_loss           | -5.5692263    |
| entropy                 | 3.4428484     |
| ep_rewmean              | -1.12         |
| episodes                | 3824          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 382201        |
| policy_loss             | 0.37569106    |
| qf1_loss                | 0.001277348   |
| qf2_loss                | 0.0012949761  |
| time_elapsed            | 1946          |
| total timesteps         | 382300        |
| value_loss              | 6.6616645e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00060489844  |
| ent_coef_loss           | 5.3042994      |
| entropy                 | 3.5393262      |
| ep_rewmean              | -1.12          |
| episodes                | 3828           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -1.1           |
| n_updates               | 382601         |
| policy_loss             | 0.38565987     |
| qf1_loss                | 0.00013757552  |
| qf2_loss                | 0.000104190935 |
| time_elapsed            | 1948           |
| total timesteps         | 382700         |
| value_loss              | 7.956876e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006110336  |
| ent_coef_loss           | -6.7952147    |
| entropy                 | 3.1282547     |
| ep_rewmean              | -1.13         |
| episodes                | 3832          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 383001        |
| policy_loss             | 0.37346327    |
| qf1_loss                | 6.157903e-05  |
| qf2_loss                | 3.4462762e-05 |
| time_elapsed            | 1950          |
| total timesteps         | 383100        |
| value_loss              | 6.868366e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00059129664 |
| ent_coef_loss           | -9.837374     |
| entropy                 | 3.0735443     |
| ep_rewmean              | -1.12         |
| episodes                | 3836          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 383401        |
| policy_loss             | 0.37796652    |
| qf1_loss                | 0.0010123948  |
| qf2_loss                | 0.0010495065  |
| time_elapsed            | 1952          |
| total timesteps         | 383500        |
| value_loss              | 8.527279e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005617299  |
| ent_coef_loss           | 6.6150255     |
| entropy                 | 2.3655088     |
| ep_rewmean              | -1.11         |
| episodes                | 3840          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 383801        |
| policy_loss             | 0.3976835     |
| qf1_loss                | 5.1494073e-05 |
| qf2_loss                | 4.228981e-05  |
| time_elapsed            | 1954          |
| total timesteps         | 383900        |
| value_loss              | 4.4383953e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00055609934 |
| ent_coef_loss           | 11.499243     |
| entropy                 | 3.5275164     |
| ep_rewmean              | -1.09         |
| episodes                | 3844          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 384201        |
| policy_loss             | 0.3717429     |
| qf1_loss                | 0.0006969797  |
| qf2_loss                | 0.0006980884  |
| time_elapsed            | 1956          |
| total timesteps         | 384300        |
| value_loss              | 0.00015593565 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000558491   |
| ent_coef_loss           | 6.366148      |
| entropy                 | 2.8536782     |
| ep_rewmean              | -1.08         |
| episodes                | 3848          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 384601        |
| policy_loss             | 0.40837526    |
| qf1_loss                | 0.0052682823  |
| qf2_loss                | 0.0051323026  |
| time_elapsed            | 1958          |
| total timesteps         | 384700        |
| value_loss              | 5.6045596e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005920697  |
| ent_coef_loss           | -4.720757     |
| entropy                 | 3.19195       |
| ep_rewmean              | -1.06         |
| episodes                | 3852          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 385001        |
| policy_loss             | 0.36996305    |
| qf1_loss                | 0.0002952935  |
| qf2_loss                | 0.0003035957  |
| time_elapsed            | 1960          |
| total timesteps         | 385100        |
| value_loss              | 5.5421922e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000599794   |
| ent_coef_loss           | 2.7792556     |
| entropy                 | 3.1582196     |
| ep_rewmean              | -1.04         |
| episodes                | 3856          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 385401        |
| policy_loss             | 0.35444275    |
| qf1_loss                | 7.0431044e-05 |
| qf2_loss                | 5.9071146e-05 |
| time_elapsed            | 1962          |
| total timesteps         | 385500        |
| value_loss              | 8.617365e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0006280616   |
| ent_coef_loss           | -2.0845392     |
| entropy                 | 3.7597551      |
| ep_rewmean              | -1.02          |
| episodes                | 3860           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -1             |
| n_updates               | 385801         |
| policy_loss             | 0.38993758     |
| qf1_loss                | 9.551952e-05   |
| qf2_loss                | 0.000113050526 |
| time_elapsed            | 1964           |
| total timesteps         | 385900         |
| value_loss              | 8.303123e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00061621045 |
| ent_coef_loss           | -4.8030405    |
| entropy                 | 3.7684155     |
| ep_rewmean              | -1.01         |
| episodes                | 3864          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 386201        |
| policy_loss             | 0.34731442    |
| qf1_loss                | 0.00019478661 |
| qf2_loss                | 0.00011106738 |
| time_elapsed            | 1966          |
| total timesteps         | 386300        |
| value_loss              | 6.6818306e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00062154233 |
| ent_coef_loss           | 3.6666377     |
| entropy                 | 3.3165555     |
| ep_rewmean              | -1.03         |
| episodes                | 3868          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 386601        |
| policy_loss             | 0.37513316    |
| qf1_loss                | 6.921803e-05  |
| qf2_loss                | 6.483894e-05  |
| time_elapsed            | 1968          |
| total timesteps         | 386700        |
| value_loss              | 5.4290784e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006138441  |
| ent_coef_loss           | -9.9314785    |
| entropy                 | 3.8326416     |
| ep_rewmean              | -1.04         |
| episodes                | 3872          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 387001        |
| policy_loss             | 0.3556338     |
| qf1_loss                | 4.9256658e-05 |
| qf2_loss                | 5.787235e-05  |
| time_elapsed            | 1970          |
| total timesteps         | 387100        |
| value_loss              | 5.2807325e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00059750857 |
| ent_coef_loss           | -1.460835     |
| entropy                 | 4.0946226     |
| ep_rewmean              | -1.07         |
| episodes                | 3876          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 387401        |
| policy_loss             | 0.343134      |
| qf1_loss                | 0.001134292   |
| qf2_loss                | 0.0011242072  |
| time_elapsed            | 1972          |
| total timesteps         | 387500        |
| value_loss              | 3.6770405e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00064611225 |
| ent_coef_loss           | -6.0175557    |
| entropy                 | 3.9160817     |
| ep_rewmean              | -1.08         |
| episodes                | 3880          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 387801        |
| policy_loss             | 0.33657318    |
| qf1_loss                | 5.6617537e-05 |
| qf2_loss                | 7.720915e-05  |
| time_elapsed            | 1974          |
| total timesteps         | 387900        |
| value_loss              | 0.00016329414 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00066938024 |
| ent_coef_loss           | -1.8042297    |
| entropy                 | 3.879152      |
| ep_rewmean              | -1.04         |
| episodes                | 3884          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 388201        |
| policy_loss             | 0.351349      |
| qf1_loss                | 0.0012330923  |
| qf2_loss                | 0.0012145189  |
| time_elapsed            | 1976          |
| total timesteps         | 388300        |
| value_loss              | 6.624537e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00068910065 |
| ent_coef_loss           | 13.2793255    |
| entropy                 | 3.9024706     |
| ep_rewmean              | -0.999        |
| episodes                | 3888          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 388601        |
| policy_loss             | 0.3592853     |
| qf1_loss                | 0.00013407772 |
| qf2_loss                | 9.3582596e-05 |
| time_elapsed            | 1978          |
| total timesteps         | 388700        |
| value_loss              | 0.00032361134 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00067217636 |
| ent_coef_loss           | -4.42498      |
| entropy                 | 3.641096      |
| ep_rewmean              | -0.964        |
| episodes                | 3892          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 389001        |
| policy_loss             | 0.3442572     |
| qf1_loss                | 4.1992556e-05 |
| qf2_loss                | 3.8675684e-05 |
| time_elapsed            | 1980          |
| total timesteps         | 389100        |
| value_loss              | 0.00020936449 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0006496626   |
| ent_coef_loss           | -10.193115     |
| entropy                 | 3.6317303      |
| ep_rewmean              | -0.933         |
| episodes                | 3896           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.9           |
| n_updates               | 389401         |
| policy_loss             | 0.32182217     |
| qf1_loss                | 2.7532262e-05  |
| qf2_loss                | 4.42975e-05    |
| time_elapsed            | 1982           |
| total timesteps         | 389500         |
| value_loss              | 0.000106603504 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00068876985 |
| ent_coef_loss           | 2.5931273     |
| entropy                 | 3.7460177     |
| ep_rewmean              | -0.927        |
| episodes                | 3900          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 389801        |
| policy_loss             | 0.33596182    |
| qf1_loss                | 0.0014199809  |
| qf2_loss                | 0.0013651522  |
| time_elapsed            | 1984          |
| total timesteps         | 389900        |
| value_loss              | 0.00014178347 |
-------------------------------------------
Eval num_timesteps=390000, episode_reward=-0.80 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000716418   |
| ent_coef_loss           | -0.30682147   |
| entropy                 | 3.7959604     |
| ep_rewmean              | -0.901        |
| episodes                | 3904          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 390201        |
| policy_loss             | 0.3200581     |
| qf1_loss                | 0.0005564693  |
| qf2_loss                | 0.00055984006 |
| time_elapsed            | 1986          |
| total timesteps         | 390300        |
| value_loss              | 9.510121e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00071614754 |
| ent_coef_loss           | 7.4098916     |
| entropy                 | 4.3934345     |
| ep_rewmean              | -0.896        |
| episodes                | 3908          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 390601        |
| policy_loss             | 0.31021565    |
| qf1_loss                | 0.00020585104 |
| qf2_loss                | 0.00018115295 |
| time_elapsed            | 1988          |
| total timesteps         | 390700        |
| value_loss              | 4.6241075e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00070029293 |
| ent_coef_loss           | -2.0753975    |
| entropy                 | 3.4970407     |
| ep_rewmean              | -0.902        |
| episodes                | 3912          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 391001        |
| policy_loss             | 0.3116759     |
| qf1_loss                | 0.00011284359 |
| qf2_loss                | 8.8966306e-05 |
| time_elapsed            | 1990          |
| total timesteps         | 391100        |
| value_loss              | 7.253665e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00068828196 |
| ent_coef_loss           | 8.226763      |
| entropy                 | 4.3583727     |
| ep_rewmean              | -0.922        |
| episodes                | 3916          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 391401        |
| policy_loss             | 0.2931574     |
| qf1_loss                | 7.160656e-05  |
| qf2_loss                | 6.510438e-05  |
| time_elapsed            | 1992          |
| total timesteps         | 391500        |
| value_loss              | 4.1830415e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006908803  |
| ent_coef_loss           | 2.0784216     |
| entropy                 | 4.2900963     |
| ep_rewmean              | -0.929        |
| episodes                | 3920          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 391801        |
| policy_loss             | 0.29262358    |
| qf1_loss                | 0.0013420833  |
| qf2_loss                | 0.0013184263  |
| time_elapsed            | 1994          |
| total timesteps         | 391900        |
| value_loss              | 4.1648847e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006447747  |
| ent_coef_loss           | -9.722319     |
| entropy                 | 4.4936113     |
| ep_rewmean              | -0.936        |
| episodes                | 3924          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 392201        |
| policy_loss             | 0.27796364    |
| qf1_loss                | 0.00079546805 |
| qf2_loss                | 0.00084658345 |
| time_elapsed            | 1996          |
| total timesteps         | 392300        |
| value_loss              | 2.2011835e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005960459  |
| ent_coef_loss           | -9.974108     |
| entropy                 | 3.9807785     |
| ep_rewmean              | -0.945        |
| episodes                | 3928          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 392601        |
| policy_loss             | 0.32105085    |
| qf1_loss                | 2.5328138e-05 |
| qf2_loss                | 3.3009484e-05 |
| time_elapsed            | 1998          |
| total timesteps         | 392700        |
| value_loss              | 3.1805772e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00054895325 |
| ent_coef_loss           | 3.8920527     |
| entropy                 | 4.339442      |
| ep_rewmean              | -0.951        |
| episodes                | 3932          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 393001        |
| policy_loss             | 0.26557934    |
| qf1_loss                | 6.940905e-05  |
| qf2_loss                | 6.503359e-05  |
| time_elapsed            | 2000          |
| total timesteps         | 393100        |
| value_loss              | 3.9470273e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004987353  |
| ent_coef_loss           | -2.2283177    |
| entropy                 | 3.6491811     |
| ep_rewmean              | -0.986        |
| episodes                | 3936          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 393401        |
| policy_loss             | 0.27408603    |
| qf1_loss                | 6.7892935e-05 |
| qf2_loss                | 4.765427e-05  |
| time_elapsed            | 2002          |
| total timesteps         | 393500        |
| value_loss              | 5.082474e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00046997893 |
| ent_coef_loss           | -12.52612     |
| entropy                 | 3.3444076     |
| ep_rewmean              | -1.03         |
| episodes                | 3940          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 393801        |
| policy_loss             | 0.26222432    |
| qf1_loss                | 3.9981696e-05 |
| qf2_loss                | 5.51528e-05   |
| time_elapsed            | 2004          |
| total timesteps         | 393900        |
| value_loss              | 3.7149584e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00045067165 |
| ent_coef_loss           | -5.0826106    |
| entropy                 | 3.4312346     |
| ep_rewmean              | -1.07         |
| episodes                | 3944          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 394201        |
| policy_loss             | 0.26953924    |
| qf1_loss                | 2.4776244e-05 |
| qf2_loss                | 2.8681603e-05 |
| time_elapsed            | 2006          |
| total timesteps         | 394300        |
| value_loss              | 3.88074e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00045552506 |
| ent_coef_loss           | 2.0470378     |
| entropy                 | 3.0335732     |
| ep_rewmean              | -1.1          |
| episodes                | 3948          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 394601        |
| policy_loss             | 0.2539918     |
| qf1_loss                | 0.0005432456  |
| qf2_loss                | 0.000550451   |
| time_elapsed            | 2008          |
| total timesteps         | 394700        |
| value_loss              | 4.1107945e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00045791193 |
| ent_coef_loss           | -1.2094172    |
| entropy                 | 3.216974      |
| ep_rewmean              | -1.17         |
| episodes                | 3952          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 395001        |
| policy_loss             | 0.2500427     |
| qf1_loss                | 2.711964e-05  |
| qf2_loss                | 4.0836298e-05 |
| time_elapsed            | 2010          |
| total timesteps         | 395100        |
| value_loss              | 4.287704e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00047937094 |
| ent_coef_loss           | 2.9496212     |
| entropy                 | 3.3900945     |
| ep_rewmean              | -1.23         |
| episodes                | 3956          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 395401        |
| policy_loss             | 0.24329478    |
| qf1_loss                | 4.5600136e-05 |
| qf2_loss                | 2.6182002e-05 |
| time_elapsed            | 2012          |
| total timesteps         | 395500        |
| value_loss              | 3.6591002e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0004736151   |
| ent_coef_loss           | -2.6289697     |
| entropy                 | 3.337366       |
| ep_rewmean              | -1.26          |
| episodes                | 3960           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -1.3           |
| n_updates               | 395801         |
| policy_loss             | 0.24311233     |
| qf1_loss                | 0.0001069415   |
| qf2_loss                | 0.000100646685 |
| time_elapsed            | 2014           |
| total timesteps         | 395900         |
| value_loss              | 4.192497e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00047999423 |
| ent_coef_loss           | -1.8548245    |
| entropy                 | 3.3045964     |
| ep_rewmean              | -1.29         |
| episodes                | 3964          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 396201        |
| policy_loss             | 0.23231786    |
| qf1_loss                | 3.2484044e-05 |
| qf2_loss                | 3.6876765e-05 |
| time_elapsed            | 2016          |
| total timesteps         | 396300        |
| value_loss              | 3.4849163e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00046496486 |
| ent_coef_loss           | -4.308834     |
| entropy                 | 3.5596948     |
| ep_rewmean              | -1.31         |
| episodes                | 3968          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 396601        |
| policy_loss             | 0.2557906     |
| qf1_loss                | 2.806232e-05  |
| qf2_loss                | 2.5004663e-05 |
| time_elapsed            | 2018          |
| total timesteps         | 396700        |
| value_loss              | 3.1174066e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00043739745 |
| ent_coef_loss           | -2.5978627    |
| entropy                 | 3.694401      |
| ep_rewmean              | -1.32         |
| episodes                | 3972          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 397001        |
| policy_loss             | 0.23612107    |
| qf1_loss                | 5.744793e-05  |
| qf2_loss                | 3.068371e-05  |
| time_elapsed            | 2020          |
| total timesteps         | 397100        |
| value_loss              | 5.0905757e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00042052811  |
| ent_coef_loss           | -2.3758388     |
| entropy                 | 3.286096       |
| ep_rewmean              | -1.32          |
| episodes                | 3976           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -1.3           |
| n_updates               | 397401         |
| policy_loss             | 0.22469307     |
| qf1_loss                | 0.00010920943  |
| qf2_loss                | 0.000110941204 |
| time_elapsed            | 2022           |
| total timesteps         | 397500         |
| value_loss              | 2.891016e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00041052498 |
| ent_coef_loss           | 0.3054148     |
| entropy                 | 3.7760003     |
| ep_rewmean              | -1.29         |
| episodes                | 3980          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 397801        |
| policy_loss             | 0.2497788     |
| qf1_loss                | 2.3346951e-05 |
| qf2_loss                | 1.7343227e-05 |
| time_elapsed            | 2024          |
| total timesteps         | 397900        |
| value_loss              | 2.6515992e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00042428152 |
| ent_coef_loss           | -5.525425     |
| entropy                 | 4.0110598     |
| ep_rewmean              | -1.26         |
| episodes                | 3984          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.3          |
| n_updates               | 398201        |
| policy_loss             | 0.247493      |
| qf1_loss                | 5.9572463e-05 |
| qf2_loss                | 5.4336044e-05 |
| time_elapsed            | 2026          |
| total timesteps         | 398300        |
| value_loss              | 3.015284e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00043500363 |
| ent_coef_loss           | -3.488478     |
| entropy                 | 3.8531787     |
| ep_rewmean              | -1.23         |
| episodes                | 3988          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 398601        |
| policy_loss             | 0.23791243    |
| qf1_loss                | 0.0003061698  |
| qf2_loss                | 0.00025599138 |
| time_elapsed            | 2028          |
| total timesteps         | 398700        |
| value_loss              | 3.0985855e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004267254  |
| ent_coef_loss           | 1.9330587     |
| entropy                 | 3.9977558     |
| ep_rewmean              | -1.2          |
| episodes                | 3992          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 399001        |
| policy_loss             | 0.23902985    |
| qf1_loss                | 2.1672578e-05 |
| qf2_loss                | 2.6542337e-05 |
| time_elapsed            | 2030          |
| total timesteps         | 399100        |
| value_loss              | 2.180004e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00040484744 |
| ent_coef_loss           | 3.7030616     |
| entropy                 | 4.4969044     |
| ep_rewmean              | -1.16         |
| episodes                | 3996          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.2          |
| n_updates               | 399401        |
| policy_loss             | 0.2783441     |
| qf1_loss                | 4.994472e-05  |
| qf2_loss                | 3.410722e-05  |
| time_elapsed            | 2032          |
| total timesteps         | 399500        |
| value_loss              | 0.00023067644 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00039138045 |
| ent_coef_loss           | 5.8532376     |
| entropy                 | 4.312054      |
| ep_rewmean              | -1.11         |
| episodes                | 4000          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 399801        |
| policy_loss             | 0.2618936     |
| qf1_loss                | 4.3687407e-05 |
| qf2_loss                | 6.0731167e-05 |
| time_elapsed            | 2034          |
| total timesteps         | 399900        |
| value_loss              | 0.00016196148 |
-------------------------------------------
Eval num_timesteps=400000, episode_reward=-0.30 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00041127697 |
| ent_coef_loss           | 11.78015      |
| entropy                 | 3.945746      |
| ep_rewmean              | -1.08         |
| episodes                | 4004          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 400201        |
| policy_loss             | 0.26275128    |
| qf1_loss                | 2.2782882e-05 |
| qf2_loss                | 3.8548373e-05 |
| time_elapsed            | 2037          |
| total timesteps         | 400300        |
| value_loss              | 2.3582954e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004186524  |
| ent_coef_loss           | 5.5155797     |
| entropy                 | 4.062693      |
| ep_rewmean              | -1.06         |
| episodes                | 4008          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 400601        |
| policy_loss             | 0.2487081     |
| qf1_loss                | 2.0650157e-05 |
| qf2_loss                | 2.4750796e-05 |
| time_elapsed            | 2039          |
| total timesteps         | 400700        |
| value_loss              | 7.935269e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00042258832 |
| ent_coef_loss           | 7.4492483     |
| entropy                 | 4.0978646     |
| ep_rewmean              | -1.07         |
| episodes                | 4012          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 401001        |
| policy_loss             | 0.26021358    |
| qf1_loss                | 5.1885978e-05 |
| qf2_loss                | 8.023931e-05  |
| time_elapsed            | 2041          |
| total timesteps         | 401100        |
| value_loss              | 3.3396238e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00043852726 |
| ent_coef_loss           | -6.3720293    |
| entropy                 | 4.054707      |
| ep_rewmean              | -1.09         |
| episodes                | 4016          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 401401        |
| policy_loss             | 0.23671016    |
| qf1_loss                | 3.166395e-05  |
| qf2_loss                | 2.9033856e-05 |
| time_elapsed            | 2043          |
| total timesteps         | 401500        |
| value_loss              | 2.4183257e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00046027947 |
| ent_coef_loss           | -6.1140018    |
| entropy                 | 4.142669      |
| ep_rewmean              | -1.08         |
| episodes                | 4020          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 401801        |
| policy_loss             | 0.25750265    |
| qf1_loss                | 4.2388907e-05 |
| qf2_loss                | 4.699093e-05  |
| time_elapsed            | 2045          |
| total timesteps         | 401900        |
| value_loss              | 2.9428418e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004738794  |
| ent_coef_loss           | -7.772119     |
| entropy                 | 4.404834      |
| ep_rewmean              | -1.07         |
| episodes                | 4024          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 402201        |
| policy_loss             | 0.24311304    |
| qf1_loss                | 2.7908614e-05 |
| qf2_loss                | 1.9300223e-05 |
| time_elapsed            | 2047          |
| total timesteps         | 402300        |
| value_loss              | 6.2806794e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00047186585 |
| ent_coef_loss           | -1.6896226    |
| entropy                 | 4.5632477     |
| ep_rewmean              | -1.06         |
| episodes                | 4028          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 402601        |
| policy_loss             | 0.25089908    |
| qf1_loss                | 3.4000113e-05 |
| qf2_loss                | 3.9553663e-05 |
| time_elapsed            | 2049          |
| total timesteps         | 402700        |
| value_loss              | 4.2512784e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00046681074 |
| ent_coef_loss           | 7.0768714     |
| entropy                 | 4.5201607     |
| ep_rewmean              | -1.06         |
| episodes                | 4032          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1.1          |
| n_updates               | 403001        |
| policy_loss             | 0.23929992    |
| qf1_loss                | 3.8038514e-05 |
| qf2_loss                | 1.7574283e-05 |
| time_elapsed            | 2051          |
| total timesteps         | 403100        |
| value_loss              | 3.762593e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00047944978 |
| ent_coef_loss           | -3.9820838    |
| entropy                 | 4.4490843     |
| ep_rewmean              | -1.02         |
| episodes                | 4036          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 403401        |
| policy_loss             | 0.23651846    |
| qf1_loss                | 3.863608e-05  |
| qf2_loss                | 7.114288e-05  |
| time_elapsed            | 2053          |
| total timesteps         | 403500        |
| value_loss              | 2.7394388e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000448654   |
| ent_coef_loss           | 0.4185872     |
| entropy                 | 4.579669      |
| ep_rewmean              | -0.98         |
| episodes                | 4040          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -1            |
| n_updates               | 403801        |
| policy_loss             | 0.22798729    |
| qf1_loss                | 1.859893e-05  |
| qf2_loss                | 2.3978693e-05 |
| time_elapsed            | 2055          |
| total timesteps         | 403900        |
| value_loss              | 2.149379e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004431026  |
| ent_coef_loss           | -16.392166    |
| entropy                 | 5.0835433     |
| ep_rewmean              | -0.946        |
| episodes                | 4044          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 404201        |
| policy_loss             | 0.25171012    |
| qf1_loss                | 1.6901682e-05 |
| qf2_loss                | 1.823249e-05  |
| time_elapsed            | 2057          |
| total timesteps         | 404300        |
| value_loss              | 2.4987166e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00041533343 |
| ent_coef_loss           | 8.237481      |
| entropy                 | 4.0754423     |
| ep_rewmean              | -0.893        |
| episodes                | 4048          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 404601        |
| policy_loss             | 0.2372177     |
| qf1_loss                | 0.0013794422  |
| qf2_loss                | 0.0013520615  |
| time_elapsed            | 2059          |
| total timesteps         | 404700        |
| value_loss              | 2.4501827e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00040568516 |
| ent_coef_loss           | 0.6511061     |
| entropy                 | 4.1134133     |
| ep_rewmean              | -0.817        |
| episodes                | 4052          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 405001        |
| policy_loss             | 0.23141369    |
| qf1_loss                | 0.0017616986  |
| qf2_loss                | 0.0017618198  |
| time_elapsed            | 2061          |
| total timesteps         | 405100        |
| value_loss              | 3.732577e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00038210728 |
| ent_coef_loss           | -11.360151    |
| entropy                 | 4.325048      |
| ep_rewmean              | -0.757        |
| episodes                | 4056          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 405401        |
| policy_loss             | 0.2367729     |
| qf1_loss                | 7.4982025e-05 |
| qf2_loss                | 7.48897e-05   |
| time_elapsed            | 2063          |
| total timesteps         | 405500        |
| value_loss              | 2.2362805e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00035736623 |
| ent_coef_loss           | -7.808642     |
| entropy                 | 4.6653895     |
| ep_rewmean              | -0.722        |
| episodes                | 4060          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 405801        |
| policy_loss             | 0.23123388    |
| qf1_loss                | 0.0004893445  |
| qf2_loss                | 0.0004860474  |
| time_elapsed            | 2065          |
| total timesteps         | 405900        |
| value_loss              | 1.5893078e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00034904323 |
| ent_coef_loss           | 1.491363      |
| entropy                 | 4.192396      |
| ep_rewmean              | -0.682        |
| episodes                | 4064          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 406201        |
| policy_loss             | 0.2507978     |
| qf1_loss                | 2.40089e-05   |
| qf2_loss                | 1.8804618e-05 |
| time_elapsed            | 2067          |
| total timesteps         | 406300        |
| value_loss              | 2.4857349e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00034792756 |
| ent_coef_loss           | 9.648974      |
| entropy                 | 3.7494977     |
| ep_rewmean              | -0.656        |
| episodes                | 4068          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 406601        |
| policy_loss             | 0.24840818    |
| qf1_loss                | 3.558132e-05  |
| qf2_loss                | 5.055892e-05  |
| time_elapsed            | 2069          |
| total timesteps         | 406700        |
| value_loss              | 3.025047e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003409271  |
| ent_coef_loss           | -2.9994292    |
| entropy                 | 3.8763127     |
| ep_rewmean              | -0.625        |
| episodes                | 4072          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 407001        |
| policy_loss             | 0.23262039    |
| qf1_loss                | 3.6320795e-05 |
| qf2_loss                | 3.4793735e-05 |
| time_elapsed            | 2071          |
| total timesteps         | 407100        |
| value_loss              | 2.3406377e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00032387764 |
| ent_coef_loss           | 5.616353      |
| entropy                 | 3.3341646     |
| ep_rewmean              | -0.603        |
| episodes                | 4076          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 407401        |
| policy_loss             | 0.2090894     |
| qf1_loss                | 4.2583608e-05 |
| qf2_loss                | 4.2034335e-05 |
| time_elapsed            | 2073          |
| total timesteps         | 407500        |
| value_loss              | 2.3127925e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00032735837 |
| ent_coef_loss           | -0.8081684    |
| entropy                 | 4.004644      |
| ep_rewmean              | -0.594        |
| episodes                | 4080          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 407801        |
| policy_loss             | 0.22399329    |
| qf1_loss                | 2.3918248e-05 |
| qf2_loss                | 2.2314227e-05 |
| time_elapsed            | 2075          |
| total timesteps         | 407900        |
| value_loss              | 1.6035468e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00032253188 |
| ent_coef_loss           | -8.9455595    |
| entropy                 | 3.9468489     |
| ep_rewmean              | -0.592        |
| episodes                | 4084          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 408201        |
| policy_loss             | 0.20957224    |
| qf1_loss                | 6.826526e-05  |
| qf2_loss                | 7.7639736e-05 |
| time_elapsed            | 2077          |
| total timesteps         | 408300        |
| value_loss              | 1.980076e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033109335 |
| ent_coef_loss           | 2.6398945     |
| entropy                 | 3.9649088     |
| ep_rewmean              | -0.59         |
| episodes                | 4088          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 408601        |
| policy_loss             | 0.24837254    |
| qf1_loss                | 0.0005613455  |
| qf2_loss                | 0.0005273658  |
| time_elapsed            | 2079          |
| total timesteps         | 408700        |
| value_loss              | 2.4373086e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00034946157 |
| ent_coef_loss           | -7.7226105    |
| entropy                 | 3.8659198     |
| ep_rewmean              | -0.59         |
| episodes                | 4092          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 409001        |
| policy_loss             | 0.24780121    |
| qf1_loss                | 1.9461448e-05 |
| qf2_loss                | 2.815683e-05  |
| time_elapsed            | 2081          |
| total timesteps         | 409100        |
| value_loss              | 1.6409547e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033429632 |
| ent_coef_loss           | -1.0786142    |
| entropy                 | 4.0703783     |
| ep_rewmean              | -0.593        |
| episodes                | 4096          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 409401        |
| policy_loss             | 0.22640474    |
| qf1_loss                | 0.00020750253 |
| qf2_loss                | 0.00025759925 |
| time_elapsed            | 2083          |
| total timesteps         | 409500        |
| value_loss              | 2.7760161e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033124845 |
| ent_coef_loss           | 10.039109     |
| entropy                 | 3.7756157     |
| ep_rewmean              | -0.596        |
| episodes                | 4100          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 409801        |
| policy_loss             | 0.2204558     |
| qf1_loss                | 3.649613e-05  |
| qf2_loss                | 3.277923e-05  |
| time_elapsed            | 2085          |
| total timesteps         | 409900        |
| value_loss              | 2.6700265e-05 |
-------------------------------------------
Eval num_timesteps=410000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033428005 |
| ent_coef_loss           | 0.36579633    |
| entropy                 | 4.3025503     |
| ep_rewmean              | -0.599        |
| episodes                | 4104          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 410201        |
| policy_loss             | 0.22235979    |
| qf1_loss                | 0.00013986374 |
| qf2_loss                | 0.0001244695  |
| time_elapsed            | 2087          |
| total timesteps         | 410300        |
| value_loss              | 1.6675054e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00032074424 |
| ent_coef_loss           | -11.328555    |
| entropy                 | 3.5450273     |
| ep_rewmean              | -0.595        |
| episodes                | 4108          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 410601        |
| policy_loss             | 0.22545695    |
| qf1_loss                | 1.4285244e-05 |
| qf2_loss                | 1.5403373e-05 |
| time_elapsed            | 2089          |
| total timesteps         | 410700        |
| value_loss              | 1.7064762e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00031111858 |
| ent_coef_loss           | -1.4937754    |
| entropy                 | 3.9117393     |
| ep_rewmean              | -0.569        |
| episodes                | 4112          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 411001        |
| policy_loss             | 0.21833682    |
| qf1_loss                | 3.469388e-05  |
| qf2_loss                | 3.2658994e-05 |
| time_elapsed            | 2091          |
| total timesteps         | 411100        |
| value_loss              | 5.7236986e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00030485028 |
| ent_coef_loss           | -3.94023      |
| entropy                 | 3.2220442     |
| ep_rewmean              | -0.526        |
| episodes                | 4116          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 411401        |
| policy_loss             | 0.2329356     |
| qf1_loss                | 2.3410397e-05 |
| qf2_loss                | 2.2820766e-05 |
| time_elapsed            | 2093          |
| total timesteps         | 411500        |
| value_loss              | 2.556961e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00030304963 |
| ent_coef_loss           | -2.7867196    |
| entropy                 | 3.8499274     |
| ep_rewmean              | -0.525        |
| episodes                | 4120          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 411801        |
| policy_loss             | 0.21577711    |
| qf1_loss                | 0.0011575245  |
| qf2_loss                | 0.001162993   |
| time_elapsed            | 2095          |
| total timesteps         | 411900        |
| value_loss              | 5.1031602e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00030277143 |
| ent_coef_loss           | 8.456826      |
| entropy                 | 3.458741      |
| ep_rewmean              | -0.534        |
| episodes                | 4124          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 412201        |
| policy_loss             | 0.25509942    |
| qf1_loss                | 0.00044857748 |
| qf2_loss                | 0.00045991325 |
| time_elapsed            | 2097          |
| total timesteps         | 412300        |
| value_loss              | 3.59427e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00030970917 |
| ent_coef_loss           | 2.902149      |
| entropy                 | 3.793457      |
| ep_rewmean              | -0.549        |
| episodes                | 4128          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 412601        |
| policy_loss             | 0.21803081    |
| qf1_loss                | 2.8062546e-05 |
| qf2_loss                | 3.3979042e-05 |
| time_elapsed            | 2099          |
| total timesteps         | 412700        |
| value_loss              | 1.6853613e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003132398  |
| ent_coef_loss           | -2.8041475    |
| entropy                 | 3.639616      |
| ep_rewmean              | -0.579        |
| episodes                | 4132          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 413001        |
| policy_loss             | 0.21191624    |
| qf1_loss                | 3.1786305e-05 |
| qf2_loss                | 2.8753873e-05 |
| time_elapsed            | 2101          |
| total timesteps         | 413100        |
| value_loss              | 2.1676702e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00035281462 |
| ent_coef_loss           | -5.5219517    |
| entropy                 | 3.3674364     |
| ep_rewmean              | -0.607        |
| episodes                | 4136          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 413401        |
| policy_loss             | 0.22965685    |
| qf1_loss                | 2.6793718e-05 |
| qf2_loss                | 3.553246e-05  |
| time_elapsed            | 2103          |
| total timesteps         | 413500        |
| value_loss              | 2.9271643e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00039397168 |
| ent_coef_loss           | -1.4105226    |
| entropy                 | 3.3241005     |
| ep_rewmean              | -0.665        |
| episodes                | 4140          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 413801        |
| policy_loss             | 0.24554451    |
| qf1_loss                | 0.0016622499  |
| qf2_loss                | 0.0015765608  |
| time_elapsed            | 2105          |
| total timesteps         | 413900        |
| value_loss              | 2.8147533e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004190215  |
| ent_coef_loss           | 8.710485      |
| entropy                 | 4.006687      |
| ep_rewmean              | -0.721        |
| episodes                | 4144          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 414201        |
| policy_loss             | 0.23742309    |
| qf1_loss                | 0.00023760404 |
| qf2_loss                | 0.00022477526 |
| time_elapsed            | 2107          |
| total timesteps         | 414300        |
| value_loss              | 5.098854e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00042105603 |
| ent_coef_loss           | -8.1032       |
| entropy                 | 3.6629598     |
| ep_rewmean              | -0.768        |
| episodes                | 4148          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 414601        |
| policy_loss             | 0.24506296    |
| qf1_loss                | 1.7082319e-05 |
| qf2_loss                | 2.8757848e-05 |
| time_elapsed            | 2109          |
| total timesteps         | 414700        |
| value_loss              | 3.3963912e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00042442864 |
| ent_coef_loss           | 3.273417      |
| entropy                 | 3.905898      |
| ep_rewmean              | -0.799        |
| episodes                | 4152          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 415001        |
| policy_loss             | 0.23401308    |
| qf1_loss                | 3.0602932e-05 |
| qf2_loss                | 2.4422468e-05 |
| time_elapsed            | 2111          |
| total timesteps         | 415100        |
| value_loss              | 3.332566e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00044161867 |
| ent_coef_loss           | -3.0984814    |
| entropy                 | 3.9939675     |
| ep_rewmean              | -0.798        |
| episodes                | 4156          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 415401        |
| policy_loss             | 0.2617335     |
| qf1_loss                | 2.2048358e-05 |
| qf2_loss                | 1.8211149e-05 |
| time_elapsed            | 2113          |
| total timesteps         | 415500        |
| value_loss              | 2.5246612e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004572194  |
| ent_coef_loss           | 11.47663      |
| entropy                 | 4.0375977     |
| ep_rewmean              | -0.799        |
| episodes                | 4160          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 415801        |
| policy_loss             | 0.252293      |
| qf1_loss                | 3.107586e-05  |
| qf2_loss                | 2.654438e-05  |
| time_elapsed            | 2115          |
| total timesteps         | 415900        |
| value_loss              | 6.1190134e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004745166  |
| ent_coef_loss           | -3.6665115    |
| entropy                 | 3.8118553     |
| ep_rewmean              | -0.811        |
| episodes                | 4164          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 416201        |
| policy_loss             | 0.24466544    |
| qf1_loss                | 0.00038134793 |
| qf2_loss                | 0.00036319476 |
| time_elapsed            | 2117          |
| total timesteps         | 416300        |
| value_loss              | 2.4769159e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00047516052 |
| ent_coef_loss           | 0.43842435    |
| entropy                 | 3.6643124     |
| ep_rewmean              | -0.819        |
| episodes                | 4168          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 416601        |
| policy_loss             | 0.26822364    |
| qf1_loss                | 5.839613e-05  |
| qf2_loss                | 4.2541094e-05 |
| time_elapsed            | 2119          |
| total timesteps         | 416700        |
| value_loss              | 3.0551295e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00045671975 |
| ent_coef_loss           | -3.818604     |
| entropy                 | 3.3857102     |
| ep_rewmean              | -0.83         |
| episodes                | 4172          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 417001        |
| policy_loss             | 0.25862366    |
| qf1_loss                | 0.00046170093 |
| qf2_loss                | 0.000501084   |
| time_elapsed            | 2121          |
| total timesteps         | 417100        |
| value_loss              | 2.4481154e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00043629762 |
| ent_coef_loss           | -1.0615942    |
| entropy                 | 3.6321182     |
| ep_rewmean              | -0.842        |
| episodes                | 4176          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 417401        |
| policy_loss             | 0.2566291     |
| qf1_loss                | 2.539222e-05  |
| qf2_loss                | 2.4662751e-05 |
| time_elapsed            | 2123          |
| total timesteps         | 417500        |
| value_loss              | 3.0993873e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00043351232 |
| ent_coef_loss           | 8.017175      |
| entropy                 | 3.6358206     |
| ep_rewmean              | -0.847        |
| episodes                | 4180          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 417801        |
| policy_loss             | 0.24536926    |
| qf1_loss                | 0.00014079027 |
| qf2_loss                | 0.00011847686 |
| time_elapsed            | 2125          |
| total timesteps         | 417900        |
| value_loss              | 1.8152361e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00042816764 |
| ent_coef_loss           | 3.1481242     |
| entropy                 | 4.0237374     |
| ep_rewmean              | -0.856        |
| episodes                | 4184          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 418201        |
| policy_loss             | 0.2640242     |
| qf1_loss                | 2.1810674e-05 |
| qf2_loss                | 2.7699487e-05 |
| time_elapsed            | 2127          |
| total timesteps         | 418300        |
| value_loss              | 2.6996335e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004300218  |
| ent_coef_loss           | -11.298094    |
| entropy                 | 3.2390716     |
| ep_rewmean              | -0.86         |
| episodes                | 4188          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 418601        |
| policy_loss             | 0.23928918    |
| qf1_loss                | 0.00016420084 |
| qf2_loss                | 0.0001923611  |
| time_elapsed            | 2129          |
| total timesteps         | 418700        |
| value_loss              | 4.382681e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000415119   |
| ent_coef_loss           | -4.026306     |
| entropy                 | 3.1504495     |
| ep_rewmean              | -0.867        |
| episodes                | 4192          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 419001        |
| policy_loss             | 0.26352316    |
| qf1_loss                | 7.3027026e-05 |
| qf2_loss                | 8.8989065e-05 |
| time_elapsed            | 2131          |
| total timesteps         | 419100        |
| value_loss              | 3.3210847e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004062173  |
| ent_coef_loss           | -10.684455    |
| entropy                 | 3.0108829     |
| ep_rewmean              | -0.876        |
| episodes                | 4196          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 419401        |
| policy_loss             | 0.23392668    |
| qf1_loss                | 2.3638717e-05 |
| qf2_loss                | 1.9757197e-05 |
| time_elapsed            | 2133          |
| total timesteps         | 419500        |
| value_loss              | 2.0063811e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00039540543 |
| ent_coef_loss           | -5.9373274    |
| entropy                 | 3.060488      |
| ep_rewmean              | -0.886        |
| episodes                | 4200          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 419801        |
| policy_loss             | 0.23250443    |
| qf1_loss                | 1.7038254e-05 |
| qf2_loss                | 1.9762674e-05 |
| time_elapsed            | 2135          |
| total timesteps         | 419900        |
| value_loss              | 2.9144783e-05 |
-------------------------------------------
Eval num_timesteps=420000, episode_reward=-0.44 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000378723   |
| ent_coef_loss           | -4.556477     |
| entropy                 | 3.4678502     |
| ep_rewmean              | -0.891        |
| episodes                | 4204          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 420201        |
| policy_loss             | 0.23586592    |
| qf1_loss                | 7.502111e-05  |
| qf2_loss                | 9.113578e-05  |
| time_elapsed            | 2137          |
| total timesteps         | 420300        |
| value_loss              | 1.7753906e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00038587823 |
| ent_coef_loss           | 1.2530675     |
| entropy                 | 3.1900868     |
| ep_rewmean              | -0.89         |
| episodes                | 4208          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 420601        |
| policy_loss             | 0.24676575    |
| qf1_loss                | 0.00050836185 |
| qf2_loss                | 0.0004990408  |
| time_elapsed            | 2139          |
| total timesteps         | 420700        |
| value_loss              | 2.2225955e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00038024044 |
| ent_coef_loss           | -6.0237627    |
| entropy                 | 3.2501807     |
| ep_rewmean              | -0.891        |
| episodes                | 4212          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 421001        |
| policy_loss             | 0.22556508    |
| qf1_loss                | 0.00019373334 |
| qf2_loss                | 0.00021692326 |
| time_elapsed            | 2141          |
| total timesteps         | 421100        |
| value_loss              | 1.8288629e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00037519512 |
| ent_coef_loss           | -4.7435493    |
| entropy                 | 3.1923656     |
| ep_rewmean              | -0.89         |
| episodes                | 4216          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 421401        |
| policy_loss             | 0.23438117    |
| qf1_loss                | 9.205725e-06  |
| qf2_loss                | 1.3205247e-05 |
| time_elapsed            | 2143          |
| total timesteps         | 421500        |
| value_loss              | 1.7220245e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00036200037 |
| ent_coef_loss           | -2.8070064    |
| entropy                 | 3.4627163     |
| ep_rewmean              | -0.885        |
| episodes                | 4220          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 421801        |
| policy_loss             | 0.23556626    |
| qf1_loss                | 1.9890136e-05 |
| qf2_loss                | 2.5209916e-05 |
| time_elapsed            | 2145          |
| total timesteps         | 421900        |
| value_loss              | 2.9635294e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003493496  |
| ent_coef_loss           | 7.465989      |
| entropy                 | 3.0435774     |
| ep_rewmean              | -0.874        |
| episodes                | 4224          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 422201        |
| policy_loss             | 0.23846814    |
| qf1_loss                | 0.00028108145 |
| qf2_loss                | 0.0002475741  |
| time_elapsed            | 2147          |
| total timesteps         | 422300        |
| value_loss              | 3.75542e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00034089913 |
| ent_coef_loss           | -9.390141     |
| entropy                 | 3.1502774     |
| ep_rewmean              | -0.854        |
| episodes                | 4228          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.9          |
| n_updates               | 422601        |
| policy_loss             | 0.23759201    |
| qf1_loss                | 5.6249057e-05 |
| qf2_loss                | 5.8909824e-05 |
| time_elapsed            | 2149          |
| total timesteps         | 422700        |
| value_loss              | 2.5505506e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00034499733 |
| ent_coef_loss           | -5.160666     |
| entropy                 | 2.659476      |
| ep_rewmean              | -0.812        |
| episodes                | 4232          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 423001        |
| policy_loss             | 0.22441727    |
| qf1_loss                | 3.988813e-05  |
| qf2_loss                | 3.6897327e-05 |
| time_elapsed            | 2151          |
| total timesteps         | 423100        |
| value_loss              | 2.1124113e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00034553965 |
| ent_coef_loss           | -2.1768293    |
| entropy                 | 2.884324      |
| ep_rewmean              | -0.772        |
| episodes                | 4236          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 423401        |
| policy_loss             | 0.22747393    |
| qf1_loss                | 1.5431155e-05 |
| qf2_loss                | 1.250565e-05  |
| time_elapsed            | 2153          |
| total timesteps         | 423500        |
| value_loss              | 2.384868e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00034209763 |
| ent_coef_loss           | 6.8987412     |
| entropy                 | 2.7199159     |
| ep_rewmean              | -0.7          |
| episodes                | 4240          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 423801        |
| policy_loss             | 0.22102019    |
| qf1_loss                | 0.00037635982 |
| qf2_loss                | 0.00039441106 |
| time_elapsed            | 2155          |
| total timesteps         | 423900        |
| value_loss              | 1.6967011e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003399385  |
| ent_coef_loss           | 9.295769      |
| entropy                 | 2.8654227     |
| ep_rewmean              | -0.63         |
| episodes                | 4244          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 424201        |
| policy_loss             | 0.21926895    |
| qf1_loss                | 3.7758862e-05 |
| qf2_loss                | 3.528233e-05  |
| time_elapsed            | 2157          |
| total timesteps         | 424300        |
| value_loss              | 3.074109e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00035690574 |
| ent_coef_loss           | 11.219149     |
| entropy                 | 3.2235458     |
| ep_rewmean              | -0.591        |
| episodes                | 4248          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 424601        |
| policy_loss             | 0.22315429    |
| qf1_loss                | 0.002360927   |
| qf2_loss                | 0.0025628451  |
| time_elapsed            | 2159          |
| total timesteps         | 424700        |
| value_loss              | 2.1002103e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00038780566 |
| ent_coef_loss           | 7.921441      |
| entropy                 | 3.488469      |
| ep_rewmean              | -0.561        |
| episodes                | 4252          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 425001        |
| policy_loss             | 0.21735294    |
| qf1_loss                | 1.724347e-05  |
| qf2_loss                | 1.6648719e-05 |
| time_elapsed            | 2161          |
| total timesteps         | 425100        |
| value_loss              | 1.9111032e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0004088978  |
| ent_coef_loss           | -0.6882148    |
| entropy                 | 3.5128503     |
| ep_rewmean              | -0.55         |
| episodes                | 4256          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 425401        |
| policy_loss             | 0.22864851    |
| qf1_loss                | 0.00026626638 |
| qf2_loss                | 0.00028263888 |
| time_elapsed            | 2163          |
| total timesteps         | 425500        |
| value_loss              | 4.816584e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00042631762 |
| ent_coef_loss           | 2.6875415     |
| entropy                 | 3.7748        |
| ep_rewmean              | -0.537        |
| episodes                | 4260          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 425801        |
| policy_loss             | 0.2198059     |
| qf1_loss                | 0.0006250617  |
| qf2_loss                | 0.0006220376  |
| time_elapsed            | 2165          |
| total timesteps         | 425900        |
| value_loss              | 2.0178632e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00041790647 |
| ent_coef_loss           | -4.173686     |
| entropy                 | 3.7536924     |
| ep_rewmean              | -0.514        |
| episodes                | 4264          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 426201        |
| policy_loss             | 0.21913265    |
| qf1_loss                | 1.1945581e-05 |
| qf2_loss                | 1.1792254e-05 |
| time_elapsed            | 2167          |
| total timesteps         | 426300        |
| value_loss              | 2.4095283e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00039702796  |
| ent_coef_loss           | 11.520968      |
| entropy                 | 4.0569315      |
| ep_rewmean              | -0.495         |
| episodes                | 4268           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.5           |
| n_updates               | 426601         |
| policy_loss             | 0.21758157     |
| qf1_loss                | 1.48550735e-05 |
| qf2_loss                | 2.1519572e-05  |
| time_elapsed            | 2169           |
| total timesteps         | 426700         |
| value_loss              | 2.8773818e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003898024  |
| ent_coef_loss           | -6.147105     |
| entropy                 | 4.233151      |
| ep_rewmean              | -0.475        |
| episodes                | 4272          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 427001        |
| policy_loss             | 0.23001197    |
| qf1_loss                | 3.153755e-05  |
| qf2_loss                | 2.4361683e-05 |
| time_elapsed            | 2171          |
| total timesteps         | 427100        |
| value_loss              | 2.327175e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00038129571 |
| ent_coef_loss           | -9.607397     |
| entropy                 | 3.525264      |
| ep_rewmean              | -0.459        |
| episodes                | 4276          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 427401        |
| policy_loss             | 0.21113917    |
| qf1_loss                | 0.00014073333 |
| qf2_loss                | 0.00013318012 |
| time_elapsed            | 2173          |
| total timesteps         | 427500        |
| value_loss              | 2.420375e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00038397743 |
| ent_coef_loss           | -4.021158     |
| entropy                 | 3.6487117     |
| ep_rewmean              | -0.446        |
| episodes                | 4280          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 427801        |
| policy_loss             | 0.21714269    |
| qf1_loss                | 0.00025043424 |
| qf2_loss                | 0.0002473487  |
| time_elapsed            | 2175          |
| total timesteps         | 427900        |
| value_loss              | 1.8659086e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00040192372 |
| ent_coef_loss           | -1.0143719    |
| entropy                 | 3.4460144     |
| ep_rewmean              | -0.43         |
| episodes                | 4284          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 428201        |
| policy_loss             | 0.21483126    |
| qf1_loss                | 3.7173675e-05 |
| qf2_loss                | 4.353747e-05  |
| time_elapsed            | 2177          |
| total timesteps         | 428300        |
| value_loss              | 2.4232088e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00039636702 |
| ent_coef_loss           | -2.7586424    |
| entropy                 | 3.4507332     |
| ep_rewmean              | -0.42         |
| episodes                | 4288          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 428601        |
| policy_loss             | 0.20339319    |
| qf1_loss                | 0.00017553077 |
| qf2_loss                | 0.0001734857  |
| time_elapsed            | 2179          |
| total timesteps         | 428700        |
| value_loss              | 2.214561e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00038465712 |
| ent_coef_loss           | 1.4238954     |
| entropy                 | 3.3616118     |
| ep_rewmean              | -0.406        |
| episodes                | 4292          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 429001        |
| policy_loss             | 0.20196214    |
| qf1_loss                | 0.00013611114 |
| qf2_loss                | 0.00012998827 |
| time_elapsed            | 2181          |
| total timesteps         | 429100        |
| value_loss              | 1.4754547e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003878356  |
| ent_coef_loss           | -5.86941      |
| entropy                 | 3.422243      |
| ep_rewmean              | -0.39         |
| episodes                | 4296          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 429401        |
| policy_loss             | 0.21186942    |
| qf1_loss                | 2.0336302e-05 |
| qf2_loss                | 1.2595569e-05 |
| time_elapsed            | 2183          |
| total timesteps         | 429500        |
| value_loss              | 2.9034021e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003878924  |
| ent_coef_loss           | -3.5066876    |
| entropy                 | 3.734943      |
| ep_rewmean              | -0.381        |
| episodes                | 4300          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 429801        |
| policy_loss             | 0.20639257    |
| qf1_loss                | 1.8574952e-05 |
| qf2_loss                | 1.822794e-05  |
| time_elapsed            | 2185          |
| total timesteps         | 429900        |
| value_loss              | 2.715338e-05  |
-------------------------------------------
Eval num_timesteps=430000, episode_reward=-0.31 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00036112076 |
| ent_coef_loss           | -0.1381836    |
| entropy                 | 3.305117      |
| ep_rewmean              | -0.376        |
| episodes                | 4304          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 430201        |
| policy_loss             | 0.22263718    |
| qf1_loss                | 2.727755e-05  |
| qf2_loss                | 1.7817047e-05 |
| time_elapsed            | 2187          |
| total timesteps         | 430300        |
| value_loss              | 2.4200042e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003316986  |
| ent_coef_loss           | -5.4020853    |
| entropy                 | 2.863761      |
| ep_rewmean              | -0.373        |
| episodes                | 4308          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 430601        |
| policy_loss             | 0.20617124    |
| qf1_loss                | 3.5217745e-05 |
| qf2_loss                | 2.9547935e-05 |
| time_elapsed            | 2189          |
| total timesteps         | 430700        |
| value_loss              | 3.7585956e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00031996882 |
| ent_coef_loss           | -4.475523     |
| entropy                 | 2.838789      |
| ep_rewmean              | -0.393        |
| episodes                | 4312          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 431001        |
| policy_loss             | 0.19609272    |
| qf1_loss                | 1.4688997e-05 |
| qf2_loss                | 2.3619741e-05 |
| time_elapsed            | 2191          |
| total timesteps         | 431100        |
| value_loss              | 1.9540927e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00032944136 |
| ent_coef_loss           | 3.5724704     |
| entropy                 | 3.002142      |
| ep_rewmean              | -0.411        |
| episodes                | 4316          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 431401        |
| policy_loss             | 0.19913033    |
| qf1_loss                | 0.0003184641  |
| qf2_loss                | 0.00036415743 |
| time_elapsed            | 2193          |
| total timesteps         | 431500        |
| value_loss              | 1.6733296e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00032459223 |
| ent_coef_loss           | -12.876429    |
| entropy                 | 3.2096727     |
| ep_rewmean              | -0.411        |
| episodes                | 4320          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 431801        |
| policy_loss             | 0.18968101    |
| qf1_loss                | 0.00029070297 |
| qf2_loss                | 0.00033592686 |
| time_elapsed            | 2195          |
| total timesteps         | 431900        |
| value_loss              | 5.8447753e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00032332027 |
| ent_coef_loss           | 12.446067     |
| entropy                 | 3.0432184     |
| ep_rewmean              | -0.415        |
| episodes                | 4324          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 432201        |
| policy_loss             | 0.18290836    |
| qf1_loss                | 0.00010121292 |
| qf2_loss                | 9.831637e-05  |
| time_elapsed            | 2197          |
| total timesteps         | 432300        |
| value_loss              | 2.6242598e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003155241  |
| ent_coef_loss           | 0.6978241     |
| entropy                 | 2.5605435     |
| ep_rewmean              | -0.422        |
| episodes                | 4328          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 432601        |
| policy_loss             | 0.19973192    |
| qf1_loss                | 0.00069165137 |
| qf2_loss                | 0.0006755309  |
| time_elapsed            | 2199          |
| total timesteps         | 432700        |
| value_loss              | 1.603468e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003098418  |
| ent_coef_loss           | -7.0190268    |
| entropy                 | 2.8549361     |
| ep_rewmean              | -0.436        |
| episodes                | 4332          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 433001        |
| policy_loss             | 0.18308468    |
| qf1_loss                | 0.00017332727 |
| qf2_loss                | 0.0001643352  |
| time_elapsed            | 2201          |
| total timesteps         | 433100        |
| value_loss              | 1.6868555e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00029857014 |
| ent_coef_loss           | -0.87803054   |
| entropy                 | 2.6841156     |
| ep_rewmean              | -0.444        |
| episodes                | 4336          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 433401        |
| policy_loss             | 0.17710054    |
| qf1_loss                | 1.8443418e-05 |
| qf2_loss                | 1.1912971e-05 |
| time_elapsed            | 2203          |
| total timesteps         | 433500        |
| value_loss              | 2.0067888e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00030106975 |
| ent_coef_loss           | 1.8239775     |
| entropy                 | 3.3257725     |
| ep_rewmean              | -0.451        |
| episodes                | 4340          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 433801        |
| policy_loss             | 0.18234555    |
| qf1_loss                | 6.692026e-05  |
| qf2_loss                | 6.705304e-05  |
| time_elapsed            | 2205          |
| total timesteps         | 433900        |
| value_loss              | 1.8118324e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00029539663 |
| ent_coef_loss           | 2.2992082     |
| entropy                 | 2.8682027     |
| ep_rewmean              | -0.458        |
| episodes                | 4344          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 434201        |
| policy_loss             | 0.17776285    |
| qf1_loss                | 2.7235228e-05 |
| qf2_loss                | 1.7287766e-05 |
| time_elapsed            | 2207          |
| total timesteps         | 434300        |
| value_loss              | 1.0353917e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0002950045  |
| ent_coef_loss           | 11.021332     |
| entropy                 | 2.5604048     |
| ep_rewmean              | -0.448        |
| episodes                | 4348          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 434601        |
| policy_loss             | 0.17750853    |
| qf1_loss                | 1.14539e-05   |
| qf2_loss                | 1.2493072e-05 |
| time_elapsed            | 2209          |
| total timesteps         | 434700        |
| value_loss              | 2.7847007e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003021429  |
| ent_coef_loss           | -0.4185152    |
| entropy                 | 3.0275455     |
| ep_rewmean              | -0.441        |
| episodes                | 4352          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 435001        |
| policy_loss             | 0.17685252    |
| qf1_loss                | 0.00017687402 |
| qf2_loss                | 0.0001773441  |
| time_elapsed            | 2211          |
| total timesteps         | 435100        |
| value_loss              | 1.7482585e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00030365918 |
| ent_coef_loss           | 2.7482586     |
| entropy                 | 3.0990453     |
| ep_rewmean              | -0.447        |
| episodes                | 4356          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 435401        |
| policy_loss             | 0.1842201     |
| qf1_loss                | 0.00022861367 |
| qf2_loss                | 0.00020891435 |
| time_elapsed            | 2213          |
| total timesteps         | 435500        |
| value_loss              | 1.88847e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0002980214  |
| ent_coef_loss           | 6.19487       |
| entropy                 | 2.694235      |
| ep_rewmean              | -0.45         |
| episodes                | 4360          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 435801        |
| policy_loss             | 0.19710958    |
| qf1_loss                | 2.8365741e-05 |
| qf2_loss                | 2.3556138e-05 |
| time_elapsed            | 2215          |
| total timesteps         | 435900        |
| value_loss              | 2.6684496e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00030487587 |
| ent_coef_loss           | -4.832363     |
| entropy                 | 2.8744822     |
| ep_rewmean              | -0.458        |
| episodes                | 4364          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 436201        |
| policy_loss             | 0.19548588    |
| qf1_loss                | 0.00016913393 |
| qf2_loss                | 0.00019856651 |
| time_elapsed            | 2217          |
| total timesteps         | 436300        |
| value_loss              | 1.8070752e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0003132189  |
| ent_coef_loss           | 1.8159113     |
| entropy                 | 2.707564      |
| ep_rewmean              | -0.461        |
| episodes                | 4368          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 436601        |
| policy_loss             | 0.17074206    |
| qf1_loss                | 2.2493574e-05 |
| qf2_loss                | 2.7096463e-05 |
| time_elapsed            | 2219          |
| total timesteps         | 436700        |
| value_loss              | 2.1677137e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00031462507 |
| ent_coef_loss           | -10.004835    |
| entropy                 | 2.9009829     |
| ep_rewmean              | -0.464        |
| episodes                | 4372          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 437001        |
| policy_loss             | 0.1796712     |
| qf1_loss                | 1.0368819e-05 |
| qf2_loss                | 7.052765e-06  |
| time_elapsed            | 2221          |
| total timesteps         | 437100        |
| value_loss              | 2.2376094e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00031560747 |
| ent_coef_loss           | -1.9004889    |
| entropy                 | 2.6845856     |
| ep_rewmean              | -0.465        |
| episodes                | 4376          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 437401        |
| policy_loss             | 0.18324283    |
| qf1_loss                | 9.732863e-06  |
| qf2_loss                | 1.4168831e-05 |
| time_elapsed            | 2223          |
| total timesteps         | 437500        |
| value_loss              | 1.3911882e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0003136287 |
| ent_coef_loss           | -2.7177932   |
| entropy                 | 2.8174486    |
| ep_rewmean              | -0.466       |
| episodes                | 4380         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -0.5         |
| n_updates               | 437801       |
| policy_loss             | 0.1699607    |
| qf1_loss                | 0.0011397086 |
| qf2_loss                | 0.0011235278 |
| time_elapsed            | 2225         |
| total timesteps         | 437900       |
| value_loss              | 1.845782e-05 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0003087884   |
| ent_coef_loss           | -8.835927      |
| entropy                 | 3.2236786      |
| ep_rewmean              | -0.466         |
| episodes                | 4384           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.5           |
| n_updates               | 438201         |
| policy_loss             | 0.18112728     |
| qf1_loss                | 1.5023659e-05  |
| qf2_loss                | 1.40125585e-05 |
| time_elapsed            | 2227           |
| total timesteps         | 438300         |
| value_loss              | 2.9787408e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00032014097 |
| ent_coef_loss           | -3.1907167    |
| entropy                 | 3.0471573     |
| ep_rewmean              | -0.464        |
| episodes                | 4388          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 438601        |
| policy_loss             | 0.17353182    |
| qf1_loss                | 1.838213e-05  |
| qf2_loss                | 1.9580435e-05 |
| time_elapsed            | 2229          |
| total timesteps         | 438700        |
| value_loss              | 1.151845e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00033001084 |
| ent_coef_loss           | 4.4945545     |
| entropy                 | 3.2129683     |
| ep_rewmean              | -0.464        |
| episodes                | 4392          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 439001        |
| policy_loss             | 0.17902717    |
| qf1_loss                | 0.00069326407 |
| qf2_loss                | 0.0007522459  |
| time_elapsed            | 2231          |
| total timesteps         | 439100        |
| value_loss              | 2.7511698e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00032632073 |
| ent_coef_loss           | -12.096991    |
| entropy                 | 3.5418885     |
| ep_rewmean              | -0.463        |
| episodes                | 4396          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 439401        |
| policy_loss             | 0.1403606     |
| qf1_loss                | 0.00024736085 |
| qf2_loss                | 0.00024776283 |
| time_elapsed            | 2233          |
| total timesteps         | 439500        |
| value_loss              | 2.164458e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00031068805 |
| ent_coef_loss           | 4.138898      |
| entropy                 | 2.9315846     |
| ep_rewmean              | -0.457        |
| episodes                | 4400          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 439801        |
| policy_loss             | 0.16112402    |
| qf1_loss                | 1.9235295e-05 |
| qf2_loss                | 1.6781152e-05 |
| time_elapsed            | 2235          |
| total timesteps         | 439900        |
| value_loss              | 1.9513753e-05 |
-------------------------------------------
Eval num_timesteps=440000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00029390174 |
| ent_coef_loss           | -3.919728     |
| entropy                 | 2.9552054     |
| ep_rewmean              | -0.454        |
| episodes                | 4404          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 440201        |
| policy_loss             | 0.16562894    |
| qf1_loss                | 0.00043483422 |
| qf2_loss                | 0.00047264734 |
| time_elapsed            | 2237          |
| total timesteps         | 440300        |
| value_loss              | 2.3460041e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000279962   |
| ent_coef_loss           | 6.062383      |
| entropy                 | 3.0630474     |
| ep_rewmean              | -0.453        |
| episodes                | 4408          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 440601        |
| policy_loss             | 0.1508406     |
| qf1_loss                | 0.00016732875 |
| qf2_loss                | 0.00016374256 |
| time_elapsed            | 2239          |
| total timesteps         | 440700        |
| value_loss              | 1.3690442e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00026256064 |
| ent_coef_loss           | 4.639185      |
| entropy                 | 2.609687      |
| ep_rewmean              | -0.428        |
| episodes                | 4412          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 441001        |
| policy_loss             | 0.15750003    |
| qf1_loss                | 0.00028949836 |
| qf2_loss                | 0.000282625   |
| time_elapsed            | 2242          |
| total timesteps         | 441100        |
| value_loss              | 1.6078091e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00024634047 |
| ent_coef_loss           | -14.400435    |
| entropy                 | 2.8423386     |
| ep_rewmean              | -0.408        |
| episodes                | 4416          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 441401        |
| policy_loss             | 0.14791161    |
| qf1_loss                | 9.436302e-06  |
| qf2_loss                | 4.929922e-06  |
| time_elapsed            | 2244          |
| total timesteps         | 441500        |
| value_loss              | 7.693864e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00023311884 |
| ent_coef_loss           | 14.155895     |
| entropy                 | 2.7739959     |
| ep_rewmean              | -0.409        |
| episodes                | 4420          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 441801        |
| policy_loss             | 0.15693343    |
| qf1_loss                | 0.00015635406 |
| qf2_loss                | 0.00017467712 |
| time_elapsed            | 2246          |
| total timesteps         | 441900        |
| value_loss              | 1.21252e-05   |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00022548072  |
| ent_coef_loss           | -7.934371      |
| entropy                 | 3.102273       |
| ep_rewmean              | -0.401         |
| episodes                | 4424           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.4           |
| n_updates               | 442201         |
| policy_loss             | 0.15108313     |
| qf1_loss                | 1.0459092e-05  |
| qf2_loss                | 1.344555e-05   |
| time_elapsed            | 2248           |
| total timesteps         | 442300         |
| value_loss              | 1.23598875e-05 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00021376178 |
| ent_coef_loss           | -0.6285615    |
| entropy                 | 2.618166      |
| ep_rewmean              | -0.388        |
| episodes                | 4428          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 442601        |
| policy_loss             | 0.1493311     |
| qf1_loss                | 9.588835e-06  |
| qf2_loss                | 1.9889252e-05 |
| time_elapsed            | 2250          |
| total timesteps         | 442700        |
| value_loss              | 1.6944168e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00020356347 |
| ent_coef_loss           | -1.0994897    |
| entropy                 | 2.0080426     |
| ep_rewmean              | -0.372        |
| episodes                | 4432          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 443001        |
| policy_loss             | 0.14673203    |
| qf1_loss                | 0.00024163008 |
| qf2_loss                | 0.00019568398 |
| time_elapsed            | 2252          |
| total timesteps         | 443100        |
| value_loss              | 1.7380964e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00020092804 |
| ent_coef_loss           | 1.5723612     |
| entropy                 | 2.2375817     |
| ep_rewmean              | -0.363        |
| episodes                | 4436          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 443401        |
| policy_loss             | 0.14265397    |
| qf1_loss                | 4.4985896e-05 |
| qf2_loss                | 4.5309258e-05 |
| time_elapsed            | 2254          |
| total timesteps         | 443500        |
| value_loss              | 1.7095488e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00019447943 |
| ent_coef_loss           | -6.3855186    |
| entropy                 | 2.4293432     |
| ep_rewmean              | -0.355        |
| episodes                | 4440          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 443801        |
| policy_loss             | 0.13938126    |
| qf1_loss                | 1.0213418e-05 |
| qf2_loss                | 6.3626385e-06 |
| time_elapsed            | 2256          |
| total timesteps         | 443900        |
| value_loss              | 1.8023788e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00019149462 |
| ent_coef_loss           | -4.103289     |
| entropy                 | 2.6230621     |
| ep_rewmean              | -0.347        |
| episodes                | 4444          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 444201        |
| policy_loss             | 0.14273511    |
| qf1_loss                | 1.9750862e-05 |
| qf2_loss                | 3.761358e-05  |
| time_elapsed            | 2258          |
| total timesteps         | 444300        |
| value_loss              | 9.877929e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00019357479 |
| ent_coef_loss           | -0.07065374   |
| entropy                 | 3.082837      |
| ep_rewmean              | -0.344        |
| episodes                | 4448          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 444601        |
| policy_loss             | 0.14997901    |
| qf1_loss                | 3.959426e-05  |
| qf2_loss                | 4.2078285e-05 |
| time_elapsed            | 2260          |
| total timesteps         | 444700        |
| value_loss              | 1.6828095e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00018856462 |
| ent_coef_loss           | 8.058324      |
| entropy                 | 2.9597936     |
| ep_rewmean              | -0.342        |
| episodes                | 4452          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 445001        |
| policy_loss             | 0.14067672    |
| qf1_loss                | 5.134206e-06  |
| qf2_loss                | 5.7395505e-06 |
| time_elapsed            | 2262          |
| total timesteps         | 445100        |
| value_loss              | 4.7699477e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00018340125 |
| ent_coef_loss           | -0.30491424   |
| entropy                 | 2.6824398     |
| ep_rewmean              | -0.333        |
| episodes                | 4456          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 445401        |
| policy_loss             | 0.15477702    |
| qf1_loss                | 8.951507e-06  |
| qf2_loss                | 9.633391e-06  |
| time_elapsed            | 2263          |
| total timesteps         | 445500        |
| value_loss              | 2.8951361e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00018428577 |
| ent_coef_loss           | -6.024664     |
| entropy                 | 2.808702      |
| ep_rewmean              | -0.326        |
| episodes                | 4460          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 445801        |
| policy_loss             | 0.13314757    |
| qf1_loss                | 0.00024369739 |
| qf2_loss                | 0.00025324526 |
| time_elapsed            | 2266          |
| total timesteps         | 445900        |
| value_loss              | 1.2339058e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000182218   |
| ent_coef_loss           | 7.163558      |
| entropy                 | 3.28835       |
| ep_rewmean              | -0.315        |
| episodes                | 4464          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 446201        |
| policy_loss             | 0.12965661    |
| qf1_loss                | 0.0002543933  |
| qf2_loss                | 0.000276227   |
| time_elapsed            | 2267          |
| total timesteps         | 446300        |
| value_loss              | 1.0552927e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00017778928 |
| ent_coef_loss           | 10.51067      |
| entropy                 | 3.65971       |
| ep_rewmean              | -0.311        |
| episodes                | 4468          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 446601        |
| policy_loss             | 0.1408265     |
| qf1_loss                | 0.00022377666 |
| qf2_loss                | 0.0002174959  |
| time_elapsed            | 2269          |
| total timesteps         | 446700        |
| value_loss              | 1.0455619e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000177703   |
| ent_coef_loss           | -7.157504     |
| entropy                 | 3.2669125     |
| ep_rewmean              | -0.306        |
| episodes                | 4472          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 447001        |
| policy_loss             | 0.116848394   |
| qf1_loss                | 0.00010501392 |
| qf2_loss                | 0.0001026145  |
| time_elapsed            | 2271          |
| total timesteps         | 447100        |
| value_loss              | 1.6925984e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00017499886 |
| ent_coef_loss           | 7.83419       |
| entropy                 | 3.7259033     |
| ep_rewmean              | -0.302        |
| episodes                | 4476          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 447401        |
| policy_loss             | 0.110927664   |
| qf1_loss                | 4.422033e-05  |
| qf2_loss                | 3.9946397e-05 |
| time_elapsed            | 2273          |
| total timesteps         | 447500        |
| value_loss              | 4.89347e-06   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00016700754 |
| ent_coef_loss           | -5.013571     |
| entropy                 | 3.209538      |
| ep_rewmean              | -0.301        |
| episodes                | 4480          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 447801        |
| policy_loss             | 0.12809049    |
| qf1_loss                | 5.173167e-05  |
| qf2_loss                | 6.38878e-05   |
| time_elapsed            | 2276          |
| total timesteps         | 447900        |
| value_loss              | 2.4443334e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0001582905  |
| ent_coef_loss           | -8.81282      |
| entropy                 | 2.9909735     |
| ep_rewmean              | -0.302        |
| episodes                | 4484          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 448201        |
| policy_loss             | 0.108526215   |
| qf1_loss                | 4.63157e-06   |
| qf2_loss                | 4.889549e-06  |
| time_elapsed            | 2278          |
| total timesteps         | 448300        |
| value_loss              | 1.0645529e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00014713955 |
| ent_coef_loss           | -4.206899     |
| entropy                 | 2.5318906     |
| ep_rewmean              | -0.304        |
| episodes                | 4488          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 448601        |
| policy_loss             | 0.1110325     |
| qf1_loss                | 4.3129144e-06 |
| qf2_loss                | 5.116066e-06  |
| time_elapsed            | 2280          |
| total timesteps         | 448700        |
| value_loss              | 4.776379e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00014605689 |
| ent_coef_loss           | -4.350335     |
| entropy                 | 2.6982417     |
| ep_rewmean              | -0.304        |
| episodes                | 4492          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 449001        |
| policy_loss             | 0.10471501    |
| qf1_loss                | 5.788073e-05  |
| qf2_loss                | 5.1366216e-05 |
| time_elapsed            | 2282          |
| total timesteps         | 449100        |
| value_loss              | 2.9997966e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00014309345 |
| ent_coef_loss           | 7.5469904     |
| entropy                 | 2.9774609     |
| ep_rewmean              | -0.302        |
| episodes                | 4496          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 449401        |
| policy_loss             | 0.10638332    |
| qf1_loss                | 1.3082836e-05 |
| qf2_loss                | 2.1886988e-05 |
| time_elapsed            | 2284          |
| total timesteps         | 449500        |
| value_loss              | 9.673869e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00014048445 |
| ent_coef_loss           | -4.287978     |
| entropy                 | 2.737979      |
| ep_rewmean              | -0.298        |
| episodes                | 4500          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 449801        |
| policy_loss             | 0.10851343    |
| qf1_loss                | 8.049329e-06  |
| qf2_loss                | 6.177078e-06  |
| time_elapsed            | 2286          |
| total timesteps         | 449900        |
| value_loss              | 8.759659e-06  |
-------------------------------------------
Eval num_timesteps=450000, episode_reward=-0.27 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00013214962 |
| ent_coef_loss           | 3.6476417     |
| entropy                 | 2.7169087     |
| ep_rewmean              | -0.295        |
| episodes                | 4504          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 450201        |
| policy_loss             | 0.10433244    |
| qf1_loss                | 0.00010352413 |
| qf2_loss                | 0.00010131873 |
| time_elapsed            | 2288          |
| total timesteps         | 450300        |
| value_loss              | 1.8124025e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00012433597 |
| ent_coef_loss           | -12.556153    |
| entropy                 | 2.9990153     |
| ep_rewmean              | -0.293        |
| episodes                | 4508          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 450601        |
| policy_loss             | 0.101348214   |
| qf1_loss                | 3.4488345e-05 |
| qf2_loss                | 4.0880026e-05 |
| time_elapsed            | 2290          |
| total timesteps         | 450700        |
| value_loss              | 9.427367e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00011631474 |
| ent_coef_loss           | -8.870275     |
| entropy                 | 3.0578108     |
| ep_rewmean              | -0.292        |
| episodes                | 4512          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 451001        |
| policy_loss             | 0.09740144    |
| qf1_loss                | 1.8887122e-05 |
| qf2_loss                | 2.6204714e-05 |
| time_elapsed            | 2292          |
| total timesteps         | 451100        |
| value_loss              | 5.0923727e-06 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00011195356  |
| ent_coef_loss           | -9.390116      |
| entropy                 | 2.7721         |
| ep_rewmean              | -0.288         |
| episodes                | 4516           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.3           |
| n_updates               | 451401         |
| policy_loss             | 0.09576457     |
| qf1_loss                | 0.000104394225 |
| qf2_loss                | 9.987746e-05   |
| time_elapsed            | 2294           |
| total timesteps         | 451500         |
| value_loss              | 1.0475137e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010805526 |
| ent_coef_loss           | 4.633228      |
| entropy                 | 2.171335      |
| ep_rewmean              | -0.279        |
| episodes                | 4520          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 451801        |
| policy_loss             | 0.10336906    |
| qf1_loss                | 2.1147109e-05 |
| qf2_loss                | 1.871775e-05  |
| time_elapsed            | 2296          |
| total timesteps         | 451900        |
| value_loss              | 1.1273235e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00010625004  |
| ent_coef_loss           | -18.653189     |
| entropy                 | 2.9614801      |
| ep_rewmean              | -0.276         |
| episodes                | 4524           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.3           |
| n_updates               | 452201         |
| policy_loss             | 0.090109065    |
| qf1_loss                | 9.744495e-05   |
| qf2_loss                | 0.000104427745 |
| time_elapsed            | 2298           |
| total timesteps         | 452300         |
| value_loss              | 1.1877526e-05  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010305701 |
| ent_coef_loss           | -12.951938    |
| entropy                 | 2.770172      |
| ep_rewmean              | -0.274        |
| episodes                | 4528          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 452601        |
| policy_loss             | 0.09133231    |
| qf1_loss                | 1.8625993e-05 |
| qf2_loss                | 1.7893572e-05 |
| time_elapsed            | 2300          |
| total timesteps         | 452700        |
| value_loss              | 7.779361e-06  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.000100820056 |
| ent_coef_loss           | -3.7801056     |
| entropy                 | 2.6582046      |
| ep_rewmean              | -0.276         |
| episodes                | 4532           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.3           |
| n_updates               | 453001         |
| policy_loss             | 0.09027685     |
| qf1_loss                | 2.6532784e-06  |
| qf2_loss                | 2.4008025e-06  |
| time_elapsed            | 2302           |
| total timesteps         | 453100         |
| value_loss              | 2.439247e-06   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010038238 |
| ent_coef_loss           | -5.419648     |
| entropy                 | 2.3737376     |
| ep_rewmean              | -0.279        |
| episodes                | 4536          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 453401        |
| policy_loss             | 0.09562154    |
| qf1_loss                | 6.4814103e-06 |
| qf2_loss                | 2.2610793e-06 |
| time_elapsed            | 2304          |
| total timesteps         | 453500        |
| value_loss              | 2.537559e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 9.654397e-05  |
| ent_coef_loss           | -3.1639283    |
| entropy                 | 2.9140174     |
| ep_rewmean              | -0.279        |
| episodes                | 4540          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 453801        |
| policy_loss             | 0.09449943    |
| qf1_loss                | 3.2044023e-05 |
| qf2_loss                | 3.2077012e-05 |
| time_elapsed            | 2306          |
| total timesteps         | 453900        |
| value_loss              | 1.4702853e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010214166 |
| ent_coef_loss           | 9.739203      |
| entropy                 | 2.567978      |
| ep_rewmean              | -0.283        |
| episodes                | 4544          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 454201        |
| policy_loss             | 0.083718464   |
| qf1_loss                | 2.328946e-06  |
| qf2_loss                | 4.5607067e-06 |
| time_elapsed            | 2308          |
| total timesteps         | 454300        |
| value_loss              | 4.019562e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010716448 |
| ent_coef_loss           | -0.73147786   |
| entropy                 | 2.825518      |
| ep_rewmean              | -0.288        |
| episodes                | 4548          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 454601        |
| policy_loss             | 0.0824209     |
| qf1_loss                | 3.7635094e-05 |
| qf2_loss                | 3.816184e-05  |
| time_elapsed            | 2310          |
| total timesteps         | 454700        |
| value_loss              | 2.8344712e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010247447 |
| ent_coef_loss           | -10.64893     |
| entropy                 | 2.930905      |
| ep_rewmean              | -0.289        |
| episodes                | 4552          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 455001        |
| policy_loss             | 0.09227873    |
| qf1_loss                | 1.0217339e-05 |
| qf2_loss                | 8.484864e-06  |
| time_elapsed            | 2312          |
| total timesteps         | 455100        |
| value_loss              | 7.816909e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 9.9935256e-05 |
| ent_coef_loss           | -14.7303505   |
| entropy                 | 2.4995632     |
| ep_rewmean              | -0.29         |
| episodes                | 4556          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 455401        |
| policy_loss             | 0.07609848    |
| qf1_loss                | 6.176667e-05  |
| qf2_loss                | 7.873576e-05  |
| time_elapsed            | 2314          |
| total timesteps         | 455500        |
| value_loss              | 1.2105342e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 9.825988e-05  |
| ent_coef_loss           | -0.983593     |
| entropy                 | 2.6498632     |
| ep_rewmean              | -0.292        |
| episodes                | 4560          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 455801        |
| policy_loss             | 0.06785887    |
| qf1_loss                | 5.5990936e-06 |
| qf2_loss                | 6.029313e-06  |
| time_elapsed            | 2316          |
| total timesteps         | 455900        |
| value_loss              | 5.6188574e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 9.9343924e-05 |
| ent_coef_loss           | -3.34304      |
| entropy                 | 2.1336517     |
| ep_rewmean              | -0.293        |
| episodes                | 4564          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 456201        |
| policy_loss             | 0.08301806    |
| qf1_loss                | 5.6434706e-06 |
| qf2_loss                | 1.4675731e-05 |
| time_elapsed            | 2318          |
| total timesteps         | 456300        |
| value_loss              | 9.470853e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010264749 |
| ent_coef_loss           | -11.09298     |
| entropy                 | 2.8313882     |
| ep_rewmean              | -0.293        |
| episodes                | 4568          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 456601        |
| policy_loss             | 0.086958036   |
| qf1_loss                | 1.323195e-05  |
| qf2_loss                | 1.3205796e-05 |
| time_elapsed            | 2320          |
| total timesteps         | 456700        |
| value_loss              | 1.1528332e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 9.90108e-05   |
| ent_coef_loss           | -0.8249744    |
| entropy                 | 2.8766549     |
| ep_rewmean              | -0.294        |
| episodes                | 4572          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 457001        |
| policy_loss             | 0.100862846   |
| qf1_loss                | 7.157885e-06  |
| qf2_loss                | 6.879919e-06  |
| time_elapsed            | 2322          |
| total timesteps         | 457100        |
| value_loss              | 7.0815695e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 9.9712204e-05 |
| ent_coef_loss           | 5.793894      |
| entropy                 | 2.790122      |
| ep_rewmean              | -0.294        |
| episodes                | 4576          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 457401        |
| policy_loss             | 0.07506742    |
| qf1_loss                | 1.1190523e-05 |
| qf2_loss                | 1.2843165e-05 |
| time_elapsed            | 2324          |
| total timesteps         | 457500        |
| value_loss              | 1.036329e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00011022619 |
| ent_coef_loss           | -1.9166932    |
| entropy                 | 2.8129873     |
| ep_rewmean              | -0.299        |
| episodes                | 4580          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 457801        |
| policy_loss             | 0.07078133    |
| qf1_loss                | 3.1796653e-06 |
| qf2_loss                | 4.5584934e-06 |
| time_elapsed            | 2326          |
| total timesteps         | 457900        |
| value_loss              | 8.1455855e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00011156262 |
| ent_coef_loss           | -17.20307     |
| entropy                 | 3.332066      |
| ep_rewmean              | -0.3          |
| episodes                | 4584          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 458201        |
| policy_loss             | 0.08108863    |
| qf1_loss                | 2.6168777e-06 |
| qf2_loss                | 2.4862843e-06 |
| time_elapsed            | 2328          |
| total timesteps         | 458300        |
| value_loss              | 8.311365e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010849742 |
| ent_coef_loss           | 5.6230016     |
| entropy                 | 2.7693167     |
| ep_rewmean              | -0.301        |
| episodes                | 4588          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 458601        |
| policy_loss             | 0.06730871    |
| qf1_loss                | 1.5552263e-05 |
| qf2_loss                | 1.0901771e-05 |
| time_elapsed            | 2330          |
| total timesteps         | 458700        |
| value_loss              | 4.142629e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010289958 |
| ent_coef_loss           | -14.085138    |
| entropy                 | 3.0991702     |
| ep_rewmean              | -0.307        |
| episodes                | 4592          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 459001        |
| policy_loss             | 0.065519966   |
| qf1_loss                | 4.7861968e-06 |
| qf2_loss                | 4.7113426e-06 |
| time_elapsed            | 2332          |
| total timesteps         | 459100        |
| value_loss              | 1.4676507e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.000101862475 |
| ent_coef_loss           | 3.3992503      |
| entropy                 | 2.9234138      |
| ep_rewmean              | -0.32          |
| episodes                | 4596           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.3           |
| n_updates               | 459401         |
| policy_loss             | 0.09043522     |
| qf1_loss                | 4.705131e-06   |
| qf2_loss                | 5.78903e-06    |
| time_elapsed            | 2334           |
| total timesteps         | 459500         |
| value_loss              | 7.1251698e-06  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 9.956121e-05  |
| ent_coef_loss           | 7.0967593     |
| entropy                 | 2.7070212     |
| ep_rewmean              | -0.323        |
| episodes                | 4600          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 459801        |
| policy_loss             | 0.06604458    |
| qf1_loss                | 4.3057553e-06 |
| qf2_loss                | 4.983392e-06  |
| time_elapsed            | 2336          |
| total timesteps         | 459900        |
| value_loss              | 1.1389451e-05 |
-------------------------------------------
Eval num_timesteps=460000, episode_reward=-0.37 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 9.959037e-05  |
| ent_coef_loss           | -2.3303359    |
| entropy                 | 2.6663716     |
| ep_rewmean              | -0.33         |
| episodes                | 4604          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 460201        |
| policy_loss             | 0.08050627    |
| qf1_loss                | 3.0440735e-06 |
| qf2_loss                | 3.3273332e-06 |
| time_elapsed            | 2338          |
| total timesteps         | 460300        |
| value_loss              | 7.3927195e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010060414 |
| ent_coef_loss           | 6.123601      |
| entropy                 | 3.019759      |
| ep_rewmean              | -0.335        |
| episodes                | 4608          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 460601        |
| policy_loss             | 0.07680635    |
| qf1_loss                | 9.226026e-06  |
| qf2_loss                | 1.935876e-05  |
| time_elapsed            | 2340          |
| total timesteps         | 460700        |
| value_loss              | 1.7615965e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00011082774 |
| ent_coef_loss           | 16.699358     |
| entropy                 | 2.9333963     |
| ep_rewmean              | -0.34         |
| episodes                | 4612          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 461001        |
| policy_loss             | 0.06913482    |
| qf1_loss                | 1.0609541e-05 |
| qf2_loss                | 7.6292936e-06 |
| time_elapsed            | 2342          |
| total timesteps         | 461100        |
| value_loss              | 8.7001235e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00012530302 |
| ent_coef_loss           | -0.6592629    |
| entropy                 | 3.3435512     |
| ep_rewmean              | -0.346        |
| episodes                | 4616          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 461401        |
| policy_loss             | 0.051678974   |
| qf1_loss                | 5.7653997e-05 |
| qf2_loss                | 7.039208e-05  |
| time_elapsed            | 2344          |
| total timesteps         | 461500        |
| value_loss              | 6.7470814e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0001348513  |
| ent_coef_loss           | -1.9352018    |
| entropy                 | 3.6951947     |
| ep_rewmean              | -0.364        |
| episodes                | 4620          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 461801        |
| policy_loss             | 0.060940653   |
| qf1_loss                | 2.7792644e-06 |
| qf2_loss                | 4.4837243e-06 |
| time_elapsed            | 2346          |
| total timesteps         | 461900        |
| value_loss              | 7.906359e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00014479994 |
| ent_coef_loss           | -13.747945    |
| entropy                 | 3.5385194     |
| ep_rewmean              | -0.377        |
| episodes                | 4624          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 462201        |
| policy_loss             | 0.06550467    |
| qf1_loss                | 2.7860924e-05 |
| qf2_loss                | 2.761635e-05  |
| time_elapsed            | 2348          |
| total timesteps         | 462300        |
| value_loss              | 5.6020485e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00014990903 |
| ent_coef_loss           | 5.052109      |
| entropy                 | 3.5944867     |
| ep_rewmean              | -0.387        |
| episodes                | 4628          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 462601        |
| policy_loss             | 0.063385755   |
| qf1_loss                | 8.222287e-06  |
| qf2_loss                | 1.0087098e-05 |
| time_elapsed            | 2350          |
| total timesteps         | 462700        |
| value_loss              | 4.3105874e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00015493146 |
| ent_coef_loss           | -3.865135     |
| entropy                 | 3.4390168     |
| ep_rewmean              | -0.398        |
| episodes                | 4632          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 463001        |
| policy_loss             | 0.024027374   |
| qf1_loss                | 3.571919e-06  |
| qf2_loss                | 5.738496e-06  |
| time_elapsed            | 2352          |
| total timesteps         | 463100        |
| value_loss              | 9.083484e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00015812514 |
| ent_coef_loss           | 8.868319      |
| entropy                 | 3.079863      |
| ep_rewmean              | -0.4          |
| episodes                | 4636          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 463401        |
| policy_loss             | 0.041395955   |
| qf1_loss                | 9.114695e-06  |
| qf2_loss                | 6.1370874e-06 |
| time_elapsed            | 2354          |
| total timesteps         | 463500        |
| value_loss              | 4.512719e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00015787923 |
| ent_coef_loss           | 0.16781473    |
| entropy                 | 3.3365614     |
| ep_rewmean              | -0.408        |
| episodes                | 4640          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 463801        |
| policy_loss             | 0.070305154   |
| qf1_loss                | 1.0714457e-05 |
| qf2_loss                | 1.4472313e-05 |
| time_elapsed            | 2356          |
| total timesteps         | 463900        |
| value_loss              | 7.3769697e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00015949077 |
| ent_coef_loss           | -3.2481172    |
| entropy                 | 3.3428257     |
| ep_rewmean              | -0.409        |
| episodes                | 4644          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 464201        |
| policy_loss             | 0.03956917    |
| qf1_loss                | 3.5172282e-06 |
| qf2_loss                | 3.4891402e-06 |
| time_elapsed            | 2358          |
| total timesteps         | 464300        |
| value_loss              | 4.7701046e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00015694038 |
| ent_coef_loss           | -0.8033457    |
| entropy                 | 2.9397044     |
| ep_rewmean              | -0.411        |
| episodes                | 4648          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 464601        |
| policy_loss             | 0.03924028    |
| qf1_loss                | 3.9354513e-06 |
| qf2_loss                | 2.7199235e-06 |
| time_elapsed            | 2360          |
| total timesteps         | 464700        |
| value_loss              | 3.5305652e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00015656771 |
| ent_coef_loss           | -7.2836823    |
| entropy                 | 3.1464791     |
| ep_rewmean              | -0.413        |
| episodes                | 4652          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 465001        |
| policy_loss             | 0.033233184   |
| qf1_loss                | 7.84074e-06   |
| qf2_loss                | 9.263889e-06  |
| time_elapsed            | 2362          |
| total timesteps         | 465100        |
| value_loss              | 2.617629e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0001573992  |
| ent_coef_loss           | -13.656644    |
| entropy                 | 2.835373      |
| ep_rewmean              | -0.417        |
| episodes                | 4656          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 465401        |
| policy_loss             | 0.012017796   |
| qf1_loss                | 5.757219e-06  |
| qf2_loss                | 6.2487666e-06 |
| time_elapsed            | 2364          |
| total timesteps         | 465500        |
| value_loss              | 2.6567755e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00015275685 |
| ent_coef_loss           | -7.4806423    |
| entropy                 | 2.8710492     |
| ep_rewmean              | -0.422        |
| episodes                | 4660          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 465801        |
| policy_loss             | 0.012608312   |
| qf1_loss                | 6.7894043e-06 |
| qf2_loss                | 7.2606335e-06 |
| time_elapsed            | 2366          |
| total timesteps         | 465900        |
| value_loss              | 4.512458e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00015255653 |
| ent_coef_loss           | 2.7204835     |
| entropy                 | 3.810259      |
| ep_rewmean              | -0.425        |
| episodes                | 4664          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 466201        |
| policy_loss             | 0.021224365   |
| qf1_loss                | 4.295345e-06  |
| qf2_loss                | 4.682226e-06  |
| time_elapsed            | 2368          |
| total timesteps         | 466300        |
| value_loss              | 7.181963e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00014889216 |
| ent_coef_loss           | -4.2975316    |
| entropy                 | 3.0069947     |
| ep_rewmean              | -0.425        |
| episodes                | 4668          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 466601        |
| policy_loss             | 0.027131557   |
| qf1_loss                | 3.4482466e-06 |
| qf2_loss                | 3.1387344e-06 |
| time_elapsed            | 2370          |
| total timesteps         | 466700        |
| value_loss              | 6.3962552e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0001526392  |
| ent_coef_loss           | 6.881245      |
| entropy                 | 3.8956974     |
| ep_rewmean              | -0.422        |
| episodes                | 4672          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 467001        |
| policy_loss             | 0.020855132   |
| qf1_loss                | 7.558064e-06  |
| qf2_loss                | 7.3956858e-06 |
| time_elapsed            | 2372          |
| total timesteps         | 467100        |
| value_loss              | 5.078946e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00015781344 |
| ent_coef_loss           | 4.684181      |
| entropy                 | 3.469804      |
| ep_rewmean              | -0.419        |
| episodes                | 4676          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 467401        |
| policy_loss             | 0.02124145    |
| qf1_loss                | 3.607189e-05  |
| qf2_loss                | 3.519858e-05  |
| time_elapsed            | 2374          |
| total timesteps         | 467500        |
| value_loss              | 3.9476818e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00015460425 |
| ent_coef_loss           | -5.0343537    |
| entropy                 | 3.682796      |
| ep_rewmean              | -0.411        |
| episodes                | 4680          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 467801        |
| policy_loss             | 0.013695685   |
| qf1_loss                | 4.3802847e-05 |
| qf2_loss                | 4.150696e-05  |
| time_elapsed            | 2376          |
| total timesteps         | 467900        |
| value_loss              | 5.033683e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00014344965 |
| ent_coef_loss           | -4.7233286    |
| entropy                 | 3.712792      |
| ep_rewmean              | -0.406        |
| episodes                | 4684          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 468201        |
| policy_loss             | 0.030357504   |
| qf1_loss                | 5.4092766e-06 |
| qf2_loss                | 2.115889e-06  |
| time_elapsed            | 2379          |
| total timesteps         | 468300        |
| value_loss              | 1.9863637e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00013195656 |
| ent_coef_loss           | -3.0285938    |
| entropy                 | 4.0084496     |
| ep_rewmean              | -0.4          |
| episodes                | 4688          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 468601        |
| policy_loss             | 0.02225897    |
| qf1_loss                | 2.6164455e-06 |
| qf2_loss                | 2.3889315e-06 |
| time_elapsed            | 2381          |
| total timesteps         | 468700        |
| value_loss              | 3.3763238e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00012070655 |
| ent_coef_loss           | -11.913449    |
| entropy                 | 3.2659876     |
| ep_rewmean              | -0.39         |
| episodes                | 4692          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 469001        |
| policy_loss             | 0.028573604   |
| qf1_loss                | 3.7619302e-06 |
| qf2_loss                | 3.4220068e-06 |
| time_elapsed            | 2383          |
| total timesteps         | 469100        |
| value_loss              | 3.543368e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010912242 |
| ent_coef_loss           | -11.427885    |
| entropy                 | 3.254274      |
| ep_rewmean              | -0.376        |
| episodes                | 4696          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 469401        |
| policy_loss             | 0.03107678    |
| qf1_loss                | 2.1598632e-06 |
| qf2_loss                | 2.7388674e-06 |
| time_elapsed            | 2385          |
| total timesteps         | 469500        |
| value_loss              | 3.946925e-06  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.000100710124 |
| ent_coef_loss           | -5.619828      |
| entropy                 | 4.102225       |
| ep_rewmean              | -0.371         |
| episodes                | 4700           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.4           |
| n_updates               | 469801         |
| policy_loss             | 0.010628098    |
| qf1_loss                | 1.3568183e-06  |
| qf2_loss                | 1.5401899e-06  |
| time_elapsed            | 2387           |
| total timesteps         | 469900         |
| value_loss              | 1.903363e-06   |
--------------------------------------------
Eval num_timesteps=470000, episode_reward=-0.23 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 9.505055e-05 |
| ent_coef_loss           | -1.9299836   |
| entropy                 | 3.7283735    |
| ep_rewmean              | -0.363       |
| episodes                | 4704         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -0.4         |
| n_updates               | 470201       |
| policy_loss             | 0.025293931  |
| qf1_loss                | 2.776359e-06 |
| qf2_loss                | 3.481331e-06 |
| time_elapsed            | 2389         |
| total timesteps         | 470300       |
| value_loss              | 4.441239e-06 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 9.46557e-05   |
| ent_coef_loss           | -4.0983887    |
| entropy                 | 3.9838138     |
| ep_rewmean              | -0.36         |
| episodes                | 4708          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 470601        |
| policy_loss             | 0.025534334   |
| qf1_loss                | 2.4985088e-06 |
| qf2_loss                | 2.391544e-06  |
| time_elapsed            | 2391          |
| total timesteps         | 470700        |
| value_loss              | 1.7535663e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 8.966814e-05  |
| ent_coef_loss           | -18.2479      |
| entropy                 | 3.94631       |
| ep_rewmean              | -0.354        |
| episodes                | 4712          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 471001        |
| policy_loss             | 0.0149631575  |
| qf1_loss                | 1.9454328e-06 |
| qf2_loss                | 1.7683315e-06 |
| time_elapsed            | 2393          |
| total timesteps         | 471100        |
| value_loss              | 1.5949203e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 8.537251e-05  |
| ent_coef_loss           | 1.3874774     |
| entropy                 | 4.138318      |
| ep_rewmean              | -0.348        |
| episodes                | 4716          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 471401        |
| policy_loss             | 0.022558171   |
| qf1_loss                | 2.5525349e-06 |
| qf2_loss                | 4.0559535e-06 |
| time_elapsed            | 2395          |
| total timesteps         | 471500        |
| value_loss              | 2.4510655e-06 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 8.168364e-05 |
| ent_coef_loss           | -2.523724    |
| entropy                 | 3.5445194    |
| ep_rewmean              | -0.33        |
| episodes                | 4720         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -0.3         |
| n_updates               | 471801       |
| policy_loss             | 0.038298145  |
| qf1_loss                | 7.192318e-07 |
| qf2_loss                | 8.940373e-07 |
| time_elapsed            | 2397         |
| total timesteps         | 471900       |
| value_loss              | 3.425349e-06 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 8.257371e-05  |
| ent_coef_loss           | -10.932079    |
| entropy                 | 4.21461       |
| ep_rewmean              | -0.315        |
| episodes                | 4724          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 472201        |
| policy_loss             | 0.029522454   |
| qf1_loss                | 1.1697632e-06 |
| qf2_loss                | 1.5997427e-06 |
| time_elapsed            | 2399          |
| total timesteps         | 472300        |
| value_loss              | 2.470852e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 9.521013e-05  |
| ent_coef_loss           | 30.4687       |
| entropy                 | 2.721727      |
| ep_rewmean              | -0.306        |
| episodes                | 4728          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 472601        |
| policy_loss             | 0.033425234   |
| qf1_loss                | 9.817771e-07  |
| qf2_loss                | 1.2103542e-06 |
| time_elapsed            | 2401          |
| total timesteps         | 472700        |
| value_loss              | 4.905085e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00011924204 |
| ent_coef_loss           | 39.360947     |
| entropy                 | 2.3768196     |
| ep_rewmean              | -0.293        |
| episodes                | 4732          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 473001        |
| policy_loss             | 0.030883022   |
| qf1_loss                | 8.493569e-07  |
| qf2_loss                | 1.3810003e-06 |
| time_elapsed            | 2403          |
| total timesteps         | 473100        |
| value_loss              | 5.0767294e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00013948214 |
| ent_coef_loss           | 26.70691      |
| entropy                 | 3.3969715     |
| ep_rewmean              | -0.286        |
| episodes                | 4736          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 473401        |
| policy_loss             | 0.040887475   |
| qf1_loss                | 1.3978414e-06 |
| qf2_loss                | 1.8520952e-06 |
| time_elapsed            | 2405          |
| total timesteps         | 473500        |
| value_loss              | 3.1731802e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00016018907 |
| ent_coef_loss           | 23.068407     |
| entropy                 | 3.1979837     |
| ep_rewmean              | -0.28         |
| episodes                | 4740          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 473801        |
| policy_loss             | 0.047043722   |
| qf1_loss                | 1.8214308e-06 |
| qf2_loss                | 1.3585383e-06 |
| time_elapsed            | 2407          |
| total timesteps         | 473900        |
| value_loss              | 5.608129e-06  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0001797761   |
| ent_coef_loss           | 21.100315      |
| entropy                 | 3.4290247      |
| ep_rewmean              | -0.276         |
| episodes                | 4744           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.3           |
| n_updates               | 474201         |
| policy_loss             | 0.047911055    |
| qf1_loss                | 1.4482443e-05  |
| qf2_loss                | 1.46362345e-05 |
| time_elapsed            | 2409           |
| total timesteps         | 474300         |
| value_loss              | 2.491873e-06   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00019941689 |
| ent_coef_loss           | 24.051653     |
| entropy                 | 3.5661387     |
| ep_rewmean              | -0.271        |
| episodes                | 4748          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 474601        |
| policy_loss             | 0.057003707   |
| qf1_loss                | 7.414269e-05  |
| qf2_loss                | 8.186652e-05  |
| time_elapsed            | 2411          |
| total timesteps         | 474700        |
| value_loss              | 3.908577e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00021994994 |
| ent_coef_loss           | 14.6456585    |
| entropy                 | 4.171078      |
| ep_rewmean              | -0.273        |
| episodes                | 4752          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 475001        |
| policy_loss             | 0.06915252    |
| qf1_loss                | 2.596533e-05  |
| qf2_loss                | 2.6479172e-05 |
| time_elapsed            | 2413          |
| total timesteps         | 475100        |
| value_loss              | 6.1212586e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00023907992 |
| ent_coef_loss           | 4.5024505     |
| entropy                 | 4.553902      |
| ep_rewmean              | -0.277        |
| episodes                | 4756          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 475401        |
| policy_loss             | 0.08359015    |
| qf1_loss                | 1.9869049e-06 |
| qf2_loss                | 2.1503542e-06 |
| time_elapsed            | 2415          |
| total timesteps         | 475500        |
| value_loss              | 7.110686e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00024392907 |
| ent_coef_loss           | -2.7448945    |
| entropy                 | 4.171732      |
| ep_rewmean              | -0.279        |
| episodes                | 4760          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 475801        |
| policy_loss             | 0.07100342    |
| qf1_loss                | 0.00010815121 |
| qf2_loss                | 0.00010156064 |
| time_elapsed            | 2417          |
| total timesteps         | 475900        |
| value_loss              | 3.0677572e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00024255486 |
| ent_coef_loss           | -3.839872     |
| entropy                 | 3.9399147     |
| ep_rewmean              | -0.285        |
| episodes                | 4764          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 476201        |
| policy_loss             | 0.09157421    |
| qf1_loss                | 4.2490124e-06 |
| qf2_loss                | 4.2388738e-06 |
| time_elapsed            | 2419          |
| total timesteps         | 476300        |
| value_loss              | 1.6880796e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00022684038 |
| ent_coef_loss           | -15.654371    |
| entropy                 | 3.904448      |
| ep_rewmean              | -0.294        |
| episodes                | 4768          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 476601        |
| policy_loss             | 0.07735717    |
| qf1_loss                | 2.007529e-06  |
| qf2_loss                | 3.2472635e-06 |
| time_elapsed            | 2421          |
| total timesteps         | 476700        |
| value_loss              | 3.7321424e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00020225342 |
| ent_coef_loss           | -15.638519    |
| entropy                 | 4.092842      |
| ep_rewmean              | -0.303        |
| episodes                | 4772          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 477001        |
| policy_loss             | 0.08607324    |
| qf1_loss                | 1.819051e-06  |
| qf2_loss                | 1.7905454e-06 |
| time_elapsed            | 2423          |
| total timesteps         | 477100        |
| value_loss              | 6.374361e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00018071775 |
| ent_coef_loss           | -6.6757355    |
| entropy                 | 4.52334       |
| ep_rewmean              | -0.31         |
| episodes                | 4776          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 477401        |
| policy_loss             | 0.0795274     |
| qf1_loss                | 1.3229549e-06 |
| qf2_loss                | 1.8800575e-06 |
| time_elapsed            | 2425          |
| total timesteps         | 477500        |
| value_loss              | 2.3252612e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00016079027 |
| ent_coef_loss           | -21.1214      |
| entropy                 | 4.794718      |
| ep_rewmean              | -0.317        |
| episodes                | 4780          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 477801        |
| policy_loss             | 0.078813806   |
| qf1_loss                | 3.3054344e-05 |
| qf2_loss                | 3.21723e-05   |
| time_elapsed            | 2427          |
| total timesteps         | 477900        |
| value_loss              | 5.1037923e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00014106576 |
| ent_coef_loss           | -22.760506    |
| entropy                 | 4.54496       |
| ep_rewmean              | -0.322        |
| episodes                | 4784          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 478201        |
| policy_loss             | 0.086386144   |
| qf1_loss                | 4.0618783e-05 |
| qf2_loss                | 4.146689e-05  |
| time_elapsed            | 2429          |
| total timesteps         | 478300        |
| value_loss              | 2.4500937e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00014033997 |
| ent_coef_loss           | -12.928073    |
| entropy                 | 3.7882237     |
| ep_rewmean              | -0.354        |
| episodes                | 4788          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 478601        |
| policy_loss             | 0.08915813    |
| qf1_loss                | 1.8465041e-06 |
| qf2_loss                | 2.6354614e-06 |
| time_elapsed            | 2431          |
| total timesteps         | 478700        |
| value_loss              | 1.6910093e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0001367667  |
| ent_coef_loss           | 5.5999365     |
| entropy                 | 3.1251671     |
| ep_rewmean              | -0.37         |
| episodes                | 4792          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 479001        |
| policy_loss             | 0.08890137    |
| qf1_loss                | 1.2959656e-06 |
| qf2_loss                | 1.1756237e-06 |
| time_elapsed            | 2433          |
| total timesteps         | 479100        |
| value_loss              | 1.8480218e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00013843893 |
| ent_coef_loss           | -0.80627155   |
| entropy                 | 3.136697      |
| ep_rewmean              | -0.381        |
| episodes                | 4796          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 479401        |
| policy_loss             | 0.08320994    |
| qf1_loss                | 2.2771876e-06 |
| qf2_loss                | 4.144384e-06  |
| time_elapsed            | 2435          |
| total timesteps         | 479500        |
| value_loss              | 2.9028495e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00013833217 |
| ent_coef_loss           | -8.584993     |
| entropy                 | 3.103778      |
| ep_rewmean              | -0.391        |
| episodes                | 4800          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 479801        |
| policy_loss             | 0.093960404   |
| qf1_loss                | 4.077406e-06  |
| qf2_loss                | 2.6775606e-06 |
| time_elapsed            | 2437          |
| total timesteps         | 479900        |
| value_loss              | 4.51293e-06   |
-------------------------------------------
Eval num_timesteps=480000, episode_reward=-0.74 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00014178369 |
| ent_coef_loss           | -11.583486    |
| entropy                 | 3.370937      |
| ep_rewmean              | -0.426        |
| episodes                | 4804          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 480201        |
| policy_loss             | 0.08310217    |
| qf1_loss                | 8.510146e-05  |
| qf2_loss                | 3.622163e-05  |
| time_elapsed            | 2439          |
| total timesteps         | 480300        |
| value_loss              | 2.1184178e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00014780773 |
| ent_coef_loss           | 6.271362      |
| entropy                 | 2.533351      |
| ep_rewmean              | -0.432        |
| episodes                | 4808          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 480601        |
| policy_loss             | 0.102613695   |
| qf1_loss                | 2.2825466e-06 |
| qf2_loss                | 3.207358e-06  |
| time_elapsed            | 2441          |
| total timesteps         | 480700        |
| value_loss              | 4.6409114e-06 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00015272074  |
| ent_coef_loss           | 7.5766106      |
| entropy                 | 2.8803718      |
| ep_rewmean              | -0.443         |
| episodes                | 4812           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.4           |
| n_updates               | 481001         |
| policy_loss             | 0.092298165    |
| qf1_loss                | 3.704041e-06   |
| qf2_loss                | 3.262315e-06   |
| time_elapsed            | 2443           |
| total timesteps         | 481100         |
| value_loss              | 1.27959065e-05 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00016233628 |
| ent_coef_loss           | 11.443522     |
| entropy                 | 3.6912622     |
| ep_rewmean              | -0.456        |
| episodes                | 4816          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 481401        |
| policy_loss             | 0.09546575    |
| qf1_loss                | 3.280014e-06  |
| qf2_loss                | 3.8414155e-06 |
| time_elapsed            | 2445          |
| total timesteps         | 481500        |
| value_loss              | 1.6414335e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00017314326 |
| ent_coef_loss           | -4.6213145    |
| entropy                 | 3.3178859     |
| ep_rewmean              | -0.495        |
| episodes                | 4820          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 481801        |
| policy_loss             | 0.09974899    |
| qf1_loss                | 2.6935746e-05 |
| qf2_loss                | 2.520929e-05  |
| time_elapsed            | 2447          |
| total timesteps         | 481900        |
| value_loss              | 4.6741516e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00018020043 |
| ent_coef_loss           | -7.653017     |
| entropy                 | 3.0692859     |
| ep_rewmean              | -0.54         |
| episodes                | 4824          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 482201        |
| policy_loss             | 0.09404358    |
| qf1_loss                | 1.0858296e-05 |
| qf2_loss                | 1.2673678e-05 |
| time_elapsed            | 2449          |
| total timesteps         | 482300        |
| value_loss              | 6.9914613e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000183668   |
| ent_coef_loss           | -10.445464    |
| entropy                 | 3.0522456     |
| ep_rewmean              | -0.659        |
| episodes                | 4828          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 482601        |
| policy_loss             | 0.0892006     |
| qf1_loss                | 1.2076744e-05 |
| qf2_loss                | 1.4549519e-05 |
| time_elapsed            | 2452          |
| total timesteps         | 482700        |
| value_loss              | 9.787418e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00018517439 |
| ent_coef_loss           | 2.8595006     |
| entropy                 | 3.26688       |
| ep_rewmean              | -0.718        |
| episodes                | 4832          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 483001        |
| policy_loss             | 0.0989701     |
| qf1_loss                | 0.0003620486  |
| qf2_loss                | 0.0003757605  |
| time_elapsed            | 2454          |
| total timesteps         | 483100        |
| value_loss              | 1.2941345e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00018792138 |
| ent_coef_loss           | -5.2792115    |
| entropy                 | 2.559978      |
| ep_rewmean              | -0.782        |
| episodes                | 4836          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 483401        |
| policy_loss             | 0.103593536   |
| qf1_loss                | 9.586074e-06  |
| qf2_loss                | 8.600483e-06  |
| time_elapsed            | 2456          |
| total timesteps         | 483500        |
| value_loss              | 6.11844e-06   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00019012911 |
| ent_coef_loss           | 17.676512     |
| entropy                 | 3.0364592     |
| ep_rewmean              | -0.799        |
| episodes                | 4840          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 483801        |
| policy_loss             | 0.09224801    |
| qf1_loss                | 6.2754107e-06 |
| qf2_loss                | 1.1455973e-05 |
| time_elapsed            | 2458          |
| total timesteps         | 483900        |
| value_loss              | 5.1185852e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00019775578 |
| ent_coef_loss           | 11.28915      |
| entropy                 | 3.3921988     |
| ep_rewmean              | -0.808        |
| episodes                | 4844          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 484201        |
| policy_loss             | 0.11686835    |
| qf1_loss                | 8.663447e-06  |
| qf2_loss                | 8.729776e-06  |
| time_elapsed            | 2460          |
| total timesteps         | 484300        |
| value_loss              | 8.768448e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00019633383 |
| ent_coef_loss           | -7.748802     |
| entropy                 | 3.7620034     |
| ep_rewmean              | -0.815        |
| episodes                | 4848          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 484601        |
| policy_loss             | 0.07549542    |
| qf1_loss                | 6.0238985e-05 |
| qf2_loss                | 6.1485174e-05 |
| time_elapsed            | 2462          |
| total timesteps         | 484700        |
| value_loss              | 1.357737e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0001893653  |
| ent_coef_loss           | -7.546259     |
| entropy                 | 3.8129077     |
| ep_rewmean              | -0.818        |
| episodes                | 4852          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 485001        |
| policy_loss             | 0.09073721    |
| qf1_loss                | 4.9349583e-06 |
| qf2_loss                | 5.5827586e-06 |
| time_elapsed            | 2464          |
| total timesteps         | 485100        |
| value_loss              | 7.5427797e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000179309   |
| ent_coef_loss           | -7.2899       |
| entropy                 | 3.7690363     |
| ep_rewmean              | -0.819        |
| episodes                | 4856          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 485401        |
| policy_loss             | 0.083746046   |
| qf1_loss                | 7.5902817e-06 |
| qf2_loss                | 7.2786806e-06 |
| time_elapsed            | 2466          |
| total timesteps         | 485500        |
| value_loss              | 6.4937985e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00016738384 |
| ent_coef_loss           | -10.089585    |
| entropy                 | 3.7529573     |
| ep_rewmean              | -0.825        |
| episodes                | 4860          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 485801        |
| policy_loss             | 0.06732913    |
| qf1_loss                | 4.10594e-05   |
| qf2_loss                | 4.506408e-05  |
| time_elapsed            | 2468          |
| total timesteps         | 485900        |
| value_loss              | 1.0398768e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00017445082 |
| ent_coef_loss           | 14.139364     |
| entropy                 | 4.0278406     |
| ep_rewmean              | -0.824        |
| episodes                | 4864          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 486201        |
| policy_loss             | 0.11290759    |
| qf1_loss                | 1.2799422e-05 |
| qf2_loss                | 6.8367804e-06 |
| time_elapsed            | 2470          |
| total timesteps         | 486300        |
| value_loss              | 1.0927808e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00016826668 |
| ent_coef_loss           | -1.6056018    |
| entropy                 | 3.9027479     |
| ep_rewmean              | -0.822        |
| episodes                | 4868          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 486601        |
| policy_loss             | 0.08131477    |
| qf1_loss                | 9.179752e-06  |
| qf2_loss                | 9.814176e-06  |
| time_elapsed            | 2472          |
| total timesteps         | 486700        |
| value_loss              | 2.0814914e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00016341629  |
| ent_coef_loss           | 8.658604       |
| entropy                 | 3.359577       |
| ep_rewmean              | -0.817         |
| episodes                | 4872           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.8           |
| n_updates               | 487001         |
| policy_loss             | 0.08551413     |
| qf1_loss                | 8.9232926e-05  |
| qf2_loss                | 8.024702e-05   |
| time_elapsed            | 2474           |
| total timesteps         | 487100         |
| value_loss              | 0.000102069025 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00015833066 |
| ent_coef_loss           | -6.7659707    |
| entropy                 | 3.9769406     |
| ep_rewmean              | -0.817        |
| episodes                | 4876          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 487401        |
| policy_loss             | 0.07663415    |
| qf1_loss                | 3.9491624e-06 |
| qf2_loss                | 2.440046e-06  |
| time_elapsed            | 2476          |
| total timesteps         | 487500        |
| value_loss              | 3.6551467e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00015043133 |
| ent_coef_loss           | 5.8622346     |
| entropy                 | 3.6670506     |
| ep_rewmean              | -0.815        |
| episodes                | 4880          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 487801        |
| policy_loss             | 0.09754482    |
| qf1_loss                | 7.102436e-06  |
| qf2_loss                | 5.1218376e-06 |
| time_elapsed            | 2478          |
| total timesteps         | 487900        |
| value_loss              | 8.226129e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00014918126 |
| ent_coef_loss           | 12.706138     |
| entropy                 | 3.638702      |
| ep_rewmean              | -0.812        |
| episodes                | 4884          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 488201        |
| policy_loss             | 0.07654271    |
| qf1_loss                | 5.908676e-06  |
| qf2_loss                | 6.375941e-06  |
| time_elapsed            | 2480          |
| total timesteps         | 488300        |
| value_loss              | 8.370751e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00014523156 |
| ent_coef_loss           | 11.448841     |
| entropy                 | 3.5726013     |
| ep_rewmean              | -0.783        |
| episodes                | 4888          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 488601        |
| policy_loss             | 0.10306649    |
| qf1_loss                | 1.0162127e-05 |
| qf2_loss                | 9.428888e-06  |
| time_elapsed            | 2482          |
| total timesteps         | 488700        |
| value_loss              | 5.5086434e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00013611818 |
| ent_coef_loss           | -9.915998     |
| entropy                 | 3.3969417     |
| ep_rewmean              | -0.769        |
| episodes                | 4892          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 489001        |
| policy_loss             | 0.085647784   |
| qf1_loss                | 7.751746e-06  |
| qf2_loss                | 7.6925335e-06 |
| time_elapsed            | 2484          |
| total timesteps         | 489100        |
| value_loss              | 5.174272e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00012887902 |
| ent_coef_loss           | -5.577337     |
| entropy                 | 3.510701      |
| ep_rewmean              | -0.759        |
| episodes                | 4896          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.8          |
| n_updates               | 489401        |
| policy_loss             | 0.064063966   |
| qf1_loss                | 3.193835e-06  |
| qf2_loss                | 2.975881e-06  |
| time_elapsed            | 2486          |
| total timesteps         | 489500        |
| value_loss              | 5.2420883e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00011928094 |
| ent_coef_loss           | -8.02641      |
| entropy                 | 3.2347033     |
| ep_rewmean              | -0.749        |
| episodes                | 4900          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 489801        |
| policy_loss             | 0.082288034   |
| qf1_loss                | 3.6825684e-05 |
| qf2_loss                | 2.8488046e-05 |
| time_elapsed            | 2488          |
| total timesteps         | 489900        |
| value_loss              | 1.2342476e-05 |
-------------------------------------------
Eval num_timesteps=490000, episode_reward=-0.27 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00011301179 |
| ent_coef_loss           | -14.552374    |
| entropy                 | 3.1300468     |
| ep_rewmean              | -0.715        |
| episodes                | 4904          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 490201        |
| policy_loss             | 0.08501586    |
| qf1_loss                | 7.2562575e-06 |
| qf2_loss                | 7.3370925e-06 |
| time_elapsed            | 2490          |
| total timesteps         | 490300        |
| value_loss              | 5.0179824e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010742981 |
| ent_coef_loss           | -3.386499     |
| entropy                 | 3.1102173     |
| ep_rewmean              | -0.705        |
| episodes                | 4908          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 490601        |
| policy_loss             | 0.07368833    |
| qf1_loss                | 8.288703e-05  |
| qf2_loss                | 7.904362e-05  |
| time_elapsed            | 2492          |
| total timesteps         | 490700        |
| value_loss              | 5.5474275e-06 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.000102793165 |
| ent_coef_loss           | -10.336968     |
| entropy                 | 3.5288773      |
| ep_rewmean              | -0.694         |
| episodes                | 4912           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.7           |
| n_updates               | 491001         |
| policy_loss             | 0.06360146     |
| qf1_loss                | 4.8751812e-05  |
| qf2_loss                | 4.877205e-05   |
| time_elapsed            | 2494           |
| total timesteps         | 491100         |
| value_loss              | 3.6151569e-06  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0001019975  |
| ent_coef_loss           | -2.8219895    |
| entropy                 | 3.4713845     |
| ep_rewmean              | -0.681        |
| episodes                | 4916          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.7          |
| n_updates               | 491401        |
| policy_loss             | 0.07319644    |
| qf1_loss                | 3.951073e-06  |
| qf2_loss                | 4.4358694e-06 |
| time_elapsed            | 2496          |
| total timesteps         | 491500        |
| value_loss              | 3.2530506e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010345454 |
| ent_coef_loss           | -4.900113     |
| entropy                 | 3.9028819     |
| ep_rewmean              | -0.642        |
| episodes                | 4920          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 491801        |
| policy_loss             | 0.056958452   |
| qf1_loss                | 2.1908982e-06 |
| qf2_loss                | 2.7382862e-06 |
| time_elapsed            | 2498          |
| total timesteps         | 491900        |
| value_loss              | 4.582848e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010204644 |
| ent_coef_loss           | -14.696447    |
| entropy                 | 3.273166      |
| ep_rewmean              | -0.597        |
| episodes                | 4924          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.6          |
| n_updates               | 492201        |
| policy_loss             | 0.073635496   |
| qf1_loss                | 2.8623863e-06 |
| qf2_loss                | 2.9099454e-06 |
| time_elapsed            | 2500          |
| total timesteps         | 492300        |
| value_loss              | 5.6230347e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 9.654333e-05  |
| ent_coef_loss           | -4.122303     |
| entropy                 | 3.2566478     |
| ep_rewmean              | -0.477        |
| episodes                | 4928          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.5          |
| n_updates               | 492601        |
| policy_loss             | 0.060856953   |
| qf1_loss                | 5.566335e-06  |
| qf2_loss                | 4.8239854e-06 |
| time_elapsed            | 2502          |
| total timesteps         | 492700        |
| value_loss              | 1.7918868e-06 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 9.150743e-05 |
| ent_coef_loss           | -6.10345     |
| entropy                 | 3.3639638    |
| ep_rewmean              | -0.416       |
| episodes                | 4932         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -0.4         |
| n_updates               | 493001       |
| policy_loss             | 0.06276664   |
| qf1_loss                | 5.382563e-06 |
| qf2_loss                | 7.512931e-06 |
| time_elapsed            | 2504         |
| total timesteps         | 493100       |
| value_loss              | 4.170379e-06 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 8.908011e-05  |
| ent_coef_loss           | -1.4477658    |
| entropy                 | 2.886248      |
| ep_rewmean              | -0.35         |
| episodes                | 4936          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.4          |
| n_updates               | 493401        |
| policy_loss             | 0.060484737   |
| qf1_loss                | 8.919152e-06  |
| qf2_loss                | 8.1695025e-06 |
| time_elapsed            | 2506          |
| total timesteps         | 493500        |
| value_loss              | 5.642647e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 8.979162e-05  |
| ent_coef_loss           | 1.8713741     |
| entropy                 | 3.087606      |
| ep_rewmean              | -0.329        |
| episodes                | 4940          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 493801        |
| policy_loss             | 0.062157884   |
| qf1_loss                | 1.8402834e-05 |
| qf2_loss                | 1.1972876e-05 |
| time_elapsed            | 2508          |
| total timesteps         | 493900        |
| value_loss              | 5.745601e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 9.9713056e-05 |
| ent_coef_loss           | 9.5951185     |
| entropy                 | 3.304753      |
| ep_rewmean              | -0.316        |
| episodes                | 4944          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 494201        |
| policy_loss             | 0.060442436   |
| qf1_loss                | 4.452444e-06  |
| qf2_loss                | 4.6626624e-06 |
| time_elapsed            | 2510          |
| total timesteps         | 494300        |
| value_loss              | 1.4705089e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010734327 |
| ent_coef_loss           | 2.0101147     |
| entropy                 | 3.1733806     |
| ep_rewmean              | -0.305        |
| episodes                | 4948          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 494601        |
| policy_loss             | 0.07897076    |
| qf1_loss                | 3.015806e-05  |
| qf2_loss                | 2.3202878e-05 |
| time_elapsed            | 2512          |
| total timesteps         | 494700        |
| value_loss              | 9.616698e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010435886 |
| ent_coef_loss           | -4.916016     |
| entropy                 | 4.000051      |
| ep_rewmean              | -0.293        |
| episodes                | 4952          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 495001        |
| policy_loss             | 0.07748354    |
| qf1_loss                | 1.8618814e-06 |
| qf2_loss                | 1.6241145e-06 |
| time_elapsed            | 2514          |
| total timesteps         | 495100        |
| value_loss              | 2.5208792e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 9.864116e-05  |
| ent_coef_loss           | 4.661337      |
| entropy                 | 3.6792896     |
| ep_rewmean              | -0.284        |
| episodes                | 4956          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 495401        |
| policy_loss             | 0.06848993    |
| qf1_loss                | 7.799028e-06  |
| qf2_loss                | 8.539479e-06  |
| time_elapsed            | 2516          |
| total timesteps         | 495500        |
| value_loss              | 1.2069895e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00010498515 |
| ent_coef_loss           | -7.7577257    |
| entropy                 | 4.1344376     |
| ep_rewmean              | -0.271        |
| episodes                | 4960          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 495801        |
| policy_loss             | 0.067529395   |
| qf1_loss                | 9.813553e-06  |
| qf2_loss                | 1.2455991e-05 |
| time_elapsed            | 2518          |
| total timesteps         | 495900        |
| value_loss              | 8.271005e-06  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0001086287 |
| ent_coef_loss           | -13.775416   |
| entropy                 | 3.8976517    |
| ep_rewmean              | -0.263       |
| episodes                | 4964         |
| eplenmean               | 100          |
| fps                     | 196          |
| mean 100 episode reward | -0.3         |
| n_updates               | 496201       |
| policy_loss             | 0.06624143   |
| qf1_loss                | 3.701829e-06 |
| qf2_loss                | 5.936815e-06 |
| time_elapsed            | 2520         |
| total timesteps         | 496300       |
| value_loss              | 4.660992e-06 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00011651414 |
| ent_coef_loss           | -2.2670636    |
| entropy                 | 3.9790645     |
| ep_rewmean              | -0.257        |
| episodes                | 4968          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 496601        |
| policy_loss             | 0.08029635    |
| qf1_loss                | 4.310351e-06  |
| qf2_loss                | 4.008022e-06  |
| time_elapsed            | 2522          |
| total timesteps         | 496700        |
| value_loss              | 4.356741e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00012102261 |
| ent_coef_loss           | -8.8920965    |
| entropy                 | 4.162779      |
| ep_rewmean              | -0.255        |
| episodes                | 4972          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.3          |
| n_updates               | 497001        |
| policy_loss             | 0.072334826   |
| qf1_loss                | 3.1500713e-06 |
| qf2_loss                | 3.766244e-06  |
| time_elapsed            | 2524          |
| total timesteps         | 497100        |
| value_loss              | 9.000692e-06  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00012377826 |
| ent_coef_loss           | 8.69058       |
| entropy                 | 4.4471817     |
| ep_rewmean              | -0.249        |
| episodes                | 4976          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.2          |
| n_updates               | 497401        |
| policy_loss             | 0.07830607    |
| qf1_loss                | 2.1082253e-06 |
| qf2_loss                | 2.1234735e-06 |
| time_elapsed            | 2526          |
| total timesteps         | 497500        |
| value_loss              | 1.9206618e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00011856191 |
| ent_coef_loss           | 5.171977      |
| entropy                 | 3.9900289     |
| ep_rewmean              | -0.246        |
| episodes                | 4980          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.2          |
| n_updates               | 497801        |
| policy_loss             | 0.082710266   |
| qf1_loss                | 6.0995026e-06 |
| qf2_loss                | 4.3045e-06    |
| time_elapsed            | 2528          |
| total timesteps         | 497900        |
| value_loss              | 3.1589566e-06 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.000114645845 |
| ent_coef_loss           | -20.100742     |
| entropy                 | 3.9879527      |
| ep_rewmean              | -0.244         |
| episodes                | 4984           |
| eplenmean               | 100            |
| fps                     | 196            |
| mean 100 episode reward | -0.2           |
| n_updates               | 498201         |
| policy_loss             | 0.072862074    |
| qf1_loss                | 7.462022e-06   |
| qf2_loss                | 5.848095e-06   |
| time_elapsed            | 2530           |
| total timesteps         | 498300         |
| value_loss              | 3.7566235e-06  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00011041915 |
| ent_coef_loss           | 5.409422      |
| entropy                 | 4.1730766     |
| ep_rewmean              | -0.242        |
| episodes                | 4988          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.2          |
| n_updates               | 498601        |
| policy_loss             | 0.07983963    |
| qf1_loss                | 3.605666e-06  |
| qf2_loss                | 5.317039e-06  |
| time_elapsed            | 2532          |
| total timesteps         | 498700        |
| value_loss              | 2.3267633e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00012618864 |
| ent_coef_loss           | 7.638405      |
| entropy                 | 4.101959      |
| ep_rewmean              | -0.243        |
| episodes                | 4992          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.2          |
| n_updates               | 499001        |
| policy_loss             | 0.08315245    |
| qf1_loss                | 5.1843354e-06 |
| qf2_loss                | 3.618633e-06  |
| time_elapsed            | 2534          |
| total timesteps         | 499100        |
| value_loss              | 5.6427752e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0001312402  |
| ent_coef_loss           | 8.144054      |
| entropy                 | 4.71329       |
| ep_rewmean              | -0.244        |
| episodes                | 4996          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.2          |
| n_updates               | 499401        |
| policy_loss             | 0.07648201    |
| qf1_loss                | 1.520574e-06  |
| qf2_loss                | 1.4011766e-06 |
| time_elapsed            | 2536          |
| total timesteps         | 499500        |
| value_loss              | 2.4565375e-06 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00011842258 |
| ent_coef_loss           | 1.4028759     |
| entropy                 | 3.9660935     |
| ep_rewmean              | -0.245        |
| episodes                | 5000          |
| eplenmean               | 100           |
| fps                     | 196           |
| mean 100 episode reward | -0.2          |
| n_updates               | 499801        |
| policy_loss             | 0.08433987    |
| qf1_loss                | 1.5767048e-06 |
| qf2_loss                | 1.5081097e-06 |
| time_elapsed            | 2538          |
| total timesteps         | 499900        |
| value_loss              | 3.066886e-06  |
-------------------------------------------
/ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/callbacks.py:285: UserWarning: Training and eval env are not of the same type<stable_baselines.common.base_class._UnvecWrapper object at 0x7f288578df60> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f288578dc50>
  "{} != {}".format(self.training_env, self.eval_env))
Eval num_timesteps=500000, episode_reward=-0.24 +/- 0.00
Episode length: 100.00 +/- 0.00
Saving to logs/train_0.5M_widowx_reacher-v5_KAY/sac/widowx_reacher-v5_2
pybullet build time: May 18 2020 02:46:26
