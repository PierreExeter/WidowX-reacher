--------------------------------------------------------------------------
WARNING: There was an error initializing an OpenFabrics device.

  Local host:   n295
  Local device: hfi1_0
--------------------------------------------------------------------------
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:141: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/sac/policies.py:194: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:232: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:294: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/sac/sac.py:314: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

========== widowx_reacher-v7 ==========
Seed: 1
OrderedDict([('n_timesteps', 60000.0),
             ('policy', 'MlpPolicy'),
             ('policy_kwargs', 'dict(layers=[256, 256])')])
Using 1 environments
Overwriting n_timesteps with n=500000
Creating test environment
TRAINING ENV TYPE :  <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f036da734a8>
EVAL ENV TYPE :  <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f036b3ddda0>
Log path: logs/train_0.5M_widowx_reacher-v7_KAY/sac/widowx_reacher-v7_2
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.9417401    |
| ent_coef_loss           | -0.60877734  |
| entropy                 | 7.6870604    |
| ep_rewmean              | -0.598       |
| episodes                | 4            |
| eplenmean               | 100          |
| fps                     | 190          |
| mean 100 episode reward | -0.6         |
| n_updates               | 201          |
| policy_loss             | -6.226984    |
| qf1_loss                | 0.0020322672 |
| qf2_loss                | 0.0019004373 |
| time_elapsed            | 1            |
| total timesteps         | 300          |
| value_loss              | 0.08344239   |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.8352383   |
| ent_coef_loss           | -1.8161385  |
| entropy                 | 7.719105    |
| ep_rewmean              | -1.62       |
| episodes                | 8           |
| eplenmean               | 100         |
| fps                     | 197         |
| mean 100 episode reward | -1.6        |
| n_updates               | 601         |
| policy_loss             | -11.621618  |
| qf1_loss                | 0.036073122 |
| qf2_loss                | 0.034789167 |
| time_elapsed            | 3           |
| total timesteps         | 700         |
| value_loss              | 0.16875961  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.7408158  |
| ent_coef_loss           | -3.019916  |
| entropy                 | 7.7092557  |
| ep_rewmean              | -1.27      |
| episodes                | 12         |
| eplenmean               | 100        |
| fps                     | 200        |
| mean 100 episode reward | -1.3       |
| n_updates               | 1001       |
| policy_loss             | -16.228407 |
| qf1_loss                | 1.7246306  |
| qf2_loss                | 1.7759194  |
| time_elapsed            | 5          |
| total timesteps         | 1100       |
| value_loss              | 0.07594265 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.6571463  |
| ent_coef_loss           | -4.2083764 |
| entropy                 | 7.8587704  |
| ep_rewmean              | -1.21      |
| episodes                | 16         |
| eplenmean               | 100        |
| fps                     | 201        |
| mean 100 episode reward | -1.2       |
| n_updates               | 1401       |
| policy_loss             | -20.467892 |
| qf1_loss                | 1.582967   |
| qf2_loss                | 1.7490582  |
| time_elapsed            | 7          |
| total timesteps         | 1500       |
| value_loss              | 0.7783709  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.5830904  |
| ent_coef_loss           | -5.423381  |
| entropy                 | 7.9755163  |
| ep_rewmean              | -1.27      |
| episodes                | 20         |
| eplenmean               | 100        |
| fps                     | 202        |
| mean 100 episode reward | -1.3       |
| n_updates               | 1801       |
| policy_loss             | -24.503033 |
| qf1_loss                | 5.8347335  |
| qf2_loss                | 6.123023   |
| time_elapsed            | 9          |
| total timesteps         | 1900       |
| value_loss              | 0.32050616 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.5174116  |
| ent_coef_loss           | -6.6052194 |
| entropy                 | 7.900589   |
| ep_rewmean              | -1.28      |
| episodes                | 24         |
| eplenmean               | 100        |
| fps                     | 202        |
| mean 100 episode reward | -1.3       |
| n_updates               | 2201       |
| policy_loss             | -27.02235  |
| qf1_loss                | 0.22095892 |
| qf2_loss                | 0.20413893 |
| time_elapsed            | 11         |
| total timesteps         | 2300       |
| value_loss              | 0.43402076 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.45918563 |
| ent_coef_loss           | -7.8991528 |
| entropy                 | 7.6643515  |
| ep_rewmean              | -1.25      |
| episodes                | 28         |
| eplenmean               | 100        |
| fps                     | 202        |
| mean 100 episode reward | -1.3       |
| n_updates               | 2601       |
| policy_loss             | -29.911976 |
| qf1_loss                | 7.178059   |
| qf2_loss                | 6.9541187  |
| time_elapsed            | 13         |
| total timesteps         | 2700       |
| value_loss              | 0.588302   |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.40750447 |
| ent_coef_loss           | -8.923168  |
| entropy                 | 7.5596128  |
| ep_rewmean              | -1.24      |
| episodes                | 32         |
| eplenmean               | 100        |
| fps                     | 202        |
| mean 100 episode reward | -1.2       |
| n_updates               | 3001       |
| policy_loss             | -31.832691 |
| qf1_loss                | 8.103851   |
| qf2_loss                | 7.9763203  |
| time_elapsed            | 15         |
| total timesteps         | 3100       |
| value_loss              | 0.285063   |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.36174735 |
| ent_coef_loss           | -9.949398  |
| entropy                 | 7.628525   |
| ep_rewmean              | -1.23      |
| episodes                | 36         |
| eplenmean               | 100        |
| fps                     | 202        |
| mean 100 episode reward | -1.2       |
| n_updates               | 3401       |
| policy_loss             | -33.38971  |
| qf1_loss                | 3.6222246  |
| qf2_loss                | 4.5826263  |
| time_elapsed            | 17         |
| total timesteps         | 3500       |
| value_loss              | 0.19143222 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.3212311  |
| ent_coef_loss           | -11.130533 |
| entropy                 | 7.3795996  |
| ep_rewmean              | -1.24      |
| episodes                | 40         |
| eplenmean               | 100        |
| fps                     | 202        |
| mean 100 episode reward | -1.2       |
| n_updates               | 3801       |
| policy_loss             | -34.924294 |
| qf1_loss                | 4.938576   |
| qf2_loss                | 6.677843   |
| time_elapsed            | 19         |
| total timesteps         | 3900       |
| value_loss              | 0.39832222 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.28522974  |
| ent_coef_loss           | -12.3609295 |
| entropy                 | 7.513935    |
| ep_rewmean              | -1.28       |
| episodes                | 44          |
| eplenmean               | 100         |
| fps                     | 202         |
| mean 100 episode reward | -1.3        |
| n_updates               | 4201        |
| policy_loss             | -34.966553  |
| qf1_loss                | 1.5157403   |
| qf2_loss                | 3.1028874   |
| time_elapsed            | 21          |
| total timesteps         | 4300        |
| value_loss              | 0.41720825  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.2535837  |
| ent_coef_loss           | -12.708189 |
| entropy                 | 7.1739845  |
| ep_rewmean              | -1.29      |
| episodes                | 48         |
| eplenmean               | 100        |
| fps                     | 202        |
| mean 100 episode reward | -1.3       |
| n_updates               | 4601       |
| policy_loss             | -35.432587 |
| qf1_loss                | 5.227462   |
| qf2_loss                | 3.1578758  |
| time_elapsed            | 23         |
| total timesteps         | 4700       |
| value_loss              | 0.26456136 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.22652353 |
| ent_coef_loss           | -13.951545 |
| entropy                 | 6.875362   |
| ep_rewmean              | -1.37      |
| episodes                | 52         |
| eplenmean               | 100        |
| fps                     | 203        |
| mean 100 episode reward | -1.4       |
| n_updates               | 5001       |
| policy_loss             | -35.379116 |
| qf1_loss                | 10.551819  |
| qf2_loss                | 10.376422  |
| time_elapsed            | 25         |
| total timesteps         | 5100       |
| value_loss              | 1.4423476  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.20246775 |
| ent_coef_loss           | -14.325064 |
| entropy                 | 6.9024086  |
| ep_rewmean              | -1.46      |
| episodes                | 56         |
| eplenmean               | 100        |
| fps                     | 203        |
| mean 100 episode reward | -1.5       |
| n_updates               | 5401       |
| policy_loss             | -36.4358   |
| qf1_loss                | 0.3203933  |
| qf2_loss                | 0.3037435  |
| time_elapsed            | 27         |
| total timesteps         | 5500       |
| value_loss              | 1.095341   |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.18153183 |
| ent_coef_loss           | -14.570576 |
| entropy                 | 6.6486125  |
| ep_rewmean              | -1.45      |
| episodes                | 60         |
| eplenmean               | 100        |
| fps                     | 203        |
| mean 100 episode reward | -1.4       |
| n_updates               | 5801       |
| policy_loss             | -35.9394   |
| qf1_loss                | 0.19321379 |
| qf2_loss                | 0.24614367 |
| time_elapsed            | 29         |
| total timesteps         | 5900       |
| value_loss              | 0.6468122  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.16341612 |
| ent_coef_loss           | -14.311712 |
| entropy                 | 6.139111   |
| ep_rewmean              | -1.6       |
| episodes                | 64         |
| eplenmean               | 100        |
| fps                     | 203        |
| mean 100 episode reward | -1.6       |
| n_updates               | 6201       |
| policy_loss             | -34.901154 |
| qf1_loss                | 1.1218618  |
| qf2_loss                | 1.0873249  |
| time_elapsed            | 30         |
| total timesteps         | 6300       |
| value_loss              | 0.6237252  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.14640802 |
| ent_coef_loss           | -13.482626 |
| entropy                 | 5.8505754  |
| ep_rewmean              | -1.63      |
| episodes                | 68         |
| eplenmean               | 100        |
| fps                     | 203        |
| mean 100 episode reward | -1.6       |
| n_updates               | 6601       |
| policy_loss             | -35.522717 |
| qf1_loss                | 0.34899706 |
| qf2_loss                | 0.33719766 |
| time_elapsed            | 32         |
| total timesteps         | 6700       |
| value_loss              | 0.2991616  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.13084754 |
| ent_coef_loss           | -13.875238 |
| entropy                 | 6.3028207  |
| ep_rewmean              | -1.66      |
| episodes                | 72         |
| eplenmean               | 100        |
| fps                     | 204        |
| mean 100 episode reward | -1.7       |
| n_updates               | 7001       |
| policy_loss             | -35.2085   |
| qf1_loss                | 0.4261523  |
| qf2_loss                | 0.39910913 |
| time_elapsed            | 34         |
| total timesteps         | 7100       |
| value_loss              | 0.33558384 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.11704415 |
| ent_coef_loss           | -15.459478 |
| entropy                 | 5.2905483  |
| ep_rewmean              | -1.68      |
| episodes                | 76         |
| eplenmean               | 100        |
| fps                     | 204        |
| mean 100 episode reward | -1.7       |
| n_updates               | 7401       |
| policy_loss             | -33.996014 |
| qf1_loss                | 10.274445  |
| qf2_loss                | 10.777326  |
| time_elapsed            | 36         |
| total timesteps         | 7500       |
| value_loss              | 0.24021241 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.10914554 |
| ent_coef_loss           | -5.899801  |
| entropy                 | 2.8899114  |
| ep_rewmean              | -1.71      |
| episodes                | 80         |
| eplenmean               | 100        |
| fps                     | 204        |
| mean 100 episode reward | -1.7       |
| n_updates               | 7801       |
| policy_loss             | -34.133095 |
| qf1_loss                | 10.390666  |
| qf2_loss                | 10.69313   |
| time_elapsed            | 38         |
| total timesteps         | 7900       |
| value_loss              | 0.21633501 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.103893116 |
| ent_coef_loss           | -9.361397   |
| entropy                 | 4.7036695   |
| ep_rewmean              | -1.71       |
| episodes                | 84          |
| eplenmean               | 100         |
| fps                     | 204         |
| mean 100 episode reward | -1.7        |
| n_updates               | 8201        |
| policy_loss             | -32.545036  |
| qf1_loss                | 0.2097838   |
| qf2_loss                | 0.24247831  |
| time_elapsed            | 40          |
| total timesteps         | 8300        |
| value_loss              | 0.20543565  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.09626587 |
| ent_coef_loss           | -9.806566  |
| entropy                 | 3.924169   |
| ep_rewmean              | -1.69      |
| episodes                | 88         |
| eplenmean               | 100        |
| fps                     | 205        |
| mean 100 episode reward | -1.7       |
| n_updates               | 8601       |
| policy_loss             | -31.927975 |
| qf1_loss                | 0.21485761 |
| qf2_loss                | 0.31047946 |
| time_elapsed            | 42         |
| total timesteps         | 8700       |
| value_loss              | 0.17070782 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.08843257 |
| ent_coef_loss           | -8.118771  |
| entropy                 | 2.5841956  |
| ep_rewmean              | -1.72      |
| episodes                | 92         |
| eplenmean               | 100        |
| fps                     | 205        |
| mean 100 episode reward | -1.7       |
| n_updates               | 9001       |
| policy_loss             | -32.099125 |
| qf1_loss                | 0.17660217 |
| qf2_loss                | 0.17671174 |
| time_elapsed            | 44         |
| total timesteps         | 9100       |
| value_loss              | 0.24028057 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.082155384 |
| ent_coef_loss           | -4.556412   |
| entropy                 | 3.3805203   |
| ep_rewmean              | -1.78       |
| episodes                | 96          |
| eplenmean               | 100         |
| fps                     | 205         |
| mean 100 episode reward | -1.8        |
| n_updates               | 9401        |
| policy_loss             | -31.427832  |
| qf1_loss                | 0.20527896  |
| qf2_loss                | 0.18891673  |
| time_elapsed            | 46          |
| total timesteps         | 9500        |
| value_loss              | 0.2301445   |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.07674775 |
| ent_coef_loss           | -7.70829   |
| entropy                 | 2.4430518  |
| ep_rewmean              | -1.8       |
| episodes                | 100        |
| eplenmean               | 100        |
| fps                     | 205        |
| mean 100 episode reward | -1.8       |
| n_updates               | 9801       |
| policy_loss             | -30.276752 |
| qf1_loss                | 5.955961   |
| qf2_loss                | 6.048959   |
| time_elapsed            | 48         |
| total timesteps         | 9900       |
| value_loss              | 0.20635955 |
----------------------------------------
Eval num_timesteps=10000, episode_reward=-1.07 +/- 0.69
Episode length: 100.00 +/- 0.00
New best mean reward!
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.07115754 |
| ent_coef_loss           | -6.0913386 |
| entropy                 | 2.3339815  |
| ep_rewmean              | -1.82      |
| episodes                | 104        |
| eplenmean               | 100        |
| fps                     | 204        |
| mean 100 episode reward | -1.8       |
| n_updates               | 10201      |
| policy_loss             | -30.169226 |
| qf1_loss                | 0.47958302 |
| qf2_loss                | 0.50437504 |
| time_elapsed            | 50         |
| total timesteps         | 10300      |
| value_loss              | 0.1703473  |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.06550167 |
| ent_coef_loss           | -2.4137406 |
| entropy                 | 1.8385302  |
| ep_rewmean              | -1.77      |
| episodes                | 108        |
| eplenmean               | 100        |
| fps                     | 204        |
| mean 100 episode reward | -1.8       |
| n_updates               | 10601      |
| policy_loss             | -29.90693  |
| qf1_loss                | 5.9425783  |
| qf2_loss                | 6.3352146  |
| time_elapsed            | 52         |
| total timesteps         | 10700      |
| value_loss              | 0.37956634 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.06393315  |
| ent_coef_loss           | 0.23101366  |
| entropy                 | 0.017798983 |
| ep_rewmean              | -1.8        |
| episodes                | 112         |
| eplenmean               | 100         |
| fps                     | 204         |
| mean 100 episode reward | -1.8        |
| n_updates               | 11001       |
| policy_loss             | -29.590916  |
| qf1_loss                | 0.5019739   |
| qf2_loss                | 0.6177523   |
| time_elapsed            | 54          |
| total timesteps         | 11100       |
| value_loss              | 0.53532684  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.06605667  |
| ent_coef_loss           | 0.078427374 |
| entropy                 | 0.5774371   |
| ep_rewmean              | -1.82       |
| episodes                | 116         |
| eplenmean               | 100         |
| fps                     | 204         |
| mean 100 episode reward | -1.8        |
| n_updates               | 11401       |
| policy_loss             | -28.537167  |
| qf1_loss                | 0.21605317  |
| qf2_loss                | 0.30852708  |
| time_elapsed            | 56          |
| total timesteps         | 11500       |
| value_loss              | 0.29632318  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.06446861 |
| ent_coef_loss           | -1.1807967 |
| entropy                 | 0.23881942 |
| ep_rewmean              | -1.84      |
| episodes                | 120        |
| eplenmean               | 100        |
| fps                     | 205        |
| mean 100 episode reward | -1.8       |
| n_updates               | 11801      |
| policy_loss             | -27.138096 |
| qf1_loss                | 0.23786312 |
| qf2_loss                | 0.31899405 |
| time_elapsed            | 58         |
| total timesteps         | 11900      |
| value_loss              | 0.21328883 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.06046852 |
| ent_coef_loss           | -1.9046234 |
| entropy                 | 0.20087141 |
| ep_rewmean              | -1.83      |
| episodes                | 124        |
| eplenmean               | 100        |
| fps                     | 205        |
| mean 100 episode reward | -1.8       |
| n_updates               | 12201      |
| policy_loss             | -26.39183  |
| qf1_loss                | 8.002729   |
| qf2_loss                | 7.570291   |
| time_elapsed            | 59         |
| total timesteps         | 12300      |
| value_loss              | 0.3517762  |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.056560095 |
| ent_coef_loss           | -2.4110188  |
| entropy                 | -0.44750786 |
| ep_rewmean              | -1.83       |
| episodes                | 128         |
| eplenmean               | 100         |
| fps                     | 205         |
| mean 100 episode reward | -1.8        |
| n_updates               | 12601       |
| policy_loss             | -24.961107  |
| qf1_loss                | 0.29779696  |
| qf2_loss                | 0.30182868  |
| time_elapsed            | 61          |
| total timesteps         | 12700       |
| value_loss              | 0.41242397  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.053036828 |
| ent_coef_loss           | -2.2740388  |
| entropy                 | 0.31575269  |
| ep_rewmean              | -1.83       |
| episodes                | 132         |
| eplenmean               | 100         |
| fps                     | 205         |
| mean 100 episode reward | -1.8        |
| n_updates               | 13001       |
| policy_loss             | -23.558998  |
| qf1_loss                | 5.5262127   |
| qf2_loss                | 5.696174    |
| time_elapsed            | 63          |
| total timesteps         | 13100       |
| value_loss              | 0.57254946  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.049047153 |
| ent_coef_loss           | 1.6332186   |
| entropy                 | -0.3637715  |
| ep_rewmean              | -1.82       |
| episodes                | 136         |
| eplenmean               | 100         |
| fps                     | 205         |
| mean 100 episode reward | -1.8        |
| n_updates               | 13401       |
| policy_loss             | -23.732353  |
| qf1_loss                | 0.28091228  |
| qf2_loss                | 0.29474717  |
| time_elapsed            | 65          |
| total timesteps         | 13500       |
| value_loss              | 0.19605911  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.04748987 |
| ent_coef_loss           | -4.7281885 |
| entropy                 | -0.5095483 |
| ep_rewmean              | -1.81      |
| episodes                | 140        |
| eplenmean               | 100        |
| fps                     | 205        |
| mean 100 episode reward | -1.8       |
| n_updates               | 13801      |
| policy_loss             | -22.421413 |
| qf1_loss                | 0.4123834  |
| qf2_loss                | 1.0866914  |
| time_elapsed            | 67         |
| total timesteps         | 13900      |
| value_loss              | 0.18167272 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.0452129   |
| ent_coef_loss           | -0.28088117 |
| entropy                 | -1.5925434  |
| ep_rewmean              | -1.83       |
| episodes                | 144         |
| eplenmean               | 100         |
| fps                     | 205         |
| mean 100 episode reward | -1.8        |
| n_updates               | 14201       |
| policy_loss             | -22.480309  |
| qf1_loss                | 3.6180215   |
| qf2_loss                | 3.6521332   |
| time_elapsed            | 69          |
| total timesteps         | 14300       |
| value_loss              | 0.13092566  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.04419902 |
| ent_coef_loss           | -2.2587385 |
| entropy                 | -1.8803496 |
| ep_rewmean              | -1.84      |
| episodes                | 148        |
| eplenmean               | 100        |
| fps                     | 206        |
| mean 100 episode reward | -1.8       |
| n_updates               | 14601      |
| policy_loss             | -23.138103 |
| qf1_loss                | 1.9213201  |
| qf2_loss                | 1.9606096  |
| time_elapsed            | 71         |
| total timesteps         | 14700      |
| value_loss              | 0.09372689 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.043756165 |
| ent_coef_loss           | 1.8440411   |
| entropy                 | -1.2570431  |
| ep_rewmean              | -1.8        |
| episodes                | 152         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -1.8        |
| n_updates               | 15001       |
| policy_loss             | -22.471262  |
| qf1_loss                | 8.233052    |
| qf2_loss                | 8.118651    |
| time_elapsed            | 73          |
| total timesteps         | 15100       |
| value_loss              | 0.22246626  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.044471756 |
| ent_coef_loss           | 0.6635954   |
| entropy                 | -0.1190535  |
| ep_rewmean              | -1.78       |
| episodes                | 156         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -1.8        |
| n_updates               | 15401       |
| policy_loss             | -21.962759  |
| qf1_loss                | 0.18725738  |
| qf2_loss                | 0.19538909  |
| time_elapsed            | 75          |
| total timesteps         | 15500       |
| value_loss              | 0.18367323  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.044969216 |
| ent_coef_loss           | -2.9508784  |
| entropy                 | 0.4109024   |
| ep_rewmean              | -1.93       |
| episodes                | 160         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -1.9        |
| n_updates               | 15801       |
| policy_loss             | -21.536642  |
| qf1_loss                | 0.1388587   |
| qf2_loss                | 0.13786308  |
| time_elapsed            | 77          |
| total timesteps         | 15900       |
| value_loss              | 0.27890456  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.043001916 |
| ent_coef_loss           | 2.0102975   |
| entropy                 | 1.0834641   |
| ep_rewmean              | -1.89       |
| episodes                | 164         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -1.9        |
| n_updates               | 16201       |
| policy_loss             | -21.254005  |
| qf1_loss                | 3.9015112   |
| qf2_loss                | 4.120009    |
| time_elapsed            | 78          |
| total timesteps         | 16300       |
| value_loss              | 0.23369575  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.043825094 |
| ent_coef_loss           | -1.7092352  |
| entropy                 | 0.01030276  |
| ep_rewmean              | -1.88       |
| episodes                | 168         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -1.9        |
| n_updates               | 16601       |
| policy_loss             | -21.88422   |
| qf1_loss                | 4.002774    |
| qf2_loss                | 4.1716547   |
| time_elapsed            | 80          |
| total timesteps         | 16700       |
| value_loss              | 0.27168727  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.046465285 |
| ent_coef_loss           | 2.919077    |
| entropy                 | 1.4684434   |
| ep_rewmean              | -1.91       |
| episodes                | 172         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -1.9        |
| n_updates               | 17001       |
| policy_loss             | -20.526651  |
| qf1_loss                | 5.721365    |
| qf2_loss                | 5.6296916   |
| time_elapsed            | 82          |
| total timesteps         | 17100       |
| value_loss              | 0.42254293  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.051855545 |
| ent_coef_loss           | -1.2362521  |
| entropy                 | 1.9883163   |
| ep_rewmean              | -1.94       |
| episodes                | 176         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -1.9        |
| n_updates               | 17401       |
| policy_loss             | -20.240677  |
| qf1_loss                | 3.658483    |
| qf2_loss                | 3.4401104   |
| time_elapsed            | 84          |
| total timesteps         | 17500       |
| value_loss              | 0.15865403  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.047461405 |
| ent_coef_loss           | 0.27420473  |
| entropy                 | 1.9621854   |
| ep_rewmean              | -1.92       |
| episodes                | 180         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -1.9        |
| n_updates               | 17801       |
| policy_loss             | -19.790623  |
| qf1_loss                | 0.115325525 |
| qf2_loss                | 0.10039507  |
| time_elapsed            | 86          |
| total timesteps         | 17900       |
| value_loss              | 0.11952549  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.04534949 |
| ent_coef_loss           | 0.61631376 |
| entropy                 | 2.1484072  |
| ep_rewmean              | -1.95      |
| episodes                | 184        |
| eplenmean               | 100        |
| fps                     | 206        |
| mean 100 episode reward | -2         |
| n_updates               | 18201      |
| policy_loss             | -19.169422 |
| qf1_loss                | 0.08049193 |
| qf2_loss                | 0.08791157 |
| time_elapsed            | 88         |
| total timesteps         | 18300      |
| value_loss              | 0.09193455 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.041783266 |
| ent_coef_loss           | -6.3649216  |
| entropy                 | 0.85462683  |
| ep_rewmean              | -2.04       |
| episodes                | 188         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -2          |
| n_updates               | 18601       |
| policy_loss             | -18.701885  |
| qf1_loss                | 0.09415148  |
| qf2_loss                | 0.07823388  |
| time_elapsed            | 90          |
| total timesteps         | 18700       |
| value_loss              | 0.06337407  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.039109178 |
| ent_coef_loss           | 2.356321    |
| entropy                 | 1.3129172   |
| ep_rewmean              | -2.09       |
| episodes                | 192         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -2.1        |
| n_updates               | 19001       |
| policy_loss             | -18.252262  |
| qf1_loss                | 3.8926463   |
| qf2_loss                | 3.8828602   |
| time_elapsed            | 92          |
| total timesteps         | 19100       |
| value_loss              | 0.15381464  |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.03824983 |
| ent_coef_loss           | 1.4990296  |
| entropy                 | 0.47919992 |
| ep_rewmean              | -2.18      |
| episodes                | 196        |
| eplenmean               | 100        |
| fps                     | 206        |
| mean 100 episode reward | -2.2       |
| n_updates               | 19401      |
| policy_loss             | -17.839743 |
| qf1_loss                | 0.958625   |
| qf2_loss                | 0.9411734  |
| time_elapsed            | 94         |
| total timesteps         | 19500      |
| value_loss              | 0.18497372 |
----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.03839196 |
| ent_coef_loss           | -0.5375079 |
| entropy                 | 1.5007544  |
| ep_rewmean              | -2.27      |
| episodes                | 200        |
| eplenmean               | 100        |
| fps                     | 206        |
| mean 100 episode reward | -2.3       |
| n_updates               | 19801      |
| policy_loss             | -17.651257 |
| qf1_loss                | 0.15352157 |
| qf2_loss                | 0.15692863 |
| time_elapsed            | 96         |
| total timesteps         | 19900      |
| value_loss              | 0.13277158 |
----------------------------------------
Eval num_timesteps=20000, episode_reward=-1.48 +/- 0.35
Episode length: 100.00 +/- 0.00
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.03630128 |
| ent_coef_loss           | -0.610791  |
| entropy                 | 0.6504263  |
| ep_rewmean              | -2.34      |
| episodes                | 204        |
| eplenmean               | 100        |
| fps                     | 206        |
| mean 100 episode reward | -2.3       |
| n_updates               | 20201      |
| policy_loss             | -16.843092 |
| qf1_loss                | 0.16809383 |
| qf2_loss                | 0.15361974 |
| time_elapsed            | 98         |
| total timesteps         | 20300      |
| value_loss              | 0.07631182 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.036218558 |
| ent_coef_loss           | 2.1130643   |
| entropy                 | 1.4123087   |
| ep_rewmean              | -2.45       |
| episodes                | 208         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -2.4        |
| n_updates               | 20601       |
| policy_loss             | -16.275158  |
| qf1_loss                | 0.0755495   |
| qf2_loss                | 0.12106326  |
| time_elapsed            | 100         |
| total timesteps         | 20700       |
| value_loss              | 0.09875469  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.036361907 |
| ent_coef_loss           | 2.0939972   |
| entropy                 | 1.4178615   |
| ep_rewmean              | -2.55       |
| episodes                | 212         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -2.5        |
| n_updates               | 21001       |
| policy_loss             | -16.46708   |
| qf1_loss                | 0.07027966  |
| qf2_loss                | 0.060359105 |
| time_elapsed            | 102         |
| total timesteps         | 21100       |
| value_loss              | 0.12332563  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.03412279  |
| ent_coef_loss           | -4.2700624  |
| entropy                 | 1.8059356   |
| ep_rewmean              | -2.58       |
| episodes                | 216         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -2.6        |
| n_updates               | 21401       |
| policy_loss             | -14.938188  |
| qf1_loss                | 0.08659125  |
| qf2_loss                | 0.058818124 |
| time_elapsed            | 104         |
| total timesteps         | 21500       |
| value_loss              | 0.052446652 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.031077927 |
| ent_coef_loss           | -2.0216446  |
| entropy                 | 1.4353644   |
| ep_rewmean              | -2.62       |
| episodes                | 220         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -2.6        |
| n_updates               | 21801       |
| policy_loss             | -14.795437  |
| qf1_loss                | 3.133461    |
| qf2_loss                | 3.1208358   |
| time_elapsed            | 105         |
| total timesteps         | 21900       |
| value_loss              | 0.07785575  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.03147366  |
| ent_coef_loss           | -2.0443478  |
| entropy                 | 1.6661822   |
| ep_rewmean              | -2.63       |
| episodes                | 224         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -2.6        |
| n_updates               | 22201       |
| policy_loss             | -14.369577  |
| qf1_loss                | 0.050951265 |
| qf2_loss                | 0.055338413 |
| time_elapsed            | 107         |
| total timesteps         | 22300       |
| value_loss              | 0.03990089  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.030991696 |
| ent_coef_loss           | 1.1275811   |
| entropy                 | 1.0997901   |
| ep_rewmean              | -2.64       |
| episodes                | 228         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -2.6        |
| n_updates               | 22601       |
| policy_loss             | -13.7277355 |
| qf1_loss                | 0.05207403  |
| qf2_loss                | 0.07635463  |
| time_elapsed            | 109         |
| total timesteps         | 22700       |
| value_loss              | 0.15194316  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.031057987 |
| ent_coef_loss           | 0.61671424  |
| entropy                 | 0.80343246  |
| ep_rewmean              | -2.68       |
| episodes                | 232         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -2.7        |
| n_updates               | 23001       |
| policy_loss             | -13.212711  |
| qf1_loss                | 0.0634119   |
| qf2_loss                | 0.060823098 |
| time_elapsed            | 111         |
| total timesteps         | 23100       |
| value_loss              | 0.040051945 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.030492458 |
| ent_coef_loss           | 1.8042212   |
| entropy                 | 1.274178    |
| ep_rewmean              | -2.7        |
| episodes                | 236         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -2.7        |
| n_updates               | 23401       |
| policy_loss             | -12.428507  |
| qf1_loss                | 0.06494598  |
| qf2_loss                | 0.05404128  |
| time_elapsed            | 113         |
| total timesteps         | 23500       |
| value_loss              | 0.046170123 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.029135607 |
| ent_coef_loss           | -1.6458249  |
| entropy                 | 0.85113835  |
| ep_rewmean              | -2.73       |
| episodes                | 240         |
| eplenmean               | 100         |
| fps                     | 206         |
| mean 100 episode reward | -2.7        |
| n_updates               | 23801       |
| policy_loss             | -12.138844  |
| qf1_loss                | 0.049419545 |
| qf2_loss                | 0.08558224  |
| time_elapsed            | 115         |
| total timesteps         | 23900       |
| value_loss              | 0.034105036 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.029937122 |
| ent_coef_loss           | 0.35163152  |
| entropy                 | 1.450228    |
| ep_rewmean              | -2.71       |
| episodes                | 244         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.7        |
| n_updates               | 24201       |
| policy_loss             | -11.3979645 |
| qf1_loss                | 1.1880704   |
| qf2_loss                | 1.1777651   |
| time_elapsed            | 117         |
| total timesteps         | 24300       |
| value_loss              | 0.15285969  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.033069063 |
| ent_coef_loss           | -1.0447376  |
| entropy                 | 1.5711076   |
| ep_rewmean              | -2.69       |
| episodes                | 248         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.7        |
| n_updates               | 24601       |
| policy_loss             | -10.863192  |
| qf1_loss                | 0.034284934 |
| qf2_loss                | 0.054690056 |
| time_elapsed            | 119         |
| total timesteps         | 24700       |
| value_loss              | 0.054136895 |
-----------------------------------------
----------------------------------------
| current_lr              | 0.0003     |
| ent_coef                | 0.03167154 |
| ent_coef_loss           | -2.739546  |
| entropy                 | 1.4811401  |
| ep_rewmean              | -2.77      |
| episodes                | 252        |
| eplenmean               | 100        |
| fps                     | 207        |
| mean 100 episode reward | -2.8       |
| n_updates               | 25001      |
| policy_loss             | -10.779575 |
| qf1_loss                | 0.09427602 |
| qf2_loss                | 0.12531775 |
| time_elapsed            | 121        |
| total timesteps         | 25100      |
| value_loss              | 0.03484088 |
----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.028329223 |
| ent_coef_loss           | 3.0249197   |
| entropy                 | 1.5561881   |
| ep_rewmean              | -2.78       |
| episodes                | 256         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.8        |
| n_updates               | 25401       |
| policy_loss             | -10.1052    |
| qf1_loss                | 0.058614396 |
| qf2_loss                | 0.06548294  |
| time_elapsed            | 123         |
| total timesteps         | 25500       |
| value_loss              | 0.036923427 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.02604902  |
| ent_coef_loss           | -1.8543756  |
| entropy                 | 1.1936922   |
| ep_rewmean              | -2.62       |
| episodes                | 260         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.6        |
| n_updates               | 25801       |
| policy_loss             | -9.868559   |
| qf1_loss                | 0.047394484 |
| qf2_loss                | 0.030375037 |
| time_elapsed            | 124         |
| total timesteps         | 25900       |
| value_loss              | 0.027920358 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.025279637 |
| ent_coef_loss           | -1.8199086  |
| entropy                 | 1.4762493   |
| ep_rewmean              | -2.6        |
| episodes                | 264         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.6        |
| n_updates               | 26201       |
| policy_loss             | -9.151678   |
| qf1_loss                | 0.083099626 |
| qf2_loss                | 0.07106638  |
| time_elapsed            | 126         |
| total timesteps         | 26300       |
| value_loss              | 0.15300573  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.023723517 |
| ent_coef_loss           | -4.724203   |
| entropy                 | 1.395406    |
| ep_rewmean              | -2.61       |
| episodes                | 268         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.6        |
| n_updates               | 26601       |
| policy_loss             | -8.978722   |
| qf1_loss                | 0.04049498  |
| qf2_loss                | 0.03074527  |
| time_elapsed            | 128         |
| total timesteps         | 26700       |
| value_loss              | 0.055548437 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.02192926  |
| ent_coef_loss           | -1.3988938  |
| entropy                 | 0.92759883  |
| ep_rewmean              | -2.56       |
| episodes                | 272         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.6        |
| n_updates               | 27001       |
| policy_loss             | -8.478739   |
| qf1_loss                | 0.52476054  |
| qf2_loss                | 0.51035386  |
| time_elapsed            | 130         |
| total timesteps         | 27100       |
| value_loss              | 0.030580755 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.021221975 |
| ent_coef_loss           | -3.8128896  |
| entropy                 | 1.6620407   |
| ep_rewmean              | -2.52       |
| episodes                | 276         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.5        |
| n_updates               | 27401       |
| policy_loss             | -8.25527    |
| qf1_loss                | 0.47220075  |
| qf2_loss                | 0.44738662  |
| time_elapsed            | 132         |
| total timesteps         | 27500       |
| value_loss              | 0.024395417 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.020669777 |
| ent_coef_loss           | -0.54489124 |
| entropy                 | 1.1848813   |
| ep_rewmean              | -2.53       |
| episodes                | 280         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.5        |
| n_updates               | 27801       |
| policy_loss             | -7.853884   |
| qf1_loss                | 0.028435895 |
| qf2_loss                | 0.03013541  |
| time_elapsed            | 134         |
| total timesteps         | 27900       |
| value_loss              | 0.02081482  |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.019238062 |
| ent_coef_loss           | 0.45912844  |
| entropy                 | 1.2640097   |
| ep_rewmean              | -2.48       |
| episodes                | 284         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.5        |
| n_updates               | 28201       |
| policy_loss             | -7.3052893  |
| qf1_loss                | 0.5403534   |
| qf2_loss                | 0.7495148   |
| time_elapsed            | 136         |
| total timesteps         | 28300       |
| value_loss              | 0.024673432 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.019031351 |
| ent_coef_loss           | 1.7844782   |
| entropy                 | 2.4566414   |
| ep_rewmean              | -2.39       |
| episodes                | 288         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.4        |
| n_updates               | 28601       |
| policy_loss             | -7.1337748  |
| qf1_loss                | 0.03109019  |
| qf2_loss                | 0.031086292 |
| time_elapsed            | 138         |
| total timesteps         | 28700       |
| value_loss              | 0.0343293   |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.018203286 |
| ent_coef_loss           | -0.54357    |
| entropy                 | 1.5211418   |
| ep_rewmean              | -2.36       |
| episodes                | 292         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.4        |
| n_updates               | 29001       |
| policy_loss             | -7.1586847  |
| qf1_loss                | 0.6520754   |
| qf2_loss                | 0.64703625  |
| time_elapsed            | 140         |
| total timesteps         | 29100       |
| value_loss              | 0.026406325 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.017413385 |
| ent_coef_loss           | -1.2148869  |
| entropy                 | 0.8098272   |
| ep_rewmean              | -2.25       |
| episodes                | 296         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.3        |
| n_updates               | 29401       |
| policy_loss             | -6.7686143  |
| qf1_loss                | 0.19399172  |
| qf2_loss                | 0.20453347  |
| time_elapsed            | 142         |
| total timesteps         | 29500       |
| value_loss              | 0.027732363 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.018629324 |
| ent_coef_loss           | 4.2651277   |
| entropy                 | -0.40764987 |
| ep_rewmean              | -2.13       |
| episodes                | 300         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.1        |
| n_updates               | 29801       |
| policy_loss             | -6.427957   |
| qf1_loss                | 0.111369565 |
| qf2_loss                | 0.100110896 |
| time_elapsed            | 144         |
| total timesteps         | 29900       |
| value_loss              | 0.051206995 |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-1.53 +/- 1.15
Episode length: 100.00 +/- 0.00
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.01973697  |
| ent_coef_loss           | 1.682143    |
| entropy                 | 0.39070717  |
| ep_rewmean              | -2.09       |
| episodes                | 304         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.1        |
| n_updates               | 30201       |
| policy_loss             | -6.449314   |
| qf1_loss                | 0.016156225 |
| qf2_loss                | 0.023375332 |
| time_elapsed            | 146         |
| total timesteps         | 30300       |
| value_loss              | 0.013323982 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.019300781 |
| ent_coef_loss           | -1.9009409  |
| entropy                 | 0.28241265  |
| ep_rewmean              | -2.03       |
| episodes                | 308         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2          |
| n_updates               | 30601       |
| policy_loss             | -6.203844   |
| qf1_loss                | 0.016553175 |
| qf2_loss                | 0.015410713 |
| time_elapsed            | 148         |
| total timesteps         | 30700       |
| value_loss              | 0.014699148 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.018029524 |
| ent_coef_loss           | 1.0324754   |
| entropy                 | 0.23644754  |
| ep_rewmean              | -1.97       |
| episodes                | 312         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2          |
| n_updates               | 31001       |
| policy_loss             | -5.8768287  |
| qf1_loss                | 0.009652345 |
| qf2_loss                | 0.013700793 |
| time_elapsed            | 150         |
| total timesteps         | 31100       |
| value_loss              | 0.038670756 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.017836569 |
| ent_coef_loss           | 0.4407041   |
| entropy                 | 0.05590287  |
| ep_rewmean              | -1.99       |
| episodes                | 316         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2          |
| n_updates               | 31401       |
| policy_loss             | -5.801551   |
| qf1_loss                | 0.021051444 |
| qf2_loss                | 0.011560883 |
| time_elapsed            | 151         |
| total timesteps         | 31500       |
| value_loss              | 0.02266781  |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.017893473  |
| ent_coef_loss           | 1.0055859    |
| entropy                 | 0.25647718   |
| ep_rewmean              | -1.92        |
| episodes                | 320          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 31801        |
| policy_loss             | -5.545228    |
| qf1_loss                | 0.0069350544 |
| qf2_loss                | 0.0072038737 |
| time_elapsed            | 153          |
| total timesteps         | 31900        |
| value_loss              | 0.036951154  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.016595451 |
| ent_coef_loss           | -0.6629038  |
| entropy                 | 0.8582241   |
| ep_rewmean              | -1.91       |
| episodes                | 324         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -1.9        |
| n_updates               | 32201       |
| policy_loss             | -5.329733   |
| qf1_loss                | 0.60744107  |
| qf2_loss                | 0.61863476  |
| time_elapsed            | 155         |
| total timesteps         | 32300       |
| value_loss              | 0.009382002 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.015641661  |
| ent_coef_loss           | -2.2327135   |
| entropy                 | 0.9757594    |
| ep_rewmean              | -1.95        |
| episodes                | 328          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 32601        |
| policy_loss             | -5.228185    |
| qf1_loss                | 0.0105817355 |
| qf2_loss                | 0.008020977  |
| time_elapsed            | 157          |
| total timesteps         | 32700        |
| value_loss              | 0.015704073  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.014361434 |
| ent_coef_loss           | -4.081748   |
| entropy                 | 0.94784975  |
| ep_rewmean              | -2          |
| episodes                | 332         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2          |
| n_updates               | 33001       |
| policy_loss             | -4.8124304  |
| qf1_loss                | 0.012135155 |
| qf2_loss                | 0.016139762 |
| time_elapsed            | 159         |
| total timesteps         | 33100       |
| value_loss              | 0.025044177 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.012644722 |
| ent_coef_loss           | 0.41938448  |
| entropy                 | 0.76441264  |
| ep_rewmean              | -2.01       |
| episodes                | 336         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2          |
| n_updates               | 33401       |
| policy_loss             | -4.9382687  |
| qf1_loss                | 0.4040297   |
| qf2_loss                | 0.3969745   |
| time_elapsed            | 161         |
| total timesteps         | 33500       |
| value_loss              | 0.009592864 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.01238686  |
| ent_coef_loss           | 0.3197981   |
| entropy                 | 0.7239474   |
| ep_rewmean              | -2.01       |
| episodes                | 340         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2          |
| n_updates               | 33801       |
| policy_loss             | -4.507991   |
| qf1_loss                | 0.014489327 |
| qf2_loss                | 0.018669283 |
| time_elapsed            | 163         |
| total timesteps         | 33900       |
| value_loss              | 0.012363709 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.011878504  |
| ent_coef_loss           | 0.4907974    |
| entropy                 | 0.706824     |
| ep_rewmean              | -2.02        |
| episodes                | 344          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 34201        |
| policy_loss             | -4.5856524   |
| qf1_loss                | 0.054270204  |
| qf2_loss                | 0.0075806486 |
| time_elapsed            | 165          |
| total timesteps         | 34300        |
| value_loss              | 0.009941772  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.011534295 |
| ent_coef_loss           | -8.941664   |
| entropy                 | 1.1367123   |
| ep_rewmean              | -2.06       |
| episodes                | 348         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.1        |
| n_updates               | 34601       |
| policy_loss             | -4.432355   |
| qf1_loss                | 0.007338156 |
| qf2_loss                | 0.010902546 |
| time_elapsed            | 167         |
| total timesteps         | 34700       |
| value_loss              | 0.009801996 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.010859897  |
| ent_coef_loss           | 0.6747334    |
| entropy                 | 1.014885     |
| ep_rewmean              | -2.01        |
| episodes                | 352          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 35001        |
| policy_loss             | -4.353983    |
| qf1_loss                | 0.009208387  |
| qf2_loss                | 0.006405942  |
| time_elapsed            | 169          |
| total timesteps         | 35100        |
| value_loss              | 0.0069000586 |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.010606918 |
| ent_coef_loss           | 6.4786673   |
| entropy                 | 2.759858    |
| ep_rewmean              | -2          |
| episodes                | 356         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2          |
| n_updates               | 35401       |
| policy_loss             | -4.1464972  |
| qf1_loss                | 0.15300551  |
| qf2_loss                | 0.15043685  |
| time_elapsed            | 171         |
| total timesteps         | 35500       |
| value_loss              | 0.007380656 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.010206601 |
| ent_coef_loss           | 3.7215483   |
| entropy                 | 1.8262391   |
| ep_rewmean              | -2.04       |
| episodes                | 360         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2          |
| n_updates               | 35801       |
| policy_loss             | -4.070353   |
| qf1_loss                | 0.16043572  |
| qf2_loss                | 0.1521758   |
| time_elapsed            | 173         |
| total timesteps         | 35900       |
| value_loss              | 0.007034823 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.010621965  |
| ent_coef_loss           | 6.6533737    |
| entropy                 | 1.918381     |
| ep_rewmean              | -2.01        |
| episodes                | 364          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 36201        |
| policy_loss             | -4.019805    |
| qf1_loss                | 0.0040127346 |
| qf2_loss                | 0.0055826744 |
| time_elapsed            | 175          |
| total timesteps         | 36300        |
| value_loss              | 0.012915365  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.010896025 |
| ent_coef_loss           | 5.8715706   |
| entropy                 | 1.3675637   |
| ep_rewmean              | -2          |
| episodes                | 368         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2          |
| n_updates               | 36601       |
| policy_loss             | -3.8294356  |
| qf1_loss                | 0.20245188  |
| qf2_loss                | 0.21597339  |
| time_elapsed            | 176         |
| total timesteps         | 36700       |
| value_loss              | 0.020274337 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.011327691  |
| ent_coef_loss           | -1.7310946   |
| entropy                 | 2.3397667    |
| ep_rewmean              | -1.99        |
| episodes                | 372          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 37001        |
| policy_loss             | -3.7058558   |
| qf1_loss                | 0.0075721396 |
| qf2_loss                | 0.008694805  |
| time_elapsed            | 178          |
| total timesteps         | 37100        |
| value_loss              | 0.015985731  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.010927604  |
| ent_coef_loss           | -7.95298     |
| entropy                 | 2.0002213    |
| ep_rewmean              | -1.98        |
| episodes                | 376          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 37401        |
| policy_loss             | -3.511085    |
| qf1_loss                | 0.09618507   |
| qf2_loss                | 0.10332891   |
| time_elapsed            | 180          |
| total timesteps         | 37500        |
| value_loss              | 0.0069891354 |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.010323152 |
| ent_coef_loss           | 0.82458425  |
| entropy                 | 2.1170025   |
| ep_rewmean              | -2          |
| episodes                | 380         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2          |
| n_updates               | 37801       |
| policy_loss             | -3.2151701  |
| qf1_loss                | 0.010404125 |
| qf2_loss                | 0.008069568 |
| time_elapsed            | 182         |
| total timesteps         | 37900       |
| value_loss              | 0.006887656 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.010054195 |
| ent_coef_loss           | -2.989526   |
| entropy                 | 2.304965    |
| ep_rewmean              | -2.04       |
| episodes                | 384         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2          |
| n_updates               | 38201       |
| policy_loss             | -3.1328475  |
| qf1_loss                | 0.11045634  |
| qf2_loss                | 0.10359669  |
| time_elapsed            | 184         |
| total timesteps         | 38300       |
| value_loss              | 0.01076748  |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0099327825 |
| ent_coef_loss           | -1.9463751   |
| entropy                 | 2.0649507    |
| ep_rewmean              | -2.06        |
| episodes                | 388          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 38601        |
| policy_loss             | -3.1105223   |
| qf1_loss                | 0.003885601  |
| qf2_loss                | 0.0023571562 |
| time_elapsed            | 186          |
| total timesteps         | 38700        |
| value_loss              | 0.0067849113 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.009097317  |
| ent_coef_loss           | -2.7468877   |
| entropy                 | 2.3307502    |
| ep_rewmean              | -2.08        |
| episodes                | 392          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 39001        |
| policy_loss             | -2.9913242   |
| qf1_loss                | 0.03453077   |
| qf2_loss                | 0.03529411   |
| time_elapsed            | 188          |
| total timesteps         | 39100        |
| value_loss              | 0.0064326236 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.008632336  |
| ent_coef_loss           | 6.9843254    |
| entropy                 | 2.6982489    |
| ep_rewmean              | -2.1         |
| episodes                | 396          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 39401        |
| policy_loss             | -2.8030841   |
| qf1_loss                | 0.020934395  |
| qf2_loss                | 0.052031968  |
| time_elapsed            | 190          |
| total timesteps         | 39500        |
| value_loss              | 0.0069464482 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.009034772  |
| ent_coef_loss           | -2.6805115   |
| entropy                 | 3.3990905    |
| ep_rewmean              | -2.2         |
| episodes                | 400          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 39801        |
| policy_loss             | -2.6035814   |
| qf1_loss                | 0.036734477  |
| qf2_loss                | 0.04007876   |
| time_elapsed            | 192          |
| total timesteps         | 39900        |
| value_loss              | 0.0034734928 |
------------------------------------------
Eval num_timesteps=40000, episode_reward=-2.53 +/- 1.30
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.00862669   |
| ent_coef_loss           | -4.3250084   |
| entropy                 | 3.985927     |
| ep_rewmean              | -2.18        |
| episodes                | 404          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 40201        |
| policy_loss             | -2.6886835   |
| qf1_loss                | 0.004237344  |
| qf2_loss                | 0.0045272554 |
| time_elapsed            | 194          |
| total timesteps         | 40300        |
| value_loss              | 0.009058743  |
------------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.008117058 |
| ent_coef_loss           | -3.0489097  |
| entropy                 | 3.6537645   |
| ep_rewmean              | -2.19       |
| episodes                | 408         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.2        |
| n_updates               | 40601       |
| policy_loss             | -2.8270645  |
| qf1_loss                | 0.11027675  |
| qf2_loss                | 0.11592129  |
| time_elapsed            | 196         |
| total timesteps         | 40700       |
| value_loss              | 0.005525246 |
-----------------------------------------
-----------------------------------------
| current_lr              | 0.0003      |
| ent_coef                | 0.007386977 |
| ent_coef_loss           | -5.25753    |
| entropy                 | 2.9997709   |
| ep_rewmean              | -2.12       |
| episodes                | 412         |
| eplenmean               | 100         |
| fps                     | 207         |
| mean 100 episode reward | -2.1        |
| n_updates               | 41001       |
| policy_loss             | -2.5491395  |
| qf1_loss                | 0.07004184  |
| qf2_loss                | 0.06840738  |
| time_elapsed            | 198         |
| total timesteps         | 41100       |
| value_loss              | 0.007139502 |
-----------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0071985954 |
| ent_coef_loss           | -4.604019    |
| entropy                 | 2.7278237    |
| ep_rewmean              | -2.11        |
| episodes                | 416          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 41401        |
| policy_loss             | -2.4933126   |
| qf1_loss                | 0.0022010999 |
| qf2_loss                | 0.0020705983 |
| time_elapsed            | 200          |
| total timesteps         | 41500        |
| value_loss              | 0.0023905889 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.00633962   |
| ent_coef_loss           | -3.6996274   |
| entropy                 | 2.426631     |
| ep_rewmean              | -2.14        |
| episodes                | 420          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 41801        |
| policy_loss             | -2.3965712   |
| qf1_loss                | 0.11316835   |
| qf2_loss                | 0.11156872   |
| time_elapsed            | 202          |
| total timesteps         | 41900        |
| value_loss              | 0.0028638253 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0055814544 |
| ent_coef_loss           | 0.7289169    |
| entropy                 | 2.3985267    |
| ep_rewmean              | -2.21        |
| episodes                | 424          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 42201        |
| policy_loss             | -2.4147248   |
| qf1_loss                | 0.0026546954 |
| qf2_loss                | 0.0029620132 |
| time_elapsed            | 204          |
| total timesteps         | 42300        |
| value_loss              | 0.0018245834 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0050216736 |
| ent_coef_loss           | 1.3288019    |
| entropy                 | 2.3984618    |
| ep_rewmean              | -2.13        |
| episodes                | 428          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 42601        |
| policy_loss             | -2.2731233   |
| qf1_loss                | 0.07068522   |
| qf2_loss                | 0.07107264   |
| time_elapsed            | 206          |
| total timesteps         | 42700        |
| value_loss              | 0.004713344  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.004872774  |
| ent_coef_loss           | -7.04991     |
| entropy                 | 1.9708996    |
| ep_rewmean              | -2.1         |
| episodes                | 432          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 43001        |
| policy_loss             | -2.3207223   |
| qf1_loss                | 0.0012656382 |
| qf2_loss                | 0.0013619885 |
| time_elapsed            | 208          |
| total timesteps         | 43100        |
| value_loss              | 0.0047877897 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0049774605 |
| ent_coef_loss           | -1.4475842   |
| entropy                 | 1.6402557    |
| ep_rewmean              | -2.1         |
| episodes                | 436          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 43401        |
| policy_loss             | -2.286115    |
| qf1_loss                | 0.03919534   |
| qf2_loss                | 0.032582827  |
| time_elapsed            | 209          |
| total timesteps         | 43500        |
| value_loss              | 0.002768393  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0050333412 |
| ent_coef_loss           | -2.743441    |
| entropy                 | 1.4781427    |
| ep_rewmean              | -2.12        |
| episodes                | 440          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 43801        |
| policy_loss             | -2.3773131   |
| qf1_loss                | 0.0029249117 |
| qf2_loss                | 0.002320629  |
| time_elapsed            | 211          |
| total timesteps         | 43900        |
| value_loss              | 0.0051896684 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.004938733  |
| ent_coef_loss           | 1.6446272    |
| entropy                 | 1.4134266    |
| ep_rewmean              | -2.11        |
| episodes                | 444          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 44201        |
| policy_loss             | -2.1729028   |
| qf1_loss                | 0.002423454  |
| qf2_loss                | 0.0035469963 |
| time_elapsed            | 213          |
| total timesteps         | 44300        |
| value_loss              | 0.010372713  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0047481535 |
| ent_coef_loss           | 2.4661999    |
| entropy                 | 0.74300134   |
| ep_rewmean              | -2.11        |
| episodes                | 448          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 44601        |
| policy_loss             | -2.1175961   |
| qf1_loss                | 0.0023326783 |
| qf2_loss                | 0.0016102385 |
| time_elapsed            | 215          |
| total timesteps         | 44700        |
| value_loss              | 0.0035285237 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0043590604 |
| ent_coef_loss           | -0.67310494  |
| entropy                 | 1.2641169    |
| ep_rewmean              | -2.08        |
| episodes                | 452          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 45001        |
| policy_loss             | -1.9837512   |
| qf1_loss                | 0.0010015578 |
| qf2_loss                | 0.0016760726 |
| time_elapsed            | 217          |
| total timesteps         | 45100        |
| value_loss              | 0.0016159293 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.004065638  |
| ent_coef_loss           | -6.0607166   |
| entropy                 | 0.93693364   |
| ep_rewmean              | -2.05        |
| episodes                | 456          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 45401        |
| policy_loss             | -2.0081787   |
| qf1_loss                | 0.0013658558 |
| qf2_loss                | 0.0013507993 |
| time_elapsed            | 219          |
| total timesteps         | 45500        |
| value_loss              | 0.0037149717 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.003873913  |
| ent_coef_loss           | -1.6551533   |
| entropy                 | 1.1369588    |
| ep_rewmean              | -2.03        |
| episodes                | 460          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 45801        |
| policy_loss             | -1.8618097   |
| qf1_loss                | 0.0016165199 |
| qf2_loss                | 0.0020718796 |
| time_elapsed            | 221          |
| total timesteps         | 45900        |
| value_loss              | 0.0018057546 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0036605957 |
| ent_coef_loss           | -2.0109277   |
| entropy                 | 1.2875919    |
| ep_rewmean              | -2.03        |
| episodes                | 464          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 46201        |
| policy_loss             | -1.845843    |
| qf1_loss                | 0.0019958012 |
| qf2_loss                | 0.0026771927 |
| time_elapsed            | 223          |
| total timesteps         | 46300        |
| value_loss              | 0.0038021759 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0035965373 |
| ent_coef_loss           | 1.3744726    |
| entropy                 | 1.1198682    |
| ep_rewmean              | -2.07        |
| episodes                | 468          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 46601        |
| policy_loss             | -1.6931541   |
| qf1_loss                | 0.0016020178 |
| qf2_loss                | 0.0013190014 |
| time_elapsed            | 225          |
| total timesteps         | 46700        |
| value_loss              | 0.0026805517 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0036428105 |
| ent_coef_loss           | -0.77052134  |
| entropy                 | 1.6883705    |
| ep_rewmean              | -2.12        |
| episodes                | 472          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 47001        |
| policy_loss             | -1.7284675   |
| qf1_loss                | 0.0014877232 |
| qf2_loss                | 0.0014532454 |
| time_elapsed            | 227          |
| total timesteps         | 47100        |
| value_loss              | 0.0010833028 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0034228186 |
| ent_coef_loss           | -1.9563032   |
| entropy                 | 1.5999188    |
| ep_rewmean              | -2.19        |
| episodes                | 476          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 47401        |
| policy_loss             | -1.6728156   |
| qf1_loss                | 0.001108099  |
| qf2_loss                | 0.0015625821 |
| time_elapsed            | 229          |
| total timesteps         | 47500        |
| value_loss              | 0.0009888262 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.003156153  |
| ent_coef_loss           | -4.101548    |
| entropy                 | 1.4176672    |
| ep_rewmean              | -2.17        |
| episodes                | 480          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 47801        |
| policy_loss             | -1.6448913   |
| qf1_loss                | 0.02307261   |
| qf2_loss                | 0.024180664  |
| time_elapsed            | 231          |
| total timesteps         | 47900        |
| value_loss              | 0.0017545264 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0030987624 |
| ent_coef_loss           | -1.3560511   |
| entropy                 | 1.6793015    |
| ep_rewmean              | -2.18        |
| episodes                | 484          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 48201        |
| policy_loss             | -1.5394567   |
| qf1_loss                | 0.015623151  |
| qf2_loss                | 0.013724834  |
| time_elapsed            | 232          |
| total timesteps         | 48300        |
| value_loss              | 0.0010896684 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002874971  |
| ent_coef_loss           | -4.3264503   |
| entropy                 | 1.8854228    |
| ep_rewmean              | -2.18        |
| episodes                | 488          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 48601        |
| policy_loss             | -1.4741131   |
| qf1_loss                | 0.0009470244 |
| qf2_loss                | 0.002392181  |
| time_elapsed            | 234          |
| total timesteps         | 48700        |
| value_loss              | 0.0027313172 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002946644  |
| ent_coef_loss           | 4.3141294    |
| entropy                 | 2.2302918    |
| ep_rewmean              | -2.13        |
| episodes                | 492          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 49001        |
| policy_loss             | -1.4886637   |
| qf1_loss                | 0.0010102068 |
| qf2_loss                | 0.0014339089 |
| time_elapsed            | 236          |
| total timesteps         | 49100        |
| value_loss              | 0.0035944618 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0029395332 |
| ent_coef_loss           | -4.8330755   |
| entropy                 | 1.7804327    |
| ep_rewmean              | -2.07        |
| episodes                | 496          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 49401        |
| policy_loss             | -1.3847882   |
| qf1_loss                | 0.013828456  |
| qf2_loss                | 0.022141384  |
| time_elapsed            | 238          |
| total timesteps         | 49500        |
| value_loss              | 0.0013218215 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0027423813 |
| ent_coef_loss           | -0.20124313  |
| entropy                 | 1.4737701    |
| ep_rewmean              | -1.98        |
| episodes                | 500          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 49801        |
| policy_loss             | -1.2959168   |
| qf1_loss                | 0.0056428476 |
| qf2_loss                | 0.004112499  |
| time_elapsed            | 240          |
| total timesteps         | 49900        |
| value_loss              | 0.0006188185 |
------------------------------------------
Eval num_timesteps=50000, episode_reward=-1.98 +/- 1.19
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002722787  |
| ent_coef_loss           | 1.0595063    |
| entropy                 | 2.4031966    |
| ep_rewmean              | -1.97        |
| episodes                | 504          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 50201        |
| policy_loss             | -1.2308909   |
| qf1_loss                | 0.0019645188 |
| qf2_loss                | 0.0010108857 |
| time_elapsed            | 242          |
| total timesteps         | 50300        |
| value_loss              | 0.0009486498 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0026696804  |
| ent_coef_loss           | -3.579766     |
| entropy                 | 1.5033287     |
| ep_rewmean              | -1.95         |
| episodes                | 508           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 50601         |
| policy_loss             | -1.1995437    |
| qf1_loss                | 0.00952067    |
| qf2_loss                | 0.009648793   |
| time_elapsed            | 244           |
| total timesteps         | 50700         |
| value_loss              | 0.00050737726 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0026420942  |
| ent_coef_loss           | 2.3309612     |
| entropy                 | 1.9659846     |
| ep_rewmean              | -1.97         |
| episodes                | 512           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 51001         |
| policy_loss             | -1.1042721    |
| qf1_loss                | 0.007937783   |
| qf2_loss                | 0.0038931654  |
| time_elapsed            | 246           |
| total timesteps         | 51100         |
| value_loss              | 0.00072390796 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0025499132 |
| ent_coef_loss           | -4.358088    |
| entropy                 | 1.8687167    |
| ep_rewmean              | -1.91        |
| episodes                | 516          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 51401        |
| policy_loss             | -1.0600117   |
| qf1_loss                | 0.0004293195 |
| qf2_loss                | 0.0003932055 |
| time_elapsed            | 248          |
| total timesteps         | 51500        |
| value_loss              | 0.0004690286 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0023355945  |
| ent_coef_loss           | -4.6838303    |
| entropy                 | 2.6926842     |
| ep_rewmean              | -1.89         |
| episodes                | 520           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 51801         |
| policy_loss             | -0.9194256    |
| qf1_loss                | 0.00053241523 |
| qf2_loss                | 0.00060263195 |
| time_elapsed            | 250           |
| total timesteps         | 51900         |
| value_loss              | 0.00085177936 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0022346075 |
| ent_coef_loss           | -4.2947836   |
| entropy                 | 2.5609126    |
| ep_rewmean              | -1.84        |
| episodes                | 524          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 52201        |
| policy_loss             | -0.88633215  |
| qf1_loss                | 0.0077390294 |
| qf2_loss                | 0.0072293407 |
| time_elapsed            | 252          |
| total timesteps         | 52300        |
| value_loss              | 0.0010313981 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020558261  |
| ent_coef_loss           | -5.2610836    |
| entropy                 | 1.9789829     |
| ep_rewmean              | -1.87         |
| episodes                | 528           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 52601         |
| policy_loss             | -0.83491474   |
| qf1_loss                | 0.01394674    |
| qf2_loss                | 0.014746205   |
| time_elapsed            | 254           |
| total timesteps         | 52700         |
| value_loss              | 0.00042290433 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019135516  |
| ent_coef_loss           | 5.2909775     |
| entropy                 | 1.6372852     |
| ep_rewmean              | -1.86         |
| episodes                | 532           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 53001         |
| policy_loss             | -0.7511186    |
| qf1_loss                | 0.0026189457  |
| qf2_loss                | 0.0023234554  |
| time_elapsed            | 255           |
| total timesteps         | 53100         |
| value_loss              | 0.00035263374 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017210915  |
| ent_coef_loss           | -6.1251373    |
| entropy                 | 1.1201968     |
| ep_rewmean              | -1.83         |
| episodes                | 536           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 53401         |
| policy_loss             | -0.69048035   |
| qf1_loss                | 0.009831247   |
| qf2_loss                | 0.009133691   |
| time_elapsed            | 257           |
| total timesteps         | 53500         |
| value_loss              | 0.00050338946 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016882685 |
| ent_coef_loss           | 2.9171343    |
| entropy                 | 2.1253316    |
| ep_rewmean              | -1.82        |
| episodes                | 540          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 53801        |
| policy_loss             | -0.63220495  |
| qf1_loss                | 0.005107708  |
| qf2_loss                | 0.0050537693 |
| time_elapsed            | 259          |
| total timesteps         | 53900        |
| value_loss              | 0.0004563359 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016963413  |
| ent_coef_loss           | -2.6786554    |
| entropy                 | 2.2024515     |
| ep_rewmean              | -1.84         |
| episodes                | 544           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 54201         |
| policy_loss             | -0.59333235   |
| qf1_loss                | 0.0002781026  |
| qf2_loss                | 0.00028635323 |
| time_elapsed            | 261           |
| total timesteps         | 54300         |
| value_loss              | 0.00029107978 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001618478   |
| ent_coef_loss           | -7.446454     |
| entropy                 | 2.148881      |
| ep_rewmean              | -1.86         |
| episodes                | 548           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 54601         |
| policy_loss             | -0.53408694   |
| qf1_loss                | 0.00027160317 |
| qf2_loss                | 0.0003648791  |
| time_elapsed            | 263           |
| total timesteps         | 54700         |
| value_loss              | 0.00037702607 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014723121  |
| ent_coef_loss           | -6.6121607    |
| entropy                 | 1.7577493     |
| ep_rewmean              | -1.86         |
| episodes                | 552           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 55001         |
| policy_loss             | -0.4972037    |
| qf1_loss                | 0.0021696643  |
| qf2_loss                | 0.0021751993  |
| time_elapsed            | 265           |
| total timesteps         | 55100         |
| value_loss              | 0.00030366692 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013229597 |
| ent_coef_loss           | -1.6108298   |
| entropy                 | 1.8357811    |
| ep_rewmean              | -1.87        |
| episodes                | 556          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 55401        |
| policy_loss             | -0.40595144  |
| qf1_loss                | 0.001279979  |
| qf2_loss                | 0.0013690133 |
| time_elapsed            | 267          |
| total timesteps         | 55500        |
| value_loss              | 0.0002445135 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012072728  |
| ent_coef_loss           | -5.6510186    |
| entropy                 | 2.0087395     |
| ep_rewmean              | -1.85         |
| episodes                | 560           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 55801         |
| policy_loss             | -0.35695344   |
| qf1_loss                | 0.00011758275 |
| qf2_loss                | 0.00016096466 |
| time_elapsed            | 269           |
| total timesteps         | 55900         |
| value_loss              | 0.00020762347 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011400498 |
| ent_coef_loss           | -2.1506476   |
| entropy                 | 1.3372316    |
| ep_rewmean              | -1.91        |
| episodes                | 564          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 56201        |
| policy_loss             | -0.33152896  |
| qf1_loss                | 0.0012456228 |
| qf2_loss                | 0.001407897  |
| time_elapsed            | 271          |
| total timesteps         | 56300        |
| value_loss              | 0.000344628  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011032326 |
| ent_coef_loss           | -6.1390924   |
| entropy                 | 1.6644647    |
| ep_rewmean              | -1.87        |
| episodes                | 568          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 56601        |
| policy_loss             | -0.25913304  |
| qf1_loss                | 0.0006034964 |
| qf2_loss                | 0.0007177621 |
| time_elapsed            | 273          |
| total timesteps         | 56700        |
| value_loss              | 0.0002462577 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0011527169   |
| ent_coef_loss           | 5.4574943      |
| entropy                 | 1.9855682      |
| ep_rewmean              | -1.85          |
| episodes                | 572            |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -1.8           |
| n_updates               | 57001          |
| policy_loss             | -0.18247311    |
| qf1_loss                | 0.00029542818  |
| qf2_loss                | 0.00039003522  |
| time_elapsed            | 275            |
| total timesteps         | 57100          |
| value_loss              | 0.000106283434 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011520954  |
| ent_coef_loss           | -4.995197     |
| entropy                 | 2.1442614     |
| ep_rewmean              | -1.78         |
| episodes                | 576           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 57401         |
| policy_loss             | -0.13055043   |
| qf1_loss                | 0.00019188665 |
| qf2_loss                | 0.0001820178  |
| time_elapsed            | 276           |
| total timesteps         | 57500         |
| value_loss              | 0.00014015009 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0010755544   |
| ent_coef_loss           | -2.8128645     |
| entropy                 | 2.4328756      |
| ep_rewmean              | -1.76          |
| episodes                | 580            |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -1.8           |
| n_updates               | 57801          |
| policy_loss             | -0.0911847     |
| qf1_loss                | 0.000117061165 |
| qf2_loss                | 9.508276e-05   |
| time_elapsed            | 278            |
| total timesteps         | 57900          |
| value_loss              | 0.0003250275   |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0009735603   |
| ent_coef_loss           | -4.9692545     |
| entropy                 | 2.0553794      |
| ep_rewmean              | -1.68          |
| episodes                | 584            |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -1.7           |
| n_updates               | 58201          |
| policy_loss             | -0.045467712   |
| qf1_loss                | 0.00010219731  |
| qf2_loss                | 0.000115716975 |
| time_elapsed            | 280            |
| total timesteps         | 58300          |
| value_loss              | 8.927548e-05   |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008960313  |
| ent_coef_loss           | 1.2438588     |
| entropy                 | 2.1191003     |
| ep_rewmean              | -1.7          |
| episodes                | 588           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 58601         |
| policy_loss             | -0.014933403  |
| qf1_loss                | 0.0005413281  |
| qf2_loss                | 0.0004149974  |
| time_elapsed            | 282           |
| total timesteps         | 58700         |
| value_loss              | 0.00011744051 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008543889  |
| ent_coef_loss           | -3.3158863    |
| entropy                 | 1.9164534     |
| ep_rewmean              | -1.72         |
| episodes                | 592           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 59001         |
| policy_loss             | 0.03678672    |
| qf1_loss                | 0.00010363045 |
| qf2_loss                | 9.5334435e-05 |
| time_elapsed            | 284           |
| total timesteps         | 59100         |
| value_loss              | 0.0001634518  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008529776  |
| ent_coef_loss           | 3.252711      |
| entropy                 | 2.639336      |
| ep_rewmean              | -1.77         |
| episodes                | 596           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 59401         |
| policy_loss             | 0.060046766   |
| qf1_loss                | 9.744426e-05  |
| qf2_loss                | 9.464527e-05  |
| time_elapsed            | 286           |
| total timesteps         | 59500         |
| value_loss              | 0.00017078665 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009172888  |
| ent_coef_loss           | 10.98303      |
| entropy                 | 2.7265234     |
| ep_rewmean              | -1.78         |
| episodes                | 600           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 59801         |
| policy_loss             | 0.083183184   |
| qf1_loss                | 0.00010142689 |
| qf2_loss                | 8.355373e-05  |
| time_elapsed            | 288           |
| total timesteps         | 59900         |
| value_loss              | 0.00020854236 |
-------------------------------------------
Eval num_timesteps=60000, episode_reward=-2.28 +/- 0.89
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0009484243 |
| ent_coef_loss           | -10.134127   |
| entropy                 | 4.0508986    |
| ep_rewmean              | -1.77        |
| episodes                | 604          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 60201        |
| policy_loss             | 0.122085795  |
| qf1_loss                | 0.0001812625 |
| qf2_loss                | 0.0002311599 |
| time_elapsed            | 290          |
| total timesteps         | 60300        |
| value_loss              | 0.0012049407 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009652151  |
| ent_coef_loss           | 7.883235      |
| entropy                 | 2.9985297     |
| ep_rewmean              | -1.8          |
| episodes                | 608           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 60601         |
| policy_loss             | 0.16259786    |
| qf1_loss                | 0.0001312866  |
| qf2_loss                | 0.00012444789 |
| time_elapsed            | 292           |
| total timesteps         | 60700         |
| value_loss              | 0.00056402094 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010629615  |
| ent_coef_loss           | 14.123299     |
| entropy                 | 3.169206      |
| ep_rewmean              | -1.82         |
| episodes                | 612           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 61001         |
| policy_loss             | 0.19255134    |
| qf1_loss                | 0.0002092441  |
| qf2_loss                | 0.00016758734 |
| time_elapsed            | 294           |
| total timesteps         | 61100         |
| value_loss              | 0.0006469113  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012162514  |
| ent_coef_loss           | 7.3906193     |
| entropy                 | 2.6553926     |
| ep_rewmean              | -1.82         |
| episodes                | 616           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 61401         |
| policy_loss             | 0.2237904     |
| qf1_loss                | 0.00028671327 |
| qf2_loss                | 0.00022972672 |
| time_elapsed            | 296           |
| total timesteps         | 61500         |
| value_loss              | 0.0009033674  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013776027  |
| ent_coef_loss           | 8.868595      |
| entropy                 | 2.8563564     |
| ep_rewmean              | -1.82         |
| episodes                | 620           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 61801         |
| policy_loss             | 0.2649784     |
| qf1_loss                | 0.0005105162  |
| qf2_loss                | 0.00042444046 |
| time_elapsed            | 298           |
| total timesteps         | 61900         |
| value_loss              | 0.0009296384  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014260052  |
| ent_coef_loss           | -12.338484    |
| entropy                 | 3.0944557     |
| ep_rewmean              | -1.85         |
| episodes                | 624           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 62201         |
| policy_loss             | 0.32063636    |
| qf1_loss                | 0.00018806022 |
| qf2_loss                | 0.00019373352 |
| time_elapsed            | 300           |
| total timesteps         | 62300         |
| value_loss              | 0.0002788433  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013627295  |
| ent_coef_loss           | -10.879285    |
| entropy                 | 2.218515      |
| ep_rewmean              | -1.85         |
| episodes                | 628           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 62601         |
| policy_loss             | 0.3478315     |
| qf1_loss                | 0.00028178736 |
| qf2_loss                | 0.00020765317 |
| time_elapsed            | 302           |
| total timesteps         | 62700         |
| value_loss              | 0.00017612986 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012720879  |
| ent_coef_loss           | -6.1099973    |
| entropy                 | 1.9453373     |
| ep_rewmean              | -1.83         |
| episodes                | 632           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 63001         |
| policy_loss             | 0.39753133    |
| qf1_loss                | 0.00028007914 |
| qf2_loss                | 0.00028825336 |
| time_elapsed            | 303           |
| total timesteps         | 63100         |
| value_loss              | 0.00029057407 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011496287  |
| ent_coef_loss           | -11.495656    |
| entropy                 | 1.5301657     |
| ep_rewmean              | -1.88         |
| episodes                | 636           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 63401         |
| policy_loss             | 0.41754147    |
| qf1_loss                | 0.0017395482  |
| qf2_loss                | 0.0015594502  |
| time_elapsed            | 305           |
| total timesteps         | 63500         |
| value_loss              | 0.00016294251 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010764503  |
| ent_coef_loss           | -7.953615     |
| entropy                 | 2.5707653     |
| ep_rewmean              | -1.92         |
| episodes                | 640           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 63801         |
| policy_loss             | 0.43644583    |
| qf1_loss                | 0.00028563588 |
| qf2_loss                | 0.00038646616 |
| time_elapsed            | 307           |
| total timesteps         | 63900         |
| value_loss              | 0.00028055345 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010038606  |
| ent_coef_loss           | 4.5685186     |
| entropy                 | 2.1842186     |
| ep_rewmean              | -1.89         |
| episodes                | 644           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 64201         |
| policy_loss             | 0.43282002    |
| qf1_loss                | 0.0022447247  |
| qf2_loss                | 0.0024245437  |
| time_elapsed            | 309           |
| total timesteps         | 64300         |
| value_loss              | 0.00039247243 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009762152  |
| ent_coef_loss           | 6.047046      |
| entropy                 | 1.9400356     |
| ep_rewmean              | -1.9          |
| episodes                | 648           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 64601         |
| policy_loss             | 0.4499982     |
| qf1_loss                | 0.0036206446  |
| qf2_loss                | 0.0036877627  |
| time_elapsed            | 311           |
| total timesteps         | 64700         |
| value_loss              | 0.00055488304 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00096526067 |
| ent_coef_loss           | 3.3004375     |
| entropy                 | 2.9786875     |
| ep_rewmean              | -1.9          |
| episodes                | 652           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 65001         |
| policy_loss             | 0.42937106    |
| qf1_loss                | 0.0021723167  |
| qf2_loss                | 0.0020296269  |
| time_elapsed            | 313           |
| total timesteps         | 65100         |
| value_loss              | 0.0001776813  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010251465  |
| ent_coef_loss           | -2.6931872    |
| entropy                 | 3.1855211     |
| ep_rewmean              | -1.94         |
| episodes                | 656           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 65401         |
| policy_loss             | 0.42961013    |
| qf1_loss                | 0.0015095049  |
| qf2_loss                | 0.0016287128  |
| time_elapsed            | 315           |
| total timesteps         | 65500         |
| value_loss              | 0.00022771122 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010541696  |
| ent_coef_loss           | 8.095209      |
| entropy                 | 2.7735014     |
| ep_rewmean              | -2.07         |
| episodes                | 660           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 65801         |
| policy_loss             | 0.4309616     |
| qf1_loss                | 0.00040766786 |
| qf2_loss                | 0.0003926142  |
| time_elapsed            | 317           |
| total timesteps         | 65900         |
| value_loss              | 0.00045775197 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000989293   |
| ent_coef_loss           | -6.855316     |
| entropy                 | 1.5938059     |
| ep_rewmean              | -2.1          |
| episodes                | 664           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 66201         |
| policy_loss             | 0.4603178     |
| qf1_loss                | 0.00020061203 |
| qf2_loss                | 0.00022193299 |
| time_elapsed            | 319           |
| total timesteps         | 66300         |
| value_loss              | 9.03481e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009996118  |
| ent_coef_loss           | 4.5684776     |
| entropy                 | 1.6937535     |
| ep_rewmean              | -2.11         |
| episodes                | 668           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 66601         |
| policy_loss             | 0.4609776     |
| qf1_loss                | 0.0023242997  |
| qf2_loss                | 0.0022344713  |
| time_elapsed            | 321           |
| total timesteps         | 66700         |
| value_loss              | 0.00061681087 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010145191  |
| ent_coef_loss           | -14.902426    |
| entropy                 | 1.7844033     |
| ep_rewmean              | -2.13         |
| episodes                | 672           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 67001         |
| policy_loss             | 0.49410126    |
| qf1_loss                | 0.00016394936 |
| qf2_loss                | 0.00013475615 |
| time_elapsed            | 323           |
| total timesteps         | 67100         |
| value_loss              | 0.00012496703 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009826681  |
| ent_coef_loss           | 5.452897      |
| entropy                 | 1.4345078     |
| ep_rewmean              | -2.17         |
| episodes                | 676           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 67401         |
| policy_loss             | 0.49222913    |
| qf1_loss                | 0.0017843342  |
| qf2_loss                | 0.0019068624  |
| time_elapsed            | 325           |
| total timesteps         | 67500         |
| value_loss              | 0.00012610297 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009816317  |
| ent_coef_loss           | -6.1839323    |
| entropy                 | 2.0942965     |
| ep_rewmean              | -2.2          |
| episodes                | 680           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 67801         |
| policy_loss             | 0.51783365    |
| qf1_loss                | 0.0016865821  |
| qf2_loss                | 0.0017616531  |
| time_elapsed            | 326           |
| total timesteps         | 67900         |
| value_loss              | 0.00011090577 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00094493665 |
| ent_coef_loss           | -4.535009     |
| entropy                 | 1.968632      |
| ep_rewmean              | -2.25         |
| episodes                | 684           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 68201         |
| policy_loss             | 0.5089469     |
| qf1_loss                | 0.00019892797 |
| qf2_loss                | 0.00019983915 |
| time_elapsed            | 328           |
| total timesteps         | 68300         |
| value_loss              | 0.00020560052 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00086514145 |
| ent_coef_loss           | -9.427557     |
| entropy                 | 1.2093027     |
| ep_rewmean              | -2.25         |
| episodes                | 688           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 68601         |
| policy_loss             | 0.53138834    |
| qf1_loss                | 0.00018509815 |
| qf2_loss                | 0.00014255958 |
| time_elapsed            | 330           |
| total timesteps         | 68700         |
| value_loss              | 0.00019912064 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0007740983 |
| ent_coef_loss           | -5.1713476   |
| entropy                 | 0.88574255   |
| ep_rewmean              | -2.22        |
| episodes                | 692          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 69001        |
| policy_loss             | 0.5614297    |
| qf1_loss                | 0.0028443818 |
| qf2_loss                | 0.0028008323 |
| time_elapsed            | 332          |
| total timesteps         | 69100        |
| value_loss              | 0.0014290636 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00076939276 |
| ent_coef_loss           | 4.085717      |
| entropy                 | 1.3804111     |
| ep_rewmean              | -2.17         |
| episodes                | 696           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 69401         |
| policy_loss             | 0.5424944     |
| qf1_loss                | 0.002403847   |
| qf2_loss                | 0.0023202635  |
| time_elapsed            | 334           |
| total timesteps         | 69500         |
| value_loss              | 0.00031101942 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007646899  |
| ent_coef_loss           | 1.5101964     |
| entropy                 | 1.501231      |
| ep_rewmean              | -2.16         |
| episodes                | 700           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 69801         |
| policy_loss             | 0.5039478     |
| qf1_loss                | 0.0030016582  |
| qf2_loss                | 0.0030751312  |
| time_elapsed            | 336           |
| total timesteps         | 69900         |
| value_loss              | 0.00021451048 |
-------------------------------------------
Eval num_timesteps=70000, episode_reward=-4.29 +/- 1.95
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0008515281 |
| ent_coef_loss           | 3.0776396    |
| entropy                 | 2.341551     |
| ep_rewmean              | -2.28        |
| episodes                | 704          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 70201        |
| policy_loss             | 0.53076535   |
| qf1_loss                | 0.001761346  |
| qf2_loss                | 0.0016994239 |
| time_elapsed            | 338          |
| total timesteps         | 70300        |
| value_loss              | 0.0006760999 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0008450763 |
| ent_coef_loss           | 3.0293124    |
| entropy                 | 1.8530116    |
| ep_rewmean              | -2.3         |
| episodes                | 708          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 70601        |
| policy_loss             | 0.48485935   |
| qf1_loss                | 0.0018006554 |
| qf2_loss                | 0.0018644535 |
| time_elapsed            | 340          |
| total timesteps         | 70700        |
| value_loss              | 7.157924e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00081683684 |
| ent_coef_loss           | 3.8445764     |
| entropy                 | 1.406048      |
| ep_rewmean              | -2.29         |
| episodes                | 712           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 71001         |
| policy_loss             | 0.4815675     |
| qf1_loss                | 0.0002231192  |
| qf2_loss                | 0.00018232384 |
| time_elapsed            | 342           |
| total timesteps         | 71100         |
| value_loss              | 0.00017080753 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000797717   |
| ent_coef_loss           | 7.503278      |
| entropy                 | 1.158407      |
| ep_rewmean              | -2.38         |
| episodes                | 716           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 71401         |
| policy_loss             | 0.48389643    |
| qf1_loss                | 0.00014521452 |
| qf2_loss                | 0.00012766359 |
| time_elapsed            | 344           |
| total timesteps         | 71500         |
| value_loss              | 9.290518e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00078311743 |
| ent_coef_loss           | -6.2927256    |
| entropy                 | 0.92390764    |
| ep_rewmean              | -2.41         |
| episodes                | 720           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 71801         |
| policy_loss             | 0.50211644    |
| qf1_loss                | 0.00015691895 |
| qf2_loss                | 0.00013595785 |
| time_elapsed            | 346           |
| total timesteps         | 71900         |
| value_loss              | 0.0001386095  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007489021  |
| ent_coef_loss           | 6.2163563     |
| entropy                 | 1.3108763     |
| ep_rewmean              | -2.37         |
| episodes                | 724           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 72201         |
| policy_loss             | 0.50604343    |
| qf1_loss                | 0.00014113073 |
| qf2_loss                | 0.00012649628 |
| time_elapsed            | 348           |
| total timesteps         | 72300         |
| value_loss              | 8.7547436e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0007549576 |
| ent_coef_loss           | 5.187097     |
| entropy                 | 0.56994545   |
| ep_rewmean              | -2.38        |
| episodes                | 728          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.4         |
| n_updates               | 72601        |
| policy_loss             | 0.48282498   |
| qf1_loss                | 0.0021927825 |
| qf2_loss                | 0.0021570495 |
| time_elapsed            | 350          |
| total timesteps         | 72700        |
| value_loss              | 5.059685e-05 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0008037091 |
| ent_coef_loss           | 8.181877     |
| entropy                 | 1.2729006    |
| ep_rewmean              | -2.46        |
| episodes                | 732          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.5         |
| n_updates               | 73001        |
| policy_loss             | 0.47536594   |
| qf1_loss                | 0.008508252  |
| qf2_loss                | 0.007877877  |
| time_elapsed            | 352          |
| total timesteps         | 73100        |
| value_loss              | 0.0006306948 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00087462267 |
| ent_coef_loss           | 5.017663      |
| entropy                 | 1.8481834     |
| ep_rewmean              | -2.57         |
| episodes                | 736           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 73401         |
| policy_loss             | 0.45946378    |
| qf1_loss                | 0.0002732759  |
| qf2_loss                | 0.0002566944  |
| time_elapsed            | 353           |
| total timesteps         | 73500         |
| value_loss              | 8.0865895e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008888201  |
| ent_coef_loss           | 4.7389803     |
| entropy                 | 1.2077622     |
| ep_rewmean              | -2.56         |
| episodes                | 740           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 73801         |
| policy_loss             | 0.47430938    |
| qf1_loss                | 0.00013458538 |
| qf2_loss                | 0.00012420618 |
| time_elapsed            | 355           |
| total timesteps         | 73900         |
| value_loss              | 6.415887e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008586807  |
| ent_coef_loss           | -1.6131583    |
| entropy                 | 0.38537169    |
| ep_rewmean              | -2.64         |
| episodes                | 744           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 74201         |
| policy_loss             | 0.4761797     |
| qf1_loss                | 0.00020098922 |
| qf2_loss                | 0.00011727053 |
| time_elapsed            | 357           |
| total timesteps         | 74300         |
| value_loss              | 0.00014605028 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008615849  |
| ent_coef_loss           | -3.4232757    |
| entropy                 | 0.34842306    |
| ep_rewmean              | -2.63         |
| episodes                | 748           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 74601         |
| policy_loss             | 0.4931976     |
| qf1_loss                | 0.00020361942 |
| qf2_loss                | 0.0001909534  |
| time_elapsed            | 359           |
| total timesteps         | 74700         |
| value_loss              | 0.00012687861 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00092264195 |
| ent_coef_loss           | -0.6203356    |
| entropy                 | 0.4870137     |
| ep_rewmean              | -2.7          |
| episodes                | 752           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.7          |
| n_updates               | 75001         |
| policy_loss             | 0.49182665    |
| qf1_loss                | 0.00013742177 |
| qf2_loss                | 0.00013032311 |
| time_elapsed            | 361           |
| total timesteps         | 75100         |
| value_loss              | 0.00023671534 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009931328  |
| ent_coef_loss           | -8.186904     |
| entropy                 | 1.4554104     |
| ep_rewmean              | -2.74         |
| episodes                | 756           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.7          |
| n_updates               | 75401         |
| policy_loss             | 0.5160643     |
| qf1_loss                | 0.0028202452  |
| qf2_loss                | 0.0027295896  |
| time_elapsed            | 363           |
| total timesteps         | 75500         |
| value_loss              | 0.00016046644 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000968336   |
| ent_coef_loss           | -2.7927725    |
| entropy                 | 0.8459885     |
| ep_rewmean              | -2.62         |
| episodes                | 760           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 75801         |
| policy_loss             | 0.5061269     |
| qf1_loss                | 0.002387882   |
| qf2_loss                | 0.0024497504  |
| time_elapsed            | 365           |
| total timesteps         | 75900         |
| value_loss              | 0.00041549982 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00096838176 |
| ent_coef_loss           | -1.6560869    |
| entropy                 | 0.14401948    |
| ep_rewmean              | -2.55         |
| episodes                | 764           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 76201         |
| policy_loss             | 0.51693165    |
| qf1_loss                | 0.00012661195 |
| qf2_loss                | 0.00012685126 |
| time_elapsed            | 367           |
| total timesteps         | 76300         |
| value_loss              | 6.935556e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010200008  |
| ent_coef_loss           | 7.8823743     |
| entropy                 | 0.82828194    |
| ep_rewmean              | -2.5          |
| episodes                | 768           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 76601         |
| policy_loss             | 0.5150554     |
| qf1_loss                | 0.00021763997 |
| qf2_loss                | 0.00017363208 |
| time_elapsed            | 369           |
| total timesteps         | 76700         |
| value_loss              | 0.00021959649 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001073116   |
| ent_coef_loss           | -0.9703183    |
| entropy                 | 1.0691572     |
| ep_rewmean              | -2.47         |
| episodes                | 772           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 77001         |
| policy_loss             | 0.51767004    |
| qf1_loss                | 0.0018940682  |
| qf2_loss                | 0.0019792605  |
| time_elapsed            | 371           |
| total timesteps         | 77100         |
| value_loss              | 0.00015031763 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011476284  |
| ent_coef_loss           | 4.882786      |
| entropy                 | 1.6897976     |
| ep_rewmean              | -2.43         |
| episodes                | 776           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 77401         |
| policy_loss             | 0.5473294     |
| qf1_loss                | 0.00027534412 |
| qf2_loss                | 0.00023521806 |
| time_elapsed            | 373           |
| total timesteps         | 77500         |
| value_loss              | 7.520833e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012977462  |
| ent_coef_loss           | 2.3251956     |
| entropy                 | 1.7736012     |
| ep_rewmean              | -2.4          |
| episodes                | 780           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 77801         |
| policy_loss             | 0.5356405     |
| qf1_loss                | 0.00027908132 |
| qf2_loss                | 0.00024843094 |
| time_elapsed            | 375           |
| total timesteps         | 77900         |
| value_loss              | 8.1797894e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013692181  |
| ent_coef_loss           | 6.729265      |
| entropy                 | 1.5043548     |
| ep_rewmean              | -2.41         |
| episodes                | 784           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 78201         |
| policy_loss             | 0.5373422     |
| qf1_loss                | 0.0001888418  |
| qf2_loss                | 0.00018273824 |
| time_elapsed            | 376           |
| total timesteps         | 78300         |
| value_loss              | 8.771785e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013735661  |
| ent_coef_loss           | -8.018762     |
| entropy                 | 2.6182797     |
| ep_rewmean              | -2.42         |
| episodes                | 788           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 78601         |
| policy_loss             | 0.5530281     |
| qf1_loss                | 0.003480114   |
| qf2_loss                | 0.0032380156  |
| time_elapsed            | 378           |
| total timesteps         | 78700         |
| value_loss              | 0.00023078747 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013396378  |
| ent_coef_loss           | -4.899615     |
| entropy                 | 2.1709208     |
| ep_rewmean              | -2.44         |
| episodes                | 792           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 79001         |
| policy_loss             | 0.57525885    |
| qf1_loss                | 0.0001628832  |
| qf2_loss                | 0.00015193546 |
| time_elapsed            | 380           |
| total timesteps         | 79100         |
| value_loss              | 0.00010942738 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012880414  |
| ent_coef_loss           | -7.2129755    |
| entropy                 | 1.9328618     |
| ep_rewmean              | -2.41         |
| episodes                | 796           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 79401         |
| policy_loss             | 0.55602133    |
| qf1_loss                | 0.00036791194 |
| qf2_loss                | 0.00042185906 |
| time_elapsed            | 382           |
| total timesteps         | 79500         |
| value_loss              | 0.00037911415 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001186605   |
| ent_coef_loss           | 4.4149556     |
| entropy                 | 1.6777124     |
| ep_rewmean              | -2.43         |
| episodes                | 800           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 79801         |
| policy_loss             | 0.54551953    |
| qf1_loss                | 0.00032496778 |
| qf2_loss                | 0.000240252   |
| time_elapsed            | 384           |
| total timesteps         | 79900         |
| value_loss              | 0.00012961804 |
-------------------------------------------
Eval num_timesteps=80000, episode_reward=-1.23 +/- 0.78
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011130847  |
| ent_coef_loss           | -7.370098     |
| entropy                 | 0.81413937    |
| ep_rewmean              | -2.38         |
| episodes                | 804           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 80201         |
| policy_loss             | 0.57422876    |
| qf1_loss                | 0.00028061203 |
| qf2_loss                | 0.00023401093 |
| time_elapsed            | 386           |
| total timesteps         | 80300         |
| value_loss              | 7.170753e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011755134 |
| ent_coef_loss           | 6.343443     |
| entropy                 | 2.3105385    |
| ep_rewmean              | -2.34        |
| episodes                | 808          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 80601        |
| policy_loss             | 0.61254674   |
| qf1_loss                | 0.0029423255 |
| qf2_loss                | 0.0029526204 |
| time_elapsed            | 388          |
| total timesteps         | 80700        |
| value_loss              | 0.0005041767 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012727323  |
| ent_coef_loss           | -1.0844786    |
| entropy                 | 1.8490125     |
| ep_rewmean              | -2.33         |
| episodes                | 812           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 81001         |
| policy_loss             | 0.57997644    |
| qf1_loss                | 0.0036651506  |
| qf2_loss                | 0.0036473214  |
| time_elapsed            | 390           |
| total timesteps         | 81100         |
| value_loss              | 0.00022473518 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011790235  |
| ent_coef_loss           | 5.126727      |
| entropy                 | 1.0885887     |
| ep_rewmean              | -2.25         |
| episodes                | 816           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 81401         |
| policy_loss             | 0.56838393    |
| qf1_loss                | 0.002418602   |
| qf2_loss                | 0.0025559154  |
| time_elapsed            | 392           |
| total timesteps         | 81500         |
| value_loss              | 0.00030499222 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011094555  |
| ent_coef_loss           | 0.6636174     |
| entropy                 | 1.2851069     |
| ep_rewmean              | -2.27         |
| episodes                | 820           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 81801         |
| policy_loss             | 0.59353924    |
| qf1_loss                | 0.0031723992  |
| qf2_loss                | 0.0032169092  |
| time_elapsed            | 394           |
| total timesteps         | 81900         |
| value_loss              | 0.00012388738 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001189557  |
| ent_coef_loss           | 14.736277    |
| entropy                 | 1.5979488    |
| ep_rewmean              | -2.25        |
| episodes                | 824          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 82201        |
| policy_loss             | 0.6093824    |
| qf1_loss                | 0.0030854247 |
| qf2_loss                | 0.0029235599 |
| time_elapsed            | 396          |
| total timesteps         | 82300        |
| value_loss              | 0.0002000569 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011463509  |
| ent_coef_loss           | -1.4135392    |
| entropy                 | -0.050689027  |
| ep_rewmean              | -2.26         |
| episodes                | 828           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 82601         |
| policy_loss             | 0.5790297     |
| qf1_loss                | 0.0051443367  |
| qf2_loss                | 0.005088067   |
| time_elapsed            | 398           |
| total timesteps         | 82700         |
| value_loss              | 0.00022240028 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010652164  |
| ent_coef_loss           | 4.486297      |
| entropy                 | 0.024906926   |
| ep_rewmean              | -2.21         |
| episodes                | 832           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 83001         |
| policy_loss             | 0.6054505     |
| qf1_loss                | 0.002390991   |
| qf2_loss                | 0.002446718   |
| time_elapsed            | 399           |
| total timesteps         | 83100         |
| value_loss              | 0.00014488696 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010451728  |
| ent_coef_loss           | -4.840489     |
| entropy                 | -0.32031205   |
| ep_rewmean              | -2.1          |
| episodes                | 836           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 83401         |
| policy_loss             | 0.5994952     |
| qf1_loss                | 0.0031922753  |
| qf2_loss                | 0.0032229654  |
| time_elapsed            | 401           |
| total timesteps         | 83500         |
| value_loss              | 0.00036036316 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0009805792   |
| ent_coef_loss           | 10.772177      |
| entropy                 | 0.335198       |
| ep_rewmean              | -2.06          |
| episodes                | 840            |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -2.1           |
| n_updates               | 83801          |
| policy_loss             | 0.6138112      |
| qf1_loss                | 0.00017255197  |
| qf2_loss                | 0.0001769541   |
| time_elapsed            | 403            |
| total timesteps         | 83900          |
| value_loss              | 0.000117038304 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010616805  |
| ent_coef_loss           | 8.289149      |
| entropy                 | 1.0844837     |
| ep_rewmean              | -1.99         |
| episodes                | 844           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 84201         |
| policy_loss             | 0.6065842     |
| qf1_loss                | 0.0028895906  |
| qf2_loss                | 0.0029993884  |
| time_elapsed            | 405           |
| total timesteps         | 84300         |
| value_loss              | 0.00016828915 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011628885  |
| ent_coef_loss           | 1.3889704     |
| entropy                 | 1.9473951     |
| ep_rewmean              | -2            |
| episodes                | 848           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 84601         |
| policy_loss             | 0.5947689     |
| qf1_loss                | 0.00017401678 |
| qf2_loss                | 0.00015753298 |
| time_elapsed            | 407           |
| total timesteps         | 84700         |
| value_loss              | 0.00012707741 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012165013 |
| ent_coef_loss           | -2.2212226   |
| entropy                 | 1.1534034    |
| ep_rewmean              | -1.98        |
| episodes                | 852          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 85001        |
| policy_loss             | 0.556008     |
| qf1_loss                | 0.0025371092 |
| qf2_loss                | 0.0025534749 |
| time_elapsed            | 409          |
| total timesteps         | 85100        |
| value_loss              | 0.000615721  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012465755  |
| ent_coef_loss           | -2.0296645    |
| entropy                 | 1.2226789     |
| ep_rewmean              | -1.92         |
| episodes                | 856           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 85401         |
| policy_loss             | 0.56413937    |
| qf1_loss                | 0.00028053913 |
| qf2_loss                | 0.00025763205 |
| time_elapsed            | 411           |
| total timesteps         | 85500         |
| value_loss              | 0.00014025928 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001312862   |
| ent_coef_loss           | 1.618651      |
| entropy                 | 1.29438       |
| ep_rewmean              | -1.96         |
| episodes                | 860           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 85801         |
| policy_loss             | 0.56890154    |
| qf1_loss                | 0.00338478    |
| qf2_loss                | 0.0035838939  |
| time_elapsed            | 413           |
| total timesteps         | 85900         |
| value_loss              | 0.00016846837 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013049201  |
| ent_coef_loss           | -7.633933     |
| entropy                 | 1.8066097     |
| ep_rewmean              | -1.97         |
| episodes                | 864           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 86201         |
| policy_loss             | 0.56276435    |
| qf1_loss                | 0.00013647639 |
| qf2_loss                | 0.00013307076 |
| time_elapsed            | 415           |
| total timesteps         | 86300         |
| value_loss              | 0.00012376471 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012687483  |
| ent_coef_loss           | 1.3988008     |
| entropy                 | 1.8245226     |
| ep_rewmean              | -2.07         |
| episodes                | 868           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 86601         |
| policy_loss             | 0.5478908     |
| qf1_loss                | 0.00012700965 |
| qf2_loss                | 0.0001190005  |
| time_elapsed            | 417           |
| total timesteps         | 86700         |
| value_loss              | 0.0002493692  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001270736   |
| ent_coef_loss           | -0.97362417   |
| entropy                 | 2.0412564     |
| ep_rewmean              | -2.07         |
| episodes                | 872           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 87001         |
| policy_loss             | 0.5336652     |
| qf1_loss                | 0.0001562603  |
| qf2_loss                | 0.00019202309 |
| time_elapsed            | 419           |
| total timesteps         | 87100         |
| value_loss              | 0.00022246287 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012406036  |
| ent_coef_loss           | 8.475264      |
| entropy                 | 0.4580766     |
| ep_rewmean              | -2.08         |
| episodes                | 876           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 87401         |
| policy_loss             | 0.52088636    |
| qf1_loss                | 0.0022037975  |
| qf2_loss                | 0.0023448414  |
| time_elapsed            | 420           |
| total timesteps         | 87500         |
| value_loss              | 0.00019584966 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012430776  |
| ent_coef_loss           | 0.9793998     |
| entropy                 | 1.6306344     |
| ep_rewmean              | -2.07         |
| episodes                | 880           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 87801         |
| policy_loss             | 0.533476      |
| qf1_loss                | 0.00014555544 |
| qf2_loss                | 0.00014251386 |
| time_elapsed            | 422           |
| total timesteps         | 87900         |
| value_loss              | 0.0002095995  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012737869  |
| ent_coef_loss           | 3.610589      |
| entropy                 | 1.3092299     |
| ep_rewmean              | -2.08         |
| episodes                | 884           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 88201         |
| policy_loss             | 0.54872763    |
| qf1_loss                | 0.0001936696  |
| qf2_loss                | 0.0002200406  |
| time_elapsed            | 424           |
| total timesteps         | 88300         |
| value_loss              | 0.00021350359 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013010263  |
| ent_coef_loss           | 3.3638406     |
| entropy                 | 1.6977301     |
| ep_rewmean              | -2.03         |
| episodes                | 888           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 88601         |
| policy_loss             | 0.55487645    |
| qf1_loss                | 0.0017628251  |
| qf2_loss                | 0.0016582358  |
| time_elapsed            | 426           |
| total timesteps         | 88700         |
| value_loss              | 0.00036050344 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013048983  |
| ent_coef_loss           | -9.007969     |
| entropy                 | 1.6461358     |
| ep_rewmean              | -2.03         |
| episodes                | 892           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 89001         |
| policy_loss             | 0.5426198     |
| qf1_loss                | 0.00026060344 |
| qf2_loss                | 0.0003099697  |
| time_elapsed            | 428           |
| total timesteps         | 89100         |
| value_loss              | 0.0005024052  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012197873  |
| ent_coef_loss           | -4.8188047    |
| entropy                 | 2.3130264     |
| ep_rewmean              | -2.09         |
| episodes                | 896           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 89401         |
| policy_loss             | 0.5504744     |
| qf1_loss                | 0.00015906776 |
| qf2_loss                | 0.00016007246 |
| time_elapsed            | 430           |
| total timesteps         | 89500         |
| value_loss              | 0.00030932025 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012335639  |
| ent_coef_loss           | 9.93466       |
| entropy                 | 2.8899655     |
| ep_rewmean              | -2.09         |
| episodes                | 900           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 89801         |
| policy_loss             | 0.54692733    |
| qf1_loss                | 0.0002381858  |
| qf2_loss                | 0.00020959237 |
| time_elapsed            | 432           |
| total timesteps         | 89900         |
| value_loss              | 0.0002778843  |
-------------------------------------------
Eval num_timesteps=90000, episode_reward=-1.38 +/- 1.10
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014033916  |
| ent_coef_loss           | 1.0756192     |
| entropy                 | 3.6688976     |
| ep_rewmean              | -2.03         |
| episodes                | 904           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 90201         |
| policy_loss             | 0.554224      |
| qf1_loss                | 0.00012648344 |
| qf2_loss                | 0.00016270694 |
| time_elapsed            | 434           |
| total timesteps         | 90300         |
| value_loss              | 0.00015415243 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014922046  |
| ent_coef_loss           | 1.9601152     |
| entropy                 | 3.540996      |
| ep_rewmean              | -2.02         |
| episodes                | 908           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 90601         |
| policy_loss             | 0.56046164    |
| qf1_loss                | 0.00017442335 |
| qf2_loss                | 0.00014646971 |
| time_elapsed            | 436           |
| total timesteps         | 90700         |
| value_loss              | 0.0001695354  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001540358   |
| ent_coef_loss           | 0.66466546    |
| entropy                 | 3.842699      |
| ep_rewmean              | -2.06         |
| episodes                | 912           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 91001         |
| policy_loss             | 0.5144845     |
| qf1_loss                | 0.00033343246 |
| qf2_loss                | 0.00035474414 |
| time_elapsed            | 438           |
| total timesteps         | 91100         |
| value_loss              | 0.0007039098  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014787542  |
| ent_coef_loss           | 7.3609924     |
| entropy                 | 3.3731036     |
| ep_rewmean              | -2.1          |
| episodes                | 916           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 91401         |
| policy_loss             | 0.5939852     |
| qf1_loss                | 0.00018763484 |
| qf2_loss                | 0.00019237891 |
| time_elapsed            | 440           |
| total timesteps         | 91500         |
| value_loss              | 0.00019967198 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015648195  |
| ent_coef_loss           | 1.1337754     |
| entropy                 | 3.684939      |
| ep_rewmean              | -2.11         |
| episodes                | 920           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 91801         |
| policy_loss             | 0.5686213     |
| qf1_loss                | 0.00012671377 |
| qf2_loss                | 0.00012616008 |
| time_elapsed            | 442           |
| total timesteps         | 91900         |
| value_loss              | 0.00021391132 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0015655562   |
| ent_coef_loss           | -9.487948      |
| entropy                 | 3.6097977      |
| ep_rewmean              | -2.11          |
| episodes                | 924            |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -2.1           |
| n_updates               | 92201          |
| policy_loss             | 0.58242345     |
| qf1_loss                | 0.00018614778  |
| qf2_loss                | 0.000115471965 |
| time_elapsed            | 444            |
| total timesteps         | 92300          |
| value_loss              | 0.00040396093  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014531581  |
| ent_coef_loss           | -6.283143     |
| entropy                 | 3.4242318     |
| ep_rewmean              | -2.19         |
| episodes                | 928           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 92601         |
| policy_loss             | 0.592563      |
| qf1_loss                | 0.0043485505  |
| qf2_loss                | 0.0043836557  |
| time_elapsed            | 446           |
| total timesteps         | 92700         |
| value_loss              | 0.00011490866 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014011443  |
| ent_coef_loss           | -12.228431    |
| entropy                 | 3.3413658     |
| ep_rewmean              | -2.22         |
| episodes                | 932           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 93001         |
| policy_loss             | 0.5963423     |
| qf1_loss                | 0.00015053639 |
| qf2_loss                | 0.00013118974 |
| time_elapsed            | 447           |
| total timesteps         | 93100         |
| value_loss              | 0.00019389809 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013100993  |
| ent_coef_loss           | -4.22207      |
| entropy                 | 3.21415       |
| ep_rewmean              | -2.22         |
| episodes                | 936           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 93401         |
| policy_loss             | 0.58463514    |
| qf1_loss                | 0.00014391664 |
| qf2_loss                | 0.0001358131  |
| time_elapsed            | 449           |
| total timesteps         | 93500         |
| value_loss              | 0.00035211942 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012381929  |
| ent_coef_loss           | 0.5584588     |
| entropy                 | 3.3984818     |
| ep_rewmean              | -2.23         |
| episodes                | 940           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 93801         |
| policy_loss             | 0.61123466    |
| qf1_loss                | 0.00044228908 |
| qf2_loss                | 0.00046222509 |
| time_elapsed            | 451           |
| total timesteps         | 93900         |
| value_loss              | 0.00019526228 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012644818  |
| ent_coef_loss           | -5.996463     |
| entropy                 | 2.9069362     |
| ep_rewmean              | -2.24         |
| episodes                | 944           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 94201         |
| policy_loss             | 0.6185005     |
| qf1_loss                | 0.0032419413  |
| qf2_loss                | 0.0032663627  |
| time_elapsed            | 453           |
| total timesteps         | 94300         |
| value_loss              | 0.00018460475 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012335498  |
| ent_coef_loss           | 4.633212      |
| entropy                 | 2.3919227     |
| ep_rewmean              | -2.23         |
| episodes                | 948           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 94601         |
| policy_loss             | 0.57625914    |
| qf1_loss                | 0.010795958   |
| qf2_loss                | 0.010459903   |
| time_elapsed            | 455           |
| total timesteps         | 94700         |
| value_loss              | 0.00020171404 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012309361  |
| ent_coef_loss           | 5.016607      |
| entropy                 | 2.161819      |
| ep_rewmean              | -2.34         |
| episodes                | 952           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 95001         |
| policy_loss             | 0.5991518     |
| qf1_loss                | 0.00029381725 |
| qf2_loss                | 0.00030819874 |
| time_elapsed            | 457           |
| total timesteps         | 95100         |
| value_loss              | 0.00021761926 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012585016  |
| ent_coef_loss           | 4.541553      |
| entropy                 | 2.60288       |
| ep_rewmean              | -2.36         |
| episodes                | 956           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 95401         |
| policy_loss             | 0.58059895    |
| qf1_loss                | 0.0067571485  |
| qf2_loss                | 0.007085662   |
| time_elapsed            | 459           |
| total timesteps         | 95500         |
| value_loss              | 0.00034472172 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012370091  |
| ent_coef_loss           | 4.656069      |
| entropy                 | 1.3789594     |
| ep_rewmean              | -2.34         |
| episodes                | 960           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 95801         |
| policy_loss             | 0.5934105     |
| qf1_loss                | 0.002623091   |
| qf2_loss                | 0.0026177927  |
| time_elapsed            | 461           |
| total timesteps         | 95900         |
| value_loss              | 0.00015914507 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012576479  |
| ent_coef_loss           | -5.2749906    |
| entropy                 | 1.721672      |
| ep_rewmean              | -2.29         |
| episodes                | 964           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 96201         |
| policy_loss             | 0.5908938     |
| qf1_loss                | 0.0002411219  |
| qf2_loss                | 0.00014329192 |
| time_elapsed            | 463           |
| total timesteps         | 96300         |
| value_loss              | 0.00021932175 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012285039  |
| ent_coef_loss           | 5.9133625     |
| entropy                 | 1.9679029     |
| ep_rewmean              | -2.22         |
| episodes                | 968           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 96601         |
| policy_loss             | 0.5999274     |
| qf1_loss                | 0.00018060523 |
| qf2_loss                | 0.00022417746 |
| time_elapsed            | 465           |
| total timesteps         | 96700         |
| value_loss              | 0.00025197136 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012367159 |
| ent_coef_loss           | -3.6739738   |
| entropy                 | 1.6503325    |
| ep_rewmean              | -2.26        |
| episodes                | 972          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 97001        |
| policy_loss             | 0.61009026   |
| qf1_loss                | 0.002151157  |
| qf2_loss                | 0.0030733251 |
| time_elapsed            | 467          |
| total timesteps         | 97100        |
| value_loss              | 0.0001761006 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011576602  |
| ent_coef_loss           | 9.695145      |
| entropy                 | 1.4451603     |
| ep_rewmean              | -2.27         |
| episodes                | 976           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 97401         |
| policy_loss             | 0.60299075    |
| qf1_loss                | 0.00018710332 |
| qf2_loss                | 0.00017308602 |
| time_elapsed            | 469           |
| total timesteps         | 97500         |
| value_loss              | 0.0002063734  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001149615   |
| ent_coef_loss           | -3.4844706    |
| entropy                 | 1.3466988     |
| ep_rewmean              | -2.32         |
| episodes                | 980           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 97801         |
| policy_loss             | 0.59833217    |
| qf1_loss                | 0.00025557197 |
| qf2_loss                | 0.00022654724 |
| time_elapsed            | 470           |
| total timesteps         | 97900         |
| value_loss              | 0.00016385748 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011258188  |
| ent_coef_loss           | -3.9580173    |
| entropy                 | 1.4219676     |
| ep_rewmean              | -2.31         |
| episodes                | 984           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 98201         |
| policy_loss             | 0.6114162     |
| qf1_loss                | 0.00027386652 |
| qf2_loss                | 0.00022371761 |
| time_elapsed            | 472           |
| total timesteps         | 98300         |
| value_loss              | 0.00016655802 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011716185 |
| ent_coef_loss           | 1.0172997    |
| entropy                 | 1.4212961    |
| ep_rewmean              | -2.35        |
| episodes                | 988          |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 98601        |
| policy_loss             | 0.62331885   |
| qf1_loss                | 0.0023213208 |
| qf2_loss                | 0.0024188405 |
| time_elapsed            | 474          |
| total timesteps         | 98700        |
| value_loss              | 0.0001596039 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001137859   |
| ent_coef_loss           | 0.8828838     |
| entropy                 | 1.3725125     |
| ep_rewmean              | -2.32         |
| episodes                | 992           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 99001         |
| policy_loss             | 0.6326419     |
| qf1_loss                | 0.008967526   |
| qf2_loss                | 0.008737245   |
| time_elapsed            | 476           |
| total timesteps         | 99100         |
| value_loss              | 0.00023452652 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012429265  |
| ent_coef_loss           | 3.022172      |
| entropy                 | 1.9270792     |
| ep_rewmean              | -2.3          |
| episodes                | 996           |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 99401         |
| policy_loss             | 0.6580378     |
| qf1_loss                | 0.000194909   |
| qf2_loss                | 0.00022012739 |
| time_elapsed            | 478           |
| total timesteps         | 99500         |
| value_loss              | 0.0007077042  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012332575  |
| ent_coef_loss           | -7.2626877    |
| entropy                 | 1.7200754     |
| ep_rewmean              | -2.3          |
| episodes                | 1000          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 99801         |
| policy_loss             | 0.68837917    |
| qf1_loss                | 0.00023833351 |
| qf2_loss                | 0.00024127166 |
| time_elapsed            | 480           |
| total timesteps         | 99900         |
| value_loss              | 0.00018647913 |
-------------------------------------------
Eval num_timesteps=100000, episode_reward=-2.53 +/- 1.03
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012672821  |
| ent_coef_loss           | -0.4994786    |
| entropy                 | 1.2479478     |
| ep_rewmean              | -2.37         |
| episodes                | 1004          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 100201        |
| policy_loss             | 0.6707536     |
| qf1_loss                | 0.00021585508 |
| qf2_loss                | 0.00019617882 |
| time_elapsed            | 482           |
| total timesteps         | 100300        |
| value_loss              | 0.00018655435 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013334159  |
| ent_coef_loss           | 0.5702832     |
| entropy                 | 1.9084575     |
| ep_rewmean              | -2.39         |
| episodes                | 1008          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 100601        |
| policy_loss             | 0.6748103     |
| qf1_loss                | 0.00023472725 |
| qf2_loss                | 0.00018201955 |
| time_elapsed            | 484           |
| total timesteps         | 100700        |
| value_loss              | 0.00016647077 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014193995  |
| ent_coef_loss           | 4.7309136     |
| entropy                 | 1.4593415     |
| ep_rewmean              | -2.34         |
| episodes                | 1012          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 101001        |
| policy_loss             | 0.6659144     |
| qf1_loss                | 0.0031577598  |
| qf2_loss                | 0.0034333821  |
| time_elapsed            | 486           |
| total timesteps         | 101100        |
| value_loss              | 0.00027697725 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014983515  |
| ent_coef_loss           | -4.69955      |
| entropy                 | 2.1929848     |
| ep_rewmean              | -2.32         |
| episodes                | 1016          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 101401        |
| policy_loss             | 0.74181134    |
| qf1_loss                | 0.00021446351 |
| qf2_loss                | 0.00015406465 |
| time_elapsed            | 488           |
| total timesteps         | 101500        |
| value_loss              | 0.00019435122 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015088579  |
| ent_coef_loss           | 4.9940243     |
| entropy                 | 2.0196178     |
| ep_rewmean              | -2.29         |
| episodes                | 1020          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 101801        |
| policy_loss             | 0.7118557     |
| qf1_loss                | 0.00015828265 |
| qf2_loss                | 0.00014879677 |
| time_elapsed            | 490           |
| total timesteps         | 101900        |
| value_loss              | 0.00013254007 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015325247  |
| ent_coef_loss           | 0.39864492    |
| entropy                 | 2.016992      |
| ep_rewmean              | -2.36         |
| episodes                | 1024          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 102201        |
| policy_loss             | 0.7525215     |
| qf1_loss                | 0.005080686   |
| qf2_loss                | 0.0046513826  |
| time_elapsed            | 492           |
| total timesteps         | 102300        |
| value_loss              | 0.00026035527 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015949502  |
| ent_coef_loss           | 3.9855936     |
| entropy                 | 2.3093934     |
| ep_rewmean              | -2.32         |
| episodes                | 1028          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 102601        |
| policy_loss             | 0.7017067     |
| qf1_loss                | 0.00025348156 |
| qf2_loss                | 0.00025931332 |
| time_elapsed            | 494           |
| total timesteps         | 102700        |
| value_loss              | 0.00017923638 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001685614   |
| ent_coef_loss           | -3.5993755    |
| entropy                 | 2.0477564     |
| ep_rewmean              | -2.28         |
| episodes                | 1032          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 103001        |
| policy_loss             | 0.7343442     |
| qf1_loss                | 0.0002709978  |
| qf2_loss                | 0.00023111887 |
| time_elapsed            | 496           |
| total timesteps         | 103100        |
| value_loss              | 0.00013446459 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016964416  |
| ent_coef_loss           | -6.353488     |
| entropy                 | 2.1540537     |
| ep_rewmean              | -2.29         |
| episodes                | 1036          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 103401        |
| policy_loss             | 0.8002019     |
| qf1_loss                | 0.00017265513 |
| qf2_loss                | 0.0002443322  |
| time_elapsed            | 497           |
| total timesteps         | 103500        |
| value_loss              | 0.00027749623 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016663383  |
| ent_coef_loss           | -5.633812     |
| entropy                 | 1.7758293     |
| ep_rewmean              | -2.32         |
| episodes                | 1040          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 103801        |
| policy_loss             | 0.78280866    |
| qf1_loss                | 0.0067996127  |
| qf2_loss                | 0.0067600715  |
| time_elapsed            | 499           |
| total timesteps         | 103900        |
| value_loss              | 0.00016525414 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001594421   |
| ent_coef_loss           | -2.2434042    |
| entropy                 | 1.8907378     |
| ep_rewmean              | -2.34         |
| episodes                | 1044          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 104201        |
| policy_loss             | 0.7590375     |
| qf1_loss                | 0.00020477142 |
| qf2_loss                | 0.00022476801 |
| time_elapsed            | 501           |
| total timesteps         | 104300        |
| value_loss              | 0.00026154652 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014671044  |
| ent_coef_loss           | -6.9316173    |
| entropy                 | 1.3407226     |
| ep_rewmean              | -2.37         |
| episodes                | 1048          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 104601        |
| policy_loss             | 0.74754465    |
| qf1_loss                | 0.0056546745  |
| qf2_loss                | 0.0057876282  |
| time_elapsed            | 503           |
| total timesteps         | 104700        |
| value_loss              | 0.00021991748 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014974164  |
| ent_coef_loss           | 1.7237402     |
| entropy                 | 2.5730724     |
| ep_rewmean              | -2.23         |
| episodes                | 1052          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 105001        |
| policy_loss             | 0.74247456    |
| qf1_loss                | 0.0050439215  |
| qf2_loss                | 0.005417462   |
| time_elapsed            | 505           |
| total timesteps         | 105100        |
| value_loss              | 0.00023390715 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014436863  |
| ent_coef_loss           | 3.715758      |
| entropy                 | 2.6143627     |
| ep_rewmean              | -2.2          |
| episodes                | 1056          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 105401        |
| policy_loss             | 0.7144562     |
| qf1_loss                | 0.00046385665 |
| qf2_loss                | 0.00046759745 |
| time_elapsed            | 507           |
| total timesteps         | 105500        |
| value_loss              | 0.0005018633  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013947164  |
| ent_coef_loss           | 6.355591      |
| entropy                 | 1.8967173     |
| ep_rewmean              | -2.24         |
| episodes                | 1060          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 105801        |
| policy_loss             | 0.71744925    |
| qf1_loss                | 0.00023287038 |
| qf2_loss                | 0.00025841407 |
| time_elapsed            | 509           |
| total timesteps         | 105900        |
| value_loss              | 0.00023669873 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013681753  |
| ent_coef_loss           | -2.5211213    |
| entropy                 | 1.8056773     |
| ep_rewmean              | -2.27         |
| episodes                | 1064          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 106201        |
| policy_loss             | 0.7388727     |
| qf1_loss                | 0.0076163416  |
| qf2_loss                | 0.007416997   |
| time_elapsed            | 511           |
| total timesteps         | 106300        |
| value_loss              | 0.00055979844 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014448557  |
| ent_coef_loss           | 1.2716961     |
| entropy                 | 1.08153       |
| ep_rewmean              | -2.31         |
| episodes                | 1068          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 106601        |
| policy_loss             | 0.71572655    |
| qf1_loss                | 0.0002962523  |
| qf2_loss                | 0.00031495144 |
| time_elapsed            | 513           |
| total timesteps         | 106700        |
| value_loss              | 0.0003290294  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014627979  |
| ent_coef_loss           | 0.5926307     |
| entropy                 | 1.0735518     |
| ep_rewmean              | -2.28         |
| episodes                | 1072          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 107001        |
| policy_loss             | 0.71705246    |
| qf1_loss                | 0.0060538463  |
| qf2_loss                | 0.0056730574  |
| time_elapsed            | 515           |
| total timesteps         | 107100        |
| value_loss              | 0.00032539875 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014931114  |
| ent_coef_loss           | 4.845011      |
| entropy                 | 1.3078399     |
| ep_rewmean              | -2.29         |
| episodes                | 1076          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 107401        |
| policy_loss             | 0.7205431     |
| qf1_loss                | 0.0037933637  |
| qf2_loss                | 0.00402108    |
| time_elapsed            | 517           |
| total timesteps         | 107500        |
| value_loss              | 0.00025321168 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015934664  |
| ent_coef_loss           | 10.695939     |
| entropy                 | 1.5658257     |
| ep_rewmean              | -2.32         |
| episodes                | 1080          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 107801        |
| policy_loss             | 0.6980475     |
| qf1_loss                | 0.0013346663  |
| qf2_loss                | 0.0012061261  |
| time_elapsed            | 518           |
| total timesteps         | 107900        |
| value_loss              | 0.00025199392 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001646358   |
| ent_coef_loss           | -1.7119011    |
| entropy                 | 1.7777164     |
| ep_rewmean              | -2.29         |
| episodes                | 1084          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 108201        |
| policy_loss             | 0.717305      |
| qf1_loss                | 0.0091012735  |
| qf2_loss                | 0.009610906   |
| time_elapsed            | 520           |
| total timesteps         | 108300        |
| value_loss              | 0.00020718476 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017085074  |
| ent_coef_loss           | 8.118757      |
| entropy                 | 1.377574      |
| ep_rewmean              | -2.3          |
| episodes                | 1088          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 108601        |
| policy_loss             | 0.6575009     |
| qf1_loss                | 0.00034624274 |
| qf2_loss                | 0.0003385282  |
| time_elapsed            | 522           |
| total timesteps         | 108700        |
| value_loss              | 0.0005338935  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016553501 |
| ent_coef_loss           | 0.19254786   |
| entropy                 | 1.7155144    |
| ep_rewmean              | -2.3         |
| episodes                | 1092         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 109001       |
| policy_loss             | 0.70606      |
| qf1_loss                | 0.0028100987 |
| qf2_loss                | 0.0026470653 |
| time_elapsed            | 524          |
| total timesteps         | 109100       |
| value_loss              | 0.0002326734 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015929316  |
| ent_coef_loss           | -3.0468137    |
| entropy                 | 2.147845      |
| ep_rewmean              | -2.32         |
| episodes                | 1096          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 109401        |
| policy_loss             | 0.6926604     |
| qf1_loss                | 0.0054146606  |
| qf2_loss                | 0.0053317673  |
| time_elapsed            | 526           |
| total timesteps         | 109500        |
| value_loss              | 0.00030761235 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014821469  |
| ent_coef_loss           | -0.06028509   |
| entropy                 | 1.7187458     |
| ep_rewmean              | -2.34         |
| episodes                | 1100          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 109801        |
| policy_loss             | 0.68432724    |
| qf1_loss                | 0.0042580366  |
| qf2_loss                | 0.004334993   |
| time_elapsed            | 528           |
| total timesteps         | 109900        |
| value_loss              | 0.00034398792 |
-------------------------------------------
Eval num_timesteps=110000, episode_reward=-3.65 +/- 1.73
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014699713  |
| ent_coef_loss           | -2.852089     |
| entropy                 | 2.1043978     |
| ep_rewmean              | -2.37         |
| episodes                | 1104          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 110201        |
| policy_loss             | 0.79537416    |
| qf1_loss                | 0.00046951542 |
| qf2_loss                | 0.00040547783 |
| time_elapsed            | 530           |
| total timesteps         | 110300        |
| value_loss              | 0.0002492046  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014622225  |
| ent_coef_loss           | -0.30413413   |
| entropy                 | 2.3876457     |
| ep_rewmean              | -2.36         |
| episodes                | 1108          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 110601        |
| policy_loss             | 0.7083783     |
| qf1_loss                | 0.0004949394  |
| qf2_loss                | 0.0003409539  |
| time_elapsed            | 532           |
| total timesteps         | 110700        |
| value_loss              | 0.00035609395 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014465895  |
| ent_coef_loss           | -1.8175969    |
| entropy                 | 2.1269073     |
| ep_rewmean              | -2.42         |
| episodes                | 1112          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 111001        |
| policy_loss             | 0.7431992     |
| qf1_loss                | 0.00559759    |
| qf2_loss                | 0.005627844   |
| time_elapsed            | 534           |
| total timesteps         | 111100        |
| value_loss              | 0.00021647144 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013960372  |
| ent_coef_loss           | -3.811375     |
| entropy                 | 0.82003796    |
| ep_rewmean              | -2.39         |
| episodes                | 1116          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 111401        |
| policy_loss             | 0.68808854    |
| qf1_loss                | 0.0056830156  |
| qf2_loss                | 0.006032495   |
| time_elapsed            | 536           |
| total timesteps         | 111500        |
| value_loss              | 0.00022807045 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013889543 |
| ent_coef_loss           | -0.3368621   |
| entropy                 | 1.0424005    |
| ep_rewmean              | -2.4         |
| episodes                | 1120         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.4         |
| n_updates               | 111801       |
| policy_loss             | 0.69856906   |
| qf1_loss                | 0.0043454845 |
| qf2_loss                | 0.0044522695 |
| time_elapsed            | 538          |
| total timesteps         | 111900       |
| value_loss              | 0.0004985496 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013188806  |
| ent_coef_loss           | 4.1422567     |
| entropy                 | 0.94320405    |
| ep_rewmean              | -2.32         |
| episodes                | 1124          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 112201        |
| policy_loss             | 0.68920517    |
| qf1_loss                | 0.0003629992  |
| qf2_loss                | 0.00037733497 |
| time_elapsed            | 540           |
| total timesteps         | 112300        |
| value_loss              | 0.00042894535 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012206793  |
| ent_coef_loss           | -0.6385275    |
| entropy                 | 1.2855353     |
| ep_rewmean              | -2.28         |
| episodes                | 1128          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 112601        |
| policy_loss             | 0.7405604     |
| qf1_loss                | 0.0002612999  |
| qf2_loss                | 0.00022093536 |
| time_elapsed            | 542           |
| total timesteps         | 112700        |
| value_loss              | 0.000282233   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011417487  |
| ent_coef_loss           | -3.0616603    |
| entropy                 | 0.6363181     |
| ep_rewmean              | -2.31         |
| episodes                | 1132          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 113001        |
| policy_loss             | 0.7341801     |
| qf1_loss                | 0.0044139028  |
| qf2_loss                | 0.004415056   |
| time_elapsed            | 544           |
| total timesteps         | 113100        |
| value_loss              | 0.00030014865 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011346656  |
| ent_coef_loss           | 3.2860045     |
| entropy                 | 0.91095483    |
| ep_rewmean              | -2.3          |
| episodes                | 1136          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 113401        |
| policy_loss             | 0.72524035    |
| qf1_loss                | 0.0003100306  |
| qf2_loss                | 0.0003816632  |
| time_elapsed            | 546           |
| total timesteps         | 113500        |
| value_loss              | 0.00021288887 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011537606  |
| ent_coef_loss           | -2.3155348    |
| entropy                 | 1.09744       |
| ep_rewmean              | -2.25         |
| episodes                | 1140          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 113801        |
| policy_loss             | 0.7098477     |
| qf1_loss                | 0.00018141005 |
| qf2_loss                | 0.00019373774 |
| time_elapsed            | 548           |
| total timesteps         | 113900        |
| value_loss              | 0.0001899239  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011707423 |
| ent_coef_loss           | 1.3530703    |
| entropy                 | 1.0211365    |
| ep_rewmean              | -2.23        |
| episodes                | 1144         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 114201       |
| policy_loss             | 0.70825124   |
| qf1_loss                | 0.014278796  |
| qf2_loss                | 0.014204936  |
| time_elapsed            | 550          |
| total timesteps         | 114300       |
| value_loss              | 0.0002665102 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011573058  |
| ent_coef_loss           | 3.2528553     |
| entropy                 | 0.87882924    |
| ep_rewmean              | -2.17         |
| episodes                | 1148          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 114601        |
| policy_loss             | 0.69528085    |
| qf1_loss                | 0.0025193328  |
| qf2_loss                | 0.0027255877  |
| time_elapsed            | 551           |
| total timesteps         | 114700        |
| value_loss              | 0.00037754793 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011666997  |
| ent_coef_loss           | 1.7890029     |
| entropy                 | 0.77944195    |
| ep_rewmean              | -2.2          |
| episodes                | 1152          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 115001        |
| policy_loss             | 0.6870084     |
| qf1_loss                | 0.0004962857  |
| qf2_loss                | 0.00038262253 |
| time_elapsed            | 553           |
| total timesteps         | 115100        |
| value_loss              | 0.0006302563  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011615318  |
| ent_coef_loss           | 0.43384743    |
| entropy                 | 0.7399931     |
| ep_rewmean              | -2.18         |
| episodes                | 1156          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 115401        |
| policy_loss             | 0.7356998     |
| qf1_loss                | 0.004401184   |
| qf2_loss                | 0.0048673903  |
| time_elapsed            | 555           |
| total timesteps         | 115500        |
| value_loss              | 0.00017958446 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012081666  |
| ent_coef_loss           | 7.064948      |
| entropy                 | 0.6030446     |
| ep_rewmean              | -2.15         |
| episodes                | 1160          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 115801        |
| policy_loss             | 0.7319016     |
| qf1_loss                | 0.00026831694 |
| qf2_loss                | 0.0003139307  |
| time_elapsed            | 557           |
| total timesteps         | 115900        |
| value_loss              | 0.00021748786 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012202073  |
| ent_coef_loss           | -3.9050329    |
| entropy                 | 1.439429      |
| ep_rewmean              | -2.16         |
| episodes                | 1164          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 116201        |
| policy_loss             | 0.7269131     |
| qf1_loss                | 0.0038962075  |
| qf2_loss                | 0.0038319635  |
| time_elapsed            | 559           |
| total timesteps         | 116300        |
| value_loss              | 0.00012025937 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001350005   |
| ent_coef_loss           | 1.756063      |
| entropy                 | 1.8205729     |
| ep_rewmean              | -2.19         |
| episodes                | 1168          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 116601        |
| policy_loss             | 0.73954993    |
| qf1_loss                | 0.00048078527 |
| qf2_loss                | 0.0006015429  |
| time_elapsed            | 561           |
| total timesteps         | 116700        |
| value_loss              | 0.00035860378 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014364008  |
| ent_coef_loss           | 6.655035      |
| entropy                 | 1.9851792     |
| ep_rewmean              | -2.27         |
| episodes                | 1172          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 117001        |
| policy_loss             | 0.7331619     |
| qf1_loss                | 0.00042024982 |
| qf2_loss                | 0.0002984653  |
| time_elapsed            | 563           |
| total timesteps         | 117100        |
| value_loss              | 0.00031432154 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001438287  |
| ent_coef_loss           | 5.9368086    |
| entropy                 | 1.853478     |
| ep_rewmean              | -2.25        |
| episodes                | 1176         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 117401       |
| policy_loss             | 0.731485     |
| qf1_loss                | 0.011714695  |
| qf2_loss                | 0.011871135  |
| time_elapsed            | 565          |
| total timesteps         | 117500       |
| value_loss              | 0.0002158915 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013935803  |
| ent_coef_loss           | -3.885971     |
| entropy                 | 1.2989385     |
| ep_rewmean              | -2.2          |
| episodes                | 1180          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 117801        |
| policy_loss             | 0.7468337     |
| qf1_loss                | 0.0060692946  |
| qf2_loss                | 0.0060646674  |
| time_elapsed            | 567           |
| total timesteps         | 117900        |
| value_loss              | 0.00022047872 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013603675  |
| ent_coef_loss           | -2.4434795    |
| entropy                 | 1.5571029     |
| ep_rewmean              | -2.22         |
| episodes                | 1184          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 118201        |
| policy_loss             | 0.7280063     |
| qf1_loss                | 0.00018124157 |
| qf2_loss                | 0.0002545279  |
| time_elapsed            | 569           |
| total timesteps         | 118300        |
| value_loss              | 0.00019351662 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013518835  |
| ent_coef_loss           | -0.74013925   |
| entropy                 | 1.5157993     |
| ep_rewmean              | -2.2          |
| episodes                | 1188          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 118601        |
| policy_loss             | 0.7535634     |
| qf1_loss                | 0.005318193   |
| qf2_loss                | 0.005344494   |
| time_elapsed            | 571           |
| total timesteps         | 118700        |
| value_loss              | 0.00014274592 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013314894  |
| ent_coef_loss           | -4.9519176    |
| entropy                 | 1.5529797     |
| ep_rewmean              | -2.26         |
| episodes                | 1192          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 119001        |
| policy_loss             | 0.7510084     |
| qf1_loss                | 0.0053942823  |
| qf2_loss                | 0.005208371   |
| time_elapsed            | 573           |
| total timesteps         | 119100        |
| value_loss              | 0.00034188252 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013298441  |
| ent_coef_loss           | 4.9178667     |
| entropy                 | 1.1993561     |
| ep_rewmean              | -2.29         |
| episodes                | 1196          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 119401        |
| policy_loss             | 0.7185174     |
| qf1_loss                | 0.0038860564  |
| qf2_loss                | 0.0034998632  |
| time_elapsed            | 575           |
| total timesteps         | 119500        |
| value_loss              | 0.00055220554 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013233729 |
| ent_coef_loss           | -0.27210498  |
| entropy                 | 1.4242406    |
| ep_rewmean              | -2.26        |
| episodes                | 1200         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 119801       |
| policy_loss             | 0.74683887   |
| qf1_loss                | 0.004637698  |
| qf2_loss                | 0.0046563046 |
| time_elapsed            | 577          |
| total timesteps         | 119900       |
| value_loss              | 0.0005637577 |
------------------------------------------
Eval num_timesteps=120000, episode_reward=-1.41 +/- 1.01
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014497038 |
| ent_coef_loss           | 9.072479     |
| entropy                 | 1.525165     |
| ep_rewmean              | -2.21        |
| episodes                | 1204         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 120201       |
| policy_loss             | 0.74603885   |
| qf1_loss                | 0.004063621  |
| qf2_loss                | 0.004137025  |
| time_elapsed            | 579          |
| total timesteps         | 120300       |
| value_loss              | 0.0004178537 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015510082  |
| ent_coef_loss           | 1.0960457     |
| entropy                 | 1.3848181     |
| ep_rewmean              | -2.22         |
| episodes                | 1208          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 120601        |
| policy_loss             | 0.6916766     |
| qf1_loss                | 0.00024652987 |
| qf2_loss                | 0.0002219684  |
| time_elapsed            | 581           |
| total timesteps         | 120700        |
| value_loss              | 0.00030692638 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015707291 |
| ent_coef_loss           | -4.874647    |
| entropy                 | 1.7232105    |
| ep_rewmean              | -2.21        |
| episodes                | 1212         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 121001       |
| policy_loss             | 0.7246424    |
| qf1_loss                | 0.0013069375 |
| qf2_loss                | 0.0012519544 |
| time_elapsed            | 583          |
| total timesteps         | 121100       |
| value_loss              | 0.0010008852 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015227143  |
| ent_coef_loss           | -5.083879     |
| entropy                 | 1.684185      |
| ep_rewmean              | -2.28         |
| episodes                | 1216          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 121401        |
| policy_loss             | 0.73539513    |
| qf1_loss                | 0.0002634963  |
| qf2_loss                | 0.00028360198 |
| time_elapsed            | 584           |
| total timesteps         | 121500        |
| value_loss              | 0.00029068062 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014613812  |
| ent_coef_loss           | -1.4716159    |
| entropy                 | 1.2287312     |
| ep_rewmean              | -2.32         |
| episodes                | 1220          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 121801        |
| policy_loss             | 0.677132      |
| qf1_loss                | 0.0042491425  |
| qf2_loss                | 0.0042784903  |
| time_elapsed            | 586           |
| total timesteps         | 121900        |
| value_loss              | 0.00045343477 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014105211  |
| ent_coef_loss           | -11.31023     |
| entropy                 | 0.2955341     |
| ep_rewmean              | -2.36         |
| episodes                | 1224          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 122201        |
| policy_loss             | 0.71842635    |
| qf1_loss                | 0.00019225577 |
| qf2_loss                | 0.00017833072 |
| time_elapsed            | 588           |
| total timesteps         | 122300        |
| value_loss              | 0.0001972086  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012900974  |
| ent_coef_loss           | 0.5452777     |
| entropy                 | 0.45309925    |
| ep_rewmean              | -2.33         |
| episodes                | 1228          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 122601        |
| policy_loss             | 0.66938686    |
| qf1_loss                | 0.00033874623 |
| qf2_loss                | 0.00034036674 |
| time_elapsed            | 590           |
| total timesteps         | 122700        |
| value_loss              | 0.00066369    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012156246  |
| ent_coef_loss           | -2.4702482    |
| entropy                 | 0.1347171     |
| ep_rewmean              | -2.31         |
| episodes                | 1232          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 123001        |
| policy_loss             | 0.6966331     |
| qf1_loss                | 0.00018631434 |
| qf2_loss                | 0.00020823881 |
| time_elapsed            | 592           |
| total timesteps         | 123100        |
| value_loss              | 0.0002627711  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001197643   |
| ent_coef_loss           | -1.8051729    |
| entropy                 | 0.48281282    |
| ep_rewmean              | -2.29         |
| episodes                | 1236          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 123401        |
| policy_loss             | 0.7105819     |
| qf1_loss                | 0.00014142058 |
| qf2_loss                | 0.00016354228 |
| time_elapsed            | 594           |
| total timesteps         | 123500        |
| value_loss              | 0.00027412872 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012187954  |
| ent_coef_loss           | -0.4681933    |
| entropy                 | 0.92402464    |
| ep_rewmean              | -2.29         |
| episodes                | 1240          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 123801        |
| policy_loss             | 0.69744813    |
| qf1_loss                | 0.00028780126 |
| qf2_loss                | 0.00022872047 |
| time_elapsed            | 596           |
| total timesteps         | 123900        |
| value_loss              | 0.0001511815  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011753356  |
| ent_coef_loss           | -8.025261     |
| entropy                 | 0.29621804    |
| ep_rewmean              | -2.28         |
| episodes                | 1244          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 124201        |
| policy_loss             | 0.7237553     |
| qf1_loss                | 0.00019134794 |
| qf2_loss                | 0.00028576926 |
| time_elapsed            | 598           |
| total timesteps         | 124300        |
| value_loss              | 0.00039918584 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011276633  |
| ent_coef_loss           | -2.8337717    |
| entropy                 | 0.0049755275  |
| ep_rewmean              | -2.27         |
| episodes                | 1248          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 124601        |
| policy_loss             | 0.7158179     |
| qf1_loss                | 0.00045078143 |
| qf2_loss                | 0.00037271218 |
| time_elapsed            | 600           |
| total timesteps         | 124700        |
| value_loss              | 0.00014670246 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011096576  |
| ent_coef_loss           | 3.878863      |
| entropy                 | 0.32055196    |
| ep_rewmean              | -2.26         |
| episodes                | 1252          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 125001        |
| policy_loss             | 0.7151851     |
| qf1_loss                | 0.007745629   |
| qf2_loss                | 0.007699549   |
| time_elapsed            | 602           |
| total timesteps         | 125100        |
| value_loss              | 0.00016138345 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010891396  |
| ent_coef_loss           | -4.49884      |
| entropy                 | 0.18770857    |
| ep_rewmean              | -2.27         |
| episodes                | 1256          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 125401        |
| policy_loss             | 0.74890053    |
| qf1_loss                | 0.00012638094 |
| qf2_loss                | 0.0001580973  |
| time_elapsed            | 604           |
| total timesteps         | 125500        |
| value_loss              | 0.00015377057 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010492379  |
| ent_coef_loss           | 0.18497992    |
| entropy                 | 0.38582844    |
| ep_rewmean              | -2.28         |
| episodes                | 1260          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 125801        |
| policy_loss             | 0.68974775    |
| qf1_loss                | 0.009111657   |
| qf2_loss                | 0.0091924     |
| time_elapsed            | 605           |
| total timesteps         | 125900        |
| value_loss              | 0.00029024854 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010351435  |
| ent_coef_loss           | -5.415062     |
| entropy                 | 0.32132027    |
| ep_rewmean              | -2.26         |
| episodes                | 1264          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 126201        |
| policy_loss             | 0.75512564    |
| qf1_loss                | 0.00041272346 |
| qf2_loss                | 0.00034023303 |
| time_elapsed            | 607           |
| total timesteps         | 126300        |
| value_loss              | 0.00015071002 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010104101  |
| ent_coef_loss           | 3.1924326     |
| entropy                 | -0.46392336   |
| ep_rewmean              | -2.24         |
| episodes                | 1268          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 126601        |
| policy_loss             | 0.6669549     |
| qf1_loss                | 0.0016839589  |
| qf2_loss                | 0.0019223366  |
| time_elapsed            | 609           |
| total timesteps         | 126700        |
| value_loss              | 0.00021756337 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010011932  |
| ent_coef_loss           | -1.3865216    |
| entropy                 | -0.3306921    |
| ep_rewmean              | -2.13         |
| episodes                | 1272          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 127001        |
| policy_loss             | 0.707491      |
| qf1_loss                | 0.00019645458 |
| qf2_loss                | 0.00020925858 |
| time_elapsed            | 611           |
| total timesteps         | 127100        |
| value_loss              | 0.00035590894 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001026425   |
| ent_coef_loss           | 4.388742      |
| entropy                 | 0.27721062    |
| ep_rewmean              | -2.16         |
| episodes                | 1276          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 127401        |
| policy_loss             | 0.7106543     |
| qf1_loss                | 0.00025135203 |
| qf2_loss                | 0.00031881395 |
| time_elapsed            | 613           |
| total timesteps         | 127500        |
| value_loss              | 0.00053969305 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010956702  |
| ent_coef_loss           | 4.1674757     |
| entropy                 | 0.8714808     |
| ep_rewmean              | -2.18         |
| episodes                | 1280          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 127801        |
| policy_loss             | 0.75446874    |
| qf1_loss                | 0.011642085   |
| qf2_loss                | 0.011527736   |
| time_elapsed            | 615           |
| total timesteps         | 127900        |
| value_loss              | 0.00020371188 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001197779   |
| ent_coef_loss           | 0.77898115    |
| entropy                 | 1.2083278     |
| ep_rewmean              | -2.18         |
| episodes                | 1284          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 128201        |
| policy_loss             | 0.72229356    |
| qf1_loss                | 0.00080919615 |
| qf2_loss                | 0.0008123322  |
| time_elapsed            | 617           |
| total timesteps         | 128300        |
| value_loss              | 0.00018292549 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012757564  |
| ent_coef_loss           | -5.5086083    |
| entropy                 | 1.5760884     |
| ep_rewmean              | -2.17         |
| episodes                | 1288          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 128601        |
| policy_loss             | 0.74893737    |
| qf1_loss                | 0.00016606555 |
| qf2_loss                | 0.00014048476 |
| time_elapsed            | 619           |
| total timesteps         | 128700        |
| value_loss              | 0.0001937693  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013543953  |
| ent_coef_loss           | 2.180668      |
| entropy                 | 1.9533768     |
| ep_rewmean              | -2.15         |
| episodes                | 1292          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 129001        |
| policy_loss             | 0.7074357     |
| qf1_loss                | 0.0046766545  |
| qf2_loss                | 0.004880626   |
| time_elapsed            | 621           |
| total timesteps         | 129100        |
| value_loss              | 0.00058581424 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014877443  |
| ent_coef_loss           | 3.1267552     |
| entropy                 | 2.357339      |
| ep_rewmean              | -2.16         |
| episodes                | 1296          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 129401        |
| policy_loss             | 0.7207896     |
| qf1_loss                | 0.00883335    |
| qf2_loss                | 0.008838169   |
| time_elapsed            | 623           |
| total timesteps         | 129500        |
| value_loss              | 0.00015982844 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015459032  |
| ent_coef_loss           | -2.9586115    |
| entropy                 | 2.509264      |
| ep_rewmean              | -2.16         |
| episodes                | 1300          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 129801        |
| policy_loss             | 0.72607327    |
| qf1_loss                | 0.0044964356  |
| qf2_loss                | 0.004470523   |
| time_elapsed            | 625           |
| total timesteps         | 129900        |
| value_loss              | 0.00020143937 |
-------------------------------------------
Eval num_timesteps=130000, episode_reward=-1.80 +/- 0.78
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016112529  |
| ent_coef_loss           | 9.395878      |
| entropy                 | 2.645904      |
| ep_rewmean              | -2.16         |
| episodes                | 1304          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 130201        |
| policy_loss             | 0.7172681     |
| qf1_loss                | 0.0003620531  |
| qf2_loss                | 0.00025305076 |
| time_elapsed            | 627           |
| total timesteps         | 130300        |
| value_loss              | 0.0002346178  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016386746  |
| ent_coef_loss           | -0.49781597   |
| entropy                 | 2.2859974     |
| ep_rewmean              | -2.13         |
| episodes                | 1308          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 130601        |
| policy_loss             | 0.66980207    |
| qf1_loss                | 0.0002923492  |
| qf2_loss                | 0.00039103758 |
| time_elapsed            | 629           |
| total timesteps         | 130700        |
| value_loss              | 0.0005245368  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016515136  |
| ent_coef_loss           | -2.4655743    |
| entropy                 | 2.6648455     |
| ep_rewmean              | -2.11         |
| episodes                | 1312          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 131001        |
| policy_loss             | 0.73185813    |
| qf1_loss                | 0.002005098   |
| qf2_loss                | 0.0017425217  |
| time_elapsed            | 631           |
| total timesteps         | 131100        |
| value_loss              | 0.00027931773 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017637544  |
| ent_coef_loss           | 1.8986173     |
| entropy                 | 2.4442606     |
| ep_rewmean              | -2.1          |
| episodes                | 1316          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 131401        |
| policy_loss             | 0.75851333    |
| qf1_loss                | 0.00023655145 |
| qf2_loss                | 0.00015033726 |
| time_elapsed            | 632           |
| total timesteps         | 131500        |
| value_loss              | 0.000304977   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017812565  |
| ent_coef_loss           | 0.8837912     |
| entropy                 | 2.8843584     |
| ep_rewmean              | -2.11         |
| episodes                | 1320          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 131801        |
| policy_loss             | 0.75855863    |
| qf1_loss                | 0.00031529754 |
| qf2_loss                | 0.0003430591  |
| time_elapsed            | 634           |
| total timesteps         | 131900        |
| value_loss              | 0.00036318315 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017456232  |
| ent_coef_loss           | 0.16732645    |
| entropy                 | 3.080827      |
| ep_rewmean              | -2.08         |
| episodes                | 1324          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 132201        |
| policy_loss             | 0.8055115     |
| qf1_loss                | 0.00022494039 |
| qf2_loss                | 0.0004546362  |
| time_elapsed            | 636           |
| total timesteps         | 132300        |
| value_loss              | 0.00047013184 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016768206 |
| ent_coef_loss           | 6.314968     |
| entropy                 | 2.4085855    |
| ep_rewmean              | -2.09        |
| episodes                | 1328         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 132601       |
| policy_loss             | 0.80947876   |
| qf1_loss                | 0.0030746784 |
| qf2_loss                | 0.0029295518 |
| time_elapsed            | 638          |
| total timesteps         | 132700       |
| value_loss              | 0.0003827496 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016342448 |
| ent_coef_loss           | -2.4686599   |
| entropy                 | 2.3919897    |
| ep_rewmean              | -2.11        |
| episodes                | 1332         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 133001       |
| policy_loss             | 0.831291     |
| qf1_loss                | 0.0026970797 |
| qf2_loss                | 0.0022829722 |
| time_elapsed            | 640          |
| total timesteps         | 133100       |
| value_loss              | 0.0006685925 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016369324  |
| ent_coef_loss           | 1.3724471     |
| entropy                 | 2.5747094     |
| ep_rewmean              | -2.15         |
| episodes                | 1336          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 133401        |
| policy_loss             | 0.7803033     |
| qf1_loss                | 0.00022309952 |
| qf2_loss                | 0.00020309453 |
| time_elapsed            | 642           |
| total timesteps         | 133500        |
| value_loss              | 0.0004924402  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017118704  |
| ent_coef_loss           | -0.036631346  |
| entropy                 | 2.3501112     |
| ep_rewmean              | -2.23         |
| episodes                | 1340          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 133801        |
| policy_loss             | 0.75722265    |
| qf1_loss                | 0.0002248194  |
| qf2_loss                | 0.00017683917 |
| time_elapsed            | 644           |
| total timesteps         | 133900        |
| value_loss              | 0.00027681747 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017621992  |
| ent_coef_loss           | 1.1252247     |
| entropy                 | 2.3314524     |
| ep_rewmean              | -2.23         |
| episodes                | 1344          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 134201        |
| policy_loss             | 0.7825397     |
| qf1_loss                | 0.008672126   |
| qf2_loss                | 0.008859552   |
| time_elapsed            | 646           |
| total timesteps         | 134300        |
| value_loss              | 0.00035699666 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017737369  |
| ent_coef_loss           | -6.9927573    |
| entropy                 | 2.5250144     |
| ep_rewmean              | -2.26         |
| episodes                | 1348          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 134601        |
| policy_loss             | 0.80187565    |
| qf1_loss                | 0.003859002   |
| qf2_loss                | 0.004084737   |
| time_elapsed            | 648           |
| total timesteps         | 134700        |
| value_loss              | 0.00024768745 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017677833  |
| ent_coef_loss           | 0.66105735    |
| entropy                 | 2.5640693     |
| ep_rewmean              | -2.22         |
| episodes                | 1352          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 135001        |
| policy_loss             | 0.7632009     |
| qf1_loss                | 0.00031373726 |
| qf2_loss                | 0.00023177118 |
| time_elapsed            | 650           |
| total timesteps         | 135100        |
| value_loss              | 0.0002651205  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017629438  |
| ent_coef_loss           | -2.1182919    |
| entropy                 | 2.4905992     |
| ep_rewmean              | -2.19         |
| episodes                | 1356          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 135401        |
| policy_loss             | 0.7454722     |
| qf1_loss                | 0.00049783447 |
| qf2_loss                | 0.00034907743 |
| time_elapsed            | 651           |
| total timesteps         | 135500        |
| value_loss              | 0.00030604503 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017002025  |
| ent_coef_loss           | -0.8421314    |
| entropy                 | 2.5709877     |
| ep_rewmean              | -2.16         |
| episodes                | 1360          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 135801        |
| policy_loss             | 0.81939596    |
| qf1_loss                | 0.00023903562 |
| qf2_loss                | 0.00020474906 |
| time_elapsed            | 653           |
| total timesteps         | 135900        |
| value_loss              | 0.0003306361  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016600651  |
| ent_coef_loss           | -11.073853    |
| entropy                 | 2.0694494     |
| ep_rewmean              | -2.13         |
| episodes                | 1364          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 136201        |
| policy_loss             | 0.8019004     |
| qf1_loss                | 0.0002771882  |
| qf2_loss                | 0.00024450367 |
| time_elapsed            | 655           |
| total timesteps         | 136300        |
| value_loss              | 0.00039002523 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016489091  |
| ent_coef_loss           | -0.9249501    |
| entropy                 | 2.6608748     |
| ep_rewmean              | -2.1          |
| episodes                | 1368          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 136601        |
| policy_loss             | 0.8603112     |
| qf1_loss                | 0.000284229   |
| qf2_loss                | 0.00029352418 |
| time_elapsed            | 657           |
| total timesteps         | 136700        |
| value_loss              | 0.00029303826 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015546682  |
| ent_coef_loss           | -0.27923465   |
| entropy                 | 2.0302196     |
| ep_rewmean              | -2.16         |
| episodes                | 1372          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 137001        |
| policy_loss             | 0.8570431     |
| qf1_loss                | 0.00024552032 |
| qf2_loss                | 0.00027600303 |
| time_elapsed            | 659           |
| total timesteps         | 137100        |
| value_loss              | 0.0001792977  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014254157  |
| ent_coef_loss           | -2.5919178    |
| entropy                 | 1.8351262     |
| ep_rewmean              | -2.16         |
| episodes                | 1376          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 137401        |
| policy_loss             | 0.79316384    |
| qf1_loss                | 0.00022813643 |
| qf2_loss                | 0.00019242556 |
| time_elapsed            | 661           |
| total timesteps         | 137500        |
| value_loss              | 0.00034469878 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014348305  |
| ent_coef_loss           | 5.6892147     |
| entropy                 | 2.5429022     |
| ep_rewmean              | -2.16         |
| episodes                | 1380          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 137801        |
| policy_loss             | 0.8106661     |
| qf1_loss                | 0.0074369377  |
| qf2_loss                | 0.007529243   |
| time_elapsed            | 663           |
| total timesteps         | 137900        |
| value_loss              | 0.00041249438 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014237358  |
| ent_coef_loss           | -1.441172     |
| entropy                 | 2.03165       |
| ep_rewmean              | -2.16         |
| episodes                | 1384          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 138201        |
| policy_loss             | 0.8268373     |
| qf1_loss                | 0.0028561486  |
| qf2_loss                | 0.0031586247  |
| time_elapsed            | 665           |
| total timesteps         | 138300        |
| value_loss              | 0.00022245123 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001448614   |
| ent_coef_loss           | 4.9579034     |
| entropy                 | 1.9329138     |
| ep_rewmean              | -2.18         |
| episodes                | 1388          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 138601        |
| policy_loss             | 0.84751374    |
| qf1_loss                | 0.0039046793  |
| qf2_loss                | 0.0038597584  |
| time_elapsed            | 667           |
| total timesteps         | 138700        |
| value_loss              | 0.00038407854 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014451272  |
| ent_coef_loss           | 1.5888212     |
| entropy                 | 2.2195914     |
| ep_rewmean              | -2.19         |
| episodes                | 1392          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 139001        |
| policy_loss             | 0.80487037    |
| qf1_loss                | 0.00023682375 |
| qf2_loss                | 0.00037749432 |
| time_elapsed            | 669           |
| total timesteps         | 139100        |
| value_loss              | 0.00031869774 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014755409  |
| ent_coef_loss           | 3.5229356     |
| entropy                 | 1.8192713     |
| ep_rewmean              | -2.15         |
| episodes                | 1396          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 139401        |
| policy_loss             | 0.8294723     |
| qf1_loss                | 0.006676748   |
| qf2_loss                | 0.006551156   |
| time_elapsed            | 671           |
| total timesteps         | 139500        |
| value_loss              | 0.00021215898 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015455103  |
| ent_coef_loss           | -0.072603464  |
| entropy                 | 1.7970604     |
| ep_rewmean              | -2.16         |
| episodes                | 1400          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 139801        |
| policy_loss             | 0.7696093     |
| qf1_loss                | 0.0031466698  |
| qf2_loss                | 0.0031619917  |
| time_elapsed            | 672           |
| total timesteps         | 139900        |
| value_loss              | 0.00023698925 |
-------------------------------------------
Eval num_timesteps=140000, episode_reward=-1.96 +/- 0.71
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00160736    |
| ent_coef_loss           | -0.22868538   |
| entropy                 | 1.3969436     |
| ep_rewmean              | -2.12         |
| episodes                | 1404          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 140201        |
| policy_loss             | 0.808604      |
| qf1_loss                | 0.008210625   |
| qf2_loss                | 0.008339729   |
| time_elapsed            | 675           |
| total timesteps         | 140300        |
| value_loss              | 0.00026403804 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015620433  |
| ent_coef_loss           | -6.953362     |
| entropy                 | 1.1997287     |
| ep_rewmean              | -2.13         |
| episodes                | 1408          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 140601        |
| policy_loss             | 0.78554404    |
| qf1_loss                | 0.00026109917 |
| qf2_loss                | 0.00023634423 |
| time_elapsed            | 677           |
| total timesteps         | 140700        |
| value_loss              | 0.00031860825 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014728802  |
| ent_coef_loss           | -2.990852     |
| entropy                 | 1.1971624     |
| ep_rewmean              | -2.08         |
| episodes                | 1412          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 141001        |
| policy_loss             | 0.7637657     |
| qf1_loss                | 0.006515881   |
| qf2_loss                | 0.006556901   |
| time_elapsed            | 678           |
| total timesteps         | 141100        |
| value_loss              | 0.00021203756 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013887477  |
| ent_coef_loss           | 2.2161245     |
| entropy                 | 0.9474623     |
| ep_rewmean              | -2.08         |
| episodes                | 1416          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 141401        |
| policy_loss             | 0.674509      |
| qf1_loss                | 0.00034782127 |
| qf2_loss                | 0.00024939128 |
| time_elapsed            | 680           |
| total timesteps         | 141500        |
| value_loss              | 0.00040151062 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013667785  |
| ent_coef_loss           | 5.7545395     |
| entropy                 | 1.0654353     |
| ep_rewmean              | -2.04         |
| episodes                | 1420          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 141801        |
| policy_loss             | 0.6758894     |
| qf1_loss                | 0.00039679292 |
| qf2_loss                | 0.00029793163 |
| time_elapsed            | 682           |
| total timesteps         | 141900        |
| value_loss              | 0.00033229328 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014592045  |
| ent_coef_loss           | 9.623316      |
| entropy                 | 1.2968512     |
| ep_rewmean              | -2.16         |
| episodes                | 1424          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 142201        |
| policy_loss             | 0.68557596    |
| qf1_loss                | 0.008249846   |
| qf2_loss                | 0.008009383   |
| time_elapsed            | 684           |
| total timesteps         | 142300        |
| value_loss              | 0.00023434224 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001545738   |
| ent_coef_loss           | -0.08150482   |
| entropy                 | 1.2461008     |
| ep_rewmean              | -2.21         |
| episodes                | 1428          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 142601        |
| policy_loss             | 0.69428384    |
| qf1_loss                | 0.00034609588 |
| qf2_loss                | 0.0003843504  |
| time_elapsed            | 686           |
| total timesteps         | 142700        |
| value_loss              | 0.00059981324 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016001677 |
| ent_coef_loss           | 0.2621116    |
| entropy                 | 1.699543     |
| ep_rewmean              | -2.2         |
| episodes                | 1432         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 143001       |
| policy_loss             | 0.7122568    |
| qf1_loss                | 0.004962655  |
| qf2_loss                | 0.0049192156 |
| time_elapsed            | 688          |
| total timesteps         | 143100       |
| value_loss              | 0.0004770538 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016069707  |
| ent_coef_loss           | -4.0376983    |
| entropy                 | 1.4251653     |
| ep_rewmean              | -2.17         |
| episodes                | 1436          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 143401        |
| policy_loss             | 0.6912688     |
| qf1_loss                | 0.00027941418 |
| qf2_loss                | 0.00018910153 |
| time_elapsed            | 690           |
| total timesteps         | 143500        |
| value_loss              | 0.0003922577  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015416329  |
| ent_coef_loss           | 4.780969      |
| entropy                 | 1.528487      |
| ep_rewmean              | -2.17         |
| episodes                | 1440          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 143801        |
| policy_loss             | 0.6976799     |
| qf1_loss                | 0.00031147333 |
| qf2_loss                | 0.00031498403 |
| time_elapsed            | 692           |
| total timesteps         | 143900        |
| value_loss              | 0.00018848093 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014871258  |
| ent_coef_loss           | -2.3112316    |
| entropy                 | 1.1462622     |
| ep_rewmean              | -2.18         |
| episodes                | 1444          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 144201        |
| policy_loss             | 0.6753986     |
| qf1_loss                | 0.004595341   |
| qf2_loss                | 0.0044121076  |
| time_elapsed            | 694           |
| total timesteps         | 144300        |
| value_loss              | 0.00036925363 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014172556  |
| ent_coef_loss           | -6.0680065    |
| entropy                 | 1.2751054     |
| ep_rewmean              | -2.25         |
| episodes                | 1448          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 144601        |
| policy_loss             | 0.6758805     |
| qf1_loss                | 0.00924511    |
| qf2_loss                | 0.009199155   |
| time_elapsed            | 696           |
| total timesteps         | 144700        |
| value_loss              | 0.00026333123 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013097938  |
| ent_coef_loss           | -2.8546925    |
| entropy                 | 0.65060914    |
| ep_rewmean              | -2.29         |
| episodes                | 1452          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 145001        |
| policy_loss             | 0.6780674     |
| qf1_loss                | 0.00018009506 |
| qf2_loss                | 0.00016670884 |
| time_elapsed            | 698           |
| total timesteps         | 145100        |
| value_loss              | 0.00015852967 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012264892  |
| ent_coef_loss           | -3.3806896    |
| entropy                 | -0.039967813  |
| ep_rewmean              | -2.34         |
| episodes                | 1456          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 145401        |
| policy_loss             | 0.6649703     |
| qf1_loss                | 0.00018314022 |
| qf2_loss                | 0.00019163423 |
| time_elapsed            | 700           |
| total timesteps         | 145500        |
| value_loss              | 0.00024049524 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011850087  |
| ent_coef_loss           | 0.4374547     |
| entropy                 | 0.29969       |
| ep_rewmean              | -2.37         |
| episodes                | 1460          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 145801        |
| policy_loss             | 0.6802927     |
| qf1_loss                | 0.0029018675  |
| qf2_loss                | 0.0011651044  |
| time_elapsed            | 701           |
| total timesteps         | 145900        |
| value_loss              | 0.00071766746 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011943165  |
| ent_coef_loss           | -2.5827346    |
| entropy                 | -0.112469375  |
| ep_rewmean              | -2.41         |
| episodes                | 1464          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 146201        |
| policy_loss             | 0.6507061     |
| qf1_loss                | 0.0003146176  |
| qf2_loss                | 0.00033467964 |
| time_elapsed            | 703           |
| total timesteps         | 146300        |
| value_loss              | 0.0002927548  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011925609  |
| ent_coef_loss           | -1.0101151    |
| entropy                 | -0.02944638   |
| ep_rewmean              | -2.37         |
| episodes                | 1468          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 146601        |
| policy_loss             | 0.62364125    |
| qf1_loss                | 0.0005191473  |
| qf2_loss                | 0.00045254274 |
| time_elapsed            | 705           |
| total timesteps         | 146700        |
| value_loss              | 0.00034323003 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012255124  |
| ent_coef_loss           | 9.998205      |
| entropy                 | 0.26006564    |
| ep_rewmean              | -2.39         |
| episodes                | 1472          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 147001        |
| policy_loss             | 0.62399733    |
| qf1_loss                | 0.0028334653  |
| qf2_loss                | 0.00295558    |
| time_elapsed            | 707           |
| total timesteps         | 147100        |
| value_loss              | 0.00033921102 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012491866 |
| ent_coef_loss           | 1.9049902    |
| entropy                 | -0.23592076  |
| ep_rewmean              | -2.38        |
| episodes                | 1476         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.4         |
| n_updates               | 147401       |
| policy_loss             | 0.62299633   |
| qf1_loss                | 0.0042512272 |
| qf2_loss                | 0.0041867383 |
| time_elapsed            | 709          |
| total timesteps         | 147500       |
| value_loss              | 0.0007502912 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013068392  |
| ent_coef_loss           | -4.309852     |
| entropy                 | 0.3852458     |
| ep_rewmean              | -2.43         |
| episodes                | 1480          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 147801        |
| policy_loss             | 0.6450105     |
| qf1_loss                | 0.00036883057 |
| qf2_loss                | 0.00029061438 |
| time_elapsed            | 711           |
| total timesteps         | 147900        |
| value_loss              | 0.00021179611 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012849605  |
| ent_coef_loss           | 0.9351052     |
| entropy                 | 0.5814009     |
| ep_rewmean              | -2.42         |
| episodes                | 1484          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 148201        |
| policy_loss             | 0.6216544     |
| qf1_loss                | 0.0067032776  |
| qf2_loss                | 0.0066950694  |
| time_elapsed            | 713           |
| total timesteps         | 148300        |
| value_loss              | 0.00027909488 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001252964   |
| ent_coef_loss           | -4.380413     |
| entropy                 | 0.016170826   |
| ep_rewmean              | -2.4          |
| episodes                | 1488          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 148601        |
| policy_loss             | 0.6491275     |
| qf1_loss                | 0.00022110056 |
| qf2_loss                | 0.00034909026 |
| time_elapsed            | 715           |
| total timesteps         | 148700        |
| value_loss              | 0.00038569432 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011903009  |
| ent_coef_loss           | -4.759364     |
| entropy                 | -0.11555435   |
| ep_rewmean              | -2.43         |
| episodes                | 1492          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 149001        |
| policy_loss             | 0.66817105    |
| qf1_loss                | 0.00019329884 |
| qf2_loss                | 0.00026942158 |
| time_elapsed            | 717           |
| total timesteps         | 149100        |
| value_loss              | 0.0001709086  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011538382  |
| ent_coef_loss           | 0.99295235    |
| entropy                 | 0.4103896     |
| ep_rewmean              | -2.41         |
| episodes                | 1496          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 149401        |
| policy_loss             | 0.64352465    |
| qf1_loss                | 0.00024158838 |
| qf2_loss                | 0.0001840567  |
| time_elapsed            | 719           |
| total timesteps         | 149500        |
| value_loss              | 0.00023966789 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011827337  |
| ent_coef_loss           | -4.548767     |
| entropy                 | 0.66285086    |
| ep_rewmean              | -2.41         |
| episodes                | 1500          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 149801        |
| policy_loss             | 0.6624887     |
| qf1_loss                | 0.0088386545  |
| qf2_loss                | 0.009239908   |
| time_elapsed            | 721           |
| total timesteps         | 149900        |
| value_loss              | 0.00019722726 |
-------------------------------------------
Eval num_timesteps=150000, episode_reward=-1.38 +/- 0.41
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011968358  |
| ent_coef_loss           | -0.4454192    |
| entropy                 | -0.13120288   |
| ep_rewmean              | -2.45         |
| episodes                | 1504          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 150201        |
| policy_loss             | 0.654065      |
| qf1_loss                | 0.00032365572 |
| qf2_loss                | 0.0002683288  |
| time_elapsed            | 723           |
| total timesteps         | 150300        |
| value_loss              | 0.0002220201  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001196543  |
| ent_coef_loss           | 7.0907693    |
| entropy                 | -0.23558795  |
| ep_rewmean              | -2.46        |
| episodes                | 1508         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.5         |
| n_updates               | 150601       |
| policy_loss             | 0.6625422    |
| qf1_loss                | 0.0027387356 |
| qf2_loss                | 0.0025344458 |
| time_elapsed            | 725          |
| total timesteps         | 150700       |
| value_loss              | 0.0003499236 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011872479  |
| ent_coef_loss           | -2.0522165    |
| entropy                 | 0.68131524    |
| ep_rewmean              | -2.49         |
| episodes                | 1512          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 151001        |
| policy_loss             | 0.69180435    |
| qf1_loss                | 0.0002767844  |
| qf2_loss                | 0.00020954187 |
| time_elapsed            | 727           |
| total timesteps         | 151100        |
| value_loss              | 0.00020241417 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011677588  |
| ent_coef_loss           | -3.8734467    |
| entropy                 | -0.06796431   |
| ep_rewmean              | -2.47         |
| episodes                | 1516          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 151401        |
| policy_loss             | 0.593315      |
| qf1_loss                | 0.0026337919  |
| qf2_loss                | 0.0025441977  |
| time_elapsed            | 729           |
| total timesteps         | 151500        |
| value_loss              | 0.00030218024 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011720264  |
| ent_coef_loss           | -0.35129333   |
| entropy                 | 0.081439205   |
| ep_rewmean              | -2.46         |
| episodes                | 1520          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 151801        |
| policy_loss             | 0.6854076     |
| qf1_loss                | 0.004563413   |
| qf2_loss                | 0.0043604136  |
| time_elapsed            | 731           |
| total timesteps         | 151900        |
| value_loss              | 0.00023170747 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011841705  |
| ent_coef_loss           | 3.238442      |
| entropy                 | 0.5761409     |
| ep_rewmean              | -2.36         |
| episodes                | 1524          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 152201        |
| policy_loss             | 0.6610813     |
| qf1_loss                | 0.00056960905 |
| qf2_loss                | 0.00043496618 |
| time_elapsed            | 733           |
| total timesteps         | 152300        |
| value_loss              | 0.00031309942 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001199573   |
| ent_coef_loss           | -9.443332     |
| entropy                 | 0.4039423     |
| ep_rewmean              | -2.31         |
| episodes                | 1528          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 152601        |
| policy_loss             | 0.6737321     |
| qf1_loss                | 0.0002109379  |
| qf2_loss                | 0.00023348336 |
| time_elapsed            | 734           |
| total timesteps         | 152700        |
| value_loss              | 0.0001919808  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011844133  |
| ent_coef_loss           | -2.505744     |
| entropy                 | -0.42031187   |
| ep_rewmean              | -2.29         |
| episodes                | 1532          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 153001        |
| policy_loss             | 0.648322      |
| qf1_loss                | 0.003210626   |
| qf2_loss                | 0.003039238   |
| time_elapsed            | 736           |
| total timesteps         | 153100        |
| value_loss              | 0.00021862893 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011777312  |
| ent_coef_loss           | -4.1544847    |
| entropy                 | -0.514549     |
| ep_rewmean              | -2.34         |
| episodes                | 1536          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 153401        |
| policy_loss             | 0.65583813    |
| qf1_loss                | 0.004730864   |
| qf2_loss                | 0.0046476787  |
| time_elapsed            | 738           |
| total timesteps         | 153500        |
| value_loss              | 0.00019127764 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001132706  |
| ent_coef_loss           | 2.3340437    |
| entropy                 | -0.5409262   |
| ep_rewmean              | -2.33        |
| episodes                | 1540         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 153801       |
| policy_loss             | 0.5972407    |
| qf1_loss                | 0.0017747422 |
| qf2_loss                | 0.0018437075 |
| time_elapsed            | 740          |
| total timesteps         | 153900       |
| value_loss              | 0.0002287094 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011276219  |
| ent_coef_loss           | 1.8160753     |
| entropy                 | -0.7364665    |
| ep_rewmean              | -2.36         |
| episodes                | 1544          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 154201        |
| policy_loss             | 0.6382357     |
| qf1_loss                | 0.00023954707 |
| qf2_loss                | 0.00021216719 |
| time_elapsed            | 742           |
| total timesteps         | 154300        |
| value_loss              | 0.00020080194 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011722718  |
| ent_coef_loss           | 0.4501214     |
| entropy                 | -0.3612698    |
| ep_rewmean              | -2.29         |
| episodes                | 1548          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 154601        |
| policy_loss             | 0.5997449     |
| qf1_loss                | 0.0023716572  |
| qf2_loss                | 0.0028244173  |
| time_elapsed            | 744           |
| total timesteps         | 154700        |
| value_loss              | 0.00018060235 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012770918  |
| ent_coef_loss           | 2.3985891     |
| entropy                 | -0.24393901   |
| ep_rewmean              | -2.24         |
| episodes                | 1552          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 155001        |
| policy_loss             | 0.59174204    |
| qf1_loss                | 0.0001922669  |
| qf2_loss                | 0.00016971212 |
| time_elapsed            | 746           |
| total timesteps         | 155100        |
| value_loss              | 0.00025837854 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013282066  |
| ent_coef_loss           | -6.163343     |
| entropy                 | 0.15509345    |
| ep_rewmean              | -2.23         |
| episodes                | 1556          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 155401        |
| policy_loss             | 0.5926055     |
| qf1_loss                | 0.006528274   |
| qf2_loss                | 0.0064277     |
| time_elapsed            | 748           |
| total timesteps         | 155500        |
| value_loss              | 0.00019691131 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013647662  |
| ent_coef_loss           | -0.41058356   |
| entropy                 | -0.011052314  |
| ep_rewmean              | -2.22         |
| episodes                | 1560          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 155801        |
| policy_loss             | 0.5438874     |
| qf1_loss                | 0.0002487753  |
| qf2_loss                | 0.00030077214 |
| time_elapsed            | 750           |
| total timesteps         | 155900        |
| value_loss              | 0.00042649874 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013383762  |
| ent_coef_loss           | 1.9143581     |
| entropy                 | -0.62270653   |
| ep_rewmean              | -2.21         |
| episodes                | 1564          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 156201        |
| policy_loss             | 0.5980184     |
| qf1_loss                | 0.0017926308  |
| qf2_loss                | 0.0017768163  |
| time_elapsed            | 752           |
| total timesteps         | 156300        |
| value_loss              | 0.00022696922 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013247606  |
| ent_coef_loss           | 6.0812397     |
| entropy                 | -0.22758049   |
| ep_rewmean              | -2.25         |
| episodes                | 1568          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 156601        |
| policy_loss             | 0.5730429     |
| qf1_loss                | 0.00024421146 |
| qf2_loss                | 0.00037440116 |
| time_elapsed            | 754           |
| total timesteps         | 156700        |
| value_loss              | 0.000347118   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001333702   |
| ent_coef_loss           | -1.3118566    |
| entropy                 | -0.33436263   |
| ep_rewmean              | -2.25         |
| episodes                | 1572          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 157001        |
| policy_loss             | 0.57533234    |
| qf1_loss                | 0.00027733156 |
| qf2_loss                | 0.00031407693 |
| time_elapsed            | 756           |
| total timesteps         | 157100        |
| value_loss              | 0.00018109119 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013530753  |
| ent_coef_loss           | 5.338087      |
| entropy                 | -0.053184174  |
| ep_rewmean              | -2.24         |
| episodes                | 1576          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 157401        |
| policy_loss             | 0.62129337    |
| qf1_loss                | 0.0009182896  |
| qf2_loss                | 0.0010167798  |
| time_elapsed            | 758           |
| total timesteps         | 157500        |
| value_loss              | 0.00020689008 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013243085 |
| ent_coef_loss           | -0.18622518  |
| entropy                 | -0.25818437  |
| ep_rewmean              | -2.2         |
| episodes                | 1580         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 157801       |
| policy_loss             | 0.60107076   |
| qf1_loss                | 0.0040497417 |
| qf2_loss                | 0.003995301  |
| time_elapsed            | 759          |
| total timesteps         | 157900       |
| value_loss              | 0.0003863506 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013518236 |
| ent_coef_loss           | 1.5684317    |
| entropy                 | -0.23860519  |
| ep_rewmean              | -2.22        |
| episodes                | 1584         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 158201       |
| policy_loss             | 0.55526596   |
| qf1_loss                | 0.0023809937 |
| qf2_loss                | 0.0022119351 |
| time_elapsed            | 761          |
| total timesteps         | 158300       |
| value_loss              | 0.000216282  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013472617  |
| ent_coef_loss           | -1.1579123    |
| entropy                 | -0.25597554   |
| ep_rewmean              | -2.2          |
| episodes                | 1588          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 158601        |
| policy_loss             | 0.5714171     |
| qf1_loss                | 0.0018288884  |
| qf2_loss                | 0.0017196339  |
| time_elapsed            | 763           |
| total timesteps         | 158700        |
| value_loss              | 0.00016473563 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013212744  |
| ent_coef_loss           | -2.0175982    |
| entropy                 | -0.23426995   |
| ep_rewmean              | -2.13         |
| episodes                | 1592          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 159001        |
| policy_loss             | 0.6100918     |
| qf1_loss                | 0.002711921   |
| qf2_loss                | 0.0026299057  |
| time_elapsed            | 765           |
| total timesteps         | 159100        |
| value_loss              | 0.00014276782 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001263926   |
| ent_coef_loss           | -4.7261953    |
| entropy                 | -0.81456065   |
| ep_rewmean              | -2.13         |
| episodes                | 1596          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 159401        |
| policy_loss             | 0.6453028     |
| qf1_loss                | 0.0011911759  |
| qf2_loss                | 0.0012864323  |
| time_elapsed            | 767           |
| total timesteps         | 159500        |
| value_loss              | 0.00018593723 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012295893  |
| ent_coef_loss           | -0.19104528   |
| entropy                 | -0.60538286   |
| ep_rewmean              | -2.08         |
| episodes                | 1600          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 159801        |
| policy_loss             | 0.6282976     |
| qf1_loss                | 0.00025876216 |
| qf2_loss                | 0.00023592019 |
| time_elapsed            | 769           |
| total timesteps         | 159900        |
| value_loss              | 0.00023702365 |
-------------------------------------------
Eval num_timesteps=160000, episode_reward=-1.89 +/- 0.77
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001231649  |
| ent_coef_loss           | -0.07027465  |
| entropy                 | -0.11563291  |
| ep_rewmean              | -2.08        |
| episodes                | 1604         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 160201       |
| policy_loss             | 0.6589261    |
| qf1_loss                | 0.01761271   |
| qf2_loss                | 0.018136209  |
| time_elapsed            | 771          |
| total timesteps         | 160300       |
| value_loss              | 0.0007374989 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012551018  |
| ent_coef_loss           | 3.607329      |
| entropy                 | -0.28243166   |
| ep_rewmean              | -2.07         |
| episodes                | 1608          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 160601        |
| policy_loss             | 0.63822377    |
| qf1_loss                | 0.00021434706 |
| qf2_loss                | 0.00020512621 |
| time_elapsed            | 773           |
| total timesteps         | 160700        |
| value_loss              | 0.00040668482 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012715919  |
| ent_coef_loss           | -1.7402318    |
| entropy                 | -0.49051964   |
| ep_rewmean              | -2.07         |
| episodes                | 1612          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 161001        |
| policy_loss             | 0.6382141     |
| qf1_loss                | 0.00020547974 |
| qf2_loss                | 0.00021564784 |
| time_elapsed            | 775           |
| total timesteps         | 161100        |
| value_loss              | 0.0003064926  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001343717   |
| ent_coef_loss           | 1.5058653     |
| entropy                 | -0.87275165   |
| ep_rewmean              | -2.13         |
| episodes                | 1616          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 161401        |
| policy_loss             | 0.6559129     |
| qf1_loss                | 0.00022650484 |
| qf2_loss                | 0.0003490257  |
| time_elapsed            | 777           |
| total timesteps         | 161500        |
| value_loss              | 0.00026649667 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013679483 |
| ent_coef_loss           | -2.308107    |
| entropy                 | 0.061013192  |
| ep_rewmean              | -2.16        |
| episodes                | 1620         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 161801       |
| policy_loss             | 0.66194296   |
| qf1_loss                | 0.015763188  |
| qf2_loss                | 0.014744317  |
| time_elapsed            | 779          |
| total timesteps         | 161900       |
| value_loss              | 0.0003207376 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014052874  |
| ent_coef_loss           | -0.78549194   |
| entropy                 | -0.10537486   |
| ep_rewmean              | -2.19         |
| episodes                | 1624          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 162201        |
| policy_loss             | 0.6920295     |
| qf1_loss                | 0.00033644272 |
| qf2_loss                | 0.00036537886 |
| time_elapsed            | 781           |
| total timesteps         | 162300        |
| value_loss              | 0.00020714961 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014743095  |
| ent_coef_loss           | -3.6228185    |
| entropy                 | 0.049729854   |
| ep_rewmean              | -2.21         |
| episodes                | 1628          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 162601        |
| policy_loss             | 0.5944221     |
| qf1_loss                | 0.00039655637 |
| qf2_loss                | 0.00042587344 |
| time_elapsed            | 783           |
| total timesteps         | 162700        |
| value_loss              | 0.00016529797 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015345408 |
| ent_coef_loss           | 2.788062     |
| entropy                 | 0.10561855   |
| ep_rewmean              | -2.16        |
| episodes                | 1632         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 163001       |
| policy_loss             | 0.6473429    |
| qf1_loss                | 0.0022785235 |
| qf2_loss                | 0.0022815524 |
| time_elapsed            | 784          |
| total timesteps         | 163100       |
| value_loss              | 0.0001896995 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016152846  |
| ent_coef_loss           | -4.0121536    |
| entropy                 | 0.7658866     |
| ep_rewmean              | -2.08         |
| episodes                | 1636          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 163401        |
| policy_loss             | 0.6692632     |
| qf1_loss                | 0.00094756065 |
| qf2_loss                | 0.00094426743 |
| time_elapsed            | 786           |
| total timesteps         | 163500        |
| value_loss              | 0.0003919038  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016171812 |
| ent_coef_loss           | -2.9630642   |
| entropy                 | 0.8137115    |
| ep_rewmean              | -2.08        |
| episodes                | 1640         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 163801       |
| policy_loss             | 0.6443796    |
| qf1_loss                | 0.0048102527 |
| qf2_loss                | 0.0048676548 |
| time_elapsed            | 788          |
| total timesteps         | 163900       |
| value_loss              | 0.0003031866 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016183137  |
| ent_coef_loss           | -0.024174929  |
| entropy                 | 0.08576093    |
| ep_rewmean              | -2.05         |
| episodes                | 1644          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 164201        |
| policy_loss             | 0.6406973     |
| qf1_loss                | 0.00020720917 |
| qf2_loss                | 0.00019765772 |
| time_elapsed            | 790           |
| total timesteps         | 164300        |
| value_loss              | 0.00026215875 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016254426  |
| ent_coef_loss           | -2.8064744    |
| entropy                 | 0.2345004     |
| ep_rewmean              | -2.04         |
| episodes                | 1648          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 164601        |
| policy_loss             | 0.6520636     |
| qf1_loss                | 0.00030084702 |
| qf2_loss                | 0.00026138723 |
| time_elapsed            | 792           |
| total timesteps         | 164700        |
| value_loss              | 0.0003644884  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016415018  |
| ent_coef_loss           | 1.2365297     |
| entropy                 | 0.26405528    |
| ep_rewmean              | -2.12         |
| episodes                | 1652          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 165001        |
| policy_loss             | 0.70725137    |
| qf1_loss                | 0.0024046046  |
| qf2_loss                | 0.0023209662  |
| time_elapsed            | 794           |
| total timesteps         | 165100        |
| value_loss              | 0.00028115604 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016242797  |
| ent_coef_loss           | 4.413881      |
| entropy                 | 0.36613858    |
| ep_rewmean              | -2.12         |
| episodes                | 1656          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 165401        |
| policy_loss             | 0.65226907    |
| qf1_loss                | 0.00022166011 |
| qf2_loss                | 0.00021492201 |
| time_elapsed            | 796           |
| total timesteps         | 165500        |
| value_loss              | 0.00023319706 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015914352  |
| ent_coef_loss           | 7.2724986     |
| entropy                 | 0.34049705    |
| ep_rewmean              | -2.15         |
| episodes                | 1660          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 165801        |
| policy_loss             | 0.68540955    |
| qf1_loss                | 0.02360288    |
| qf2_loss                | 0.0234382     |
| time_elapsed            | 798           |
| total timesteps         | 165900        |
| value_loss              | 0.00016891482 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015631922  |
| ent_coef_loss           | -3.5334218    |
| entropy                 | 0.4295894     |
| ep_rewmean              | -2.19         |
| episodes                | 1664          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 166201        |
| policy_loss             | 0.64340687    |
| qf1_loss                | 0.0048244307  |
| qf2_loss                | 0.005160571   |
| time_elapsed            | 800           |
| total timesteps         | 166300        |
| value_loss              | 0.00024391396 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015263046  |
| ent_coef_loss           | -1.6934191    |
| entropy                 | 1.4751602     |
| ep_rewmean              | -2.19         |
| episodes                | 1668          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 166601        |
| policy_loss             | 0.66811043    |
| qf1_loss                | 0.00054638385 |
| qf2_loss                | 0.00043504458 |
| time_elapsed            | 802           |
| total timesteps         | 166700        |
| value_loss              | 0.00023763307 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015182953 |
| ent_coef_loss           | 0.30150223   |
| entropy                 | 1.1191087    |
| ep_rewmean              | -2.17        |
| episodes                | 1672         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 167001       |
| policy_loss             | 0.64677644   |
| qf1_loss                | 0.005828173  |
| qf2_loss                | 0.005787989  |
| time_elapsed            | 804          |
| total timesteps         | 167100       |
| value_loss              | 0.0002688506 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014862892  |
| ent_coef_loss           | -0.45944524   |
| entropy                 | 0.916592      |
| ep_rewmean              | -2.2          |
| episodes                | 1676          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 167401        |
| policy_loss             | 0.657213      |
| qf1_loss                | 0.00022191508 |
| qf2_loss                | 0.00021413338 |
| time_elapsed            | 806           |
| total timesteps         | 167500        |
| value_loss              | 0.00018323427 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015881534  |
| ent_coef_loss           | 8.956142      |
| entropy                 | 1.5879909     |
| ep_rewmean              | -2.2          |
| episodes                | 1680          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 167801        |
| policy_loss             | 0.596501      |
| qf1_loss                | 0.00028412358 |
| qf2_loss                | 0.0002628317  |
| time_elapsed            | 807           |
| total timesteps         | 167900        |
| value_loss              | 0.00045390998 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017609325  |
| ent_coef_loss           | 0.6612382     |
| entropy                 | 1.0789336     |
| ep_rewmean              | -2.16         |
| episodes                | 1684          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 168201        |
| policy_loss             | 0.611982      |
| qf1_loss                | 0.0020817071  |
| qf2_loss                | 0.0020641482  |
| time_elapsed            | 809           |
| total timesteps         | 168300        |
| value_loss              | 0.00020834833 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018558279  |
| ent_coef_loss           | -6.804569     |
| entropy                 | 0.9125228     |
| ep_rewmean              | -2.14         |
| episodes                | 1688          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 168601        |
| policy_loss             | 0.67397594    |
| qf1_loss                | 0.0002650119  |
| qf2_loss                | 0.00031865985 |
| time_elapsed            | 811           |
| total timesteps         | 168700        |
| value_loss              | 0.0005539559  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018046527  |
| ent_coef_loss           | -1.7596552    |
| entropy                 | 1.533601      |
| ep_rewmean              | -2.14         |
| episodes                | 1692          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 169001        |
| policy_loss             | 0.64070034    |
| qf1_loss                | 0.00043308234 |
| qf2_loss                | 0.00039575296 |
| time_elapsed            | 813           |
| total timesteps         | 169100        |
| value_loss              | 0.00039861022 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017295611  |
| ent_coef_loss           | 5.0202193     |
| entropy                 | 0.67210853    |
| ep_rewmean              | -2.17         |
| episodes                | 1696          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 169401        |
| policy_loss             | 0.71253484    |
| qf1_loss                | 0.017354915   |
| qf2_loss                | 0.015192205   |
| time_elapsed            | 815           |
| total timesteps         | 169500        |
| value_loss              | 0.00088776054 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00172388    |
| ent_coef_loss           | 1.6996068     |
| entropy                 | 1.3445739     |
| ep_rewmean              | -2.19         |
| episodes                | 1700          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 169801        |
| policy_loss             | 0.58514565    |
| qf1_loss                | 0.0033574179  |
| qf2_loss                | 0.0034190284  |
| time_elapsed            | 817           |
| total timesteps         | 169900        |
| value_loss              | 0.00032014435 |
-------------------------------------------
Eval num_timesteps=170000, episode_reward=-2.65 +/- 1.98
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017015057 |
| ent_coef_loss           | 3.2630448    |
| entropy                 | 1.3255719    |
| ep_rewmean              | -2.14        |
| episodes                | 1704         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 170201       |
| policy_loss             | 0.6163705    |
| qf1_loss                | 0.009318197  |
| qf2_loss                | 0.009135321  |
| time_elapsed            | 819          |
| total timesteps         | 170300       |
| value_loss              | 0.0003087758 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016829686  |
| ent_coef_loss           | -6.5888405    |
| entropy                 | 1.4532006     |
| ep_rewmean              | -2.18         |
| episodes                | 1708          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 170601        |
| policy_loss             | 0.6660298     |
| qf1_loss                | 0.0008201286  |
| qf2_loss                | 0.00036442425 |
| time_elapsed            | 821           |
| total timesteps         | 170700        |
| value_loss              | 0.0002820628  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016375913  |
| ent_coef_loss           | -5.2051897    |
| entropy                 | 1.5121816     |
| ep_rewmean              | -2.22         |
| episodes                | 1712          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 171001        |
| policy_loss             | 0.6443707     |
| qf1_loss                | 0.0002416515  |
| qf2_loss                | 0.00016084121 |
| time_elapsed            | 823           |
| total timesteps         | 171100        |
| value_loss              | 0.00021573275 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016083927  |
| ent_coef_loss           | 0.95494294    |
| entropy                 | 0.78330255    |
| ep_rewmean              | -2.18         |
| episodes                | 1716          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 171401        |
| policy_loss             | 0.6260978     |
| qf1_loss                | 0.00036896777 |
| qf2_loss                | 0.00038641703 |
| time_elapsed            | 825           |
| total timesteps         | 171500        |
| value_loss              | 0.000316125   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015884867  |
| ent_coef_loss           | -2.190165     |
| entropy                 | 1.3292258     |
| ep_rewmean              | -2.19         |
| episodes                | 1720          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 171801        |
| policy_loss             | 0.69207245    |
| qf1_loss                | 0.00027536356 |
| qf2_loss                | 0.00023873325 |
| time_elapsed            | 827           |
| total timesteps         | 171900        |
| value_loss              | 0.00026431854 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015681682 |
| ent_coef_loss           | -1.0415229   |
| entropy                 | 1.0630487    |
| ep_rewmean              | -2.15        |
| episodes                | 1724         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 172201       |
| policy_loss             | 0.6370158    |
| qf1_loss                | 0.002062066  |
| qf2_loss                | 0.0019390257 |
| time_elapsed            | 829          |
| total timesteps         | 172300       |
| value_loss              | 0.0002354238 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015169493  |
| ent_coef_loss           | -1.509023     |
| entropy                 | 0.8667847     |
| ep_rewmean              | -2.16         |
| episodes                | 1728          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 172601        |
| policy_loss             | 0.6803485     |
| qf1_loss                | 0.00038019588 |
| qf2_loss                | 0.0003497478  |
| time_elapsed            | 831           |
| total timesteps         | 172700        |
| value_loss              | 0.0001521966  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014843395  |
| ent_coef_loss           | 1.2527375     |
| entropy                 | 1.4906542     |
| ep_rewmean              | -2.26         |
| episodes                | 1732          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 173001        |
| policy_loss             | 0.6804046     |
| qf1_loss                | 0.0008427947  |
| qf2_loss                | 0.00085684797 |
| time_elapsed            | 833           |
| total timesteps         | 173100        |
| value_loss              | 0.00051986217 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014630149  |
| ent_coef_loss           | 6.7256136     |
| entropy                 | 1.1281128     |
| ep_rewmean              | -2.27         |
| episodes                | 1736          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 173401        |
| policy_loss             | 0.6556102     |
| qf1_loss                | 0.00026962784 |
| qf2_loss                | 0.0002318878  |
| time_elapsed            | 835           |
| total timesteps         | 173500        |
| value_loss              | 0.00030370057 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001417745   |
| ent_coef_loss           | -6.9230204    |
| entropy                 | 1.7530231     |
| ep_rewmean              | -2.19         |
| episodes                | 1740          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 173801        |
| policy_loss             | 0.71060956    |
| qf1_loss                | 0.00024284357 |
| qf2_loss                | 0.0003886149  |
| time_elapsed            | 836           |
| total timesteps         | 173900        |
| value_loss              | 0.00025791483 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014157859  |
| ent_coef_loss           | -6.685316     |
| entropy                 | 1.9954818     |
| ep_rewmean              | -2.17         |
| episodes                | 1744          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 174201        |
| policy_loss             | 0.70854884    |
| qf1_loss                | 0.00020901657 |
| qf2_loss                | 0.00020849143 |
| time_elapsed            | 838           |
| total timesteps         | 174300        |
| value_loss              | 0.00030144386 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014317139  |
| ent_coef_loss           | 7.6575065     |
| entropy                 | 2.0102518     |
| ep_rewmean              | -2.2          |
| episodes                | 1748          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 174601        |
| policy_loss             | 0.5916873     |
| qf1_loss                | 0.00029621698 |
| qf2_loss                | 0.00023163407 |
| time_elapsed            | 840           |
| total timesteps         | 174700        |
| value_loss              | 0.00026328288 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014478406  |
| ent_coef_loss           | -2.1125753    |
| entropy                 | 1.5053196     |
| ep_rewmean              | -2.14         |
| episodes                | 1752          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 175001        |
| policy_loss             | 0.68891543    |
| qf1_loss                | 0.00026310765 |
| qf2_loss                | 0.00027450675 |
| time_elapsed            | 842           |
| total timesteps         | 175100        |
| value_loss              | 0.0002502151  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015360225  |
| ent_coef_loss           | -0.17563844   |
| entropy                 | 2.0737343     |
| ep_rewmean              | -2.13         |
| episodes                | 1756          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 175401        |
| policy_loss             | 0.66576296    |
| qf1_loss                | 0.0002733585  |
| qf2_loss                | 0.00023400431 |
| time_elapsed            | 844           |
| total timesteps         | 175500        |
| value_loss              | 0.0003239651  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016624099  |
| ent_coef_loss           | -2.538696     |
| entropy                 | 1.8205094     |
| ep_rewmean              | -2.11         |
| episodes                | 1760          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 175801        |
| policy_loss             | 0.6134134     |
| qf1_loss                | 0.0043602167  |
| qf2_loss                | 0.004391608   |
| time_elapsed            | 846           |
| total timesteps         | 175900        |
| value_loss              | 0.00042204463 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017378984  |
| ent_coef_loss           | 4.3942795     |
| entropy                 | 2.1426613     |
| ep_rewmean              | -2.08         |
| episodes                | 1764          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 176201        |
| policy_loss             | 0.6630584     |
| qf1_loss                | 0.00030409277 |
| qf2_loss                | 0.00030398974 |
| time_elapsed            | 848           |
| total timesteps         | 176300        |
| value_loss              | 0.00028850487 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016346142  |
| ent_coef_loss           | 3.3410318     |
| entropy                 | 1.7554698     |
| ep_rewmean              | -2.07         |
| episodes                | 1768          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 176601        |
| policy_loss             | 0.6890013     |
| qf1_loss                | 0.0059413468  |
| qf2_loss                | 0.006107154   |
| time_elapsed            | 850           |
| total timesteps         | 176700        |
| value_loss              | 0.00034955077 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015532433 |
| ent_coef_loss           | -2.773745    |
| entropy                 | 1.3661292    |
| ep_rewmean              | -2.05        |
| episodes                | 1772         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 177001       |
| policy_loss             | 0.6890277    |
| qf1_loss                | 0.000365082  |
| qf2_loss                | 0.000455345  |
| time_elapsed            | 852          |
| total timesteps         | 177100       |
| value_loss              | 0.0002888028 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016551282 |
| ent_coef_loss           | 3.2039926    |
| entropy                 | 1.5584056    |
| ep_rewmean              | -1.97        |
| episodes                | 1776         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 177401       |
| policy_loss             | 0.6970302    |
| qf1_loss                | 0.0013067316 |
| qf2_loss                | 0.0012877755 |
| time_elapsed            | 853          |
| total timesteps         | 177500       |
| value_loss              | 0.0004128815 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017532143  |
| ent_coef_loss           | 2.3995633     |
| entropy                 | 2.1420107     |
| ep_rewmean              | -1.91         |
| episodes                | 1780          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 177801        |
| policy_loss             | 0.6552376     |
| qf1_loss                | 0.00028365062 |
| qf2_loss                | 0.00031594114 |
| time_elapsed            | 855           |
| total timesteps         | 177900        |
| value_loss              | 0.0008114987  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017314062 |
| ent_coef_loss           | -5.474646    |
| entropy                 | 0.801296     |
| ep_rewmean              | -1.89        |
| episodes                | 1784         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 178201       |
| policy_loss             | 0.69242555   |
| qf1_loss                | 0.0043497775 |
| qf2_loss                | 0.004311486  |
| time_elapsed            | 857          |
| total timesteps         | 178300       |
| value_loss              | 0.0003174365 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001632027   |
| ent_coef_loss           | -1.8064337    |
| entropy                 | 1.9271061     |
| ep_rewmean              | -1.94         |
| episodes                | 1788          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 178601        |
| policy_loss             | 0.68646944    |
| qf1_loss                | 0.0002274479  |
| qf2_loss                | 0.00022593563 |
| time_elapsed            | 859           |
| total timesteps         | 178700        |
| value_loss              | 0.0003599829  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016016486  |
| ent_coef_loss           | -5.443604     |
| entropy                 | 1.4746115     |
| ep_rewmean              | -1.92         |
| episodes                | 1792          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 179001        |
| policy_loss             | 0.67376596    |
| qf1_loss                | 0.0002335103  |
| qf2_loss                | 0.00020608724 |
| time_elapsed            | 861           |
| total timesteps         | 179100        |
| value_loss              | 0.00026713478 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015637104  |
| ent_coef_loss           | 4.69293       |
| entropy                 | 1.0653391     |
| ep_rewmean              | -1.88         |
| episodes                | 1796          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 179401        |
| policy_loss             | 0.6931234     |
| qf1_loss                | 0.00030888643 |
| qf2_loss                | 0.0002162784  |
| time_elapsed            | 863           |
| total timesteps         | 179500        |
| value_loss              | 0.00046473992 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015155119  |
| ent_coef_loss           | -0.74671173   |
| entropy                 | 1.1518028     |
| ep_rewmean              | -1.88         |
| episodes                | 1800          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 179801        |
| policy_loss             | 0.71660835    |
| qf1_loss                | 0.00018786435 |
| qf2_loss                | 0.00020221785 |
| time_elapsed            | 865           |
| total timesteps         | 179900        |
| value_loss              | 0.0002926677  |
-------------------------------------------
Eval num_timesteps=180000, episode_reward=-2.17 +/- 1.87
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014822282  |
| ent_coef_loss           | 3.755598      |
| entropy                 | 1.2165284     |
| ep_rewmean              | -1.96         |
| episodes                | 1804          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 180201        |
| policy_loss             | 0.6291468     |
| qf1_loss                | 0.0002878696  |
| qf2_loss                | 0.00030056923 |
| time_elapsed            | 867           |
| total timesteps         | 180300        |
| value_loss              | 0.00032375933 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013910322  |
| ent_coef_loss           | -4.2350082    |
| entropy                 | 1.7029307     |
| ep_rewmean              | -1.96         |
| episodes                | 1808          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 180601        |
| policy_loss             | 0.6599769     |
| qf1_loss                | 0.00023594584 |
| qf2_loss                | 0.00026035364 |
| time_elapsed            | 869           |
| total timesteps         | 180700        |
| value_loss              | 0.00026419404 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014329331  |
| ent_coef_loss           | 3.4153152     |
| entropy                 | 1.6688833     |
| ep_rewmean              | -1.98         |
| episodes                | 1812          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 181001        |
| policy_loss             | 0.6125977     |
| qf1_loss                | 0.00049961056 |
| qf2_loss                | 0.00056506484 |
| time_elapsed            | 871           |
| total timesteps         | 181100        |
| value_loss              | 0.0002497997  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001560817   |
| ent_coef_loss           | 2.321096      |
| entropy                 | 2.15657       |
| ep_rewmean              | -1.96         |
| episodes                | 1816          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 181401        |
| policy_loss             | 0.6859167     |
| qf1_loss                | 0.0042261556  |
| qf2_loss                | 0.0040628174  |
| time_elapsed            | 873           |
| total timesteps         | 181500        |
| value_loss              | 0.00016485123 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016623345  |
| ent_coef_loss           | -1.6200212    |
| entropy                 | 2.24951       |
| ep_rewmean              | -1.93         |
| episodes                | 1820          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 181801        |
| policy_loss             | 0.7211751     |
| qf1_loss                | 0.00032965207 |
| qf2_loss                | 0.0004196721  |
| time_elapsed            | 875           |
| total timesteps         | 181900        |
| value_loss              | 0.0003993065  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001705647   |
| ent_coef_loss           | -0.7053058    |
| entropy                 | 2.285408      |
| ep_rewmean              | -1.87         |
| episodes                | 1824          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 182201        |
| policy_loss             | 0.63281786    |
| qf1_loss                | 0.0003571725  |
| qf2_loss                | 0.00027288095 |
| time_elapsed            | 876           |
| total timesteps         | 182300        |
| value_loss              | 0.00029620563 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00167405    |
| ent_coef_loss           | 1.1325603     |
| entropy                 | 2.0652227     |
| ep_rewmean              | -1.85         |
| episodes                | 1828          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 182601        |
| policy_loss             | 0.7141738     |
| qf1_loss                | 0.006789383   |
| qf2_loss                | 0.0068551395  |
| time_elapsed            | 878           |
| total timesteps         | 182700        |
| value_loss              | 0.00019746748 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016428588  |
| ent_coef_loss           | -2.3029318    |
| entropy                 | 1.7017353     |
| ep_rewmean              | -1.8          |
| episodes                | 1832          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 183001        |
| policy_loss             | 0.6378344     |
| qf1_loss                | 0.0013103319  |
| qf2_loss                | 0.001459335   |
| time_elapsed            | 880           |
| total timesteps         | 183100        |
| value_loss              | 0.00036554394 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001600163   |
| ent_coef_loss           | -5.723509     |
| entropy                 | 1.9242231     |
| ep_rewmean              | -1.82         |
| episodes                | 1836          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 183401        |
| policy_loss             | 0.6761557     |
| qf1_loss                | 0.00019890704 |
| qf2_loss                | 0.00020385148 |
| time_elapsed            | 882           |
| total timesteps         | 183500        |
| value_loss              | 0.000247159   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016173178  |
| ent_coef_loss           | -2.3669002    |
| entropy                 | 1.6731122     |
| ep_rewmean              | -1.83         |
| episodes                | 1840          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 183801        |
| policy_loss             | 0.6329756     |
| qf1_loss                | 0.0016576952  |
| qf2_loss                | 0.001687222   |
| time_elapsed            | 884           |
| total timesteps         | 183900        |
| value_loss              | 0.00044292415 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015395121  |
| ent_coef_loss           | -4.1275845    |
| entropy                 | 1.4851011     |
| ep_rewmean              | -1.85         |
| episodes                | 1844          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 184201        |
| policy_loss             | 0.6548452     |
| qf1_loss                | 0.0002744861  |
| qf2_loss                | 0.00023570526 |
| time_elapsed            | 886           |
| total timesteps         | 184300        |
| value_loss              | 0.00025443715 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014555845  |
| ent_coef_loss           | -6.6689177    |
| entropy                 | 2.3725095     |
| ep_rewmean              | -1.81         |
| episodes                | 1848          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 184601        |
| policy_loss             | 0.6598774     |
| qf1_loss                | 0.00046483608 |
| qf2_loss                | 0.0005013774  |
| time_elapsed            | 888           |
| total timesteps         | 184700        |
| value_loss              | 0.00023471154 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014911     |
| ent_coef_loss           | 1.2825539     |
| entropy                 | 2.2732449     |
| ep_rewmean              | -1.87         |
| episodes                | 1852          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 185001        |
| policy_loss             | 0.63361764    |
| qf1_loss                | 0.00019258092 |
| qf2_loss                | 0.00020075397 |
| time_elapsed            | 890           |
| total timesteps         | 185100        |
| value_loss              | 0.00023442865 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015452524  |
| ent_coef_loss           | -2.2745667    |
| entropy                 | 1.8499196     |
| ep_rewmean              | -1.89         |
| episodes                | 1856          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 185401        |
| policy_loss             | 0.6372668     |
| qf1_loss                | 0.00017957416 |
| qf2_loss                | 0.00015939976 |
| time_elapsed            | 892           |
| total timesteps         | 185500        |
| value_loss              | 0.00018661263 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001569862   |
| ent_coef_loss           | 4.104885      |
| entropy                 | 1.8755648     |
| ep_rewmean              | -1.86         |
| episodes                | 1860          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 185801        |
| policy_loss             | 0.61781764    |
| qf1_loss                | 0.00018599036 |
| qf2_loss                | 0.00020381405 |
| time_elapsed            | 894           |
| total timesteps         | 185900        |
| value_loss              | 0.00034706603 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001581958   |
| ent_coef_loss           | 0.28302342    |
| entropy                 | 1.6216329     |
| ep_rewmean              | -1.8          |
| episodes                | 1864          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 186201        |
| policy_loss             | 0.5979723     |
| qf1_loss                | 0.0020640069  |
| qf2_loss                | 0.0020764496  |
| time_elapsed            | 896           |
| total timesteps         | 186300        |
| value_loss              | 0.00033174467 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015138594  |
| ent_coef_loss           | 2.0113597     |
| entropy                 | 1.7920849     |
| ep_rewmean              | -1.82         |
| episodes                | 1868          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 186601        |
| policy_loss             | 0.59865487    |
| qf1_loss                | 0.0011225909  |
| qf2_loss                | 0.0011265134  |
| time_elapsed            | 898           |
| total timesteps         | 186700        |
| value_loss              | 0.00021307627 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014196121  |
| ent_coef_loss           | -1.4268783    |
| entropy                 | 1.6385334     |
| ep_rewmean              | -1.81         |
| episodes                | 1872          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 187001        |
| policy_loss             | 0.65490186    |
| qf1_loss                | 0.000978873   |
| qf2_loss                | 0.0013195416  |
| time_elapsed            | 899           |
| total timesteps         | 187100        |
| value_loss              | 0.00019627852 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014111837  |
| ent_coef_loss           | 0.7202819     |
| entropy                 | 1.5729952     |
| ep_rewmean              | -1.83         |
| episodes                | 1876          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 187401        |
| policy_loss             | 0.60525703    |
| qf1_loss                | 0.0071946294  |
| qf2_loss                | 0.006993221   |
| time_elapsed            | 901           |
| total timesteps         | 187500        |
| value_loss              | 0.00024154031 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013989819  |
| ent_coef_loss           | -0.99374026   |
| entropy                 | 1.9202712     |
| ep_rewmean              | -1.85         |
| episodes                | 1880          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 187801        |
| policy_loss             | 0.66180074    |
| qf1_loss                | 0.00017117587 |
| qf2_loss                | 0.00021401257 |
| time_elapsed            | 903           |
| total timesteps         | 187900        |
| value_loss              | 0.00036782678 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014037536  |
| ent_coef_loss           | 0.868901      |
| entropy                 | 1.8744872     |
| ep_rewmean              | -1.85         |
| episodes                | 1884          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 188201        |
| policy_loss             | 0.7037759     |
| qf1_loss                | 0.00015309062 |
| qf2_loss                | 0.00022184475 |
| time_elapsed            | 905           |
| total timesteps         | 188300        |
| value_loss              | 0.00016238159 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013626502  |
| ent_coef_loss           | -2.2023556    |
| entropy                 | 0.6144793     |
| ep_rewmean              | -1.81         |
| episodes                | 1888          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 188601        |
| policy_loss             | 0.71069014    |
| qf1_loss                | 0.00030704355 |
| qf2_loss                | 0.000279764   |
| time_elapsed            | 907           |
| total timesteps         | 188700        |
| value_loss              | 0.00030524185 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013743963  |
| ent_coef_loss           | 0.33628035    |
| entropy                 | 0.7381244     |
| ep_rewmean              | -1.83         |
| episodes                | 1892          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 189001        |
| policy_loss             | 0.64615303    |
| qf1_loss                | 0.00021816374 |
| qf2_loss                | 0.00022321401 |
| time_elapsed            | 909           |
| total timesteps         | 189100        |
| value_loss              | 0.0003930335  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014317918  |
| ent_coef_loss           | 2.2303185     |
| entropy                 | 1.1842657     |
| ep_rewmean              | -1.85         |
| episodes                | 1896          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 189401        |
| policy_loss             | 0.6493447     |
| qf1_loss                | 0.0039896457  |
| qf2_loss                | 0.0039891545  |
| time_elapsed            | 911           |
| total timesteps         | 189500        |
| value_loss              | 0.00024342642 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014590647  |
| ent_coef_loss           | 0.35263968    |
| entropy                 | 1.1646786     |
| ep_rewmean              | -1.86         |
| episodes                | 1900          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 189801        |
| policy_loss             | 0.6587275     |
| qf1_loss                | 0.0013485788  |
| qf2_loss                | 0.0013337419  |
| time_elapsed            | 913           |
| total timesteps         | 189900        |
| value_loss              | 0.00033820828 |
-------------------------------------------
Eval num_timesteps=190000, episode_reward=-1.51 +/- 1.02
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014530208  |
| ent_coef_loss           | -0.6470063    |
| entropy                 | 0.35106322    |
| ep_rewmean              | -1.78         |
| episodes                | 1904          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 190201        |
| policy_loss             | 0.6530055     |
| qf1_loss                | 0.00021100184 |
| qf2_loss                | 0.00023601296 |
| time_elapsed            | 915           |
| total timesteps         | 190300        |
| value_loss              | 0.00030498655 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014454194 |
| ent_coef_loss           | -3.8644357   |
| entropy                 | 0.32115686   |
| ep_rewmean              | -1.71        |
| episodes                | 1908         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 190601       |
| policy_loss             | 0.6429169    |
| qf1_loss                | 0.0045215324 |
| qf2_loss                | 0.004495557  |
| time_elapsed            | 917          |
| total timesteps         | 190700       |
| value_loss              | 0.000310016  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014009292  |
| ent_coef_loss           | -8.144976     |
| entropy                 | 0.06179662    |
| ep_rewmean              | -1.65         |
| episodes                | 1912          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 191001        |
| policy_loss             | 0.66508496    |
| qf1_loss                | 0.00020724977 |
| qf2_loss                | 0.00017403714 |
| time_elapsed            | 919           |
| total timesteps         | 191100        |
| value_loss              | 0.00023694197 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013431724  |
| ent_coef_loss           | -0.2569008    |
| entropy                 | 0.50862896    |
| ep_rewmean              | -1.63         |
| episodes                | 1916          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 191401        |
| policy_loss             | 0.66847247    |
| qf1_loss                | 0.00018909949 |
| qf2_loss                | 0.00021173005 |
| time_elapsed            | 921           |
| total timesteps         | 191500        |
| value_loss              | 0.00064689893 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013198362  |
| ent_coef_loss           | -2.2318325    |
| entropy                 | 0.5506764     |
| ep_rewmean              | -1.62         |
| episodes                | 1920          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 191801        |
| policy_loss             | 0.71230996    |
| qf1_loss                | 0.00022173653 |
| qf2_loss                | 0.00025007463 |
| time_elapsed            | 922           |
| total timesteps         | 191900        |
| value_loss              | 0.0002164443  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013333472  |
| ent_coef_loss           | 3.4678137     |
| entropy                 | -0.14186901   |
| ep_rewmean              | -1.69         |
| episodes                | 1924          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 192201        |
| policy_loss             | 0.6825838     |
| qf1_loss                | 0.00021875845 |
| qf2_loss                | 0.00017888503 |
| time_elapsed            | 924           |
| total timesteps         | 192300        |
| value_loss              | 0.00018739389 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013448728  |
| ent_coef_loss           | 8.990744      |
| entropy                 | 0.38357827    |
| ep_rewmean              | -1.72         |
| episodes                | 1928          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 192601        |
| policy_loss             | 0.6704388     |
| qf1_loss                | 0.00023276126 |
| qf2_loss                | 0.00020436755 |
| time_elapsed            | 926           |
| total timesteps         | 192700        |
| value_loss              | 0.00020909165 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013771962  |
| ent_coef_loss           | -3.3873575    |
| entropy                 | -0.31896928   |
| ep_rewmean              | -1.7          |
| episodes                | 1932          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 193001        |
| policy_loss             | 0.6599938     |
| qf1_loss                | 0.00029474735 |
| qf2_loss                | 0.00022490835 |
| time_elapsed            | 928           |
| total timesteps         | 193100        |
| value_loss              | 0.00016446126 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013967137  |
| ent_coef_loss           | 1.0562968     |
| entropy                 | 0.27320638    |
| ep_rewmean              | -1.68         |
| episodes                | 1936          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 193401        |
| policy_loss             | 0.61190045    |
| qf1_loss                | 0.0028879826  |
| qf2_loss                | 0.003060149   |
| time_elapsed            | 930           |
| total timesteps         | 193500        |
| value_loss              | 0.00028274715 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013938907 |
| ent_coef_loss           | 4.0649767    |
| entropy                 | -0.09093617  |
| ep_rewmean              | -1.66        |
| episodes                | 1940         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 193801       |
| policy_loss             | 0.68271875   |
| qf1_loss                | 0.0010529272 |
| qf2_loss                | 0.0007867512 |
| time_elapsed            | 932          |
| total timesteps         | 193900       |
| value_loss              | 0.0002860431 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013402001  |
| ent_coef_loss           | -0.7968041    |
| entropy                 | 0.032167442   |
| ep_rewmean              | -1.64         |
| episodes                | 1944          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 194201        |
| policy_loss             | 0.6368662     |
| qf1_loss                | 0.00019665444 |
| qf2_loss                | 0.00018869256 |
| time_elapsed            | 934           |
| total timesteps         | 194300        |
| value_loss              | 0.00018683592 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013141185 |
| ent_coef_loss           | 0.3432908    |
| entropy                 | -0.23672482  |
| ep_rewmean              | -1.65        |
| episodes                | 1948         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 194601       |
| policy_loss             | 0.6413263    |
| qf1_loss                | 0.0021616279 |
| qf2_loss                | 0.0018857549 |
| time_elapsed            | 936          |
| total timesteps         | 194700       |
| value_loss              | 0.0004248214 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013423964  |
| ent_coef_loss           | -4.3321533    |
| entropy                 | 0.4745225     |
| ep_rewmean              | -1.59         |
| episodes                | 1952          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 195001        |
| policy_loss             | 0.6801907     |
| qf1_loss                | 0.00018598684 |
| qf2_loss                | 0.00020645997 |
| time_elapsed            | 938           |
| total timesteps         | 195100        |
| value_loss              | 0.00043681782 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012900267 |
| ent_coef_loss           | 0.8531436    |
| entropy                 | 0.46184662   |
| ep_rewmean              | -1.58        |
| episodes                | 1956         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.6         |
| n_updates               | 195401       |
| policy_loss             | 0.67916656   |
| qf1_loss                | 0.0013543534 |
| qf2_loss                | 0.0011725378 |
| time_elapsed            | 940          |
| total timesteps         | 195500       |
| value_loss              | 0.000256287  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012607545  |
| ent_coef_loss           | 2.520743      |
| entropy                 | 0.54397327    |
| ep_rewmean              | -1.59         |
| episodes                | 1960          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 195801        |
| policy_loss             | 0.66195977    |
| qf1_loss                | 0.005539204   |
| qf2_loss                | 0.0054097665  |
| time_elapsed            | 941           |
| total timesteps         | 195900        |
| value_loss              | 0.00030604622 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012398264  |
| ent_coef_loss           | 2.9257004     |
| entropy                 | -0.0074619725 |
| ep_rewmean              | -1.62         |
| episodes                | 1964          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 196201        |
| policy_loss             | 0.6543572     |
| qf1_loss                | 0.00020851815 |
| qf2_loss                | 0.00026082006 |
| time_elapsed            | 943           |
| total timesteps         | 196300        |
| value_loss              | 0.00020265329 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012342046  |
| ent_coef_loss           | -3.0934153    |
| entropy                 | -0.100967824  |
| ep_rewmean              | -1.57         |
| episodes                | 1968          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 196601        |
| policy_loss             | 0.64757496    |
| qf1_loss                | 0.00017143518 |
| qf2_loss                | 0.00012118019 |
| time_elapsed            | 945           |
| total timesteps         | 196700        |
| value_loss              | 0.00031366752 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012627309  |
| ent_coef_loss           | -3.616053     |
| entropy                 | 0.49606082    |
| ep_rewmean              | -1.57         |
| episodes                | 1972          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 197001        |
| policy_loss             | 0.6587777     |
| qf1_loss                | 0.00026641443 |
| qf2_loss                | 0.00030335897 |
| time_elapsed            | 947           |
| total timesteps         | 197100        |
| value_loss              | 0.00017361698 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014016167  |
| ent_coef_loss           | 4.2232766     |
| entropy                 | 0.9284072     |
| ep_rewmean              | -1.59         |
| episodes                | 1976          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 197401        |
| policy_loss             | 0.6537807     |
| qf1_loss                | 0.0009853949  |
| qf2_loss                | 0.0011995572  |
| time_elapsed            | 949           |
| total timesteps         | 197500        |
| value_loss              | 0.00021728076 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014938541  |
| ent_coef_loss           | 1.0339862     |
| entropy                 | 1.5143391     |
| ep_rewmean              | -1.65         |
| episodes                | 1980          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.6          |
| n_updates               | 197801        |
| policy_loss             | 0.65310335    |
| qf1_loss                | 0.00051188964 |
| qf2_loss                | 0.00047389913 |
| time_elapsed            | 951           |
| total timesteps         | 197900        |
| value_loss              | 0.00021664872 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014976914  |
| ent_coef_loss           | -5.3184795    |
| entropy                 | 1.2655998     |
| ep_rewmean              | -1.76         |
| episodes                | 1984          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 198201        |
| policy_loss             | 0.661951      |
| qf1_loss                | 0.00042753722 |
| qf2_loss                | 0.0003408119  |
| time_elapsed            | 953           |
| total timesteps         | 198300        |
| value_loss              | 0.00025297087 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013634008  |
| ent_coef_loss           | -3.6072028    |
| entropy                 | 1.380755      |
| ep_rewmean              | -1.81         |
| episodes                | 1988          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 198601        |
| policy_loss             | 0.6716839     |
| qf1_loss                | 0.001818402   |
| qf2_loss                | 0.0018857016  |
| time_elapsed            | 955           |
| total timesteps         | 198700        |
| value_loss              | 0.00031447492 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012569968 |
| ent_coef_loss           | 0.9416932    |
| entropy                 | 0.6591268    |
| ep_rewmean              | -1.78        |
| episodes                | 1992         |
| eplenmean               | 100          |
| fps                     | 208          |
| mean 100 episode reward | -1.8         |
| n_updates               | 199001       |
| policy_loss             | 0.6471876    |
| qf1_loss                | 0.0012121128 |
| qf2_loss                | 0.0011659571 |
| time_elapsed            | 957          |
| total timesteps         | 199100       |
| value_loss              | 0.0002464824 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012179641  |
| ent_coef_loss           | -6.4578943    |
| entropy                 | 0.69946456    |
| ep_rewmean              | -1.78         |
| episodes                | 1996          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 199401        |
| policy_loss             | 0.648306      |
| qf1_loss                | 0.0054889712  |
| qf2_loss                | 0.0057771886  |
| time_elapsed            | 959           |
| total timesteps         | 199500        |
| value_loss              | 0.00040899456 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012090604  |
| ent_coef_loss           | 5.23239       |
| entropy                 | 0.090105265   |
| ep_rewmean              | -1.83         |
| episodes                | 2000          |
| eplenmean               | 100           |
| fps                     | 208           |
| mean 100 episode reward | -1.8          |
| n_updates               | 199801        |
| policy_loss             | 0.6940384     |
| qf1_loss                | 0.00024749938 |
| qf2_loss                | 0.00014345995 |
| time_elapsed            | 960           |
| total timesteps         | 199900        |
| value_loss              | 0.00023896189 |
-------------------------------------------
Eval num_timesteps=200000, episode_reward=-2.07 +/- 1.03
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00120795    |
| ent_coef_loss           | 2.7709668     |
| entropy                 | 0.46715224    |
| ep_rewmean              | -1.88         |
| episodes                | 2004          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 200201        |
| policy_loss             | 0.64853996    |
| qf1_loss                | 0.0030970222  |
| qf2_loss                | 0.0031000953  |
| time_elapsed            | 963           |
| total timesteps         | 200300        |
| value_loss              | 0.00020250742 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012242484  |
| ent_coef_loss           | 2.773772      |
| entropy                 | 0.65593827    |
| ep_rewmean              | -1.91         |
| episodes                | 2008          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 200601        |
| policy_loss             | 0.67280644    |
| qf1_loss                | 0.00023394875 |
| qf2_loss                | 0.00023030551 |
| time_elapsed            | 965           |
| total timesteps         | 200700        |
| value_loss              | 0.0002611298  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001276895   |
| ent_coef_loss           | 1.318327      |
| entropy                 | 0.8648046     |
| ep_rewmean              | -1.88         |
| episodes                | 2012          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 201001        |
| policy_loss             | 0.6539779     |
| qf1_loss                | 0.00016852116 |
| qf2_loss                | 0.00015246039 |
| time_elapsed            | 966           |
| total timesteps         | 201100        |
| value_loss              | 0.00016024394 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012742359  |
| ent_coef_loss           | -1.6078444    |
| entropy                 | 0.6246744     |
| ep_rewmean              | -1.88         |
| episodes                | 2016          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 201401        |
| policy_loss             | 0.63637674    |
| qf1_loss                | 0.0041374615  |
| qf2_loss                | 0.003995227   |
| time_elapsed            | 968           |
| total timesteps         | 201500        |
| value_loss              | 0.00019144532 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012413391  |
| ent_coef_loss           | -4.4518056    |
| entropy                 | 1.1950085     |
| ep_rewmean              | -1.89         |
| episodes                | 2020          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 201801        |
| policy_loss             | 0.6727245     |
| qf1_loss                | 0.00017809498 |
| qf2_loss                | 0.00025270155 |
| time_elapsed            | 970           |
| total timesteps         | 201900        |
| value_loss              | 0.0003102426  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012415197  |
| ent_coef_loss           | 2.8373737     |
| entropy                 | 1.2719345     |
| ep_rewmean              | -1.82         |
| episodes                | 2024          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 202201        |
| policy_loss             | 0.6765168     |
| qf1_loss                | 0.0046276585  |
| qf2_loss                | 0.004423912   |
| time_elapsed            | 972           |
| total timesteps         | 202300        |
| value_loss              | 0.00018885887 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011854444  |
| ent_coef_loss           | 0.80334044    |
| entropy                 | 1.0715823     |
| ep_rewmean              | -1.76         |
| episodes                | 2028          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 202601        |
| policy_loss             | 0.6613531     |
| qf1_loss                | 0.008150991   |
| qf2_loss                | 0.007954591   |
| time_elapsed            | 974           |
| total timesteps         | 202700        |
| value_loss              | 0.00039133496 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011635468  |
| ent_coef_loss           | -10.383932    |
| entropy                 | 1.0930219     |
| ep_rewmean              | -1.75         |
| episodes                | 2032          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 203001        |
| policy_loss             | 0.6546496     |
| qf1_loss                | 0.00023630433 |
| qf2_loss                | 0.00022611086 |
| time_elapsed            | 976           |
| total timesteps         | 203100        |
| value_loss              | 0.00017411963 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011609797 |
| ent_coef_loss           | 2.0261595    |
| entropy                 | 0.67330754   |
| ep_rewmean              | -1.73        |
| episodes                | 2036         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 203401       |
| policy_loss             | 0.64523804   |
| qf1_loss                | 0.002027592  |
| qf2_loss                | 0.0017681818 |
| time_elapsed            | 978          |
| total timesteps         | 203500       |
| value_loss              | 0.0003096998 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011562787  |
| ent_coef_loss           | -1.1352516    |
| entropy                 | -0.24094993   |
| ep_rewmean              | -1.74         |
| episodes                | 2040          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 203801        |
| policy_loss             | 0.6394096     |
| qf1_loss                | 0.004902496   |
| qf2_loss                | 0.0051283687  |
| time_elapsed            | 980           |
| total timesteps         | 203900        |
| value_loss              | 0.00028675114 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011712689  |
| ent_coef_loss           | 2.760885      |
| entropy                 | 0.13093773    |
| ep_rewmean              | -1.74         |
| episodes                | 2044          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 204201        |
| policy_loss             | 0.6380928     |
| qf1_loss                | 0.0066082254  |
| qf2_loss                | 0.0061127604  |
| time_elapsed            | 982           |
| total timesteps         | 204300        |
| value_loss              | 0.00023285778 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011427864  |
| ent_coef_loss           | -1.681395     |
| entropy                 | -0.45120615   |
| ep_rewmean              | -1.77         |
| episodes                | 2048          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 204601        |
| policy_loss             | 0.6163517     |
| qf1_loss                | 0.00035200798 |
| qf2_loss                | 0.00030170142 |
| time_elapsed            | 984           |
| total timesteps         | 204700        |
| value_loss              | 0.000258817   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011821784  |
| ent_coef_loss           | 6.593791      |
| entropy                 | -0.6814381    |
| ep_rewmean              | -1.77         |
| episodes                | 2052          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 205001        |
| policy_loss             | 0.6058905     |
| qf1_loss                | 0.0011625169  |
| qf2_loss                | 0.0013011643  |
| time_elapsed            | 986           |
| total timesteps         | 205100        |
| value_loss              | 0.00031562452 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011969727  |
| ent_coef_loss           | 8.4358425     |
| entropy                 | -0.5801231    |
| ep_rewmean              | -1.74         |
| episodes                | 2056          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 205401        |
| policy_loss             | 0.58355653    |
| qf1_loss                | 0.009815389   |
| qf2_loss                | 0.009959958   |
| time_elapsed            | 988           |
| total timesteps         | 205500        |
| value_loss              | 0.00027287728 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012528218  |
| ent_coef_loss           | 0.120310664   |
| entropy                 | 0.10544084    |
| ep_rewmean              | -1.77         |
| episodes                | 2060          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 205801        |
| policy_loss             | 0.6386509     |
| qf1_loss                | 0.00029692167 |
| qf2_loss                | 0.00040831396 |
| time_elapsed            | 989           |
| total timesteps         | 205900        |
| value_loss              | 0.0004426505  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013285879  |
| ent_coef_loss           | 0.87900686    |
| entropy                 | -0.57658863   |
| ep_rewmean              | -1.76         |
| episodes                | 2064          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 206201        |
| policy_loss             | 0.5778825     |
| qf1_loss                | 0.0003184214  |
| qf2_loss                | 0.00034331356 |
| time_elapsed            | 991           |
| total timesteps         | 206300        |
| value_loss              | 0.00033234697 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013786837  |
| ent_coef_loss           | 4.173562      |
| entropy                 | -0.54577047   |
| ep_rewmean              | -1.76         |
| episodes                | 2068          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 206601        |
| policy_loss             | 0.5827321     |
| qf1_loss                | 0.0014756629  |
| qf2_loss                | 0.0012272471  |
| time_elapsed            | 993           |
| total timesteps         | 206700        |
| value_loss              | 0.00037317813 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013655245  |
| ent_coef_loss           | -0.33675718   |
| entropy                 | -0.6984643    |
| ep_rewmean              | -1.79         |
| episodes                | 2072          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 207001        |
| policy_loss             | 0.5823196     |
| qf1_loss                | 0.00038737088 |
| qf2_loss                | 0.0002998832  |
| time_elapsed            | 995           |
| total timesteps         | 207100        |
| value_loss              | 0.00032695924 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013194014  |
| ent_coef_loss           | 5.451849      |
| entropy                 | 0.12974685    |
| ep_rewmean              | -1.76         |
| episodes                | 2076          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 207401        |
| policy_loss             | 0.54153794    |
| qf1_loss                | 0.00025052746 |
| qf2_loss                | 0.00031466782 |
| time_elapsed            | 997           |
| total timesteps         | 207500        |
| value_loss              | 0.00033159403 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012719703  |
| ent_coef_loss           | 4.583757      |
| entropy                 | -0.24425432   |
| ep_rewmean              | -1.7          |
| episodes                | 2080          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 207801        |
| policy_loss             | 0.5469098     |
| qf1_loss                | 0.00018158258 |
| qf2_loss                | 0.00018625984 |
| time_elapsed            | 999           |
| total timesteps         | 207900        |
| value_loss              | 0.00042275296 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012240208  |
| ent_coef_loss           | 1.297365      |
| entropy                 | -0.9770493    |
| ep_rewmean              | -1.59         |
| episodes                | 2084          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 208201        |
| policy_loss             | 0.53650236    |
| qf1_loss                | 0.0002730272  |
| qf2_loss                | 0.0002758941  |
| time_elapsed            | 1001          |
| total timesteps         | 208300        |
| value_loss              | 0.00020952764 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011710377  |
| ent_coef_loss           | 1.5128438     |
| entropy                 | 0.09084064    |
| ep_rewmean              | -1.56         |
| episodes                | 2088          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 208601        |
| policy_loss             | 0.5541593     |
| qf1_loss                | 0.00024147074 |
| qf2_loss                | 0.0002076438  |
| time_elapsed            | 1003          |
| total timesteps         | 208700        |
| value_loss              | 0.00024140863 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010923977  |
| ent_coef_loss           | 2.3982406     |
| entropy                 | -0.8580718    |
| ep_rewmean              | -1.55         |
| episodes                | 2092          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 209001        |
| policy_loss             | 0.5592997     |
| qf1_loss                | 0.00032275604 |
| qf2_loss                | 0.00034708693 |
| time_elapsed            | 1005          |
| total timesteps         | 209100        |
| value_loss              | 0.00025235256 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010615134  |
| ent_coef_loss           | -6.7896338    |
| entropy                 | -0.6073847    |
| ep_rewmean              | -1.54         |
| episodes                | 2096          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.5          |
| n_updates               | 209401        |
| policy_loss             | 0.5691936     |
| qf1_loss                | 0.0005085441  |
| qf2_loss                | 0.00047549358 |
| time_elapsed            | 1007          |
| total timesteps         | 209500        |
| value_loss              | 0.00072416564 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010050274  |
| ent_coef_loss           | 7.9761105     |
| entropy                 | -0.28920946   |
| ep_rewmean              | -1.47         |
| episodes                | 2100          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.5          |
| n_updates               | 209801        |
| policy_loss             | 0.55581856    |
| qf1_loss                | 0.00023764031 |
| qf2_loss                | 0.000257693   |
| time_elapsed            | 1009          |
| total timesteps         | 209900        |
| value_loss              | 0.00043334463 |
-------------------------------------------
Eval num_timesteps=210000, episode_reward=-0.91 +/- 0.66
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00097371585 |
| ent_coef_loss           | 4.9919043     |
| entropy                 | -0.8381297    |
| ep_rewmean              | -1.44         |
| episodes                | 2104          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.4          |
| n_updates               | 210201        |
| policy_loss             | 0.55909514    |
| qf1_loss                | 0.0004133797  |
| qf2_loss                | 0.00036681222 |
| time_elapsed            | 1011          |
| total timesteps         | 210300        |
| value_loss              | 0.00024003218 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009670376  |
| ent_coef_loss           | 2.439488      |
| entropy                 | -0.5180342    |
| ep_rewmean              | -1.43         |
| episodes                | 2108          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.4          |
| n_updates               | 210601        |
| policy_loss             | 0.5992406     |
| qf1_loss                | 0.006602752   |
| qf2_loss                | 0.0071277535  |
| time_elapsed            | 1013          |
| total timesteps         | 210700        |
| value_loss              | 0.00023115103 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00097418076 |
| ent_coef_loss           | 1.3186607     |
| entropy                 | 0.3227293     |
| ep_rewmean              | -1.43         |
| episodes                | 2112          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.4          |
| n_updates               | 211001        |
| policy_loss             | 0.5826193     |
| qf1_loss                | 0.00031707255 |
| qf2_loss                | 0.00041098188 |
| time_elapsed            | 1015          |
| total timesteps         | 211100        |
| value_loss              | 0.00035760418 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009705364  |
| ent_coef_loss           | 2.9810765     |
| entropy                 | -0.24443588   |
| ep_rewmean              | -1.43         |
| episodes                | 2116          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.4          |
| n_updates               | 211401        |
| policy_loss             | 0.55297184    |
| qf1_loss                | 0.0025475472  |
| qf2_loss                | 0.0025258705  |
| time_elapsed            | 1017          |
| total timesteps         | 211500        |
| value_loss              | 0.00012346113 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00096825155 |
| ent_coef_loss           | -2.3095047    |
| entropy                 | -0.015188361  |
| ep_rewmean              | -1.46         |
| episodes                | 2120          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.5          |
| n_updates               | 211801        |
| policy_loss             | 0.5746834     |
| qf1_loss                | 0.00019207268 |
| qf2_loss                | 0.00018788145 |
| time_elapsed            | 1019          |
| total timesteps         | 211900        |
| value_loss              | 0.0002060945  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00096325594 |
| ent_coef_loss           | -2.444056     |
| entropy                 | 0.4248265     |
| ep_rewmean              | -1.48         |
| episodes                | 2124          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.5          |
| n_updates               | 212201        |
| policy_loss             | 0.59301984    |
| qf1_loss                | 0.0001811252  |
| qf2_loss                | 0.00019790982 |
| time_elapsed            | 1021          |
| total timesteps         | 212300        |
| value_loss              | 0.00020082743 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009712619  |
| ent_coef_loss           | 2.4639735     |
| entropy                 | 0.6074017     |
| ep_rewmean              | -1.54         |
| episodes                | 2128          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.5          |
| n_updates               | 212601        |
| policy_loss             | 0.54515696    |
| qf1_loss                | 0.00038300443 |
| qf2_loss                | 0.00025805092 |
| time_elapsed            | 1022          |
| total timesteps         | 212700        |
| value_loss              | 0.00028077496 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010152677 |
| ent_coef_loss           | 5.3683214    |
| entropy                 | 0.43881106   |
| ep_rewmean              | -1.58        |
| episodes                | 2132         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.6         |
| n_updates               | 213001       |
| policy_loss             | 0.6121727    |
| qf1_loss                | 0.0022834544 |
| qf2_loss                | 0.0022483352 |
| time_elapsed            | 1024         |
| total timesteps         | 213100       |
| value_loss              | 0.0005298853 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012108022  |
| ent_coef_loss           | -0.4221846    |
| entropy                 | 1.172148      |
| ep_rewmean              | -1.66         |
| episodes                | 2136          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 213401        |
| policy_loss             | 0.5892321     |
| qf1_loss                | 0.0024825712  |
| qf2_loss                | 0.0024374237  |
| time_elapsed            | 1026          |
| total timesteps         | 213500        |
| value_loss              | 0.00023748502 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013713175  |
| ent_coef_loss           | 4.1616344     |
| entropy                 | 1.3025516     |
| ep_rewmean              | -1.65         |
| episodes                | 2140          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 213801        |
| policy_loss             | 0.59376335    |
| qf1_loss                | 0.00024479185 |
| qf2_loss                | 0.00019808466 |
| time_elapsed            | 1028          |
| total timesteps         | 213900        |
| value_loss              | 0.00021804583 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014433573  |
| ent_coef_loss           | 5.5520716     |
| entropy                 | 1.34524       |
| ep_rewmean              | -1.66         |
| episodes                | 2144          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 214201        |
| policy_loss             | 0.59247816    |
| qf1_loss                | 0.0004737727  |
| qf2_loss                | 0.000496901   |
| time_elapsed            | 1030          |
| total timesteps         | 214300        |
| value_loss              | 0.00046043014 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014981156  |
| ent_coef_loss           | -3.552319     |
| entropy                 | 1.2279701     |
| ep_rewmean              | -1.65         |
| episodes                | 2148          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 214601        |
| policy_loss             | 0.6278769     |
| qf1_loss                | 0.0026790926  |
| qf2_loss                | 0.0027715822  |
| time_elapsed            | 1032          |
| total timesteps         | 214700        |
| value_loss              | 0.00025771756 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015148342  |
| ent_coef_loss           | -1.7132788    |
| entropy                 | 1.4385196     |
| ep_rewmean              | -1.67         |
| episodes                | 2152          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 215001        |
| policy_loss             | 0.63671637    |
| qf1_loss                | 0.0018528643  |
| qf2_loss                | 0.001823291   |
| time_elapsed            | 1034          |
| total timesteps         | 215100        |
| value_loss              | 0.00026164975 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014263506  |
| ent_coef_loss           | -1.940897     |
| entropy                 | 0.45561123    |
| ep_rewmean              | -1.7          |
| episodes                | 2156          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 215401        |
| policy_loss             | 0.61288303    |
| qf1_loss                | 0.00030255888 |
| qf2_loss                | 0.00031042023 |
| time_elapsed            | 1036          |
| total timesteps         | 215500        |
| value_loss              | 0.00024662341 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012898938  |
| ent_coef_loss           | -3.8437223    |
| entropy                 | 1.1433854     |
| ep_rewmean              | -1.7          |
| episodes                | 2160          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 215801        |
| policy_loss             | 0.62545425    |
| qf1_loss                | 0.0013269255  |
| qf2_loss                | 0.0012939398  |
| time_elapsed            | 1038          |
| total timesteps         | 215900        |
| value_loss              | 0.00031001295 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011982222  |
| ent_coef_loss           | -1.9170326    |
| entropy                 | 1.1280007     |
| ep_rewmean              | -1.76         |
| episodes                | 2164          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 216201        |
| policy_loss             | 0.59787595    |
| qf1_loss                | 0.0003287197  |
| qf2_loss                | 0.00028658047 |
| time_elapsed            | 1040          |
| total timesteps         | 216300        |
| value_loss              | 0.00018805379 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011528285  |
| ent_coef_loss           | 3.6306264     |
| entropy                 | 1.3489037     |
| ep_rewmean              | -1.84         |
| episodes                | 2168          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 216601        |
| policy_loss             | 0.64494455    |
| qf1_loss                | 0.0001976536  |
| qf2_loss                | 0.0001729379  |
| time_elapsed            | 1042          |
| total timesteps         | 216700        |
| value_loss              | 0.00017938652 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011227079  |
| ent_coef_loss           | 0.6880344     |
| entropy                 | 0.4554342     |
| ep_rewmean              | -1.85         |
| episodes                | 2172          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 217001        |
| policy_loss             | 0.6073773     |
| qf1_loss                | 0.00016583412 |
| qf2_loss                | 0.00016416993 |
| time_elapsed            | 1044          |
| total timesteps         | 217100        |
| value_loss              | 0.0003523784  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011266464  |
| ent_coef_loss           | 2.1896925     |
| entropy                 | 0.6260371     |
| ep_rewmean              | -1.87         |
| episodes                | 2176          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 217401        |
| policy_loss             | 0.6096875     |
| qf1_loss                | 0.00358766    |
| qf2_loss                | 0.0037040648  |
| time_elapsed            | 1046          |
| total timesteps         | 217500        |
| value_loss              | 0.00023051849 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011091165  |
| ent_coef_loss           | 1.363023      |
| entropy                 | 0.660645      |
| ep_rewmean              | -1.9          |
| episodes                | 2180          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 217801        |
| policy_loss             | 0.6220116     |
| qf1_loss                | 0.00031174516 |
| qf2_loss                | 0.0003866068  |
| time_elapsed            | 1048          |
| total timesteps         | 217900        |
| value_loss              | 0.00021742632 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001090975   |
| ent_coef_loss           | -4.6933107    |
| entropy                 | 0.8524049     |
| ep_rewmean              | -1.98         |
| episodes                | 2184          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 218201        |
| policy_loss             | 0.59392846    |
| qf1_loss                | 0.0021627983  |
| qf2_loss                | 0.002385868   |
| time_elapsed            | 1049          |
| total timesteps         | 218300        |
| value_loss              | 0.00015839012 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001083818   |
| ent_coef_loss           | 1.3277798     |
| entropy                 | 0.8264708     |
| ep_rewmean              | -1.99         |
| episodes                | 2188          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 218601        |
| policy_loss             | 0.61537004    |
| qf1_loss                | 0.003918752   |
| qf2_loss                | 0.0039008863  |
| time_elapsed            | 1051          |
| total timesteps         | 218700        |
| value_loss              | 0.00021516235 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010099896  |
| ent_coef_loss           | 2.8208408     |
| entropy                 | -0.5735602    |
| ep_rewmean              | -2            |
| episodes                | 2192          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 219001        |
| policy_loss             | 0.5873997     |
| qf1_loss                | 0.00023429524 |
| qf2_loss                | 0.00025268205 |
| time_elapsed            | 1053          |
| total timesteps         | 219100        |
| value_loss              | 0.00024353564 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009415409  |
| ent_coef_loss           | -4.8209896    |
| entropy                 | -0.1379456    |
| ep_rewmean              | -2.11         |
| episodes                | 2196          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 219401        |
| policy_loss             | 0.6511271     |
| qf1_loss                | 0.00021080661 |
| qf2_loss                | 0.00016097448 |
| time_elapsed            | 1055          |
| total timesteps         | 219500        |
| value_loss              | 0.00034567242 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008738098  |
| ent_coef_loss           | -1.9638505    |
| entropy                 | -1.2156882    |
| ep_rewmean              | -2.19         |
| episodes                | 2200          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 219801        |
| policy_loss             | 0.6222871     |
| qf1_loss                | 0.0020055955  |
| qf2_loss                | 0.0021346733  |
| time_elapsed            | 1057          |
| total timesteps         | 219900        |
| value_loss              | 0.00021798666 |
-------------------------------------------
Eval num_timesteps=220000, episode_reward=-2.08 +/- 1.35
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008712432  |
| ent_coef_loss           | -1.8942571    |
| entropy                 | -0.5481025    |
| ep_rewmean              | -2.21         |
| episodes                | 2204          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 220201        |
| policy_loss             | 0.60421336    |
| qf1_loss                | 0.004142303   |
| qf2_loss                | 0.0041828398  |
| time_elapsed            | 1059          |
| total timesteps         | 220300        |
| value_loss              | 0.00018390245 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000854997   |
| ent_coef_loss           | -0.5085397    |
| entropy                 | -0.8875104    |
| ep_rewmean              | -2.2          |
| episodes                | 2208          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 220601        |
| policy_loss             | 0.58276343    |
| qf1_loss                | 0.0035807954  |
| qf2_loss                | 0.0037315667  |
| time_elapsed            | 1061          |
| total timesteps         | 220700        |
| value_loss              | 0.00014834518 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008546762  |
| ent_coef_loss           | -3.494568     |
| entropy                 | -0.38535774   |
| ep_rewmean              | -2.23         |
| episodes                | 2212          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 221001        |
| policy_loss             | 0.6380962     |
| qf1_loss                | 0.00018652744 |
| qf2_loss                | 0.00013522088 |
| time_elapsed            | 1063          |
| total timesteps         | 221100        |
| value_loss              | 0.00018001757 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008680588  |
| ent_coef_loss           | -0.5193186    |
| entropy                 | -0.31131595   |
| ep_rewmean              | -2.31         |
| episodes                | 2216          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 221401        |
| policy_loss             | 0.591161      |
| qf1_loss                | 0.00027442782 |
| qf2_loss                | 0.00024626945 |
| time_elapsed            | 1065          |
| total timesteps         | 221500        |
| value_loss              | 0.000257846   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00087329076 |
| ent_coef_loss           | -3.7296338    |
| entropy                 | -0.072009325  |
| ep_rewmean              | -2.28         |
| episodes                | 2220          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 221801        |
| policy_loss             | 0.62788063    |
| qf1_loss                | 0.0051747076  |
| qf2_loss                | 0.0052015204  |
| time_elapsed            | 1067          |
| total timesteps         | 221900        |
| value_loss              | 0.00023246776 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008484562  |
| ent_coef_loss           | 1.4897327     |
| entropy                 | -0.04883571   |
| ep_rewmean              | -2.3          |
| episodes                | 2224          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 222201        |
| policy_loss             | 0.5827968     |
| qf1_loss                | 0.0029394247  |
| qf2_loss                | 0.0029659863  |
| time_elapsed            | 1069          |
| total timesteps         | 222300        |
| value_loss              | 0.00021289714 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00085010444 |
| ent_coef_loss           | -3.6053557    |
| entropy                 | -0.20030873   |
| ep_rewmean              | -2.38         |
| episodes                | 2228          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 222601        |
| policy_loss             | 0.6161313     |
| qf1_loss                | 0.00023057808 |
| qf2_loss                | 0.00020048564 |
| time_elapsed            | 1071          |
| total timesteps         | 222700        |
| value_loss              | 0.00012923818 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00080924906 |
| ent_coef_loss           | -3.8569033    |
| entropy                 | 0.12751687    |
| ep_rewmean              | -2.35         |
| episodes                | 2232          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 223001        |
| policy_loss             | 0.6238161     |
| qf1_loss                | 0.0019299897  |
| qf2_loss                | 0.0019432075  |
| time_elapsed            | 1073          |
| total timesteps         | 223100        |
| value_loss              | 0.00019191018 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000788488   |
| ent_coef_loss           | 7.4131236     |
| entropy                 | 0.22449104    |
| ep_rewmean              | -2.28         |
| episodes                | 2236          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 223401        |
| policy_loss             | 0.61246777    |
| qf1_loss                | 0.0038710223  |
| qf2_loss                | 0.0038242326  |
| time_elapsed            | 1075          |
| total timesteps         | 223500        |
| value_loss              | 0.00022342759 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008269835  |
| ent_coef_loss           | 5.945815      |
| entropy                 | 0.52718496    |
| ep_rewmean              | -2.3          |
| episodes                | 2240          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 223801        |
| policy_loss             | 0.58823633    |
| qf1_loss                | 0.00021302307 |
| qf2_loss                | 0.00017088816 |
| time_elapsed            | 1077          |
| total timesteps         | 223900        |
| value_loss              | 0.00020797586 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00086770294 |
| ent_coef_loss           | -1.2584219    |
| entropy                 | 0.34040385    |
| ep_rewmean              | -2.34         |
| episodes                | 2244          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 224201        |
| policy_loss             | 0.5495268     |
| qf1_loss                | 0.00022629122 |
| qf2_loss                | 0.00018071383 |
| time_elapsed            | 1079          |
| total timesteps         | 224300        |
| value_loss              | 0.0002074524  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009023061  |
| ent_coef_loss           | -1.8327317    |
| entropy                 | 1.0328382     |
| ep_rewmean              | -2.36         |
| episodes                | 2248          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 224601        |
| policy_loss             | 0.6097816     |
| qf1_loss                | 0.0010503554  |
| qf2_loss                | 0.0011411592  |
| time_elapsed            | 1081          |
| total timesteps         | 224700        |
| value_loss              | 0.00015615254 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00093073316 |
| ent_coef_loss           | 8.239646      |
| entropy                 | 1.0154356     |
| ep_rewmean              | -2.34         |
| episodes                | 2252          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 225001        |
| policy_loss             | 0.587585      |
| qf1_loss                | 0.00017082904 |
| qf2_loss                | 0.0002481913  |
| time_elapsed            | 1082          |
| total timesteps         | 225100        |
| value_loss              | 0.00042578042 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00097412686 |
| ent_coef_loss           | 3.3844557     |
| entropy                 | 1.7094219     |
| ep_rewmean              | -2.38         |
| episodes                | 2256          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 225401        |
| policy_loss             | 0.5586612     |
| qf1_loss                | 0.00028524428 |
| qf2_loss                | 0.00022826067 |
| time_elapsed            | 1084          |
| total timesteps         | 225500        |
| value_loss              | 0.0001280237  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009912938  |
| ent_coef_loss           | -0.3888693    |
| entropy                 | 1.4907893     |
| ep_rewmean              | -2.4          |
| episodes                | 2260          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 225801        |
| policy_loss             | 0.55289954    |
| qf1_loss                | 0.0002487534  |
| qf2_loss                | 0.00021469168 |
| time_elapsed            | 1086          |
| total timesteps         | 225900        |
| value_loss              | 0.00025668647 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010036156  |
| ent_coef_loss           | -0.36237204   |
| entropy                 | 1.4168286     |
| ep_rewmean              | -2.36         |
| episodes                | 2264          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 226201        |
| policy_loss             | 0.55633956    |
| qf1_loss                | 0.00022937919 |
| qf2_loss                | 0.00022175425 |
| time_elapsed            | 1088          |
| total timesteps         | 226300        |
| value_loss              | 0.00025037612 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010229886 |
| ent_coef_loss           | 3.1634035    |
| entropy                 | 2.012681     |
| ep_rewmean              | -2.3         |
| episodes                | 2268         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 226601       |
| policy_loss             | 0.5526117    |
| qf1_loss                | 0.0035484675 |
| qf2_loss                | 0.003556198  |
| time_elapsed            | 1090         |
| total timesteps         | 226700       |
| value_loss              | 9.489763e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010237137  |
| ent_coef_loss           | -1.6471007    |
| entropy                 | 1.3277168     |
| ep_rewmean              | -2.33         |
| episodes                | 2272          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 227001        |
| policy_loss             | 0.5550693     |
| qf1_loss                | 0.00030216848 |
| qf2_loss                | 0.0001834318  |
| time_elapsed            | 1092          |
| total timesteps         | 227100        |
| value_loss              | 0.00018036237 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010342282  |
| ent_coef_loss           | -0.64390504   |
| entropy                 | 1.5400336     |
| ep_rewmean              | -2.41         |
| episodes                | 2276          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 227401        |
| policy_loss             | 0.55150646    |
| qf1_loss                | 0.00027379295 |
| qf2_loss                | 0.000371737   |
| time_elapsed            | 1094          |
| total timesteps         | 227500        |
| value_loss              | 0.00026359246 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010767855  |
| ent_coef_loss           | -0.025417864  |
| entropy                 | 1.1879574     |
| ep_rewmean              | -2.48         |
| episodes                | 2280          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 227801        |
| policy_loss             | 0.5225687     |
| qf1_loss                | 0.00015070685 |
| qf2_loss                | 0.00015238064 |
| time_elapsed            | 1096          |
| total timesteps         | 227900        |
| value_loss              | 0.00011141956 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010478275  |
| ent_coef_loss           | 0.41246974    |
| entropy                 | 0.64965725    |
| ep_rewmean              | -2.42         |
| episodes                | 2284          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 228201        |
| policy_loss             | 0.53560483    |
| qf1_loss                | 0.0003281975  |
| qf2_loss                | 0.00031260832 |
| time_elapsed            | 1098          |
| total timesteps         | 228300        |
| value_loss              | 0.00028890415 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010089475  |
| ent_coef_loss           | 12.168063     |
| entropy                 | 0.50155795    |
| ep_rewmean              | -2.45         |
| episodes                | 2288          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 228601        |
| policy_loss             | 0.5395872     |
| qf1_loss                | 0.007251564   |
| qf2_loss                | 0.007289125   |
| time_elapsed            | 1100          |
| total timesteps         | 228700        |
| value_loss              | 0.00028841465 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010981803  |
| ent_coef_loss           | 5.7390356     |
| entropy                 | 0.6303739     |
| ep_rewmean              | -2.53         |
| episodes                | 2292          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 229001        |
| policy_loss             | 0.56055653    |
| qf1_loss                | 0.00029888534 |
| qf2_loss                | 0.0002371461  |
| time_elapsed            | 1102          |
| total timesteps         | 229100        |
| value_loss              | 0.00031866255 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012968628  |
| ent_coef_loss           | 2.521619      |
| entropy                 | 1.6447818     |
| ep_rewmean              | -2.46         |
| episodes                | 2296          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 229401        |
| policy_loss             | 0.58503085    |
| qf1_loss                | 0.00026833828 |
| qf2_loss                | 0.00030814542 |
| time_elapsed            | 1104          |
| total timesteps         | 229500        |
| value_loss              | 0.0004276034  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015127979  |
| ent_coef_loss           | 11.508831     |
| entropy                 | 1.7868419     |
| ep_rewmean              | -2.38         |
| episodes                | 2300          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 229801        |
| policy_loss             | 0.6459975     |
| qf1_loss                | 0.00036193104 |
| qf2_loss                | 0.00032186924 |
| time_elapsed            | 1105          |
| total timesteps         | 229900        |
| value_loss              | 0.0004174682  |
-------------------------------------------
Eval num_timesteps=230000, episode_reward=-1.57 +/- 0.76
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016761282  |
| ent_coef_loss           | 3.213708      |
| entropy                 | 2.3751268     |
| ep_rewmean              | -2.36         |
| episodes                | 2304          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 230201        |
| policy_loss             | 0.6514039     |
| qf1_loss                | 0.0012321002  |
| qf2_loss                | 0.0012215388  |
| time_elapsed            | 1108          |
| total timesteps         | 230300        |
| value_loss              | 0.00047367893 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017145262  |
| ent_coef_loss           | -3.163021     |
| entropy                 | 2.9253504     |
| ep_rewmean              | -2.39         |
| episodes                | 2308          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 230601        |
| policy_loss             | 0.666369      |
| qf1_loss                | 0.00050888525 |
| qf2_loss                | 0.00060207647 |
| time_elapsed            | 1109          |
| total timesteps         | 230700        |
| value_loss              | 0.00032601738 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016787078 |
| ent_coef_loss           | -2.6678596   |
| entropy                 | 2.9477525    |
| ep_rewmean              | -2.41        |
| episodes                | 2312         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.4         |
| n_updates               | 231001       |
| policy_loss             | 0.6722219    |
| qf1_loss                | 0.00211155   |
| qf2_loss                | 0.0027288436 |
| time_elapsed            | 1111         |
| total timesteps         | 231100       |
| value_loss              | 0.0005228917 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016662811  |
| ent_coef_loss           | 5.3604364     |
| entropy                 | 2.1841664     |
| ep_rewmean              | -2.32         |
| episodes                | 2316          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 231401        |
| policy_loss             | 0.71280336    |
| qf1_loss                | 0.015103561   |
| qf2_loss                | 0.01503378    |
| time_elapsed            | 1113          |
| total timesteps         | 231500        |
| value_loss              | 0.00061463227 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0018261414 |
| ent_coef_loss           | 5.3919287    |
| entropy                 | 2.1759672    |
| ep_rewmean              | -2.31        |
| episodes                | 2320         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 231801       |
| policy_loss             | 0.7704356    |
| qf1_loss                | 0.0019116768 |
| qf2_loss                | 0.0019224861 |
| time_elapsed            | 1115         |
| total timesteps         | 231900       |
| value_loss              | 0.0004726877 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019137413  |
| ent_coef_loss           | 8.3677635     |
| entropy                 | 2.0925374     |
| ep_rewmean              | -2.28         |
| episodes                | 2324          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 232201        |
| policy_loss             | 0.8104807     |
| qf1_loss                | 0.00042774604 |
| qf2_loss                | 0.0005325895  |
| time_elapsed            | 1117          |
| total timesteps         | 232300        |
| value_loss              | 0.00041371182 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019797883  |
| ent_coef_loss           | -3.172606     |
| entropy                 | 3.1230202     |
| ep_rewmean              | -2.19         |
| episodes                | 2328          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 232601        |
| policy_loss             | 0.74903214    |
| qf1_loss                | 0.006939346   |
| qf2_loss                | 0.0066819703  |
| time_elapsed            | 1119          |
| total timesteps         | 232700        |
| value_loss              | 0.00044051372 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019125472  |
| ent_coef_loss           | -3.6114938    |
| entropy                 | 2.8362143     |
| ep_rewmean              | -2.26         |
| episodes                | 2332          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 233001        |
| policy_loss             | 0.7465414     |
| qf1_loss                | 0.00332148    |
| qf2_loss                | 0.0032510818  |
| time_elapsed            | 1121          |
| total timesteps         | 233100        |
| value_loss              | 0.00085268635 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019018506  |
| ent_coef_loss           | -9.894903     |
| entropy                 | 3.1811733     |
| ep_rewmean              | -2.32         |
| episodes                | 2336          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 233401        |
| policy_loss             | 0.71050596    |
| qf1_loss                | 0.0073637865  |
| qf2_loss                | 0.0070335176  |
| time_elapsed            | 1123          |
| total timesteps         | 233500        |
| value_loss              | 0.00029241777 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018323194  |
| ent_coef_loss           | 5.1916523     |
| entropy                 | 3.0003552     |
| ep_rewmean              | -2.32         |
| episodes                | 2340          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 233801        |
| policy_loss             | 0.7635675     |
| qf1_loss                | 0.004469852   |
| qf2_loss                | 0.0043545654  |
| time_elapsed            | 1125          |
| total timesteps         | 233900        |
| value_loss              | 0.00026902108 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018205969  |
| ent_coef_loss           | -0.8121712    |
| entropy                 | 2.6547012     |
| ep_rewmean              | -2.33         |
| episodes                | 2344          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 234201        |
| policy_loss             | 0.7385638     |
| qf1_loss                | 0.005777099   |
| qf2_loss                | 0.00568553    |
| time_elapsed            | 1127          |
| total timesteps         | 234300        |
| value_loss              | 0.00034039927 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018505056  |
| ent_coef_loss           | 8.166585      |
| entropy                 | 2.7527442     |
| ep_rewmean              | -2.3          |
| episodes                | 2348          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 234601        |
| policy_loss             | 0.78512394    |
| qf1_loss                | 0.006005304   |
| qf2_loss                | 0.005064576   |
| time_elapsed            | 1129          |
| total timesteps         | 234700        |
| value_loss              | 0.00045391847 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019882424  |
| ent_coef_loss           | 8.959805      |
| entropy                 | 2.7599318     |
| ep_rewmean              | -2.3          |
| episodes                | 2352          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 235001        |
| policy_loss             | 0.8158039     |
| qf1_loss                | 0.004262392   |
| qf2_loss                | 0.004272609   |
| time_elapsed            | 1130          |
| total timesteps         | 235100        |
| value_loss              | 0.00040659777 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021793505  |
| ent_coef_loss           | 2.7095866     |
| entropy                 | 3.756525      |
| ep_rewmean              | -2.24         |
| episodes                | 2356          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 235401        |
| policy_loss             | 0.80774605    |
| qf1_loss                | 0.00026425457 |
| qf2_loss                | 0.0002383822  |
| time_elapsed            | 1132          |
| total timesteps         | 235500        |
| value_loss              | 0.00029181148 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002343874   |
| ent_coef_loss           | 3.3782556     |
| entropy                 | 3.3121464     |
| ep_rewmean              | -2.26         |
| episodes                | 2360          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 235801        |
| policy_loss             | 0.8176328     |
| qf1_loss                | 0.00029230816 |
| qf2_loss                | 0.000337105   |
| time_elapsed            | 1134          |
| total timesteps         | 235900        |
| value_loss              | 0.0003529684  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0023053777 |
| ent_coef_loss           | -3.8693132   |
| entropy                 | 3.5632596    |
| ep_rewmean              | -2.25        |
| episodes                | 2364         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 236201       |
| policy_loss             | 0.87907267   |
| qf1_loss                | 0.0027196717 |
| qf2_loss                | 0.0026096269 |
| time_elapsed            | 1136         |
| total timesteps         | 236300       |
| value_loss              | 0.0003341576 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002327453   |
| ent_coef_loss           | 1.6824424     |
| entropy                 | 3.5076346     |
| ep_rewmean              | -2.23         |
| episodes                | 2368          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 236601        |
| policy_loss             | 0.81046116    |
| qf1_loss                | 0.00050575787 |
| qf2_loss                | 0.0003844411  |
| time_elapsed            | 1138          |
| total timesteps         | 236700        |
| value_loss              | 0.00043258132 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0023195073 |
| ent_coef_loss           | -3.726325    |
| entropy                 | 3.2723765    |
| ep_rewmean              | -2.17        |
| episodes                | 2372         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 237001       |
| policy_loss             | 0.8666184    |
| qf1_loss                | 0.010592168  |
| qf2_loss                | 0.01031777   |
| time_elapsed            | 1140         |
| total timesteps         | 237100       |
| value_loss              | 0.0006832357 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002406261  |
| ent_coef_loss           | -6.8776145   |
| entropy                 | 3.7448492    |
| ep_rewmean              | -2.11        |
| episodes                | 2376         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 237401       |
| policy_loss             | 0.85454136   |
| qf1_loss                | 0.0026364843 |
| qf2_loss                | 0.0023649517 |
| time_elapsed            | 1142         |
| total timesteps         | 237500       |
| value_loss              | 0.0006566798 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0024766552 |
| ent_coef_loss           | -7.7388983   |
| entropy                 | 3.9311385    |
| ep_rewmean              | -2.05        |
| episodes                | 2380         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 237801       |
| policy_loss             | 0.9094065    |
| qf1_loss                | 0.008304581  |
| qf2_loss                | 0.007990369  |
| time_elapsed            | 1144         |
| total timesteps         | 237900       |
| value_loss              | 0.0003498894 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002513484   |
| ent_coef_loss           | 2.5413132     |
| entropy                 | 4.345857      |
| ep_rewmean              | -2.1          |
| episodes                | 2384          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 238201        |
| policy_loss             | 0.9702694     |
| qf1_loss                | 0.0005247962  |
| qf2_loss                | 0.0003383475  |
| time_elapsed            | 1146          |
| total timesteps         | 238300        |
| value_loss              | 0.00043939747 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0024667783  |
| ent_coef_loss           | -2.4570951    |
| entropy                 | 4.286571      |
| ep_rewmean              | -2.04         |
| episodes                | 2388          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 238601        |
| policy_loss             | 1.0194321     |
| qf1_loss                | 0.00062991556 |
| qf2_loss                | 0.0006351375  |
| time_elapsed            | 1148          |
| total timesteps         | 238700        |
| value_loss              | 0.00065497524 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002492136  |
| ent_coef_loss           | 2.3404498    |
| entropy                 | 4.0790377    |
| ep_rewmean              | -2.01        |
| episodes                | 2392         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 239001       |
| policy_loss             | 0.95808387   |
| qf1_loss                | 0.0007378819 |
| qf2_loss                | 0.000678087  |
| time_elapsed            | 1150         |
| total timesteps         | 239100       |
| value_loss              | 0.0003883433 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0025846795 |
| ent_coef_loss           | 11.390432    |
| entropy                 | 3.5370197    |
| ep_rewmean              | -1.97        |
| episodes                | 2396         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 239401       |
| policy_loss             | 0.9950278    |
| qf1_loss                | 0.016625296  |
| qf2_loss                | 0.016645966  |
| time_elapsed            | 1151         |
| total timesteps         | 239500       |
| value_loss              | 0.0005740947 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0028950502  |
| ent_coef_loss           | 1.7469971     |
| entropy                 | 3.2572372     |
| ep_rewmean              | -2.02         |
| episodes                | 2400          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 239801        |
| policy_loss             | 1.0133543     |
| qf1_loss                | 0.008184548   |
| qf2_loss                | 0.008244592   |
| time_elapsed            | 1153          |
| total timesteps         | 239900        |
| value_loss              | 0.00040031184 |
-------------------------------------------
Eval num_timesteps=240000, episode_reward=-1.50 +/- 0.57
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002876508   |
| ent_coef_loss           | -2.0841303    |
| entropy                 | 3.3643699     |
| ep_rewmean              | -2.01         |
| episodes                | 2404          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 240201        |
| policy_loss             | 1.0031886     |
| qf1_loss                | 0.012607732   |
| qf2_loss                | 0.0127045885  |
| time_elapsed            | 1156          |
| total timesteps         | 240300        |
| value_loss              | 0.00040215655 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0026843653  |
| ent_coef_loss           | -0.5144056    |
| entropy                 | 3.9960222     |
| ep_rewmean              | -2.01         |
| episodes                | 2408          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 240601        |
| policy_loss             | 1.0198245     |
| qf1_loss                | 0.011821101   |
| qf2_loss                | 0.011475643   |
| time_elapsed            | 1157          |
| total timesteps         | 240700        |
| value_loss              | 0.00034523726 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0024141127 |
| ent_coef_loss           | -7.5111237   |
| entropy                 | 4.251542     |
| ep_rewmean              | -2           |
| episodes                | 2412         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 241001       |
| policy_loss             | 0.99015594   |
| qf1_loss                | 0.009064138  |
| qf2_loss                | 0.0088913925 |
| time_elapsed            | 1159         |
| total timesteps         | 241100       |
| value_loss              | 0.0008448377 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0023088674  |
| ent_coef_loss           | 3.1308148     |
| entropy                 | 4.0116825     |
| ep_rewmean              | -2.05         |
| episodes                | 2416          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 241401        |
| policy_loss             | 1.0785294     |
| qf1_loss                | 0.0001967211  |
| qf2_loss                | 0.0002004372  |
| time_elapsed            | 1161          |
| total timesteps         | 241500        |
| value_loss              | 0.00041293108 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0023140367  |
| ent_coef_loss           | -1.1313758    |
| entropy                 | 3.7687988     |
| ep_rewmean              | -2.07         |
| episodes                | 2420          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 241801        |
| policy_loss             | 0.9752352     |
| qf1_loss                | 0.0006404923  |
| qf2_loss                | 0.00046099437 |
| time_elapsed            | 1163          |
| total timesteps         | 241900        |
| value_loss              | 0.00040808247 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022811024  |
| ent_coef_loss           | 0.39107686    |
| entropy                 | 3.338718      |
| ep_rewmean              | -2.1          |
| episodes                | 2424          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 242201        |
| policy_loss             | 1.0570161     |
| qf1_loss                | 0.00027354262 |
| qf2_loss                | 0.00029971806 |
| time_elapsed            | 1165          |
| total timesteps         | 242300        |
| value_loss              | 0.00040463815 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021078999  |
| ent_coef_loss           | -2.8888078    |
| entropy                 | 3.2936735     |
| ep_rewmean              | -2.1          |
| episodes                | 2428          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 242601        |
| policy_loss             | 1.0032661     |
| qf1_loss                | 0.00073305424 |
| qf2_loss                | 0.0009314028  |
| time_elapsed            | 1167          |
| total timesteps         | 242700        |
| value_loss              | 0.0010468292  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021236395  |
| ent_coef_loss           | -3.78355      |
| entropy                 | 3.0040815     |
| ep_rewmean              | -2.03         |
| episodes                | 2432          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 243001        |
| policy_loss             | 1.0264982     |
| qf1_loss                | 0.013462051   |
| qf2_loss                | 0.014126008   |
| time_elapsed            | 1169          |
| total timesteps         | 243100        |
| value_loss              | 0.00040116528 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0020418547 |
| ent_coef_loss           | -5.830894    |
| entropy                 | 3.0086033    |
| ep_rewmean              | -1.99        |
| episodes                | 2436         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 243401       |
| policy_loss             | 0.99112916   |
| qf1_loss                | 0.0101138465 |
| qf2_loss                | 0.010188051  |
| time_elapsed            | 1171         |
| total timesteps         | 243500       |
| value_loss              | 0.0004923157 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019788456  |
| ent_coef_loss           | -0.018954396  |
| entropy                 | 3.3174052     |
| ep_rewmean              | -2.01         |
| episodes                | 2440          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 243801        |
| policy_loss             | 0.9831691     |
| qf1_loss                | 0.0027036201  |
| qf2_loss                | 0.0027125305  |
| time_elapsed            | 1173          |
| total timesteps         | 243900        |
| value_loss              | 0.00023699379 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001885274   |
| ent_coef_loss           | -5.4249806    |
| entropy                 | 2.3866503     |
| ep_rewmean              | -2.03         |
| episodes                | 2444          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 244201        |
| policy_loss             | 1.0595616     |
| qf1_loss                | 0.00042413725 |
| qf2_loss                | 0.00045662542 |
| time_elapsed            | 1175          |
| total timesteps         | 244300        |
| value_loss              | 0.0003055055  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0018161315 |
| ent_coef_loss           | -6.085292    |
| entropy                 | 2.6673958    |
| ep_rewmean              | -2.02        |
| episodes                | 2448         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 244601       |
| policy_loss             | 0.9934255    |
| qf1_loss                | 0.020897565  |
| qf2_loss                | 0.02037401   |
| time_elapsed            | 1177         |
| total timesteps         | 244700       |
| value_loss              | 0.0007686358 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017881088 |
| ent_coef_loss           | 3.0893118    |
| entropy                 | 1.9756411    |
| ep_rewmean              | -2           |
| episodes                | 2452         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 245001       |
| policy_loss             | 0.9774082    |
| qf1_loss                | 0.00302631   |
| qf2_loss                | 0.0028898332 |
| time_elapsed            | 1179         |
| total timesteps         | 245100       |
| value_loss              | 0.0009548796 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017640656  |
| ent_coef_loss           | -5.4329267    |
| entropy                 | 2.3640642     |
| ep_rewmean              | -2            |
| episodes                | 2456          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 245401        |
| policy_loss             | 0.90166867    |
| qf1_loss                | 0.01732417    |
| qf2_loss                | 0.01695984    |
| time_elapsed            | 1180          |
| total timesteps         | 245500        |
| value_loss              | 0.00025217352 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016968186  |
| ent_coef_loss           | 2.101691      |
| entropy                 | 3.05968       |
| ep_rewmean              | -1.94         |
| episodes                | 2460          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 245801        |
| policy_loss             | 0.94950545    |
| qf1_loss                | 0.003522311   |
| qf2_loss                | 0.0041076993  |
| time_elapsed            | 1182          |
| total timesteps         | 245900        |
| value_loss              | 0.00042661512 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016466477  |
| ent_coef_loss           | 0.0046135187  |
| entropy                 | 2.476276      |
| ep_rewmean              | -1.95         |
| episodes                | 2464          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 246201        |
| policy_loss             | 0.92605567    |
| qf1_loss                | 0.0002529667  |
| qf2_loss                | 0.00025204523 |
| time_elapsed            | 1184          |
| total timesteps         | 246300        |
| value_loss              | 0.0003230123  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015449959  |
| ent_coef_loss           | -2.6716738    |
| entropy                 | 2.6476588     |
| ep_rewmean              | -1.98         |
| episodes                | 2468          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 246601        |
| policy_loss             | 0.97638434    |
| qf1_loss                | 0.00021326265 |
| qf2_loss                | 0.00023164353 |
| time_elapsed            | 1186          |
| total timesteps         | 246700        |
| value_loss              | 0.00032426557 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015578391  |
| ent_coef_loss           | 1.7172914     |
| entropy                 | 2.5750477     |
| ep_rewmean              | -1.98         |
| episodes                | 2472          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 247001        |
| policy_loss             | 0.85763425    |
| qf1_loss                | 0.00033977383 |
| qf2_loss                | 0.00022390808 |
| time_elapsed            | 1188          |
| total timesteps         | 247100        |
| value_loss              | 0.00028774337 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014956617  |
| ent_coef_loss           | 6.688761      |
| entropy                 | 2.390846      |
| ep_rewmean              | -1.95         |
| episodes                | 2476          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 247401        |
| policy_loss             | 0.95027673    |
| qf1_loss                | 0.00035847613 |
| qf2_loss                | 0.0003641328  |
| time_elapsed            | 1190          |
| total timesteps         | 247500        |
| value_loss              | 0.00031814416 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014526633  |
| ent_coef_loss           | 5.723173      |
| entropy                 | 1.9022195     |
| ep_rewmean              | -1.86         |
| episodes                | 2480          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 247801        |
| policy_loss             | 0.9409109     |
| qf1_loss                | 0.0011621015  |
| qf2_loss                | 0.0012373618  |
| time_elapsed            | 1192          |
| total timesteps         | 247900        |
| value_loss              | 0.00029880487 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014186931  |
| ent_coef_loss           | 2.0530393     |
| entropy                 | 2.0373933     |
| ep_rewmean              | -1.83         |
| episodes                | 2484          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 248201        |
| policy_loss             | 0.9044453     |
| qf1_loss                | 0.00026635214 |
| qf2_loss                | 0.00033024402 |
| time_elapsed            | 1194          |
| total timesteps         | 248300        |
| value_loss              | 0.0005061029  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013715934  |
| ent_coef_loss           | -3.019555     |
| entropy                 | 1.760751      |
| ep_rewmean              | -1.83         |
| episodes                | 2488          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 248601        |
| policy_loss             | 0.9197273     |
| qf1_loss                | 0.00031460344 |
| qf2_loss                | 0.00030738322 |
| time_elapsed            | 1196          |
| total timesteps         | 248700        |
| value_loss              | 0.00032618933 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001262894  |
| ent_coef_loss           | -3.1613219   |
| entropy                 | 1.6990843    |
| ep_rewmean              | -1.78        |
| episodes                | 2492         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 249001       |
| policy_loss             | 0.90621006   |
| qf1_loss                | 0.0076695853 |
| qf2_loss                | 0.007936485  |
| time_elapsed            | 1198         |
| total timesteps         | 249100       |
| value_loss              | 0.0002740162 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001233191   |
| ent_coef_loss           | -5.239052     |
| entropy                 | 1.0930804     |
| ep_rewmean              | -1.79         |
| episodes                | 2496          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 249401        |
| policy_loss             | 0.8561672     |
| qf1_loss                | 0.00027310944 |
| qf2_loss                | 0.00026725465 |
| time_elapsed            | 1199          |
| total timesteps         | 249500        |
| value_loss              | 0.0001817141  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012226821  |
| ent_coef_loss           | 0.03148794    |
| entropy                 | 1.1411164     |
| ep_rewmean              | -1.77         |
| episodes                | 2500          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 249801        |
| policy_loss             | 0.84287655    |
| qf1_loss                | 0.0002905219  |
| qf2_loss                | 0.0003018655  |
| time_elapsed            | 1201          |
| total timesteps         | 249900        |
| value_loss              | 0.00016231733 |
-------------------------------------------
Eval num_timesteps=250000, episode_reward=-2.07 +/- 0.30
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011447896  |
| ent_coef_loss           | -9.194769     |
| entropy                 | 1.3306673     |
| ep_rewmean              | -1.76         |
| episodes                | 2504          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 250201        |
| policy_loss             | 0.8360961     |
| qf1_loss                | 0.00032639643 |
| qf2_loss                | 0.00022311897 |
| time_elapsed            | 1204          |
| total timesteps         | 250300        |
| value_loss              | 0.00015452688 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011002969  |
| ent_coef_loss           | 2.2151318     |
| entropy                 | 1.4768604     |
| ep_rewmean              | -1.78         |
| episodes                | 2508          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 250601        |
| policy_loss             | 0.8994058     |
| qf1_loss                | 0.00819433    |
| qf2_loss                | 0.008029548   |
| time_elapsed            | 1205          |
| total timesteps         | 250700        |
| value_loss              | 0.00019879057 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010421778 |
| ent_coef_loss           | 0.5979672    |
| entropy                 | 0.6675437    |
| ep_rewmean              | -1.73        |
| episodes                | 2512         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 251001       |
| policy_loss             | 0.85060585   |
| qf1_loss                | 0.0069578323 |
| qf2_loss                | 0.007398839  |
| time_elapsed            | 1207         |
| total timesteps         | 251100       |
| value_loss              | 0.0002940202 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009975148  |
| ent_coef_loss           | 2.1555302     |
| entropy                 | 0.42773733    |
| ep_rewmean              | -1.69         |
| episodes                | 2516          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 251401        |
| policy_loss             | 0.84655786    |
| qf1_loss                | 0.00036429672 |
| qf2_loss                | 0.0003369712  |
| time_elapsed            | 1209          |
| total timesteps         | 251500        |
| value_loss              | 0.00017465217 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010506472  |
| ent_coef_loss           | -6.678398     |
| entropy                 | 1.2189839     |
| ep_rewmean              | -1.71         |
| episodes                | 2520          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 251801        |
| policy_loss             | 0.8172446     |
| qf1_loss                | 0.0017631105  |
| qf2_loss                | 0.0021132422  |
| time_elapsed            | 1211          |
| total timesteps         | 251900        |
| value_loss              | 0.00016353079 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010551473  |
| ent_coef_loss           | 6.9471827     |
| entropy                 | 1.3131196     |
| ep_rewmean              | -1.7          |
| episodes                | 2524          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 252201        |
| policy_loss             | 0.7610251     |
| qf1_loss                | 0.0027708686  |
| qf2_loss                | 0.0027292764  |
| time_elapsed            | 1213          |
| total timesteps         | 252300        |
| value_loss              | 0.00038502365 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001068891   |
| ent_coef_loss           | -3.934303     |
| entropy                 | 1.2107432     |
| ep_rewmean              | -1.7          |
| episodes                | 2528          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 252601        |
| policy_loss             | 0.8252137     |
| qf1_loss                | 0.00015039349 |
| qf2_loss                | 0.00020493119 |
| time_elapsed            | 1215          |
| total timesteps         | 252700        |
| value_loss              | 0.0001945446  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010111828  |
| ent_coef_loss           | 4.7131276     |
| entropy                 | 0.78327763    |
| ep_rewmean              | -1.73         |
| episodes                | 2532          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 253001        |
| policy_loss             | 0.7479037     |
| qf1_loss                | 0.00034592283 |
| qf2_loss                | 0.00033200387 |
| time_elapsed            | 1217          |
| total timesteps         | 253100        |
| value_loss              | 0.00023824838 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010050216  |
| ent_coef_loss           | 0.39617455    |
| entropy                 | 0.93860555    |
| ep_rewmean              | -1.78         |
| episodes                | 2536          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 253401        |
| policy_loss             | 0.7754017     |
| qf1_loss                | 0.0010849856  |
| qf2_loss                | 0.00088331895 |
| time_elapsed            | 1219          |
| total timesteps         | 253500        |
| value_loss              | 0.00027554034 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010174345  |
| ent_coef_loss           | -1.4917462    |
| entropy                 | 1.181205      |
| ep_rewmean              | -1.73         |
| episodes                | 2540          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 253801        |
| policy_loss             | 0.8117532     |
| qf1_loss                | 0.0012733294  |
| qf2_loss                | 0.0014142945  |
| time_elapsed            | 1221          |
| total timesteps         | 253900        |
| value_loss              | 0.00041273463 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010750043  |
| ent_coef_loss           | 4.1553574     |
| entropy                 | 1.5994208     |
| ep_rewmean              | -1.7          |
| episodes                | 2544          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 254201        |
| policy_loss             | 0.7901317     |
| qf1_loss                | 0.0004193886  |
| qf2_loss                | 0.00034624906 |
| time_elapsed            | 1223          |
| total timesteps         | 254300        |
| value_loss              | 0.00015364597 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012164062  |
| ent_coef_loss           | 1.5683839     |
| entropy                 | 2.2722013     |
| ep_rewmean              | -1.76         |
| episodes                | 2548          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 254601        |
| policy_loss             | 0.8217976     |
| qf1_loss                | 0.0020065014  |
| qf2_loss                | 0.0020793725  |
| time_elapsed            | 1224          |
| total timesteps         | 254700        |
| value_loss              | 0.00035982474 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013050794  |
| ent_coef_loss           | 15.190647     |
| entropy                 | 2.630258      |
| ep_rewmean              | -1.82         |
| episodes                | 2552          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 255001        |
| policy_loss             | 0.78746474    |
| qf1_loss                | 0.0006723929  |
| qf2_loss                | 0.000675544   |
| time_elapsed            | 1226          |
| total timesteps         | 255100        |
| value_loss              | 0.00047292418 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013694218 |
| ent_coef_loss           | -10.198942   |
| entropy                 | 2.82077      |
| ep_rewmean              | -1.88        |
| episodes                | 2556         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 255401       |
| policy_loss             | 0.7986165    |
| qf1_loss                | 0.003733891  |
| qf2_loss                | 0.00429374   |
| time_elapsed            | 1228         |
| total timesteps         | 255500       |
| value_loss              | 0.0007219522 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013300154  |
| ent_coef_loss           | 1.4135369     |
| entropy                 | 2.2648838     |
| ep_rewmean              | -1.95         |
| episodes                | 2560          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 255801        |
| policy_loss             | 0.8631177     |
| qf1_loss                | 0.00046859714 |
| qf2_loss                | 0.0005432332  |
| time_elapsed            | 1230          |
| total timesteps         | 255900        |
| value_loss              | 0.0012421426  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012977821 |
| ent_coef_loss           | -4.065512    |
| entropy                 | 2.0922236    |
| ep_rewmean              | -1.97        |
| episodes                | 2564         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 256201       |
| policy_loss             | 0.8424207    |
| qf1_loss                | 0.0146424575 |
| qf2_loss                | 0.014214044  |
| time_elapsed            | 1232         |
| total timesteps         | 256300       |
| value_loss              | 0.0005624921 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001245176   |
| ent_coef_loss           | 1.4197772     |
| entropy                 | 1.6347909     |
| ep_rewmean              | -2.02         |
| episodes                | 2568          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 256601        |
| policy_loss             | 0.839604      |
| qf1_loss                | 0.00027384923 |
| qf2_loss                | 0.000404075   |
| time_elapsed            | 1234          |
| total timesteps         | 256700        |
| value_loss              | 0.0003204777  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011502401  |
| ent_coef_loss           | -8.881548     |
| entropy                 | 1.2853003     |
| ep_rewmean              | -2.08         |
| episodes                | 2572          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 257001        |
| policy_loss             | 0.80013573    |
| qf1_loss                | 0.00038709232 |
| qf2_loss                | 0.00033827932 |
| time_elapsed            | 1236          |
| total timesteps         | 257100        |
| value_loss              | 0.00035031588 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010422927  |
| ent_coef_loss           | -10.427338    |
| entropy                 | 1.1797917     |
| ep_rewmean              | -2.13         |
| episodes                | 2576          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 257401        |
| policy_loss             | 0.8102618     |
| qf1_loss                | 0.00037805003 |
| qf2_loss                | 0.00024538164 |
| time_elapsed            | 1238          |
| total timesteps         | 257500        |
| value_loss              | 0.0004468574  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009974473  |
| ent_coef_loss           | -10.202175    |
| entropy                 | 0.6143125     |
| ep_rewmean              | -2.18         |
| episodes                | 2580          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 257801        |
| policy_loss             | 0.76295817    |
| qf1_loss                | 0.00042001042 |
| qf2_loss                | 0.00038079268 |
| time_elapsed            | 1240          |
| total timesteps         | 257900        |
| value_loss              | 0.0003472142  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009817446  |
| ent_coef_loss           | 1.5239213     |
| entropy                 | 1.2492088     |
| ep_rewmean              | -2.16         |
| episodes                | 2584          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 258201        |
| policy_loss             | 0.7375357     |
| qf1_loss                | 0.003614344   |
| qf2_loss                | 0.0041220845  |
| time_elapsed            | 1242          |
| total timesteps         | 258300        |
| value_loss              | 0.00038403092 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009794389  |
| ent_coef_loss           | 2.6963983     |
| entropy                 | 0.7667035     |
| ep_rewmean              | -2.22         |
| episodes                | 2588          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 258601        |
| policy_loss             | 0.7491343     |
| qf1_loss                | 0.00036128372 |
| qf2_loss                | 0.0003198582  |
| time_elapsed            | 1243          |
| total timesteps         | 258700        |
| value_loss              | 0.000315694   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009999517  |
| ent_coef_loss           | 1.4901314     |
| entropy                 | 1.2851207     |
| ep_rewmean              | -2.26         |
| episodes                | 2592          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 259001        |
| policy_loss             | 0.66548747    |
| qf1_loss                | 0.0028960062  |
| qf2_loss                | 0.0031372253  |
| time_elapsed            | 1245          |
| total timesteps         | 259100        |
| value_loss              | 0.00019590964 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010147789 |
| ent_coef_loss           | 4.781544     |
| entropy                 | 1.1567864    |
| ep_rewmean              | -2.27        |
| episodes                | 2596         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 259401       |
| policy_loss             | 0.7283515    |
| qf1_loss                | 0.004297398  |
| qf2_loss                | 0.0042235367 |
| time_elapsed            | 1247         |
| total timesteps         | 259500       |
| value_loss              | 0.0002637737 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010603372  |
| ent_coef_loss           | 6.904749      |
| entropy                 | 1.469153      |
| ep_rewmean              | -2.28         |
| episodes                | 2600          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 259801        |
| policy_loss             | 0.739524      |
| qf1_loss                | 0.0019080377  |
| qf2_loss                | 0.0017309602  |
| time_elapsed            | 1249          |
| total timesteps         | 259900        |
| value_loss              | 0.00028779177 |
-------------------------------------------
Eval num_timesteps=260000, episode_reward=-3.00 +/- 1.37
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010942041 |
| ent_coef_loss           | 1.173318     |
| entropy                 | 1.9350412    |
| ep_rewmean              | -2.29        |
| episodes                | 2604         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 260201       |
| policy_loss             | 0.7207539    |
| qf1_loss                | 0.0002610372 |
| qf2_loss                | 0.0003626729 |
| time_elapsed            | 1251         |
| total timesteps         | 260300       |
| value_loss              | 0.0001992851 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010698374  |
| ent_coef_loss           | -6.3463964    |
| entropy                 | 1.0685226     |
| ep_rewmean              | -2.26         |
| episodes                | 2608          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 260601        |
| policy_loss             | 0.7060776     |
| qf1_loss                | 0.00025611106 |
| qf2_loss                | 0.0002631013  |
| time_elapsed            | 1253          |
| total timesteps         | 260700        |
| value_loss              | 0.000294999   |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010635522 |
| ent_coef_loss           | -2.4754593   |
| entropy                 | 1.774833     |
| ep_rewmean              | -2.35        |
| episodes                | 2612         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 261001       |
| policy_loss             | 0.674132     |
| qf1_loss                | 0.0055175107 |
| qf2_loss                | 0.0057518384 |
| time_elapsed            | 1255         |
| total timesteps         | 261100       |
| value_loss              | 0.0005138881 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010304542  |
| ent_coef_loss           | 2.8439069     |
| entropy                 | 1.3824822     |
| ep_rewmean              | -2.38         |
| episodes                | 2616          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 261401        |
| policy_loss             | 0.69170463    |
| qf1_loss                | 0.016748138   |
| qf2_loss                | 0.016813511   |
| time_elapsed            | 1257          |
| total timesteps         | 261500        |
| value_loss              | 0.00033417737 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010179154  |
| ent_coef_loss           | -2.0042703    |
| entropy                 | 1.7642506     |
| ep_rewmean              | -2.38         |
| episodes                | 2620          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 261801        |
| policy_loss             | 0.69643974    |
| qf1_loss                | 0.0036718585  |
| qf2_loss                | 0.0035399592  |
| time_elapsed            | 1259          |
| total timesteps         | 261900        |
| value_loss              | 0.00033596542 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010012939  |
| ent_coef_loss           | -1.4624307    |
| entropy                 | 1.4544481     |
| ep_rewmean              | -2.38         |
| episodes                | 2624          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 262201        |
| policy_loss             | 0.67640173    |
| qf1_loss                | 0.00022014239 |
| qf2_loss                | 0.00024207236 |
| time_elapsed            | 1261          |
| total timesteps         | 262300        |
| value_loss              | 0.0002668542  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00094357645 |
| ent_coef_loss           | -3.9212437    |
| entropy                 | 0.8775823     |
| ep_rewmean              | -2.41         |
| episodes                | 2628          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 262601        |
| policy_loss             | 0.74971426    |
| qf1_loss                | 0.00033903608 |
| qf2_loss                | 0.00051585416 |
| time_elapsed            | 1263          |
| total timesteps         | 262700        |
| value_loss              | 0.0002549843  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008973846  |
| ent_coef_loss           | -0.1028254    |
| entropy                 | 1.2265289     |
| ep_rewmean              | -2.41         |
| episodes                | 2632          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 263001        |
| policy_loss             | 0.6810587     |
| qf1_loss                | 0.0044443035  |
| qf2_loss                | 0.004404572   |
| time_elapsed            | 1265          |
| total timesteps         | 263100        |
| value_loss              | 0.00032187442 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008942804  |
| ent_coef_loss           | -6.5090084    |
| entropy                 | 1.290948      |
| ep_rewmean              | -2.43         |
| episodes                | 2636          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 263401        |
| policy_loss             | 0.71515155    |
| qf1_loss                | 0.0005929222  |
| qf2_loss                | 0.00049643574 |
| time_elapsed            | 1267          |
| total timesteps         | 263500        |
| value_loss              | 0.00031775667 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00088145427 |
| ent_coef_loss           | 0.65801936    |
| entropy                 | 1.2966632     |
| ep_rewmean              | -2.46         |
| episodes                | 2640          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 263801        |
| policy_loss             | 0.6755439     |
| qf1_loss                | 0.017743837   |
| qf2_loss                | 0.017801333   |
| time_elapsed            | 1269          |
| total timesteps         | 263900        |
| value_loss              | 0.00046805356 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00088705454 |
| ent_coef_loss           | -2.107821     |
| entropy                 | 1.6196522     |
| ep_rewmean              | -2.42         |
| episodes                | 2644          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 264201        |
| policy_loss             | 0.6659715     |
| qf1_loss                | 0.00065548136 |
| qf2_loss                | 0.00053440256 |
| time_elapsed            | 1271          |
| total timesteps         | 264300        |
| value_loss              | 0.00026108793 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0008715195 |
| ent_coef_loss           | 3.9105623    |
| entropy                 | 0.304103     |
| ep_rewmean              | -2.35        |
| episodes                | 2648         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 264601       |
| policy_loss             | 0.7291274    |
| qf1_loss                | 0.005732693  |
| qf2_loss                | 0.0054759365 |
| time_elapsed            | 1272         |
| total timesteps         | 264700       |
| value_loss              | 0.0003537512 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008870397  |
| ent_coef_loss           | -5.041105     |
| entropy                 | 1.041306      |
| ep_rewmean              | -2.3          |
| episodes                | 2652          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 265001        |
| policy_loss             | 0.7391656     |
| qf1_loss                | 0.00038903367 |
| qf2_loss                | 0.00037161162 |
| time_elapsed            | 1274          |
| total timesteps         | 265100        |
| value_loss              | 0.00022504633 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00090293796 |
| ent_coef_loss           | -3.9425175    |
| entropy                 | 0.5974752     |
| ep_rewmean              | -2.23         |
| episodes                | 2656          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 265401        |
| policy_loss             | 0.7271992     |
| qf1_loss                | 0.0032675355  |
| qf2_loss                | 0.003112108   |
| time_elapsed            | 1276          |
| total timesteps         | 265500        |
| value_loss              | 0.00030789757 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00095625676 |
| ent_coef_loss           | -0.22795606   |
| entropy                 | 1.2419846     |
| ep_rewmean              | -2.17         |
| episodes                | 2660          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 265801        |
| policy_loss             | 0.6832652     |
| qf1_loss                | 0.00048023838 |
| qf2_loss                | 0.00044689677 |
| time_elapsed            | 1278          |
| total timesteps         | 265900        |
| value_loss              | 0.00022425075 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010201229  |
| ent_coef_loss           | 2.427367      |
| entropy                 | 1.353188      |
| ep_rewmean              | -2.15         |
| episodes                | 2664          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 266201        |
| policy_loss             | 0.72283673    |
| qf1_loss                | 0.009795789   |
| qf2_loss                | 0.009879066   |
| time_elapsed            | 1280          |
| total timesteps         | 266300        |
| value_loss              | 0.00019802146 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010651418  |
| ent_coef_loss           | 4.4061546     |
| entropy                 | 1.8629699     |
| ep_rewmean              | -2.08         |
| episodes                | 2668          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 266601        |
| policy_loss             | 0.6756173     |
| qf1_loss                | 0.00043050863 |
| qf2_loss                | 0.00039242822 |
| time_elapsed            | 1282          |
| total timesteps         | 266700        |
| value_loss              | 0.00022722557 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010722843  |
| ent_coef_loss           | 3.5975368     |
| entropy                 | 1.7319846     |
| ep_rewmean              | -2.03         |
| episodes                | 2672          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 267001        |
| policy_loss             | 0.7646464     |
| qf1_loss                | 0.009522825   |
| qf2_loss                | 0.010711113   |
| time_elapsed            | 1284          |
| total timesteps         | 267100        |
| value_loss              | 0.00037827372 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010801353  |
| ent_coef_loss           | -1.42694      |
| entropy                 | 1.4476452     |
| ep_rewmean              | -1.96         |
| episodes                | 2676          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 267401        |
| policy_loss             | 0.7904946     |
| qf1_loss                | 0.00037670325 |
| qf2_loss                | 0.00030453491 |
| time_elapsed            | 1286          |
| total timesteps         | 267500        |
| value_loss              | 0.0004114735  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010829181 |
| ent_coef_loss           | 3.8847284    |
| entropy                 | 1.1857414    |
| ep_rewmean              | -1.95        |
| episodes                | 2680         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 267801       |
| policy_loss             | 0.8052419    |
| qf1_loss                | 0.008349911  |
| qf2_loss                | 0.007629176  |
| time_elapsed            | 1288         |
| total timesteps         | 267900       |
| value_loss              | 0.0003662412 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011209443  |
| ent_coef_loss           | 5.6955757     |
| entropy                 | 1.2903917     |
| ep_rewmean              | -1.98         |
| episodes                | 2684          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 268201        |
| policy_loss             | 0.8044863     |
| qf1_loss                | 0.020238433   |
| qf2_loss                | 0.020146105   |
| time_elapsed            | 1290          |
| total timesteps         | 268300        |
| value_loss              | 0.00042363693 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001120677   |
| ent_coef_loss           | 0.80460167    |
| entropy                 | 1.3101072     |
| ep_rewmean              | -1.92         |
| episodes                | 2688          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 268601        |
| policy_loss             | 0.86319876    |
| qf1_loss                | 0.00057572726 |
| qf2_loss                | 0.00036113994 |
| time_elapsed            | 1292          |
| total timesteps         | 268700        |
| value_loss              | 0.0003995118  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011260079  |
| ent_coef_loss           | -2.0813875    |
| entropy                 | 1.4196097     |
| ep_rewmean              | -1.89         |
| episodes                | 2692          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 269001        |
| policy_loss             | 0.82107127    |
| qf1_loss                | 0.000519285   |
| qf2_loss                | 0.00047561715 |
| time_elapsed            | 1294          |
| total timesteps         | 269100        |
| value_loss              | 0.00032335753 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011470988  |
| ent_coef_loss           | -5.994796     |
| entropy                 | 1.4605247     |
| ep_rewmean              | -1.88         |
| episodes                | 2696          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 269401        |
| policy_loss             | 0.8373095     |
| qf1_loss                | 0.00082938257 |
| qf2_loss                | 0.0007842011  |
| time_elapsed            | 1295          |
| total timesteps         | 269500        |
| value_loss              | 0.000322307   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011528076  |
| ent_coef_loss           | 6.5036373     |
| entropy                 | 1.8103842     |
| ep_rewmean              | -1.87         |
| episodes                | 2700          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 269801        |
| policy_loss             | 0.7658978     |
| qf1_loss                | 0.0003293958  |
| qf2_loss                | 0.00030662402 |
| time_elapsed            | 1297          |
| total timesteps         | 269900        |
| value_loss              | 0.00034194702 |
-------------------------------------------
Eval num_timesteps=270000, episode_reward=-1.24 +/- 0.75
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011464301  |
| ent_coef_loss           | -2.0168245    |
| entropy                 | 1.8365324     |
| ep_rewmean              | -1.88         |
| episodes                | 2704          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 270201        |
| policy_loss             | 0.7828919     |
| qf1_loss                | 0.00040102773 |
| qf2_loss                | 0.0004576749  |
| time_elapsed            | 1300          |
| total timesteps         | 270300        |
| value_loss              | 0.00034796484 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011344048 |
| ent_coef_loss           | -6.1612444   |
| entropy                 | 2.0876522    |
| ep_rewmean              | -1.86        |
| episodes                | 2708         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 270601       |
| policy_loss             | 0.786703     |
| qf1_loss                | 0.00792758   |
| qf2_loss                | 0.0082229795 |
| time_elapsed            | 1301         |
| total timesteps         | 270700       |
| value_loss              | 0.0002472179 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011501441  |
| ent_coef_loss           | 1.2716119     |
| entropy                 | 2.3173132     |
| ep_rewmean              | -1.81         |
| episodes                | 2712          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 271001        |
| policy_loss             | 0.8252485     |
| qf1_loss                | 0.00023099536 |
| qf2_loss                | 0.00024327882 |
| time_elapsed            | 1303          |
| total timesteps         | 271100        |
| value_loss              | 0.0002692149  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00116178    |
| ent_coef_loss           | -7.7337427    |
| entropy                 | 2.483625      |
| ep_rewmean              | -1.79         |
| episodes                | 2716          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 271401        |
| policy_loss             | 0.82842374    |
| qf1_loss                | 0.00031771365 |
| qf2_loss                | 0.0002455461  |
| time_elapsed            | 1305          |
| total timesteps         | 271500        |
| value_loss              | 0.00050506345 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011614161  |
| ent_coef_loss           | -0.37275124   |
| entropy                 | 1.5059264     |
| ep_rewmean              | -1.78         |
| episodes                | 2720          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 271801        |
| policy_loss             | 0.75542474    |
| qf1_loss                | 0.0024220299  |
| qf2_loss                | 0.0024268227  |
| time_elapsed            | 1307          |
| total timesteps         | 271900        |
| value_loss              | 0.00032605065 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001201869   |
| ent_coef_loss           | 4.868226      |
| entropy                 | 2.352313      |
| ep_rewmean              | -1.8          |
| episodes                | 2724          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 272201        |
| policy_loss             | 0.8753072     |
| qf1_loss                | 0.00022444295 |
| qf2_loss                | 0.00024597647 |
| time_elapsed            | 1309          |
| total timesteps         | 272300        |
| value_loss              | 0.00020984694 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012188193  |
| ent_coef_loss           | -2.1583285    |
| entropy                 | 1.9301943     |
| ep_rewmean              | -1.79         |
| episodes                | 2728          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 272601        |
| policy_loss             | 0.802184      |
| qf1_loss                | 0.00034141343 |
| qf2_loss                | 0.00030296948 |
| time_elapsed            | 1311          |
| total timesteps         | 272700        |
| value_loss              | 0.0003105391  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001224868   |
| ent_coef_loss           | -6.9963794    |
| entropy                 | 1.860048      |
| ep_rewmean              | -1.78         |
| episodes                | 2732          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 273001        |
| policy_loss             | 0.8950547     |
| qf1_loss                | 0.00038133806 |
| qf2_loss                | 0.0002976596  |
| time_elapsed            | 1313          |
| total timesteps         | 273100        |
| value_loss              | 0.00054951594 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001227052   |
| ent_coef_loss           | -9.498962     |
| entropy                 | 2.0837965     |
| ep_rewmean              | -1.76         |
| episodes                | 2736          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 273401        |
| policy_loss             | 0.7450136     |
| qf1_loss                | 0.00029035492 |
| qf2_loss                | 0.0002685251  |
| time_elapsed            | 1315          |
| total timesteps         | 273500        |
| value_loss              | 0.0004351394  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012558417 |
| ent_coef_loss           | 1.3155603    |
| entropy                 | 1.7635028    |
| ep_rewmean              | -1.75        |
| episodes                | 2740         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 273801       |
| policy_loss             | 0.89597267   |
| qf1_loss                | 0.0019405098 |
| qf2_loss                | 0.0021152874 |
| time_elapsed            | 1317         |
| total timesteps         | 273900       |
| value_loss              | 0.00027143   |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012593456  |
| ent_coef_loss           | 3.7960858     |
| entropy                 | 1.8310351     |
| ep_rewmean              | -1.76         |
| episodes                | 2744          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 274201        |
| policy_loss             | 0.8429226     |
| qf1_loss                | 0.00043233446 |
| qf2_loss                | 0.00037291236 |
| time_elapsed            | 1319          |
| total timesteps         | 274300        |
| value_loss              | 0.0002661225  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012686024  |
| ent_coef_loss           | 9.572523      |
| entropy                 | 2.2187998     |
| ep_rewmean              | -1.78         |
| episodes                | 2748          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 274601        |
| policy_loss             | 0.90203565    |
| qf1_loss                | 0.002538022   |
| qf2_loss                | 0.0025813296  |
| time_elapsed            | 1321          |
| total timesteps         | 274700        |
| value_loss              | 0.00032044286 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013745961  |
| ent_coef_loss           | -1.7678013    |
| entropy                 | 2.2827606     |
| ep_rewmean              | -1.83         |
| episodes                | 2752          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 275001        |
| policy_loss             | 0.8609233     |
| qf1_loss                | 0.00032175056 |
| qf2_loss                | 0.0005930162  |
| time_elapsed            | 1323          |
| total timesteps         | 275100        |
| value_loss              | 0.00031960398 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014300273  |
| ent_coef_loss           | 0.078538895   |
| entropy                 | 2.441959      |
| ep_rewmean              | -1.85         |
| episodes                | 2756          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 275401        |
| policy_loss             | 0.8591167     |
| qf1_loss                | 0.0004381844  |
| qf2_loss                | 0.0005201092  |
| time_elapsed            | 1324          |
| total timesteps         | 275500        |
| value_loss              | 0.00036491614 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015164784  |
| ent_coef_loss           | 5.905543      |
| entropy                 | 3.1876383     |
| ep_rewmean              | -1.86         |
| episodes                | 2760          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 275801        |
| policy_loss             | 0.8708736     |
| qf1_loss                | 0.00026683125 |
| qf2_loss                | 0.00028433726 |
| time_elapsed            | 1326          |
| total timesteps         | 275900        |
| value_loss              | 0.0003267454  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016139896  |
| ent_coef_loss           | -1.7286887    |
| entropy                 | 2.8496013     |
| ep_rewmean              | -1.85         |
| episodes                | 2764          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 276201        |
| policy_loss             | 0.8415209     |
| qf1_loss                | 0.006752779   |
| qf2_loss                | 0.0068109934  |
| time_elapsed            | 1328          |
| total timesteps         | 276300        |
| value_loss              | 0.00024687022 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016195094  |
| ent_coef_loss           | -4.3034573    |
| entropy                 | 2.861941      |
| ep_rewmean              | -1.85         |
| episodes                | 2768          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 276601        |
| policy_loss             | 0.7828659     |
| qf1_loss                | 0.0050158077  |
| qf2_loss                | 0.0048645157  |
| time_elapsed            | 1330          |
| total timesteps         | 276700        |
| value_loss              | 0.00035725947 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016099964  |
| ent_coef_loss           | 5.7402415     |
| entropy                 | 2.574623      |
| ep_rewmean              | -1.88         |
| episodes                | 2772          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 277001        |
| policy_loss             | 0.7663449     |
| qf1_loss                | 0.009340476   |
| qf2_loss                | 0.008944929   |
| time_elapsed            | 1332          |
| total timesteps         | 277100        |
| value_loss              | 0.00036872015 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015826281  |
| ent_coef_loss           | -2.2886837    |
| entropy                 | 2.6088853     |
| ep_rewmean              | -1.9          |
| episodes                | 2776          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 277401        |
| policy_loss             | 0.83256245    |
| qf1_loss                | 0.008750864   |
| qf2_loss                | 0.00855425    |
| time_elapsed            | 1334          |
| total timesteps         | 277500        |
| value_loss              | 0.00025332006 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015461936  |
| ent_coef_loss           | -2.505354     |
| entropy                 | 2.5739968     |
| ep_rewmean              | -1.88         |
| episodes                | 2780          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 277801        |
| policy_loss             | 0.7886748     |
| qf1_loss                | 0.004852366   |
| qf2_loss                | 0.0047664135  |
| time_elapsed            | 1336          |
| total timesteps         | 277900        |
| value_loss              | 0.00032073044 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014967768  |
| ent_coef_loss           | 2.3254023     |
| entropy                 | 2.1321366     |
| ep_rewmean              | -1.84         |
| episodes                | 2784          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 278201        |
| policy_loss             | 0.77975523    |
| qf1_loss                | 0.00039518587 |
| qf2_loss                | 0.00035108853 |
| time_elapsed            | 1338          |
| total timesteps         | 278300        |
| value_loss              | 0.00041000103 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014287719  |
| ent_coef_loss           | -6.6472893    |
| entropy                 | 2.791552      |
| ep_rewmean              | -1.83         |
| episodes                | 2788          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 278601        |
| policy_loss             | 0.8403841     |
| qf1_loss                | 0.00036394718 |
| qf2_loss                | 0.00033352524 |
| time_elapsed            | 1340          |
| total timesteps         | 278700        |
| value_loss              | 0.00035671314 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001365044   |
| ent_coef_loss           | -1.8810918    |
| entropy                 | 2.0778012     |
| ep_rewmean              | -1.85         |
| episodes                | 2792          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 279001        |
| policy_loss             | 0.86167246    |
| qf1_loss                | 0.00036087786 |
| qf2_loss                | 0.0002836507  |
| time_elapsed            | 1342          |
| total timesteps         | 279100        |
| value_loss              | 0.0002048919  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013330904  |
| ent_coef_loss           | -0.66061497   |
| entropy                 | 2.258707      |
| ep_rewmean              | -1.85         |
| episodes                | 2796          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 279401        |
| policy_loss             | 0.8520001     |
| qf1_loss                | 0.0025274483  |
| qf2_loss                | 0.0025089504  |
| time_elapsed            | 1344          |
| total timesteps         | 279500        |
| value_loss              | 0.00019562001 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012956143  |
| ent_coef_loss           | -6.422655     |
| entropy                 | 1.7239428     |
| ep_rewmean              | -1.82         |
| episodes                | 2800          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 279801        |
| policy_loss             | 0.81537664    |
| qf1_loss                | 0.008287094   |
| qf2_loss                | 0.008391      |
| time_elapsed            | 1346          |
| total timesteps         | 279900        |
| value_loss              | 0.00039816176 |
-------------------------------------------
Eval num_timesteps=280000, episode_reward=-1.52 +/- 0.98
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012830693  |
| ent_coef_loss           | 1.6642911     |
| entropy                 | 2.4511976     |
| ep_rewmean              | -1.81         |
| episodes                | 2804          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 280201        |
| policy_loss             | 0.82639194    |
| qf1_loss                | 0.00056031335 |
| qf2_loss                | 0.00045950402 |
| time_elapsed            | 1348          |
| total timesteps         | 280300        |
| value_loss              | 0.00030040118 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012270713  |
| ent_coef_loss           | -2.4058352    |
| entropy                 | 1.959604      |
| ep_rewmean              | -1.9          |
| episodes                | 2808          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 280601        |
| policy_loss             | 0.84817404    |
| qf1_loss                | 0.00029877602 |
| qf2_loss                | 0.00023024472 |
| time_elapsed            | 1350          |
| total timesteps         | 280700        |
| value_loss              | 0.0003268205  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001180315   |
| ent_coef_loss           | -5.454409     |
| entropy                 | 2.121934      |
| ep_rewmean              | -1.93         |
| episodes                | 2812          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 281001        |
| policy_loss             | 0.87183607    |
| qf1_loss                | 0.027541116   |
| qf2_loss                | 0.027010802   |
| time_elapsed            | 1352          |
| total timesteps         | 281100        |
| value_loss              | 0.00015792761 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001137572   |
| ent_coef_loss           | 4.536549      |
| entropy                 | 1.6777068     |
| ep_rewmean              | -1.95         |
| episodes                | 2816          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 281401        |
| policy_loss             | 0.84612423    |
| qf1_loss                | 0.00050447835 |
| qf2_loss                | 0.0005916011  |
| time_elapsed            | 1354          |
| total timesteps         | 281500        |
| value_loss              | 0.0002807923  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010927754  |
| ent_coef_loss           | 3.621274      |
| entropy                 | 1.5558709     |
| ep_rewmean              | -1.91         |
| episodes                | 2820          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 281801        |
| policy_loss             | 0.84900224    |
| qf1_loss                | 0.0057884036  |
| qf2_loss                | 0.0059332014  |
| time_elapsed            | 1355          |
| total timesteps         | 281900        |
| value_loss              | 0.00033277372 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001069612   |
| ent_coef_loss           | 1.4835689     |
| entropy                 | 1.6299499     |
| ep_rewmean              | -1.93         |
| episodes                | 2824          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 282201        |
| policy_loss             | 0.83842945    |
| qf1_loss                | 0.0004270924  |
| qf2_loss                | 0.0005494761  |
| time_elapsed            | 1357          |
| total timesteps         | 282300        |
| value_loss              | 0.00029916712 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010365023  |
| ent_coef_loss           | -2.5739665    |
| entropy                 | 1.5586653     |
| ep_rewmean              | -1.93         |
| episodes                | 2828          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 282601        |
| policy_loss             | 0.87515885    |
| qf1_loss                | 0.00017711593 |
| qf2_loss                | 0.00014270353 |
| time_elapsed            | 1359          |
| total timesteps         | 282700        |
| value_loss              | 0.0001537863  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010082592  |
| ent_coef_loss           | -0.1865598    |
| entropy                 | 1.6079124     |
| ep_rewmean              | -1.94         |
| episodes                | 2832          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 283001        |
| policy_loss             | 0.90949655    |
| qf1_loss                | 0.00026494183 |
| qf2_loss                | 0.0003423233  |
| time_elapsed            | 1361          |
| total timesteps         | 283100        |
| value_loss              | 0.0001586103  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009782912  |
| ent_coef_loss           | -5.3794503    |
| entropy                 | 1.3877121     |
| ep_rewmean              | -1.88         |
| episodes                | 2836          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 283401        |
| policy_loss             | 0.8390659     |
| qf1_loss                | 0.01592946    |
| qf2_loss                | 0.015324635   |
| time_elapsed            | 1363          |
| total timesteps         | 283500        |
| value_loss              | 0.00015928151 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001009629   |
| ent_coef_loss           | 5.683898      |
| entropy                 | 1.911953      |
| ep_rewmean              | -1.91         |
| episodes                | 2840          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 283801        |
| policy_loss             | 0.8454326     |
| qf1_loss                | 0.008975866   |
| qf2_loss                | 0.009816416   |
| time_elapsed            | 1365          |
| total timesteps         | 283900        |
| value_loss              | 0.00015695572 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010213153 |
| ent_coef_loss           | 7.0460167    |
| entropy                 | 1.1683334    |
| ep_rewmean              | -1.94        |
| episodes                | 2844         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 284201       |
| policy_loss             | 0.7989031    |
| qf1_loss                | 0.005595109  |
| qf2_loss                | 0.005307921  |
| time_elapsed            | 1367         |
| total timesteps         | 284300       |
| value_loss              | 0.000541514  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010718441  |
| ent_coef_loss           | -0.2292614    |
| entropy                 | 1.7750113     |
| ep_rewmean              | -2.05         |
| episodes                | 2848          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 284601        |
| policy_loss             | 0.8192123     |
| qf1_loss                | 0.013197913   |
| qf2_loss                | 0.012945216   |
| time_elapsed            | 1369          |
| total timesteps         | 284700        |
| value_loss              | 0.00019934512 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010654242 |
| ent_coef_loss           | -1.4947519   |
| entropy                 | 2.2586105    |
| ep_rewmean              | -2.08        |
| episodes                | 2852         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 285001       |
| policy_loss             | 0.86017776   |
| qf1_loss                | 0.0071313125 |
| qf2_loss                | 0.007454596  |
| time_elapsed            | 1371         |
| total timesteps         | 285100       |
| value_loss              | 0.0001537014 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001039936   |
| ent_coef_loss           | 2.289172      |
| entropy                 | 1.3594484     |
| ep_rewmean              | -2.09         |
| episodes                | 2856          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 285401        |
| policy_loss             | 0.83497226    |
| qf1_loss                | 0.0030433396  |
| qf2_loss                | 0.0027466977  |
| time_elapsed            | 1373          |
| total timesteps         | 285500        |
| value_loss              | 0.00022994791 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010632556  |
| ent_coef_loss           | 4.1937876     |
| entropy                 | 2.0300052     |
| ep_rewmean              | -2.07         |
| episodes                | 2860          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 285801        |
| policy_loss             | 0.77824235    |
| qf1_loss                | 0.0007705453  |
| qf2_loss                | 0.0006997089  |
| time_elapsed            | 1375          |
| total timesteps         | 285900        |
| value_loss              | 0.00027977183 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010618618  |
| ent_coef_loss           | 3.4110553     |
| entropy                 | 1.9717686     |
| ep_rewmean              | -2.04         |
| episodes                | 2864          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 286201        |
| policy_loss             | 0.8349583     |
| qf1_loss                | 0.003119287   |
| qf2_loss                | 0.0031725313  |
| time_elapsed            | 1376          |
| total timesteps         | 286300        |
| value_loss              | 0.00022855258 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010163358  |
| ent_coef_loss           | -5.3701015    |
| entropy                 | 1.4755647     |
| ep_rewmean              | -2.07         |
| episodes                | 2868          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 286601        |
| policy_loss             | 0.81682026    |
| qf1_loss                | 0.00027028777 |
| qf2_loss                | 0.0002484718  |
| time_elapsed            | 1378          |
| total timesteps         | 286700        |
| value_loss              | 0.00021145628 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009933275  |
| ent_coef_loss           | 3.5379505     |
| entropy                 | 1.280575      |
| ep_rewmean              | -2.03         |
| episodes                | 2872          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 287001        |
| policy_loss             | 0.8781271     |
| qf1_loss                | 0.00041770266 |
| qf2_loss                | 0.00032562952 |
| time_elapsed            | 1380          |
| total timesteps         | 287100        |
| value_loss              | 0.00021764621 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010138169  |
| ent_coef_loss           | 3.1064456     |
| entropy                 | 2.618645      |
| ep_rewmean              | -2.04         |
| episodes                | 2876          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 287401        |
| policy_loss             | 0.76254326    |
| qf1_loss                | 0.00016923496 |
| qf2_loss                | 0.0001893104  |
| time_elapsed            | 1382          |
| total timesteps         | 287500        |
| value_loss              | 0.00015371408 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010373552  |
| ent_coef_loss           | 0.060853362   |
| entropy                 | 2.3258092     |
| ep_rewmean              | -2.03         |
| episodes                | 2880          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 287801        |
| policy_loss             | 0.8992645     |
| qf1_loss                | 0.0002423182  |
| qf2_loss                | 0.00024565292 |
| time_elapsed            | 1384          |
| total timesteps         | 287900        |
| value_loss              | 0.00027040916 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001073289   |
| ent_coef_loss           | 4.861454      |
| entropy                 | 2.4387364     |
| ep_rewmean              | -2.07         |
| episodes                | 2884          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 288201        |
| policy_loss             | 0.852407      |
| qf1_loss                | 0.0018862792  |
| qf2_loss                | 0.0018086842  |
| time_elapsed            | 1386          |
| total timesteps         | 288300        |
| value_loss              | 0.00020049041 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011278988  |
| ent_coef_loss           | -2.150668     |
| entropy                 | 1.9540257     |
| ep_rewmean              | -2.1          |
| episodes                | 2888          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 288601        |
| policy_loss             | 0.7939192     |
| qf1_loss                | 0.00030089056 |
| qf2_loss                | 0.00031771648 |
| time_elapsed            | 1388          |
| total timesteps         | 288700        |
| value_loss              | 0.00021850903 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011977743  |
| ent_coef_loss           | 6.247915      |
| entropy                 | 2.3747423     |
| ep_rewmean              | -2.07         |
| episodes                | 2892          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 289001        |
| policy_loss             | 0.81123984    |
| qf1_loss                | 0.0001779991  |
| qf2_loss                | 0.00021176963 |
| time_elapsed            | 1390          |
| total timesteps         | 289100        |
| value_loss              | 0.00038989005 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012486649  |
| ent_coef_loss           | 4.002453      |
| entropy                 | 2.5213037     |
| ep_rewmean              | -2.05         |
| episodes                | 2896          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 289401        |
| policy_loss             | 0.78510696    |
| qf1_loss                | 0.004027086   |
| qf2_loss                | 0.0055386648  |
| time_elapsed            | 1392          |
| total timesteps         | 289500        |
| value_loss              | 0.00023909596 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012757065  |
| ent_coef_loss           | 4.27738       |
| entropy                 | 2.196228      |
| ep_rewmean              | -2.06         |
| episodes                | 2900          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 289801        |
| policy_loss             | 0.85444975    |
| qf1_loss                | 0.0060369684  |
| qf2_loss                | 0.0062402315  |
| time_elapsed            | 1394          |
| total timesteps         | 289900        |
| value_loss              | 0.00025393162 |
-------------------------------------------
Eval num_timesteps=290000, episode_reward=-1.66 +/- 0.59
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012520425  |
| ent_coef_loss           | 2.1680632     |
| entropy                 | 2.003748      |
| ep_rewmean              | -2.06         |
| episodes                | 2904          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 290201        |
| policy_loss             | 0.84714854    |
| qf1_loss                | 0.0066979234  |
| qf2_loss                | 0.0066857934  |
| time_elapsed            | 1396          |
| total timesteps         | 290300        |
| value_loss              | 0.00028629345 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011685693  |
| ent_coef_loss           | 0.93887085    |
| entropy                 | 1.898735      |
| ep_rewmean              | -1.99         |
| episodes                | 2908          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 290601        |
| policy_loss             | 0.81943786    |
| qf1_loss                | 0.00034409208 |
| qf2_loss                | 0.00027112284 |
| time_elapsed            | 1398          |
| total timesteps         | 290700        |
| value_loss              | 0.0002987386  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011291608  |
| ent_coef_loss           | -1.6937876    |
| entropy                 | 2.1122203     |
| ep_rewmean              | -1.97         |
| episodes                | 2912          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 291001        |
| policy_loss             | 0.78731817    |
| qf1_loss                | 0.0003576511  |
| qf2_loss                | 0.00024745596 |
| time_elapsed            | 1400          |
| total timesteps         | 291100        |
| value_loss              | 0.0003933473  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011599151  |
| ent_coef_loss           | 1.0140578     |
| entropy                 | 2.4243424     |
| ep_rewmean              | -1.97         |
| episodes                | 2916          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 291401        |
| policy_loss             | 0.80038       |
| qf1_loss                | 0.0017863235  |
| qf2_loss                | 0.0017801108  |
| time_elapsed            | 1402          |
| total timesteps         | 291500        |
| value_loss              | 0.00025700126 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012251204  |
| ent_coef_loss           | 7.6740627     |
| entropy                 | 2.0080035     |
| ep_rewmean              | -1.95         |
| episodes                | 2920          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 291801        |
| policy_loss             | 0.87345755    |
| qf1_loss                | 0.00040956395 |
| qf2_loss                | 0.00035402575 |
| time_elapsed            | 1404          |
| total timesteps         | 291900        |
| value_loss              | 0.00041804987 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012956223  |
| ent_coef_loss           | 1.668305      |
| entropy                 | 2.664928      |
| ep_rewmean              | -2            |
| episodes                | 2924          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 292201        |
| policy_loss             | 0.85689104    |
| qf1_loss                | 0.0005243675  |
| qf2_loss                | 0.00029264105 |
| time_elapsed            | 1406          |
| total timesteps         | 292300        |
| value_loss              | 0.00031369904 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013353559  |
| ent_coef_loss           | -5.5284767    |
| entropy                 | 3.0016255     |
| ep_rewmean              | -1.95         |
| episodes                | 2928          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 292601        |
| policy_loss             | 0.8039354     |
| qf1_loss                | 0.0018306798  |
| qf2_loss                | 0.0016498133  |
| time_elapsed            | 1408          |
| total timesteps         | 292700        |
| value_loss              | 0.00041545762 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001391559   |
| ent_coef_loss           | -2.0476742    |
| entropy                 | 2.8998854     |
| ep_rewmean              | -1.94         |
| episodes                | 2932          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 293001        |
| policy_loss             | 0.85600847    |
| qf1_loss                | 0.00087766966 |
| qf2_loss                | 0.00095972314 |
| time_elapsed            | 1410          |
| total timesteps         | 293100        |
| value_loss              | 0.0004966861  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014314593  |
| ent_coef_loss           | -1.9737701    |
| entropy                 | 2.999117      |
| ep_rewmean              | -2.07         |
| episodes                | 2936          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 293401        |
| policy_loss             | 0.79529214    |
| qf1_loss                | 0.0003218057  |
| qf2_loss                | 0.00026385058 |
| time_elapsed            | 1412          |
| total timesteps         | 293500        |
| value_loss              | 0.00014836963 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014743678  |
| ent_coef_loss           | -3.6955268    |
| entropy                 | 2.8718934     |
| ep_rewmean              | -2.07         |
| episodes                | 2940          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 293801        |
| policy_loss             | 0.74096817    |
| qf1_loss                | 0.004981416   |
| qf2_loss                | 0.0050856117  |
| time_elapsed            | 1414          |
| total timesteps         | 293900        |
| value_loss              | 0.00047161296 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001438877   |
| ent_coef_loss           | -3.5098886    |
| entropy                 | 3.1630845     |
| ep_rewmean              | -2.02         |
| episodes                | 2944          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 294201        |
| policy_loss             | 0.839646      |
| qf1_loss                | 0.004658592   |
| qf2_loss                | 0.0046107583  |
| time_elapsed            | 1416          |
| total timesteps         | 294300        |
| value_loss              | 0.00018868965 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014534942  |
| ent_coef_loss           | -0.12725496   |
| entropy                 | 2.9724307     |
| ep_rewmean              | -1.94         |
| episodes                | 2948          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 294601        |
| policy_loss             | 0.76306975    |
| qf1_loss                | 0.0022962808  |
| qf2_loss                | 0.002382775   |
| time_elapsed            | 1417          |
| total timesteps         | 294700        |
| value_loss              | 0.00023535267 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014476266 |
| ent_coef_loss           | 0.98469836   |
| entropy                 | 2.5095062    |
| ep_rewmean              | -1.9         |
| episodes                | 2952         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 295001       |
| policy_loss             | 0.6788211    |
| qf1_loss                | 0.006034457  |
| qf2_loss                | 0.006225041  |
| time_elapsed            | 1419         |
| total timesteps         | 295100       |
| value_loss              | 0.0003084754 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014800472  |
| ent_coef_loss           | -0.008744836  |
| entropy                 | 2.3040833     |
| ep_rewmean              | -1.9          |
| episodes                | 2956          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 295401        |
| policy_loss             | 0.7206918     |
| qf1_loss                | 0.00092771475 |
| qf2_loss                | 0.00072200526 |
| time_elapsed            | 1421          |
| total timesteps         | 295500        |
| value_loss              | 0.00029459933 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014725635 |
| ent_coef_loss           | 1.2461872    |
| entropy                 | 2.5966241    |
| ep_rewmean              | -1.93        |
| episodes                | 2960         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 295801       |
| policy_loss             | 0.7002349    |
| qf1_loss                | 0.010006632  |
| qf2_loss                | 0.0099742785 |
| time_elapsed            | 1423         |
| total timesteps         | 295900       |
| value_loss              | 0.0003410732 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014922039  |
| ent_coef_loss           | -2.0293884    |
| entropy                 | 2.466155      |
| ep_rewmean              | -1.93         |
| episodes                | 2964          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 296201        |
| policy_loss             | 0.6617416     |
| qf1_loss                | 0.00019116882 |
| qf2_loss                | 0.00016460844 |
| time_elapsed            | 1425          |
| total timesteps         | 296300        |
| value_loss              | 0.00023490914 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014980728  |
| ent_coef_loss           | -1.6504126    |
| entropy                 | 2.3756423     |
| ep_rewmean              | -1.91         |
| episodes                | 2968          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 296601        |
| policy_loss             | 0.67968976    |
| qf1_loss                | 0.00039894416 |
| qf2_loss                | 0.0002542248  |
| time_elapsed            | 1427          |
| total timesteps         | 296700        |
| value_loss              | 0.00017468774 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001477842   |
| ent_coef_loss           | 5.5784063     |
| entropy                 | 1.9044763     |
| ep_rewmean              | -2.02         |
| episodes                | 2972          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 297001        |
| policy_loss             | 0.6908437     |
| qf1_loss                | 0.00037447404 |
| qf2_loss                | 0.00041565887 |
| time_elapsed            | 1429          |
| total timesteps         | 297100        |
| value_loss              | 0.00020754697 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001475301   |
| ent_coef_loss           | -0.66431266   |
| entropy                 | 2.5576618     |
| ep_rewmean              | -2            |
| episodes                | 2976          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 297401        |
| policy_loss             | 0.62870884    |
| qf1_loss                | 0.00544098    |
| qf2_loss                | 0.0058873277  |
| time_elapsed            | 1431          |
| total timesteps         | 297500        |
| value_loss              | 0.00025834417 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014994793  |
| ent_coef_loss           | 4.2749386     |
| entropy                 | 2.4573698     |
| ep_rewmean              | -2.03         |
| episodes                | 2980          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 297801        |
| policy_loss             | 0.65962875    |
| qf1_loss                | 0.0029901792  |
| qf2_loss                | 0.003159296   |
| time_elapsed            | 1433          |
| total timesteps         | 297900        |
| value_loss              | 0.00033905136 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015038572  |
| ent_coef_loss           | -0.13656333   |
| entropy                 | 2.8221514     |
| ep_rewmean              | -2.01         |
| episodes                | 2984          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 298201        |
| policy_loss             | 0.63971376    |
| qf1_loss                | 0.0014400807  |
| qf2_loss                | 0.0020520377  |
| time_elapsed            | 1435          |
| total timesteps         | 298300        |
| value_loss              | 0.00018320161 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015310084  |
| ent_coef_loss           | -2.9040713    |
| entropy                 | 2.8389313     |
| ep_rewmean              | -2.03         |
| episodes                | 2988          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 298601        |
| policy_loss             | 0.65110934    |
| qf1_loss                | 0.0002460993  |
| qf2_loss                | 0.0001750078  |
| time_elapsed            | 1437          |
| total timesteps         | 298700        |
| value_loss              | 0.00024384273 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015458036  |
| ent_coef_loss           | -7.3104877    |
| entropy                 | 3.3357515     |
| ep_rewmean              | -2.05         |
| episodes                | 2992          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 299001        |
| policy_loss             | 0.68202734    |
| qf1_loss                | 0.0025056468  |
| qf2_loss                | 0.002489325   |
| time_elapsed            | 1439          |
| total timesteps         | 299100        |
| value_loss              | 0.00027213653 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014958478  |
| ent_coef_loss           | -5.107219     |
| entropy                 | 2.7251325     |
| ep_rewmean              | -2.04         |
| episodes                | 2996          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 299401        |
| policy_loss             | 0.6470009     |
| qf1_loss                | 0.013352976   |
| qf2_loss                | 0.013094409   |
| time_elapsed            | 1440          |
| total timesteps         | 299500        |
| value_loss              | 0.00017318857 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014483212  |
| ent_coef_loss           | 1.6136427     |
| entropy                 | 2.721147      |
| ep_rewmean              | -2.16         |
| episodes                | 3000          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 299801        |
| policy_loss             | 0.6636788     |
| qf1_loss                | 0.00025975925 |
| qf2_loss                | 0.0002789958  |
| time_elapsed            | 1442          |
| total timesteps         | 299900        |
| value_loss              | 0.00017547002 |
-------------------------------------------
Eval num_timesteps=300000, episode_reward=-1.95 +/- 1.14
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014284286  |
| ent_coef_loss           | 4.957867      |
| entropy                 | 3.0554662     |
| ep_rewmean              | -2.24         |
| episodes                | 3004          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 300201        |
| policy_loss             | 0.72225547    |
| qf1_loss                | 0.00026238023 |
| qf2_loss                | 0.00022243608 |
| time_elapsed            | 1444          |
| total timesteps         | 300300        |
| value_loss              | 0.00037943933 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013928236  |
| ent_coef_loss           | 2.431173      |
| entropy                 | 2.4280581     |
| ep_rewmean              | -2.22         |
| episodes                | 3008          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 300601        |
| policy_loss             | 0.708414      |
| qf1_loss                | 0.001958099   |
| qf2_loss                | 0.0021027494  |
| time_elapsed            | 1446          |
| total timesteps         | 300700        |
| value_loss              | 0.00023531567 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013405657  |
| ent_coef_loss           | 4.547447      |
| entropy                 | 2.0432587     |
| ep_rewmean              | -2.19         |
| episodes                | 3012          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 301001        |
| policy_loss             | 0.69016004    |
| qf1_loss                | 0.00029441746 |
| qf2_loss                | 0.00030214357 |
| time_elapsed            | 1448          |
| total timesteps         | 301100        |
| value_loss              | 0.0006142189  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012738701  |
| ent_coef_loss           | 0.33296573    |
| entropy                 | 2.291295      |
| ep_rewmean              | -2.16         |
| episodes                | 3016          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 301401        |
| policy_loss             | 0.6977552     |
| qf1_loss                | 0.0040209484  |
| qf2_loss                | 0.0039977334  |
| time_elapsed            | 1450          |
| total timesteps         | 301500        |
| value_loss              | 0.00013378494 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012613359  |
| ent_coef_loss           | -5.193819     |
| entropy                 | 2.651888      |
| ep_rewmean              | -2.21         |
| episodes                | 3020          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 301801        |
| policy_loss             | 0.6538442     |
| qf1_loss                | 0.00025202756 |
| qf2_loss                | 0.00025268682 |
| time_elapsed            | 1452          |
| total timesteps         | 301900        |
| value_loss              | 0.00022610644 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00119218    |
| ent_coef_loss           | -2.8012798    |
| entropy                 | 2.3503523     |
| ep_rewmean              | -2.13         |
| episodes                | 3024          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 302201        |
| policy_loss             | 0.6137209     |
| qf1_loss                | 0.0019083025  |
| qf2_loss                | 0.0021398151  |
| time_elapsed            | 1454          |
| total timesteps         | 302300        |
| value_loss              | 0.00019149209 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011813139  |
| ent_coef_loss           | -0.10750204   |
| entropy                 | 2.6558218     |
| ep_rewmean              | -2.15         |
| episodes                | 3028          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 302601        |
| policy_loss             | 0.6564918     |
| qf1_loss                | 0.005940406   |
| qf2_loss                | 0.00569327    |
| time_elapsed            | 1456          |
| total timesteps         | 302700        |
| value_loss              | 0.00025796087 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011818137  |
| ent_coef_loss           | 1.6344671     |
| entropy                 | 2.4311738     |
| ep_rewmean              | -2.16         |
| episodes                | 3032          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 303001        |
| policy_loss             | 0.61086696    |
| qf1_loss                | 0.0002892844  |
| qf2_loss                | 0.00035694736 |
| time_elapsed            | 1458          |
| total timesteps         | 303100        |
| value_loss              | 0.00038440208 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011880571 |
| ent_coef_loss           | 1.2266576    |
| entropy                 | 2.6722746    |
| ep_rewmean              | -2.11        |
| episodes                | 3036         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 303401       |
| policy_loss             | 0.6173217    |
| qf1_loss                | 0.0029701595 |
| qf2_loss                | 0.0030147315 |
| time_elapsed            | 1460         |
| total timesteps         | 303500       |
| value_loss              | 0.0002113684 |
------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0011511432   |
| ent_coef_loss           | -4.379188      |
| entropy                 | 2.3994083      |
| ep_rewmean              | -2.07          |
| episodes                | 3040           |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -2.1           |
| n_updates               | 303801         |
| policy_loss             | 0.6317719      |
| qf1_loss                | 0.000115392584 |
| qf2_loss                | 0.00012733518  |
| time_elapsed            | 1462           |
| total timesteps         | 303900         |
| value_loss              | 0.00024910452  |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001139376   |
| ent_coef_loss           | -3.1790123    |
| entropy                 | 2.1730027     |
| ep_rewmean              | -2.08         |
| episodes                | 3044          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 304201        |
| policy_loss             | 0.6535321     |
| qf1_loss                | 0.0024605878  |
| qf2_loss                | 0.0020926904  |
| time_elapsed            | 1463          |
| total timesteps         | 304300        |
| value_loss              | 0.00023188817 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011445746  |
| ent_coef_loss           | -5.236232     |
| entropy                 | 2.865728      |
| ep_rewmean              | -2.07         |
| episodes                | 3048          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 304601        |
| policy_loss             | 0.6832084     |
| qf1_loss                | 0.0007817103  |
| qf2_loss                | 0.0006075164  |
| time_elapsed            | 1465          |
| total timesteps         | 304700        |
| value_loss              | 0.00019667081 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011609892  |
| ent_coef_loss           | -2.1648695    |
| entropy                 | 2.3500762     |
| ep_rewmean              | -2.07         |
| episodes                | 3052          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 305001        |
| policy_loss             | 0.6173972     |
| qf1_loss                | 0.00030667684 |
| qf2_loss                | 0.00031416165 |
| time_elapsed            | 1467          |
| total timesteps         | 305100        |
| value_loss              | 0.00018119189 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011311973  |
| ent_coef_loss           | -2.116742     |
| entropy                 | 2.7067213     |
| ep_rewmean              | -2.07         |
| episodes                | 3056          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 305401        |
| policy_loss             | 0.62101674    |
| qf1_loss                | 0.0089457035  |
| qf2_loss                | 0.008582406   |
| time_elapsed            | 1469          |
| total timesteps         | 305500        |
| value_loss              | 0.00016553566 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010449595  |
| ent_coef_loss           | -4.320393     |
| entropy                 | 2.5705514     |
| ep_rewmean              | -2.04         |
| episodes                | 3060          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 305801        |
| policy_loss             | 0.618696      |
| qf1_loss                | 0.00021363446 |
| qf2_loss                | 0.00014382895 |
| time_elapsed            | 1471          |
| total timesteps         | 305900        |
| value_loss              | 0.00012656728 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010557179 |
| ent_coef_loss           | 1.4983757    |
| entropy                 | 2.018683     |
| ep_rewmean              | -2.07        |
| episodes                | 3064         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 306201       |
| policy_loss             | 0.6397114    |
| qf1_loss                | 0.0002654536 |
| qf2_loss                | 0.0003970986 |
| time_elapsed            | 1473         |
| total timesteps         | 306300       |
| value_loss              | 0.0005408566 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010719106  |
| ent_coef_loss           | 2.2340589     |
| entropy                 | 2.2326856     |
| ep_rewmean              | -2.05         |
| episodes                | 3068          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 306601        |
| policy_loss             | 0.5986649     |
| qf1_loss                | 0.0010280975  |
| qf2_loss                | 0.00088636164 |
| time_elapsed            | 1475          |
| total timesteps         | 306700        |
| value_loss              | 0.00015576612 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011033504  |
| ent_coef_loss           | 3.3133245     |
| entropy                 | 1.9382749     |
| ep_rewmean              | -1.95         |
| episodes                | 3072          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 307001        |
| policy_loss             | 0.64049304    |
| qf1_loss                | 0.010445928   |
| qf2_loss                | 0.010567381   |
| time_elapsed            | 1477          |
| total timesteps         | 307100        |
| value_loss              | 0.00014885413 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011205119  |
| ent_coef_loss           | -0.48282373   |
| entropy                 | 2.223909      |
| ep_rewmean              | -1.95         |
| episodes                | 3076          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 307401        |
| policy_loss             | 0.5751786     |
| qf1_loss                | 0.00032219233 |
| qf2_loss                | 0.00028722285 |
| time_elapsed            | 1479          |
| total timesteps         | 307500        |
| value_loss              | 0.00012337134 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011262516  |
| ent_coef_loss           | 1.2152483     |
| entropy                 | 1.7767051     |
| ep_rewmean              | -2            |
| episodes                | 3080          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 307801        |
| policy_loss             | 0.61443985    |
| qf1_loss                | 0.000633555   |
| qf2_loss                | 0.0006151844  |
| time_elapsed            | 1481          |
| total timesteps         | 307900        |
| value_loss              | 0.00012791032 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00119262    |
| ent_coef_loss           | -4.1320486    |
| entropy                 | 2.5288196     |
| ep_rewmean              | -2.01         |
| episodes                | 3084          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 308201        |
| policy_loss             | 0.62412214    |
| qf1_loss                | 0.0019848372  |
| qf2_loss                | 0.00209666    |
| time_elapsed            | 1483          |
| total timesteps         | 308300        |
| value_loss              | 0.00016327307 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012226389  |
| ent_coef_loss           | 0.35954237    |
| entropy                 | 3.1235058     |
| ep_rewmean              | -1.99         |
| episodes                | 3088          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 308601        |
| policy_loss             | 0.6108854     |
| qf1_loss                | 0.00092038553 |
| qf2_loss                | 0.0010966345  |
| time_elapsed            | 1484          |
| total timesteps         | 308700        |
| value_loss              | 0.00027676654 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012619526  |
| ent_coef_loss           | -4.991655     |
| entropy                 | 2.2754889     |
| ep_rewmean              | -2.04         |
| episodes                | 3092          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 309001        |
| policy_loss             | 0.55759406    |
| qf1_loss                | 0.004275752   |
| qf2_loss                | 0.0042019063  |
| time_elapsed            | 1486          |
| total timesteps         | 309100        |
| value_loss              | 0.00037773966 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013045686  |
| ent_coef_loss           | 7.1279798     |
| entropy                 | 2.9749284     |
| ep_rewmean              | -2.08         |
| episodes                | 3096          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 309401        |
| policy_loss             | 0.60474193    |
| qf1_loss                | 0.00049103634 |
| qf2_loss                | 0.0004462438  |
| time_elapsed            | 1488          |
| total timesteps         | 309500        |
| value_loss              | 0.00013176042 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013904799  |
| ent_coef_loss           | 1.1301911     |
| entropy                 | 2.6977139     |
| ep_rewmean              | -1.99         |
| episodes                | 3100          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 309801        |
| policy_loss             | 0.5362973     |
| qf1_loss                | 0.00023423307 |
| qf2_loss                | 0.00021121193 |
| time_elapsed            | 1490          |
| total timesteps         | 309900        |
| value_loss              | 0.00019869588 |
-------------------------------------------
Eval num_timesteps=310000, episode_reward=-5.25 +/- 2.67
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014018199 |
| ent_coef_loss           | -0.626866    |
| entropy                 | 3.0049093    |
| ep_rewmean              | -1.96        |
| episodes                | 3104         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 310201       |
| policy_loss             | 0.5518782    |
| qf1_loss                | 0.0017145374 |
| qf2_loss                | 0.0020855174 |
| time_elapsed            | 1492         |
| total timesteps         | 310300       |
| value_loss              | 0.0002422898 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013223334 |
| ent_coef_loss           | -7.0424643   |
| entropy                 | 2.818265     |
| ep_rewmean              | -1.99        |
| episodes                | 3108         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 310601       |
| policy_loss             | 0.612299     |
| qf1_loss                | 0.0014869263 |
| qf2_loss                | 0.001473379  |
| time_elapsed            | 1494         |
| total timesteps         | 310700       |
| value_loss              | 0.0004775355 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012128986  |
| ent_coef_loss           | -1.6063963    |
| entropy                 | 2.0601869     |
| ep_rewmean              | -1.99         |
| episodes                | 3112          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 311001        |
| policy_loss             | 0.64744186    |
| qf1_loss                | 0.00023602019 |
| qf2_loss                | 0.00023568759 |
| time_elapsed            | 1496          |
| total timesteps         | 311100        |
| value_loss              | 0.00020831569 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011348419  |
| ent_coef_loss           | 3.6803555     |
| entropy                 | 2.184079      |
| ep_rewmean              | -2            |
| episodes                | 3116          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 311401        |
| policy_loss             | 0.62916577    |
| qf1_loss                | 0.0022325155  |
| qf2_loss                | 0.0022588645  |
| time_elapsed            | 1498          |
| total timesteps         | 311500        |
| value_loss              | 0.00040671407 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010837674  |
| ent_coef_loss           | 2.2020216     |
| entropy                 | 1.7397087     |
| ep_rewmean              | -1.97         |
| episodes                | 3120          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 311801        |
| policy_loss             | 0.6303725     |
| qf1_loss                | 0.014228478   |
| qf2_loss                | 0.013966114   |
| time_elapsed            | 1500          |
| total timesteps         | 311900        |
| value_loss              | 0.00019100854 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010430871  |
| ent_coef_loss           | 4.6452293     |
| entropy                 | 1.4056017     |
| ep_rewmean              | -1.99         |
| episodes                | 3124          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 312201        |
| policy_loss             | 0.6715646     |
| qf1_loss                | 0.00019798393 |
| qf2_loss                | 0.00017962874 |
| time_elapsed            | 1502          |
| total timesteps         | 312300        |
| value_loss              | 0.0002633193  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010343546 |
| ent_coef_loss           | 3.5957005    |
| entropy                 | 0.7491956    |
| ep_rewmean              | -2           |
| episodes                | 3128         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 312601       |
| policy_loss             | 0.6516788    |
| qf1_loss                | 0.0008555113 |
| qf2_loss                | 0.0009146474 |
| time_elapsed            | 1504         |
| total timesteps         | 312700       |
| value_loss              | 0.0003722327 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010078594  |
| ent_coef_loss           | 2.3917656     |
| entropy                 | 0.9736184     |
| ep_rewmean              | -2            |
| episodes                | 3132          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 313001        |
| policy_loss             | 0.72188497    |
| qf1_loss                | 0.016118849   |
| qf2_loss                | 0.016491773   |
| time_elapsed            | 1506          |
| total timesteps         | 313100        |
| value_loss              | 0.00014435056 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010024046  |
| ent_coef_loss           | 8.61568       |
| entropy                 | 0.72771335    |
| ep_rewmean              | -1.95         |
| episodes                | 3136          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 313401        |
| policy_loss             | 0.6979714     |
| qf1_loss                | 0.002025911   |
| qf2_loss                | 0.0020147436  |
| time_elapsed            | 1508          |
| total timesteps         | 313500        |
| value_loss              | 0.00020690389 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00105172    |
| ent_coef_loss           | 3.1761382     |
| entropy                 | 1.4338094     |
| ep_rewmean              | -1.96         |
| episodes                | 3140          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 313801        |
| policy_loss             | 0.7229698     |
| qf1_loss                | 0.0002535039  |
| qf2_loss                | 0.00018590892 |
| time_elapsed            | 1510          |
| total timesteps         | 313900        |
| value_loss              | 0.00019870592 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011887837  |
| ent_coef_loss           | 3.544344      |
| entropy                 | 1.9045813     |
| ep_rewmean              | -1.98         |
| episodes                | 3144          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 314201        |
| policy_loss             | 0.6464205     |
| qf1_loss                | 0.0030861679  |
| qf2_loss                | 0.0030263679  |
| time_elapsed            | 1511          |
| total timesteps         | 314300        |
| value_loss              | 0.00041134894 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012471428  |
| ent_coef_loss           | 4.7786436     |
| entropy                 | 1.3475691     |
| ep_rewmean              | -1.96         |
| episodes                | 3148          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 314601        |
| policy_loss             | 0.7469783     |
| qf1_loss                | 0.00035143807 |
| qf2_loss                | 0.00034697534 |
| time_elapsed            | 1513          |
| total timesteps         | 314700        |
| value_loss              | 0.00023140524 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012888744 |
| ent_coef_loss           | 5.4687443    |
| entropy                 | 1.4713142    |
| ep_rewmean              | -1.92        |
| episodes                | 3152         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 315001       |
| policy_loss             | 0.7468201    |
| qf1_loss                | 0.017862001  |
| qf2_loss                | 0.017436191  |
| time_elapsed            | 1515         |
| total timesteps         | 315100       |
| value_loss              | 0.0003659891 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013400365  |
| ent_coef_loss           | 1.590407      |
| entropy                 | 1.9892898     |
| ep_rewmean              | -1.92         |
| episodes                | 3156          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 315401        |
| policy_loss             | 0.7450292     |
| qf1_loss                | 0.00027601226 |
| qf2_loss                | 0.00025264124 |
| time_elapsed            | 1517          |
| total timesteps         | 315500        |
| value_loss              | 0.00036205444 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013613084  |
| ent_coef_loss           | 1.2849742     |
| entropy                 | 1.6131473     |
| ep_rewmean              | -1.96         |
| episodes                | 3160          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 315801        |
| policy_loss             | 0.7584858     |
| qf1_loss                | 0.0003181696  |
| qf2_loss                | 0.00030926484 |
| time_elapsed            | 1519          |
| total timesteps         | 315900        |
| value_loss              | 0.0003076825  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014533382  |
| ent_coef_loss           | 6.123979      |
| entropy                 | 2.3666847     |
| ep_rewmean              | -2.01         |
| episodes                | 3164          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 316201        |
| policy_loss             | 0.8594186     |
| qf1_loss                | 0.00042502757 |
| qf2_loss                | 0.00054590055 |
| time_elapsed            | 1521          |
| total timesteps         | 316300        |
| value_loss              | 0.00078177766 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015509763  |
| ent_coef_loss           | 0.34868252    |
| entropy                 | 2.1648502     |
| ep_rewmean              | -2.02         |
| episodes                | 3168          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 316601        |
| policy_loss             | 0.73151004    |
| qf1_loss                | 0.0004585198  |
| qf2_loss                | 0.00034701033 |
| time_elapsed            | 1523          |
| total timesteps         | 316700        |
| value_loss              | 0.00046101946 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001573995   |
| ent_coef_loss           | -7.4792786    |
| entropy                 | 1.892944      |
| ep_rewmean              | -2.06         |
| episodes                | 3172          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 317001        |
| policy_loss             | 0.77538145    |
| qf1_loss                | 0.0008879929  |
| qf2_loss                | 0.0009102896  |
| time_elapsed            | 1525          |
| total timesteps         | 317100        |
| value_loss              | 0.00040466562 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015784716  |
| ent_coef_loss           | -0.6683192    |
| entropy                 | 2.0665393     |
| ep_rewmean              | -2.11         |
| episodes                | 3176          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 317401        |
| policy_loss             | 0.8429734     |
| qf1_loss                | 0.00035508582 |
| qf2_loss                | 0.00040944613 |
| time_elapsed            | 1527          |
| total timesteps         | 317500        |
| value_loss              | 0.00030698552 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015950963  |
| ent_coef_loss           | -6.3569126    |
| entropy                 | 2.8258219     |
| ep_rewmean              | -2.06         |
| episodes                | 3180          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 317801        |
| policy_loss             | 0.8630473     |
| qf1_loss                | 0.0007068111  |
| qf2_loss                | 0.00039553893 |
| time_elapsed            | 1529          |
| total timesteps         | 317900        |
| value_loss              | 0.0004736276  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015925496  |
| ent_coef_loss           | -0.929389     |
| entropy                 | 2.6458125     |
| ep_rewmean              | -2.07         |
| episodes                | 3184          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 318201        |
| policy_loss             | 0.90752894    |
| qf1_loss                | 0.0004248558  |
| qf2_loss                | 0.00052532787 |
| time_elapsed            | 1531          |
| total timesteps         | 318300        |
| value_loss              | 0.0010017701  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015912341  |
| ent_coef_loss           | 1.3455911     |
| entropy                 | 2.8583894     |
| ep_rewmean              | -2.04         |
| episodes                | 3188          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 318601        |
| policy_loss             | 0.78228354    |
| qf1_loss                | 0.0053943493  |
| qf2_loss                | 0.005523175   |
| time_elapsed            | 1533          |
| total timesteps         | 318700        |
| value_loss              | 0.00042734848 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017497475 |
| ent_coef_loss           | 1.1414591    |
| entropy                 | 3.2409415    |
| ep_rewmean              | -2           |
| episodes                | 3192         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 319001       |
| policy_loss             | 0.8366074    |
| qf1_loss                | 0.0005295573 |
| qf2_loss                | 0.0007612071 |
| time_elapsed            | 1534         |
| total timesteps         | 319100       |
| value_loss              | 0.0006455738 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018052362  |
| ent_coef_loss           | -0.5531302    |
| entropy                 | 2.9531412     |
| ep_rewmean              | -1.98         |
| episodes                | 3196          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 319401        |
| policy_loss             | 0.84703755    |
| qf1_loss                | 0.0057334346  |
| qf2_loss                | 0.005862273   |
| time_elapsed            | 1536          |
| total timesteps         | 319500        |
| value_loss              | 0.00019877795 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017423509  |
| ent_coef_loss           | -0.11758566   |
| entropy                 | 3.0046859     |
| ep_rewmean              | -1.97         |
| episodes                | 3200          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 319801        |
| policy_loss             | 0.8074276     |
| qf1_loss                | 0.008441357   |
| qf2_loss                | 0.0078019914  |
| time_elapsed            | 1538          |
| total timesteps         | 319900        |
| value_loss              | 0.00030165084 |
-------------------------------------------
Eval num_timesteps=320000, episode_reward=-1.89 +/- 1.04
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016612513  |
| ent_coef_loss           | -5.2147226    |
| entropy                 | 2.7503896     |
| ep_rewmean              | -1.94         |
| episodes                | 3204          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 320201        |
| policy_loss             | 0.71420056    |
| qf1_loss                | 0.00033617788 |
| qf2_loss                | 0.00037109485 |
| time_elapsed            | 1540          |
| total timesteps         | 320300        |
| value_loss              | 0.00044982514 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016685391  |
| ent_coef_loss           | -3.2475955    |
| entropy                 | 3.2269392     |
| ep_rewmean              | -1.94         |
| episodes                | 3208          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 320601        |
| policy_loss             | 0.79091203    |
| qf1_loss                | 0.028602675   |
| qf2_loss                | 0.029016428   |
| time_elapsed            | 1542          |
| total timesteps         | 320700        |
| value_loss              | 0.00037884223 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015756494  |
| ent_coef_loss           | -5.4813337    |
| entropy                 | 3.564404      |
| ep_rewmean              | -1.98         |
| episodes                | 3212          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 321001        |
| policy_loss             | 0.8310358     |
| qf1_loss                | 0.031637218   |
| qf2_loss                | 0.03038775    |
| time_elapsed            | 1544          |
| total timesteps         | 321100        |
| value_loss              | 0.00016230866 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014981771 |
| ent_coef_loss           | -3.5475528   |
| entropy                 | 3.2875779    |
| ep_rewmean              | -2           |
| episodes                | 3216         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 321401       |
| policy_loss             | 0.8183936    |
| qf1_loss                | 0.004254922  |
| qf2_loss                | 0.0037123922 |
| time_elapsed            | 1546         |
| total timesteps         | 321500       |
| value_loss              | 0.000306451  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013993029  |
| ent_coef_loss           | -2.5818071    |
| entropy                 | 2.5376773     |
| ep_rewmean              | -2            |
| episodes                | 3220          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 321801        |
| policy_loss             | 0.7670978     |
| qf1_loss                | 0.011097353   |
| qf2_loss                | 0.010966992   |
| time_elapsed            | 1548          |
| total timesteps         | 321900        |
| value_loss              | 0.00041722297 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013753416  |
| ent_coef_loss           | 3.4195266     |
| entropy                 | 2.634982      |
| ep_rewmean              | -2            |
| episodes                | 3224          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 322201        |
| policy_loss             | 0.8143209     |
| qf1_loss                | 0.00041895674 |
| qf2_loss                | 0.0004529857  |
| time_elapsed            | 1550          |
| total timesteps         | 322300        |
| value_loss              | 0.0003248998  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013249842  |
| ent_coef_loss           | -1.5838091    |
| entropy                 | 3.0202026     |
| ep_rewmean              | -1.98         |
| episodes                | 3228          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 322601        |
| policy_loss             | 0.74754006    |
| qf1_loss                | 0.0003599017  |
| qf2_loss                | 0.0003915677  |
| time_elapsed            | 1552          |
| total timesteps         | 322700        |
| value_loss              | 0.00032543618 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012894351 |
| ent_coef_loss           | -0.4261415   |
| entropy                 | 3.179256     |
| ep_rewmean              | -1.94        |
| episodes                | 3232         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 323001       |
| policy_loss             | 0.8399452    |
| qf1_loss                | 0.0051661283 |
| qf2_loss                | 0.004836912  |
| time_elapsed            | 1554         |
| total timesteps         | 323100       |
| value_loss              | 0.0002164345 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013388243  |
| ent_coef_loss           | -13.125898    |
| entropy                 | 3.1983147     |
| ep_rewmean              | -1.99         |
| episodes                | 3236          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 323401        |
| policy_loss             | 0.7955126     |
| qf1_loss                | 0.00045882483 |
| qf2_loss                | 0.0003124086  |
| time_elapsed            | 1556          |
| total timesteps         | 323500        |
| value_loss              | 0.00015989595 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001373984  |
| ent_coef_loss           | -2.7431805   |
| entropy                 | 3.1500928    |
| ep_rewmean              | -1.97        |
| episodes                | 3240         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 323801       |
| policy_loss             | 0.7901975    |
| qf1_loss                | 0.0009855806 |
| qf2_loss                | 0.0008264179 |
| time_elapsed            | 1558         |
| total timesteps         | 323900       |
| value_loss              | 0.0002873654 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013917773  |
| ent_coef_loss           | -8.762455     |
| entropy                 | 3.1921234     |
| ep_rewmean              | -2.01         |
| episodes                | 3244          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 324201        |
| policy_loss             | 0.8235455     |
| qf1_loss                | 0.00029028187 |
| qf2_loss                | 0.0002759044  |
| time_elapsed            | 1560          |
| total timesteps         | 324300        |
| value_loss              | 0.0003593285  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013958035 |
| ent_coef_loss           | 3.8816748    |
| entropy                 | 3.212943     |
| ep_rewmean              | -2.05        |
| episodes                | 3248         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 324601       |
| policy_loss             | 0.84918547   |
| qf1_loss                | 0.00190071   |
| qf2_loss                | 0.002015141  |
| time_elapsed            | 1562         |
| total timesteps         | 324700       |
| value_loss              | 0.0002988601 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014235179  |
| ent_coef_loss           | -4.664732     |
| entropy                 | 3.9799392     |
| ep_rewmean              | -2.14         |
| episodes                | 3252          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 325001        |
| policy_loss             | 0.8225124     |
| qf1_loss                | 0.00039447777 |
| qf2_loss                | 0.00023436398 |
| time_elapsed            | 1563          |
| total timesteps         | 325100        |
| value_loss              | 0.00023536866 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014838249  |
| ent_coef_loss           | 4.8144946     |
| entropy                 | 3.5233407     |
| ep_rewmean              | -2.11         |
| episodes                | 3256          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 325401        |
| policy_loss             | 0.7913846     |
| qf1_loss                | 0.0004269012  |
| qf2_loss                | 0.0003866756  |
| time_elapsed            | 1565          |
| total timesteps         | 325500        |
| value_loss              | 0.00037001548 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015445392  |
| ent_coef_loss           | -0.7690886    |
| entropy                 | 3.6742063     |
| ep_rewmean              | -2.09         |
| episodes                | 3260          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 325801        |
| policy_loss             | 0.81200206    |
| qf1_loss                | 0.010095896   |
| qf2_loss                | 0.01023922    |
| time_elapsed            | 1567          |
| total timesteps         | 325900        |
| value_loss              | 0.00019527267 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015277537 |
| ent_coef_loss           | -2.028382    |
| entropy                 | 3.458702     |
| ep_rewmean              | -2.04        |
| episodes                | 3264         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 326201       |
| policy_loss             | 0.82107866   |
| qf1_loss                | 0.007857602  |
| qf2_loss                | 0.0076826876 |
| time_elapsed            | 1569         |
| total timesteps         | 326300       |
| value_loss              | 0.0002397327 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014721879  |
| ent_coef_loss           | -3.6251678    |
| entropy                 | 3.0332272     |
| ep_rewmean              | -2.02         |
| episodes                | 3268          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 326601        |
| policy_loss             | 0.8196335     |
| qf1_loss                | 0.012484069   |
| qf2_loss                | 0.012545957   |
| time_elapsed            | 1571          |
| total timesteps         | 326700        |
| value_loss              | 0.00017208785 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015471686  |
| ent_coef_loss           | -3.0962915    |
| entropy                 | 3.355538      |
| ep_rewmean              | -2.01         |
| episodes                | 3272          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 327001        |
| policy_loss             | 0.85238683    |
| qf1_loss                | 0.00050063553 |
| qf2_loss                | 0.00050048373 |
| time_elapsed            | 1573          |
| total timesteps         | 327100        |
| value_loss              | 0.00030027982 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016314341  |
| ent_coef_loss           | 1.8585374     |
| entropy                 | 3.3045604     |
| ep_rewmean              | -2.03         |
| episodes                | 3276          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 327401        |
| policy_loss             | 0.81232727    |
| qf1_loss                | 0.016919035   |
| qf2_loss                | 0.015663568   |
| time_elapsed            | 1575          |
| total timesteps         | 327500        |
| value_loss              | 0.00023650739 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016951462  |
| ent_coef_loss           | 4.495273      |
| entropy                 | 3.1159291     |
| ep_rewmean              | -2.03         |
| episodes                | 3280          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 327801        |
| policy_loss             | 0.80245197    |
| qf1_loss                | 0.00031939693 |
| qf2_loss                | 0.00023984424 |
| time_elapsed            | 1577          |
| total timesteps         | 327900        |
| value_loss              | 0.0003171313  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018061628  |
| ent_coef_loss           | -3.334783     |
| entropy                 | 3.3564649     |
| ep_rewmean              | -2.05         |
| episodes                | 3284          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 328201        |
| policy_loss             | 0.7819012     |
| qf1_loss                | 0.004253416   |
| qf2_loss                | 0.0046203537  |
| time_elapsed            | 1579          |
| total timesteps         | 328300        |
| value_loss              | 0.00024272814 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018620655  |
| ent_coef_loss           | 3.123068      |
| entropy                 | 3.474552      |
| ep_rewmean              | -2.05         |
| episodes                | 3288          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 328601        |
| policy_loss             | 0.8101483     |
| qf1_loss                | 0.00021406834 |
| qf2_loss                | 0.00029565266 |
| time_elapsed            | 1581          |
| total timesteps         | 328700        |
| value_loss              | 0.00037683814 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017713981 |
| ent_coef_loss           | -3.299588    |
| entropy                 | 3.2166598    |
| ep_rewmean              | -2.03        |
| episodes                | 3292         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 329001       |
| policy_loss             | 0.8250834    |
| qf1_loss                | 0.002670613  |
| qf2_loss                | 0.002829446  |
| time_elapsed            | 1583         |
| total timesteps         | 329100       |
| value_loss              | 0.0002869719 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016675203  |
| ent_coef_loss           | -5.898899     |
| entropy                 | 3.1176877     |
| ep_rewmean              | -2.05         |
| episodes                | 3296          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 329401        |
| policy_loss             | 0.83457756    |
| qf1_loss                | 0.00024653765 |
| qf2_loss                | 0.00020969345 |
| time_elapsed            | 1585          |
| total timesteps         | 329500        |
| value_loss              | 0.00024445166 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015597382  |
| ent_coef_loss           | 1.7645413     |
| entropy                 | 3.2991133     |
| ep_rewmean              | -2.04         |
| episodes                | 3300          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 329801        |
| policy_loss             | 0.8676492     |
| qf1_loss                | 0.00030792152 |
| qf2_loss                | 0.0002991664  |
| time_elapsed            | 1586          |
| total timesteps         | 329900        |
| value_loss              | 0.00025069594 |
-------------------------------------------
Eval num_timesteps=330000, episode_reward=-2.55 +/- 1.14
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014726408  |
| ent_coef_loss           | -3.1171365    |
| entropy                 | 2.7774808     |
| ep_rewmean              | -2.07         |
| episodes                | 3304          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 330201        |
| policy_loss             | 0.85924107    |
| qf1_loss                | 0.0028883663  |
| qf2_loss                | 0.0026725277  |
| time_elapsed            | 1589          |
| total timesteps         | 330300        |
| value_loss              | 0.00020802059 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014588629  |
| ent_coef_loss           | 3.5135522     |
| entropy                 | 3.1669188     |
| ep_rewmean              | -2.1          |
| episodes                | 3308          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 330601        |
| policy_loss             | 0.8575039     |
| qf1_loss                | 0.011909709   |
| qf2_loss                | 0.012542749   |
| time_elapsed            | 1590          |
| total timesteps         | 330700        |
| value_loss              | 0.00022083343 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001406266   |
| ent_coef_loss           | -7.079773     |
| entropy                 | 3.2682352     |
| ep_rewmean              | -2.08         |
| episodes                | 3312          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 331001        |
| policy_loss             | 0.8292762     |
| qf1_loss                | 0.00014853732 |
| qf2_loss                | 0.00018275512 |
| time_elapsed            | 1592          |
| total timesteps         | 331100        |
| value_loss              | 0.00031292695 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013560271 |
| ent_coef_loss           | 1.889801     |
| entropy                 | 2.4974627    |
| ep_rewmean              | -2.07        |
| episodes                | 3316         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 331401       |
| policy_loss             | 0.8427794    |
| qf1_loss                | 0.011150589  |
| qf2_loss                | 0.011380787  |
| time_elapsed            | 1594         |
| total timesteps         | 331500       |
| value_loss              | 0.0003566619 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013025943  |
| ent_coef_loss           | -3.4436731    |
| entropy                 | 2.3835914     |
| ep_rewmean              | -2.22         |
| episodes                | 3320          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 331801        |
| policy_loss             | 0.8352752     |
| qf1_loss                | 0.000378263   |
| qf2_loss                | 0.00021012838 |
| time_elapsed            | 1596          |
| total timesteps         | 331900        |
| value_loss              | 0.00023911541 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012249971  |
| ent_coef_loss           | -5.4916277    |
| entropy                 | 2.7185054     |
| ep_rewmean              | -2.3          |
| episodes                | 3324          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 332201        |
| policy_loss             | 0.8407918     |
| qf1_loss                | 0.009242692   |
| qf2_loss                | 0.008928129   |
| time_elapsed            | 1598          |
| total timesteps         | 332300        |
| value_loss              | 0.00021555784 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011391798  |
| ent_coef_loss           | -6.0077367    |
| entropy                 | 2.1683412     |
| ep_rewmean              | -2.44         |
| episodes                | 3328          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 332601        |
| policy_loss             | 0.8452737     |
| qf1_loss                | 0.0049419203  |
| qf2_loss                | 0.00514126    |
| time_elapsed            | 1600          |
| total timesteps         | 332700        |
| value_loss              | 0.00014102376 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011450949  |
| ent_coef_loss           | -3.772149     |
| entropy                 | 2.3337207     |
| ep_rewmean              | -2.54         |
| episodes                | 3332          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 333001        |
| policy_loss             | 0.837185      |
| qf1_loss                | 0.00037839095 |
| qf2_loss                | 0.00037302286 |
| time_elapsed            | 1602          |
| total timesteps         | 333100        |
| value_loss              | 0.00019640889 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011657416  |
| ent_coef_loss           | 0.46373892    |
| entropy                 | 2.1435063     |
| ep_rewmean              | -2.64         |
| episodes                | 3336          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 333401        |
| policy_loss             | 0.8841849     |
| qf1_loss                | 0.00022256095 |
| qf2_loss                | 0.0002132302  |
| time_elapsed            | 1604          |
| total timesteps         | 333500        |
| value_loss              | 0.0002500573  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011536011  |
| ent_coef_loss           | -6.3180575    |
| entropy                 | 1.5257002     |
| ep_rewmean              | -2.64         |
| episodes                | 3340          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 333801        |
| policy_loss             | 0.8971877     |
| qf1_loss                | 0.00035933667 |
| qf2_loss                | 0.00035403087 |
| time_elapsed            | 1606          |
| total timesteps         | 333900        |
| value_loss              | 0.00014584031 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011974117  |
| ent_coef_loss           | 5.492868      |
| entropy                 | 1.3272219     |
| ep_rewmean              | -2.55         |
| episodes                | 3344          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 334201        |
| policy_loss             | 0.874437      |
| qf1_loss                | 0.012202584   |
| qf2_loss                | 0.012842284   |
| time_elapsed            | 1608          |
| total timesteps         | 334300        |
| value_loss              | 0.00031839823 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013034897  |
| ent_coef_loss           | 2.9538527     |
| entropy                 | 2.2591076     |
| ep_rewmean              | -2.59         |
| episodes                | 3348          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 334601        |
| policy_loss             | 0.9358616     |
| qf1_loss                | 0.00036111847 |
| qf2_loss                | 0.00025630792 |
| time_elapsed            | 1610          |
| total timesteps         | 334700        |
| value_loss              | 0.00031922    |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014226655  |
| ent_coef_loss           | -1.0082214    |
| entropy                 | 2.778548      |
| ep_rewmean              | -2.49         |
| episodes                | 3352          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 335001        |
| policy_loss             | 0.9694003     |
| qf1_loss                | 0.01389038    |
| qf2_loss                | 0.014182908   |
| time_elapsed            | 1612          |
| total timesteps         | 335100        |
| value_loss              | 0.00057149015 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015400165  |
| ent_coef_loss           | -3.444893     |
| entropy                 | 3.1366944     |
| ep_rewmean              | -2.52         |
| episodes                | 3356          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 335401        |
| policy_loss             | 0.95888096    |
| qf1_loss                | 0.00077340123 |
| qf2_loss                | 0.0006735862  |
| time_elapsed            | 1614          |
| total timesteps         | 335500        |
| value_loss              | 0.0006857133  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016010675  |
| ent_coef_loss           | 2.0556455     |
| entropy                 | 3.1094172     |
| ep_rewmean              | -2.5          |
| episodes                | 3360          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 335801        |
| policy_loss             | 0.99111533    |
| qf1_loss                | 0.008085932   |
| qf2_loss                | 0.0084502855  |
| time_elapsed            | 1616          |
| total timesteps         | 335900        |
| value_loss              | 0.00026230776 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016444969  |
| ent_coef_loss           | 4.41639       |
| entropy                 | 3.1866784     |
| ep_rewmean              | -2.53         |
| episodes                | 3364          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 336201        |
| policy_loss             | 0.99191195    |
| qf1_loss                | 0.0005131507  |
| qf2_loss                | 0.0004877185  |
| time_elapsed            | 1617          |
| total timesteps         | 336300        |
| value_loss              | 0.00036831025 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001611405   |
| ent_coef_loss           | 2.9281259     |
| entropy                 | 2.8901072     |
| ep_rewmean              | -2.6          |
| episodes                | 3368          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 336601        |
| policy_loss             | 1.0080997     |
| qf1_loss                | 0.0010453216  |
| qf2_loss                | 0.00092404766 |
| time_elapsed            | 1619          |
| total timesteps         | 336700        |
| value_loss              | 0.0004186699  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015884398  |
| ent_coef_loss           | -5.4472475    |
| entropy                 | 2.793736      |
| ep_rewmean              | -2.66         |
| episodes                | 3372          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.7          |
| n_updates               | 337001        |
| policy_loss             | 1.0580661     |
| qf1_loss                | 0.002511937   |
| qf2_loss                | 0.002593351   |
| time_elapsed            | 1621          |
| total timesteps         | 337100        |
| value_loss              | 0.00041777466 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015504454 |
| ent_coef_loss           | 0.027792454  |
| entropy                 | 1.8858014    |
| ep_rewmean              | -2.62        |
| episodes                | 3376         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.6         |
| n_updates               | 337401       |
| policy_loss             | 1.0499945    |
| qf1_loss                | 0.0038414276 |
| qf2_loss                | 0.0039213654 |
| time_elapsed            | 1623         |
| total timesteps         | 337500       |
| value_loss              | 0.0004138762 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015889655 |
| ent_coef_loss           | 10.894819    |
| entropy                 | 2.6548765    |
| ep_rewmean              | -2.62        |
| episodes                | 3380         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.6         |
| n_updates               | 337801       |
| policy_loss             | 1.0398705    |
| qf1_loss                | 0.004198373  |
| qf2_loss                | 0.004778851  |
| time_elapsed            | 1625         |
| total timesteps         | 337900       |
| value_loss              | 0.000483882  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017844199  |
| ent_coef_loss           | 2.6193585     |
| entropy                 | 3.1140454     |
| ep_rewmean              | -2.6          |
| episodes                | 3384          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 338201        |
| policy_loss             | 1.0627481     |
| qf1_loss                | 0.005273151   |
| qf2_loss                | 0.0055271     |
| time_elapsed            | 1627          |
| total timesteps         | 338300        |
| value_loss              | 0.00056257844 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019013818  |
| ent_coef_loss           | -2.3219633    |
| entropy                 | 3.4006233     |
| ep_rewmean              | -2.63         |
| episodes                | 3388          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 338601        |
| policy_loss             | 1.0711036     |
| qf1_loss                | 0.0006279878  |
| qf2_loss                | 0.00040833664 |
| time_elapsed            | 1629          |
| total timesteps         | 338700        |
| value_loss              | 0.00088362873 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020200564  |
| ent_coef_loss           | 4.4134245     |
| entropy                 | 3.535283      |
| ep_rewmean              | -2.67         |
| episodes                | 3392          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.7          |
| n_updates               | 339001        |
| policy_loss             | 1.0294044     |
| qf1_loss                | 0.00044272363 |
| qf2_loss                | 0.00045080727 |
| time_elapsed            | 1631          |
| total timesteps         | 339100        |
| value_loss              | 0.00036035234 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022077407  |
| ent_coef_loss           | 5.2864027     |
| entropy                 | 3.7918258     |
| ep_rewmean              | -2.67         |
| episodes                | 3396          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.7          |
| n_updates               | 339401        |
| policy_loss             | 1.0790228     |
| qf1_loss                | 0.0006156746  |
| qf2_loss                | 0.00044709875 |
| time_elapsed            | 1633          |
| total timesteps         | 339500        |
| value_loss              | 0.0005549141  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0023861353  |
| ent_coef_loss           | 8.401167      |
| entropy                 | 3.8043976     |
| ep_rewmean              | -2.68         |
| episodes                | 3400          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.7          |
| n_updates               | 339801        |
| policy_loss             | 1.0931034     |
| qf1_loss                | 0.00073663075 |
| qf2_loss                | 0.000665658   |
| time_elapsed            | 1635          |
| total timesteps         | 339900        |
| value_loss              | 0.0006244115  |
-------------------------------------------
Eval num_timesteps=340000, episode_reward=-2.41 +/- 0.82
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0024990726  |
| ent_coef_loss           | 4.426252      |
| entropy                 | 3.758832      |
| ep_rewmean              | -2.68         |
| episodes                | 3404          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.7          |
| n_updates               | 340201        |
| policy_loss             | 1.1231453     |
| qf1_loss                | 0.01530167    |
| qf2_loss                | 0.0162789     |
| time_elapsed            | 1637          |
| total timesteps         | 340300        |
| value_loss              | 0.00045031155 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0025892018  |
| ent_coef_loss           | 0.36271107    |
| entropy                 | 3.732586      |
| ep_rewmean              | -2.65         |
| episodes                | 3408          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 340601        |
| policy_loss             | 1.1098912     |
| qf1_loss                | 0.017829215   |
| qf2_loss                | 0.017391136   |
| time_elapsed            | 1639          |
| total timesteps         | 340700        |
| value_loss              | 0.00089854386 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0026639935  |
| ent_coef_loss           | -6.9216146    |
| entropy                 | 3.7892869     |
| ep_rewmean              | -2.7          |
| episodes                | 3412          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.7          |
| n_updates               | 341001        |
| policy_loss             | 1.0915728     |
| qf1_loss                | 0.020627724   |
| qf2_loss                | 0.020652046   |
| time_elapsed            | 1641          |
| total timesteps         | 341100        |
| value_loss              | 0.00052483147 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002776084  |
| ent_coef_loss           | 4.625475     |
| entropy                 | 3.804882     |
| ep_rewmean              | -2.7         |
| episodes                | 3416         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.7         |
| n_updates               | 341401       |
| policy_loss             | 1.1611468    |
| qf1_loss                | 0.0007343509 |
| qf2_loss                | 0.0004561518 |
| time_elapsed            | 1643         |
| total timesteps         | 341500       |
| value_loss              | 0.000613584  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0028258243  |
| ent_coef_loss           | 3.6254249     |
| entropy                 | 4.0660515     |
| ep_rewmean              | -2.57         |
| episodes                | 3420          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 341801        |
| policy_loss             | 1.2048981     |
| qf1_loss                | 0.00085102813 |
| qf2_loss                | 0.00096624513 |
| time_elapsed            | 1645          |
| total timesteps         | 341900        |
| value_loss              | 0.0009335096  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0028605566 |
| ent_coef_loss           | 3.5773785    |
| entropy                 | 3.7694235    |
| ep_rewmean              | -2.47        |
| episodes                | 3424         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.5         |
| n_updates               | 342201       |
| policy_loss             | 1.2128707    |
| qf1_loss                | 0.043976244  |
| qf2_loss                | 0.043693602  |
| time_elapsed            | 1647         |
| total timesteps         | 342300       |
| value_loss              | 0.0013367294 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0028459635  |
| ent_coef_loss           | -4.0116434    |
| entropy                 | 3.4643936     |
| ep_rewmean              | -2.39         |
| episodes                | 3428          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 342601        |
| policy_loss             | 1.2041068     |
| qf1_loss                | 0.0010911501  |
| qf2_loss                | 0.0008953427  |
| time_elapsed            | 1649          |
| total timesteps         | 342700        |
| value_loss              | 0.00057397725 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0028462051  |
| ent_coef_loss           | 3.3376508     |
| entropy                 | 3.9338062     |
| ep_rewmean              | -2.31         |
| episodes                | 3432          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 343001        |
| policy_loss             | 1.2305601     |
| qf1_loss                | 0.0005403834  |
| qf2_loss                | 0.00082284195 |
| time_elapsed            | 1651          |
| total timesteps         | 343100        |
| value_loss              | 0.0008448068  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0028208958  |
| ent_coef_loss           | 0.85019374    |
| entropy                 | 3.5223122     |
| ep_rewmean              | -2.18         |
| episodes                | 3436          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 343401        |
| policy_loss             | 1.2665546     |
| qf1_loss                | 0.00052139605 |
| qf2_loss                | 0.000800189   |
| time_elapsed            | 1653          |
| total timesteps         | 343500        |
| value_loss              | 0.00062669866 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0027500878 |
| ent_coef_loss           | -1.131989    |
| entropy                 | 3.5117917    |
| ep_rewmean              | -2.21        |
| episodes                | 3440         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 343801       |
| policy_loss             | 1.2384384    |
| qf1_loss                | 0.0006087895 |
| qf2_loss                | 0.0008362829 |
| time_elapsed            | 1655         |
| total timesteps         | 343900       |
| value_loss              | 0.000643725  |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0027389966 |
| ent_coef_loss           | -1.8337607   |
| entropy                 | 3.7783518    |
| ep_rewmean              | -2.26        |
| episodes                | 3444         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 344201       |
| policy_loss             | 1.3232942    |
| qf1_loss                | 0.0005430182 |
| qf2_loss                | 0.0005122574 |
| time_elapsed            | 1657         |
| total timesteps         | 344300       |
| value_loss              | 0.0012720237 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0027468821 |
| ent_coef_loss           | 1.5867386    |
| entropy                 | 3.3020935    |
| ep_rewmean              | -2.31        |
| episodes                | 3448         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 344601       |
| policy_loss             | 1.2573797    |
| qf1_loss                | 0.025152171  |
| qf2_loss                | 0.024681868  |
| time_elapsed            | 1659         |
| total timesteps         | 344700       |
| value_loss              | 0.001165923  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002629538   |
| ent_coef_loss           | -7.809469     |
| entropy                 | 3.130655      |
| ep_rewmean              | -2.35         |
| episodes                | 3452          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 345001        |
| policy_loss             | 1.3151639     |
| qf1_loss                | 0.0007853699  |
| qf2_loss                | 0.00055365125 |
| time_elapsed            | 1661          |
| total timesteps         | 345100        |
| value_loss              | 0.0009066467  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0026922924 |
| ent_coef_loss           | 2.2080436    |
| entropy                 | 3.0486233    |
| ep_rewmean              | -2.36        |
| episodes                | 3456         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.4         |
| n_updates               | 345401       |
| policy_loss             | 1.3401052    |
| qf1_loss                | 0.0009342865 |
| qf2_loss                | 0.0007363279 |
| time_elapsed            | 1663         |
| total timesteps         | 345500       |
| value_loss              | 0.0011983882 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0026194276  |
| ent_coef_loss           | -3.34531      |
| entropy                 | 2.5506372     |
| ep_rewmean              | -2.38         |
| episodes                | 3460          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 345801        |
| policy_loss             | 1.2860239     |
| qf1_loss                | 0.00090445793 |
| qf2_loss                | 0.00095151947 |
| time_elapsed            | 1665          |
| total timesteps         | 345900        |
| value_loss              | 0.0005410474  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0026120837  |
| ent_coef_loss           | 1.065551      |
| entropy                 | 3.355921      |
| ep_rewmean              | -2.35         |
| episodes                | 3464          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 346201        |
| policy_loss             | 1.2475256     |
| qf1_loss                | 0.009131768   |
| qf2_loss                | 0.009432322   |
| time_elapsed            | 1667          |
| total timesteps         | 346300        |
| value_loss              | 0.00091546145 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0025222185  |
| ent_coef_loss           | 1.0292491     |
| entropy                 | 3.0738845     |
| ep_rewmean              | -2.27         |
| episodes                | 3468          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 346601        |
| policy_loss             | 1.3043873     |
| qf1_loss                | 0.0047313184  |
| qf2_loss                | 0.0043302043  |
| time_elapsed            | 1669          |
| total timesteps         | 346700        |
| value_loss              | 0.00081276376 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0024525598 |
| ent_coef_loss           | -1.5050988   |
| entropy                 | 3.866619     |
| ep_rewmean              | -2.19        |
| episodes                | 3472         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 347001       |
| policy_loss             | 1.2948556    |
| qf1_loss                | 0.0014155502 |
| qf2_loss                | 0.0016006106 |
| time_elapsed            | 1671         |
| total timesteps         | 347100       |
| value_loss              | 0.0010744913 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.002340452  |
| ent_coef_loss           | -6.6316037   |
| entropy                 | 3.3494015    |
| ep_rewmean              | -2.14        |
| episodes                | 3476         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 347401       |
| policy_loss             | 1.340174     |
| qf1_loss                | 0.006666412  |
| qf2_loss                | 0.0065504774 |
| time_elapsed            | 1673         |
| total timesteps         | 347500       |
| value_loss              | 0.0009043637 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022170315  |
| ent_coef_loss           | -0.71002686   |
| entropy                 | 3.0653582     |
| ep_rewmean              | -2.15         |
| episodes                | 3480          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 347801        |
| policy_loss             | 1.3087921     |
| qf1_loss                | 0.00070855394 |
| qf2_loss                | 0.00047437608 |
| time_elapsed            | 1675          |
| total timesteps         | 347900        |
| value_loss              | 0.0007584421  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0021038642  |
| ent_coef_loss           | 0.27502298    |
| entropy                 | 2.9763465     |
| ep_rewmean              | -2.13         |
| episodes                | 3484          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 348201        |
| policy_loss             | 1.2078204     |
| qf1_loss                | 0.0009990328  |
| qf2_loss                | 0.000843097   |
| time_elapsed            | 1677          |
| total timesteps         | 348300        |
| value_loss              | 0.00053190574 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0020415187 |
| ent_coef_loss           | 0.83086324   |
| entropy                 | 3.0421724    |
| ep_rewmean              | -2.14        |
| episodes                | 3488         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 348601       |
| policy_loss             | 1.2735388    |
| qf1_loss                | 0.022402387  |
| qf2_loss                | 0.02333999   |
| time_elapsed            | 1679         |
| total timesteps         | 348700       |
| value_loss              | 0.0007417003 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018658384  |
| ent_coef_loss           | -6.6331935    |
| entropy                 | 3.1734838     |
| ep_rewmean              | -2.12         |
| episodes                | 3492          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 349001        |
| policy_loss             | 1.217099      |
| qf1_loss                | 0.00059023255 |
| qf2_loss                | 0.0005857013  |
| time_elapsed            | 1681          |
| total timesteps         | 349100        |
| value_loss              | 0.0008577498  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017224042  |
| ent_coef_loss           | -1.3427476    |
| entropy                 | 2.6191735     |
| ep_rewmean              | -2.08         |
| episodes                | 3496          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 349401        |
| policy_loss             | 1.2350335     |
| qf1_loss                | 0.00061360595 |
| qf2_loss                | 0.0004773886  |
| time_elapsed            | 1683          |
| total timesteps         | 349500        |
| value_loss              | 0.00051047246 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016379888  |
| ent_coef_loss           | -0.9369416    |
| entropy                 | 2.4218538     |
| ep_rewmean              | -2.07         |
| episodes                | 3500          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 349801        |
| policy_loss             | 1.2063849     |
| qf1_loss                | 0.0071653505  |
| qf2_loss                | 0.0070293257  |
| time_elapsed            | 1685          |
| total timesteps         | 349900        |
| value_loss              | 0.00060558756 |
-------------------------------------------
Eval num_timesteps=350000, episode_reward=-2.42 +/- 0.85
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016967142  |
| ent_coef_loss           | 10.220923     |
| entropy                 | 2.0804033     |
| ep_rewmean              | -2.04         |
| episodes                | 3504          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 350201        |
| policy_loss             | 1.1228046     |
| qf1_loss                | 0.00088786543 |
| qf2_loss                | 0.0010539046  |
| time_elapsed            | 1687          |
| total timesteps         | 350300        |
| value_loss              | 0.00076970353 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017703823 |
| ent_coef_loss           | 0.9578454    |
| entropy                 | 2.296865     |
| ep_rewmean              | -2.01        |
| episodes                | 3508         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 350601       |
| policy_loss             | 1.1267009    |
| qf1_loss                | 0.0018066905 |
| qf2_loss                | 0.002186669  |
| time_elapsed            | 1689         |
| total timesteps         | 350700       |
| value_loss              | 0.0005572147 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0018188728 |
| ent_coef_loss           | 1.0747321    |
| entropy                 | 2.1023512    |
| ep_rewmean              | -1.91        |
| episodes                | 3512         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 351001       |
| policy_loss             | 1.0923178    |
| qf1_loss                | 0.0008117625 |
| qf2_loss                | 0.0008004183 |
| time_elapsed            | 1691         |
| total timesteps         | 351100       |
| value_loss              | 0.0012453602 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0018572257 |
| ent_coef_loss           | -7.0262213   |
| entropy                 | 2.099061     |
| ep_rewmean              | -1.91        |
| episodes                | 3516         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 351401       |
| policy_loss             | 1.104554     |
| qf1_loss                | 0.0024003023 |
| qf2_loss                | 0.0023460577 |
| time_elapsed            | 1693         |
| total timesteps         | 351500       |
| value_loss              | 0.0004225421 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0018005982 |
| ent_coef_loss           | 0.6490985    |
| entropy                 | 2.613153     |
| ep_rewmean              | -1.9         |
| episodes                | 3520         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 351801       |
| policy_loss             | 0.9702952    |
| qf1_loss                | 0.0008261582 |
| qf2_loss                | 0.0006543101 |
| time_elapsed            | 1695         |
| total timesteps         | 351900       |
| value_loss              | 0.0004464014 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017345231 |
| ent_coef_loss           | -2.3139296   |
| entropy                 | 2.5526567    |
| ep_rewmean              | -1.92        |
| episodes                | 3524         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 352201       |
| policy_loss             | 1.0558481    |
| qf1_loss                | 0.0007961206 |
| qf2_loss                | 0.0006163416 |
| time_elapsed            | 1697         |
| total timesteps         | 352300       |
| value_loss              | 0.0009303389 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017082744  |
| ent_coef_loss           | -2.2314968    |
| entropy                 | 2.3104577     |
| ep_rewmean              | -1.89         |
| episodes                | 3528          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 352601        |
| policy_loss             | 0.98799       |
| qf1_loss                | 0.00035340973 |
| qf2_loss                | 0.0005474768  |
| time_elapsed            | 1699          |
| total timesteps         | 352700        |
| value_loss              | 0.0003953842  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017903236  |
| ent_coef_loss           | -2.6801834    |
| entropy                 | 2.1392794     |
| ep_rewmean              | -1.88         |
| episodes                | 3532          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 353001        |
| policy_loss             | 0.96256864    |
| qf1_loss                | 0.0019932997  |
| qf2_loss                | 0.0018425141  |
| time_elapsed            | 1700          |
| total timesteps         | 353100        |
| value_loss              | 0.00082805415 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0019899183 |
| ent_coef_loss           | 2.7740967    |
| entropy                 | 2.276517     |
| ep_rewmean              | -1.88        |
| episodes                | 3536         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 353401       |
| policy_loss             | 0.9947057    |
| qf1_loss                | 0.0034042548 |
| qf2_loss                | 0.0031796335 |
| time_elapsed            | 1702         |
| total timesteps         | 353500       |
| value_loss              | 0.0004321644 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0020845556 |
| ent_coef_loss           | 0.16749167   |
| entropy                 | 2.6702743    |
| ep_rewmean              | -1.91        |
| episodes                | 3540         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 353801       |
| policy_loss             | 1.0033469    |
| qf1_loss                | 0.016331032  |
| qf2_loss                | 0.017526656  |
| time_elapsed            | 1704         |
| total timesteps         | 353900       |
| value_loss              | 0.0006561925 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0022660557  |
| ent_coef_loss           | 0.26800466    |
| entropy                 | 2.943279      |
| ep_rewmean              | -1.88         |
| episodes                | 3544          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 354201        |
| policy_loss             | 0.93163145    |
| qf1_loss                | 0.00028120365 |
| qf2_loss                | 0.00035620722 |
| time_elapsed            | 1706          |
| total timesteps         | 354300        |
| value_loss              | 0.0007351966  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0023243767  |
| ent_coef_loss           | -4.98073      |
| entropy                 | 3.0411654     |
| ep_rewmean              | -1.76         |
| episodes                | 3548          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 354601        |
| policy_loss             | 0.9134022     |
| qf1_loss                | 0.00071987935 |
| qf2_loss                | 0.000522809   |
| time_elapsed            | 1708          |
| total timesteps         | 354700        |
| value_loss              | 0.0006210171  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002185929   |
| ent_coef_loss           | -6.433282     |
| entropy                 | 3.1841016     |
| ep_rewmean              | -1.71         |
| episodes                | 3552          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 355001        |
| policy_loss             | 0.99223596    |
| qf1_loss                | 0.0005029936  |
| qf2_loss                | 0.000417537   |
| time_elapsed            | 1710          |
| total timesteps         | 355100        |
| value_loss              | 0.00045561552 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0022226512 |
| ent_coef_loss           | 2.782634     |
| entropy                 | 3.0643563    |
| ep_rewmean              | -1.71        |
| episodes                | 3556         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 355401       |
| policy_loss             | 0.93966067   |
| qf1_loss                | 0.01618808   |
| qf2_loss                | 0.016844744  |
| time_elapsed            | 1712         |
| total timesteps         | 355500       |
| value_loss              | 0.0004980731 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0023602508 |
| ent_coef_loss           | 2.4858851    |
| entropy                 | 3.1765099    |
| ep_rewmean              | -1.69        |
| episodes                | 3560         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 355801       |
| policy_loss             | 0.9319685    |
| qf1_loss                | 0.012721302  |
| qf2_loss                | 0.012505577  |
| time_elapsed            | 1714         |
| total timesteps         | 355900       |
| value_loss              | 0.0003385614 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002388125   |
| ent_coef_loss           | 1.7948833     |
| entropy                 | 3.483774      |
| ep_rewmean              | -1.68         |
| episodes                | 3564          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 356201        |
| policy_loss             | 1.0161438     |
| qf1_loss                | 0.00036804134 |
| qf2_loss                | 0.00044383615 |
| time_elapsed            | 1716          |
| total timesteps         | 356300        |
| value_loss              | 0.0004420819  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0025925448 |
| ent_coef_loss           | -2.156312    |
| entropy                 | 3.6243973    |
| ep_rewmean              | -1.69        |
| episodes                | 3568         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 356601       |
| policy_loss             | 0.9293481    |
| qf1_loss                | 0.0005805997 |
| qf2_loss                | 0.0005784295 |
| time_elapsed            | 1718         |
| total timesteps         | 356700       |
| value_loss              | 0.0004652214 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0026703232  |
| ent_coef_loss           | -1.6767514    |
| entropy                 | 3.8802128     |
| ep_rewmean              | -1.72         |
| episodes                | 3572          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 357001        |
| policy_loss             | 0.92163706    |
| qf1_loss                | 0.000681689   |
| qf2_loss                | 0.00042480737 |
| time_elapsed            | 1720          |
| total timesteps         | 357100        |
| value_loss              | 0.00035904138 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0025942193  |
| ent_coef_loss           | 0.16315901    |
| entropy                 | 3.534347      |
| ep_rewmean              | -1.72         |
| episodes                | 3576          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 357401        |
| policy_loss             | 0.9875273     |
| qf1_loss                | 0.0008757917  |
| qf2_loss                | 0.0008364967  |
| time_elapsed            | 1722          |
| total timesteps         | 357500        |
| value_loss              | 0.00035746698 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0023424728  |
| ent_coef_loss           | 2.7535722     |
| entropy                 | 3.4048572     |
| ep_rewmean              | -1.73         |
| episodes                | 3580          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 357801        |
| policy_loss             | 0.9276769     |
| qf1_loss                | 0.00061781134 |
| qf2_loss                | 0.0006215826  |
| time_elapsed            | 1724          |
| total timesteps         | 357900        |
| value_loss              | 0.0004556987  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00217984    |
| ent_coef_loss           | -3.36337      |
| entropy                 | 3.0350032     |
| ep_rewmean              | -1.72         |
| episodes                | 3584          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 358201        |
| policy_loss             | 0.90636206    |
| qf1_loss                | 0.0021804716  |
| qf2_loss                | 0.0027826393  |
| time_elapsed            | 1726          |
| total timesteps         | 358300        |
| value_loss              | 0.00044769573 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.002082205   |
| ent_coef_loss           | -4.9176927    |
| entropy                 | 3.2686126     |
| ep_rewmean              | -1.72         |
| episodes                | 3588          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 358601        |
| policy_loss             | 0.980458      |
| qf1_loss                | 0.00036615034 |
| qf2_loss                | 0.0005200958  |
| time_elapsed            | 1728          |
| total timesteps         | 358700        |
| value_loss              | 0.0002368243  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019481571  |
| ent_coef_loss           | -1.1388113    |
| entropy                 | 2.9907928     |
| ep_rewmean              | -1.72         |
| episodes                | 3592          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 359001        |
| policy_loss             | 0.8695922     |
| qf1_loss                | 0.00057939533 |
| qf2_loss                | 0.00036906608 |
| time_elapsed            | 1730          |
| total timesteps         | 359100        |
| value_loss              | 0.0004253846  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0019532219 |
| ent_coef_loss           | 5.0420446    |
| entropy                 | 3.4497638    |
| ep_rewmean              | -1.78        |
| episodes                | 3596         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 359401       |
| policy_loss             | 0.88857496   |
| qf1_loss                | 0.00537383   |
| qf2_loss                | 0.004991789  |
| time_elapsed            | 1731         |
| total timesteps         | 359500       |
| value_loss              | 0.0002400121 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018207835  |
| ent_coef_loss           | 0.35454392    |
| entropy                 | 3.0273337     |
| ep_rewmean              | -1.79         |
| episodes                | 3600          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 359801        |
| policy_loss             | 0.876498      |
| qf1_loss                | 0.00052489614 |
| qf2_loss                | 0.00037514797 |
| time_elapsed            | 1733          |
| total timesteps         | 359900        |
| value_loss              | 0.00034518357 |
-------------------------------------------
Eval num_timesteps=360000, episode_reward=-1.15 +/- 0.90
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017420012  |
| ent_coef_loss           | -2.6710248    |
| entropy                 | 3.0981226     |
| ep_rewmean              | -1.86         |
| episodes                | 3604          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 360201        |
| policy_loss             | 0.9230882     |
| qf1_loss                | 0.00039258378 |
| qf2_loss                | 0.0003573264  |
| time_elapsed            | 1736          |
| total timesteps         | 360300        |
| value_loss              | 0.00030161603 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016489727  |
| ent_coef_loss           | 1.2764592     |
| entropy                 | 2.988755      |
| ep_rewmean              | -1.89         |
| episodes                | 3608          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 360601        |
| policy_loss             | 0.89063805    |
| qf1_loss                | 0.0003840337  |
| qf2_loss                | 0.00031614734 |
| time_elapsed            | 1738          |
| total timesteps         | 360700        |
| value_loss              | 0.00030976054 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016110647  |
| ent_coef_loss           | -4.7311993    |
| entropy                 | 3.3669543     |
| ep_rewmean              | -1.92         |
| episodes                | 3612          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 361001        |
| policy_loss             | 0.91306514    |
| qf1_loss                | 0.014508871   |
| qf2_loss                | 0.013976235   |
| time_elapsed            | 1739          |
| total timesteps         | 361100        |
| value_loss              | 0.00031750987 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015946697  |
| ent_coef_loss           | 2.6082625     |
| entropy                 | 3.346435      |
| ep_rewmean              | -1.93         |
| episodes                | 3616          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 361401        |
| policy_loss             | 0.89483374    |
| qf1_loss                | 0.00037639376 |
| qf2_loss                | 0.00040385895 |
| time_elapsed            | 1741          |
| total timesteps         | 361500        |
| value_loss              | 0.00029907742 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016291275  |
| ent_coef_loss           | 5.0762696     |
| entropy                 | 3.0422153     |
| ep_rewmean              | -2.01         |
| episodes                | 3620          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 361801        |
| policy_loss             | 0.829165      |
| qf1_loss                | 0.0005203963  |
| qf2_loss                | 0.00049747416 |
| time_elapsed            | 1743          |
| total timesteps         | 361900        |
| value_loss              | 0.00035326259 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016669948  |
| ent_coef_loss           | -3.1545208    |
| entropy                 | 3.5712562     |
| ep_rewmean              | -2            |
| episodes                | 3624          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 362201        |
| policy_loss             | 0.8622001     |
| qf1_loss                | 0.011889598   |
| qf2_loss                | 0.011569711   |
| time_elapsed            | 1745          |
| total timesteps         | 362300        |
| value_loss              | 0.00024734344 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017167899  |
| ent_coef_loss           | -1.175675     |
| entropy                 | 3.6968405     |
| ep_rewmean              | -2.02         |
| episodes                | 3628          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 362601        |
| policy_loss             | 0.86376894    |
| qf1_loss                | 0.000979876   |
| qf2_loss                | 0.0010380243  |
| time_elapsed            | 1747          |
| total timesteps         | 362700        |
| value_loss              | 0.00021976102 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001789582   |
| ent_coef_loss           | 0.2352488     |
| entropy                 | 3.6755276     |
| ep_rewmean              | -2.01         |
| episodes                | 3632          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 363001        |
| policy_loss             | 0.8399255     |
| qf1_loss                | 0.0055357045  |
| qf2_loss                | 0.0068878047  |
| time_elapsed            | 1749          |
| total timesteps         | 363100        |
| value_loss              | 0.00031264324 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019078236  |
| ent_coef_loss           | -0.8685545    |
| entropy                 | 3.8362634     |
| ep_rewmean              | -1.96         |
| episodes                | 3636          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 363401        |
| policy_loss             | 0.8400516     |
| qf1_loss                | 0.0003497824  |
| qf2_loss                | 0.00028307212 |
| time_elapsed            | 1751          |
| total timesteps         | 363500        |
| value_loss              | 0.0004027643  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0020386344 |
| ent_coef_loss           | -2.007926    |
| entropy                 | 4.179278     |
| ep_rewmean              | -1.93        |
| episodes                | 3640         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 363801       |
| policy_loss             | 0.79592407   |
| qf1_loss                | 0.005005762  |
| qf2_loss                | 0.005400051  |
| time_elapsed            | 1753         |
| total timesteps         | 363900       |
| value_loss              | 0.0002876965 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020927512  |
| ent_coef_loss           | -7.369142     |
| entropy                 | 4.1439486     |
| ep_rewmean              | -1.91         |
| episodes                | 3644          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 364201        |
| policy_loss             | 0.81502616    |
| qf1_loss                | 0.0003561254  |
| qf2_loss                | 0.00037944622 |
| time_elapsed            | 1755          |
| total timesteps         | 364300        |
| value_loss              | 0.00033290667 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0020677743  |
| ent_coef_loss           | -1.96802      |
| entropy                 | 4.1865773     |
| ep_rewmean              | -1.93         |
| episodes                | 3648          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 364601        |
| policy_loss             | 0.8557857     |
| qf1_loss                | 0.008970703   |
| qf2_loss                | 0.008873013   |
| time_elapsed            | 1757          |
| total timesteps         | 364700        |
| value_loss              | 0.00038151816 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0020287838 |
| ent_coef_loss           | -3.4723094   |
| entropy                 | 4.2389803    |
| ep_rewmean              | -1.95        |
| episodes                | 3652         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 365001       |
| policy_loss             | 0.8471318    |
| qf1_loss                | 0.0013677456 |
| qf2_loss                | 0.0013017231 |
| time_elapsed            | 1759         |
| total timesteps         | 365100       |
| value_loss              | 0.0002697375 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0019352651  |
| ent_coef_loss           | -5.4181085    |
| entropy                 | 3.3217342     |
| ep_rewmean              | -1.93         |
| episodes                | 3656          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 365401        |
| policy_loss             | 0.7972136     |
| qf1_loss                | 0.007833368   |
| qf2_loss                | 0.0074313236  |
| time_elapsed            | 1761          |
| total timesteps         | 365500        |
| value_loss              | 0.00024625618 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018573718  |
| ent_coef_loss           | 0.2662238     |
| entropy                 | 3.8098204     |
| ep_rewmean              | -1.95         |
| episodes                | 3660          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 365801        |
| policy_loss             | 0.8235606     |
| qf1_loss                | 0.00032106094 |
| qf2_loss                | 0.0003229722  |
| time_elapsed            | 1763          |
| total timesteps         | 365900        |
| value_loss              | 0.00023518334 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001826697  |
| ent_coef_loss           | -4.397302    |
| entropy                 | 4.003648     |
| ep_rewmean              | -1.94        |
| episodes                | 3664         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 366201       |
| policy_loss             | 0.7996852    |
| qf1_loss                | 0.009420499  |
| qf2_loss                | 0.009584952  |
| time_elapsed            | 1765         |
| total timesteps         | 366300       |
| value_loss              | 0.0003796097 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017698336  |
| ent_coef_loss           | -5.0736523    |
| entropy                 | 3.6484694     |
| ep_rewmean              | -1.97         |
| episodes                | 3668          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 366601        |
| policy_loss             | 0.8382839     |
| qf1_loss                | 0.0054705604  |
| qf2_loss                | 0.005505297   |
| time_elapsed            | 1766          |
| total timesteps         | 366700        |
| value_loss              | 0.00025549546 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017075292  |
| ent_coef_loss           | -7.5409317    |
| entropy                 | 3.6507392     |
| ep_rewmean              | -1.96         |
| episodes                | 3672          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 367001        |
| policy_loss             | 0.79117495    |
| qf1_loss                | 0.0003619329  |
| qf2_loss                | 0.00039596212 |
| time_elapsed            | 1768          |
| total timesteps         | 367100        |
| value_loss              | 0.0002165754  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016844562  |
| ent_coef_loss           | 0.5479593     |
| entropy                 | 3.66567       |
| ep_rewmean              | -2.1          |
| episodes                | 3676          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 367401        |
| policy_loss             | 0.7624677     |
| qf1_loss                | 0.00040773433 |
| qf2_loss                | 0.00042295764 |
| time_elapsed            | 1770          |
| total timesteps         | 367500        |
| value_loss              | 0.00036282005 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016696033  |
| ent_coef_loss           | -2.9037974    |
| entropy                 | 3.653543      |
| ep_rewmean              | -2.13         |
| episodes                | 3680          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 367801        |
| policy_loss             | 0.75669944    |
| qf1_loss                | 0.0016498521  |
| qf2_loss                | 0.00142311    |
| time_elapsed            | 1772          |
| total timesteps         | 367900        |
| value_loss              | 0.00023780199 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015545682  |
| ent_coef_loss           | 0.5318153     |
| entropy                 | 3.887686      |
| ep_rewmean              | -2.19         |
| episodes                | 3684          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 368201        |
| policy_loss             | 0.7846296     |
| qf1_loss                | 0.008252378   |
| qf2_loss                | 0.007770695   |
| time_elapsed            | 1774          |
| total timesteps         | 368300        |
| value_loss              | 0.00026745407 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014325478 |
| ent_coef_loss           | -5.1819744   |
| entropy                 | 3.5848737    |
| ep_rewmean              | -2.24        |
| episodes                | 3688         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 368601       |
| policy_loss             | 0.7893766    |
| qf1_loss                | 0.0014219554 |
| qf2_loss                | 0.0013359616 |
| time_elapsed            | 1776         |
| total timesteps         | 368700       |
| value_loss              | 0.000322036  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014557935  |
| ent_coef_loss           | 0.80956596    |
| entropy                 | 4.064637      |
| ep_rewmean              | -2.23         |
| episodes                | 3692          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 369001        |
| policy_loss             | 0.79822695    |
| qf1_loss                | 0.00382479    |
| qf2_loss                | 0.003922777   |
| time_elapsed            | 1778          |
| total timesteps         | 369100        |
| value_loss              | 0.00032381172 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014593061  |
| ent_coef_loss           | -5.8242803    |
| entropy                 | 3.5058804     |
| ep_rewmean              | -2.23         |
| episodes                | 3696          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 369401        |
| policy_loss             | 0.78893185    |
| qf1_loss                | 0.0003933498  |
| qf2_loss                | 0.00046874734 |
| time_elapsed            | 1780          |
| total timesteps         | 369500        |
| value_loss              | 0.00027018966 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014942596 |
| ent_coef_loss           | -3.4351907   |
| entropy                 | 4.145974     |
| ep_rewmean              | -2.27        |
| episodes                | 3700         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 369801       |
| policy_loss             | 0.8035262    |
| qf1_loss                | 0.0019500343 |
| qf2_loss                | 0.0020409294 |
| time_elapsed            | 1782         |
| total timesteps         | 369900       |
| value_loss              | 0.0003004094 |
------------------------------------------
Eval num_timesteps=370000, episode_reward=-1.20 +/- 1.12
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014778096  |
| ent_coef_loss           | 2.2459497     |
| entropy                 | 3.7210772     |
| ep_rewmean              | -2.23         |
| episodes                | 3704          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 370201        |
| policy_loss             | 0.7873093     |
| qf1_loss                | 0.0029980657  |
| qf2_loss                | 0.002652851   |
| time_elapsed            | 1784          |
| total timesteps         | 370300        |
| value_loss              | 0.00025545736 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014282883  |
| ent_coef_loss           | -11.29706     |
| entropy                 | 3.2217803     |
| ep_rewmean              | -2.18         |
| episodes                | 3708          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 370601        |
| policy_loss             | 0.84694993    |
| qf1_loss                | 0.00031585613 |
| qf2_loss                | 0.00026946457 |
| time_elapsed            | 1786          |
| total timesteps         | 370700        |
| value_loss              | 0.00022883309 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013146324  |
| ent_coef_loss           | -2.882298     |
| entropy                 | 3.1926565     |
| ep_rewmean              | -2.19         |
| episodes                | 3712          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 371001        |
| policy_loss             | 0.8925129     |
| qf1_loss                | 0.00065649184 |
| qf2_loss                | 0.00048133754 |
| time_elapsed            | 1788          |
| total timesteps         | 371100        |
| value_loss              | 0.00043439335 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012971659  |
| ent_coef_loss           | -2.2114596    |
| entropy                 | 3.0027385     |
| ep_rewmean              | -2.18         |
| episodes                | 3716          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 371401        |
| policy_loss             | 0.9045063     |
| qf1_loss                | 0.0003213716  |
| qf2_loss                | 0.0001794417  |
| time_elapsed            | 1790          |
| total timesteps         | 371500        |
| value_loss              | 0.00021300494 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013470927 |
| ent_coef_loss           | 0.3177464    |
| entropy                 | 3.4877236    |
| ep_rewmean              | -2.11        |
| episodes                | 3720         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 371801       |
| policy_loss             | 0.82914925   |
| qf1_loss                | 0.003941141  |
| qf2_loss                | 0.0039821137 |
| time_elapsed            | 1792         |
| total timesteps         | 371900       |
| value_loss              | 0.0002193425 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013684845  |
| ent_coef_loss           | -0.16077614   |
| entropy                 | 3.4896111     |
| ep_rewmean              | -2.09         |
| episodes                | 3724          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 372201        |
| policy_loss             | 0.8498276     |
| qf1_loss                | 0.00053116615 |
| qf2_loss                | 0.00062589266 |
| time_elapsed            | 1794          |
| total timesteps         | 372300        |
| value_loss              | 0.00030501373 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001467152   |
| ent_coef_loss           | 2.1249535     |
| entropy                 | 3.8705034     |
| ep_rewmean              | -2.05         |
| episodes                | 3728          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 372601        |
| policy_loss             | 0.8891705     |
| qf1_loss                | 0.00032340206 |
| qf2_loss                | 0.00029752144 |
| time_elapsed            | 1796          |
| total timesteps         | 372700        |
| value_loss              | 0.0002322284  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014694779  |
| ent_coef_loss           | 3.9659665     |
| entropy                 | 3.11476       |
| ep_rewmean              | -2.04         |
| episodes                | 3732          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 373001        |
| policy_loss             | 0.9049429     |
| qf1_loss                | 0.00039092422 |
| qf2_loss                | 0.0004902397  |
| time_elapsed            | 1797          |
| total timesteps         | 373100        |
| value_loss              | 0.00021113726 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015079114  |
| ent_coef_loss           | -0.3322211    |
| entropy                 | 3.1492605     |
| ep_rewmean              | -2.07         |
| episodes                | 3736          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 373401        |
| policy_loss             | 0.83257574    |
| qf1_loss                | 0.015145358   |
| qf2_loss                | 0.01532318    |
| time_elapsed            | 1799          |
| total timesteps         | 373500        |
| value_loss              | 0.00053643493 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015450534  |
| ent_coef_loss           | 1.7173293     |
| entropy                 | 3.7664733     |
| ep_rewmean              | -2.06         |
| episodes                | 3740          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 373801        |
| policy_loss             | 0.88713896    |
| qf1_loss                | 0.00401924    |
| qf2_loss                | 0.004286478   |
| time_elapsed            | 1801          |
| total timesteps         | 373900        |
| value_loss              | 0.00029473793 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015403397  |
| ent_coef_loss           | 2.3401313     |
| entropy                 | 3.7280278     |
| ep_rewmean              | -2.07         |
| episodes                | 3744          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 374201        |
| policy_loss             | 0.8396236     |
| qf1_loss                | 0.0004904334  |
| qf2_loss                | 0.000292602   |
| time_elapsed            | 1803          |
| total timesteps         | 374300        |
| value_loss              | 0.00025834626 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001502519   |
| ent_coef_loss           | 0.58831024    |
| entropy                 | 3.109414      |
| ep_rewmean              | -2.05         |
| episodes                | 3748          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 374601        |
| policy_loss             | 0.8913702     |
| qf1_loss                | 0.00030764175 |
| qf2_loss                | 0.00029495909 |
| time_elapsed            | 1805          |
| total timesteps         | 374700        |
| value_loss              | 0.00035505678 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014558872  |
| ent_coef_loss           | -2.790321     |
| entropy                 | 3.6047604     |
| ep_rewmean              | -2.06         |
| episodes                | 3752          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 375001        |
| policy_loss             | 0.84281796    |
| qf1_loss                | 0.0044803484  |
| qf2_loss                | 0.004485434   |
| time_elapsed            | 1807          |
| total timesteps         | 375100        |
| value_loss              | 0.00024242236 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014467019  |
| ent_coef_loss           | -4.3588314    |
| entropy                 | 2.9364836     |
| ep_rewmean              | -2.08         |
| episodes                | 3756          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 375401        |
| policy_loss             | 0.77612704    |
| qf1_loss                | 0.0008492478  |
| qf2_loss                | 0.0007018008  |
| time_elapsed            | 1809          |
| total timesteps         | 375500        |
| value_loss              | 0.00015955421 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014136967  |
| ent_coef_loss           | -3.3761487    |
| entropy                 | 3.0916977     |
| ep_rewmean              | -2.07         |
| episodes                | 3760          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 375801        |
| policy_loss             | 0.84087265    |
| qf1_loss                | 0.0056770546  |
| qf2_loss                | 0.005422361   |
| time_elapsed            | 1811          |
| total timesteps         | 375900        |
| value_loss              | 0.00014535282 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014407726  |
| ent_coef_loss           | -2.4030213    |
| entropy                 | 3.299087      |
| ep_rewmean              | -2.08         |
| episodes                | 3764          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 376201        |
| policy_loss             | 0.799256      |
| qf1_loss                | 0.0002022858  |
| qf2_loss                | 0.00018719336 |
| time_elapsed            | 1813          |
| total timesteps         | 376300        |
| value_loss              | 0.00022102107 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001467392   |
| ent_coef_loss           | -6.4037447    |
| entropy                 | 3.2993803     |
| ep_rewmean              | -2.06         |
| episodes                | 3768          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 376601        |
| policy_loss             | 0.82467186    |
| qf1_loss                | 0.0003384888  |
| qf2_loss                | 0.0003593514  |
| time_elapsed            | 1815          |
| total timesteps         | 376700        |
| value_loss              | 0.00019648412 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014569602  |
| ent_coef_loss           | -0.5227668    |
| entropy                 | 3.011979      |
| ep_rewmean              | -2.07         |
| episodes                | 3772          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 377001        |
| policy_loss             | 0.772985      |
| qf1_loss                | 0.00087862415 |
| qf2_loss                | 0.0011667546  |
| time_elapsed            | 1817          |
| total timesteps         | 377100        |
| value_loss              | 0.00020686336 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014029908  |
| ent_coef_loss           | -5.2921705    |
| entropy                 | 2.9910438     |
| ep_rewmean              | -1.92         |
| episodes                | 3776          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 377401        |
| policy_loss             | 0.77715045    |
| qf1_loss                | 0.0006105124  |
| qf2_loss                | 0.0004478356  |
| time_elapsed            | 1819          |
| total timesteps         | 377500        |
| value_loss              | 0.00028491075 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013343432 |
| ent_coef_loss           | -2.999683    |
| entropy                 | 2.9793553    |
| ep_rewmean              | -1.88        |
| episodes                | 3780         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 377801       |
| policy_loss             | 0.7956069    |
| qf1_loss                | 0.004089397  |
| qf2_loss                | 0.0046603763 |
| time_elapsed            | 1820         |
| total timesteps         | 377900       |
| value_loss              | 0.0004442577 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012761226  |
| ent_coef_loss           | 2.197922      |
| entropy                 | 2.5996642     |
| ep_rewmean              | -1.82         |
| episodes                | 3784          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 378201        |
| policy_loss             | 0.77195275    |
| qf1_loss                | 0.00039989644 |
| qf2_loss                | 0.0004388635  |
| time_elapsed            | 1822          |
| total timesteps         | 378300        |
| value_loss              | 0.0003361047  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012758854 |
| ent_coef_loss           | 0.40433478   |
| entropy                 | 3.2463493    |
| ep_rewmean              | -1.77        |
| episodes                | 3788         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 378601       |
| policy_loss             | 0.78972733   |
| qf1_loss                | 0.008532419  |
| qf2_loss                | 0.00855872   |
| time_elapsed            | 1824         |
| total timesteps         | 378700       |
| value_loss              | 0.0003901429 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012243675  |
| ent_coef_loss           | -3.1842163    |
| entropy                 | 2.6045961     |
| ep_rewmean              | -1.74         |
| episodes                | 3792          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 379001        |
| policy_loss             | 0.78807557    |
| qf1_loss                | 0.011284975   |
| qf2_loss                | 0.011857284   |
| time_elapsed            | 1826          |
| total timesteps         | 379100        |
| value_loss              | 0.00026231213 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001217784   |
| ent_coef_loss           | -1.2277623    |
| entropy                 | 3.020286      |
| ep_rewmean              | -1.69         |
| episodes                | 3796          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 379401        |
| policy_loss             | 0.758017      |
| qf1_loss                | 0.00046177453 |
| qf2_loss                | 0.00043720618 |
| time_elapsed            | 1828          |
| total timesteps         | 379500        |
| value_loss              | 0.0003949938  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001190926   |
| ent_coef_loss           | 7.7262664     |
| entropy                 | 2.7855277     |
| ep_rewmean              | -1.64         |
| episodes                | 3800          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 379801        |
| policy_loss             | 0.8068788     |
| qf1_loss                | 0.00039582571 |
| qf2_loss                | 0.00037318293 |
| time_elapsed            | 1830          |
| total timesteps         | 379900        |
| value_loss              | 0.00020500248 |
-------------------------------------------
Eval num_timesteps=380000, episode_reward=-1.43 +/- 0.89
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001202198   |
| ent_coef_loss           | -4.454489     |
| entropy                 | 2.9828258     |
| ep_rewmean              | -1.65         |
| episodes                | 3804          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 380201        |
| policy_loss             | 0.8148214     |
| qf1_loss                | 0.007107783   |
| qf2_loss                | 0.006908542   |
| time_elapsed            | 1832          |
| total timesteps         | 380300        |
| value_loss              | 0.00036872734 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012185664  |
| ent_coef_loss           | 1.1248451     |
| entropy                 | 3.4017296     |
| ep_rewmean              | -1.65         |
| episodes                | 3808          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 380601        |
| policy_loss             | 0.86318135    |
| qf1_loss                | 0.00754571    |
| qf2_loss                | 0.007442251   |
| time_elapsed            | 1834          |
| total timesteps         | 380700        |
| value_loss              | 0.00027760124 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012280243  |
| ent_coef_loss           | -4.483544     |
| entropy                 | 3.1200545     |
| ep_rewmean              | -1.65         |
| episodes                | 3812          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 381001        |
| policy_loss             | 0.7366083     |
| qf1_loss                | 0.00075823    |
| qf2_loss                | 0.00068969536 |
| time_elapsed            | 1836          |
| total timesteps         | 381100        |
| value_loss              | 0.0002695945  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012392579  |
| ent_coef_loss           | -5.1672406    |
| entropy                 | 3.053337      |
| ep_rewmean              | -1.65         |
| episodes                | 3816          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 381401        |
| policy_loss             | 0.82353675    |
| qf1_loss                | 0.00028432911 |
| qf2_loss                | 0.00033178114 |
| time_elapsed            | 1838          |
| total timesteps         | 381500        |
| value_loss              | 0.00025852924 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012189023  |
| ent_coef_loss           | 9.8187685     |
| entropy                 | 3.2354743     |
| ep_rewmean              | -1.65         |
| episodes                | 3820          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 381801        |
| policy_loss             | 0.8054221     |
| qf1_loss                | 0.00062955264 |
| qf2_loss                | 0.0005825352  |
| time_elapsed            | 1840          |
| total timesteps         | 381900        |
| value_loss              | 0.000605441   |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013179916 |
| ent_coef_loss           | 2.2650886    |
| entropy                 | 3.4680457    |
| ep_rewmean              | -1.67        |
| episodes                | 3824         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 382201       |
| policy_loss             | 0.8318684    |
| qf1_loss                | 0.0052633346 |
| qf2_loss                | 0.0052002    |
| time_elapsed            | 1842         |
| total timesteps         | 382300       |
| value_loss              | 0.0003308562 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014614774 |
| ent_coef_loss           | -0.45004416  |
| entropy                 | 3.1221662    |
| ep_rewmean              | -1.68        |
| episodes                | 3828         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 382601       |
| policy_loss             | 0.798453     |
| qf1_loss                | 0.0005303292 |
| qf2_loss                | 0.0005027759 |
| time_elapsed            | 1844         |
| total timesteps         | 382700       |
| value_loss              | 0.0004204042 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014437737  |
| ent_coef_loss           | 3.3995314     |
| entropy                 | 3.226807      |
| ep_rewmean              | -1.7          |
| episodes                | 3832          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 383001        |
| policy_loss             | 0.8060918     |
| qf1_loss                | 0.00035853568 |
| qf2_loss                | 0.00028402772 |
| time_elapsed            | 1846          |
| total timesteps         | 383100        |
| value_loss              | 0.0002109572  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015258265  |
| ent_coef_loss           | -0.01705134   |
| entropy                 | 2.9964592     |
| ep_rewmean              | -1.7          |
| episodes                | 3836          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 383401        |
| policy_loss             | 0.8449342     |
| qf1_loss                | 0.0066581354  |
| qf2_loss                | 0.0065207356  |
| time_elapsed            | 1848          |
| total timesteps         | 383500        |
| value_loss              | 0.00038869772 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014804404  |
| ent_coef_loss           | 0.0097619295  |
| entropy                 | 2.867854      |
| ep_rewmean              | -1.71         |
| episodes                | 3840          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 383801        |
| policy_loss             | 0.844496      |
| qf1_loss                | 0.00025415717 |
| qf2_loss                | 0.00024378666 |
| time_elapsed            | 1850          |
| total timesteps         | 383900        |
| value_loss              | 0.00021457695 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0014215087 |
| ent_coef_loss           | 2.6143422    |
| entropy                 | 2.6849856    |
| ep_rewmean              | -1.73        |
| episodes                | 3844         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 384201       |
| policy_loss             | 0.75699806   |
| qf1_loss                | 0.0036334477 |
| qf2_loss                | 0.003825164  |
| time_elapsed            | 1852         |
| total timesteps         | 384300       |
| value_loss              | 0.0004765205 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013748413 |
| ent_coef_loss           | -4.727538    |
| entropy                 | 3.0078132    |
| ep_rewmean              | -1.73        |
| episodes                | 3848         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 384601       |
| policy_loss             | 0.81765693   |
| qf1_loss                | 0.011318718  |
| qf2_loss                | 0.011172494  |
| time_elapsed            | 1853         |
| total timesteps         | 384700       |
| value_loss              | 0.0002312233 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012917871  |
| ent_coef_loss           | 0.65692693    |
| entropy                 | 2.6625485     |
| ep_rewmean              | -1.75         |
| episodes                | 3852          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 385001        |
| policy_loss             | 0.78684556    |
| qf1_loss                | 0.009397475   |
| qf2_loss                | 0.010306793   |
| time_elapsed            | 1855          |
| total timesteps         | 385100        |
| value_loss              | 0.00025773907 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012743999  |
| ent_coef_loss           | 0.48224556    |
| entropy                 | 2.555579      |
| ep_rewmean              | -1.72         |
| episodes                | 3856          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 385401        |
| policy_loss             | 0.7802578     |
| qf1_loss                | 0.00052991544 |
| qf2_loss                | 0.00037917198 |
| time_elapsed            | 1857          |
| total timesteps         | 385500        |
| value_loss              | 0.00022100515 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013364904  |
| ent_coef_loss           | -6.8029804    |
| entropy                 | 2.8405461     |
| ep_rewmean              | -1.79         |
| episodes                | 3860          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 385801        |
| policy_loss             | 0.8259216     |
| qf1_loss                | 0.0002645132  |
| qf2_loss                | 0.00030021218 |
| time_elapsed            | 1859          |
| total timesteps         | 385900        |
| value_loss              | 0.00018644895 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013105122  |
| ent_coef_loss           | -4.310405     |
| entropy                 | 2.6451855     |
| ep_rewmean              | -1.89         |
| episodes                | 3864          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 386201        |
| policy_loss             | 0.81880593    |
| qf1_loss                | 0.0003597142  |
| qf2_loss                | 0.00030664794 |
| time_elapsed            | 1861          |
| total timesteps         | 386300        |
| value_loss              | 0.0001906539  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013445386  |
| ent_coef_loss           | 8.846523      |
| entropy                 | 3.1218958     |
| ep_rewmean              | -1.95         |
| episodes                | 3868          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 386601        |
| policy_loss             | 0.842408      |
| qf1_loss                | 0.0007737461  |
| qf2_loss                | 0.00068809814 |
| time_elapsed            | 1863          |
| total timesteps         | 386700        |
| value_loss              | 0.00024494663 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013511933  |
| ent_coef_loss           | 5.5671787     |
| entropy                 | 3.0150762     |
| ep_rewmean              | -1.96         |
| episodes                | 3872          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 387001        |
| policy_loss             | 0.8235632     |
| qf1_loss                | 0.00023459311 |
| qf2_loss                | 0.00022407179 |
| time_elapsed            | 1865          |
| total timesteps         | 387100        |
| value_loss              | 0.0002002345  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013902716  |
| ent_coef_loss           | 4.2013206     |
| entropy                 | 3.0401852     |
| ep_rewmean              | -2.01         |
| episodes                | 3876          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 387401        |
| policy_loss             | 0.823985      |
| qf1_loss                | 0.0047237608  |
| qf2_loss                | 0.0046391133  |
| time_elapsed            | 1867          |
| total timesteps         | 387500        |
| value_loss              | 0.00051080255 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013653246  |
| ent_coef_loss           | -4.3601255    |
| entropy                 | 2.830123      |
| ep_rewmean              | -2.04         |
| episodes                | 3880          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 387801        |
| policy_loss             | 0.79342574    |
| qf1_loss                | 0.00029877026 |
| qf2_loss                | 0.0003754396  |
| time_elapsed            | 1869          |
| total timesteps         | 387900        |
| value_loss              | 0.00046212308 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012991151  |
| ent_coef_loss           | -4.2712216    |
| entropy                 | 2.7686296     |
| ep_rewmean              | -2.11         |
| episodes                | 3884          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 388201        |
| policy_loss             | 0.8130884     |
| qf1_loss                | 0.007134576   |
| qf2_loss                | 0.007778545   |
| time_elapsed            | 1871          |
| total timesteps         | 388300        |
| value_loss              | 0.00041350862 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012822369 |
| ent_coef_loss           | -6.61748     |
| entropy                 | 2.9515624    |
| ep_rewmean              | -2.22        |
| episodes                | 3888         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 388601       |
| policy_loss             | 0.7950828    |
| qf1_loss                | 0.002717107  |
| qf2_loss                | 0.0027266976 |
| time_elapsed            | 1873         |
| total timesteps         | 388700       |
| value_loss              | 0.0002793611 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012216453  |
| ent_coef_loss           | -0.26605463   |
| entropy                 | 2.7524412     |
| ep_rewmean              | -2.28         |
| episodes                | 3892          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 389001        |
| policy_loss             | 0.7827685     |
| qf1_loss                | 0.0003612071  |
| qf2_loss                | 0.00026285596 |
| time_elapsed            | 1875          |
| total timesteps         | 389100        |
| value_loss              | 0.00021908764 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012242047  |
| ent_coef_loss           | 2.9141598     |
| entropy                 | 2.7242937     |
| ep_rewmean              | -2.27         |
| episodes                | 3896          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 389401        |
| policy_loss             | 0.8114617     |
| qf1_loss                | 0.00033016302 |
| qf2_loss                | 0.00023322283 |
| time_elapsed            | 1877          |
| total timesteps         | 389500        |
| value_loss              | 0.00047030495 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012531714  |
| ent_coef_loss           | -7.011814     |
| entropy                 | 2.9000838     |
| ep_rewmean              | -2.31         |
| episodes                | 3900          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 389801        |
| policy_loss             | 0.784912      |
| qf1_loss                | 0.008433011   |
| qf2_loss                | 0.0089148795  |
| time_elapsed            | 1879          |
| total timesteps         | 389900        |
| value_loss              | 0.00022751334 |
-------------------------------------------
Eval num_timesteps=390000, episode_reward=-3.13 +/- 1.53
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013845715  |
| ent_coef_loss           | 1.2208073     |
| entropy                 | 3.1270657     |
| ep_rewmean              | -2.35         |
| episodes                | 3904          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 390201        |
| policy_loss             | 0.766333      |
| qf1_loss                | 0.006166009   |
| qf2_loss                | 0.005751011   |
| time_elapsed            | 1881          |
| total timesteps         | 390300        |
| value_loss              | 0.00020243309 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014428041  |
| ent_coef_loss           | 0.061211348   |
| entropy                 | 2.7687466     |
| ep_rewmean              | -2.39         |
| episodes                | 3908          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 390601        |
| policy_loss             | 0.77021074    |
| qf1_loss                | 0.002800464   |
| qf2_loss                | 0.0028808727  |
| time_elapsed            | 1883          |
| total timesteps         | 390700        |
| value_loss              | 0.00020013642 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001510451   |
| ent_coef_loss           | 5.0523334     |
| entropy                 | 2.9568877     |
| ep_rewmean              | -2.44         |
| episodes                | 3912          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 391001        |
| policy_loss             | 0.7266122     |
| qf1_loss                | 0.0003591685  |
| qf2_loss                | 0.00034850798 |
| time_elapsed            | 1885          |
| total timesteps         | 391100        |
| value_loss              | 0.0002080182  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015194584 |
| ent_coef_loss           | -1.6475042   |
| entropy                 | 2.8639827    |
| ep_rewmean              | -2.47        |
| episodes                | 3916         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.5         |
| n_updates               | 391401       |
| policy_loss             | 0.7571939    |
| qf1_loss                | 0.008705043  |
| qf2_loss                | 0.0094387075 |
| time_elapsed            | 1887         |
| total timesteps         | 391500       |
| value_loss              | 0.0004286135 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001451372   |
| ent_coef_loss           | 3.098229      |
| entropy                 | 2.6301453     |
| ep_rewmean              | -2.5          |
| episodes                | 3920          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.5          |
| n_updates               | 391801        |
| policy_loss             | 0.7388888     |
| qf1_loss                | 0.013857024   |
| qf2_loss                | 0.0136127025  |
| time_elapsed            | 1889          |
| total timesteps         | 391900        |
| value_loss              | 0.00020661461 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001424546   |
| ent_coef_loss           | -2.2432504    |
| entropy                 | 3.0908957     |
| ep_rewmean              | -2.59         |
| episodes                | 3924          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 392201        |
| policy_loss             | 0.7629212     |
| qf1_loss                | 0.0037081104  |
| qf2_loss                | 0.0039905347  |
| time_elapsed            | 1891          |
| total timesteps         | 392300        |
| value_loss              | 0.00046761386 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013916625  |
| ent_coef_loss           | -1.5372896    |
| entropy                 | 2.5061672     |
| ep_rewmean              | -2.74         |
| episodes                | 3928          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.7          |
| n_updates               | 392601        |
| policy_loss             | 0.75962305    |
| qf1_loss                | 0.00048546054 |
| qf2_loss                | 0.0004910978  |
| time_elapsed            | 1893          |
| total timesteps         | 392700        |
| value_loss              | 0.00024047765 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013608146  |
| ent_coef_loss           | -2.2910423    |
| entropy                 | 2.9042687     |
| ep_rewmean              | -2.75         |
| episodes                | 3932          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.7          |
| n_updates               | 393001        |
| policy_loss             | 0.7256183     |
| qf1_loss                | 0.0024976097  |
| qf2_loss                | 0.0022646831  |
| time_elapsed            | 1895          |
| total timesteps         | 393100        |
| value_loss              | 0.00024324603 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013181218  |
| ent_coef_loss           | -2.2691493    |
| entropy                 | 2.1850264     |
| ep_rewmean              | -2.75         |
| episodes                | 3936          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.8          |
| n_updates               | 393401        |
| policy_loss             | 0.7557584     |
| qf1_loss                | 0.00027140393 |
| qf2_loss                | 0.000427332   |
| time_elapsed            | 1896          |
| total timesteps         | 393500        |
| value_loss              | 0.00026351243 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001322667   |
| ent_coef_loss           | 11.152095     |
| entropy                 | 2.9250932     |
| ep_rewmean              | -2.8          |
| episodes                | 3940          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.8          |
| n_updates               | 393801        |
| policy_loss             | 0.7495413     |
| qf1_loss                | 0.0006562081  |
| qf2_loss                | 0.0007124102  |
| time_elapsed            | 1898          |
| total timesteps         | 393900        |
| value_loss              | 0.00030443905 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013971999 |
| ent_coef_loss           | -2.5767903   |
| entropy                 | 2.901589     |
| ep_rewmean              | -2.79        |
| episodes                | 3944         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.8         |
| n_updates               | 394201       |
| policy_loss             | 0.7488195    |
| qf1_loss                | 0.0003650032 |
| qf2_loss                | 0.0005762541 |
| time_elapsed            | 1900         |
| total timesteps         | 394300       |
| value_loss              | 0.0002078329 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014107384  |
| ent_coef_loss           | 3.5692015     |
| entropy                 | 2.67046       |
| ep_rewmean              | -2.8          |
| episodes                | 3948          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.8          |
| n_updates               | 394601        |
| policy_loss             | 0.7456998     |
| qf1_loss                | 0.0048058745  |
| qf2_loss                | 0.004952412   |
| time_elapsed            | 1902          |
| total timesteps         | 394700        |
| value_loss              | 0.00042130507 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013722058  |
| ent_coef_loss           | -1.2974429    |
| entropy                 | 2.675643      |
| ep_rewmean              | -2.79         |
| episodes                | 3952          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.8          |
| n_updates               | 395001        |
| policy_loss             | 0.76373553    |
| qf1_loss                | 0.00042914596 |
| qf2_loss                | 0.0004905209  |
| time_elapsed            | 1904          |
| total timesteps         | 395100        |
| value_loss              | 0.00035972358 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012948842 |
| ent_coef_loss           | 1.7760652    |
| entropy                 | 2.696608     |
| ep_rewmean              | -2.81        |
| episodes                | 3956         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.8         |
| n_updates               | 395401       |
| policy_loss             | 0.74611807   |
| qf1_loss                | 0.0002572524 |
| qf2_loss                | 0.0002071906 |
| time_elapsed            | 1906         |
| total timesteps         | 395500       |
| value_loss              | 0.0002010497 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012447515  |
| ent_coef_loss           | -2.6200356    |
| entropy                 | 2.1882396     |
| ep_rewmean              | -2.76         |
| episodes                | 3960          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.8          |
| n_updates               | 395801        |
| policy_loss             | 0.78524244    |
| qf1_loss                | 0.0040908544  |
| qf2_loss                | 0.004010995   |
| time_elapsed            | 1908          |
| total timesteps         | 395900        |
| value_loss              | 0.00016338468 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012597179  |
| ent_coef_loss           | -4.679522     |
| entropy                 | 2.2371187     |
| ep_rewmean              | -2.68         |
| episodes                | 3964          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.7          |
| n_updates               | 396201        |
| policy_loss             | 0.800322      |
| qf1_loss                | 0.000306885   |
| qf2_loss                | 0.0003650017  |
| time_elapsed            | 1910          |
| total timesteps         | 396300        |
| value_loss              | 0.00022105948 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001263444   |
| ent_coef_loss           | -2.7654397    |
| entropy                 | 2.4351504     |
| ep_rewmean              | -2.65         |
| episodes                | 3968          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.7          |
| n_updates               | 396601        |
| policy_loss             | 0.8115361     |
| qf1_loss                | 0.0002957776  |
| qf2_loss                | 0.00025495616 |
| time_elapsed            | 1912          |
| total timesteps         | 396700        |
| value_loss              | 0.00019429075 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013018964  |
| ent_coef_loss           | 8.302877      |
| entropy                 | 3.193554      |
| ep_rewmean              | -2.65         |
| episodes                | 3972          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.7          |
| n_updates               | 397001        |
| policy_loss             | 0.7896631     |
| qf1_loss                | 0.00047562493 |
| qf2_loss                | 0.00037575944 |
| time_elapsed            | 1914          |
| total timesteps         | 397100        |
| value_loss              | 0.00023673425 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012904155  |
| ent_coef_loss           | 2.649443      |
| entropy                 | 2.61414       |
| ep_rewmean              | -2.64         |
| episodes                | 3976          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 397401        |
| policy_loss             | 0.780188      |
| qf1_loss                | 0.005706665   |
| qf2_loss                | 0.0059779226  |
| time_elapsed            | 1916          |
| total timesteps         | 397500        |
| value_loss              | 0.00019308386 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012964436  |
| ent_coef_loss           | -0.6101792    |
| entropy                 | 2.798305      |
| ep_rewmean              | -2.63         |
| episodes                | 3980          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 397801        |
| policy_loss             | 0.80877364    |
| qf1_loss                | 0.00038223615 |
| qf2_loss                | 0.00033613254 |
| time_elapsed            | 1918          |
| total timesteps         | 397900        |
| value_loss              | 0.0002325129  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013479434  |
| ent_coef_loss           | -6.1770563    |
| entropy                 | 2.7842607     |
| ep_rewmean              | -2.59         |
| episodes                | 3984          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.6          |
| n_updates               | 398201        |
| policy_loss             | 0.78167284    |
| qf1_loss                | 0.00027956167 |
| qf2_loss                | 0.00030847196 |
| time_elapsed            | 1920          |
| total timesteps         | 398300        |
| value_loss              | 0.00027937317 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013108728  |
| ent_coef_loss           | -1.129158     |
| entropy                 | 2.547898      |
| ep_rewmean              | -2.45         |
| episodes                | 3988          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 398601        |
| policy_loss             | 0.8356087     |
| qf1_loss                | 0.0013446667  |
| qf2_loss                | 0.0013810042  |
| time_elapsed            | 1921          |
| total timesteps         | 398700        |
| value_loss              | 0.00014825481 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012295401  |
| ent_coef_loss           | -6.3876715    |
| entropy                 | 2.4855855     |
| ep_rewmean              | -2.43         |
| episodes                | 3992          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 399001        |
| policy_loss             | 0.8005552     |
| qf1_loss                | 0.00034513656 |
| qf2_loss                | 0.0003073177  |
| time_elapsed            | 1923          |
| total timesteps         | 399100        |
| value_loss              | 0.00017696683 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012084575  |
| ent_coef_loss           | -2.0294557    |
| entropy                 | 2.1061568     |
| ep_rewmean              | -2.42         |
| episodes                | 3996          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 399401        |
| policy_loss             | 0.7676146     |
| qf1_loss                | 0.00067944103 |
| qf2_loss                | 0.00049925107 |
| time_elapsed            | 1925          |
| total timesteps         | 399500        |
| value_loss              | 0.00025619575 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012089706 |
| ent_coef_loss           | -5.9346704   |
| entropy                 | 2.2816794    |
| ep_rewmean              | -2.39        |
| episodes                | 4000         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.4         |
| n_updates               | 399801       |
| policy_loss             | 0.8262549    |
| qf1_loss                | 0.006446378  |
| qf2_loss                | 0.0064338567 |
| time_elapsed            | 1927         |
| total timesteps         | 399900       |
| value_loss              | 0.0003843722 |
------------------------------------------
Eval num_timesteps=400000, episode_reward=-1.31 +/- 0.90
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001164431   |
| ent_coef_loss           | -7.6168137    |
| entropy                 | 2.1839225     |
| ep_rewmean              | -2.36         |
| episodes                | 4004          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 400201        |
| policy_loss             | 0.7755703     |
| qf1_loss                | 0.00026815123 |
| qf2_loss                | 0.0002945539  |
| time_elapsed            | 1929          |
| total timesteps         | 400300        |
| value_loss              | 0.00021076138 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011382198  |
| ent_coef_loss           | -9.300571     |
| entropy                 | 2.2254062     |
| ep_rewmean              | -2.37         |
| episodes                | 4008          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.4          |
| n_updates               | 400601        |
| policy_loss             | 0.81349087    |
| qf1_loss                | 0.00048888614 |
| qf2_loss                | 0.00051958964 |
| time_elapsed            | 1931          |
| total timesteps         | 400700        |
| value_loss              | 0.00018363423 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011580008  |
| ent_coef_loss           | 8.81296       |
| entropy                 | 1.8488905     |
| ep_rewmean              | -2.29         |
| episodes                | 4012          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 401001        |
| policy_loss             | 0.85147387    |
| qf1_loss                | 0.0033939094  |
| qf2_loss                | 0.0032133707  |
| time_elapsed            | 1933          |
| total timesteps         | 401100        |
| value_loss              | 0.00030621758 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011937186  |
| ent_coef_loss           | 5.05579       |
| entropy                 | 1.7353798     |
| ep_rewmean              | -2.3          |
| episodes                | 4016          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 401401        |
| policy_loss             | 0.8486185     |
| qf1_loss                | 0.000423719   |
| qf2_loss                | 0.00031276228 |
| time_elapsed            | 1935          |
| total timesteps         | 401500        |
| value_loss              | 0.00059507194 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012224623  |
| ent_coef_loss           | -4.1215467    |
| entropy                 | 1.5429283     |
| ep_rewmean              | -2.25         |
| episodes                | 4020          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 401801        |
| policy_loss             | 0.86454904    |
| qf1_loss                | 0.0006541663  |
| qf2_loss                | 0.00081927417 |
| time_elapsed            | 1937          |
| total timesteps         | 401900        |
| value_loss              | 0.0004238582  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012273756  |
| ent_coef_loss           | -4.436289     |
| entropy                 | 2.33326       |
| ep_rewmean              | -2.18         |
| episodes                | 4024          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 402201        |
| policy_loss             | 0.7927824     |
| qf1_loss                | 0.0003632984  |
| qf2_loss                | 0.00027318043 |
| time_elapsed            | 1939          |
| total timesteps         | 402300        |
| value_loss              | 0.00021149061 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001272199   |
| ent_coef_loss           | 7.3419237     |
| entropy                 | 1.8796873     |
| ep_rewmean              | -2.07         |
| episodes                | 4028          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 402601        |
| policy_loss             | 0.8344725     |
| qf1_loss                | 0.0005433706  |
| qf2_loss                | 0.00042926057 |
| time_elapsed            | 1941          |
| total timesteps         | 402700        |
| value_loss              | 0.00026237074 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013130744  |
| ent_coef_loss           | 2.832417      |
| entropy                 | 1.8033091     |
| ep_rewmean              | -2.06         |
| episodes                | 4032          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 403001        |
| policy_loss             | 0.8134693     |
| qf1_loss                | 0.00034595653 |
| qf2_loss                | 0.00030292151 |
| time_elapsed            | 1943          |
| total timesteps         | 403100        |
| value_loss              | 0.00035087817 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001463162   |
| ent_coef_loss           | 0.9156558     |
| entropy                 | 2.6603699     |
| ep_rewmean              | -2.06         |
| episodes                | 4036          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 403401        |
| policy_loss             | 0.83863705    |
| qf1_loss                | 0.0009370452  |
| qf2_loss                | 0.0005996056  |
| time_elapsed            | 1945          |
| total timesteps         | 403500        |
| value_loss              | 0.00028083991 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015611616  |
| ent_coef_loss           | 1.8832663     |
| entropy                 | 2.7436914     |
| ep_rewmean              | -2.01         |
| episodes                | 4040          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 403801        |
| policy_loss             | 0.8831514     |
| qf1_loss                | 0.00044460507 |
| qf2_loss                | 0.00038249147 |
| time_elapsed            | 1947          |
| total timesteps         | 403900        |
| value_loss              | 0.0002692883  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015614609  |
| ent_coef_loss           | 4.136212      |
| entropy                 | 2.3467445     |
| ep_rewmean              | -1.99         |
| episodes                | 4044          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 404201        |
| policy_loss             | 0.9358052     |
| qf1_loss                | 0.0006576077  |
| qf2_loss                | 0.000678679   |
| time_elapsed            | 1949          |
| total timesteps         | 404300        |
| value_loss              | 0.00024909808 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015586334  |
| ent_coef_loss           | -0.7796123    |
| entropy                 | 2.2811818     |
| ep_rewmean              | -1.99         |
| episodes                | 4048          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 404601        |
| policy_loss             | 0.873925      |
| qf1_loss                | 0.028538404   |
| qf2_loss                | 0.028502565   |
| time_elapsed            | 1951          |
| total timesteps         | 404700        |
| value_loss              | 0.00022480398 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014943179  |
| ent_coef_loss           | -0.9368894    |
| entropy                 | 2.4089916     |
| ep_rewmean              | -2.02         |
| episodes                | 4052          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 405001        |
| policy_loss             | 0.9113566     |
| qf1_loss                | 0.025279406   |
| qf2_loss                | 0.025040012   |
| time_elapsed            | 1952          |
| total timesteps         | 405100        |
| value_loss              | 0.00032169986 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013901741  |
| ent_coef_loss           | -2.3897786    |
| entropy                 | 2.0883        |
| ep_rewmean              | -2.04         |
| episodes                | 4056          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 405401        |
| policy_loss             | 0.8936006     |
| qf1_loss                | 0.032284662   |
| qf2_loss                | 0.032857962   |
| time_elapsed            | 1954          |
| total timesteps         | 405500        |
| value_loss              | 0.00017566644 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001333798   |
| ent_coef_loss           | 0.36733627    |
| entropy                 | 2.196097      |
| ep_rewmean              | -2            |
| episodes                | 4060          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 405801        |
| policy_loss             | 0.88744307    |
| qf1_loss                | 0.016648255   |
| qf2_loss                | 0.017066106   |
| time_elapsed            | 1956          |
| total timesteps         | 405900        |
| value_loss              | 0.00041993707 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012751007  |
| ent_coef_loss           | 3.008687      |
| entropy                 | 1.5034727     |
| ep_rewmean              | -1.99         |
| episodes                | 4064          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 406201        |
| policy_loss             | 0.8743857     |
| qf1_loss                | 0.00043743552 |
| qf2_loss                | 0.00029472573 |
| time_elapsed            | 1958          |
| total timesteps         | 406300        |
| value_loss              | 0.0003896755  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012517446  |
| ent_coef_loss           | -2.401778     |
| entropy                 | 1.8636442     |
| ep_rewmean              | -2.05         |
| episodes                | 4068          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 406601        |
| policy_loss             | 0.8699379     |
| qf1_loss                | 0.00045512352 |
| qf2_loss                | 0.00040419545 |
| time_elapsed            | 1960          |
| total timesteps         | 406700        |
| value_loss              | 0.00015953969 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012932478  |
| ent_coef_loss           | 0.08668363    |
| entropy                 | 2.282349      |
| ep_rewmean              | -2.09         |
| episodes                | 4072          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 407001        |
| policy_loss             | 0.87011576    |
| qf1_loss                | 0.0039404416  |
| qf2_loss                | 0.0038905332  |
| time_elapsed            | 1962          |
| total timesteps         | 407100        |
| value_loss              | 0.00041862862 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013061545  |
| ent_coef_loss           | 0.9319161     |
| entropy                 | 1.7636615     |
| ep_rewmean              | -2.07         |
| episodes                | 4076          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 407401        |
| policy_loss             | 0.8760354     |
| qf1_loss                | 0.0057665836  |
| qf2_loss                | 0.006131834   |
| time_elapsed            | 1964          |
| total timesteps         | 407500        |
| value_loss              | 0.00037444796 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012944558  |
| ent_coef_loss           | 3.5949562     |
| entropy                 | 2.3946621     |
| ep_rewmean              | -2.03         |
| episodes                | 4080          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 407801        |
| policy_loss             | 0.8835585     |
| qf1_loss                | 0.00090302824 |
| qf2_loss                | 0.0009449937  |
| time_elapsed            | 1966          |
| total timesteps         | 407900        |
| value_loss              | 0.00027148268 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013073602  |
| ent_coef_loss           | 3.845944      |
| entropy                 | 2.2437544     |
| ep_rewmean              | -1.97         |
| episodes                | 4084          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 408201        |
| policy_loss             | 0.900198      |
| qf1_loss                | 0.01192769    |
| qf2_loss                | 0.01417175    |
| time_elapsed            | 1968          |
| total timesteps         | 408300        |
| value_loss              | 0.00035422127 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013116795  |
| ent_coef_loss           | -6.3600445    |
| entropy                 | 1.6618319     |
| ep_rewmean              | -1.99         |
| episodes                | 4088          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 408601        |
| policy_loss             | 0.86214113    |
| qf1_loss                | 0.005456053   |
| qf2_loss                | 0.005803036   |
| time_elapsed            | 1970          |
| total timesteps         | 408700        |
| value_loss              | 0.00018571624 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012772963  |
| ent_coef_loss           | -5.147352     |
| entropy                 | 2.2764506     |
| ep_rewmean              | -1.97         |
| episodes                | 4092          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 409001        |
| policy_loss             | 0.91509634    |
| qf1_loss                | 0.00033862618 |
| qf2_loss                | 0.00047918205 |
| time_elapsed            | 1972          |
| total timesteps         | 409100        |
| value_loss              | 0.0002045543  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001269638  |
| ent_coef_loss           | 2.1657052    |
| entropy                 | 1.9522966    |
| ep_rewmean              | -2           |
| episodes                | 4096         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 409401       |
| policy_loss             | 0.9151028    |
| qf1_loss                | 0.0044473726 |
| qf2_loss                | 0.0043611806 |
| time_elapsed            | 1974         |
| total timesteps         | 409500       |
| value_loss              | 0.0003136862 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012834934  |
| ent_coef_loss           | 0.18889105    |
| entropy                 | 1.6489193     |
| ep_rewmean              | -1.95         |
| episodes                | 4100          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 409801        |
| policy_loss             | 0.9003563     |
| qf1_loss                | 0.00080777693 |
| qf2_loss                | 0.000635238   |
| time_elapsed            | 1976          |
| total timesteps         | 409900        |
| value_loss              | 0.00036837242 |
-------------------------------------------
Eval num_timesteps=410000, episode_reward=-1.29 +/- 0.53
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013118815  |
| ent_coef_loss           | -2.7885761    |
| entropy                 | 2.064433      |
| ep_rewmean              | -1.92         |
| episodes                | 4104          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 410201        |
| policy_loss             | 0.94657797    |
| qf1_loss                | 0.0037473878  |
| qf2_loss                | 0.00377827    |
| time_elapsed            | 1978          |
| total timesteps         | 410300        |
| value_loss              | 0.00035372807 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013405938  |
| ent_coef_loss           | 0.21828723    |
| entropy                 | 2.1142015     |
| ep_rewmean              | -1.88         |
| episodes                | 4108          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 410601        |
| policy_loss             | 0.9278036     |
| qf1_loss                | 0.00045171916 |
| qf2_loss                | 0.00054642773 |
| time_elapsed            | 1980          |
| total timesteps         | 410700        |
| value_loss              | 0.0005261164  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013529115  |
| ent_coef_loss           | 6.412054      |
| entropy                 | 2.0593069     |
| ep_rewmean              | -1.88         |
| episodes                | 4112          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 411001        |
| policy_loss             | 0.95996785    |
| qf1_loss                | 0.0005512426  |
| qf2_loss                | 0.00037199876 |
| time_elapsed            | 1982          |
| total timesteps         | 411100        |
| value_loss              | 0.00031389654 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013410918  |
| ent_coef_loss           | 10.937365     |
| entropy                 | 2.95661       |
| ep_rewmean              | -1.84         |
| episodes                | 4116          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 411401        |
| policy_loss             | 0.9467454     |
| qf1_loss                | 0.00077609764 |
| qf2_loss                | 0.0005124855  |
| time_elapsed            | 1984          |
| total timesteps         | 411500        |
| value_loss              | 0.0003695861  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00136081    |
| ent_coef_loss           | 4.8637        |
| entropy                 | 2.3723137     |
| ep_rewmean              | -1.9          |
| episodes                | 4120          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 411801        |
| policy_loss             | 0.9059818     |
| qf1_loss                | 0.010789175   |
| qf2_loss                | 0.010760054   |
| time_elapsed            | 1986          |
| total timesteps         | 411900        |
| value_loss              | 0.00045804327 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013443707 |
| ent_coef_loss           | 4.382569     |
| entropy                 | 2.5105648    |
| ep_rewmean              | -1.91        |
| episodes                | 4124         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 412201       |
| policy_loss             | 0.9374488    |
| qf1_loss                | 0.037964404  |
| qf2_loss                | 0.038515594  |
| time_elapsed            | 1987         |
| total timesteps         | 412300       |
| value_loss              | 0.0005339622 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013086158  |
| ent_coef_loss           | 2.5615268     |
| entropy                 | 2.3441653     |
| ep_rewmean              | -1.92         |
| episodes                | 4128          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 412601        |
| policy_loss             | 0.94012725    |
| qf1_loss                | 0.0010413586  |
| qf2_loss                | 0.0009271768  |
| time_elapsed            | 1989          |
| total timesteps         | 412700        |
| value_loss              | 0.00021268573 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013061763 |
| ent_coef_loss           | 4.599344     |
| entropy                 | 3.1213048    |
| ep_rewmean              | -1.96        |
| episodes                | 4132         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 413001       |
| policy_loss             | 0.9232874    |
| qf1_loss                | 0.0007163354 |
| qf2_loss                | 0.0006111985 |
| time_elapsed            | 1991         |
| total timesteps         | 413100       |
| value_loss              | 0.0002902284 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013845029  |
| ent_coef_loss           | 4.791998      |
| entropy                 | 2.5170188     |
| ep_rewmean              | -1.98         |
| episodes                | 4136          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 413401        |
| policy_loss             | 1.0515695     |
| qf1_loss                | 0.0008743147  |
| qf2_loss                | 0.0006116182  |
| time_elapsed            | 1993          |
| total timesteps         | 413500        |
| value_loss              | 0.00028131774 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014821101  |
| ent_coef_loss           | -1.8628149    |
| entropy                 | 2.3540478     |
| ep_rewmean              | -2.02         |
| episodes                | 4140          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 413801        |
| policy_loss             | 0.93403757    |
| qf1_loss                | 0.009531761   |
| qf2_loss                | 0.009578183   |
| time_elapsed            | 1995          |
| total timesteps         | 413900        |
| value_loss              | 0.00066292624 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015619494  |
| ent_coef_loss           | -1.8318291    |
| entropy                 | 2.9599776     |
| ep_rewmean              | -2.09         |
| episodes                | 4144          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 414201        |
| policy_loss             | 0.974668      |
| qf1_loss                | 0.005757318   |
| qf2_loss                | 0.0060201716  |
| time_elapsed            | 1997          |
| total timesteps         | 414300        |
| value_loss              | 0.00035647303 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0015604256 |
| ent_coef_loss           | -0.28095222  |
| entropy                 | 2.8434157    |
| ep_rewmean              | -2.09        |
| episodes                | 4148         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.1         |
| n_updates               | 414601       |
| policy_loss             | 0.9774177    |
| qf1_loss                | 0.009052239  |
| qf2_loss                | 0.009214089  |
| time_elapsed            | 1999         |
| total timesteps         | 414700       |
| value_loss              | 0.0002781647 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001514546   |
| ent_coef_loss           | -5.9976034    |
| entropy                 | 2.2085292     |
| ep_rewmean              | -2.09         |
| episodes                | 4152          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 415001        |
| policy_loss             | 0.9615067     |
| qf1_loss                | 0.0007270235  |
| qf2_loss                | 0.00059982936 |
| time_elapsed            | 2001          |
| total timesteps         | 415100        |
| value_loss              | 0.00024486892 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014730671  |
| ent_coef_loss           | 3.6496787     |
| entropy                 | 2.4747982     |
| ep_rewmean              | -2.07         |
| episodes                | 4156          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 415401        |
| policy_loss             | 0.99913394    |
| qf1_loss                | 0.0012657476  |
| qf2_loss                | 0.00093376305 |
| time_elapsed            | 2003          |
| total timesteps         | 415500        |
| value_loss              | 0.0002995989  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014831494  |
| ent_coef_loss           | 1.3743434     |
| entropy                 | 2.1207876     |
| ep_rewmean              | -2.15         |
| episodes                | 4160          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 415801        |
| policy_loss             | 0.96333456    |
| qf1_loss                | 0.0002954136  |
| qf2_loss                | 0.00022119327 |
| time_elapsed            | 2005          |
| total timesteps         | 415900        |
| value_loss              | 0.00031945202 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014962067  |
| ent_coef_loss           | -2.6721115    |
| entropy                 | 2.2150092     |
| ep_rewmean              | -2.16         |
| episodes                | 4164          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 416201        |
| policy_loss             | 0.96260744    |
| qf1_loss                | 0.009286992   |
| qf2_loss                | 0.007468933   |
| time_elapsed            | 2007          |
| total timesteps         | 416300        |
| value_loss              | 0.00037036178 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014616481  |
| ent_coef_loss           | -0.92970514   |
| entropy                 | 1.8133209     |
| ep_rewmean              | -2.07         |
| episodes                | 4168          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 416601        |
| policy_loss             | 0.9913154     |
| qf1_loss                | 0.00037375712 |
| qf2_loss                | 0.00042877145 |
| time_elapsed            | 2009          |
| total timesteps         | 416700        |
| value_loss              | 0.0002991505  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014388721  |
| ent_coef_loss           | -4.4007688    |
| entropy                 | 2.197918      |
| ep_rewmean              | -2.02         |
| episodes                | 4172          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 417001        |
| policy_loss             | 0.9806309     |
| qf1_loss                | 0.010593161   |
| qf2_loss                | 0.010815493   |
| time_elapsed            | 2011          |
| total timesteps         | 417100        |
| value_loss              | 0.00023541859 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014086701  |
| ent_coef_loss           | -6.1424303    |
| entropy                 | 2.0621593     |
| ep_rewmean              | -2.05         |
| episodes                | 4176          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 417401        |
| policy_loss             | 0.96455455    |
| qf1_loss                | 0.00051486003 |
| qf2_loss                | 0.00039964888 |
| time_elapsed            | 2013          |
| total timesteps         | 417500        |
| value_loss              | 0.00025375385 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013902902  |
| ent_coef_loss           | -2.6193566    |
| entropy                 | 2.2451613     |
| ep_rewmean              | -2.09         |
| episodes                | 4180          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 417801        |
| policy_loss             | 0.9714067     |
| qf1_loss                | 0.006666524   |
| qf2_loss                | 0.0063313423  |
| time_elapsed            | 2014          |
| total timesteps         | 417900        |
| value_loss              | 0.00020016861 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014202946  |
| ent_coef_loss           | -0.40639317   |
| entropy                 | 1.6498749     |
| ep_rewmean              | -2.18         |
| episodes                | 4184          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 418201        |
| policy_loss             | 1.0126085     |
| qf1_loss                | 0.00052763463 |
| qf2_loss                | 0.0004128541  |
| time_elapsed            | 2016          |
| total timesteps         | 418300        |
| value_loss              | 0.00016296859 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013874193 |
| ent_coef_loss           | -5.3795075   |
| entropy                 | 1.9728825    |
| ep_rewmean              | -2.18        |
| episodes                | 4188         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 418601       |
| policy_loss             | 0.9634904    |
| qf1_loss                | 0.018649379  |
| qf2_loss                | 0.018098852  |
| time_elapsed            | 2018         |
| total timesteps         | 418700       |
| value_loss              | 0.0002086937 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013275911  |
| ent_coef_loss           | -2.4669344    |
| entropy                 | 1.6747456     |
| ep_rewmean              | -2.17         |
| episodes                | 4192          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 419001        |
| policy_loss             | 0.9458891     |
| qf1_loss                | 0.00026766316 |
| qf2_loss                | 0.00028631213 |
| time_elapsed            | 2020          |
| total timesteps         | 419100        |
| value_loss              | 0.00027924567 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012880788  |
| ent_coef_loss           | -0.7922313    |
| entropy                 | 1.7952323     |
| ep_rewmean              | -2.19         |
| episodes                | 4196          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 419401        |
| policy_loss             | 0.9757689     |
| qf1_loss                | 0.0005452946  |
| qf2_loss                | 0.00054062833 |
| time_elapsed            | 2022          |
| total timesteps         | 419500        |
| value_loss              | 0.00045149945 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012697002  |
| ent_coef_loss           | 5.5582676     |
| entropy                 | 1.7436619     |
| ep_rewmean              | -2.24         |
| episodes                | 4200          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 419801        |
| policy_loss             | 0.985602      |
| qf1_loss                | 0.0006100839  |
| qf2_loss                | 0.0003612035  |
| time_elapsed            | 2024          |
| total timesteps         | 419900        |
| value_loss              | 0.00023470844 |
-------------------------------------------
Eval num_timesteps=420000, episode_reward=-2.06 +/- 1.05
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012467866  |
| ent_coef_loss           | -2.8316512    |
| entropy                 | 1.908977      |
| ep_rewmean              | -2.25         |
| episodes                | 4204          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 420201        |
| policy_loss             | 0.9648769     |
| qf1_loss                | 0.005784088   |
| qf2_loss                | 0.0058249715  |
| time_elapsed            | 2026          |
| total timesteps         | 420300        |
| value_loss              | 0.00043180742 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012459082  |
| ent_coef_loss           | -1.6099347    |
| entropy                 | 2.1280525     |
| ep_rewmean              | -2.27         |
| episodes                | 4208          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 420601        |
| policy_loss             | 0.93492925    |
| qf1_loss                | 0.0069930805  |
| qf2_loss                | 0.006980671   |
| time_elapsed            | 2028          |
| total timesteps         | 420700        |
| value_loss              | 0.00021927508 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0012403114 |
| ent_coef_loss           | -6.8492947   |
| entropy                 | 1.7119465    |
| ep_rewmean              | -2.27        |
| episodes                | 4212         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.3         |
| n_updates               | 421001       |
| policy_loss             | 0.96547174   |
| qf1_loss                | 0.007011841  |
| qf2_loss                | 0.007059398  |
| time_elapsed            | 2030         |
| total timesteps         | 421100       |
| value_loss              | 0.0006659494 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012954772  |
| ent_coef_loss           | -1.349393     |
| entropy                 | 1.6470661     |
| ep_rewmean              | -2.26         |
| episodes                | 4216          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 421401        |
| policy_loss             | 0.9910519     |
| qf1_loss                | 0.00031971102 |
| qf2_loss                | 0.00033421553 |
| time_elapsed            | 2032          |
| total timesteps         | 421500        |
| value_loss              | 0.00037849863 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014086049  |
| ent_coef_loss           | -2.113652     |
| entropy                 | 2.1511285     |
| ep_rewmean              | -2.19         |
| episodes                | 4220          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 421801        |
| policy_loss             | 1.0005236     |
| qf1_loss                | 0.0005565496  |
| qf2_loss                | 0.00044452815 |
| time_elapsed            | 2034          |
| total timesteps         | 421900        |
| value_loss              | 0.0003596507  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015409493  |
| ent_coef_loss           | 2.5327842     |
| entropy                 | 2.890532      |
| ep_rewmean              | -2.15         |
| episodes                | 4224          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 422201        |
| policy_loss             | 0.97177094    |
| qf1_loss                | 0.009513517   |
| qf2_loss                | 0.009575187   |
| time_elapsed            | 2036          |
| total timesteps         | 422300        |
| value_loss              | 0.00037957897 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016363354  |
| ent_coef_loss           | 6.7278323     |
| entropy                 | 2.4572742     |
| ep_rewmean              | -2.1          |
| episodes                | 4228          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 422601        |
| policy_loss             | 0.9595691     |
| qf1_loss                | 0.009492636   |
| qf2_loss                | 0.009226095   |
| time_elapsed            | 2038          |
| total timesteps         | 422700        |
| value_loss              | 0.00042119564 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016923969  |
| ent_coef_loss           | -3.5245361    |
| entropy                 | 2.2102966     |
| ep_rewmean              | -2.01         |
| episodes                | 4232          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 423001        |
| policy_loss             | 0.97954273    |
| qf1_loss                | 0.00041688245 |
| qf2_loss                | 0.0005313237  |
| time_elapsed            | 2040          |
| total timesteps         | 423100        |
| value_loss              | 0.0003237048  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016665846  |
| ent_coef_loss           | -0.15742946   |
| entropy                 | 2.3265805     |
| ep_rewmean              | -2.03         |
| episodes                | 4236          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 423401        |
| policy_loss             | 0.97761023    |
| qf1_loss                | 0.00037866426 |
| qf2_loss                | 0.0002772269  |
| time_elapsed            | 2041          |
| total timesteps         | 423500        |
| value_loss              | 0.0003998389  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016566846 |
| ent_coef_loss           | -2.4154055   |
| entropy                 | 2.1991143    |
| ep_rewmean              | -1.99        |
| episodes                | 4240         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 423801       |
| policy_loss             | 0.94555634   |
| qf1_loss                | 0.0064932816 |
| qf2_loss                | 0.0066535017 |
| time_elapsed            | 2043         |
| total timesteps         | 423900       |
| value_loss              | 0.0004385727 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00165928    |
| ent_coef_loss           | -3.8015728    |
| entropy                 | 2.2702289     |
| ep_rewmean              | -1.94         |
| episodes                | 4244          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 424201        |
| policy_loss             | 0.94790125    |
| qf1_loss                | 0.00069727923 |
| qf2_loss                | 0.00083605817 |
| time_elapsed            | 2045          |
| total timesteps         | 424300        |
| value_loss              | 0.0003353483  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016380365 |
| ent_coef_loss           | 2.887479     |
| entropy                 | 2.1444142    |
| ep_rewmean              | -1.97        |
| episodes                | 4248         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2           |
| n_updates               | 424601       |
| policy_loss             | 0.94368243   |
| qf1_loss                | 0.015175205  |
| qf2_loss                | 0.015020759  |
| time_elapsed            | 2047         |
| total timesteps         | 424700       |
| value_loss              | 0.0007005236 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016617758  |
| ent_coef_loss           | 4.8828363     |
| entropy                 | 2.6152875     |
| ep_rewmean              | -1.93         |
| episodes                | 4252          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 425001        |
| policy_loss             | 0.90405655    |
| qf1_loss                | 0.00035830328 |
| qf2_loss                | 0.0003579426  |
| time_elapsed            | 2049          |
| total timesteps         | 425100        |
| value_loss              | 0.00037662633 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017435044  |
| ent_coef_loss           | -2.7632983    |
| entropy                 | 2.565239      |
| ep_rewmean              | -1.95         |
| episodes                | 4256          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 425401        |
| policy_loss             | 0.96399164    |
| qf1_loss                | 0.0041695475  |
| qf2_loss                | 0.0036379509  |
| time_elapsed            | 2051          |
| total timesteps         | 425500        |
| value_loss              | 0.00040597146 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0017751474 |
| ent_coef_loss           | 0.24152827   |
| entropy                 | 2.5428576    |
| ep_rewmean              | -1.87        |
| episodes                | 4260         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 425801       |
| policy_loss             | 0.96593773   |
| qf1_loss                | 0.013773949  |
| qf2_loss                | 0.014292772  |
| time_elapsed            | 2053         |
| total timesteps         | 425900       |
| value_loss              | 0.0005867867 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0018258427  |
| ent_coef_loss           | -2.5052857    |
| entropy                 | 3.0625808     |
| ep_rewmean              | -1.85         |
| episodes                | 4264          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 426201        |
| policy_loss             | 0.95546234    |
| qf1_loss                | 0.00032311474 |
| qf2_loss                | 0.0002552893  |
| time_elapsed            | 2055          |
| total timesteps         | 426300        |
| value_loss              | 0.0003282567  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001823184   |
| ent_coef_loss           | 1.8221464     |
| entropy                 | 2.5210416     |
| ep_rewmean              | -1.88         |
| episodes                | 4268          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 426601        |
| policy_loss             | 0.94288445    |
| qf1_loss                | 0.0006898745  |
| qf2_loss                | 0.00076297903 |
| time_elapsed            | 2057          |
| total timesteps         | 426700        |
| value_loss              | 0.0005766369  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017859411  |
| ent_coef_loss           | 3.573007      |
| entropy                 | 3.0111952     |
| ep_rewmean              | -1.86         |
| episodes                | 4272          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 427001        |
| policy_loss             | 0.9351771     |
| qf1_loss                | 0.00039938535 |
| qf2_loss                | 0.00036961678 |
| time_elapsed            | 2059          |
| total timesteps         | 427100        |
| value_loss              | 0.00059390557 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0017736336  |
| ent_coef_loss           | -8.754152     |
| entropy                 | 2.747549      |
| ep_rewmean              | -1.88         |
| episodes                | 4276          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 427401        |
| policy_loss             | 0.9080157     |
| qf1_loss                | 0.0060925432  |
| qf2_loss                | 0.006102395   |
| time_elapsed            | 2061          |
| total timesteps         | 427500        |
| value_loss              | 0.00029231934 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0016724454 |
| ent_coef_loss           | 0.8389578    |
| entropy                 | 2.4109015    |
| ep_rewmean              | -1.84        |
| episodes                | 4280         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 427801       |
| policy_loss             | 0.90746355   |
| qf1_loss                | 0.005255977  |
| qf2_loss                | 0.0054396978 |
| time_elapsed            | 2062         |
| total timesteps         | 427900       |
| value_loss              | 0.0006053739 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0016089381  |
| ent_coef_loss           | -5.537704     |
| entropy                 | 2.2102747     |
| ep_rewmean              | -1.8          |
| episodes                | 4284          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 428201        |
| policy_loss             | 0.8892287     |
| qf1_loss                | 0.008802696   |
| qf2_loss                | 0.008386538   |
| time_elapsed            | 2064          |
| total timesteps         | 428300        |
| value_loss              | 0.00024687982 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015862961  |
| ent_coef_loss           | -2.2510438    |
| entropy                 | 2.1955197     |
| ep_rewmean              | -1.84         |
| episodes                | 4288          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 428601        |
| policy_loss             | 0.8679748     |
| qf1_loss                | 0.0055366857  |
| qf2_loss                | 0.00564475    |
| time_elapsed            | 2066          |
| total timesteps         | 428700        |
| value_loss              | 0.00029634804 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001587597   |
| ent_coef_loss           | -2.9218426    |
| entropy                 | 2.1303034     |
| ep_rewmean              | -1.85         |
| episodes                | 4292          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 429001        |
| policy_loss             | 0.83936226    |
| qf1_loss                | 0.005168217   |
| qf2_loss                | 0.005542253   |
| time_elapsed            | 2068          |
| total timesteps         | 429100        |
| value_loss              | 0.00025737303 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015175185  |
| ent_coef_loss           | -1.0445082    |
| entropy                 | 2.0250587     |
| ep_rewmean              | -1.84         |
| episodes                | 4296          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 429401        |
| policy_loss             | 0.83869576    |
| qf1_loss                | 0.0011000799  |
| qf2_loss                | 0.00075337704 |
| time_elapsed            | 2070          |
| total timesteps         | 429500        |
| value_loss              | 0.0003618977  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0015118929  |
| ent_coef_loss           | -6.57755      |
| entropy                 | 2.119061      |
| ep_rewmean              | -1.81         |
| episodes                | 4300          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 429801        |
| policy_loss             | 0.89078474    |
| qf1_loss                | 0.0004973129  |
| qf2_loss                | 0.00042750136 |
| time_elapsed            | 2072          |
| total timesteps         | 429900        |
| value_loss              | 0.0002573125  |
-------------------------------------------
Eval num_timesteps=430000, episode_reward=-1.02 +/- 0.34
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014337164  |
| ent_coef_loss           | -3.0632935    |
| entropy                 | 1.6740465     |
| ep_rewmean              | -1.81         |
| episodes                | 4304          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 430201        |
| policy_loss             | 0.8704771     |
| qf1_loss                | 0.00028037882 |
| qf2_loss                | 0.00027541578 |
| time_elapsed            | 2074          |
| total timesteps         | 430300        |
| value_loss              | 0.00023550409 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013868888  |
| ent_coef_loss           | 0.6488426     |
| entropy                 | 2.0989916     |
| ep_rewmean              | -1.81         |
| episodes                | 4308          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 430601        |
| policy_loss             | 0.85304517    |
| qf1_loss                | 0.0005349815  |
| qf2_loss                | 0.00040467503 |
| time_elapsed            | 2076          |
| total timesteps         | 430700        |
| value_loss              | 0.0002090369  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013614681  |
| ent_coef_loss           | -10.951836    |
| entropy                 | 1.7353607     |
| ep_rewmean              | -1.79         |
| episodes                | 4312          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 431001        |
| policy_loss             | 0.79824585    |
| qf1_loss                | 0.00020563765 |
| qf2_loss                | 0.0002207882  |
| time_elapsed            | 2078          |
| total timesteps         | 431100        |
| value_loss              | 0.00019660976 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0013575248 |
| ent_coef_loss           | -2.2251897   |
| entropy                 | 2.0913508    |
| ep_rewmean              | -1.81        |
| episodes                | 4316         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 431401       |
| policy_loss             | 0.7927064    |
| qf1_loss                | 0.008216039  |
| qf2_loss                | 0.010852584  |
| time_elapsed            | 2080         |
| total timesteps         | 431500       |
| value_loss              | 0.0004100698 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013435023  |
| ent_coef_loss           | 3.69367       |
| entropy                 | 2.0123653     |
| ep_rewmean              | -1.82         |
| episodes                | 4320          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 431801        |
| policy_loss             | 0.80909264    |
| qf1_loss                | 0.007813085   |
| qf2_loss                | 0.0076837842  |
| time_elapsed            | 2082          |
| total timesteps         | 431900        |
| value_loss              | 0.00024835262 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013156013  |
| ent_coef_loss           | 3.3218303     |
| entropy                 | 1.3028089     |
| ep_rewmean              | -1.79         |
| episodes                | 4324          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 432201        |
| policy_loss             | 0.78219247    |
| qf1_loss                | 0.019219713   |
| qf2_loss                | 0.019316528   |
| time_elapsed            | 2084          |
| total timesteps         | 432300        |
| value_loss              | 0.00023408304 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013040126  |
| ent_coef_loss           | -3.8769894    |
| entropy                 | 1.5078        |
| ep_rewmean              | -1.79         |
| episodes                | 4328          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 432601        |
| policy_loss             | 0.8220679     |
| qf1_loss                | 0.0059680534  |
| qf2_loss                | 0.0062215244  |
| time_elapsed            | 2086          |
| total timesteps         | 432700        |
| value_loss              | 0.00024658494 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012685396  |
| ent_coef_loss           | 5.2356873     |
| entropy                 | 2.1637402     |
| ep_rewmean              | -1.85         |
| episodes                | 4332          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 433001        |
| policy_loss             | 0.7430801     |
| qf1_loss                | 0.006075145   |
| qf2_loss                | 0.0056305816  |
| time_elapsed            | 2088          |
| total timesteps         | 433100        |
| value_loss              | 0.00023934293 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012506981  |
| ent_coef_loss           | -2.2768278    |
| entropy                 | 1.6904306     |
| ep_rewmean              | -1.79         |
| episodes                | 4336          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 433401        |
| policy_loss             | 0.8070773     |
| qf1_loss                | 0.0003578883  |
| qf2_loss                | 0.00036993276 |
| time_elapsed            | 2089          |
| total timesteps         | 433500        |
| value_loss              | 0.00057364325 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012572005  |
| ent_coef_loss           | 1.0729991     |
| entropy                 | 1.4476588     |
| ep_rewmean              | -1.81         |
| episodes                | 4340          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 433801        |
| policy_loss             | 0.81291157    |
| qf1_loss                | 0.006271837   |
| qf2_loss                | 0.0061771735  |
| time_elapsed            | 2091          |
| total timesteps         | 433900        |
| value_loss              | 0.00018414587 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012904708  |
| ent_coef_loss           | -1.6667564    |
| entropy                 | 2.160604      |
| ep_rewmean              | -1.8          |
| episodes                | 4344          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 434201        |
| policy_loss             | 0.74720013    |
| qf1_loss                | 0.0003801945  |
| qf2_loss                | 0.00037496933 |
| time_elapsed            | 2093          |
| total timesteps         | 434300        |
| value_loss              | 0.000239635   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013223302  |
| ent_coef_loss           | -5.343882     |
| entropy                 | 2.0954986     |
| ep_rewmean              | -1.74         |
| episodes                | 4348          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 434601        |
| policy_loss             | 0.7999773     |
| qf1_loss                | 0.00020934382 |
| qf2_loss                | 0.00017929557 |
| time_elapsed            | 2095          |
| total timesteps         | 434700        |
| value_loss              | 0.00026669193 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013468134  |
| ent_coef_loss           | -1.8765978    |
| entropy                 | 1.930151      |
| ep_rewmean              | -1.76         |
| episodes                | 4352          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 435001        |
| policy_loss             | 0.7276745     |
| qf1_loss                | 0.00040060387 |
| qf2_loss                | 0.00042472032 |
| time_elapsed            | 2097          |
| total timesteps         | 435100        |
| value_loss              | 0.00024320795 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014102656  |
| ent_coef_loss           | 3.7484963     |
| entropy                 | 2.5090468     |
| ep_rewmean              | -1.77         |
| episodes                | 4356          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 435401        |
| policy_loss             | 0.78244746    |
| qf1_loss                | 0.007501578   |
| qf2_loss                | 0.007411996   |
| time_elapsed            | 2099          |
| total timesteps         | 435500        |
| value_loss              | 0.00031265768 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014561386  |
| ent_coef_loss           | -0.21501327   |
| entropy                 | 2.2742937     |
| ep_rewmean              | -1.8          |
| episodes                | 4360          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 435801        |
| policy_loss             | 0.80669284    |
| qf1_loss                | 0.0004954162  |
| qf2_loss                | 0.0004190377  |
| time_elapsed            | 2101          |
| total timesteps         | 435900        |
| value_loss              | 0.00028638667 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0014328873  |
| ent_coef_loss           | -3.7657943    |
| entropy                 | 2.4650652     |
| ep_rewmean              | -1.81         |
| episodes                | 4364          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 436201        |
| policy_loss             | 0.8238701     |
| qf1_loss                | 0.010491438   |
| qf2_loss                | 0.010704238   |
| time_elapsed            | 2103          |
| total timesteps         | 436300        |
| value_loss              | 0.00028576236 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0013300122  |
| ent_coef_loss           | 0.6843538     |
| entropy                 | 1.9901575     |
| ep_rewmean              | -1.77         |
| episodes                | 4368          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 436601        |
| policy_loss             | 0.8172587     |
| qf1_loss                | 0.0002552808  |
| qf2_loss                | 0.00038436416 |
| time_elapsed            | 2105          |
| total timesteps         | 436700        |
| value_loss              | 0.00036493005 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012195942  |
| ent_coef_loss           | 0.5952364     |
| entropy                 | 2.098506      |
| ep_rewmean              | -1.79         |
| episodes                | 4372          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 437001        |
| policy_loss             | 0.76024       |
| qf1_loss                | 0.0005242557  |
| qf2_loss                | 0.00049582287 |
| time_elapsed            | 2107          |
| total timesteps         | 437100        |
| value_loss              | 0.0002007722  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011972821  |
| ent_coef_loss           | -4.24829      |
| entropy                 | 1.9864767     |
| ep_rewmean              | -1.78         |
| episodes                | 4376          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 437401        |
| policy_loss             | 0.8211087     |
| qf1_loss                | 0.0003150673  |
| qf2_loss                | 0.0002101823  |
| time_elapsed            | 2109          |
| total timesteps         | 437500        |
| value_loss              | 0.00018844397 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012153146  |
| ent_coef_loss           | 3.1385384     |
| entropy                 | 1.960614      |
| ep_rewmean              | -1.79         |
| episodes                | 4380          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 437801        |
| policy_loss             | 0.75954634    |
| qf1_loss                | 0.013166296   |
| qf2_loss                | 0.013264671   |
| time_elapsed            | 2110          |
| total timesteps         | 437900        |
| value_loss              | 0.00018653253 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012469299  |
| ent_coef_loss           | 0.1436317     |
| entropy                 | 2.2754202     |
| ep_rewmean              | -1.77         |
| episodes                | 4384          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 438201        |
| policy_loss             | 0.82393       |
| qf1_loss                | 0.0003814154  |
| qf2_loss                | 0.00036692643 |
| time_elapsed            | 2112          |
| total timesteps         | 438300        |
| value_loss              | 0.00033117653 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012420887  |
| ent_coef_loss           | 3.8856082     |
| entropy                 | 2.3437548     |
| ep_rewmean              | -1.76         |
| episodes                | 4388          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 438601        |
| policy_loss             | 0.79892087    |
| qf1_loss                | 0.00050063187 |
| qf2_loss                | 0.00047339202 |
| time_elapsed            | 2114          |
| total timesteps         | 438700        |
| value_loss              | 0.00031023502 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001242392   |
| ent_coef_loss           | 3.0989757     |
| entropy                 | 2.0940804     |
| ep_rewmean              | -1.77         |
| episodes                | 4392          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 439001        |
| policy_loss             | 0.8283607     |
| qf1_loss                | 0.013092354   |
| qf2_loss                | 0.013233677   |
| time_elapsed            | 2116          |
| total timesteps         | 439100        |
| value_loss              | 0.00023065243 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012102405  |
| ent_coef_loss           | 0.8969821     |
| entropy                 | 1.9405956     |
| ep_rewmean              | -1.78         |
| episodes                | 4396          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 439401        |
| policy_loss             | 0.7955119     |
| qf1_loss                | 0.0041749906  |
| qf2_loss                | 0.004182634   |
| time_elapsed            | 2118          |
| total timesteps         | 439500        |
| value_loss              | 0.00025318033 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.001164215  |
| ent_coef_loss           | 5.082179     |
| entropy                 | 1.674902     |
| ep_rewmean              | -1.8         |
| episodes                | 4400         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 439801       |
| policy_loss             | 0.7311231    |
| qf1_loss                | 0.0002533817 |
| qf2_loss                | 0.0002219684 |
| time_elapsed            | 2120         |
| total timesteps         | 439900       |
| value_loss              | 0.0003349703 |
------------------------------------------
Eval num_timesteps=440000, episode_reward=-2.47 +/- 1.35
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011372205  |
| ent_coef_loss           | 2.6049252     |
| entropy                 | 2.0874953     |
| ep_rewmean              | -1.8          |
| episodes                | 4404          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 440201        |
| policy_loss             | 0.8056007     |
| qf1_loss                | 0.0097947465  |
| qf2_loss                | 0.0095826825  |
| time_elapsed            | 2122          |
| total timesteps         | 440300        |
| value_loss              | 0.00026301976 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0011388919 |
| ent_coef_loss           | 1.7287372    |
| entropy                 | 1.7973163    |
| ep_rewmean              | -1.83        |
| episodes                | 4408         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 440601       |
| policy_loss             | 0.8162532    |
| qf1_loss                | 0.008533292  |
| qf2_loss                | 0.008560809  |
| time_elapsed            | 2124         |
| total timesteps         | 440700       |
| value_loss              | 0.0003845534 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001194296   |
| ent_coef_loss           | -2.153576     |
| entropy                 | 2.0589776     |
| ep_rewmean              | -1.88         |
| episodes                | 4412          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 441001        |
| policy_loss             | 0.78874624    |
| qf1_loss                | 0.008474133   |
| qf2_loss                | 0.008759329   |
| time_elapsed            | 2126          |
| total timesteps         | 441100        |
| value_loss              | 0.00036111375 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012212719  |
| ent_coef_loss           | -3.7024899    |
| entropy                 | 2.202691      |
| ep_rewmean              | -1.94         |
| episodes                | 4416          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 441401        |
| policy_loss             | 0.73117626    |
| qf1_loss                | 0.0003782767  |
| qf2_loss                | 0.00034385806 |
| time_elapsed            | 2128          |
| total timesteps         | 441500        |
| value_loss              | 0.00032089796 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0012112989  |
| ent_coef_loss           | -0.84758115   |
| entropy                 | 2.3475854     |
| ep_rewmean              | -1.99         |
| episodes                | 4420          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 441801        |
| policy_loss             | 0.7527059     |
| qf1_loss                | 0.0074130623  |
| qf2_loss                | 0.0070735672  |
| time_elapsed            | 2130          |
| total timesteps         | 441900        |
| value_loss              | 0.00030199537 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011813861  |
| ent_coef_loss           | -2.3069715    |
| entropy                 | 2.0100265     |
| ep_rewmean              | -2.13         |
| episodes                | 4424          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 442201        |
| policy_loss             | 0.735903      |
| qf1_loss                | 0.00029348745 |
| qf2_loss                | 0.00026547856 |
| time_elapsed            | 2132          |
| total timesteps         | 442300        |
| value_loss              | 0.00030529575 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011352528  |
| ent_coef_loss           | 5.060217      |
| entropy                 | 2.078313      |
| ep_rewmean              | -2.13         |
| episodes                | 4428          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 442601        |
| policy_loss             | 0.70419645    |
| qf1_loss                | 0.0003889821  |
| qf2_loss                | 0.00046091073 |
| time_elapsed            | 2134          |
| total timesteps         | 442700        |
| value_loss              | 0.00021387983 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001066602   |
| ent_coef_loss           | -2.3020263    |
| entropy                 | 1.8151209     |
| ep_rewmean              | -2.12         |
| episodes                | 4432          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 443001        |
| policy_loss             | 0.7115498     |
| qf1_loss                | 0.0025388105  |
| qf2_loss                | 0.0027459916  |
| time_elapsed            | 2135          |
| total timesteps         | 443100        |
| value_loss              | 0.00018873395 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010177096 |
| ent_coef_loss           | 0.3493601    |
| entropy                 | 1.726598     |
| ep_rewmean              | -2.15        |
| episodes                | 4436         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 443401       |
| policy_loss             | 0.6573051    |
| qf1_loss                | 0.0035444673 |
| qf2_loss                | 0.0036444673 |
| time_elapsed            | 2137         |
| total timesteps         | 443500       |
| value_loss              | 0.0002135963 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009920622  |
| ent_coef_loss           | 6.8335123     |
| entropy                 | 2.1269135     |
| ep_rewmean              | -2.13         |
| episodes                | 4440          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 443801        |
| policy_loss             | 0.66228056    |
| qf1_loss                | 0.0002818606  |
| qf2_loss                | 0.00023354657 |
| time_elapsed            | 2139          |
| total timesteps         | 443900        |
| value_loss              | 0.000315128   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010088541  |
| ent_coef_loss           | 5.4908056     |
| entropy                 | 1.4729593     |
| ep_rewmean              | -2.14         |
| episodes                | 4444          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 444201        |
| policy_loss             | 0.61165094    |
| qf1_loss                | 0.00023904533 |
| qf2_loss                | 0.00016700572 |
| time_elapsed            | 2141          |
| total timesteps         | 444300        |
| value_loss              | 0.00025163364 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010024041  |
| ent_coef_loss           | -4.390773     |
| entropy                 | 1.9154845     |
| ep_rewmean              | -2.2          |
| episodes                | 4448          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 444601        |
| policy_loss             | 0.6377584     |
| qf1_loss                | 0.0029422543  |
| qf2_loss                | 0.0029399993  |
| time_elapsed            | 2143          |
| total timesteps         | 444700        |
| value_loss              | 0.00015430864 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001012809   |
| ent_coef_loss           | 1.9145977     |
| entropy                 | 1.8043586     |
| ep_rewmean              | -2.18         |
| episodes                | 4452          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 445001        |
| policy_loss             | 0.5770092     |
| qf1_loss                | 0.00019165804 |
| qf2_loss                | 0.0002055147  |
| time_elapsed            | 2145          |
| total timesteps         | 445100        |
| value_loss              | 0.00022165102 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0010398661   |
| ent_coef_loss           | 2.5487115      |
| entropy                 | 2.453835       |
| ep_rewmean              | -2.16          |
| episodes                | 4456           |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -2.2           |
| n_updates               | 445401         |
| policy_loss             | 0.58228105     |
| qf1_loss                | 0.00028496547  |
| qf2_loss                | 0.00034761036  |
| time_elapsed            | 2147           |
| total timesteps         | 445500         |
| value_loss              | 0.000116286385 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010585246  |
| ent_coef_loss           | 0.9174333     |
| entropy                 | 2.3389175     |
| ep_rewmean              | -2.15         |
| episodes                | 4460          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 445801        |
| policy_loss             | 0.5792453     |
| qf1_loss                | 0.005388975   |
| qf2_loss                | 0.0053408076  |
| time_elapsed            | 2149          |
| total timesteps         | 445900        |
| value_loss              | 0.00018589504 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010615686  |
| ent_coef_loss           | 0.8376304     |
| entropy                 | 2.33257       |
| ep_rewmean              | -2.15         |
| episodes                | 4464          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 446201        |
| policy_loss             | 0.53953564    |
| qf1_loss                | 0.004541265   |
| qf2_loss                | 0.0045764796  |
| time_elapsed            | 2151          |
| total timesteps         | 446300        |
| value_loss              | 0.00021047957 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010493546 |
| ent_coef_loss           | 0.33020407   |
| entropy                 | 2.31247      |
| ep_rewmean              | -2.16        |
| episodes                | 4468         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 446601       |
| policy_loss             | 0.5467552    |
| qf1_loss                | 0.0061555095 |
| qf2_loss                | 0.0061385953 |
| time_elapsed            | 2153         |
| total timesteps         | 446700       |
| value_loss              | 0.0001494459 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0009991848 |
| ent_coef_loss           | -3.9554262   |
| entropy                 | 2.1736362    |
| ep_rewmean              | -2.17        |
| episodes                | 4472         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 447001       |
| policy_loss             | 0.5683886    |
| qf1_loss                | 0.0021697737 |
| qf2_loss                | 0.0020468757 |
| time_elapsed            | 2155         |
| total timesteps         | 447100       |
| value_loss              | 0.0002502186 |
------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0009894982 |
| ent_coef_loss           | 0.9622011    |
| entropy                 | 2.3898284    |
| ep_rewmean              | -2.17        |
| episodes                | 4476         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 447401       |
| policy_loss             | 0.535761     |
| qf1_loss                | 0.0040182434 |
| qf2_loss                | 0.0044353935 |
| time_elapsed            | 2156         |
| total timesteps         | 447500       |
| value_loss              | 0.0002440684 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000989144   |
| ent_coef_loss           | -7.0767574    |
| entropy                 | 2.0742652     |
| ep_rewmean              | -2.24         |
| episodes                | 4480          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 447801        |
| policy_loss             | 0.55669105    |
| qf1_loss                | 0.0038339342  |
| qf2_loss                | 0.0038126437  |
| time_elapsed            | 2158          |
| total timesteps         | 447900        |
| value_loss              | 0.00023838447 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009869038  |
| ent_coef_loss           | 8.69339       |
| entropy                 | 2.3754888     |
| ep_rewmean              | -2.27         |
| episodes                | 4484          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 448201        |
| policy_loss             | 0.53024316    |
| qf1_loss                | 0.00027282265 |
| qf2_loss                | 0.0002171985  |
| time_elapsed            | 2160          |
| total timesteps         | 448300        |
| value_loss              | 0.0002218128  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009970383  |
| ent_coef_loss           | 7.5268        |
| entropy                 | 2.7771864     |
| ep_rewmean              | -2.29         |
| episodes                | 4488          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 448601        |
| policy_loss             | 0.51275504    |
| qf1_loss                | 0.00014754012 |
| qf2_loss                | 0.00012410333 |
| time_elapsed            | 2162          |
| total timesteps         | 448700        |
| value_loss              | 0.00013454695 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010227867  |
| ent_coef_loss           | 5.6184325     |
| entropy                 | 2.6479387     |
| ep_rewmean              | -2.28         |
| episodes                | 4492          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 449001        |
| policy_loss             | 0.5328758     |
| qf1_loss                | 0.0010077213  |
| qf2_loss                | 0.00077952386 |
| time_elapsed            | 2164          |
| total timesteps         | 449100        |
| value_loss              | 0.0002253641  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010554179  |
| ent_coef_loss           | -1.0875316    |
| entropy                 | 3.0233016     |
| ep_rewmean              | -2.26         |
| episodes                | 4496          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 449401        |
| policy_loss             | 0.54582244    |
| qf1_loss                | 0.011788261   |
| qf2_loss                | 0.011715737   |
| time_elapsed            | 2166          |
| total timesteps         | 449500        |
| value_loss              | 0.00019667648 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010402416  |
| ent_coef_loss           | 0.049949408   |
| entropy                 | 2.8483653     |
| ep_rewmean              | -2.21         |
| episodes                | 4500          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 449801        |
| policy_loss             | 0.50719583    |
| qf1_loss                | 0.00021579402 |
| qf2_loss                | 0.00025708898 |
| time_elapsed            | 2168          |
| total timesteps         | 449900        |
| value_loss              | 0.00022300743 |
-------------------------------------------
Eval num_timesteps=450000, episode_reward=-1.61 +/- 0.51
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010590401 |
| ent_coef_loss           | -4.544879    |
| entropy                 | 2.6365788    |
| ep_rewmean              | -2.17        |
| episodes                | 4504         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 450201       |
| policy_loss             | 0.55883867   |
| qf1_loss                | 0.005568266  |
| qf2_loss                | 0.0052698213 |
| time_elapsed            | 2170         |
| total timesteps         | 450300       |
| value_loss              | 0.0002064882 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010913991  |
| ent_coef_loss           | -6.9485445    |
| entropy                 | 2.7477717     |
| ep_rewmean              | -2.15         |
| episodes                | 4508          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 450601        |
| policy_loss             | 0.49839306    |
| qf1_loss                | 0.0045167413  |
| qf2_loss                | 0.0042787716  |
| time_elapsed            | 2172          |
| total timesteps         | 450700        |
| value_loss              | 0.00020218476 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011226619  |
| ent_coef_loss           | 1.4629083     |
| entropy                 | 2.1316795     |
| ep_rewmean              | -2.12         |
| episodes                | 4512          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 451001        |
| policy_loss             | 0.46400034    |
| qf1_loss                | 0.001924089   |
| qf2_loss                | 0.001838001   |
| time_elapsed            | 2174          |
| total timesteps         | 451100        |
| value_loss              | 0.00021984329 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0011524328  |
| ent_coef_loss           | 1.885591      |
| entropy                 | 2.5441968     |
| ep_rewmean              | -2.07         |
| episodes                | 4516          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 451401        |
| policy_loss             | 0.5234186     |
| qf1_loss                | 0.008295368   |
| qf2_loss                | 0.0081555145  |
| time_elapsed            | 2176          |
| total timesteps         | 451500        |
| value_loss              | 0.00018263399 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001149171   |
| ent_coef_loss           | -3.6253684    |
| entropy                 | 2.3670683     |
| ep_rewmean              | -2.05         |
| episodes                | 4520          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 451801        |
| policy_loss             | 0.50264657    |
| qf1_loss                | 0.0036892851  |
| qf2_loss                | 0.003607581   |
| time_elapsed            | 2178          |
| total timesteps         | 451900        |
| value_loss              | 0.00041508247 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010941508  |
| ent_coef_loss           | 0.29466802    |
| entropy                 | 1.8726265     |
| ep_rewmean              | -1.98         |
| episodes                | 4524          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 452201        |
| policy_loss             | 0.55104184    |
| qf1_loss                | 0.008127516   |
| qf2_loss                | 0.008249383   |
| time_elapsed            | 2180          |
| total timesteps         | 452300        |
| value_loss              | 0.00024047466 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010692356  |
| ent_coef_loss           | 5.725168      |
| entropy                 | 2.3392        |
| ep_rewmean              | -1.97         |
| episodes                | 4528          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 452601        |
| policy_loss             | 0.50763494    |
| qf1_loss                | 0.0072593833  |
| qf2_loss                | 0.0073212073  |
| time_elapsed            | 2181          |
| total timesteps         | 452700        |
| value_loss              | 0.00033010275 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010250482  |
| ent_coef_loss           | -4.7381783    |
| entropy                 | 1.983615      |
| ep_rewmean              | -1.96         |
| episodes                | 4532          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 453001        |
| policy_loss             | 0.48813125    |
| qf1_loss                | 0.00023546249 |
| qf2_loss                | 0.00025757408 |
| time_elapsed            | 2183          |
| total timesteps         | 453100        |
| value_loss              | 0.00014778995 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010139344  |
| ent_coef_loss           | -3.26424      |
| entropy                 | 2.316461      |
| ep_rewmean              | -1.93         |
| episodes                | 4536          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 453401        |
| policy_loss             | 0.48444277    |
| qf1_loss                | 0.00021497789 |
| qf2_loss                | 0.00029170024 |
| time_elapsed            | 2185          |
| total timesteps         | 453500        |
| value_loss              | 0.00016877614 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0010236283 |
| ent_coef_loss           | -2.0874567   |
| entropy                 | 2.4649863    |
| ep_rewmean              | -1.91        |
| episodes                | 4540         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.9         |
| n_updates               | 453801       |
| policy_loss             | 0.50576186   |
| qf1_loss                | 0.0014095495 |
| qf2_loss                | 0.0013041195 |
| time_elapsed            | 2187         |
| total timesteps         | 453900       |
| value_loss              | 0.0002547211 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009783196  |
| ent_coef_loss           | -4.0935946    |
| entropy                 | 1.9159414     |
| ep_rewmean              | -1.87         |
| episodes                | 4544          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 454201        |
| policy_loss             | 0.5132172     |
| qf1_loss                | 0.00019774146 |
| qf2_loss                | 0.00016640665 |
| time_elapsed            | 2189          |
| total timesteps         | 454300        |
| value_loss              | 0.00014235944 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001008152   |
| ent_coef_loss           | 6.234991      |
| entropy                 | 1.985115      |
| ep_rewmean              | -1.83         |
| episodes                | 4548          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 454601        |
| policy_loss             | 0.52188027    |
| qf1_loss                | 0.0048009288  |
| qf2_loss                | 0.0045591067  |
| time_elapsed            | 2191          |
| total timesteps         | 454700        |
| value_loss              | 0.00074681966 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010606442  |
| ent_coef_loss           | 6.545356      |
| entropy                 | 1.9589168     |
| ep_rewmean              | -1.83         |
| episodes                | 4552          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 455001        |
| policy_loss             | 0.53514063    |
| qf1_loss                | 0.0005063582  |
| qf2_loss                | 0.00045394956 |
| time_elapsed            | 2193          |
| total timesteps         | 455100        |
| value_loss              | 0.00060823245 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.001086872   |
| ent_coef_loss           | 5.526306      |
| entropy                 | 2.3093944     |
| ep_rewmean              | -1.78         |
| episodes                | 4556          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 455401        |
| policy_loss             | 0.5335954     |
| qf1_loss                | 0.019348321   |
| qf2_loss                | 0.01949335    |
| time_elapsed            | 2195          |
| total timesteps         | 455500        |
| value_loss              | 0.00021606237 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0010320789  |
| ent_coef_loss           | -6.3550367    |
| entropy                 | 1.9218218     |
| ep_rewmean              | -1.75         |
| episodes                | 4560          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 455801        |
| policy_loss             | 0.51942754    |
| qf1_loss                | 0.00022139386 |
| qf2_loss                | 0.00028315798 |
| time_elapsed            | 2197          |
| total timesteps         | 455900        |
| value_loss              | 0.00032655423 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00096223864 |
| ent_coef_loss           | -0.49462128   |
| entropy                 | 1.7675748     |
| ep_rewmean              | -1.74         |
| episodes                | 4564          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 456201        |
| policy_loss             | 0.55468607    |
| qf1_loss                | 0.00071853417 |
| qf2_loss                | 0.00050205254 |
| time_elapsed            | 2199          |
| total timesteps         | 456300        |
| value_loss              | 0.0002486399  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00094074523 |
| ent_coef_loss           | 1.8684824     |
| entropy                 | 1.7027698     |
| ep_rewmean              | -1.77         |
| episodes                | 4568          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 456601        |
| policy_loss             | 0.5085777     |
| qf1_loss                | 0.003785162   |
| qf2_loss                | 0.0041133435  |
| time_elapsed            | 2201          |
| total timesteps         | 456700        |
| value_loss              | 0.000640816   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00093928265 |
| ent_coef_loss           | -4.4558096    |
| entropy                 | 1.8071979     |
| ep_rewmean              | -1.75         |
| episodes                | 4572          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 457001        |
| policy_loss             | 0.5238872     |
| qf1_loss                | 0.0002188372  |
| qf2_loss                | 0.00020139113 |
| time_elapsed            | 2203          |
| total timesteps         | 457100        |
| value_loss              | 0.00017030552 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00091650663 |
| ent_coef_loss           | -3.1909137    |
| entropy                 | 2.1175146     |
| ep_rewmean              | -1.72         |
| episodes                | 4576          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 457401        |
| policy_loss             | 0.55671597    |
| qf1_loss                | 0.0068655107  |
| qf2_loss                | 0.006690464   |
| time_elapsed            | 2205          |
| total timesteps         | 457500        |
| value_loss              | 0.00019255374 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008187687  |
| ent_coef_loss           | -0.80396044   |
| entropy                 | 2.3329854     |
| ep_rewmean              | -1.62         |
| episodes                | 4580          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 457801        |
| policy_loss             | 0.50607055    |
| qf1_loss                | 0.00023362011 |
| qf2_loss                | 0.00015234084 |
| time_elapsed            | 2206          |
| total timesteps         | 457900        |
| value_loss              | 0.00016051167 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007457932  |
| ent_coef_loss           | -4.9427013    |
| entropy                 | 1.8031167     |
| ep_rewmean              | -1.59         |
| episodes                | 4584          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 458201        |
| policy_loss             | 0.5485792     |
| qf1_loss                | 0.00017232614 |
| qf2_loss                | 0.00019003247 |
| time_elapsed            | 2208          |
| total timesteps         | 458300        |
| value_loss              | 9.142673e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00071081537 |
| ent_coef_loss           | 5.485607      |
| entropy                 | 2.0753646     |
| ep_rewmean              | -1.54         |
| episodes                | 4588          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.5          |
| n_updates               | 458601        |
| policy_loss             | 0.53406394    |
| qf1_loss                | 0.00040829973 |
| qf2_loss                | 0.00031097472 |
| time_elapsed            | 2210          |
| total timesteps         | 458700        |
| value_loss              | 0.00015570098 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00067302946 |
| ent_coef_loss           | -6.011052     |
| entropy                 | 2.129921      |
| ep_rewmean              | -1.54         |
| episodes                | 4592          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.5          |
| n_updates               | 459001        |
| policy_loss             | 0.54761654    |
| qf1_loss                | 0.000214133   |
| qf2_loss                | 0.000262764   |
| time_elapsed            | 2212          |
| total timesteps         | 459100        |
| value_loss              | 0.00014183317 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000650654   |
| ent_coef_loss           | 2.86666       |
| entropy                 | 2.4427564     |
| ep_rewmean              | -1.53         |
| episodes                | 4596          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.5          |
| n_updates               | 459401        |
| policy_loss             | 0.5595319     |
| qf1_loss                | 0.0005367361  |
| qf2_loss                | 0.00026244172 |
| time_elapsed            | 2214          |
| total timesteps         | 459500        |
| value_loss              | 0.00014678415 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006525534  |
| ent_coef_loss           | 2.4100797     |
| entropy                 | 2.333736      |
| ep_rewmean              | -1.54         |
| episodes                | 4600          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.5          |
| n_updates               | 459801        |
| policy_loss             | 0.5717738     |
| qf1_loss                | 0.0002740802  |
| qf2_loss                | 0.00019903657 |
| time_elapsed            | 2216          |
| total timesteps         | 459900        |
| value_loss              | 0.0002408599  |
-------------------------------------------
Eval num_timesteps=460000, episode_reward=-1.37 +/- 0.62
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006486674  |
| ent_coef_loss           | -2.1898847    |
| entropy                 | 2.5095007     |
| ep_rewmean              | -1.56         |
| episodes                | 4604          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 460201        |
| policy_loss             | 0.55815107    |
| qf1_loss                | 0.00032995117 |
| qf2_loss                | 0.00025440543 |
| time_elapsed            | 2218          |
| total timesteps         | 460300        |
| value_loss              | 0.00013989292 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00068161235 |
| ent_coef_loss           | -4.323613     |
| entropy                 | 2.9529133     |
| ep_rewmean              | -1.55         |
| episodes                | 4608          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.5          |
| n_updates               | 460601        |
| policy_loss             | 0.5779532     |
| qf1_loss                | 0.00543621    |
| qf2_loss                | 0.0054039513  |
| time_elapsed            | 2220          |
| total timesteps         | 460700        |
| value_loss              | 0.00012360922 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00071866426 |
| ent_coef_loss           | -3.4322767    |
| entropy                 | 2.7950926     |
| ep_rewmean              | -1.56         |
| episodes                | 4612          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 461001        |
| policy_loss             | 0.6046388     |
| qf1_loss                | 0.003972914   |
| qf2_loss                | 0.0043555466  |
| time_elapsed            | 2222          |
| total timesteps         | 461100        |
| value_loss              | 0.00013020268 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007587694  |
| ent_coef_loss           | -8.636072     |
| entropy                 | 2.9178429     |
| ep_rewmean              | -1.53         |
| episodes                | 4616          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.5          |
| n_updates               | 461401        |
| policy_loss             | 0.5771613     |
| qf1_loss                | 0.0031154277  |
| qf2_loss                | 0.003488616   |
| time_elapsed            | 2224          |
| total timesteps         | 461500        |
| value_loss              | 0.00012226679 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007845819  |
| ent_coef_loss           | 12.209841     |
| entropy                 | 3.2404094     |
| ep_rewmean              | -1.51         |
| episodes                | 4620          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.5          |
| n_updates               | 461801        |
| policy_loss             | 0.59816355    |
| qf1_loss                | 0.00043860305 |
| qf2_loss                | 0.00030723144 |
| time_elapsed            | 2226          |
| total timesteps         | 461900        |
| value_loss              | 7.740768e-05  |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0008459851   |
| ent_coef_loss           | -0.46532393    |
| entropy                 | 3.6593673      |
| ep_rewmean              | -1.53          |
| episodes                | 4624           |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -1.5           |
| n_updates               | 462201         |
| policy_loss             | 0.62442243     |
| qf1_loss                | 0.002321844    |
| qf2_loss                | 0.0026048964   |
| time_elapsed            | 2228           |
| total timesteps         | 462300         |
| value_loss              | 0.000106250634 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000871534   |
| ent_coef_loss           | -2.4481854    |
| entropy                 | 3.7017536     |
| ep_rewmean              | -1.54         |
| episodes                | 4628          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.5          |
| n_updates               | 462601        |
| policy_loss             | 0.6364971     |
| qf1_loss                | 0.002832904   |
| qf2_loss                | 0.0027963314  |
| time_elapsed            | 2230          |
| total timesteps         | 462700        |
| value_loss              | 0.00018388583 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00083141145 |
| ent_coef_loss           | -4.5698404    |
| entropy                 | 3.270607      |
| ep_rewmean              | -1.55         |
| episodes                | 4632          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.5          |
| n_updates               | 463001        |
| policy_loss             | 0.6171113     |
| qf1_loss                | 0.00019953925 |
| qf2_loss                | 0.00015378013 |
| time_elapsed            | 2232          |
| total timesteps         | 463100        |
| value_loss              | 9.279592e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007851661  |
| ent_coef_loss           | -5.2882156    |
| entropy                 | 2.8076975     |
| ep_rewmean              | -1.58         |
| episodes                | 4636          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 463401        |
| policy_loss             | 0.6485746     |
| qf1_loss                | 0.0033442664  |
| qf2_loss                | 0.003301407   |
| time_elapsed            | 2234          |
| total timesteps         | 463500        |
| value_loss              | 0.00013802832 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000757303   |
| ent_coef_loss           | 1.8105487     |
| entropy                 | 3.21631       |
| ep_rewmean              | -1.63         |
| episodes                | 4640          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 463801        |
| policy_loss             | 0.6722674     |
| qf1_loss                | 0.0006301789  |
| qf2_loss                | 0.0006819641  |
| time_elapsed            | 2236          |
| total timesteps         | 463900        |
| value_loss              | 0.00019027104 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00076089986  |
| ent_coef_loss           | -0.61089903    |
| entropy                 | 3.5082054      |
| ep_rewmean              | -1.7           |
| episodes                | 4644           |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -1.7           |
| n_updates               | 464201         |
| policy_loss             | 0.65119195     |
| qf1_loss                | 0.00016047548  |
| qf2_loss                | 0.00017996697  |
| time_elapsed            | 2238           |
| total timesteps         | 464300         |
| value_loss              | 0.000104135936 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000715686   |
| ent_coef_loss           | -4.5344152    |
| entropy                 | 3.190233      |
| ep_rewmean              | -1.69         |
| episodes                | 4648          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 464601        |
| policy_loss             | 0.6405543     |
| qf1_loss                | 0.00025269977 |
| qf2_loss                | 0.00019758267 |
| time_elapsed            | 2240          |
| total timesteps         | 464700        |
| value_loss              | 0.00025544642 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006716608  |
| ent_coef_loss           | 1.1358765     |
| entropy                 | 3.2015266     |
| ep_rewmean              | -1.67         |
| episodes                | 4652          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 465001        |
| policy_loss             | 0.6473954     |
| qf1_loss                | 0.0033233743  |
| qf2_loss                | 0.003243337   |
| time_elapsed            | 2242          |
| total timesteps         | 465100        |
| value_loss              | 4.4909542e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000697965   |
| ent_coef_loss           | 11.411459     |
| entropy                 | 3.3520708     |
| ep_rewmean              | -1.69         |
| episodes                | 4656          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 465401        |
| policy_loss             | 0.6886666     |
| qf1_loss                | 0.01189202    |
| qf2_loss                | 0.011799442   |
| time_elapsed            | 2243          |
| total timesteps         | 465500        |
| value_loss              | 0.00024341547 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007273427  |
| ent_coef_loss           | 3.6233616     |
| entropy                 | 3.0494225     |
| ep_rewmean              | -1.75         |
| episodes                | 4660          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 465801        |
| policy_loss             | 0.6774622     |
| qf1_loss                | 0.0068601975  |
| qf2_loss                | 0.0070300936  |
| time_elapsed            | 2245          |
| total timesteps         | 465900        |
| value_loss              | 0.00020369924 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007548986  |
| ent_coef_loss           | 4.3916583     |
| entropy                 | 3.2209806     |
| ep_rewmean              | -1.75         |
| episodes                | 4664          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 466201        |
| policy_loss             | 0.6663483     |
| qf1_loss                | 0.00017291313 |
| qf2_loss                | 0.00017089024 |
| time_elapsed            | 2247          |
| total timesteps         | 466300        |
| value_loss              | 7.8127116e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007445982  |
| ent_coef_loss           | 4.066801      |
| entropy                 | 2.885547      |
| ep_rewmean              | -1.68         |
| episodes                | 4668          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 466601        |
| policy_loss             | 0.6740727     |
| qf1_loss                | 0.00032844383 |
| qf2_loss                | 0.00029729476 |
| time_elapsed            | 2249          |
| total timesteps         | 466700        |
| value_loss              | 0.00019986395 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007402583  |
| ent_coef_loss           | 4.482854      |
| entropy                 | 3.0151858     |
| ep_rewmean              | -1.69         |
| episodes                | 4672          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 467001        |
| policy_loss             | 0.6678542     |
| qf1_loss                | 0.00207349    |
| qf2_loss                | 0.0018026971  |
| time_elapsed            | 2251          |
| total timesteps         | 467100        |
| value_loss              | 0.00012882442 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007707495  |
| ent_coef_loss           | -5.856161     |
| entropy                 | 3.2401445     |
| ep_rewmean              | -1.69         |
| episodes                | 4676          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 467401        |
| policy_loss             | 0.6829597     |
| qf1_loss                | 0.0070117866  |
| qf2_loss                | 0.0065108393  |
| time_elapsed            | 2253          |
| total timesteps         | 467500        |
| value_loss              | 0.00011768975 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00075802155 |
| ent_coef_loss           | -8.543901     |
| entropy                 | 3.3860657     |
| ep_rewmean              | -1.72         |
| episodes                | 4680          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 467801        |
| policy_loss             | 0.7111382     |
| qf1_loss                | 0.0033894437  |
| qf2_loss                | 0.0034442276  |
| time_elapsed            | 2255          |
| total timesteps         | 467900        |
| value_loss              | 0.00018921666 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00075381156 |
| ent_coef_loss           | 2.6331756     |
| entropy                 | 3.0595922     |
| ep_rewmean              | -1.69         |
| episodes                | 4684          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 468201        |
| policy_loss             | 0.6982158     |
| qf1_loss                | 0.00025664887 |
| qf2_loss                | 0.00022164358 |
| time_elapsed            | 2257          |
| total timesteps         | 468300        |
| value_loss              | 0.0002595533  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00075481395 |
| ent_coef_loss           | 4.550332      |
| entropy                 | 2.8613272     |
| ep_rewmean              | -1.7          |
| episodes                | 4688          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 468601        |
| policy_loss             | 0.6875292     |
| qf1_loss                | 0.0002513398  |
| qf2_loss                | 0.00025472743 |
| time_elapsed            | 2259          |
| total timesteps         | 468700        |
| value_loss              | 0.0001234385  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00078753283 |
| ent_coef_loss           | -1.4878452    |
| entropy                 | 2.9413657     |
| ep_rewmean              | -1.69         |
| episodes                | 4692          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 469001        |
| policy_loss             | 0.67435837    |
| qf1_loss                | 0.0066676233  |
| qf2_loss                | 0.006143343   |
| time_elapsed            | 2261          |
| total timesteps         | 469100        |
| value_loss              | 6.449591e-05  |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0007810343 |
| ent_coef_loss           | -5.684509    |
| entropy                 | 2.9238188    |
| ep_rewmean              | -1.7         |
| episodes                | 4696         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.7         |
| n_updates               | 469401       |
| policy_loss             | 0.6931729    |
| qf1_loss                | 0.0036455342 |
| qf2_loss                | 0.0036573012 |
| time_elapsed            | 2263         |
| total timesteps         | 469500       |
| value_loss              | 6.740191e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00075878715 |
| ent_coef_loss           | -5.8350315    |
| entropy                 | 2.825447      |
| ep_rewmean              | -1.74         |
| episodes                | 4700          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 469801        |
| policy_loss             | 0.70488226    |
| qf1_loss                | 0.00027502148 |
| qf2_loss                | 0.00032679416 |
| time_elapsed            | 2265          |
| total timesteps         | 469900        |
| value_loss              | 6.195881e-05  |
-------------------------------------------
Eval num_timesteps=470000, episode_reward=-1.64 +/- 0.64
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007661553  |
| ent_coef_loss           | -4.2665663    |
| entropy                 | 3.3660474     |
| ep_rewmean              | -1.72         |
| episodes                | 4704          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 470201        |
| policy_loss             | 0.70198774    |
| qf1_loss                | 0.00021329401 |
| qf2_loss                | 0.00028220646 |
| time_elapsed            | 2267          |
| total timesteps         | 470300        |
| value_loss              | 0.00012224494 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00075526076 |
| ent_coef_loss           | -3.3801668    |
| entropy                 | 3.0569625     |
| ep_rewmean              | -1.71         |
| episodes                | 4708          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 470601        |
| policy_loss             | 0.70056736    |
| qf1_loss                | 0.0054580607  |
| qf2_loss                | 0.0055529173  |
| time_elapsed            | 2269          |
| total timesteps         | 470700        |
| value_loss              | 4.9475595e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007084079  |
| ent_coef_loss           | -10.672269    |
| entropy                 | 2.8420315     |
| ep_rewmean              | -1.72         |
| episodes                | 4712          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 471001        |
| policy_loss             | 0.7007432     |
| qf1_loss                | 0.0040268465  |
| qf2_loss                | 0.003945918   |
| time_elapsed            | 2271          |
| total timesteps         | 471100        |
| value_loss              | 0.00015474978 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00067027775 |
| ent_coef_loss           | -5.822797     |
| entropy                 | 2.4333653     |
| ep_rewmean              | -1.77         |
| episodes                | 4716          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 471401        |
| policy_loss             | 0.6974189     |
| qf1_loss                | 0.002688624   |
| qf2_loss                | 0.002590385   |
| time_elapsed            | 2273          |
| total timesteps         | 471500        |
| value_loss              | 8.0481914e-05 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.00066569966  |
| ent_coef_loss           | -3.7532852     |
| entropy                 | 1.9351478      |
| ep_rewmean              | -1.78          |
| episodes                | 4720           |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -1.8           |
| n_updates               | 471801         |
| policy_loss             | 0.6969362      |
| qf1_loss                | 0.0001295005   |
| qf2_loss                | 0.0001066493   |
| time_elapsed            | 2274           |
| total timesteps         | 471900         |
| value_loss              | 0.000105197134 |
--------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0006505727   |
| ent_coef_loss           | -6.6250644     |
| entropy                 | 2.4554412      |
| ep_rewmean              | -1.7           |
| episodes                | 4724           |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -1.7           |
| n_updates               | 472201         |
| policy_loss             | 0.69653344     |
| qf1_loss                | 0.001865875    |
| qf2_loss                | 0.0017348316   |
| time_elapsed            | 2276           |
| total timesteps         | 472300         |
| value_loss              | 0.000110050314 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00067949976 |
| ent_coef_loss           | 1.7677971     |
| entropy                 | 2.4082682     |
| ep_rewmean              | -1.68         |
| episodes                | 4728          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 472601        |
| policy_loss             | 0.6824012     |
| qf1_loss                | 0.0016787975  |
| qf2_loss                | 0.0015585413  |
| time_elapsed            | 2278          |
| total timesteps         | 472700        |
| value_loss              | 6.8109846e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00067070517 |
| ent_coef_loss           | 8.226679      |
| entropy                 | 2.2434554     |
| ep_rewmean              | -1.67         |
| episodes                | 4732          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 473001        |
| policy_loss             | 0.67136323    |
| qf1_loss                | 0.00039441796 |
| qf2_loss                | 0.00026819488 |
| time_elapsed            | 2280          |
| total timesteps         | 473100        |
| value_loss              | 5.819738e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006267757  |
| ent_coef_loss           | 1.9370666     |
| entropy                 | 2.4995995     |
| ep_rewmean              | -1.64         |
| episodes                | 4736          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 473401        |
| policy_loss             | 0.6638315     |
| qf1_loss                | 0.00013618839 |
| qf2_loss                | 0.0001317492  |
| time_elapsed            | 2282          |
| total timesteps         | 473500        |
| value_loss              | 3.7803176e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005808232  |
| ent_coef_loss           | -0.61114776   |
| entropy                 | 1.8190224     |
| ep_rewmean              | -1.59         |
| episodes                | 4740          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 473801        |
| policy_loss             | 0.67702746    |
| qf1_loss                | 0.00016782504 |
| qf2_loss                | 0.00018932033 |
| time_elapsed            | 2284          |
| total timesteps         | 473900        |
| value_loss              | 9.55194e-05   |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0005533107   |
| ent_coef_loss           | -4.7517986     |
| entropy                 | 2.168969       |
| ep_rewmean              | -1.52          |
| episodes                | 4744           |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -1.5           |
| n_updates               | 474201         |
| policy_loss             | 0.66876835     |
| qf1_loss                | 0.0034726767   |
| qf2_loss                | 0.0028628896   |
| time_elapsed            | 2286           |
| total timesteps         | 474300         |
| value_loss              | 0.000105655396 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00055077183 |
| ent_coef_loss           | -4.378905     |
| entropy                 | 1.9775876     |
| ep_rewmean              | -1.58         |
| episodes                | 4748          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.6          |
| n_updates               | 474601        |
| policy_loss             | 0.665255      |
| qf1_loss                | 0.005959922   |
| qf2_loss                | 0.005780507   |
| time_elapsed            | 2288          |
| total timesteps         | 474700        |
| value_loss              | 5.7920923e-05 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0005579376 |
| ent_coef_loss           | -2.3425937   |
| entropy                 | 2.0318725    |
| ep_rewmean              | -1.59        |
| episodes                | 4752         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.6         |
| n_updates               | 475001       |
| policy_loss             | 0.66027004   |
| qf1_loss                | 0.005876898  |
| qf2_loss                | 0.0067695742 |
| time_elapsed            | 2290         |
| total timesteps         | 475100       |
| value_loss              | 8.415902e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00057508604 |
| ent_coef_loss           | -8.65343      |
| entropy                 | 2.5518794     |
| ep_rewmean              | -1.69         |
| episodes                | 4756          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.7          |
| n_updates               | 475401        |
| policy_loss             | 0.68019676    |
| qf1_loss                | 0.00022904368 |
| qf2_loss                | 0.00026886456 |
| time_elapsed            | 2292          |
| total timesteps         | 475500        |
| value_loss              | 0.00014261823 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00060458126 |
| ent_coef_loss           | 5.3052373     |
| entropy                 | 2.138213      |
| ep_rewmean              | -1.87         |
| episodes                | 4760          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 475801        |
| policy_loss             | 0.6638232     |
| qf1_loss                | 0.0063936524  |
| qf2_loss                | 0.0064188996  |
| time_elapsed            | 2294          |
| total timesteps         | 475900        |
| value_loss              | 0.00014916516 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00061929633 |
| ent_coef_loss           | -8.674538     |
| entropy                 | 3.2748637     |
| ep_rewmean              | -1.93         |
| episodes                | 4764          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 476201        |
| policy_loss             | 0.71287674    |
| qf1_loss                | 0.00427046    |
| qf2_loss                | 0.0042648674  |
| time_elapsed            | 2296          |
| total timesteps         | 476300        |
| value_loss              | 6.653845e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00069128623 |
| ent_coef_loss           | -4.872803     |
| entropy                 | 2.7236156     |
| ep_rewmean              | -1.99         |
| episodes                | 4768          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 476601        |
| policy_loss             | 0.65582466    |
| qf1_loss                | 0.00019015375 |
| qf2_loss                | 0.00017347126 |
| time_elapsed            | 2297          |
| total timesteps         | 476700        |
| value_loss              | 0.00021300436 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00074075867 |
| ent_coef_loss           | -1.975097     |
| entropy                 | 3.3518124     |
| ep_rewmean              | -2.04         |
| episodes                | 4772          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 477001        |
| policy_loss             | 0.7204125     |
| qf1_loss                | 0.00013804012 |
| qf2_loss                | 0.00014940539 |
| time_elapsed            | 2299          |
| total timesteps         | 477100        |
| value_loss              | 0.0001146534  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007751558  |
| ent_coef_loss           | 3.8853784     |
| entropy                 | 2.7806296     |
| ep_rewmean              | -2.04         |
| episodes                | 4776          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 477401        |
| policy_loss             | 0.68163735    |
| qf1_loss                | 0.00022272755 |
| qf2_loss                | 0.000225481   |
| time_elapsed            | 2301          |
| total timesteps         | 477500        |
| value_loss              | 0.00016560167 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00079658354 |
| ent_coef_loss           | -6.585232     |
| entropy                 | 2.9754906     |
| ep_rewmean              | -2.04         |
| episodes                | 4780          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 477801        |
| policy_loss             | 0.7073599     |
| qf1_loss                | 0.005315249   |
| qf2_loss                | 0.005235636   |
| time_elapsed            | 2303          |
| total timesteps         | 477900        |
| value_loss              | 0.00018229251 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008074898  |
| ent_coef_loss           | -3.202352     |
| entropy                 | 3.054585      |
| ep_rewmean              | -2.07         |
| episodes                | 4784          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 478201        |
| policy_loss             | 0.70796525    |
| qf1_loss                | 0.0057151276  |
| qf2_loss                | 0.0058251703  |
| time_elapsed            | 2305          |
| total timesteps         | 478300        |
| value_loss              | 7.6435186e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00081936194 |
| ent_coef_loss           | 9.04031       |
| entropy                 | 3.231894      |
| ep_rewmean              | -2.08         |
| episodes                | 4788          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 478601        |
| policy_loss             | 0.6898538     |
| qf1_loss                | 0.00020768633 |
| qf2_loss                | 0.00018315917 |
| time_elapsed            | 2307          |
| total timesteps         | 478700        |
| value_loss              | 0.00016135228 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00082226883 |
| ent_coef_loss           | -1.6672229    |
| entropy                 | 3.2957017     |
| ep_rewmean              | -2.11         |
| episodes                | 4792          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 479001        |
| policy_loss             | 0.719782      |
| qf1_loss                | 0.00022001381 |
| qf2_loss                | 0.00024429188 |
| time_elapsed            | 2309          |
| total timesteps         | 479100        |
| value_loss              | 0.00013621649 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00080229505 |
| ent_coef_loss           | 1.050559      |
| entropy                 | 3.568914      |
| ep_rewmean              | -2.09         |
| episodes                | 4796          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 479401        |
| policy_loss             | 0.7121854     |
| qf1_loss                | 0.00022477086 |
| qf2_loss                | 0.000144015   |
| time_elapsed            | 2311          |
| total timesteps         | 479500        |
| value_loss              | 0.00013417311 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0007528578   |
| ent_coef_loss           | -4.905283      |
| entropy                 | 3.138801       |
| ep_rewmean              | -2.1           |
| episodes                | 4800           |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -2.1           |
| n_updates               | 479801         |
| policy_loss             | 0.7025416      |
| qf1_loss                | 0.00020677944  |
| qf2_loss                | 0.00021371162  |
| time_elapsed            | 2313           |
| total timesteps         | 479900         |
| value_loss              | 0.000100196194 |
--------------------------------------------
Eval num_timesteps=480000, episode_reward=-1.82 +/- 0.77
Episode length: 100.00 +/- 0.00
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007103329  |
| ent_coef_loss           | 11.67761      |
| entropy                 | 3.4513743     |
| ep_rewmean              | -2.11         |
| episodes                | 4804          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 480201        |
| policy_loss             | 0.6818945     |
| qf1_loss                | 0.00043208935 |
| qf2_loss                | 0.00040359568 |
| time_elapsed            | 2315          |
| total timesteps         | 480300        |
| value_loss              | 0.0001303273  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007147311  |
| ent_coef_loss           | -5.551684     |
| entropy                 | 3.4797626     |
| ep_rewmean              | -2.15         |
| episodes                | 4808          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 480601        |
| policy_loss             | 0.7296457     |
| qf1_loss                | 0.00018945147 |
| qf2_loss                | 0.0001506758  |
| time_elapsed            | 2317          |
| total timesteps         | 480700        |
| value_loss              | 0.00012653731 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007298121  |
| ent_coef_loss           | -4.229721     |
| entropy                 | 2.795023      |
| ep_rewmean              | -2.1          |
| episodes                | 4812          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 481001        |
| policy_loss             | 0.71843326    |
| qf1_loss                | 0.00024838545 |
| qf2_loss                | 0.00016493569 |
| time_elapsed            | 2319          |
| total timesteps         | 481100        |
| value_loss              | 5.7296173e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007659044  |
| ent_coef_loss           | 0.38141346    |
| entropy                 | 3.285183      |
| ep_rewmean              | -2.05         |
| episodes                | 4816          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 481401        |
| policy_loss             | 0.72405577    |
| qf1_loss                | 0.00019832414 |
| qf2_loss                | 0.00014913613 |
| time_elapsed            | 2321          |
| total timesteps         | 481500        |
| value_loss              | 9.719685e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00074117805 |
| ent_coef_loss           | -4.704509     |
| entropy                 | 3.2493558     |
| ep_rewmean              | -2.01         |
| episodes                | 4820          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 481801        |
| policy_loss             | 0.740373      |
| qf1_loss                | 0.0022821994  |
| qf2_loss                | 0.0022068315  |
| time_elapsed            | 2323          |
| total timesteps         | 481900        |
| value_loss              | 7.63867e-05   |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00070981384 |
| ent_coef_loss           | -4.6136727    |
| entropy                 | 2.9169197     |
| ep_rewmean              | -2.05         |
| episodes                | 4824          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 482201        |
| policy_loss             | 0.6996088     |
| qf1_loss                | 0.0042997105  |
| qf2_loss                | 0.00400505    |
| time_elapsed            | 2324          |
| total timesteps         | 482300        |
| value_loss              | 0.00028617383 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00072037353 |
| ent_coef_loss           | 1.5942065     |
| entropy                 | 3.1106548     |
| ep_rewmean              | -2.12         |
| episodes                | 4828          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 482601        |
| policy_loss             | 0.71103185    |
| qf1_loss                | 0.0052247327  |
| qf2_loss                | 0.005302646   |
| time_elapsed            | 2326          |
| total timesteps         | 482700        |
| value_loss              | 0.00013896456 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0007307641 |
| ent_coef_loss           | 6.8349357    |
| entropy                 | 3.0342379    |
| ep_rewmean              | -2.15        |
| episodes                | 4832         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -2.2         |
| n_updates               | 483001       |
| policy_loss             | 0.69803435   |
| qf1_loss                | 0.007856736  |
| qf2_loss                | 0.007947956  |
| time_elapsed            | 2328         |
| total timesteps         | 483100       |
| value_loss              | 0.000150926  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00072060956 |
| ent_coef_loss           | -1.8971084    |
| entropy                 | 3.0382056     |
| ep_rewmean              | -2.17         |
| episodes                | 4836          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 483401        |
| policy_loss             | 0.68800485    |
| qf1_loss                | 0.003696519   |
| qf2_loss                | 0.003626153   |
| time_elapsed            | 2330          |
| total timesteps         | 483500        |
| value_loss              | 0.00010526713 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00068671757 |
| ent_coef_loss           | 2.5790458     |
| entropy                 | 3.0281286     |
| ep_rewmean              | -2.19         |
| episodes                | 4840          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 483801        |
| policy_loss             | 0.7179369     |
| qf1_loss                | 0.00459462    |
| qf2_loss                | 0.0046477867  |
| time_elapsed            | 2332          |
| total timesteps         | 483900        |
| value_loss              | 8.0618614e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006680445  |
| ent_coef_loss           | -11.463748    |
| entropy                 | 2.9008431     |
| ep_rewmean              | -2.21         |
| episodes                | 4844          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 484201        |
| policy_loss             | 0.7350081     |
| qf1_loss                | 0.00025732105 |
| qf2_loss                | 0.00025595372 |
| time_elapsed            | 2334          |
| total timesteps         | 484300        |
| value_loss              | 0.00015465403 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000654345   |
| ent_coef_loss           | 5.08249       |
| entropy                 | 2.267085      |
| ep_rewmean              | -2.19         |
| episodes                | 4848          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 484601        |
| policy_loss             | 0.66816384    |
| qf1_loss                | 0.011443011   |
| qf2_loss                | 0.011690969   |
| time_elapsed            | 2336          |
| total timesteps         | 484700        |
| value_loss              | 0.00016340513 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00062933745 |
| ent_coef_loss           | 1.6084559     |
| entropy                 | 2.3905058     |
| ep_rewmean              | -2.22         |
| episodes                | 4852          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 485001        |
| policy_loss             | 0.69192636    |
| qf1_loss                | 0.0020739092  |
| qf2_loss                | 0.002127945   |
| time_elapsed            | 2338          |
| total timesteps         | 485100        |
| value_loss              | 0.00020045748 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00060742145 |
| ent_coef_loss           | -3.9357557    |
| entropy                 | 1.7011936     |
| ep_rewmean              | -2.12         |
| episodes                | 4856          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 485401        |
| policy_loss             | 0.6894116     |
| qf1_loss                | 0.0002664894  |
| qf2_loss                | 0.00030780068 |
| time_elapsed            | 2340          |
| total timesteps         | 485500        |
| value_loss              | 0.00013597148 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000592101   |
| ent_coef_loss           | 2.0245101     |
| entropy                 | 1.6198014     |
| ep_rewmean              | -1.88         |
| episodes                | 4860          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 485801        |
| policy_loss             | 0.6932608     |
| qf1_loss                | 0.00043190867 |
| qf2_loss                | 0.0003155236  |
| time_elapsed            | 2342          |
| total timesteps         | 485900        |
| value_loss              | 0.00014769685 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0006042959 |
| ent_coef_loss           | 7.731859     |
| entropy                 | 1.4410896    |
| ep_rewmean              | -1.84        |
| episodes                | 4864         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 486201       |
| policy_loss             | 0.7376804    |
| qf1_loss                | 0.0016885673 |
| qf2_loss                | 0.001991983  |
| time_elapsed            | 2344         |
| total timesteps         | 486300       |
| value_loss              | 6.097793e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006181985  |
| ent_coef_loss           | 8.289767      |
| entropy                 | 1.9311076     |
| ep_rewmean              | -1.8          |
| episodes                | 4868          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 486601        |
| policy_loss             | 0.6813693     |
| qf1_loss                | 0.0051705865  |
| qf2_loss                | 0.005444212   |
| time_elapsed            | 2346          |
| total timesteps         | 486700        |
| value_loss              | 0.00015079496 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006177615  |
| ent_coef_loss           | -0.9778638    |
| entropy                 | 2.0821295     |
| ep_rewmean              | -1.77         |
| episodes                | 4872          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 487001        |
| policy_loss             | 0.72550654    |
| qf1_loss                | 0.0015048296  |
| qf2_loss                | 0.0016204739  |
| time_elapsed            | 2348          |
| total timesteps         | 487100        |
| value_loss              | 0.00010131272 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00057322433 |
| ent_coef_loss           | 3.443081      |
| entropy                 | 1.8314795     |
| ep_rewmean              | -1.8          |
| episodes                | 4876          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 487401        |
| policy_loss             | 0.6944531     |
| qf1_loss                | 0.00023565086 |
| qf2_loss                | 0.00022821556 |
| time_elapsed            | 2350          |
| total timesteps         | 487500        |
| value_loss              | 0.00015119699 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005632808  |
| ent_coef_loss           | 3.2169728     |
| entropy                 | 1.1728754     |
| ep_rewmean              | -1.78         |
| episodes                | 4880          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 487801        |
| policy_loss             | 0.7099985     |
| qf1_loss                | 0.00028340885 |
| qf2_loss                | 0.00025343845 |
| time_elapsed            | 2351          |
| total timesteps         | 487900        |
| value_loss              | 0.00013025489 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00059044885 |
| ent_coef_loss           | -4.968381     |
| entropy                 | 1.7732804     |
| ep_rewmean              | -1.79         |
| episodes                | 4884          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 488201        |
| policy_loss             | 0.70064586    |
| qf1_loss                | 0.00033949147 |
| qf2_loss                | 0.00042891846 |
| time_elapsed            | 2353          |
| total timesteps         | 488300        |
| value_loss              | 0.00017552839 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006079164  |
| ent_coef_loss           | -3.026524     |
| entropy                 | 1.7386701     |
| ep_rewmean              | -1.78         |
| episodes                | 4888          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 488601        |
| policy_loss             | 0.71352816    |
| qf1_loss                | 0.00026392494 |
| qf2_loss                | 0.00023783771 |
| time_elapsed            | 2355          |
| total timesteps         | 488700        |
| value_loss              | 0.00014364046 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00058599893 |
| ent_coef_loss           | 7.6278496     |
| entropy                 | 1.2938724     |
| ep_rewmean              | -1.78         |
| episodes                | 4892          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 489001        |
| policy_loss             | 0.68335056    |
| qf1_loss                | 0.0011752457  |
| qf2_loss                | 0.0012799446  |
| time_elapsed            | 2357          |
| total timesteps         | 489100        |
| value_loss              | 0.00013485397 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00056745316 |
| ent_coef_loss           | 2.996712      |
| entropy                 | 1.2909901     |
| ep_rewmean              | -1.77         |
| episodes                | 4896          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 489401        |
| policy_loss             | 0.66400886    |
| qf1_loss                | 0.00017008222 |
| qf2_loss                | 0.00022297364 |
| time_elapsed            | 2359          |
| total timesteps         | 489500        |
| value_loss              | 0.00010193552 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0005954071  |
| ent_coef_loss           | 4.162326      |
| entropy                 | 1.7934817     |
| ep_rewmean              | -1.77         |
| episodes                | 4900          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 489801        |
| policy_loss             | 0.7253047     |
| qf1_loss                | 0.0042520924  |
| qf2_loss                | 0.0042797904  |
| time_elapsed            | 2361          |
| total timesteps         | 489900        |
| value_loss              | 8.2200706e-05 |
-------------------------------------------
Eval num_timesteps=490000, episode_reward=-1.59 +/- 0.93
Episode length: 100.00 +/- 0.00
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0006242747 |
| ent_coef_loss           | -7.259796    |
| entropy                 | 1.6939125    |
| ep_rewmean              | -1.78        |
| episodes                | 4904         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 490201       |
| policy_loss             | 0.70799416   |
| qf1_loss                | 0.004089785  |
| qf2_loss                | 0.003837301  |
| time_elapsed            | 2363         |
| total timesteps         | 490300       |
| value_loss              | 9.65104e-05  |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00062427437 |
| ent_coef_loss           | -4.77097      |
| entropy                 | 1.6034193     |
| ep_rewmean              | -1.76         |
| episodes                | 4908          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 490601        |
| policy_loss             | 0.70774424    |
| qf1_loss                | 0.004017277   |
| qf2_loss                | 0.004032923   |
| time_elapsed            | 2365          |
| total timesteps         | 490700        |
| value_loss              | 0.00010786949 |
-------------------------------------------
------------------------------------------
| current_lr              | 0.0003       |
| ent_coef                | 0.0006291511 |
| ent_coef_loss           | -3.7515824   |
| entropy                 | 1.8460575    |
| ep_rewmean              | -1.82        |
| episodes                | 4912         |
| eplenmean               | 100          |
| fps                     | 207          |
| mean 100 episode reward | -1.8         |
| n_updates               | 491001       |
| policy_loss             | 0.7006906    |
| qf1_loss                | 0.0037675265 |
| qf2_loss                | 0.003466862  |
| time_elapsed            | 2367         |
| total timesteps         | 491100       |
| value_loss              | 9.666942e-05 |
------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006263165  |
| ent_coef_loss           | -5.438591     |
| entropy                 | 2.5674164     |
| ep_rewmean              | -1.86         |
| episodes                | 4916          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 491401        |
| policy_loss             | 0.6981676     |
| qf1_loss                | 0.00192271    |
| qf2_loss                | 0.0019558368  |
| time_elapsed            | 2369          |
| total timesteps         | 491500        |
| value_loss              | 0.00016909871 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00060538494 |
| ent_coef_loss           | -4.198316     |
| entropy                 | 1.9749291     |
| ep_rewmean              | -1.9          |
| episodes                | 4920          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 491801        |
| policy_loss             | 0.7049546     |
| qf1_loss                | 0.00014725594 |
| qf2_loss                | 0.00022432677 |
| time_elapsed            | 2371          |
| total timesteps         | 491900        |
| value_loss              | 9.1060385e-05 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006236734  |
| ent_coef_loss           | -0.3308351    |
| entropy                 | 2.2450614     |
| ep_rewmean              | -1.87         |
| episodes                | 4924          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 492201        |
| policy_loss             | 0.6801367     |
| qf1_loss                | 0.00021095315 |
| qf2_loss                | 0.00020059227 |
| time_elapsed            | 2373          |
| total timesteps         | 492300        |
| value_loss              | 7.149088e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006521456  |
| ent_coef_loss           | -2.2177405    |
| entropy                 | 1.7918832     |
| ep_rewmean              | -1.8          |
| episodes                | 4928          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 492601        |
| policy_loss             | 0.66370285    |
| qf1_loss                | 0.0022529364  |
| qf2_loss                | 0.0024550753  |
| time_elapsed            | 2375          |
| total timesteps         | 492700        |
| value_loss              | 0.00017671382 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006492024  |
| ent_coef_loss           | -2.709731     |
| entropy                 | 1.7438035     |
| ep_rewmean              | -1.79         |
| episodes                | 4932          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 493001        |
| policy_loss             | 0.6737877     |
| qf1_loss                | 0.00013417575 |
| qf2_loss                | 0.0001493296  |
| time_elapsed            | 2377          |
| total timesteps         | 493100        |
| value_loss              | 7.904599e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00067152985 |
| ent_coef_loss           | 3.3083029     |
| entropy                 | 2.1204133     |
| ep_rewmean              | -1.84         |
| episodes                | 4936          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.8          |
| n_updates               | 493401        |
| policy_loss             | 0.68426013    |
| qf1_loss                | 0.004651236   |
| qf2_loss                | 0.004739305   |
| time_elapsed            | 2379          |
| total timesteps         | 493500        |
| value_loss              | 0.00012937788 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0006816897  |
| ent_coef_loss           | 8.663155      |
| entropy                 | 2.3511772     |
| ep_rewmean              | -1.89         |
| episodes                | 4940          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 493801        |
| policy_loss             | 0.6500326     |
| qf1_loss                | 0.002053067   |
| qf2_loss                | 0.0019617865  |
| time_elapsed            | 2381          |
| total timesteps         | 493900        |
| value_loss              | 0.00031718283 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.000701057   |
| ent_coef_loss           | -6.83472      |
| entropy                 | 2.2810469     |
| ep_rewmean              | -1.92         |
| episodes                | 4944          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 494201        |
| policy_loss             | 0.68088603    |
| qf1_loss                | 0.0038138058  |
| qf2_loss                | 0.0039356016  |
| time_elapsed            | 2383          |
| total timesteps         | 494300        |
| value_loss              | 0.00014982658 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00069619203 |
| ent_coef_loss           | 1.3009621     |
| entropy                 | 2.227161      |
| ep_rewmean              | -1.94         |
| episodes                | 4948          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -1.9          |
| n_updates               | 494601        |
| policy_loss             | 0.67699015    |
| qf1_loss                | 0.0018009297  |
| qf2_loss                | 0.001603335   |
| time_elapsed            | 2385          |
| total timesteps         | 494700        |
| value_loss              | 0.00010967375 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00071176945 |
| ent_coef_loss           | -8.62842      |
| entropy                 | 2.966175      |
| ep_rewmean              | -1.95         |
| episodes                | 4952          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 495001        |
| policy_loss             | 0.69140565    |
| qf1_loss                | 0.00016106495 |
| qf2_loss                | 0.00019027818 |
| time_elapsed            | 2387          |
| total timesteps         | 495100        |
| value_loss              | 0.00023068594 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0007545261  |
| ent_coef_loss           | 10.999075     |
| entropy                 | 2.4695268     |
| ep_rewmean              | -1.98         |
| episodes                | 4956          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2            |
| n_updates               | 495401        |
| policy_loss             | 0.65913415    |
| qf1_loss                | 0.0004868727  |
| qf2_loss                | 0.00068677514 |
| time_elapsed            | 2388          |
| total timesteps         | 495500        |
| value_loss              | 0.00020341473 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00078612065 |
| ent_coef_loss           | 5.2614202     |
| entropy                 | 2.928816      |
| ep_rewmean              | -2.11         |
| episodes                | 4960          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.1          |
| n_updates               | 495801        |
| policy_loss             | 0.68482304    |
| qf1_loss                | 0.00054145337 |
| qf2_loss                | 0.0005080849  |
| time_elapsed            | 2390          |
| total timesteps         | 495900        |
| value_loss              | 0.0001582191  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008318556  |
| ent_coef_loss           | 3.9818516     |
| entropy                 | 3.0141544     |
| ep_rewmean              | -2.16         |
| episodes                | 4964          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 496201        |
| policy_loss             | 0.66945076    |
| qf1_loss                | 0.000305339   |
| qf2_loss                | 0.00023657188 |
| time_elapsed            | 2392          |
| total timesteps         | 496300        |
| value_loss              | 8.677796e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00085200043 |
| ent_coef_loss           | -2.9225936    |
| entropy                 | 2.7175875     |
| ep_rewmean              | -2.23         |
| episodes                | 4968          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 496601        |
| policy_loss             | 0.6909239     |
| qf1_loss                | 0.00017978091 |
| qf2_loss                | 0.00020656886 |
| time_elapsed            | 2394          |
| total timesteps         | 496700        |
| value_loss              | 9.397251e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00085294835 |
| ent_coef_loss           | -2.834618     |
| entropy                 | 2.725832      |
| ep_rewmean              | -2.22         |
| episodes                | 4972          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 497001        |
| policy_loss             | 0.6979745     |
| qf1_loss                | 0.00018171244 |
| qf2_loss                | 0.00020344433 |
| time_elapsed            | 2396          |
| total timesteps         | 497100        |
| value_loss              | 0.00010454591 |
-------------------------------------------
--------------------------------------------
| current_lr              | 0.0003         |
| ent_coef                | 0.0009164407   |
| ent_coef_loss           | 1.4170005      |
| entropy                 | 3.2560482      |
| ep_rewmean              | -2.2           |
| episodes                | 4976           |
| eplenmean               | 100            |
| fps                     | 207            |
| mean 100 episode reward | -2.2           |
| n_updates               | 497401         |
| policy_loss             | 0.69969255     |
| qf1_loss                | 0.0002453898   |
| qf2_loss                | 0.00024305598  |
| time_elapsed            | 2398           |
| total timesteps         | 497500         |
| value_loss              | 0.000100462494 |
--------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00092031446 |
| ent_coef_loss           | 6.1054144     |
| entropy                 | 2.9382844     |
| ep_rewmean              | -2.24         |
| episodes                | 4980          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.2          |
| n_updates               | 497801        |
| policy_loss             | 0.6806344     |
| qf1_loss                | 0.00019939552 |
| qf2_loss                | 0.0002449081  |
| time_elapsed            | 2400          |
| total timesteps         | 497900        |
| value_loss              | 0.00013551301 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00095921743 |
| ent_coef_loss           | 2.9186885     |
| entropy                 | 2.8870335     |
| ep_rewmean              | -2.29         |
| episodes                | 4984          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 498201        |
| policy_loss             | 0.6878863     |
| qf1_loss                | 0.00067390973 |
| qf2_loss                | 0.0007978886  |
| time_elapsed            | 2402          |
| total timesteps         | 498300        |
| value_loss              | 0.00019922739 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009126262  |
| ent_coef_loss           | -2.7429605    |
| entropy                 | 2.9607248     |
| ep_rewmean              | -2.3          |
| episodes                | 4988          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 498601        |
| policy_loss             | 0.68376446    |
| qf1_loss                | 0.0002868409  |
| qf2_loss                | 0.000177605   |
| time_elapsed            | 2404          |
| total timesteps         | 498700        |
| value_loss              | 0.00012405784 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.00090876315 |
| ent_coef_loss           | 3.0151389     |
| entropy                 | 2.8267355     |
| ep_rewmean              | -2.31         |
| episodes                | 4992          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 499001        |
| policy_loss             | 0.69621885    |
| qf1_loss                | 0.00020471023 |
| qf2_loss                | 0.0002872411  |
| time_elapsed            | 2406          |
| total timesteps         | 499100        |
| value_loss              | 0.00015203783 |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0008869767  |
| ent_coef_loss           | 1.2106509     |
| entropy                 | 2.9319072     |
| ep_rewmean              | -2.34         |
| episodes                | 4996          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 499401        |
| policy_loss             | 0.7150532     |
| qf1_loss                | 0.00018862389 |
| qf2_loss                | 0.00014226865 |
| time_elapsed            | 2408          |
| total timesteps         | 499500        |
| value_loss              | 8.799659e-05  |
-------------------------------------------
-------------------------------------------
| current_lr              | 0.0003        |
| ent_coef                | 0.0009033566  |
| ent_coef_loss           | 0.21095383    |
| entropy                 | 3.0985732     |
| ep_rewmean              | -2.33         |
| episodes                | 5000          |
| eplenmean               | 100           |
| fps                     | 207           |
| mean 100 episode reward | -2.3          |
| n_updates               | 499801        |
| policy_loss             | 0.74357194    |
| qf1_loss                | 0.00015335623 |
| qf2_loss                | 0.00020170351 |
| time_elapsed            | 2410          |
| total timesteps         | 499900        |
| value_loss              | 0.00013446929 |
-------------------------------------------
/ichec/home/users/pierre/WidowX-reacher/stable-baselines/stable_baselines/common/callbacks.py:285: UserWarning: Training and eval env are not of the same type<stable_baselines.common.base_class._UnvecWrapper object at 0x7f036b3e3160> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f036b3ddda0>
  "{} != {}".format(self.training_env, self.eval_env))
Eval num_timesteps=500000, episode_reward=-1.60 +/- 0.76
Episode length: 100.00 +/- 0.00
Saving to logs/train_0.5M_widowx_reacher-v7_KAY/sac/widowx_reacher-v7_2
pybullet build time: May 18 2020 02:46:26
