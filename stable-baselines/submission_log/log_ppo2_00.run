--------------------------------------------------------------------------
WARNING: There was an error initializing an OpenFabrics device.

  Local host:   n359
  Local device: hfi1_0
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Warning: Open MPI has detected that you are running in an environment with CUDA
devices present and that you are using Intel(r) Ompi-Path networking. However,
the environment variable PSM2_CUDA was not set, meaning that the PSM2 Omni-Path
networking library was not told how to handle CUDA support.

If your application uses CUDA buffers, you should set the environment variable
PSM2_CUDA to 1; otherwise, set it to 0. Setting the variable to the wrong value
can have performance implications on your application, or even cause it to
crash.

Since it was not set, Open MPI has defaulted to setting the PSM2_CUDA
environment variable to 1.

Local hostname: n359
--------------------------------------------------------------------------
/ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

pybullet build time: May 18 2020 02:46:26
b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkWARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f54f8e72d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f54f8e72d68>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f54f8e9d1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f54f8e9d1d0>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

========== widowx_reach-v3 ==========
Seed: 0
OrderedDict([('cliprange', 0.2),
             ('ent_coef', 0.0),
             ('gamma', 0.99),
             ('lam', 0.95),
             ('learning_rate', 0.00025),
             ('n_envs', 8),
             ('n_steps', 256),
             ('n_timesteps', 1000000.0),
             ('nminibatches', 32),
             ('noptepochs', 10),
             ('normalize', True),
             ('policy', 'MlpPolicy')])
Using 8 environments
Overwriting n_timesteps with n=1000000
********goal is : *********** [0.01366778 0.05594924 0.33835924]
********goal is : *********** [-0.02323384  0.05728437  0.26001487]
********goal is : *********** [-0.01792143 -0.12325918  0.33145612]
********goal is : *********** [0.01422341 0.05411843 0.29781762]
********goal is : *********** [0.13076835 0.01228038 0.38644897]
********goal is : *********** [-0.07784191  0.0963904   0.28687349]
********goal is : *********** [ 0.11000084 -0.04368525  0.36675979]
********goal is : *********** [-0.11863368  0.07277889  0.3169932 ]
Normalizing input and reward
TRAINING ENV TYPE 000:  <stable_baselines.common.vec_env.vec_normalize.VecNormalize object at 0x7f54f8e68080>
Creating test environment
TRAINING ENV TYPE 111:  <stable_baselines.common.vec_env.vec_normalize.VecNormalize object at 0x7f54f8e68080>
********goal is : *********** [0.01366778 0.05594924 0.33835924]
Normalization activated: {'norm_reward': False}
PIERRE - CREATE ENV FROM EVALCALLBACK: <stable_baselines.common.vec_env.vec_normalize.VecNormalize object at 0x7f54f8e72198>
********goal is : *********** [0.01366778 0.05594924 0.33835924]
Normalization activated: {'norm_reward': False}
TRAINING ENV TYPE 444:  <stable_baselines.common.vec_env.vec_normalize.VecNormalize object at 0x7f54f8e68080>
Log path: logs/train_1M_widowx_reach-v3/ppo2/widowx_reach-v3_1
-------------------------------------
| approxkl           | 0.007833169  |
| clipfrac           | 0.104199216  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.0762       |
| fps                | 1481         |
| n_updates          | 1            |
| policy_entropy     | 8.547007     |
| policy_loss        | -0.011708008 |
| serial_timesteps   | 256          |
| time_elapsed       | 2.34e-05     |
| total_timesteps    | 2048         |
| value_loss         | 0.5291279    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0061243507 |
| clipfrac           | 0.08222656   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.114        |
| fps                | 2104         |
| n_updates          | 2            |
| policy_entropy     | 8.559401     |
| policy_loss        | -0.011704313 |
| serial_timesteps   | 512          |
| time_elapsed       | 1.38         |
| total_timesteps    | 4096         |
| value_loss         | 0.098749824  |
-------------------------------------
-------------------------------------
| approxkl           | 0.004642675  |
| clipfrac           | 0.05234375   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.63        |
| explained_variance | 0.301        |
| fps                | 2055         |
| n_updates          | 3            |
| policy_entropy     | 8.552805     |
| policy_loss        | -0.008621886 |
| serial_timesteps   | 768          |
| time_elapsed       | 2.36         |
| total_timesteps    | 6144         |
| value_loss         | 0.06736123   |
-------------------------------------
-------------------------------------
| approxkl           | 0.005808971  |
| clipfrac           | 0.07631836   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.72        |
| explained_variance | -0.0698      |
| fps                | 2019         |
| n_updates          | 4            |
| policy_entropy     | 8.579691     |
| policy_loss        | -0.011803816 |
| serial_timesteps   | 1024         |
| time_elapsed       | 3.35         |
| total_timesteps    | 8192         |
| value_loss         | 0.12517299   |
-------------------------------------
Eval num_timesteps=10000, episode_reward=-0.89 +/- 0.23
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.0055358876 |
| clipfrac           | 0.066308595  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.72        |
| explained_variance | 0.285        |
| fps                | 1331         |
| n_updates          | 5            |
| policy_entropy     | 8.600575     |
| policy_loss        | -0.009823423 |
| serial_timesteps   | 1280         |
| time_elapsed       | 4.37         |
| total_timesteps    | 10240        |
| value_loss         | 0.08746382   |
-------------------------------------
-------------------------------------
| approxkl           | 0.006238051  |
| clipfrac           | 0.076123044  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.104        |
| fps                | 2095         |
| n_updates          | 6            |
| policy_entropy     | 8.56817      |
| policy_loss        | -0.012028579 |
| serial_timesteps   | 1536         |
| time_elapsed       | 5.91         |
| total_timesteps    | 12288        |
| value_loss         | 0.08956598   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007759426  |
| clipfrac           | 0.10771485   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.25         |
| fps                | 2008         |
| n_updates          | 7            |
| policy_entropy     | 8.532636     |
| policy_loss        | -0.014824325 |
| serial_timesteps   | 1792         |
| time_elapsed       | 6.88         |
| total_timesteps    | 14336        |
| value_loss         | 0.076413706  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007659413  |
| clipfrac           | 0.103076175  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.363        |
| fps                | 2126         |
| n_updates          | 8            |
| policy_entropy     | 8.520358     |
| policy_loss        | -0.014865108 |
| serial_timesteps   | 2048         |
| time_elapsed       | 7.9          |
| total_timesteps    | 16384        |
| value_loss         | 0.05757934   |
-------------------------------------
-------------------------------------
| approxkl           | 0.006694938  |
| clipfrac           | 0.09023438   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.572        |
| fps                | 2126         |
| n_updates          | 9            |
| policy_entropy     | 8.4965       |
| policy_loss        | -0.011735609 |
| serial_timesteps   | 2304         |
| time_elapsed       | 8.87         |
| total_timesteps    | 18432        |
| value_loss         | 0.047902722  |
-------------------------------------
Eval num_timesteps=20000, episode_reward=-0.82 +/- 0.27
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.008487816  |
| clipfrac           | 0.12524414   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.82        |
| explained_variance | 0.61         |
| fps                | 1463         |
| n_updates          | 10           |
| policy_entropy     | 8.45447      |
| policy_loss        | -0.014557178 |
| serial_timesteps   | 2560         |
| time_elapsed       | 9.83         |
| total_timesteps    | 20480        |
| value_loss         | 0.039647058  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00577753   |
| clipfrac           | 0.074121095  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.71        |
| explained_variance | 0.596        |
| fps                | 2083         |
| n_updates          | 11           |
| policy_entropy     | 8.423967     |
| policy_loss        | -0.010872387 |
| serial_timesteps   | 2816         |
| time_elapsed       | 11.2         |
| total_timesteps    | 22528        |
| value_loss         | 0.044716775  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0068679913 |
| clipfrac           | 0.09287109   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.7         |
| explained_variance | 0.498        |
| fps                | 2102         |
| n_updates          | 12           |
| policy_entropy     | 8.42588      |
| policy_loss        | -0.00880122  |
| serial_timesteps   | 3072         |
| time_elapsed       | 12.2         |
| total_timesteps    | 24576        |
| value_loss         | 0.068276316  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007520254  |
| clipfrac           | 0.10429688   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.69        |
| explained_variance | 0.545        |
| fps                | 2161         |
| n_updates          | 13           |
| policy_entropy     | 8.439074     |
| policy_loss        | -0.012669593 |
| serial_timesteps   | 3328         |
| time_elapsed       | 13.2         |
| total_timesteps    | 26624        |
| value_loss         | 0.07371986   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008292472  |
| clipfrac           | 0.117773436  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.65        |
| explained_variance | 0.649        |
| fps                | 2132         |
| n_updates          | 14           |
| policy_entropy     | 8.432094     |
| policy_loss        | -0.013680296 |
| serial_timesteps   | 3584         |
| time_elapsed       | 14.1         |
| total_timesteps    | 28672        |
| value_loss         | 0.04639589   |
-------------------------------------
Eval num_timesteps=30000, episode_reward=-1.41 +/- 0.06
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.008114068 |
| clipfrac           | 0.11210938  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.67       |
| explained_variance | 0.663       |
| fps                | 1495        |
| n_updates          | 15          |
| policy_entropy     | 8.413942    |
| policy_loss        | -0.01417608 |
| serial_timesteps   | 3840        |
| time_elapsed       | 15.1        |
| total_timesteps    | 30720       |
| value_loss         | 0.04182452  |
------------------------------------
-------------------------------------
| approxkl           | 0.0077642696 |
| clipfrac           | 0.10493164   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.67        |
| explained_variance | 0.627        |
| fps                | 2116         |
| n_updates          | 16           |
| policy_entropy     | 8.386642     |
| policy_loss        | -0.010499154 |
| serial_timesteps   | 4096         |
| time_elapsed       | 16.5         |
| total_timesteps    | 32768        |
| value_loss         | 0.05581944   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0067751734 |
| clipfrac           | 0.08876953   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.62        |
| explained_variance | 0.706        |
| fps                | 2096         |
| n_updates          | 17           |
| policy_entropy     | 8.356485     |
| policy_loss        | -0.009401189 |
| serial_timesteps   | 4352         |
| time_elapsed       | 17.4         |
| total_timesteps    | 34816        |
| value_loss         | 0.03872754   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008043971  |
| clipfrac           | 0.10849609   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.71        |
| explained_variance | 0.655        |
| fps                | 2107         |
| n_updates          | 18           |
| policy_entropy     | 8.319643     |
| policy_loss        | -0.016675428 |
| serial_timesteps   | 4608         |
| time_elapsed       | 18.4         |
| total_timesteps    | 36864        |
| value_loss         | 0.05406783   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008090578  |
| clipfrac           | 0.1121582    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.72        |
| explained_variance | 0.372        |
| fps                | 2106         |
| n_updates          | 19           |
| policy_entropy     | 8.29807      |
| policy_loss        | -0.011189659 |
| serial_timesteps   | 4864         |
| time_elapsed       | 19.4         |
| total_timesteps    | 38912        |
| value_loss         | 0.0932288    |
-------------------------------------
Eval num_timesteps=40000, episode_reward=-0.90 +/- 0.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.006646672  |
| clipfrac           | 0.088134766  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.74        |
| explained_variance | 0.638        |
| fps                | 1492         |
| n_updates          | 20           |
| policy_entropy     | 8.297987     |
| policy_loss        | -0.011524474 |
| serial_timesteps   | 5120         |
| time_elapsed       | 20.4         |
| total_timesteps    | 40960        |
| value_loss         | 0.040964212  |
-------------------------------------
-------------------------------------
| approxkl           | 0.006682066  |
| clipfrac           | 0.08515625   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.72        |
| explained_variance | 0.658        |
| fps                | 2128         |
| n_updates          | 21           |
| policy_entropy     | 8.285767     |
| policy_loss        | -0.013586633 |
| serial_timesteps   | 5376         |
| time_elapsed       | 21.7         |
| total_timesteps    | 43008        |
| value_loss         | 0.034217328  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00749124   |
| clipfrac           | 0.0984375    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.73        |
| explained_variance | 0.67         |
| fps                | 2048         |
| n_updates          | 22           |
| policy_entropy     | 8.27396      |
| policy_loss        | -0.012799414 |
| serial_timesteps   | 5632         |
| time_elapsed       | 22.7         |
| total_timesteps    | 45056        |
| value_loss         | 0.04053274   |
-------------------------------------
-------------------------------------
| approxkl           | 0.006020851  |
| clipfrac           | 0.07602539   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.67        |
| explained_variance | 0.596        |
| fps                | 2099         |
| n_updates          | 23           |
| policy_entropy     | 8.276521     |
| policy_loss        | -0.008275961 |
| serial_timesteps   | 5888         |
| time_elapsed       | 23.7         |
| total_timesteps    | 47104        |
| value_loss         | 0.051630102  |
-------------------------------------
--------------------------------------
| approxkl           | 0.006795778   |
| clipfrac           | 0.08662109    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.62         |
| explained_variance | 0.685         |
| fps                | 2100          |
| n_updates          | 24            |
| policy_entropy     | 8.288089      |
| policy_loss        | -0.0100894915 |
| serial_timesteps   | 6144          |
| time_elapsed       | 24.7          |
| total_timesteps    | 49152         |
| value_loss         | 0.043762352   |
--------------------------------------
Eval num_timesteps=50000, episode_reward=-0.66 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.009171432  |
| clipfrac           | 0.12568359   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.775        |
| fps                | 1456         |
| n_updates          | 25           |
| policy_entropy     | 8.278607     |
| policy_loss        | -0.014787284 |
| serial_timesteps   | 6400         |
| time_elapsed       | 25.6         |
| total_timesteps    | 51200        |
| value_loss         | 0.030490141  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0070988433 |
| clipfrac           | 0.08901367   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.56        |
| explained_variance | 0.685        |
| fps                | 2074         |
| n_updates          | 26           |
| policy_entropy     | 8.253797     |
| policy_loss        | -0.010971049 |
| serial_timesteps   | 6656         |
| time_elapsed       | 27           |
| total_timesteps    | 53248        |
| value_loss         | 0.03748447   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0071494905 |
| clipfrac           | 0.09125976   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.745        |
| fps                | 2091         |
| n_updates          | 27           |
| policy_entropy     | 8.251822     |
| policy_loss        | -0.010684681 |
| serial_timesteps   | 6912         |
| time_elapsed       | 28           |
| total_timesteps    | 55296        |
| value_loss         | 0.028793072  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008462365  |
| clipfrac           | 0.121191405  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.727        |
| fps                | 2090         |
| n_updates          | 28           |
| policy_entropy     | 8.254836     |
| policy_loss        | -0.012347977 |
| serial_timesteps   | 7168         |
| time_elapsed       | 29           |
| total_timesteps    | 57344        |
| value_loss         | 0.031522848  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0076611876 |
| clipfrac           | 0.10258789   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.712        |
| fps                | 2037         |
| n_updates          | 29           |
| policy_entropy     | 8.256759     |
| policy_loss        | -0.010886867 |
| serial_timesteps   | 7424         |
| time_elapsed       | 30           |
| total_timesteps    | 59392        |
| value_loss         | 0.03458527   |
-------------------------------------
Eval num_timesteps=60000, episode_reward=-1.58 +/- 0.09
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007040199  |
| clipfrac           | 0.09003906   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.577        |
| fps                | 1387         |
| n_updates          | 30           |
| policy_entropy     | 8.267542     |
| policy_loss        | -0.012112776 |
| serial_timesteps   | 7680         |
| time_elapsed       | 31           |
| total_timesteps    | 61440        |
| value_loss         | 0.042734396  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0072092987 |
| clipfrac           | 0.09741211   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.555        |
| fps                | 2061         |
| n_updates          | 31           |
| policy_entropy     | 8.271163     |
| policy_loss        | -0.011203472 |
| serial_timesteps   | 7936         |
| time_elapsed       | 32.5         |
| total_timesteps    | 63488        |
| value_loss         | 0.06041032   |
-------------------------------------
-------------------------------------
| approxkl           | 0.006532895  |
| clipfrac           | 0.08413086   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.623        |
| fps                | 2072         |
| n_updates          | 32           |
| policy_entropy     | 8.266235     |
| policy_loss        | -0.008868258 |
| serial_timesteps   | 8192         |
| time_elapsed       | 33.5         |
| total_timesteps    | 65536        |
| value_loss         | 0.051066495  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008503318   |
| clipfrac           | 0.118652344   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.54         |
| explained_variance | 0.457         |
| fps                | 2027          |
| n_updates          | 33            |
| policy_entropy     | 8.259355      |
| policy_loss        | -0.0146412905 |
| serial_timesteps   | 8448          |
| time_elapsed       | 34.5          |
| total_timesteps    | 67584         |
| value_loss         | 0.061604224   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008304838  |
| clipfrac           | 0.109716795  |
| ep_len_mean        | 99.8         |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.657        |
| fps                | 2081         |
| n_updates          | 34           |
| policy_entropy     | 8.267281     |
| policy_loss        | -0.013549514 |
| serial_timesteps   | 8704         |
| time_elapsed       | 35.5         |
| total_timesteps    | 69632        |
| value_loss         | 0.037091147  |
-------------------------------------
Eval num_timesteps=70000, episode_reward=-1.35 +/- 0.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0072863726 |
| clipfrac           | 0.09296875   |
| ep_len_mean        | 99.8         |
| ep_reward_mean     | -1.58        |
| explained_variance | 0.382        |
| fps                | 1474         |
| n_updates          | 35           |
| policy_entropy     | 8.267641     |
| policy_loss        | -0.009189214 |
| serial_timesteps   | 8960         |
| time_elapsed       | 36.5         |
| total_timesteps    | 71680        |
| value_loss         | 0.066100605  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0076735155 |
| clipfrac           | 0.107373044  |
| ep_len_mean        | 99.8         |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.65         |
| fps                | 2091         |
| n_updates          | 36           |
| policy_entropy     | 8.26109      |
| policy_loss        | -0.011017899 |
| serial_timesteps   | 9216         |
| time_elapsed       | 37.8         |
| total_timesteps    | 73728        |
| value_loss         | 0.04272568   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0074520493 |
| clipfrac           | 0.10209961   |
| ep_len_mean        | 99.8         |
| ep_reward_mean     | -1.6         |
| explained_variance | 0.623        |
| fps                | 2078         |
| n_updates          | 37           |
| policy_entropy     | 8.254783     |
| policy_loss        | -0.010720108 |
| serial_timesteps   | 9472         |
| time_elapsed       | 38.8         |
| total_timesteps    | 75776        |
| value_loss         | 0.04481233   |
-------------------------------------
------------------------------------
| approxkl           | 0.007550164 |
| clipfrac           | 0.09672852  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.57       |
| explained_variance | 0.66        |
| fps                | 2120        |
| n_updates          | 38          |
| policy_entropy     | 8.224535    |
| policy_loss        | -0.0090718  |
| serial_timesteps   | 9728        |
| time_elapsed       | 39.8        |
| total_timesteps    | 77824       |
| value_loss         | 0.03541333  |
------------------------------------
-------------------------------------
| approxkl           | 0.0074816337 |
| clipfrac           | 0.102832034  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.666        |
| fps                | 2133         |
| n_updates          | 39           |
| policy_entropy     | 8.194744     |
| policy_loss        | -0.009719283 |
| serial_timesteps   | 9984         |
| time_elapsed       | 40.8         |
| total_timesteps    | 79872        |
| value_loss         | 0.03417813   |
-------------------------------------
Eval num_timesteps=80000, episode_reward=-3.74 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008056367  |
| clipfrac           | 0.11225586   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.578        |
| fps                | 1465         |
| n_updates          | 40           |
| policy_entropy     | 8.172322     |
| policy_loss        | -0.012262978 |
| serial_timesteps   | 10240        |
| time_elapsed       | 41.7         |
| total_timesteps    | 81920        |
| value_loss         | 0.037091468  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008373605  |
| clipfrac           | 0.11650391   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.52         |
| fps                | 2105         |
| n_updates          | 41           |
| policy_entropy     | 8.185526     |
| policy_loss        | -0.012152256 |
| serial_timesteps   | 10496        |
| time_elapsed       | 43.1         |
| total_timesteps    | 83968        |
| value_loss         | 0.037803706  |
-------------------------------------
------------------------------------
| approxkl           | 0.006418136 |
| clipfrac           | 0.07998047  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.52       |
| explained_variance | 0.685       |
| fps                | 2096        |
| n_updates          | 42          |
| policy_entropy     | 8.199533    |
| policy_loss        | -0.00688506 |
| serial_timesteps   | 10752       |
| time_elapsed       | 44.1        |
| total_timesteps    | 86016       |
| value_loss         | 0.036060546 |
------------------------------------
-------------------------------------
| approxkl           | 0.008014654  |
| clipfrac           | 0.111767575  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.659        |
| fps                | 2115         |
| n_updates          | 43           |
| policy_entropy     | 8.180979     |
| policy_loss        | -0.011198359 |
| serial_timesteps   | 11008        |
| time_elapsed       | 45.1         |
| total_timesteps    | 88064        |
| value_loss         | 0.044141162  |
-------------------------------------
Eval num_timesteps=90000, episode_reward=-3.26 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008225206  |
| clipfrac           | 0.111572266  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.709        |
| fps                | 1477         |
| n_updates          | 44           |
| policy_entropy     | 8.177611     |
| policy_loss        | -0.010693228 |
| serial_timesteps   | 11264        |
| time_elapsed       | 46.1         |
| total_timesteps    | 90112        |
| value_loss         | 0.03002978   |
-------------------------------------
--------------------------------------
| approxkl           | 0.008217977   |
| clipfrac           | 0.11323242    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.51         |
| explained_variance | 0.802         |
| fps                | 2132          |
| n_updates          | 45            |
| policy_entropy     | 8.172483      |
| policy_loss        | -0.0125775365 |
| serial_timesteps   | 11520         |
| time_elapsed       | 47.4          |
| total_timesteps    | 92160         |
| value_loss         | 0.026959237   |
--------------------------------------
------------------------------------
| approxkl           | 0.009105067 |
| clipfrac           | 0.12963867  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.49       |
| explained_variance | 0.58        |
| fps                | 2084        |
| n_updates          | 46          |
| policy_entropy     | 8.151151    |
| policy_loss        | -0.01430322 |
| serial_timesteps   | 11776       |
| time_elapsed       | 48.4        |
| total_timesteps    | 94208       |
| value_loss         | 0.044319242 |
------------------------------------
-------------------------------------
| approxkl           | 0.0075323395 |
| clipfrac           | 0.09648438   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.683        |
| fps                | 2126         |
| n_updates          | 47           |
| policy_entropy     | 8.129335     |
| policy_loss        | -0.011321932 |
| serial_timesteps   | 12032        |
| time_elapsed       | 49.4         |
| total_timesteps    | 96256        |
| value_loss         | 0.032750305  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008051642  |
| clipfrac           | 0.113183595  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.622        |
| fps                | 2064         |
| n_updates          | 48           |
| policy_entropy     | 8.115584     |
| policy_loss        | -0.011225076 |
| serial_timesteps   | 12288        |
| time_elapsed       | 50.3         |
| total_timesteps    | 98304        |
| value_loss         | 0.041099742  |
-------------------------------------
Eval num_timesteps=100000, episode_reward=-3.18 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.007976492   |
| clipfrac           | 0.10625       |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.49         |
| explained_variance | 0.714         |
| fps                | 1497          |
| n_updates          | 49            |
| policy_entropy     | 8.101458      |
| policy_loss        | -0.0124943005 |
| serial_timesteps   | 12544         |
| time_elapsed       | 51.3          |
| total_timesteps    | 100352        |
| value_loss         | 0.035183355   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0080439    |
| clipfrac           | 0.10893555   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.53        |
| explained_variance | 0.644        |
| fps                | 2104         |
| n_updates          | 50           |
| policy_entropy     | 8.086479     |
| policy_loss        | -0.011031674 |
| serial_timesteps   | 12800        |
| time_elapsed       | 52.7         |
| total_timesteps    | 102400       |
| value_loss         | 0.050952144  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00813912   |
| clipfrac           | 0.10854492   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.702        |
| fps                | 2140         |
| n_updates          | 51           |
| policy_entropy     | 8.064901     |
| policy_loss        | -0.011551346 |
| serial_timesteps   | 13056        |
| time_elapsed       | 53.7         |
| total_timesteps    | 104448       |
| value_loss         | 0.03664175   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009284182  |
| clipfrac           | 0.13310547   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.686        |
| fps                | 2137         |
| n_updates          | 52           |
| policy_entropy     | 8.029522     |
| policy_loss        | -0.013780917 |
| serial_timesteps   | 13312        |
| time_elapsed       | 54.6         |
| total_timesteps    | 106496       |
| value_loss         | 0.044837143  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008581571  |
| clipfrac           | 0.11240234   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.662        |
| fps                | 2148         |
| n_updates          | 53           |
| policy_entropy     | 8.024869     |
| policy_loss        | -0.013057202 |
| serial_timesteps   | 13568        |
| time_elapsed       | 55.6         |
| total_timesteps    | 108544       |
| value_loss         | 0.032436162  |
-------------------------------------
Eval num_timesteps=110000, episode_reward=-3.13 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009838453  |
| clipfrac           | 0.14082031   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.729        |
| fps                | 1482         |
| n_updates          | 54           |
| policy_entropy     | 8.002357     |
| policy_loss        | -0.014536545 |
| serial_timesteps   | 13824        |
| time_elapsed       | 56.5         |
| total_timesteps    | 110592       |
| value_loss         | 0.03526601   |
-------------------------------------
-------------------------------------
| approxkl           | 0.006900248  |
| clipfrac           | 0.08876953   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.55        |
| explained_variance | 0.653        |
| fps                | 2097         |
| n_updates          | 55           |
| policy_entropy     | 7.977849     |
| policy_loss        | -0.009242559 |
| serial_timesteps   | 14080        |
| time_elapsed       | 57.9         |
| total_timesteps    | 112640       |
| value_loss         | 0.034877546  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007881386  |
| clipfrac           | 0.10639648   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.723        |
| fps                | 2024         |
| n_updates          | 56           |
| policy_entropy     | 7.952527     |
| policy_loss        | -0.012076918 |
| serial_timesteps   | 14336        |
| time_elapsed       | 58.9         |
| total_timesteps    | 114688       |
| value_loss         | 0.03857491   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008399653  |
| clipfrac           | 0.10854492   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.572        |
| fps                | 2108         |
| n_updates          | 57           |
| policy_entropy     | 7.922849     |
| policy_loss        | -0.011185045 |
| serial_timesteps   | 14592        |
| time_elapsed       | 59.9         |
| total_timesteps    | 116736       |
| value_loss         | 0.0644248    |
-------------------------------------
-------------------------------------
| approxkl           | 0.010124876  |
| clipfrac           | 0.13286133   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.721        |
| fps                | 2120         |
| n_updates          | 58           |
| policy_entropy     | 7.911991     |
| policy_loss        | -0.015045705 |
| serial_timesteps   | 14848        |
| time_elapsed       | 60.9         |
| total_timesteps    | 118784       |
| value_loss         | 0.038254995  |
-------------------------------------
Eval num_timesteps=120000, episode_reward=-3.36 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.008072342   |
| clipfrac           | 0.1109375     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.57         |
| explained_variance | 0.696         |
| fps                | 1485          |
| n_updates          | 59            |
| policy_entropy     | 7.8911934     |
| policy_loss        | -0.0107568335 |
| serial_timesteps   | 15104         |
| time_elapsed       | 61.9          |
| total_timesteps    | 120832        |
| value_loss         | 0.03865447    |
--------------------------------------
-------------------------------------
| approxkl           | 0.006988661  |
| clipfrac           | 0.09379883   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.676        |
| fps                | 2129         |
| n_updates          | 60           |
| policy_entropy     | 7.8619995    |
| policy_loss        | -0.009755376 |
| serial_timesteps   | 15360        |
| time_elapsed       | 63.2         |
| total_timesteps    | 122880       |
| value_loss         | 0.03362664   |
-------------------------------------
--------------------------------------
| approxkl           | 0.008474706   |
| clipfrac           | 0.11743164    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.54         |
| explained_variance | 0.762         |
| fps                | 2118          |
| n_updates          | 61            |
| policy_entropy     | 7.848748      |
| policy_loss        | -0.0099012405 |
| serial_timesteps   | 15616         |
| time_elapsed       | 64.2          |
| total_timesteps    | 124928        |
| value_loss         | 0.030991767   |
--------------------------------------
-------------------------------------
| approxkl           | 0.006974372  |
| clipfrac           | 0.09335937   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.699        |
| fps                | 2135         |
| n_updates          | 62           |
| policy_entropy     | 7.820399     |
| policy_loss        | -0.009643011 |
| serial_timesteps   | 15872        |
| time_elapsed       | 65.2         |
| total_timesteps    | 126976       |
| value_loss         | 0.028664995  |
-------------------------------------
------------------------------------
| approxkl           | 0.007720725 |
| clipfrac           | 0.10224609  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.42       |
| explained_variance | 0.74        |
| fps                | 2070        |
| n_updates          | 63          |
| policy_entropy     | 7.803605    |
| policy_loss        | -0.00831425 |
| serial_timesteps   | 16128       |
| time_elapsed       | 66.1        |
| total_timesteps    | 129024      |
| value_loss         | 0.03360243  |
------------------------------------
Eval num_timesteps=130000, episode_reward=-3.14 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008667969  |
| clipfrac           | 0.1272461    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.668        |
| fps                | 1484         |
| n_updates          | 64           |
| policy_entropy     | 7.7606134    |
| policy_loss        | -0.013897454 |
| serial_timesteps   | 16384        |
| time_elapsed       | 67.1         |
| total_timesteps    | 131072       |
| value_loss         | 0.034333788  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007720544  |
| clipfrac           | 0.097070314  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.668        |
| fps                | 2118         |
| n_updates          | 65           |
| policy_entropy     | 7.7287664    |
| policy_loss        | -0.009967783 |
| serial_timesteps   | 16640        |
| time_elapsed       | 68.5         |
| total_timesteps    | 133120       |
| value_loss         | 0.041986775  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008552021  |
| clipfrac           | 0.11533203   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.653        |
| fps                | 2064         |
| n_updates          | 66           |
| policy_entropy     | 7.6963167    |
| policy_loss        | -0.013099924 |
| serial_timesteps   | 16896        |
| time_elapsed       | 69.5         |
| total_timesteps    | 135168       |
| value_loss         | 0.041192826  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007733865  |
| clipfrac           | 0.09794922   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.708        |
| fps                | 2117         |
| n_updates          | 67           |
| policy_entropy     | 7.659214     |
| policy_loss        | -0.009810723 |
| serial_timesteps   | 17152        |
| time_elapsed       | 70.5         |
| total_timesteps    | 137216       |
| value_loss         | 0.035802234  |
-------------------------------------
--------------------------------------
| approxkl           | 0.006126274   |
| clipfrac           | 0.07504883    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.43         |
| explained_variance | 0.588         |
| fps                | 2133          |
| n_updates          | 68            |
| policy_entropy     | 7.6419435     |
| policy_loss        | -0.0051315576 |
| serial_timesteps   | 17408         |
| time_elapsed       | 71.4          |
| total_timesteps    | 139264        |
| value_loss         | 0.049036283   |
--------------------------------------
Eval num_timesteps=140000, episode_reward=-0.51 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.007815516  |
| clipfrac           | 0.10883789   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.644        |
| fps                | 1473         |
| n_updates          | 69           |
| policy_entropy     | 7.6256256    |
| policy_loss        | -0.011159921 |
| serial_timesteps   | 17664        |
| time_elapsed       | 72.4         |
| total_timesteps    | 141312       |
| value_loss         | 0.038610373  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0065972074 |
| clipfrac           | 0.08208008   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.715        |
| fps                | 2153         |
| n_updates          | 70           |
| policy_entropy     | 7.601819     |
| policy_loss        | -0.007057494 |
| serial_timesteps   | 17920        |
| time_elapsed       | 73.8         |
| total_timesteps    | 143360       |
| value_loss         | 0.033219513  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007960176  |
| clipfrac           | 0.10800781   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.709        |
| fps                | 2044         |
| n_updates          | 71           |
| policy_entropy     | 7.579034     |
| policy_loss        | -0.009440444 |
| serial_timesteps   | 18176        |
| time_elapsed       | 74.7         |
| total_timesteps    | 145408       |
| value_loss         | 0.0368818    |
-------------------------------------
-------------------------------------
| approxkl           | 0.006647242  |
| clipfrac           | 0.08295898   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.737        |
| fps                | 2169         |
| n_updates          | 72           |
| policy_entropy     | 7.5807343    |
| policy_loss        | -0.009350733 |
| serial_timesteps   | 18432        |
| time_elapsed       | 75.7         |
| total_timesteps    | 147456       |
| value_loss         | 0.043279327  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007634266  |
| clipfrac           | 0.09873047   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.715        |
| fps                | 2163         |
| n_updates          | 73           |
| policy_entropy     | 7.5981293    |
| policy_loss        | -0.007995476 |
| serial_timesteps   | 18688        |
| time_elapsed       | 76.7         |
| total_timesteps    | 149504       |
| value_loss         | 0.042075254  |
-------------------------------------
Eval num_timesteps=150000, episode_reward=-0.51 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.007503692  |
| clipfrac           | 0.095507815  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.745        |
| fps                | 1487         |
| n_updates          | 74           |
| policy_entropy     | 7.6093125    |
| policy_loss        | -0.009301215 |
| serial_timesteps   | 18944        |
| time_elapsed       | 77.6         |
| total_timesteps    | 151552       |
| value_loss         | 0.041002225  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0076567903 |
| clipfrac           | 0.09467773   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.808        |
| fps                | 2097         |
| n_updates          | 75           |
| policy_entropy     | 7.587241     |
| policy_loss        | -0.010288408 |
| serial_timesteps   | 19200        |
| time_elapsed       | 79           |
| total_timesteps    | 153600       |
| value_loss         | 0.032720458  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0075169704 |
| clipfrac           | 0.10151367   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.643        |
| fps                | 2138         |
| n_updates          | 76           |
| policy_entropy     | 7.555819     |
| policy_loss        | -0.009721585 |
| serial_timesteps   | 19456        |
| time_elapsed       | 80           |
| total_timesteps    | 155648       |
| value_loss         | 0.047367904  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0072336877 |
| clipfrac           | 0.09604492   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.755        |
| fps                | 2132         |
| n_updates          | 77           |
| policy_entropy     | 7.5358543    |
| policy_loss        | -0.008232807 |
| serial_timesteps   | 19712        |
| time_elapsed       | 80.9         |
| total_timesteps    | 157696       |
| value_loss         | 0.04149569   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0061956597 |
| clipfrac           | 0.07368164   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.763        |
| fps                | 2150         |
| n_updates          | 78           |
| policy_entropy     | 7.493705     |
| policy_loss        | -0.007665793 |
| serial_timesteps   | 19968        |
| time_elapsed       | 81.9         |
| total_timesteps    | 159744       |
| value_loss         | 0.032645844  |
-------------------------------------
Eval num_timesteps=160000, episode_reward=-0.52 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008024367  |
| clipfrac           | 0.103271484  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.743        |
| fps                | 1516         |
| n_updates          | 79           |
| policy_entropy     | 7.4546256    |
| policy_loss        | -0.010143519 |
| serial_timesteps   | 20224        |
| time_elapsed       | 82.8         |
| total_timesteps    | 161792       |
| value_loss         | 0.04163546   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0066886866 |
| clipfrac           | 0.08457031   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.38        |
| explained_variance | 0.72         |
| fps                | 2128         |
| n_updates          | 80           |
| policy_entropy     | 7.45654      |
| policy_loss        | -0.007317687 |
| serial_timesteps   | 20480        |
| time_elapsed       | 84.2         |
| total_timesteps    | 163840       |
| value_loss         | 0.03583839   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007227146  |
| clipfrac           | 0.08701172   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.68         |
| fps                | 2118         |
| n_updates          | 81           |
| policy_entropy     | 7.462102     |
| policy_loss        | -0.008258394 |
| serial_timesteps   | 20736        |
| time_elapsed       | 85.2         |
| total_timesteps    | 165888       |
| value_loss         | 0.04435519   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0069723264 |
| clipfrac           | 0.09272461   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.38        |
| explained_variance | 0.649        |
| fps                | 2126         |
| n_updates          | 82           |
| policy_entropy     | 7.4453135    |
| policy_loss        | -0.008036338 |
| serial_timesteps   | 20992        |
| time_elapsed       | 86.1         |
| total_timesteps    | 167936       |
| value_loss         | 0.04074754   |
-------------------------------------
-------------------------------------
| approxkl           | 0.006861304  |
| clipfrac           | 0.085839845  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.39        |
| explained_variance | 0.743        |
| fps                | 2085         |
| n_updates          | 83           |
| policy_entropy     | 7.4246154    |
| policy_loss        | -0.007275995 |
| serial_timesteps   | 21248        |
| time_elapsed       | 87.1         |
| total_timesteps    | 169984       |
| value_loss         | 0.037526134  |
-------------------------------------
Eval num_timesteps=170000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.007422927  |
| clipfrac           | 0.09858398   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.38        |
| explained_variance | 0.728        |
| fps                | 1489         |
| n_updates          | 84           |
| policy_entropy     | 7.4085298    |
| policy_loss        | -0.007995267 |
| serial_timesteps   | 21504        |
| time_elapsed       | 88.1         |
| total_timesteps    | 172032       |
| value_loss         | 0.04225802   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0075762025 |
| clipfrac           | 0.103076175  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.38        |
| explained_variance | 0.686        |
| fps                | 2160         |
| n_updates          | 85           |
| policy_entropy     | 7.385833     |
| policy_loss        | -0.007924697 |
| serial_timesteps   | 21760        |
| time_elapsed       | 89.4         |
| total_timesteps    | 174080       |
| value_loss         | 0.0478717    |
-------------------------------------
-------------------------------------
| approxkl           | 0.007920047  |
| clipfrac           | 0.11235352   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.36        |
| explained_variance | 0.805        |
| fps                | 2106         |
| n_updates          | 86           |
| policy_entropy     | 7.371698     |
| policy_loss        | -0.009347987 |
| serial_timesteps   | 22016        |
| time_elapsed       | 90.4         |
| total_timesteps    | 176128       |
| value_loss         | 0.03703982   |
-------------------------------------
--------------------------------------
| approxkl           | 0.007424702   |
| clipfrac           | 0.09819336    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.37         |
| explained_variance | 0.765         |
| fps                | 2108          |
| n_updates          | 87            |
| policy_entropy     | 7.3561983     |
| policy_loss        | -0.0069860527 |
| serial_timesteps   | 22272         |
| time_elapsed       | 91.4          |
| total_timesteps    | 178176        |
| value_loss         | 0.035866722   |
--------------------------------------
Eval num_timesteps=180000, episode_reward=-0.46 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
--------------------------------------
| approxkl           | 0.0073732184  |
| clipfrac           | 0.084375      |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.38         |
| explained_variance | 0.685         |
| fps                | 1491          |
| n_updates          | 88            |
| policy_entropy     | 7.335485      |
| policy_loss        | -0.0083787665 |
| serial_timesteps   | 22528         |
| time_elapsed       | 92.3          |
| total_timesteps    | 180224        |
| value_loss         | 0.053346943   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0065285093 |
| clipfrac           | 0.08779297   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.39        |
| explained_variance | 0.651        |
| fps                | 2069         |
| n_updates          | 89           |
| policy_entropy     | 7.3387733    |
| policy_loss        | -0.006153741 |
| serial_timesteps   | 22784        |
| time_elapsed       | 93.7         |
| total_timesteps    | 182272       |
| value_loss         | 0.04451114   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007135453  |
| clipfrac           | 0.08881836   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.717        |
| fps                | 2113         |
| n_updates          | 90           |
| policy_entropy     | 7.3428907    |
| policy_loss        | -0.008608653 |
| serial_timesteps   | 23040        |
| time_elapsed       | 94.7         |
| total_timesteps    | 184320       |
| value_loss         | 0.04062731   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0077053905  |
| clipfrac           | 0.10410156    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.657         |
| fps                | 2120          |
| n_updates          | 91            |
| policy_entropy     | 7.3182807     |
| policy_loss        | -0.0086490335 |
| serial_timesteps   | 23296         |
| time_elapsed       | 95.7          |
| total_timesteps    | 186368        |
| value_loss         | 0.0441219     |
--------------------------------------
-------------------------------------
| approxkl           | 0.007765802  |
| clipfrac           | 0.1065918    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.756        |
| fps                | 2112         |
| n_updates          | 92           |
| policy_entropy     | 7.2876616    |
| policy_loss        | -0.008600711 |
| serial_timesteps   | 23552        |
| time_elapsed       | 96.6         |
| total_timesteps    | 188416       |
| value_loss         | 0.036643486  |
-------------------------------------
Eval num_timesteps=190000, episode_reward=-0.45 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.008308393  |
| clipfrac           | 0.10893555   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.499        |
| fps                | 1481         |
| n_updates          | 93           |
| policy_entropy     | 7.3036146    |
| policy_loss        | -0.010133937 |
| serial_timesteps   | 23808        |
| time_elapsed       | 97.6         |
| total_timesteps    | 190464       |
| value_loss         | 0.06119991   |
-------------------------------------
-------------------------------------
| approxkl           | 0.006813823  |
| clipfrac           | 0.0871582    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.662        |
| fps                | 2082         |
| n_updates          | 94           |
| policy_entropy     | 7.3291006    |
| policy_loss        | -0.007944016 |
| serial_timesteps   | 24064        |
| time_elapsed       | 99           |
| total_timesteps    | 192512       |
| value_loss         | 0.046404354  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0073672994 |
| clipfrac           | 0.09770508   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.697        |
| fps                | 2131         |
| n_updates          | 95           |
| policy_entropy     | 7.330888     |
| policy_loss        | -0.009113792 |
| serial_timesteps   | 24320        |
| time_elapsed       | 100          |
| total_timesteps    | 194560       |
| value_loss         | 0.052063458  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008971476  |
| clipfrac           | 0.121875     |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.666        |
| fps                | 2163         |
| n_updates          | 96           |
| policy_entropy     | 7.3250337    |
| policy_loss        | -0.012226192 |
| serial_timesteps   | 24576        |
| time_elapsed       | 101          |
| total_timesteps    | 196608       |
| value_loss         | 0.04398177   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007957387  |
| clipfrac           | 0.11015625   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.73         |
| fps                | 2090         |
| n_updates          | 97           |
| policy_entropy     | 7.312163     |
| policy_loss        | -0.008300858 |
| serial_timesteps   | 24832        |
| time_elapsed       | 102          |
| total_timesteps    | 198656       |
| value_loss         | 0.045929026  |
-------------------------------------
Eval num_timesteps=200000, episode_reward=-0.47 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.007897749 |
| clipfrac           | 0.10253906  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.45       |
| explained_variance | 0.659       |
| fps                | 1486        |
| n_updates          | 98          |
| policy_entropy     | 7.3126345   |
| policy_loss        | -0.00992723 |
| serial_timesteps   | 25088       |
| time_elapsed       | 103         |
| total_timesteps    | 200704      |
| value_loss         | 0.058385514 |
------------------------------------
------------------------------------
| approxkl           | 0.007521636 |
| clipfrac           | 0.09921875  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.46       |
| explained_variance | 0.752       |
| fps                | 2162        |
| n_updates          | 99          |
| policy_entropy     | 7.3282485   |
| policy_loss        | -0.00860344 |
| serial_timesteps   | 25344       |
| time_elapsed       | 104         |
| total_timesteps    | 202752      |
| value_loss         | 0.041018642 |
------------------------------------
-------------------------------------
| approxkl           | 0.007397578  |
| clipfrac           | 0.10019531   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.674        |
| fps                | 2139         |
| n_updates          | 100          |
| policy_entropy     | 7.3247848    |
| policy_loss        | -0.009425389 |
| serial_timesteps   | 25600        |
| time_elapsed       | 105          |
| total_timesteps    | 204800       |
| value_loss         | 0.050143402  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077387565 |
| clipfrac           | 0.10405274   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.662        |
| fps                | 2122         |
| n_updates          | 101          |
| policy_entropy     | 7.3269334    |
| policy_loss        | -0.008980544 |
| serial_timesteps   | 25856        |
| time_elapsed       | 106          |
| total_timesteps    | 206848       |
| value_loss         | 0.044055227  |
-------------------------------------
------------------------------------
| approxkl           | 0.008648272 |
| clipfrac           | 0.12011719  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.47       |
| explained_variance | 0.669       |
| fps                | 2075        |
| n_updates          | 102         |
| policy_entropy     | 7.346546    |
| policy_loss        | -0.01149531 |
| serial_timesteps   | 26112       |
| time_elapsed       | 107         |
| total_timesteps    | 208896      |
| value_loss         | 0.053726237 |
------------------------------------
Eval num_timesteps=210000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.008591384 |
| clipfrac           | 0.115283206 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.46       |
| explained_variance | 0.677       |
| fps                | 1471        |
| n_updates          | 103         |
| policy_entropy     | 7.3458357   |
| policy_loss        | -0.01049227 |
| serial_timesteps   | 26368       |
| time_elapsed       | 108         |
| total_timesteps    | 210944      |
| value_loss         | 0.04253781  |
------------------------------------
-------------------------------------
| approxkl           | 0.0077246176 |
| clipfrac           | 0.10102539   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.69         |
| fps                | 2148         |
| n_updates          | 104          |
| policy_entropy     | 7.3404427    |
| policy_loss        | -0.007889575 |
| serial_timesteps   | 26624        |
| time_elapsed       | 109          |
| total_timesteps    | 212992       |
| value_loss         | 0.050949197  |
-------------------------------------
-------------------------------------
| approxkl           | 0.006608335  |
| clipfrac           | 0.08095703   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.677        |
| fps                | 2048         |
| n_updates          | 105          |
| policy_entropy     | 7.3391533    |
| policy_loss        | -0.006009455 |
| serial_timesteps   | 26880        |
| time_elapsed       | 110          |
| total_timesteps    | 215040       |
| value_loss         | 0.04412765   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0063408753 |
| clipfrac           | 0.07768555   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.714        |
| fps                | 2112         |
| n_updates          | 106          |
| policy_entropy     | 7.329133     |
| policy_loss        | -0.007271239 |
| serial_timesteps   | 27136        |
| time_elapsed       | 111          |
| total_timesteps    | 217088       |
| value_loss         | 0.0452745    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008007077  |
| clipfrac           | 0.10703125   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.619        |
| fps                | 2102         |
| n_updates          | 107          |
| policy_entropy     | 7.305289     |
| policy_loss        | -0.009990157 |
| serial_timesteps   | 27392        |
| time_elapsed       | 112          |
| total_timesteps    | 219136       |
| value_loss         | 0.049552184  |
-------------------------------------
Eval num_timesteps=220000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.0072356514  |
| clipfrac           | 0.095214844   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.44         |
| explained_variance | 0.663         |
| fps                | 1445          |
| n_updates          | 108           |
| policy_entropy     | 7.2790046     |
| policy_loss        | -0.0069314963 |
| serial_timesteps   | 27648         |
| time_elapsed       | 113           |
| total_timesteps    | 221184        |
| value_loss         | 0.049779154   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0072215013 |
| clipfrac           | 0.09438477   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.709        |
| fps                | 2077         |
| n_updates          | 109          |
| policy_entropy     | 7.266617     |
| policy_loss        | -0.00488283  |
| serial_timesteps   | 27904        |
| time_elapsed       | 115          |
| total_timesteps    | 223232       |
| value_loss         | 0.04376792   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0075869104 |
| clipfrac           | 0.103466794  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.699        |
| fps                | 2088         |
| n_updates          | 110          |
| policy_entropy     | 7.25264      |
| policy_loss        | -0.007571789 |
| serial_timesteps   | 28160        |
| time_elapsed       | 116          |
| total_timesteps    | 225280       |
| value_loss         | 0.040495194  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0055312505  |
| clipfrac           | 0.06225586    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.721         |
| fps                | 2118          |
| n_updates          | 111           |
| policy_entropy     | 7.249944      |
| policy_loss        | -0.0039591286 |
| serial_timesteps   | 28416         |
| time_elapsed       | 117           |
| total_timesteps    | 227328        |
| value_loss         | 0.04422765    |
--------------------------------------
-------------------------------------
| approxkl           | 0.007141008  |
| clipfrac           | 0.09404297   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.649        |
| fps                | 2067         |
| n_updates          | 112          |
| policy_entropy     | 7.253316     |
| policy_loss        | -0.008294059 |
| serial_timesteps   | 28672        |
| time_elapsed       | 118          |
| total_timesteps    | 229376       |
| value_loss         | 0.043998316  |
-------------------------------------
Eval num_timesteps=230000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.006882353  |
| clipfrac           | 0.09125976   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.713        |
| fps                | 1464         |
| n_updates          | 113          |
| policy_entropy     | 7.2540703    |
| policy_loss        | -0.005764964 |
| serial_timesteps   | 28928        |
| time_elapsed       | 119          |
| total_timesteps    | 231424       |
| value_loss         | 0.04293214   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0064066113  |
| clipfrac           | 0.07817383    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.4          |
| explained_variance | 0.705         |
| fps                | 2134          |
| n_updates          | 114           |
| policy_entropy     | 7.2418303     |
| policy_loss        | -0.0067539536 |
| serial_timesteps   | 29184         |
| time_elapsed       | 120           |
| total_timesteps    | 233472        |
| value_loss         | 0.04316898    |
--------------------------------------
--------------------------------------
| approxkl           | 0.0068559474  |
| clipfrac           | 0.08598633    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.736         |
| fps                | 2121          |
| n_updates          | 115           |
| policy_entropy     | 7.2343063     |
| policy_loss        | -0.0071578166 |
| serial_timesteps   | 29440         |
| time_elapsed       | 121           |
| total_timesteps    | 235520        |
| value_loss         | 0.043469027   |
--------------------------------------
--------------------------------------
| approxkl           | 0.006651467   |
| clipfrac           | 0.08071289    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.4          |
| explained_variance | 0.679         |
| fps                | 2083          |
| n_updates          | 116           |
| policy_entropy     | 7.215787      |
| policy_loss        | -0.0066869245 |
| serial_timesteps   | 29696         |
| time_elapsed       | 122           |
| total_timesteps    | 237568        |
| value_loss         | 0.04662885    |
--------------------------------------
--------------------------------------
| approxkl           | 0.006394635   |
| clipfrac           | 0.077978514   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.714         |
| fps                | 2035          |
| n_updates          | 117           |
| policy_entropy     | 7.1972303     |
| policy_loss        | -0.0063763084 |
| serial_timesteps   | 29952         |
| time_elapsed       | 123           |
| total_timesteps    | 239616        |
| value_loss         | 0.045026504   |
--------------------------------------
Eval num_timesteps=240000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.007366686   |
| clipfrac           | 0.09804688    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.725         |
| fps                | 1501          |
| n_updates          | 118           |
| policy_entropy     | 7.1883574     |
| policy_loss        | -0.0073896637 |
| serial_timesteps   | 30208         |
| time_elapsed       | 124           |
| total_timesteps    | 241664        |
| value_loss         | 0.04931426    |
--------------------------------------
------------------------------------
| approxkl           | 0.00710719  |
| clipfrac           | 0.0894043   |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.41       |
| explained_variance | 0.721       |
| fps                | 2116        |
| n_updates          | 119         |
| policy_entropy     | 7.172937    |
| policy_loss        | -0.00793912 |
| serial_timesteps   | 30464       |
| time_elapsed       | 125         |
| total_timesteps    | 243712      |
| value_loss         | 0.042483214 |
------------------------------------
-------------------------------------
| approxkl           | 0.0074563934 |
| clipfrac           | 0.09697266   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.728        |
| fps                | 2101         |
| n_updates          | 120          |
| policy_entropy     | 7.1358094    |
| policy_loss        | -0.005700865 |
| serial_timesteps   | 30720        |
| time_elapsed       | 126          |
| total_timesteps    | 245760       |
| value_loss         | 0.04176502   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0074979165 |
| clipfrac           | 0.097509764  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.667        |
| fps                | 2051         |
| n_updates          | 121          |
| policy_entropy     | 7.128522     |
| policy_loss        | -0.008004572 |
| serial_timesteps   | 30976        |
| time_elapsed       | 127          |
| total_timesteps    | 247808       |
| value_loss         | 0.04305654   |
-------------------------------------
--------------------------------------
| approxkl           | 0.008005125   |
| clipfrac           | 0.10649414    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.687         |
| fps                | 2129          |
| n_updates          | 122           |
| policy_entropy     | 7.1196976     |
| policy_loss        | -0.0087331105 |
| serial_timesteps   | 31232         |
| time_elapsed       | 128           |
| total_timesteps    | 249856        |
| value_loss         | 0.04275626    |
--------------------------------------
Eval num_timesteps=250000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007395692  |
| clipfrac           | 0.09716797   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.39        |
| explained_variance | 0.666        |
| fps                | 1491         |
| n_updates          | 123          |
| policy_entropy     | 7.091114     |
| policy_loss        | -0.006512175 |
| serial_timesteps   | 31488        |
| time_elapsed       | 129          |
| total_timesteps    | 251904       |
| value_loss         | 0.047002964  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00705943   |
| clipfrac           | 0.09238281   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.719        |
| fps                | 2084         |
| n_updates          | 124          |
| policy_entropy     | 7.0962663    |
| policy_loss        | -0.007349804 |
| serial_timesteps   | 31744        |
| time_elapsed       | 131          |
| total_timesteps    | 253952       |
| value_loss         | 0.044677995  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007025405  |
| clipfrac           | 0.087646484  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.714        |
| fps                | 2120         |
| n_updates          | 125          |
| policy_entropy     | 7.129032     |
| policy_loss        | -0.006265547 |
| serial_timesteps   | 32000        |
| time_elapsed       | 132          |
| total_timesteps    | 256000       |
| value_loss         | 0.047894888  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007274191  |
| clipfrac           | 0.09350586   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.721        |
| fps                | 2159         |
| n_updates          | 126          |
| policy_entropy     | 7.1370583    |
| policy_loss        | -0.006874232 |
| serial_timesteps   | 32256        |
| time_elapsed       | 133          |
| total_timesteps    | 258048       |
| value_loss         | 0.045931797  |
-------------------------------------
Eval num_timesteps=260000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.006937783   |
| clipfrac           | 0.08754883    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.4          |
| explained_variance | 0.744         |
| fps                | 1503          |
| n_updates          | 127           |
| policy_entropy     | 7.1115723     |
| policy_loss        | -0.0067013605 |
| serial_timesteps   | 32512         |
| time_elapsed       | 134           |
| total_timesteps    | 260096        |
| value_loss         | 0.045708675   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0070548244 |
| clipfrac           | 0.08427735   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.719        |
| fps                | 2116         |
| n_updates          | 128          |
| policy_entropy     | 7.0589156    |
| policy_loss        | -0.007142298 |
| serial_timesteps   | 32768        |
| time_elapsed       | 135          |
| total_timesteps    | 262144       |
| value_loss         | 0.04262663   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0069593685 |
| clipfrac           | 0.08964844   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.724        |
| fps                | 2105         |
| n_updates          | 129          |
| policy_entropy     | 7.0022974    |
| policy_loss        | -0.007471545 |
| serial_timesteps   | 33024        |
| time_elapsed       | 136          |
| total_timesteps    | 264192       |
| value_loss         | 0.04703986   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0077486336  |
| clipfrac           | 0.10039063    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.39         |
| explained_variance | 0.686         |
| fps                | 2129          |
| n_updates          | 130           |
| policy_entropy     | 6.977764      |
| policy_loss        | -0.0076756263 |
| serial_timesteps   | 33280         |
| time_elapsed       | 137           |
| total_timesteps    | 266240        |
| value_loss         | 0.041796498   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009016022  |
| clipfrac           | 0.12451172   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.738        |
| fps                | 2084         |
| n_updates          | 131          |
| policy_entropy     | 6.9475327    |
| policy_loss        | -0.009558805 |
| serial_timesteps   | 33536        |
| time_elapsed       | 138          |
| total_timesteps    | 268288       |
| value_loss         | 0.04673324   |
-------------------------------------
Eval num_timesteps=270000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.0065357387  |
| clipfrac           | 0.084375      |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.39         |
| explained_variance | 0.67          |
| fps                | 1491          |
| n_updates          | 132           |
| policy_entropy     | 6.9125457     |
| policy_loss        | -0.0033949602 |
| serial_timesteps   | 33792         |
| time_elapsed       | 139           |
| total_timesteps    | 270336        |
| value_loss         | 0.047507472   |
--------------------------------------
-------------------------------------
| approxkl           | 0.007291083  |
| clipfrac           | 0.09448242   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.7          |
| fps                | 2070         |
| n_updates          | 133          |
| policy_entropy     | 6.896611     |
| policy_loss        | -0.006481585 |
| serial_timesteps   | 34048        |
| time_elapsed       | 140          |
| total_timesteps    | 272384       |
| value_loss         | 0.04774401   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0055972463  |
| clipfrac           | 0.063085936   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.707         |
| fps                | 2091          |
| n_updates          | 134           |
| policy_entropy     | 6.8875885     |
| policy_loss        | -0.0024776147 |
| serial_timesteps   | 34304         |
| time_elapsed       | 141           |
| total_timesteps    | 274432        |
| value_loss         | 0.049627386   |
--------------------------------------
--------------------------------------
| approxkl           | 0.007570828   |
| clipfrac           | 0.097314455   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.715         |
| fps                | 2085          |
| n_updates          | 135           |
| policy_entropy     | 6.874284      |
| policy_loss        | -0.0060722358 |
| serial_timesteps   | 34560         |
| time_elapsed       | 142           |
| total_timesteps    | 276480        |
| value_loss         | 0.043292798   |
--------------------------------------
--------------------------------------
| approxkl           | 0.008075383   |
| clipfrac           | 0.10732422    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.699         |
| fps                | 2087          |
| n_updates          | 136           |
| policy_entropy     | 6.878203      |
| policy_loss        | -0.0059413994 |
| serial_timesteps   | 34816         |
| time_elapsed       | 143           |
| total_timesteps    | 278528        |
| value_loss         | 0.048658766   |
--------------------------------------
Eval num_timesteps=280000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.00739967    |
| clipfrac           | 0.09541015    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.727         |
| fps                | 1491          |
| n_updates          | 137           |
| policy_entropy     | 6.874883      |
| policy_loss        | -0.0054696365 |
| serial_timesteps   | 35072         |
| time_elapsed       | 144           |
| total_timesteps    | 280576        |
| value_loss         | 0.04167834    |
--------------------------------------
-------------------------------------
| approxkl           | 0.006630673  |
| clipfrac           | 0.08525391   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.754        |
| fps                | 2114         |
| n_updates          | 138          |
| policy_entropy     | 6.868651     |
| policy_loss        | -0.005601336 |
| serial_timesteps   | 35328        |
| time_elapsed       | 146          |
| total_timesteps    | 282624       |
| value_loss         | 0.045943     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0066630663 |
| clipfrac           | 0.08071289   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.69         |
| fps                | 2084         |
| n_updates          | 139          |
| policy_entropy     | 6.8475847    |
| policy_loss        | -0.004245493 |
| serial_timesteps   | 35584        |
| time_elapsed       | 146          |
| total_timesteps    | 284672       |
| value_loss         | 0.045918055  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0068085655 |
| clipfrac           | 0.08588867   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.723        |
| fps                | 2108         |
| n_updates          | 140          |
| policy_entropy     | 6.820967     |
| policy_loss        | -0.005598299 |
| serial_timesteps   | 35840        |
| time_elapsed       | 147          |
| total_timesteps    | 286720       |
| value_loss         | 0.045684155  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0070664375  |
| clipfrac           | 0.09003906    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.4          |
| explained_variance | 0.663         |
| fps                | 2072          |
| n_updates          | 141           |
| policy_entropy     | 6.7996507     |
| policy_loss        | -0.0053063384 |
| serial_timesteps   | 36096         |
| time_elapsed       | 148           |
| total_timesteps    | 288768        |
| value_loss         | 0.047776677   |
--------------------------------------
Eval num_timesteps=290000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.00711321   |
| clipfrac           | 0.09125976   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.674        |
| fps                | 1516         |
| n_updates          | 142          |
| policy_entropy     | 6.773326     |
| policy_loss        | -0.004554276 |
| serial_timesteps   | 36352        |
| time_elapsed       | 149          |
| total_timesteps    | 290816       |
| value_loss         | 0.047271132  |
-------------------------------------
--------------------------------------
| approxkl           | 0.00781364    |
| clipfrac           | 0.10473633    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.711         |
| fps                | 2081          |
| n_updates          | 143           |
| policy_entropy     | 6.7446175     |
| policy_loss        | -0.0067082257 |
| serial_timesteps   | 36608         |
| time_elapsed       | 151           |
| total_timesteps    | 292864        |
| value_loss         | 0.04863943    |
--------------------------------------
-------------------------------------
| approxkl           | 0.007531299  |
| clipfrac           | 0.09897461   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.701        |
| fps                | 2125         |
| n_updates          | 144          |
| policy_entropy     | 6.738402     |
| policy_loss        | -0.005965976 |
| serial_timesteps   | 36864        |
| time_elapsed       | 152          |
| total_timesteps    | 294912       |
| value_loss         | 0.046374034  |
-------------------------------------
-------------------------------------
| approxkl           | 0.006594021  |
| clipfrac           | 0.08120117   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.751        |
| fps                | 2124         |
| n_updates          | 145          |
| policy_entropy     | 6.7381096    |
| policy_loss        | -0.004107403 |
| serial_timesteps   | 37120        |
| time_elapsed       | 153          |
| total_timesteps    | 296960       |
| value_loss         | 0.0464435    |
-------------------------------------
-------------------------------------
| approxkl           | 0.007967625  |
| clipfrac           | 0.10800781   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.709        |
| fps                | 2081         |
| n_updates          | 146          |
| policy_entropy     | 6.720197     |
| policy_loss        | -0.010056278 |
| serial_timesteps   | 37376        |
| time_elapsed       | 154          |
| total_timesteps    | 299008       |
| value_loss         | 0.04545088   |
-------------------------------------
Eval num_timesteps=300000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.007853652   |
| clipfrac           | 0.093847655   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.4          |
| explained_variance | 0.771         |
| fps                | 1491          |
| n_updates          | 147           |
| policy_entropy     | 6.7065916     |
| policy_loss        | -0.0069714626 |
| serial_timesteps   | 37632         |
| time_elapsed       | 155           |
| total_timesteps    | 301056        |
| value_loss         | 0.041922268   |
--------------------------------------
-------------------------------------
| approxkl           | 0.007914782  |
| clipfrac           | 0.10068359   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.544        |
| fps                | 2150         |
| n_updates          | 148          |
| policy_entropy     | 6.7265244    |
| policy_loss        | -0.009479923 |
| serial_timesteps   | 37888        |
| time_elapsed       | 156          |
| total_timesteps    | 303104       |
| value_loss         | 0.07611225   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0085777575 |
| clipfrac           | 0.1125       |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.722        |
| fps                | 2117         |
| n_updates          | 149          |
| policy_entropy     | 6.738992     |
| policy_loss        | -0.007617984 |
| serial_timesteps   | 38144        |
| time_elapsed       | 157          |
| total_timesteps    | 305152       |
| value_loss         | 0.045928817  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009536793  |
| clipfrac           | 0.12319336   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.624        |
| fps                | 2126         |
| n_updates          | 150          |
| policy_entropy     | 6.7157683    |
| policy_loss        | -0.010853611 |
| serial_timesteps   | 38400        |
| time_elapsed       | 158          |
| total_timesteps    | 307200       |
| value_loss         | 0.050930254  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009794012  |
| clipfrac           | 0.13657227   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.715        |
| fps                | 2133         |
| n_updates          | 151          |
| policy_entropy     | 6.69406      |
| policy_loss        | -0.010400012 |
| serial_timesteps   | 38656        |
| time_elapsed       | 159          |
| total_timesteps    | 309248       |
| value_loss         | 0.03820828   |
-------------------------------------
Eval num_timesteps=310000, episode_reward=-0.51 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008364612  |
| clipfrac           | 0.11191406   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.687        |
| fps                | 1511         |
| n_updates          | 152          |
| policy_entropy     | 6.698085     |
| policy_loss        | -0.010260898 |
| serial_timesteps   | 38912        |
| time_elapsed       | 160          |
| total_timesteps    | 311296       |
| value_loss         | 0.047179647  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009456552  |
| clipfrac           | 0.1328125    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.712        |
| fps                | 2145         |
| n_updates          | 153          |
| policy_entropy     | 6.6954966    |
| policy_loss        | -0.012396558 |
| serial_timesteps   | 39168        |
| time_elapsed       | 161          |
| total_timesteps    | 313344       |
| value_loss         | 0.041657012  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008021711  |
| clipfrac           | 0.10727539   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.751        |
| fps                | 2116         |
| n_updates          | 154          |
| policy_entropy     | 6.6717005    |
| policy_loss        | -0.006758637 |
| serial_timesteps   | 39424        |
| time_elapsed       | 162          |
| total_timesteps    | 315392       |
| value_loss         | 0.039482564  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007635513  |
| clipfrac           | 0.09907226   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.68         |
| fps                | 2127         |
| n_updates          | 155          |
| policy_entropy     | 6.6294417    |
| policy_loss        | -0.005714699 |
| serial_timesteps   | 39680        |
| time_elapsed       | 163          |
| total_timesteps    | 317440       |
| value_loss         | 0.046761513  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007338005  |
| clipfrac           | 0.09311523   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.723        |
| fps                | 2124         |
| n_updates          | 156          |
| policy_entropy     | 6.592524     |
| policy_loss        | -0.004787423 |
| serial_timesteps   | 39936        |
| time_elapsed       | 164          |
| total_timesteps    | 319488       |
| value_loss         | 0.047572993  |
-------------------------------------
Eval num_timesteps=320000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0071251886 |
| clipfrac           | 0.091845706  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.39        |
| explained_variance | 0.625        |
| fps                | 1507         |
| n_updates          | 157          |
| policy_entropy     | 6.5558844    |
| policy_loss        | -0.004004538 |
| serial_timesteps   | 40192        |
| time_elapsed       | 165          |
| total_timesteps    | 321536       |
| value_loss         | 0.048887093  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007429554  |
| clipfrac           | 0.096191406  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.703        |
| fps                | 2052         |
| n_updates          | 158          |
| policy_entropy     | 6.531183     |
| policy_loss        | -0.006478624 |
| serial_timesteps   | 40448        |
| time_elapsed       | 166          |
| total_timesteps    | 323584       |
| value_loss         | 0.048066992  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009087628  |
| clipfrac           | 0.11899414   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.61         |
| fps                | 2127         |
| n_updates          | 159          |
| policy_entropy     | 6.521076     |
| policy_loss        | -0.010512908 |
| serial_timesteps   | 40704        |
| time_elapsed       | 167          |
| total_timesteps    | 325632       |
| value_loss         | 0.06317663   |
-------------------------------------
------------------------------------
| approxkl           | 0.008220962 |
| clipfrac           | 0.10727539  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.42       |
| explained_variance | 0.71        |
| fps                | 2128        |
| n_updates          | 160         |
| policy_entropy     | 6.5106797   |
| policy_loss        | -0.00822041 |
| serial_timesteps   | 40960       |
| time_elapsed       | 168         |
| total_timesteps    | 327680      |
| value_loss         | 0.046085384 |
------------------------------------
--------------------------------------
| approxkl           | 0.0062476504  |
| clipfrac           | 0.07607422    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.43         |
| explained_variance | 0.694         |
| fps                | 2103          |
| n_updates          | 161           |
| policy_entropy     | 6.5230217     |
| policy_loss        | -0.0034973957 |
| serial_timesteps   | 41216         |
| time_elapsed       | 169           |
| total_timesteps    | 329728        |
| value_loss         | 0.052872278   |
--------------------------------------
Eval num_timesteps=330000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007950464  |
| clipfrac           | 0.10297851   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.595        |
| fps                | 1507         |
| n_updates          | 162          |
| policy_entropy     | 6.5506163    |
| policy_loss        | -0.008801067 |
| serial_timesteps   | 41472        |
| time_elapsed       | 170          |
| total_timesteps    | 331776       |
| value_loss         | 0.057071228  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007652401  |
| clipfrac           | 0.10385742   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.737        |
| fps                | 2116         |
| n_updates          | 163          |
| policy_entropy     | 6.5549154    |
| policy_loss        | -0.008367934 |
| serial_timesteps   | 41728        |
| time_elapsed       | 172          |
| total_timesteps    | 333824       |
| value_loss         | 0.043613505  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007973637  |
| clipfrac           | 0.107617185  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.572        |
| fps                | 2153         |
| n_updates          | 164          |
| policy_entropy     | 6.533769     |
| policy_loss        | -0.008684243 |
| serial_timesteps   | 41984        |
| time_elapsed       | 173          |
| total_timesteps    | 335872       |
| value_loss         | 0.06185012   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007826522  |
| clipfrac           | 0.106054686  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.703        |
| fps                | 2145         |
| n_updates          | 165          |
| policy_entropy     | 6.5072937    |
| policy_loss        | -0.008946564 |
| serial_timesteps   | 42240        |
| time_elapsed       | 174          |
| total_timesteps    | 337920       |
| value_loss         | 0.05022024   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0088543035 |
| clipfrac           | 0.12226562   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.521        |
| fps                | 2090         |
| n_updates          | 166          |
| policy_entropy     | 6.4754815    |
| policy_loss        | -0.009507166 |
| serial_timesteps   | 42496        |
| time_elapsed       | 175          |
| total_timesteps    | 339968       |
| value_loss         | 0.081711754  |
-------------------------------------
Eval num_timesteps=340000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.007744035   |
| clipfrac           | 0.10439453    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.49         |
| explained_variance | 0.619         |
| fps                | 1496          |
| n_updates          | 167           |
| policy_entropy     | 6.4654603     |
| policy_loss        | -0.0070327492 |
| serial_timesteps   | 42752         |
| time_elapsed       | 176           |
| total_timesteps    | 342016        |
| value_loss         | 0.05686421    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0076655997 |
| clipfrac           | 0.10566406   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.649        |
| fps                | 2151         |
| n_updates          | 168          |
| policy_entropy     | 6.4509916    |
| policy_loss        | -0.009099895 |
| serial_timesteps   | 43008        |
| time_elapsed       | 177          |
| total_timesteps    | 344064       |
| value_loss         | 0.045885254  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008125338  |
| clipfrac           | 0.1046875    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.671        |
| fps                | 2064         |
| n_updates          | 169          |
| policy_entropy     | 6.4181643    |
| policy_loss        | -0.009498678 |
| serial_timesteps   | 43264        |
| time_elapsed       | 178          |
| total_timesteps    | 346112       |
| value_loss         | 0.04619029   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009573033  |
| clipfrac           | 0.1361328    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.496        |
| fps                | 2101         |
| n_updates          | 170          |
| policy_entropy     | 6.4042406    |
| policy_loss        | -0.008007009 |
| serial_timesteps   | 43520        |
| time_elapsed       | 179          |
| total_timesteps    | 348160       |
| value_loss         | 0.07981999   |
-------------------------------------
Eval num_timesteps=350000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008912516  |
| clipfrac           | 0.11879883   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.706        |
| fps                | 1504         |
| n_updates          | 171          |
| policy_entropy     | 6.3830137    |
| policy_loss        | -0.010571666 |
| serial_timesteps   | 43776        |
| time_elapsed       | 180          |
| total_timesteps    | 350208       |
| value_loss         | 0.04748232   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0106055625 |
| clipfrac           | 0.1496582    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.68         |
| fps                | 2097         |
| n_updates          | 172          |
| policy_entropy     | 6.361761     |
| policy_loss        | -0.013611229 |
| serial_timesteps   | 44032        |
| time_elapsed       | 181          |
| total_timesteps    | 352256       |
| value_loss         | 0.047158606  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00699739   |
| clipfrac           | 0.08759765   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.576        |
| fps                | 2110         |
| n_updates          | 173          |
| policy_entropy     | 6.3450856    |
| policy_loss        | -0.006472609 |
| serial_timesteps   | 44288        |
| time_elapsed       | 182          |
| total_timesteps    | 354304       |
| value_loss         | 0.049268425  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010510623  |
| clipfrac           | 0.13833007   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.493        |
| fps                | 2109         |
| n_updates          | 174          |
| policy_entropy     | 6.342749     |
| policy_loss        | -0.014120581 |
| serial_timesteps   | 44544        |
| time_elapsed       | 183          |
| total_timesteps    | 356352       |
| value_loss         | 0.07287534   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008842212  |
| clipfrac           | 0.11791992   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.744        |
| fps                | 2133         |
| n_updates          | 175          |
| policy_entropy     | 6.310697     |
| policy_loss        | -0.009328055 |
| serial_timesteps   | 44800        |
| time_elapsed       | 184          |
| total_timesteps    | 358400       |
| value_loss         | 0.03973213   |
-------------------------------------
Eval num_timesteps=360000, episode_reward=-1.01 +/- 0.63
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.007954711   |
| clipfrac           | 0.106738284   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.47         |
| explained_variance | 0.71          |
| fps                | 1498          |
| n_updates          | 176           |
| policy_entropy     | 6.2640753     |
| policy_loss        | -0.0084947245 |
| serial_timesteps   | 45056         |
| time_elapsed       | 185           |
| total_timesteps    | 360448        |
| value_loss         | 0.045439042   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0096139135 |
| clipfrac           | 0.123046875  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.634        |
| fps                | 2092         |
| n_updates          | 177          |
| policy_entropy     | 6.266379     |
| policy_loss        | -0.011586828 |
| serial_timesteps   | 45312        |
| time_elapsed       | 186          |
| total_timesteps    | 362496       |
| value_loss         | 0.06905635   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008424554  |
| clipfrac           | 0.10625      |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.51        |
| explained_variance | 0.603        |
| fps                | 2128         |
| n_updates          | 178          |
| policy_entropy     | 6.270843     |
| policy_loss        | -0.012179113 |
| serial_timesteps   | 45568        |
| time_elapsed       | 187          |
| total_timesteps    | 364544       |
| value_loss         | 0.07727067   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008782392  |
| clipfrac           | 0.122998044  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.67         |
| fps                | 2129         |
| n_updates          | 179          |
| policy_entropy     | 6.2537966    |
| policy_loss        | -0.012068173 |
| serial_timesteps   | 45824        |
| time_elapsed       | 188          |
| total_timesteps    | 366592       |
| value_loss         | 0.06075579   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009520985  |
| clipfrac           | 0.13789062   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.68         |
| fps                | 2140         |
| n_updates          | 180          |
| policy_entropy     | 6.2092133    |
| policy_loss        | -0.012635784 |
| serial_timesteps   | 46080        |
| time_elapsed       | 189          |
| total_timesteps    | 368640       |
| value_loss         | 0.04158854   |
-------------------------------------
Eval num_timesteps=370000, episode_reward=-0.53 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008212697  |
| clipfrac           | 0.110644534  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.49        |
| explained_variance | 0.768        |
| fps                | 1481         |
| n_updates          | 181          |
| policy_entropy     | 6.179159     |
| policy_loss        | -0.009384824 |
| serial_timesteps   | 46336        |
| time_elapsed       | 190          |
| total_timesteps    | 370688       |
| value_loss         | 0.040692113  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0076989466 |
| clipfrac           | 0.10014649   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.76         |
| fps                | 2135         |
| n_updates          | 182          |
| policy_entropy     | 6.1897583    |
| policy_loss        | -0.006606005 |
| serial_timesteps   | 46592        |
| time_elapsed       | 192          |
| total_timesteps    | 372736       |
| value_loss         | 0.042303436  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0086673945 |
| clipfrac           | 0.11992188   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.721        |
| fps                | 2107         |
| n_updates          | 183          |
| policy_entropy     | 6.1805754    |
| policy_loss        | -0.011110549 |
| serial_timesteps   | 46848        |
| time_elapsed       | 193          |
| total_timesteps    | 374784       |
| value_loss         | 0.049708847  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0098204035 |
| clipfrac           | 0.13876954   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.657        |
| fps                | 2152         |
| n_updates          | 184          |
| policy_entropy     | 6.1691675    |
| policy_loss        | -0.011232858 |
| serial_timesteps   | 47104        |
| time_elapsed       | 194          |
| total_timesteps    | 376832       |
| value_loss         | 0.049579214  |
-------------------------------------
------------------------------------
| approxkl           | 0.007639238 |
| clipfrac           | 0.09746094  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.5        |
| explained_variance | 0.711       |
| fps                | 2154        |
| n_updates          | 185         |
| policy_entropy     | 6.1867657   |
| policy_loss        | -0.00831052 |
| serial_timesteps   | 47360       |
| time_elapsed       | 195         |
| total_timesteps    | 378880      |
| value_loss         | 0.045693714 |
------------------------------------
Eval num_timesteps=380000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009334937  |
| clipfrac           | 0.12734374   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.54        |
| explained_variance | 0.609        |
| fps                | 1526         |
| n_updates          | 186          |
| policy_entropy     | 6.2115436    |
| policy_loss        | -0.011797364 |
| serial_timesteps   | 47616        |
| time_elapsed       | 196          |
| total_timesteps    | 380928       |
| value_loss         | 0.07251148   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009709736  |
| clipfrac           | 0.13217774   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.687        |
| fps                | 2124         |
| n_updates          | 187          |
| policy_entropy     | 6.2235737    |
| policy_loss        | -0.014020006 |
| serial_timesteps   | 47872        |
| time_elapsed       | 197          |
| total_timesteps    | 382976       |
| value_loss         | 0.052353196  |
-------------------------------------
-------------------------------------
| approxkl           | 0.013562597  |
| clipfrac           | 0.18759766   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.59        |
| explained_variance | 0.575        |
| fps                | 2140         |
| n_updates          | 188          |
| policy_entropy     | 6.21605      |
| policy_loss        | -0.017132502 |
| serial_timesteps   | 48128        |
| time_elapsed       | 198          |
| total_timesteps    | 385024       |
| value_loss         | 0.06588611   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0087067615 |
| clipfrac           | 0.120507814  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.682        |
| fps                | 2145         |
| n_updates          | 189          |
| policy_entropy     | 6.201053     |
| policy_loss        | -0.008289209 |
| serial_timesteps   | 48384        |
| time_elapsed       | 199          |
| total_timesteps    | 387072       |
| value_loss         | 0.04919859   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008517725  |
| clipfrac           | 0.11264648   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.57        |
| explained_variance | 0.726        |
| fps                | 2138         |
| n_updates          | 190          |
| policy_entropy     | 6.2095366    |
| policy_loss        | -0.010218995 |
| serial_timesteps   | 48640        |
| time_elapsed       | 200          |
| total_timesteps    | 389120       |
| value_loss         | 0.049015783  |
-------------------------------------
Eval num_timesteps=390000, episode_reward=-0.73 +/- 0.46
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008528323  |
| clipfrac           | 0.11333008   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.52        |
| explained_variance | 0.67         |
| fps                | 1514         |
| n_updates          | 191          |
| policy_entropy     | 6.211913     |
| policy_loss        | -0.010520641 |
| serial_timesteps   | 48896        |
| time_elapsed       | 201          |
| total_timesteps    | 391168       |
| value_loss         | 0.05836054   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008617165  |
| clipfrac           | 0.11484375   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.5         |
| explained_variance | 0.704        |
| fps                | 2111         |
| n_updates          | 192          |
| policy_entropy     | 6.2222867    |
| policy_loss        | -0.010498388 |
| serial_timesteps   | 49152        |
| time_elapsed       | 202          |
| total_timesteps    | 393216       |
| value_loss         | 0.05498147   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009282188  |
| clipfrac           | 0.1296875    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.691        |
| fps                | 2097         |
| n_updates          | 193          |
| policy_entropy     | 6.2216616    |
| policy_loss        | -0.009997801 |
| serial_timesteps   | 49408        |
| time_elapsed       | 203          |
| total_timesteps    | 395264       |
| value_loss         | 0.05834948   |
-------------------------------------
--------------------------------------
| approxkl           | 0.007835841   |
| clipfrac           | 0.10439453    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.47         |
| explained_variance | 0.719         |
| fps                | 2157          |
| n_updates          | 194           |
| policy_entropy     | 6.2071443     |
| policy_loss        | -0.0073000295 |
| serial_timesteps   | 49664         |
| time_elapsed       | 204           |
| total_timesteps    | 397312        |
| value_loss         | 0.050719053   |
--------------------------------------
--------------------------------------
| approxkl           | 0.007911467   |
| clipfrac           | 0.106933594   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.48         |
| explained_variance | 0.788         |
| fps                | 2146          |
| n_updates          | 195           |
| policy_entropy     | 6.215122      |
| policy_loss        | -0.0072336597 |
| serial_timesteps   | 49920         |
| time_elapsed       | 205           |
| total_timesteps    | 399360        |
| value_loss         | 0.044801045   |
--------------------------------------
Eval num_timesteps=400000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009471212  |
| clipfrac           | 0.13110352   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.658        |
| fps                | 1504         |
| n_updates          | 196          |
| policy_entropy     | 6.229697     |
| policy_loss        | -0.010183426 |
| serial_timesteps   | 50176        |
| time_elapsed       | 206          |
| total_timesteps    | 401408       |
| value_loss         | 0.045790475  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008836633  |
| clipfrac           | 0.123242185  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.735        |
| fps                | 2169         |
| n_updates          | 197          |
| policy_entropy     | 6.2149487    |
| policy_loss        | -0.010067073 |
| serial_timesteps   | 50432        |
| time_elapsed       | 207          |
| total_timesteps    | 403456       |
| value_loss         | 0.048711516  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0071216105 |
| clipfrac           | 0.08886719   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.61         |
| fps                | 2163         |
| n_updates          | 198          |
| policy_entropy     | 6.1744394    |
| policy_loss        | -0.009611539 |
| serial_timesteps   | 50688        |
| time_elapsed       | 208          |
| total_timesteps    | 405504       |
| value_loss         | 0.051854294  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0075473785 |
| clipfrac           | 0.09677734   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.705        |
| fps                | 2201         |
| n_updates          | 199          |
| policy_entropy     | 6.1497874    |
| policy_loss        | -0.004764649 |
| serial_timesteps   | 50944        |
| time_elapsed       | 209          |
| total_timesteps    | 407552       |
| value_loss         | 0.047846697  |
-------------------------------------
--------------------------------------
| approxkl           | 0.007515665   |
| clipfrac           | 0.09584961    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.43         |
| explained_variance | 0.732         |
| fps                | 2128          |
| n_updates          | 200           |
| policy_entropy     | 6.1232224     |
| policy_loss        | -0.0057053487 |
| serial_timesteps   | 51200         |
| time_elapsed       | 210           |
| total_timesteps    | 409600        |
| value_loss         | 0.047586355   |
--------------------------------------
Eval num_timesteps=410000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.011025118  |
| clipfrac           | 0.13950196   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.708        |
| fps                | 1489         |
| n_updates          | 201          |
| policy_entropy     | 6.114161     |
| policy_loss        | -0.013966324 |
| serial_timesteps   | 51456        |
| time_elapsed       | 211          |
| total_timesteps    | 411648       |
| value_loss         | 0.046747416  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007671618  |
| clipfrac           | 0.10258789   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.728        |
| fps                | 2141         |
| n_updates          | 202          |
| policy_entropy     | 6.1053095    |
| policy_loss        | -0.008439441 |
| serial_timesteps   | 51712        |
| time_elapsed       | 212          |
| total_timesteps    | 413696       |
| value_loss         | 0.04872674   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008206261  |
| clipfrac           | 0.10751953   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.68         |
| fps                | 2157         |
| n_updates          | 203          |
| policy_entropy     | 6.088646     |
| policy_loss        | -0.008358421 |
| serial_timesteps   | 51968        |
| time_elapsed       | 213          |
| total_timesteps    | 415744       |
| value_loss         | 0.04310919   |
-------------------------------------
------------------------------------
| approxkl           | 0.008927519 |
| clipfrac           | 0.122558594 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.44       |
| explained_variance | 0.664       |
| fps                | 2063        |
| n_updates          | 204         |
| policy_entropy     | 6.0861506   |
| policy_loss        | -0.00909239 |
| serial_timesteps   | 52224       |
| time_elapsed       | 214         |
| total_timesteps    | 417792      |
| value_loss         | 0.054914616 |
------------------------------------
--------------------------------------
| approxkl           | 0.007023274   |
| clipfrac           | 0.09165039    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.43         |
| explained_variance | 0.668         |
| fps                | 2092          |
| n_updates          | 205           |
| policy_entropy     | 6.0728984     |
| policy_loss        | -0.0032332924 |
| serial_timesteps   | 52480         |
| time_elapsed       | 215           |
| total_timesteps    | 419840        |
| value_loss         | 0.04700968    |
--------------------------------------
Eval num_timesteps=420000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.00797032   |
| clipfrac           | 0.10566406   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.672        |
| fps                | 1507         |
| n_updates          | 206          |
| policy_entropy     | 6.0646524    |
| policy_loss        | -0.009566924 |
| serial_timesteps   | 52736        |
| time_elapsed       | 216          |
| total_timesteps    | 421888       |
| value_loss         | 0.05167252   |
-------------------------------------
------------------------------------
| approxkl           | 0.008229172 |
| clipfrac           | 0.11308594  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.43       |
| explained_variance | 0.658       |
| fps                | 2100        |
| n_updates          | 207         |
| policy_entropy     | 6.05522     |
| policy_loss        | -0.00677335 |
| serial_timesteps   | 52992       |
| time_elapsed       | 218         |
| total_timesteps    | 423936      |
| value_loss         | 0.052273177 |
------------------------------------
-------------------------------------
| approxkl           | 0.008138412  |
| clipfrac           | 0.1128418    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.727        |
| fps                | 2008         |
| n_updates          | 208          |
| policy_entropy     | 6.0377536    |
| policy_loss        | -0.007921294 |
| serial_timesteps   | 53248        |
| time_elapsed       | 219          |
| total_timesteps    | 425984       |
| value_loss         | 0.047831528  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008069411  |
| clipfrac           | 0.10527344   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.723        |
| fps                | 2099         |
| n_updates          | 209          |
| policy_entropy     | 6.0496855    |
| policy_loss        | -0.008216296 |
| serial_timesteps   | 53504        |
| time_elapsed       | 220          |
| total_timesteps    | 428032       |
| value_loss         | 0.04990096   |
-------------------------------------
Eval num_timesteps=430000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007202392  |
| clipfrac           | 0.08920898   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.714        |
| fps                | 1499         |
| n_updates          | 210          |
| policy_entropy     | 6.052199     |
| policy_loss        | -0.005083942 |
| serial_timesteps   | 53760        |
| time_elapsed       | 221          |
| total_timesteps    | 430080       |
| value_loss         | 0.04534203   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008067477  |
| clipfrac           | 0.101904295  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.645        |
| fps                | 2121         |
| n_updates          | 211          |
| policy_entropy     | 6.062957     |
| policy_loss        | -0.006296862 |
| serial_timesteps   | 54016        |
| time_elapsed       | 222          |
| total_timesteps    | 432128       |
| value_loss         | 0.061145168  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007637144  |
| clipfrac           | 0.101708986  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.677        |
| fps                | 2123         |
| n_updates          | 212          |
| policy_entropy     | 6.0567374    |
| policy_loss        | -0.006213566 |
| serial_timesteps   | 54272        |
| time_elapsed       | 223          |
| total_timesteps    | 434176       |
| value_loss         | 0.047566287  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008663252  |
| clipfrac           | 0.117041014  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.732        |
| fps                | 2142         |
| n_updates          | 213          |
| policy_entropy     | 6.01597      |
| policy_loss        | -0.006804333 |
| serial_timesteps   | 54528        |
| time_elapsed       | 224          |
| total_timesteps    | 436224       |
| value_loss         | 0.048803013  |
-------------------------------------
--------------------------------------
| approxkl           | 0.007915574   |
| clipfrac           | 0.10268555    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.695         |
| fps                | 2161          |
| n_updates          | 214           |
| policy_entropy     | 5.9996843     |
| policy_loss        | -0.0056176586 |
| serial_timesteps   | 54784         |
| time_elapsed       | 225           |
| total_timesteps    | 438272        |
| value_loss         | 0.050155014   |
--------------------------------------
Eval num_timesteps=440000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008570579  |
| clipfrac           | 0.117333986  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.748        |
| fps                | 1496         |
| n_updates          | 215          |
| policy_entropy     | 5.999728     |
| policy_loss        | -0.005548824 |
| serial_timesteps   | 55040        |
| time_elapsed       | 226          |
| total_timesteps    | 440320       |
| value_loss         | 0.047483407  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007868027  |
| clipfrac           | 0.10458984   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.39        |
| explained_variance | 0.674        |
| fps                | 2112         |
| n_updates          | 216          |
| policy_entropy     | 5.990481     |
| policy_loss        | -0.005579085 |
| serial_timesteps   | 55296        |
| time_elapsed       | 227          |
| total_timesteps    | 442368       |
| value_loss         | 0.050720792  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007446344  |
| clipfrac           | 0.09418945   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.677        |
| fps                | 2177         |
| n_updates          | 217          |
| policy_entropy     | 5.9525304    |
| policy_loss        | -0.005221298 |
| serial_timesteps   | 55552        |
| time_elapsed       | 228          |
| total_timesteps    | 444416       |
| value_loss         | 0.04792469   |
-------------------------------------
--------------------------------------
| approxkl           | 0.00866962    |
| clipfrac           | 0.11811523    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.4          |
| explained_variance | 0.664         |
| fps                | 2186          |
| n_updates          | 218           |
| policy_entropy     | 5.9137845     |
| policy_loss        | -0.0058621233 |
| serial_timesteps   | 55808         |
| time_elapsed       | 229           |
| total_timesteps    | 446464        |
| value_loss         | 0.05173359    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0076328563 |
| clipfrac           | 0.09829102   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.699        |
| fps                | 2150         |
| n_updates          | 219          |
| policy_entropy     | 5.885564     |
| policy_loss        | -0.005150189 |
| serial_timesteps   | 56064        |
| time_elapsed       | 230          |
| total_timesteps    | 448512       |
| value_loss         | 0.047809325  |
-------------------------------------
Eval num_timesteps=450000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.009795701 |
| clipfrac           | 0.12011719  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.4        |
| explained_variance | 0.699       |
| fps                | 1467        |
| n_updates          | 220         |
| policy_entropy     | 5.878436    |
| policy_loss        | -0.01097048 |
| serial_timesteps   | 56320       |
| time_elapsed       | 231         |
| total_timesteps    | 450560      |
| value_loss         | 0.050132513 |
------------------------------------
--------------------------------------
| approxkl           | 0.0071724267  |
| clipfrac           | 0.088085935   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.4          |
| explained_variance | 0.677         |
| fps                | 2152          |
| n_updates          | 221           |
| policy_entropy     | 5.847842      |
| policy_loss        | -0.0056575406 |
| serial_timesteps   | 56576         |
| time_elapsed       | 232           |
| total_timesteps    | 452608        |
| value_loss         | 0.047676258   |
--------------------------------------
------------------------------------
| approxkl           | 0.009274595 |
| clipfrac           | 0.13032226  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.42       |
| explained_variance | 0.688       |
| fps                | 2140        |
| n_updates          | 222         |
| policy_entropy     | 5.81478     |
| policy_loss        | -0.00889937 |
| serial_timesteps   | 56832       |
| time_elapsed       | 233         |
| total_timesteps    | 454656      |
| value_loss         | 0.04733295  |
------------------------------------
-------------------------------------
| approxkl           | 0.00881706   |
| clipfrac           | 0.1199707    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.564        |
| fps                | 2136         |
| n_updates          | 223          |
| policy_entropy     | 5.7988844    |
| policy_loss        | -0.007118591 |
| serial_timesteps   | 57088        |
| time_elapsed       | 234          |
| total_timesteps    | 456704       |
| value_loss         | 0.0715854    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008232921  |
| clipfrac           | 0.105566405  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.688        |
| fps                | 2106         |
| n_updates          | 224          |
| policy_entropy     | 5.766706     |
| policy_loss        | -0.007302421 |
| serial_timesteps   | 57344        |
| time_elapsed       | 235          |
| total_timesteps    | 458752       |
| value_loss         | 0.052277762  |
-------------------------------------
Eval num_timesteps=460000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009017436  |
| clipfrac           | 0.12900391   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.706        |
| fps                | 1508         |
| n_updates          | 225          |
| policy_entropy     | 5.7359705    |
| policy_loss        | -0.009276364 |
| serial_timesteps   | 57600        |
| time_elapsed       | 236          |
| total_timesteps    | 460800       |
| value_loss         | 0.04804858   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009212553  |
| clipfrac           | 0.119824216  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.688        |
| fps                | 2159         |
| n_updates          | 226          |
| policy_entropy     | 5.724931     |
| policy_loss        | -0.007853908 |
| serial_timesteps   | 57856        |
| time_elapsed       | 238          |
| total_timesteps    | 462848       |
| value_loss         | 0.056740217  |
-------------------------------------
--------------------------------------
| approxkl           | 0.007842032   |
| clipfrac           | 0.10449219    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.46         |
| explained_variance | 0.742         |
| fps                | 2114          |
| n_updates          | 227           |
| policy_entropy     | 5.7048464     |
| policy_loss        | -0.0062666563 |
| serial_timesteps   | 58112         |
| time_elapsed       | 239           |
| total_timesteps    | 464896        |
| value_loss         | 0.050929796   |
--------------------------------------
------------------------------------
| approxkl           | 0.008446162 |
| clipfrac           | 0.12001953  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.44       |
| explained_variance | 0.701       |
| fps                | 2167        |
| n_updates          | 228         |
| policy_entropy     | 5.7101054   |
| policy_loss        | -0.00708635 |
| serial_timesteps   | 58368       |
| time_elapsed       | 240         |
| total_timesteps    | 466944      |
| value_loss         | 0.05151705  |
------------------------------------
--------------------------------------
| approxkl           | 0.0077404142  |
| clipfrac           | 0.103271484   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.44         |
| explained_variance | 0.744         |
| fps                | 2148          |
| n_updates          | 229           |
| policy_entropy     | 5.725527      |
| policy_loss        | -0.0044538844 |
| serial_timesteps   | 58624         |
| time_elapsed       | 240           |
| total_timesteps    | 468992        |
| value_loss         | 0.048116345   |
--------------------------------------
Eval num_timesteps=470000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.008110445 |
| clipfrac           | 0.11220703  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.42       |
| explained_variance | 0.673       |
| fps                | 1536        |
| n_updates          | 230         |
| policy_entropy     | 5.7084603   |
| policy_loss        | -0.00544734 |
| serial_timesteps   | 58880       |
| time_elapsed       | 241         |
| total_timesteps    | 471040      |
| value_loss         | 0.050540753 |
------------------------------------
-------------------------------------
| approxkl           | 0.007715768  |
| clipfrac           | 0.10341797   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.732        |
| fps                | 2120         |
| n_updates          | 231          |
| policy_entropy     | 5.67167      |
| policy_loss        | -0.006327582 |
| serial_timesteps   | 59136        |
| time_elapsed       | 243          |
| total_timesteps    | 473088       |
| value_loss         | 0.048709057  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009120825   |
| clipfrac           | 0.12612304    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.4          |
| explained_variance | 0.665         |
| fps                | 2172          |
| n_updates          | 232           |
| policy_entropy     | 5.678941      |
| policy_loss        | -0.0075747855 |
| serial_timesteps   | 59392         |
| time_elapsed       | 244           |
| total_timesteps    | 475136        |
| value_loss         | 0.05165835    |
--------------------------------------
-------------------------------------
| approxkl           | 0.009313954  |
| clipfrac           | 0.1319336    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.728        |
| fps                | 2141         |
| n_updates          | 233          |
| policy_entropy     | 5.676895     |
| policy_loss        | -0.009053325 |
| serial_timesteps   | 59648        |
| time_elapsed       | 245          |
| total_timesteps    | 477184       |
| value_loss         | 0.04906095   |
-------------------------------------
--------------------------------------
| approxkl           | 0.007989271   |
| clipfrac           | 0.10385742    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.713         |
| fps                | 2185          |
| n_updates          | 234           |
| policy_entropy     | 5.6413665     |
| policy_loss        | -0.0022519447 |
| serial_timesteps   | 59904         |
| time_elapsed       | 246           |
| total_timesteps    | 479232        |
| value_loss         | 0.051548786   |
--------------------------------------
Eval num_timesteps=480000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008858694  |
| clipfrac           | 0.11992188   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.704        |
| fps                | 1524         |
| n_updates          | 235          |
| policy_entropy     | 5.6130524    |
| policy_loss        | -0.006846717 |
| serial_timesteps   | 60160        |
| time_elapsed       | 247          |
| total_timesteps    | 481280       |
| value_loss         | 0.047089767  |
-------------------------------------
------------------------------------
| approxkl           | 0.008745046 |
| clipfrac           | 0.12055664  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.42       |
| explained_variance | 0.71        |
| fps                | 2169        |
| n_updates          | 236         |
| policy_entropy     | 5.6046185   |
| policy_loss        | -0.006086   |
| serial_timesteps   | 60416       |
| time_elapsed       | 248         |
| total_timesteps    | 483328      |
| value_loss         | 0.05209581  |
------------------------------------
------------------------------------
| approxkl           | 0.008289756 |
| clipfrac           | 0.111132815 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.41       |
| explained_variance | 0.682       |
| fps                | 2184        |
| n_updates          | 237         |
| policy_entropy     | 5.5748525   |
| policy_loss        | -0.00446801 |
| serial_timesteps   | 60672       |
| time_elapsed       | 249         |
| total_timesteps    | 485376      |
| value_loss         | 0.045884445 |
------------------------------------
--------------------------------------
| approxkl           | 0.0074336366  |
| clipfrac           | 0.0949707     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.717         |
| fps                | 2164          |
| n_updates          | 238           |
| policy_entropy     | 5.533351      |
| policy_loss        | -0.0032355008 |
| serial_timesteps   | 60928         |
| time_elapsed       | 250           |
| total_timesteps    | 487424        |
| value_loss         | 0.04953483    |
--------------------------------------
--------------------------------------
| approxkl           | 0.008050903   |
| clipfrac           | 0.10727539    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.4          |
| explained_variance | 0.657         |
| fps                | 2129          |
| n_updates          | 239           |
| policy_entropy     | 5.5105047     |
| policy_loss        | -0.0058207987 |
| serial_timesteps   | 61184         |
| time_elapsed       | 251           |
| total_timesteps    | 489472        |
| value_loss         | 0.052394062   |
--------------------------------------
Eval num_timesteps=490000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.0075653745  |
| clipfrac           | 0.099365234   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.706         |
| fps                | 1539          |
| n_updates          | 240           |
| policy_entropy     | 5.5093527     |
| policy_loss        | -0.0038188878 |
| serial_timesteps   | 61440         |
| time_elapsed       | 252           |
| total_timesteps    | 491520        |
| value_loss         | 0.049408086   |
--------------------------------------
------------------------------------
| approxkl           | 0.007723401 |
| clipfrac           | 0.10595703  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.4        |
| explained_variance | 0.66        |
| fps                | 2177        |
| n_updates          | 241         |
| policy_entropy     | 5.502191    |
| policy_loss        | -0.0061417  |
| serial_timesteps   | 61696       |
| time_elapsed       | 253         |
| total_timesteps    | 493568      |
| value_loss         | 0.053995945 |
------------------------------------
--------------------------------------
| approxkl           | 0.007435591   |
| clipfrac           | 0.095751956   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.709         |
| fps                | 2147          |
| n_updates          | 242           |
| policy_entropy     | 5.491832      |
| policy_loss        | -0.0038624636 |
| serial_timesteps   | 61952         |
| time_elapsed       | 254           |
| total_timesteps    | 495616        |
| value_loss         | 0.049143817   |
--------------------------------------
--------------------------------------
| approxkl           | 0.0075181955  |
| clipfrac           | 0.095751956   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.679         |
| fps                | 2153          |
| n_updates          | 243           |
| policy_entropy     | 5.480578      |
| policy_loss        | -0.0034746316 |
| serial_timesteps   | 62208         |
| time_elapsed       | 255           |
| total_timesteps    | 497664        |
| value_loss         | 0.05368521    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0072908727 |
| clipfrac           | 0.09736328   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.68         |
| fps                | 2187         |
| n_updates          | 244          |
| policy_entropy     | 5.469162     |
| policy_loss        | -0.006172185 |
| serial_timesteps   | 62464        |
| time_elapsed       | 256          |
| total_timesteps    | 499712       |
| value_loss         | 0.047548782  |
-------------------------------------
Eval num_timesteps=500000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008957766  |
| clipfrac           | 0.12675782   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.7          |
| fps                | 1539         |
| n_updates          | 245          |
| policy_entropy     | 5.461328     |
| policy_loss        | -0.006681098 |
| serial_timesteps   | 62720        |
| time_elapsed       | 257          |
| total_timesteps    | 501760       |
| value_loss         | 0.054526024  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0074637355  |
| clipfrac           | 0.09448242    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.681         |
| fps                | 2159          |
| n_updates          | 246           |
| policy_entropy     | 5.4426746     |
| policy_loss        | -0.0041168043 |
| serial_timesteps   | 62976         |
| time_elapsed       | 258           |
| total_timesteps    | 503808        |
| value_loss         | 0.048950635   |
--------------------------------------
--------------------------------------
| approxkl           | 0.008064991   |
| clipfrac           | 0.107666016   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.719         |
| fps                | 2129          |
| n_updates          | 247           |
| policy_entropy     | 5.4288187     |
| policy_loss        | -0.0043082344 |
| serial_timesteps   | 63232         |
| time_elapsed       | 259           |
| total_timesteps    | 505856        |
| value_loss         | 0.0518288     |
--------------------------------------
--------------------------------------
| approxkl           | 0.008791406   |
| clipfrac           | 0.12109375    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.4          |
| explained_variance | 0.684         |
| fps                | 2145          |
| n_updates          | 248           |
| policy_entropy     | 5.423923      |
| policy_loss        | -0.0063334242 |
| serial_timesteps   | 63488         |
| time_elapsed       | 260           |
| total_timesteps    | 507904        |
| value_loss         | 0.05228753    |
--------------------------------------
-------------------------------------
| approxkl           | 0.008455508  |
| clipfrac           | 0.110644534  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.73         |
| fps                | 2130         |
| n_updates          | 249          |
| policy_entropy     | 5.4072447    |
| policy_loss        | -0.005487468 |
| serial_timesteps   | 63744        |
| time_elapsed       | 261          |
| total_timesteps    | 509952       |
| value_loss         | 0.04989297   |
-------------------------------------
Eval num_timesteps=510000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.0073434883  |
| clipfrac           | 0.09399414    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.702         |
| fps                | 1493          |
| n_updates          | 250           |
| policy_entropy     | 5.405362      |
| policy_loss        | -0.0025249063 |
| serial_timesteps   | 64000         |
| time_elapsed       | 262           |
| total_timesteps    | 512000        |
| value_loss         | 0.05448807    |
--------------------------------------
--------------------------------------
| approxkl           | 0.008236193   |
| clipfrac           | 0.11264648    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.713         |
| fps                | 2096          |
| n_updates          | 251           |
| policy_entropy     | 5.4165545     |
| policy_loss        | -0.0064893523 |
| serial_timesteps   | 64256         |
| time_elapsed       | 263           |
| total_timesteps    | 514048        |
| value_loss         | 0.047351252   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0083099175 |
| clipfrac           | 0.11586914   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.725        |
| fps                | 2122         |
| n_updates          | 252          |
| policy_entropy     | 5.40049      |
| policy_loss        | -0.005817394 |
| serial_timesteps   | 64512        |
| time_elapsed       | 264          |
| total_timesteps    | 516096       |
| value_loss         | 0.051449142  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007811261  |
| clipfrac           | 0.102832034  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.704        |
| fps                | 2101         |
| n_updates          | 253          |
| policy_entropy     | 5.3742657    |
| policy_loss        | -0.005307008 |
| serial_timesteps   | 64768        |
| time_elapsed       | 265          |
| total_timesteps    | 518144       |
| value_loss         | 0.04738707   |
-------------------------------------
Eval num_timesteps=520000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008087176  |
| clipfrac           | 0.109521486  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.738        |
| fps                | 1511         |
| n_updates          | 254          |
| policy_entropy     | 5.363955     |
| policy_loss        | -0.006181118 |
| serial_timesteps   | 65024        |
| time_elapsed       | 266          |
| total_timesteps    | 520192       |
| value_loss         | 0.050505675  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008768361  |
| clipfrac           | 0.124658205  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.683        |
| fps                | 2129         |
| n_updates          | 255          |
| policy_entropy     | 5.353097     |
| policy_loss        | -0.008246968 |
| serial_timesteps   | 65280        |
| time_elapsed       | 268          |
| total_timesteps    | 522240       |
| value_loss         | 0.049935285  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009761075  |
| clipfrac           | 0.13754883   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.731        |
| fps                | 2129         |
| n_updates          | 256          |
| policy_entropy     | 5.3462453    |
| policy_loss        | -0.007364591 |
| serial_timesteps   | 65536        |
| time_elapsed       | 269          |
| total_timesteps    | 524288       |
| value_loss         | 0.05000494   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008707194  |
| clipfrac           | 0.118652344  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.671        |
| fps                | 2115         |
| n_updates          | 257          |
| policy_entropy     | 5.3422318    |
| policy_loss        | -0.006231956 |
| serial_timesteps   | 65792        |
| time_elapsed       | 270          |
| total_timesteps    | 526336       |
| value_loss         | 0.051947713  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010349462  |
| clipfrac           | 0.1475586    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.704        |
| fps                | 2116         |
| n_updates          | 258          |
| policy_entropy     | 5.332953     |
| policy_loss        | -0.009761236 |
| serial_timesteps   | 66048        |
| time_elapsed       | 270          |
| total_timesteps    | 528384       |
| value_loss         | 0.052129496  |
-------------------------------------
Eval num_timesteps=530000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007829054  |
| clipfrac           | 0.10053711   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.712        |
| fps                | 1476         |
| n_updates          | 259          |
| policy_entropy     | 5.2942233    |
| policy_loss        | -0.004182772 |
| serial_timesteps   | 66304        |
| time_elapsed       | 271          |
| total_timesteps    | 530432       |
| value_loss         | 0.05437208   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0076277093  |
| clipfrac           | 0.100048825   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.713         |
| fps                | 2146          |
| n_updates          | 260           |
| policy_entropy     | 5.27172       |
| policy_loss        | -0.0051849573 |
| serial_timesteps   | 66560         |
| time_elapsed       | 273           |
| total_timesteps    | 532480        |
| value_loss         | 0.047010317   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008279996  |
| clipfrac           | 0.11401367   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.733        |
| fps                | 2110         |
| n_updates          | 261          |
| policy_entropy     | 5.2687283    |
| policy_loss        | -0.005705794 |
| serial_timesteps   | 66816        |
| time_elapsed       | 274          |
| total_timesteps    | 534528       |
| value_loss         | 0.052184187  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008082247   |
| clipfrac           | 0.10869141    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.718         |
| fps                | 2187          |
| n_updates          | 262           |
| policy_entropy     | 5.2383904     |
| policy_loss        | -0.0036000677 |
| serial_timesteps   | 67072         |
| time_elapsed       | 275           |
| total_timesteps    | 536576        |
| value_loss         | 0.046425566   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0067374394 |
| clipfrac           | 0.08227539   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.738        |
| fps                | 2154         |
| n_updates          | 263          |
| policy_entropy     | 5.201045     |
| policy_loss        | -0.003018035 |
| serial_timesteps   | 67328        |
| time_elapsed       | 276          |
| total_timesteps    | 538624       |
| value_loss         | 0.04931033   |
-------------------------------------
Eval num_timesteps=540000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008427858  |
| clipfrac           | 0.11123047   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.673        |
| fps                | 1515         |
| n_updates          | 264          |
| policy_entropy     | 5.155883     |
| policy_loss        | -0.004568447 |
| serial_timesteps   | 67584        |
| time_elapsed       | 277          |
| total_timesteps    | 540672       |
| value_loss         | 0.048833627  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00894537   |
| clipfrac           | 0.12177734   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.733        |
| fps                | 2112         |
| n_updates          | 265          |
| policy_entropy     | 5.1029572    |
| policy_loss        | -0.005775642 |
| serial_timesteps   | 67840        |
| time_elapsed       | 278          |
| total_timesteps    | 542720       |
| value_loss         | 0.04964152   |
-------------------------------------
--------------------------------------
| approxkl           | 0.009390842   |
| clipfrac           | 0.13515624    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.667         |
| fps                | 2106          |
| n_updates          | 266           |
| policy_entropy     | 5.085068      |
| policy_loss        | -0.0068730614 |
| serial_timesteps   | 68096         |
| time_elapsed       | 279           |
| total_timesteps    | 544768        |
| value_loss         | 0.053901684   |
--------------------------------------
--------------------------------------
| approxkl           | 0.007916084   |
| clipfrac           | 0.10756836    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.705         |
| fps                | 2125          |
| n_updates          | 267           |
| policy_entropy     | 5.0734324     |
| policy_loss        | -0.0053077303 |
| serial_timesteps   | 68352         |
| time_elapsed       | 280           |
| total_timesteps    | 546816        |
| value_loss         | 0.048934627   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008917068  |
| clipfrac           | 0.1260254    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.701        |
| fps                | 2141         |
| n_updates          | 268          |
| policy_entropy     | 5.0485206    |
| policy_loss        | -0.005839377 |
| serial_timesteps   | 68608        |
| time_elapsed       | 281          |
| total_timesteps    | 548864       |
| value_loss         | 0.05455658   |
-------------------------------------
Eval num_timesteps=550000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.009178823 |
| clipfrac           | 0.124658205 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.42       |
| explained_variance | 0.691       |
| fps                | 1513        |
| n_updates          | 269         |
| policy_entropy     | 5.0342293   |
| policy_loss        | -0.00651678 |
| serial_timesteps   | 68864       |
| time_elapsed       | 282         |
| total_timesteps    | 550912      |
| value_loss         | 0.049404033 |
------------------------------------
--------------------------------------
| approxkl           | 0.007909334   |
| clipfrac           | 0.10771485    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.733         |
| fps                | 2175          |
| n_updates          | 270           |
| policy_entropy     | 5.021691      |
| policy_loss        | -0.0039334996 |
| serial_timesteps   | 69120         |
| time_elapsed       | 283           |
| total_timesteps    | 552960        |
| value_loss         | 0.051388323   |
--------------------------------------
--------------------------------------
| approxkl           | 0.008577237   |
| clipfrac           | 0.11811523    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.696         |
| fps                | 2170          |
| n_updates          | 271           |
| policy_entropy     | 5.0256796     |
| policy_loss        | -0.0070681064 |
| serial_timesteps   | 69376         |
| time_elapsed       | 284           |
| total_timesteps    | 555008        |
| value_loss         | 0.047770273   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008581458  |
| clipfrac           | 0.11464844   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.725        |
| fps                | 2131         |
| n_updates          | 272          |
| policy_entropy     | 5.0445447    |
| policy_loss        | -0.004709783 |
| serial_timesteps   | 69632        |
| time_elapsed       | 285          |
| total_timesteps    | 557056       |
| value_loss         | 0.050608397  |
-------------------------------------
------------------------------------
| approxkl           | 0.008405243 |
| clipfrac           | 0.11235352  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.41       |
| explained_variance | 0.664       |
| fps                | 2119        |
| n_updates          | 273         |
| policy_entropy     | 5.0261097   |
| policy_loss        | -0.00581271 |
| serial_timesteps   | 69888       |
| time_elapsed       | 286         |
| total_timesteps    | 559104      |
| value_loss         | 0.05268584  |
------------------------------------
Eval num_timesteps=560000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.009165674 |
| clipfrac           | 0.12866211  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.42       |
| explained_variance | 0.724       |
| fps                | 1505        |
| n_updates          | 274         |
| policy_entropy     | 4.9942865   |
| policy_loss        | -0.00590794 |
| serial_timesteps   | 70144       |
| time_elapsed       | 287         |
| total_timesteps    | 561152      |
| value_loss         | 0.051148403 |
------------------------------------
-------------------------------------
| approxkl           | 0.008538246  |
| clipfrac           | 0.11884765   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.698        |
| fps                | 2151         |
| n_updates          | 275          |
| policy_entropy     | 4.9908075    |
| policy_loss        | -0.005382261 |
| serial_timesteps   | 70400        |
| time_elapsed       | 288          |
| total_timesteps    | 563200       |
| value_loss         | 0.053500086  |
-------------------------------------
--------------------------------------
| approxkl           | 0.007938381   |
| clipfrac           | 0.10649414    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.728         |
| fps                | 2152          |
| n_updates          | 276           |
| policy_entropy     | 5.0063467     |
| policy_loss        | -0.0036148399 |
| serial_timesteps   | 70656         |
| time_elapsed       | 289           |
| total_timesteps    | 565248        |
| value_loss         | 0.047742795   |
--------------------------------------
--------------------------------------
| approxkl           | 0.009505065   |
| clipfrac           | 0.13115235    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.726         |
| fps                | 2130          |
| n_updates          | 277           |
| policy_entropy     | 4.9966125     |
| policy_loss        | -0.0064160437 |
| serial_timesteps   | 70912         |
| time_elapsed       | 290           |
| total_timesteps    | 567296        |
| value_loss         | 0.05218476    |
--------------------------------------
-------------------------------------
| approxkl           | 0.009256924  |
| clipfrac           | 0.13334961   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.704        |
| fps                | 2166         |
| n_updates          | 278          |
| policy_entropy     | 4.9833455    |
| policy_loss        | -0.008295001 |
| serial_timesteps   | 71168        |
| time_elapsed       | 291          |
| total_timesteps    | 569344       |
| value_loss         | 0.047504444  |
-------------------------------------
Eval num_timesteps=570000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.00881633   |
| clipfrac           | 0.121191405  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.719        |
| fps                | 1516         |
| n_updates          | 279          |
| policy_entropy     | 4.9723597    |
| policy_loss        | -0.005798854 |
| serial_timesteps   | 71424        |
| time_elapsed       | 292          |
| total_timesteps    | 571392       |
| value_loss         | 0.05185029   |
-------------------------------------
--------------------------------------
| approxkl           | 0.009551754   |
| clipfrac           | 0.13598633    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.693         |
| fps                | 2168          |
| n_updates          | 280           |
| policy_entropy     | 4.9386473     |
| policy_loss        | -0.0063361963 |
| serial_timesteps   | 71680         |
| time_elapsed       | 294           |
| total_timesteps    | 573440        |
| value_loss         | 0.04815469    |
--------------------------------------
--------------------------------------
| approxkl           | 0.008861743   |
| clipfrac           | 0.12080078    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.737         |
| fps                | 2103          |
| n_updates          | 281           |
| policy_entropy     | 4.9350457     |
| policy_loss        | -0.0061956635 |
| serial_timesteps   | 71936         |
| time_elapsed       | 295           |
| total_timesteps    | 575488        |
| value_loss         | 0.05046193    |
--------------------------------------
-------------------------------------
| approxkl           | 0.007823401  |
| clipfrac           | 0.10126953   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.666        |
| fps                | 2192         |
| n_updates          | 282          |
| policy_entropy     | 4.9478135    |
| policy_loss        | -0.004068756 |
| serial_timesteps   | 72192        |
| time_elapsed       | 295          |
| total_timesteps    | 577536       |
| value_loss         | 0.05373754   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009597871  |
| clipfrac           | 0.13666992   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.706        |
| fps                | 2193         |
| n_updates          | 283          |
| policy_entropy     | 4.9495897    |
| policy_loss        | -0.008122299 |
| serial_timesteps   | 72448        |
| time_elapsed       | 296          |
| total_timesteps    | 579584       |
| value_loss         | 0.0519751    |
-------------------------------------
Eval num_timesteps=580000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.00839138   |
| clipfrac           | 0.111083984  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.732        |
| fps                | 1506         |
| n_updates          | 284          |
| policy_entropy     | 4.9571066    |
| policy_loss        | -0.004553396 |
| serial_timesteps   | 72704        |
| time_elapsed       | 297          |
| total_timesteps    | 581632       |
| value_loss         | 0.052358232  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0078272205 |
| clipfrac           | 0.10688476   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.715        |
| fps                | 2121         |
| n_updates          | 285          |
| policy_entropy     | 4.9778132    |
| policy_loss        | -0.005699114 |
| serial_timesteps   | 72960        |
| time_elapsed       | 299          |
| total_timesteps    | 583680       |
| value_loss         | 0.047323406  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008413189   |
| clipfrac           | 0.117089845   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.732         |
| fps                | 2197          |
| n_updates          | 286           |
| policy_entropy     | 4.970647      |
| policy_loss        | -0.0068153506 |
| serial_timesteps   | 73216         |
| time_elapsed       | 300           |
| total_timesteps    | 585728        |
| value_loss         | 0.052258857   |
--------------------------------------
--------------------------------------
| approxkl           | 0.008600688   |
| clipfrac           | 0.11972656    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.704         |
| fps                | 2182          |
| n_updates          | 287           |
| policy_entropy     | 4.9610105     |
| policy_loss        | -0.0057601864 |
| serial_timesteps   | 73472         |
| time_elapsed       | 301           |
| total_timesteps    | 587776        |
| value_loss         | 0.047875036   |
--------------------------------------
--------------------------------------
| approxkl           | 0.00897874    |
| clipfrac           | 0.12265625    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.746         |
| fps                | 2163          |
| n_updates          | 288           |
| policy_entropy     | 4.967053      |
| policy_loss        | -0.0050840694 |
| serial_timesteps   | 73728         |
| time_elapsed       | 302           |
| total_timesteps    | 589824        |
| value_loss         | 0.050416213   |
--------------------------------------
Eval num_timesteps=590000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.008366784   |
| clipfrac           | 0.111132815   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.708         |
| fps                | 1518          |
| n_updates          | 289           |
| policy_entropy     | 4.954868      |
| policy_loss        | -0.0051431134 |
| serial_timesteps   | 73984         |
| time_elapsed       | 303           |
| total_timesteps    | 591872        |
| value_loss         | 0.048934106   |
--------------------------------------
------------------------------------
| approxkl           | 0.008265207 |
| clipfrac           | 0.111083984 |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.42       |
| explained_variance | 0.728       |
| fps                | 2166        |
| n_updates          | 290         |
| policy_entropy     | 4.9436684   |
| policy_loss        | -0.00408088 |
| serial_timesteps   | 74240       |
| time_elapsed       | 304         |
| total_timesteps    | 593920      |
| value_loss         | 0.04871994  |
------------------------------------
-------------------------------------
| approxkl           | 0.008116957  |
| clipfrac           | 0.10498047   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.689        |
| fps                | 2168         |
| n_updates          | 291          |
| policy_entropy     | 4.9116817    |
| policy_loss        | -0.005581948 |
| serial_timesteps   | 74496        |
| time_elapsed       | 305          |
| total_timesteps    | 595968       |
| value_loss         | 0.05193795   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009291148  |
| clipfrac           | 0.13266602   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.713        |
| fps                | 2185         |
| n_updates          | 292          |
| policy_entropy     | 4.8723893    |
| policy_loss        | -0.005484192 |
| serial_timesteps   | 74752        |
| time_elapsed       | 306          |
| total_timesteps    | 598016       |
| value_loss         | 0.049759172  |
-------------------------------------
Eval num_timesteps=600000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.008170007   |
| clipfrac           | 0.111376956   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.717         |
| fps                | 1519          |
| n_updates          | 293           |
| policy_entropy     | 4.8696065     |
| policy_loss        | -0.0028665238 |
| serial_timesteps   | 75008         |
| time_elapsed       | 307           |
| total_timesteps    | 600064        |
| value_loss         | 0.052778773   |
--------------------------------------
--------------------------------------
| approxkl           | 0.0091386745  |
| clipfrac           | 0.12294922    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.707         |
| fps                | 2196          |
| n_updates          | 294           |
| policy_entropy     | 4.85781       |
| policy_loss        | -0.0065160515 |
| serial_timesteps   | 75264         |
| time_elapsed       | 308           |
| total_timesteps    | 602112        |
| value_loss         | 0.048056796   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010157001  |
| clipfrac           | 0.1430664    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.726        |
| fps                | 2176         |
| n_updates          | 295          |
| policy_entropy     | 4.8326225    |
| policy_loss        | -0.008766502 |
| serial_timesteps   | 75520        |
| time_elapsed       | 309          |
| total_timesteps    | 604160       |
| value_loss         | 0.05216701   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007714486  |
| clipfrac           | 0.10683594   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.693        |
| fps                | 2156         |
| n_updates          | 296          |
| policy_entropy     | 4.809055     |
| policy_loss        | -0.004703092 |
| serial_timesteps   | 75776        |
| time_elapsed       | 310          |
| total_timesteps    | 606208       |
| value_loss         | 0.04913012   |
-------------------------------------
--------------------------------------
| approxkl           | 0.008365377   |
| clipfrac           | 0.10776367    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.74          |
| fps                | 2157          |
| n_updates          | 297           |
| policy_entropy     | 4.766153      |
| policy_loss        | -0.0058290586 |
| serial_timesteps   | 76032         |
| time_elapsed       | 311           |
| total_timesteps    | 608256        |
| value_loss         | 0.049599007   |
--------------------------------------
Eval num_timesteps=610000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007820396  |
| clipfrac           | 0.10244141   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.67         |
| fps                | 1526         |
| n_updates          | 298          |
| policy_entropy     | 4.716307     |
| policy_loss        | -0.004131696 |
| serial_timesteps   | 76288        |
| time_elapsed       | 312          |
| total_timesteps    | 610304       |
| value_loss         | 0.053089403  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008280152   |
| clipfrac           | 0.11142578    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.717         |
| fps                | 2181          |
| n_updates          | 299           |
| policy_entropy     | 4.6857147     |
| policy_loss        | -0.0058413977 |
| serial_timesteps   | 76544         |
| time_elapsed       | 313           |
| total_timesteps    | 612352        |
| value_loss         | 0.052392412   |
--------------------------------------
--------------------------------------
| approxkl           | 0.0077374033  |
| clipfrac           | 0.10258789    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.707         |
| fps                | 2138          |
| n_updates          | 300           |
| policy_entropy     | 4.66984       |
| policy_loss        | -0.0010054779 |
| serial_timesteps   | 76800         |
| time_elapsed       | 314           |
| total_timesteps    | 614400        |
| value_loss         | 0.05410136    |
--------------------------------------
------------------------------------
| approxkl           | 0.008543883 |
| clipfrac           | 0.12060547  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.42       |
| explained_variance | 0.724       |
| fps                | 2168        |
| n_updates          | 301         |
| policy_entropy     | 4.6578217   |
| policy_loss        | -0.00406115 |
| serial_timesteps   | 77056       |
| time_elapsed       | 315         |
| total_timesteps    | 616448      |
| value_loss         | 0.048998013 |
------------------------------------
--------------------------------------
| approxkl           | 0.00937199    |
| clipfrac           | 0.13623047    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.712         |
| fps                | 2168          |
| n_updates          | 302           |
| policy_entropy     | 4.6446705     |
| policy_loss        | -0.0087444205 |
| serial_timesteps   | 77312         |
| time_elapsed       | 316           |
| total_timesteps    | 618496        |
| value_loss         | 0.054072686   |
--------------------------------------
Eval num_timesteps=620000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.0077400357  |
| clipfrac           | 0.10161133    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.711         |
| fps                | 1526          |
| n_updates          | 303           |
| policy_entropy     | 4.6286        |
| policy_loss        | -0.0030236365 |
| serial_timesteps   | 77568         |
| time_elapsed       | 317           |
| total_timesteps    | 620544        |
| value_loss         | 0.048031323   |
--------------------------------------
--------------------------------------
| approxkl           | 0.008574887   |
| clipfrac           | 0.11977539    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.735         |
| fps                | 2107          |
| n_updates          | 304           |
| policy_entropy     | 4.628503      |
| policy_loss        | -0.0058625573 |
| serial_timesteps   | 77824         |
| time_elapsed       | 318           |
| total_timesteps    | 622592        |
| value_loss         | 0.05043289    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0074369563 |
| clipfrac           | 0.097558595  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.722        |
| fps                | 2181         |
| n_updates          | 305          |
| policy_entropy     | 4.6331396    |
| policy_loss        | -0.003428047 |
| serial_timesteps   | 78080        |
| time_elapsed       | 319          |
| total_timesteps    | 624640       |
| value_loss         | 0.046131983  |
-------------------------------------
--------------------------------------
| approxkl           | 0.006993289   |
| clipfrac           | 0.08916016    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.725         |
| fps                | 2162          |
| n_updates          | 306           |
| policy_entropy     | 4.6092095     |
| policy_loss        | -0.0021023748 |
| serial_timesteps   | 78336         |
| time_elapsed       | 320           |
| total_timesteps    | 626688        |
| value_loss         | 0.051744252   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0093325125 |
| clipfrac           | 0.1349121    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.669        |
| fps                | 2195         |
| n_updates          | 307          |
| policy_entropy     | 4.5663238    |
| policy_loss        | -0.007350781 |
| serial_timesteps   | 78592        |
| time_elapsed       | 321          |
| total_timesteps    | 628736       |
| value_loss         | 0.054422237  |
-------------------------------------
Eval num_timesteps=630000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009070474  |
| clipfrac           | 0.12480469   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.729        |
| fps                | 1528         |
| n_updates          | 308          |
| policy_entropy     | 4.551206     |
| policy_loss        | -0.005589407 |
| serial_timesteps   | 78848        |
| time_elapsed       | 322          |
| total_timesteps    | 630784       |
| value_loss         | 0.052708734  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008156393  |
| clipfrac           | 0.10727539   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.72         |
| fps                | 2161         |
| n_updates          | 309          |
| policy_entropy     | 4.5404115    |
| policy_loss        | -0.003729732 |
| serial_timesteps   | 79104        |
| time_elapsed       | 323          |
| total_timesteps    | 632832       |
| value_loss         | 0.054256905  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008894767   |
| clipfrac           | 0.1284668     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.71          |
| fps                | 2147          |
| n_updates          | 310           |
| policy_entropy     | 4.527635      |
| policy_loss        | -0.0056778984 |
| serial_timesteps   | 79360         |
| time_elapsed       | 324           |
| total_timesteps    | 634880        |
| value_loss         | 0.049815934   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009282304  |
| clipfrac           | 0.13242188   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.723        |
| fps                | 2175         |
| n_updates          | 311          |
| policy_entropy     | 4.5380855    |
| policy_loss        | -0.005672169 |
| serial_timesteps   | 79616        |
| time_elapsed       | 325          |
| total_timesteps    | 636928       |
| value_loss         | 0.05457751   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008569878  |
| clipfrac           | 0.11557617   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.645        |
| fps                | 2133         |
| n_updates          | 312          |
| policy_entropy     | 4.5406275    |
| policy_loss        | -0.005985529 |
| serial_timesteps   | 79872        |
| time_elapsed       | 326          |
| total_timesteps    | 638976       |
| value_loss         | 0.049757384  |
-------------------------------------
Eval num_timesteps=640000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009093582   |
| clipfrac           | 0.12631837    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.731         |
| fps                | 1510          |
| n_updates          | 313           |
| policy_entropy     | 4.5220137     |
| policy_loss        | -0.0055292808 |
| serial_timesteps   | 80128         |
| time_elapsed       | 327           |
| total_timesteps    | 641024        |
| value_loss         | 0.051978797   |
--------------------------------------
--------------------------------------
| approxkl           | 0.008840786   |
| clipfrac           | 0.12080078    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.4          |
| explained_variance | 0.676         |
| fps                | 2170          |
| n_updates          | 314           |
| policy_entropy     | 4.503895      |
| policy_loss        | -0.0057241153 |
| serial_timesteps   | 80384         |
| time_elapsed       | 329           |
| total_timesteps    | 643072        |
| value_loss         | 0.051532965   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008482983  |
| clipfrac           | 0.118701175  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.712        |
| fps                | 2187         |
| n_updates          | 315          |
| policy_entropy     | 4.4896927    |
| policy_loss        | -0.005646651 |
| serial_timesteps   | 80640        |
| time_elapsed       | 330          |
| total_timesteps    | 645120       |
| value_loss         | 0.051932205  |
-------------------------------------
--------------------------------------
| approxkl           | 0.00816721    |
| clipfrac           | 0.11230469    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.4          |
| explained_variance | 0.641         |
| fps                | 2111          |
| n_updates          | 316           |
| policy_entropy     | 4.4675436     |
| policy_loss        | -0.0048658843 |
| serial_timesteps   | 80896         |
| time_elapsed       | 330           |
| total_timesteps    | 647168        |
| value_loss         | 0.05612263    |
--------------------------------------
--------------------------------------
| approxkl           | 0.0075946054  |
| clipfrac           | 0.10161133    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.704         |
| fps                | 2195          |
| n_updates          | 317           |
| policy_entropy     | 4.4744473     |
| policy_loss        | -0.0027659987 |
| serial_timesteps   | 81152         |
| time_elapsed       | 331           |
| total_timesteps    | 649216        |
| value_loss         | 0.051073253   |
--------------------------------------
Eval num_timesteps=650000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.009181106 |
| clipfrac           | 0.12617187  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.42       |
| explained_variance | 0.712       |
| fps                | 1528        |
| n_updates          | 318         |
| policy_entropy     | 4.475739    |
| policy_loss        | -0.00331168 |
| serial_timesteps   | 81408       |
| time_elapsed       | 332         |
| total_timesteps    | 651264      |
| value_loss         | 0.056362193 |
------------------------------------
-------------------------------------
| approxkl           | 0.0104552945 |
| clipfrac           | 0.14765625   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.687        |
| fps                | 2185         |
| n_updates          | 319          |
| policy_entropy     | 4.4559965    |
| policy_loss        | -0.007989535 |
| serial_timesteps   | 81664        |
| time_elapsed       | 334          |
| total_timesteps    | 653312       |
| value_loss         | 0.04927802   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008379069  |
| clipfrac           | 0.10864258   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.726        |
| fps                | 2167         |
| n_updates          | 320          |
| policy_entropy     | 4.4219766    |
| policy_loss        | -0.004900234 |
| serial_timesteps   | 81920        |
| time_elapsed       | 335          |
| total_timesteps    | 655360       |
| value_loss         | 0.056303203  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008839834  |
| clipfrac           | 0.12001953   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.725        |
| fps                | 2192         |
| n_updates          | 321          |
| policy_entropy     | 4.4042773    |
| policy_loss        | -0.006787014 |
| serial_timesteps   | 82176        |
| time_elapsed       | 336          |
| total_timesteps    | 657408       |
| value_loss         | 0.047786262  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009783012  |
| clipfrac           | 0.13813476   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.735        |
| fps                | 2194         |
| n_updates          | 322          |
| policy_entropy     | 4.393494     |
| policy_loss        | -0.009291262 |
| serial_timesteps   | 82432        |
| time_elapsed       | 337          |
| total_timesteps    | 659456       |
| value_loss         | 0.052418005  |
-------------------------------------
Eval num_timesteps=660000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.007924356   |
| clipfrac           | 0.10732422    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.4          |
| explained_variance | 0.708         |
| fps                | 1529          |
| n_updates          | 323           |
| policy_entropy     | 4.373617      |
| policy_loss        | -0.0053930217 |
| serial_timesteps   | 82688         |
| time_elapsed       | 337           |
| total_timesteps    | 661504        |
| value_loss         | 0.050938904   |
--------------------------------------
--------------------------------------
| approxkl           | 0.009040871   |
| clipfrac           | 0.12504883    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.725         |
| fps                | 2190          |
| n_updates          | 324           |
| policy_entropy     | 4.3486543     |
| policy_loss        | -0.0063412823 |
| serial_timesteps   | 82944         |
| time_elapsed       | 339           |
| total_timesteps    | 663552        |
| value_loss         | 0.051977407   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009290369  |
| clipfrac           | 0.12861328   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.698        |
| fps                | 2131         |
| n_updates          | 325          |
| policy_entropy     | 4.3470564    |
| policy_loss        | -0.007947037 |
| serial_timesteps   | 83200        |
| time_elapsed       | 340          |
| total_timesteps    | 665600       |
| value_loss         | 0.053851433  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010013612  |
| clipfrac           | 0.14916992   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.729        |
| fps                | 2180         |
| n_updates          | 326          |
| policy_entropy     | 4.331666     |
| policy_loss        | -0.008057662 |
| serial_timesteps   | 83456        |
| time_elapsed       | 341          |
| total_timesteps    | 667648       |
| value_loss         | 0.047565363  |
-------------------------------------
--------------------------------------
| approxkl           | 0.00961579    |
| clipfrac           | 0.13857421    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.72          |
| fps                | 2175          |
| n_updates          | 327           |
| policy_entropy     | 4.291741      |
| policy_loss        | -0.0056195827 |
| serial_timesteps   | 83712         |
| time_elapsed       | 342           |
| total_timesteps    | 669696        |
| value_loss         | 0.052810065   |
--------------------------------------
Eval num_timesteps=670000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009541678   |
| clipfrac           | 0.13066407    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.699         |
| fps                | 1525          |
| n_updates          | 328           |
| policy_entropy     | 4.2507873     |
| policy_loss        | -0.0076249437 |
| serial_timesteps   | 83968         |
| time_elapsed       | 343           |
| total_timesteps    | 671744        |
| value_loss         | 0.047094934   |
--------------------------------------
--------------------------------------
| approxkl           | 0.018947177   |
| clipfrac           | 0.13759765    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.43         |
| explained_variance | 0.521         |
| fps                | 2180          |
| n_updates          | 329           |
| policy_entropy     | 4.238534      |
| policy_loss        | -0.0038634962 |
| serial_timesteps   | 84224         |
| time_elapsed       | 344           |
| total_timesteps    | 673792        |
| value_loss         | 0.08242159    |
--------------------------------------
--------------------------------------
| approxkl           | 0.008485312   |
| clipfrac           | 0.11850586    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.699         |
| fps                | 2099          |
| n_updates          | 330           |
| policy_entropy     | 4.2513676     |
| policy_loss        | -0.0061555626 |
| serial_timesteps   | 84480         |
| time_elapsed       | 345           |
| total_timesteps    | 675840        |
| value_loss         | 0.04879489    |
--------------------------------------
-------------------------------------
| approxkl           | 0.010052977  |
| clipfrac           | 0.14550781   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.745        |
| fps                | 2174         |
| n_updates          | 331          |
| policy_entropy     | 4.2444897    |
| policy_loss        | -0.007691653 |
| serial_timesteps   | 84736        |
| time_elapsed       | 346          |
| total_timesteps    | 677888       |
| value_loss         | 0.047719166  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010842992  |
| clipfrac           | 0.15244141   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.683        |
| fps                | 2172         |
| n_updates          | 332          |
| policy_entropy     | 4.199439     |
| policy_loss        | -0.008916991 |
| serial_timesteps   | 84992        |
| time_elapsed       | 347          |
| total_timesteps    | 679936       |
| value_loss         | 0.049206965  |
-------------------------------------
Eval num_timesteps=680000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009747094   |
| clipfrac           | 0.13559571    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.43         |
| explained_variance | 0.722         |
| fps                | 1527          |
| n_updates          | 333           |
| policy_entropy     | 4.165845      |
| policy_loss        | -0.0057042832 |
| serial_timesteps   | 85248         |
| time_elapsed       | 348           |
| total_timesteps    | 681984        |
| value_loss         | 0.050369106   |
--------------------------------------
--------------------------------------
| approxkl           | 0.008729951   |
| clipfrac           | 0.11640625    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.712         |
| fps                | 2162          |
| n_updates          | 334           |
| policy_entropy     | 4.165298      |
| policy_loss        | -0.0049488237 |
| serial_timesteps   | 85504         |
| time_elapsed       | 349           |
| total_timesteps    | 684032        |
| value_loss         | 0.052815337   |
--------------------------------------
-------------------------------------
| approxkl           | 0.00962303   |
| clipfrac           | 0.128125     |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.691        |
| fps                | 2155         |
| n_updates          | 335          |
| policy_entropy     | 4.143608     |
| policy_loss        | -0.006546039 |
| serial_timesteps   | 85760        |
| time_elapsed       | 350          |
| total_timesteps    | 686080       |
| value_loss         | 0.04799258   |
-------------------------------------
--------------------------------------
| approxkl           | 0.009201389   |
| clipfrac           | 0.12636718    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.697         |
| fps                | 2139          |
| n_updates          | 336           |
| policy_entropy     | 4.102604      |
| policy_loss        | -0.0043243947 |
| serial_timesteps   | 86016         |
| time_elapsed       | 351           |
| total_timesteps    | 688128        |
| value_loss         | 0.053564645   |
--------------------------------------
Eval num_timesteps=690000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010112466  |
| clipfrac           | 0.13540038   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.736        |
| fps                | 1529         |
| n_updates          | 337          |
| policy_entropy     | 4.083673     |
| policy_loss        | -0.004696657 |
| serial_timesteps   | 86272        |
| time_elapsed       | 352          |
| total_timesteps    | 690176       |
| value_loss         | 0.03913637   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0091466075  |
| clipfrac           | 0.1227539     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.764         |
| fps                | 2171          |
| n_updates          | 338           |
| policy_entropy     | 4.082141      |
| policy_loss        | -0.0046416265 |
| serial_timesteps   | 86528         |
| time_elapsed       | 353           |
| total_timesteps    | 692224        |
| value_loss         | 0.046336453   |
--------------------------------------
-------------------------------------
| approxkl           | 0.012166389  |
| clipfrac           | 0.15654297   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.54         |
| fps                | 2140         |
| n_updates          | 339          |
| policy_entropy     | 4.079027     |
| policy_loss        | -0.010387584 |
| serial_timesteps   | 86784        |
| time_elapsed       | 354          |
| total_timesteps    | 694272       |
| value_loss         | 0.0702262    |
-------------------------------------
------------------------------------
| approxkl           | 0.010179271 |
| clipfrac           | 0.1496582   |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.43       |
| explained_variance | 0.733       |
| fps                | 2188        |
| n_updates          | 340         |
| policy_entropy     | 4.0724277   |
| policy_loss        | -0.00671379 |
| serial_timesteps   | 87040       |
| time_elapsed       | 355         |
| total_timesteps    | 696320      |
| value_loss         | 0.05015984  |
------------------------------------
--------------------------------------
| approxkl           | 0.010240442   |
| clipfrac           | 0.14667968    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.669         |
| fps                | 2186          |
| n_updates          | 341           |
| policy_entropy     | 4.037057      |
| policy_loss        | -0.0068600206 |
| serial_timesteps   | 87296         |
| time_elapsed       | 356           |
| total_timesteps    | 698368        |
| value_loss         | 0.05349649    |
--------------------------------------
Eval num_timesteps=700000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009481069  |
| clipfrac           | 0.12729493   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.724        |
| fps                | 1533         |
| n_updates          | 342          |
| policy_entropy     | 4.0211782    |
| policy_loss        | -0.005689262 |
| serial_timesteps   | 87552        |
| time_elapsed       | 357          |
| total_timesteps    | 700416       |
| value_loss         | 0.049100377  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009143205   |
| clipfrac           | 0.122558594   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.47         |
| explained_variance | 0.645         |
| fps                | 2096          |
| n_updates          | 343           |
| policy_entropy     | 4.0180216     |
| policy_loss        | -0.0056606713 |
| serial_timesteps   | 87808         |
| time_elapsed       | 358           |
| total_timesteps    | 702464        |
| value_loss         | 0.064182006   |
--------------------------------------
-------------------------------------
| approxkl           | 0.00844267   |
| clipfrac           | 0.114746094  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.705        |
| fps                | 2189         |
| n_updates          | 344          |
| policy_entropy     | 4.003703     |
| policy_loss        | -0.006366865 |
| serial_timesteps   | 88064        |
| time_elapsed       | 359          |
| total_timesteps    | 704512       |
| value_loss         | 0.04802525   |
-------------------------------------
--------------------------------------
| approxkl           | 0.008942777   |
| clipfrac           | 0.120996095   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.45         |
| explained_variance | 0.75          |
| fps                | 2179          |
| n_updates          | 345           |
| policy_entropy     | 3.977869      |
| policy_loss        | -0.0054928567 |
| serial_timesteps   | 88320         |
| time_elapsed       | 360           |
| total_timesteps    | 706560        |
| value_loss         | 0.04803708    |
--------------------------------------
--------------------------------------
| approxkl           | 0.010562231   |
| clipfrac           | 0.13232422    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.47         |
| explained_variance | 0.552         |
| fps                | 2169          |
| n_updates          | 346           |
| policy_entropy     | 3.9761066     |
| policy_loss        | -0.0062542604 |
| serial_timesteps   | 88576         |
| time_elapsed       | 361           |
| total_timesteps    | 708608        |
| value_loss         | 0.07523657    |
--------------------------------------
Eval num_timesteps=710000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009130465   |
| clipfrac           | 0.11826172    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.48         |
| explained_variance | 0.722         |
| fps                | 1506          |
| n_updates          | 347           |
| policy_entropy     | 3.977649      |
| policy_loss        | -0.0042122314 |
| serial_timesteps   | 88832         |
| time_elapsed       | 362           |
| total_timesteps    | 710656        |
| value_loss         | 0.051323585   |
--------------------------------------
--------------------------------------
| approxkl           | 0.008328579   |
| clipfrac           | 0.11010742    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.44         |
| explained_variance | 0.636         |
| fps                | 2174          |
| n_updates          | 348           |
| policy_entropy     | 3.95962       |
| policy_loss        | -0.0036963094 |
| serial_timesteps   | 89088         |
| time_elapsed       | 364           |
| total_timesteps    | 712704        |
| value_loss         | 0.05517899    |
--------------------------------------
--------------------------------------
| approxkl           | 0.00921352    |
| clipfrac           | 0.12651367    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.46         |
| explained_variance | 0.714         |
| fps                | 2163          |
| n_updates          | 349           |
| policy_entropy     | 3.9486039     |
| policy_loss        | -0.0047320416 |
| serial_timesteps   | 89344         |
| time_elapsed       | 364           |
| total_timesteps    | 714752        |
| value_loss         | 0.050992716   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008876942  |
| clipfrac           | 0.12397461   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.717        |
| fps                | 2177         |
| n_updates          | 350          |
| policy_entropy     | 3.9579616    |
| policy_loss        | -0.004179038 |
| serial_timesteps   | 89600        |
| time_elapsed       | 365          |
| total_timesteps    | 716800       |
| value_loss         | 0.052564483  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009657381   |
| clipfrac           | 0.13515624    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.43         |
| explained_variance | 0.725         |
| fps                | 2175          |
| n_updates          | 351           |
| policy_entropy     | 3.9314206     |
| policy_loss        | -0.0081287315 |
| serial_timesteps   | 89856         |
| time_elapsed       | 366           |
| total_timesteps    | 718848        |
| value_loss         | 0.048606273   |
--------------------------------------
Eval num_timesteps=720000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009560505   |
| clipfrac           | 0.12475586    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.744         |
| fps                | 1526          |
| n_updates          | 352           |
| policy_entropy     | 3.909753      |
| policy_loss        | -0.0012648775 |
| serial_timesteps   | 90112         |
| time_elapsed       | 367           |
| total_timesteps    | 720896        |
| value_loss         | 0.05156353    |
--------------------------------------
-------------------------------------
| approxkl           | 0.008617455  |
| clipfrac           | 0.11806641   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.709        |
| fps                | 2185         |
| n_updates          | 353          |
| policy_entropy     | 3.8878906    |
| policy_loss        | -0.005636526 |
| serial_timesteps   | 90368        |
| time_elapsed       | 369          |
| total_timesteps    | 722944       |
| value_loss         | 0.048328556  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008925619   |
| clipfrac           | 0.122607425   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.75          |
| fps                | 2190          |
| n_updates          | 354           |
| policy_entropy     | 3.8791585     |
| policy_loss        | -0.0009615986 |
| serial_timesteps   | 90624         |
| time_elapsed       | 370           |
| total_timesteps    | 724992        |
| value_loss         | 0.049781177   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009499167  |
| clipfrac           | 0.13408203   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.718        |
| fps                | 2134         |
| n_updates          | 355          |
| policy_entropy     | 3.87746      |
| policy_loss        | -0.007130684 |
| serial_timesteps   | 90880        |
| time_elapsed       | 370          |
| total_timesteps    | 727040       |
| value_loss         | 0.04404395   |
-------------------------------------
--------------------------------------
| approxkl           | 0.011432175   |
| clipfrac           | 0.14916992    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.742         |
| fps                | 2193          |
| n_updates          | 356           |
| policy_entropy     | 3.8523479     |
| policy_loss        | -0.0065111974 |
| serial_timesteps   | 91136         |
| time_elapsed       | 371           |
| total_timesteps    | 729088        |
| value_loss         | 0.04793574    |
--------------------------------------
Eval num_timesteps=730000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.00890808    |
| clipfrac           | 0.11928711    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.694         |
| fps                | 1534          |
| n_updates          | 357           |
| policy_entropy     | 3.8326068     |
| policy_loss        | -0.0046236864 |
| serial_timesteps   | 91392         |
| time_elapsed       | 372           |
| total_timesteps    | 731136        |
| value_loss         | 0.050421517   |
--------------------------------------
-------------------------------------
| approxkl           | 0.011816244  |
| clipfrac           | 0.16938476   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.739        |
| fps                | 2171         |
| n_updates          | 358          |
| policy_entropy     | 3.7967155    |
| policy_loss        | -0.010112713 |
| serial_timesteps   | 91648        |
| time_elapsed       | 374          |
| total_timesteps    | 733184       |
| value_loss         | 0.047473807  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009621425  |
| clipfrac           | 0.13671875   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.738        |
| fps                | 2109         |
| n_updates          | 359          |
| policy_entropy     | 3.7743015    |
| policy_loss        | -0.004647398 |
| serial_timesteps   | 91904        |
| time_elapsed       | 375          |
| total_timesteps    | 735232       |
| value_loss         | 0.051873617  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009375152  |
| clipfrac           | 0.13325195   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.728        |
| fps                | 2200         |
| n_updates          | 360          |
| policy_entropy     | 3.7601554    |
| policy_loss        | -0.004372549 |
| serial_timesteps   | 92160        |
| time_elapsed       | 376          |
| total_timesteps    | 737280       |
| value_loss         | 0.047838073  |
-------------------------------------
--------------------------------------
| approxkl           | 0.010366168   |
| clipfrac           | 0.14365235    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.751         |
| fps                | 2181          |
| n_updates          | 361           |
| policy_entropy     | 3.7327495     |
| policy_loss        | -0.0073372633 |
| serial_timesteps   | 92416         |
| time_elapsed       | 377           |
| total_timesteps    | 739328        |
| value_loss         | 0.051790845   |
--------------------------------------
Eval num_timesteps=740000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0110585475 |
| clipfrac           | 0.1461914    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.748        |
| fps                | 1514         |
| n_updates          | 362          |
| policy_entropy     | 3.698342     |
| policy_loss        | -0.006850107 |
| serial_timesteps   | 92672        |
| time_elapsed       | 378          |
| total_timesteps    | 741376       |
| value_loss         | 0.04267762   |
-------------------------------------
-------------------------------------
| approxkl           | 0.015432899  |
| clipfrac           | 0.19052735   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.724        |
| fps                | 2112         |
| n_updates          | 363          |
| policy_entropy     | 3.6686409    |
| policy_loss        | -0.007751754 |
| serial_timesteps   | 92928        |
| time_elapsed       | 379          |
| total_timesteps    | 743424       |
| value_loss         | 0.054247666  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010604633  |
| clipfrac           | 0.13686523   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.651        |
| fps                | 2161         |
| n_updates          | 364          |
| policy_entropy     | 3.6539261    |
| policy_loss        | -0.007130059 |
| serial_timesteps   | 93184        |
| time_elapsed       | 380          |
| total_timesteps    | 745472       |
| value_loss         | 0.061855424  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009484612  |
| clipfrac           | 0.12866211   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.47        |
| explained_variance | 0.763        |
| fps                | 2166         |
| n_updates          | 365          |
| policy_entropy     | 3.667172     |
| policy_loss        | -0.006020992 |
| serial_timesteps   | 93440        |
| time_elapsed       | 381          |
| total_timesteps    | 747520       |
| value_loss         | 0.047128655  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0103334     |
| clipfrac           | 0.14643554    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.48         |
| explained_variance | 0.658         |
| fps                | 2178          |
| n_updates          | 366           |
| policy_entropy     | 3.6729019     |
| policy_loss        | -0.0066222576 |
| serial_timesteps   | 93696         |
| time_elapsed       | 382           |
| total_timesteps    | 749568        |
| value_loss         | 0.05817589    |
--------------------------------------
Eval num_timesteps=750000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010188879   |
| clipfrac           | 0.14243165    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.48         |
| explained_variance | 0.725         |
| fps                | 1519          |
| n_updates          | 367           |
| policy_entropy     | 3.6463723     |
| policy_loss        | -0.0042136805 |
| serial_timesteps   | 93952         |
| time_elapsed       | 383           |
| total_timesteps    | 751616        |
| value_loss         | 0.05159961    |
--------------------------------------
--------------------------------------
| approxkl           | 0.009927886   |
| clipfrac           | 0.13867188    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.46         |
| explained_variance | 0.723         |
| fps                | 2138          |
| n_updates          | 368           |
| policy_entropy     | 3.6265893     |
| policy_loss        | -0.0055090575 |
| serial_timesteps   | 94208         |
| time_elapsed       | 384           |
| total_timesteps    | 753664        |
| value_loss         | 0.053389408   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010458826   |
| clipfrac           | 0.1484375     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.44         |
| explained_variance | 0.706         |
| fps                | 2161          |
| n_updates          | 369           |
| policy_entropy     | 3.593986      |
| policy_loss        | -0.0078135105 |
| serial_timesteps   | 94464         |
| time_elapsed       | 385           |
| total_timesteps    | 755712        |
| value_loss         | 0.04816697    |
--------------------------------------
--------------------------------------
| approxkl           | 0.009014009   |
| clipfrac           | 0.12592773    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.44         |
| explained_variance | 0.727         |
| fps                | 2155          |
| n_updates          | 370           |
| policy_entropy     | 3.5576344     |
| policy_loss        | -0.0027622553 |
| serial_timesteps   | 94720         |
| time_elapsed       | 386           |
| total_timesteps    | 757760        |
| value_loss         | 0.051084857   |
--------------------------------------
-------------------------------------
| approxkl           | 0.011264052  |
| clipfrac           | 0.16665038   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.698        |
| fps                | 2148         |
| n_updates          | 371          |
| policy_entropy     | 3.5238013    |
| policy_loss        | -0.010116681 |
| serial_timesteps   | 94976        |
| time_elapsed       | 387          |
| total_timesteps    | 759808       |
| value_loss         | 0.048553422  |
-------------------------------------
Eval num_timesteps=760000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010254663   |
| clipfrac           | 0.14663085    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.739         |
| fps                | 1528          |
| n_updates          | 372           |
| policy_entropy     | 3.4849281     |
| policy_loss        | -0.0047766943 |
| serial_timesteps   | 95232         |
| time_elapsed       | 388           |
| total_timesteps    | 761856        |
| value_loss         | 0.050406683   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008879435  |
| clipfrac           | 0.12431641   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.704        |
| fps                | 2163         |
| n_updates          | 373          |
| policy_entropy     | 3.4844303    |
| policy_loss        | -0.003697611 |
| serial_timesteps   | 95488        |
| time_elapsed       | 389          |
| total_timesteps    | 763904       |
| value_loss         | 0.05105288   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010345009  |
| clipfrac           | 0.14462891   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.743        |
| fps                | 2141         |
| n_updates          | 374          |
| policy_entropy     | 3.474603     |
| policy_loss        | -0.005513037 |
| serial_timesteps   | 95744        |
| time_elapsed       | 390          |
| total_timesteps    | 765952       |
| value_loss         | 0.05141604   |
-------------------------------------
--------------------------------------
| approxkl           | 0.009967232   |
| clipfrac           | 0.13710937    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.723         |
| fps                | 2114          |
| n_updates          | 375           |
| policy_entropy     | 3.4432774     |
| policy_loss        | -0.0058673485 |
| serial_timesteps   | 96000         |
| time_elapsed       | 391           |
| total_timesteps    | 768000        |
| value_loss         | 0.051305376   |
--------------------------------------
Eval num_timesteps=770000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009654855  |
| clipfrac           | 0.13588867   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.729        |
| fps                | 1535         |
| n_updates          | 376          |
| policy_entropy     | 3.4057949    |
| policy_loss        | -0.007486059 |
| serial_timesteps   | 96256        |
| time_elapsed       | 392          |
| total_timesteps    | 770048       |
| value_loss         | 0.04400632   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009910252  |
| clipfrac           | 0.13623047   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.705        |
| fps                | 2159         |
| n_updates          | 377          |
| policy_entropy     | 3.375541     |
| policy_loss        | -0.002201926 |
| serial_timesteps   | 96512        |
| time_elapsed       | 393          |
| total_timesteps    | 772096       |
| value_loss         | 0.0522167    |
-------------------------------------
--------------------------------------
| approxkl           | 0.012051033   |
| clipfrac           | 0.14882812    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.43         |
| explained_variance | 0.596         |
| fps                | 2157          |
| n_updates          | 378           |
| policy_entropy     | 3.3877895     |
| policy_loss        | -0.0062884404 |
| serial_timesteps   | 96768         |
| time_elapsed       | 394           |
| total_timesteps    | 774144        |
| value_loss         | 0.059398156   |
--------------------------------------
-------------------------------------
| approxkl           | 0.011274361  |
| clipfrac           | 0.1637207    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.728        |
| fps                | 2176         |
| n_updates          | 379          |
| policy_entropy     | 3.4124627    |
| policy_loss        | -0.009374761 |
| serial_timesteps   | 97024        |
| time_elapsed       | 395          |
| total_timesteps    | 776192       |
| value_loss         | 0.05203878   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008393539  |
| clipfrac           | 0.11582031   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.687        |
| fps                | 2181         |
| n_updates          | 380          |
| policy_entropy     | 3.4228768    |
| policy_loss        | -0.002896661 |
| serial_timesteps   | 97280        |
| time_elapsed       | 396          |
| total_timesteps    | 778240       |
| value_loss         | 0.05215192   |
-------------------------------------
Eval num_timesteps=780000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.010495535 |
| clipfrac           | 0.13120118  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.47       |
| explained_variance | 0.523       |
| fps                | 1526        |
| n_updates          | 381         |
| policy_entropy     | 3.4241478   |
| policy_loss        | 0.00101638  |
| serial_timesteps   | 97536       |
| time_elapsed       | 397         |
| total_timesteps    | 780288      |
| value_loss         | 0.08975166  |
------------------------------------
-------------------------------------
| approxkl           | 0.011944478  |
| clipfrac           | 0.17104492   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.694        |
| fps                | 2179         |
| n_updates          | 382          |
| policy_entropy     | 3.4043465    |
| policy_loss        | -0.010010015 |
| serial_timesteps   | 97792        |
| time_elapsed       | 398          |
| total_timesteps    | 782336       |
| value_loss         | 0.05122853   |
-------------------------------------
--------------------------------------
| approxkl           | 0.011142795   |
| clipfrac           | 0.14458008    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.48         |
| explained_variance | 0.538         |
| fps                | 2170          |
| n_updates          | 383           |
| policy_entropy     | 3.4088383     |
| policy_loss        | -0.0053600795 |
| serial_timesteps   | 98048         |
| time_elapsed       | 399           |
| total_timesteps    | 784384        |
| value_loss         | 0.09343879    |
--------------------------------------
-------------------------------------
| approxkl           | 0.010524495  |
| clipfrac           | 0.1586914    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.702        |
| fps                | 2179         |
| n_updates          | 384          |
| policy_entropy     | 3.3928483    |
| policy_loss        | -0.007989169 |
| serial_timesteps   | 98304        |
| time_elapsed       | 400          |
| total_timesteps    | 786432       |
| value_loss         | 0.05364991   |
-------------------------------------
-------------------------------------
| approxkl           | 0.012188083  |
| clipfrac           | 0.17607422   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.693        |
| fps                | 2190         |
| n_updates          | 385          |
| policy_entropy     | 3.3823185    |
| policy_loss        | -0.012201601 |
| serial_timesteps   | 98560        |
| time_elapsed       | 401          |
| total_timesteps    | 788480       |
| value_loss         | 0.047738064  |
-------------------------------------
Eval num_timesteps=790000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010520841   |
| clipfrac           | 0.15371093    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.45         |
| explained_variance | 0.737         |
| fps                | 1524          |
| n_updates          | 386           |
| policy_entropy     | 3.3892562     |
| policy_loss        | -0.0066069504 |
| serial_timesteps   | 98816         |
| time_elapsed       | 402           |
| total_timesteps    | 790528        |
| value_loss         | 0.051603407   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010060027  |
| clipfrac           | 0.1362793    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.714        |
| fps                | 2162         |
| n_updates          | 387          |
| policy_entropy     | 3.3804078    |
| policy_loss        | -0.006407929 |
| serial_timesteps   | 99072        |
| time_elapsed       | 404          |
| total_timesteps    | 792576       |
| value_loss         | 0.04741534   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008713164  |
| clipfrac           | 0.12045898   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.746        |
| fps                | 2158         |
| n_updates          | 388          |
| policy_entropy     | 3.3596294    |
| policy_loss        | -0.005101792 |
| serial_timesteps   | 99328        |
| time_elapsed       | 405          |
| total_timesteps    | 794624       |
| value_loss         | 0.050676614  |
-------------------------------------
--------------------------------------
| approxkl           | 0.010265214   |
| clipfrac           | 0.14775391    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.718         |
| fps                | 2176          |
| n_updates          | 389           |
| policy_entropy     | 3.3291879     |
| policy_loss        | -0.0077950433 |
| serial_timesteps   | 99584         |
| time_elapsed       | 405           |
| total_timesteps    | 796672        |
| value_loss         | 0.045618556   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010127431   |
| clipfrac           | 0.1421875     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.763         |
| fps                | 2136          |
| n_updates          | 390           |
| policy_entropy     | 3.3024437     |
| policy_loss        | -0.0061709317 |
| serial_timesteps   | 99840         |
| time_elapsed       | 406           |
| total_timesteps    | 798720        |
| value_loss         | 0.04852016    |
--------------------------------------
Eval num_timesteps=800000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009372106  |
| clipfrac           | 0.12939453   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.718        |
| fps                | 1514         |
| n_updates          | 391          |
| policy_entropy     | 3.2889602    |
| policy_loss        | -0.003857104 |
| serial_timesteps   | 100096       |
| time_elapsed       | 407          |
| total_timesteps    | 800768       |
| value_loss         | 0.04931951   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0086250305 |
| clipfrac           | 0.1206543    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.732        |
| fps                | 2174         |
| n_updates          | 392          |
| policy_entropy     | 3.2767348    |
| policy_loss        | -0.005164475 |
| serial_timesteps   | 100352       |
| time_elapsed       | 409          |
| total_timesteps    | 802816       |
| value_loss         | 0.050358452  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009236363   |
| clipfrac           | 0.12670898    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.746         |
| fps                | 2179          |
| n_updates          | 393           |
| policy_entropy     | 3.2714107     |
| policy_loss        | -0.0036121723 |
| serial_timesteps   | 100608        |
| time_elapsed       | 410           |
| total_timesteps    | 804864        |
| value_loss         | 0.05237476    |
--------------------------------------
--------------------------------------
| approxkl           | 0.010702287   |
| clipfrac           | 0.1541504     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.735         |
| fps                | 2103          |
| n_updates          | 394           |
| policy_entropy     | 3.2531986     |
| policy_loss        | -0.0065558753 |
| serial_timesteps   | 100864        |
| time_elapsed       | 411           |
| total_timesteps    | 806912        |
| value_loss         | 0.04850381    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0098892255 |
| clipfrac           | 0.13891602   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.766        |
| fps                | 2163         |
| n_updates          | 395          |
| policy_entropy     | 3.2337093    |
| policy_loss        | -0.004744732 |
| serial_timesteps   | 101120       |
| time_elapsed       | 412          |
| total_timesteps    | 808960       |
| value_loss         | 0.051321425  |
-------------------------------------
Eval num_timesteps=810000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010410694   |
| clipfrac           | 0.1494629     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.732         |
| fps                | 1510          |
| n_updates          | 396           |
| policy_entropy     | 3.2297847     |
| policy_loss        | -0.0059492094 |
| serial_timesteps   | 101376        |
| time_elapsed       | 413           |
| total_timesteps    | 811008        |
| value_loss         | 0.047256123   |
--------------------------------------
-------------------------------------
| approxkl           | 0.011113845  |
| clipfrac           | 0.1550293    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.767        |
| fps                | 2178         |
| n_updates          | 397          |
| policy_entropy     | 3.2062373    |
| policy_loss        | -0.006854522 |
| serial_timesteps   | 101632       |
| time_elapsed       | 414          |
| total_timesteps    | 813056       |
| value_loss         | 0.047167357  |
-------------------------------------
-------------------------------------
| approxkl           | 0.01025491   |
| clipfrac           | 0.14697266   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.4         |
| explained_variance | 0.697        |
| fps                | 2142         |
| n_updates          | 398          |
| policy_entropy     | 3.1744404    |
| policy_loss        | -0.005422195 |
| serial_timesteps   | 101888       |
| time_elapsed       | 415          |
| total_timesteps    | 815104       |
| value_loss         | 0.050758116  |
-------------------------------------
--------------------------------------
| approxkl           | 0.010407547   |
| clipfrac           | 0.1517578     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.741         |
| fps                | 2153          |
| n_updates          | 399           |
| policy_entropy     | 3.1749723     |
| policy_loss        | -0.0059574386 |
| serial_timesteps   | 102144        |
| time_elapsed       | 416           |
| total_timesteps    | 817152        |
| value_loss         | 0.048348818   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0090769    |
| clipfrac           | 0.12148438   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.725        |
| fps                | 2187         |
| n_updates          | 400          |
| policy_entropy     | 3.154488     |
| policy_loss        | -0.002536485 |
| serial_timesteps   | 102400       |
| time_elapsed       | 417          |
| total_timesteps    | 819200       |
| value_loss         | 0.052115034  |
-------------------------------------
Eval num_timesteps=820000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.0102754235  |
| clipfrac           | 0.14140625    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.746         |
| fps                | 1527          |
| n_updates          | 401           |
| policy_entropy     | 3.13404       |
| policy_loss        | -0.0052029374 |
| serial_timesteps   | 102656        |
| time_elapsed       | 418           |
| total_timesteps    | 821248        |
| value_loss         | 0.044563785   |
--------------------------------------
------------------------------------
| approxkl           | 0.011455349 |
| clipfrac           | 0.16186523  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.42       |
| explained_variance | 0.745       |
| fps                | 2166        |
| n_updates          | 402         |
| policy_entropy     | 3.1274176   |
| policy_loss        | -0.00600128 |
| serial_timesteps   | 102912      |
| time_elapsed       | 419         |
| total_timesteps    | 823296      |
| value_loss         | 0.051162083 |
------------------------------------
--------------------------------------
| approxkl           | 0.008997805   |
| clipfrac           | 0.11992188    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.701         |
| fps                | 2190          |
| n_updates          | 403           |
| policy_entropy     | 3.1029105     |
| policy_loss        | -0.0035893668 |
| serial_timesteps   | 103168        |
| time_elapsed       | 420           |
| total_timesteps    | 825344        |
| value_loss         | 0.05088385    |
--------------------------------------
--------------------------------------
| approxkl           | 0.0106085045  |
| clipfrac           | 0.15600586    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.737         |
| fps                | 2203          |
| n_updates          | 404           |
| policy_entropy     | 3.094801      |
| policy_loss        | -0.0070483997 |
| serial_timesteps   | 103424        |
| time_elapsed       | 421           |
| total_timesteps    | 827392        |
| value_loss         | 0.050417412   |
--------------------------------------
--------------------------------------
| approxkl           | 0.009551294   |
| clipfrac           | 0.1319336     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.697         |
| fps                | 2183          |
| n_updates          | 405           |
| policy_entropy     | 3.09166       |
| policy_loss        | -0.0060728407 |
| serial_timesteps   | 103680        |
| time_elapsed       | 422           |
| total_timesteps    | 829440        |
| value_loss         | 0.049988132   |
--------------------------------------
Eval num_timesteps=830000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009602899   |
| clipfrac           | 0.13510743    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.748         |
| fps                | 1515          |
| n_updates          | 406           |
| policy_entropy     | 3.1027293     |
| policy_loss        | -0.0041846437 |
| serial_timesteps   | 103936        |
| time_elapsed       | 423           |
| total_timesteps    | 831488        |
| value_loss         | 0.048426256   |
--------------------------------------
--------------------------------------
| approxkl           | 0.009307599   |
| clipfrac           | 0.12734374    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.691         |
| fps                | 2199          |
| n_updates          | 407           |
| policy_entropy     | 3.106191      |
| policy_loss        | -0.0036873608 |
| serial_timesteps   | 104192        |
| time_elapsed       | 424           |
| total_timesteps    | 833536        |
| value_loss         | 0.052400537   |
--------------------------------------
--------------------------------------
| approxkl           | 0.008785668   |
| clipfrac           | 0.120996095   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.722         |
| fps                | 2205          |
| n_updates          | 408           |
| policy_entropy     | 3.0919876     |
| policy_loss        | -0.0027254128 |
| serial_timesteps   | 104448        |
| time_elapsed       | 425           |
| total_timesteps    | 835584        |
| value_loss         | 0.050887533   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010094186  |
| clipfrac           | 0.1487793    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.713        |
| fps                | 2163         |
| n_updates          | 409          |
| policy_entropy     | 3.0961275    |
| policy_loss        | -0.005977607 |
| serial_timesteps   | 104704       |
| time_elapsed       | 426          |
| total_timesteps    | 837632       |
| value_loss         | 0.053714503  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008759225   |
| clipfrac           | 0.1184082     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.718         |
| fps                | 2130          |
| n_updates          | 410           |
| policy_entropy     | 3.0946097     |
| policy_loss        | -0.0027189094 |
| serial_timesteps   | 104960        |
| time_elapsed       | 427           |
| total_timesteps    | 839680        |
| value_loss         | 0.049052197   |
--------------------------------------
Eval num_timesteps=840000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009837396  |
| clipfrac           | 0.13583985   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.734        |
| fps                | 1511         |
| n_updates          | 411          |
| policy_entropy     | 3.0831587    |
| policy_loss        | -0.003963498 |
| serial_timesteps   | 105216       |
| time_elapsed       | 428          |
| total_timesteps    | 841728       |
| value_loss         | 0.05387169   |
-------------------------------------
--------------------------------------
| approxkl           | 0.009087166   |
| clipfrac           | 0.12368164    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.723         |
| fps                | 2192          |
| n_updates          | 412           |
| policy_entropy     | 3.0364928     |
| policy_loss        | -0.0036577191 |
| serial_timesteps   | 105472        |
| time_elapsed       | 429           |
| total_timesteps    | 843776        |
| value_loss         | 0.047845278   |
--------------------------------------
--------------------------------------
| approxkl           | 0.009595363   |
| clipfrac           | 0.1373047     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.746         |
| fps                | 2149          |
| n_updates          | 413           |
| policy_entropy     | 2.9880986     |
| policy_loss        | -0.0025857862 |
| serial_timesteps   | 105728        |
| time_elapsed       | 430           |
| total_timesteps    | 845824        |
| value_loss         | 0.051401395   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010107848  |
| clipfrac           | 0.14501953   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.685        |
| fps                | 2127         |
| n_updates          | 414          |
| policy_entropy     | 2.9489775    |
| policy_loss        | -0.004498953 |
| serial_timesteps   | 105984       |
| time_elapsed       | 431          |
| total_timesteps    | 847872       |
| value_loss         | 0.052692138  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009446088  |
| clipfrac           | 0.1296875    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.746        |
| fps                | 2188         |
| n_updates          | 415          |
| policy_entropy     | 2.9267392    |
| policy_loss        | -0.004483278 |
| serial_timesteps   | 106240       |
| time_elapsed       | 432          |
| total_timesteps    | 849920       |
| value_loss         | 0.048810814  |
-------------------------------------
Eval num_timesteps=850000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.0093518775  |
| clipfrac           | 0.12885742    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.681         |
| fps                | 1513          |
| n_updates          | 416           |
| policy_entropy     | 2.9143133     |
| policy_loss        | -0.0034497376 |
| serial_timesteps   | 106496        |
| time_elapsed       | 433           |
| total_timesteps    | 851968        |
| value_loss         | 0.054259084   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010953538  |
| clipfrac           | 0.15961914   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.713        |
| fps                | 2129         |
| n_updates          | 417          |
| policy_entropy     | 2.9164042    |
| policy_loss        | -0.005568311 |
| serial_timesteps   | 106752       |
| time_elapsed       | 434          |
| total_timesteps    | 854016       |
| value_loss         | 0.051910717  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00958184   |
| clipfrac           | 0.13574219   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.721        |
| fps                | 2181         |
| n_updates          | 418          |
| policy_entropy     | 2.9285998    |
| policy_loss        | -0.004027204 |
| serial_timesteps   | 107008       |
| time_elapsed       | 435          |
| total_timesteps    | 856064       |
| value_loss         | 0.05454443   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009766945  |
| clipfrac           | 0.1416504    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.707        |
| fps                | 2149         |
| n_updates          | 419          |
| policy_entropy     | 2.913637     |
| policy_loss        | -0.005751948 |
| serial_timesteps   | 107264       |
| time_elapsed       | 436          |
| total_timesteps    | 858112       |
| value_loss         | 0.050638538  |
-------------------------------------
Eval num_timesteps=860000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.011115882   |
| clipfrac           | 0.16225585    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.73          |
| fps                | 1526          |
| n_updates          | 420           |
| policy_entropy     | 2.8840194     |
| policy_loss        | -0.0053193355 |
| serial_timesteps   | 107520        |
| time_elapsed       | 437           |
| total_timesteps    | 860160        |
| value_loss         | 0.05399663    |
--------------------------------------
--------------------------------------
| approxkl           | 0.008517272   |
| clipfrac           | 0.11323242    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.705         |
| fps                | 2182          |
| n_updates          | 421           |
| policy_entropy     | 2.8684678     |
| policy_loss        | -0.0037343535 |
| serial_timesteps   | 107776        |
| time_elapsed       | 439           |
| total_timesteps    | 862208        |
| value_loss         | 0.050115805   |
--------------------------------------
--------------------------------------
| approxkl           | 0.0095849205  |
| clipfrac           | 0.13417968    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.747         |
| fps                | 2154          |
| n_updates          | 422           |
| policy_entropy     | 2.8616383     |
| policy_loss        | -0.0040279664 |
| serial_timesteps   | 108032        |
| time_elapsed       | 440           |
| total_timesteps    | 864256        |
| value_loss         | 0.05244229    |
--------------------------------------
--------------------------------------
| approxkl           | 0.008667151   |
| clipfrac           | 0.11796875    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.699         |
| fps                | 2180          |
| n_updates          | 423           |
| policy_entropy     | 2.8331094     |
| policy_loss        | -0.0025993236 |
| serial_timesteps   | 108288        |
| time_elapsed       | 440           |
| total_timesteps    | 866304        |
| value_loss         | 0.05204177    |
--------------------------------------
-------------------------------------
| approxkl           | 0.009599273  |
| clipfrac           | 0.13554688   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.723        |
| fps                | 2186         |
| n_updates          | 424          |
| policy_entropy     | 2.7852833    |
| policy_loss        | -0.004410258 |
| serial_timesteps   | 108544       |
| time_elapsed       | 441          |
| total_timesteps    | 868352       |
| value_loss         | 0.0533687    |
-------------------------------------
Eval num_timesteps=870000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010227469  |
| clipfrac           | 0.14575195   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.707        |
| fps                | 1528         |
| n_updates          | 425          |
| policy_entropy     | 2.752654     |
| policy_loss        | -0.003026985 |
| serial_timesteps   | 108800       |
| time_elapsed       | 442          |
| total_timesteps    | 870400       |
| value_loss         | 0.05635454   |
-------------------------------------
--------------------------------------
| approxkl           | 0.010232439   |
| clipfrac           | 0.13911133    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.72          |
| fps                | 2172          |
| n_updates          | 426           |
| policy_entropy     | 2.7461774     |
| policy_loss        | -0.0016237885 |
| serial_timesteps   | 109056        |
| time_elapsed       | 444           |
| total_timesteps    | 872448        |
| value_loss         | 0.050617248   |
--------------------------------------
--------------------------------------
| approxkl           | 0.009379281   |
| clipfrac           | 0.12739258    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.716         |
| fps                | 2155          |
| n_updates          | 427           |
| policy_entropy     | 2.7455194     |
| policy_loss        | -0.0035223737 |
| serial_timesteps   | 109312        |
| time_elapsed       | 445           |
| total_timesteps    | 874496        |
| value_loss         | 0.056002267   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010365837   |
| clipfrac           | 0.14545898    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.7           |
| fps                | 2187          |
| n_updates          | 428           |
| policy_entropy     | 2.7481036     |
| policy_loss        | -0.0032100528 |
| serial_timesteps   | 109568        |
| time_elapsed       | 446           |
| total_timesteps    | 876544        |
| value_loss         | 0.050774336   |
--------------------------------------
--------------------------------------
| approxkl           | 0.0110874865  |
| clipfrac           | 0.15942383    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.721         |
| fps                | 2134          |
| n_updates          | 429           |
| policy_entropy     | 2.7749183     |
| policy_loss        | -0.0077273673 |
| serial_timesteps   | 109824        |
| time_elapsed       | 447           |
| total_timesteps    | 878592        |
| value_loss         | 0.055182595   |
--------------------------------------
Eval num_timesteps=880000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010459398  |
| clipfrac           | 0.14975587   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.695        |
| fps                | 1521         |
| n_updates          | 430          |
| policy_entropy     | 2.8011513    |
| policy_loss        | -0.004981099 |
| serial_timesteps   | 110080       |
| time_elapsed       | 447          |
| total_timesteps    | 880640       |
| value_loss         | 0.052184325  |
-------------------------------------
--------------------------------------
| approxkl           | 0.010136568   |
| clipfrac           | 0.14145508    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.734         |
| fps                | 2139          |
| n_updates          | 431           |
| policy_entropy     | 2.7865803     |
| policy_loss        | -0.0045994287 |
| serial_timesteps   | 110336        |
| time_elapsed       | 449           |
| total_timesteps    | 882688        |
| value_loss         | 0.052673936   |
--------------------------------------
--------------------------------------
| approxkl           | 0.009443502   |
| clipfrac           | 0.12905273    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.676         |
| fps                | 2180          |
| n_updates          | 432           |
| policy_entropy     | 2.7825847     |
| policy_loss        | -0.0028639545 |
| serial_timesteps   | 110592        |
| time_elapsed       | 450           |
| total_timesteps    | 884736        |
| value_loss         | 0.054929584   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010765923   |
| clipfrac           | 0.15556641    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.72          |
| fps                | 2126          |
| n_updates          | 433           |
| policy_entropy     | 2.7670085     |
| policy_loss        | -0.0065887123 |
| serial_timesteps   | 110848        |
| time_elapsed       | 451           |
| total_timesteps    | 886784        |
| value_loss         | 0.054298736   |
--------------------------------------
--------------------------------------
| approxkl           | 0.009974743   |
| clipfrac           | 0.13720703    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.716         |
| fps                | 2167          |
| n_updates          | 434           |
| policy_entropy     | 2.7452488     |
| policy_loss        | -0.0029161593 |
| serial_timesteps   | 111104        |
| time_elapsed       | 452           |
| total_timesteps    | 888832        |
| value_loss         | 0.056923114   |
--------------------------------------
Eval num_timesteps=890000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009100771  |
| clipfrac           | 0.12246094   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.718        |
| fps                | 1533         |
| n_updates          | 435          |
| policy_entropy     | 2.7377975    |
| policy_loss        | -0.003103402 |
| serial_timesteps   | 111360       |
| time_elapsed       | 453          |
| total_timesteps    | 890880       |
| value_loss         | 0.05114297   |
-------------------------------------
--------------------------------------
| approxkl           | 0.010062875   |
| clipfrac           | 0.13950196    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.728         |
| fps                | 2177          |
| n_updates          | 436           |
| policy_entropy     | 2.7340677     |
| policy_loss        | -0.0036396459 |
| serial_timesteps   | 111616        |
| time_elapsed       | 454           |
| total_timesteps    | 892928        |
| value_loss         | 0.05598837    |
--------------------------------------
-------------------------------------
| approxkl           | 0.010652535  |
| clipfrac           | 0.15405273   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.708        |
| fps                | 2161         |
| n_updates          | 437          |
| policy_entropy     | 2.7431085    |
| policy_loss        | -0.005340502 |
| serial_timesteps   | 111872       |
| time_elapsed       | 455          |
| total_timesteps    | 894976       |
| value_loss         | 0.05034017   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0115439445 |
| clipfrac           | 0.1671875    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.75         |
| fps                | 2191         |
| n_updates          | 438          |
| policy_entropy     | 2.744897     |
| policy_loss        | -0.006814254 |
| serial_timesteps   | 112128       |
| time_elapsed       | 456          |
| total_timesteps    | 897024       |
| value_loss         | 0.05189429   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009691859  |
| clipfrac           | 0.13891602   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.679        |
| fps                | 2158         |
| n_updates          | 439          |
| policy_entropy     | 2.7455447    |
| policy_loss        | -0.003666615 |
| serial_timesteps   | 112384       |
| time_elapsed       | 457          |
| total_timesteps    | 899072       |
| value_loss         | 0.054699987  |
-------------------------------------
Eval num_timesteps=900000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010010115   |
| clipfrac           | 0.14179687    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.721         |
| fps                | 1529          |
| n_updates          | 440           |
| policy_entropy     | 2.7398164     |
| policy_loss        | -0.0026731458 |
| serial_timesteps   | 112640        |
| time_elapsed       | 458           |
| total_timesteps    | 901120        |
| value_loss         | 0.053701233   |
--------------------------------------
-------------------------------------
| approxkl           | 0.011290614  |
| clipfrac           | 0.16157226   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.668        |
| fps                | 2161         |
| n_updates          | 441          |
| policy_entropy     | 2.7248511    |
| policy_loss        | -0.005090176 |
| serial_timesteps   | 112896       |
| time_elapsed       | 459          |
| total_timesteps    | 903168       |
| value_loss         | 0.05656582   |
-------------------------------------
-------------------------------------
| approxkl           | 0.011481153  |
| clipfrac           | 0.15878907   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.702        |
| fps                | 2173         |
| n_updates          | 442          |
| policy_entropy     | 2.6894956    |
| policy_loss        | -0.004289468 |
| serial_timesteps   | 113152       |
| time_elapsed       | 460          |
| total_timesteps    | 905216       |
| value_loss         | 0.05384935   |
-------------------------------------
-------------------------------------
| approxkl           | 0.011171999  |
| clipfrac           | 0.15961914   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.703        |
| fps                | 2171         |
| n_updates          | 443          |
| policy_entropy     | 2.6551015    |
| policy_loss        | -0.003872541 |
| serial_timesteps   | 113408       |
| time_elapsed       | 461          |
| total_timesteps    | 907264       |
| value_loss         | 0.0574493    |
-------------------------------------
--------------------------------------
| approxkl           | 0.008698973   |
| clipfrac           | 0.12036133    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.689         |
| fps                | 2165          |
| n_updates          | 444           |
| policy_entropy     | 2.6487916     |
| policy_loss        | -0.0032540853 |
| serial_timesteps   | 113664        |
| time_elapsed       | 462           |
| total_timesteps    | 909312        |
| value_loss         | 0.052627314   |
--------------------------------------
Eval num_timesteps=910000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009201543   |
| clipfrac           | 0.12451172    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.715         |
| fps                | 1518          |
| n_updates          | 445           |
| policy_entropy     | 2.655217      |
| policy_loss        | -0.0015746604 |
| serial_timesteps   | 113920        |
| time_elapsed       | 463           |
| total_timesteps    | 911360        |
| value_loss         | 0.056267522   |
--------------------------------------
--------------------------------------
| approxkl           | 0.009911066   |
| clipfrac           | 0.1361328     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.699         |
| fps                | 2199          |
| n_updates          | 446           |
| policy_entropy     | 2.6408272     |
| policy_loss        | -0.0022354769 |
| serial_timesteps   | 114176        |
| time_elapsed       | 464           |
| total_timesteps    | 913408        |
| value_loss         | 0.050424673   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010937529  |
| clipfrac           | 0.1574707    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.736        |
| fps                | 2169         |
| n_updates          | 447          |
| policy_entropy     | 2.6299627    |
| policy_loss        | -0.005829568 |
| serial_timesteps   | 114432       |
| time_elapsed       | 465          |
| total_timesteps    | 915456       |
| value_loss         | 0.054228324  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009861419   |
| clipfrac           | 0.13452148    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.684         |
| fps                | 2161          |
| n_updates          | 448           |
| policy_entropy     | 2.6107917     |
| policy_loss        | -0.0050516836 |
| serial_timesteps   | 114688        |
| time_elapsed       | 466           |
| total_timesteps    | 917504        |
| value_loss         | 0.054634433   |
--------------------------------------
--------------------------------------
| approxkl           | 0.01271574    |
| clipfrac           | 0.17416993    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.73          |
| fps                | 2141          |
| n_updates          | 449           |
| policy_entropy     | 2.5912745     |
| policy_loss        | -0.0056843185 |
| serial_timesteps   | 114944        |
| time_elapsed       | 467           |
| total_timesteps    | 919552        |
| value_loss         | 0.053464103   |
--------------------------------------
Eval num_timesteps=920000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009608738   |
| clipfrac           | 0.13134766    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.708         |
| fps                | 1523          |
| n_updates          | 450           |
| policy_entropy     | 2.5930893     |
| policy_loss        | -0.0015936336 |
| serial_timesteps   | 115200        |
| time_elapsed       | 468           |
| total_timesteps    | 921600        |
| value_loss         | 0.055345677   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010464579   |
| clipfrac           | 0.14335938    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.718         |
| fps                | 2179          |
| n_updates          | 451           |
| policy_entropy     | 2.5967705     |
| policy_loss        | -0.0019583043 |
| serial_timesteps   | 115456        |
| time_elapsed       | 469           |
| total_timesteps    | 923648        |
| value_loss         | 0.051512443   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009728802  |
| clipfrac           | 0.13486329   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.71         |
| fps                | 2161         |
| n_updates          | 452          |
| policy_entropy     | 2.5787847    |
| policy_loss        | -0.005007224 |
| serial_timesteps   | 115712       |
| time_elapsed       | 470          |
| total_timesteps    | 925696       |
| value_loss         | 0.05718004   |
-------------------------------------
--------------------------------------
| approxkl           | 0.010745175   |
| clipfrac           | 0.15283203    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.711         |
| fps                | 2130          |
| n_updates          | 453           |
| policy_entropy     | 2.5609868     |
| policy_loss        | -0.0038655307 |
| serial_timesteps   | 115968        |
| time_elapsed       | 471           |
| total_timesteps    | 927744        |
| value_loss         | 0.049855504   |
--------------------------------------
--------------------------------------
| approxkl           | 0.009606148   |
| clipfrac           | 0.1319336     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.727         |
| fps                | 2177          |
| n_updates          | 454           |
| policy_entropy     | 2.5417144     |
| policy_loss        | -0.0022443994 |
| serial_timesteps   | 116224        |
| time_elapsed       | 472           |
| total_timesteps    | 929792        |
| value_loss         | 0.053783406   |
--------------------------------------
Eval num_timesteps=930000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010458189  |
| clipfrac           | 0.1506836    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.41        |
| explained_variance | 0.673        |
| fps                | 1537         |
| n_updates          | 455          |
| policy_entropy     | 2.543975     |
| policy_loss        | -0.005370148 |
| serial_timesteps   | 116480       |
| time_elapsed       | 473          |
| total_timesteps    | 931840       |
| value_loss         | 0.054008402  |
-------------------------------------
--------------------------------------
| approxkl           | 0.011539703   |
| clipfrac           | 0.1619629     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.722         |
| fps                | 2166          |
| n_updates          | 456           |
| policy_entropy     | 2.546036      |
| policy_loss        | -0.0054325485 |
| serial_timesteps   | 116736        |
| time_elapsed       | 474           |
| total_timesteps    | 933888        |
| value_loss         | 0.0531872     |
--------------------------------------
--------------------------------------
| approxkl           | 0.010480571   |
| clipfrac           | 0.14282227    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.41         |
| explained_variance | 0.675         |
| fps                | 2189          |
| n_updates          | 457           |
| policy_entropy     | 2.5157492     |
| policy_loss        | -0.0046581766 |
| serial_timesteps   | 116992        |
| time_elapsed       | 475           |
| total_timesteps    | 935936        |
| value_loss         | 0.056367803   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010618859   |
| clipfrac           | 0.15517578    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.696         |
| fps                | 2173          |
| n_updates          | 458           |
| policy_entropy     | 2.4605002     |
| policy_loss        | -0.0071291276 |
| serial_timesteps   | 117248        |
| time_elapsed       | 476           |
| total_timesteps    | 937984        |
| value_loss         | 0.055953108   |
--------------------------------------
Eval num_timesteps=940000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009971753   |
| clipfrac           | 0.14223632    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.703         |
| fps                | 1513          |
| n_updates          | 459           |
| policy_entropy     | 2.3958554     |
| policy_loss        | -0.0052319216 |
| serial_timesteps   | 117504        |
| time_elapsed       | 477           |
| total_timesteps    | 940032        |
| value_loss         | 0.05682062    |
--------------------------------------
-------------------------------------
| approxkl           | 0.011155359  |
| clipfrac           | 0.15805665   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.42        |
| explained_variance | 0.723        |
| fps                | 2143         |
| n_updates          | 460          |
| policy_entropy     | 2.361662     |
| policy_loss        | -0.005507846 |
| serial_timesteps   | 117760       |
| time_elapsed       | 479          |
| total_timesteps    | 942080       |
| value_loss         | 0.04859143   |
-------------------------------------
--------------------------------------
| approxkl           | 0.010787079   |
| clipfrac           | 0.1494629     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.42         |
| explained_variance | 0.719         |
| fps                | 2144          |
| n_updates          | 461           |
| policy_entropy     | 2.3291962     |
| policy_loss        | -0.0047380347 |
| serial_timesteps   | 118016        |
| time_elapsed       | 480           |
| total_timesteps    | 944128        |
| value_loss         | 0.05446381    |
--------------------------------------
-------------------------------------
| approxkl           | 0.01242636   |
| clipfrac           | 0.16899414   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.719        |
| fps                | 2179         |
| n_updates          | 462          |
| policy_entropy     | 2.2901194    |
| policy_loss        | -0.007406066 |
| serial_timesteps   | 118272       |
| time_elapsed       | 481          |
| total_timesteps    | 946176       |
| value_loss         | 0.04732286   |
-------------------------------------
--------------------------------------
| approxkl           | 0.014616164   |
| clipfrac           | 0.18339844    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.45         |
| explained_variance | 0.697         |
| fps                | 2176          |
| n_updates          | 463           |
| policy_entropy     | 2.2833626     |
| policy_loss        | -0.0048632985 |
| serial_timesteps   | 118528        |
| time_elapsed       | 481           |
| total_timesteps    | 948224        |
| value_loss         | 0.055790376   |
--------------------------------------
Eval num_timesteps=950000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.011252185  |
| clipfrac           | 0.16489258   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.689        |
| fps                | 1528         |
| n_updates          | 464          |
| policy_entropy     | 2.2898133    |
| policy_loss        | -0.007954358 |
| serial_timesteps   | 118784       |
| time_elapsed       | 482          |
| total_timesteps    | 950272       |
| value_loss         | 0.05475816   |
-------------------------------------
-------------------------------------
| approxkl           | 0.012938684  |
| clipfrac           | 0.17592773   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.732        |
| fps                | 2176         |
| n_updates          | 465          |
| policy_entropy     | 2.2812204    |
| policy_loss        | -0.006906978 |
| serial_timesteps   | 119040       |
| time_elapsed       | 484          |
| total_timesteps    | 952320       |
| value_loss         | 0.05291625   |
-------------------------------------
-------------------------------------
| approxkl           | 0.012514718  |
| clipfrac           | 0.18222657   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.739        |
| fps                | 2182         |
| n_updates          | 466          |
| policy_entropy     | 2.2706604    |
| policy_loss        | -0.005428146 |
| serial_timesteps   | 119296       |
| time_elapsed       | 485          |
| total_timesteps    | 954368       |
| value_loss         | 0.045268133  |
-------------------------------------
--------------------------------------
| approxkl           | 0.01322421    |
| clipfrac           | 0.16269532    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.48         |
| explained_variance | 0.663         |
| fps                | 2135          |
| n_updates          | 467           |
| policy_entropy     | 2.2548316     |
| policy_loss        | -0.0046340283 |
| serial_timesteps   | 119552        |
| time_elapsed       | 486           |
| total_timesteps    | 956416        |
| value_loss         | 0.060521603   |
--------------------------------------
-------------------------------------
| approxkl           | 0.016726555  |
| clipfrac           | 0.19248047   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.695        |
| fps                | 2148         |
| n_updates          | 468          |
| policy_entropy     | 2.2439804    |
| policy_loss        | -0.006215983 |
| serial_timesteps   | 119808       |
| time_elapsed       | 487          |
| total_timesteps    | 958464       |
| value_loss         | 0.06024168   |
-------------------------------------
Eval num_timesteps=960000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0123132635 |
| clipfrac           | 0.178125     |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.48        |
| explained_variance | 0.711        |
| fps                | 1522         |
| n_updates          | 469          |
| policy_entropy     | 2.2167056    |
| policy_loss        | -0.008025839 |
| serial_timesteps   | 120064       |
| time_elapsed       | 488          |
| total_timesteps    | 960512       |
| value_loss         | 0.0506756    |
-------------------------------------
--------------------------------------
| approxkl           | 0.010727525   |
| clipfrac           | 0.15703125    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.47         |
| explained_variance | 0.751         |
| fps                | 2198          |
| n_updates          | 470           |
| policy_entropy     | 2.1965904     |
| policy_loss        | -0.0054200245 |
| serial_timesteps   | 120320        |
| time_elapsed       | 489           |
| total_timesteps    | 962560        |
| value_loss         | 0.051071234   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010118438   |
| clipfrac           | 0.14086914    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.46         |
| explained_variance | 0.696         |
| fps                | 2174          |
| n_updates          | 471           |
| policy_entropy     | 2.186235      |
| policy_loss        | -0.0047512637 |
| serial_timesteps   | 120576        |
| time_elapsed       | 490           |
| total_timesteps    | 964608        |
| value_loss         | 0.051087666   |
--------------------------------------
-------------------------------------
| approxkl           | 0.013338824  |
| clipfrac           | 0.18276367   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.749        |
| fps                | 2188         |
| n_updates          | 472          |
| policy_entropy     | 2.1734076    |
| policy_loss        | -0.008462907 |
| serial_timesteps   | 120832       |
| time_elapsed       | 491          |
| total_timesteps    | 966656       |
| value_loss         | 0.04933599   |
-------------------------------------
--------------------------------------
| approxkl           | 0.011811843   |
| clipfrac           | 0.16772461    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.44         |
| explained_variance | 0.695         |
| fps                | 2175          |
| n_updates          | 473           |
| policy_entropy     | 2.1409147     |
| policy_loss        | -0.0066867704 |
| serial_timesteps   | 121088        |
| time_elapsed       | 492           |
| total_timesteps    | 968704        |
| value_loss         | 0.05512906    |
--------------------------------------
Eval num_timesteps=970000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.012678918  |
| clipfrac           | 0.1887207    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.735        |
| fps                | 1529         |
| n_updates          | 474          |
| policy_entropy     | 2.1277833    |
| policy_loss        | -0.008205694 |
| serial_timesteps   | 121344       |
| time_elapsed       | 493          |
| total_timesteps    | 970752       |
| value_loss         | 0.053914867  |
-------------------------------------
--------------------------------------
| approxkl           | 0.010334551   |
| clipfrac           | 0.1409668     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.45         |
| explained_variance | 0.696         |
| fps                | 2160          |
| n_updates          | 475           |
| policy_entropy     | 2.1136675     |
| policy_loss        | -0.0032683555 |
| serial_timesteps   | 121600        |
| time_elapsed       | 494           |
| total_timesteps    | 972800        |
| value_loss         | 0.06085957    |
--------------------------------------
-------------------------------------
| approxkl           | 0.012388472  |
| clipfrac           | 0.17548828   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.45        |
| explained_variance | 0.753        |
| fps                | 2128         |
| n_updates          | 476          |
| policy_entropy     | 2.0669656    |
| policy_loss        | -0.008925928 |
| serial_timesteps   | 121856       |
| time_elapsed       | 495          |
| total_timesteps    | 974848       |
| value_loss         | 0.04680689   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010699874  |
| clipfrac           | 0.14321288   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.697        |
| fps                | 2165         |
| n_updates          | 477          |
| policy_entropy     | 2.0335736    |
| policy_loss        | -0.002915055 |
| serial_timesteps   | 122112       |
| time_elapsed       | 496          |
| total_timesteps    | 976896       |
| value_loss         | 0.06035029   |
-------------------------------------
--------------------------------------
| approxkl           | 0.010398979   |
| clipfrac           | 0.14472656    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.44         |
| explained_variance | 0.71          |
| fps                | 2150          |
| n_updates          | 478           |
| policy_entropy     | 2.0085182     |
| policy_loss        | -0.0037085793 |
| serial_timesteps   | 122368        |
| time_elapsed       | 497           |
| total_timesteps    | 978944        |
| value_loss         | 0.04960115    |
--------------------------------------
Eval num_timesteps=980000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010410274   |
| clipfrac           | 0.14526367    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.45         |
| explained_variance | 0.737         |
| fps                | 1527          |
| n_updates          | 479           |
| policy_entropy     | 2.0017915     |
| policy_loss        | -0.0038606948 |
| serial_timesteps   | 122624        |
| time_elapsed       | 498           |
| total_timesteps    | 980992        |
| value_loss         | 0.054695778   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0124261165 |
| clipfrac           | 0.16328125   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.674        |
| fps                | 2133         |
| n_updates          | 480          |
| policy_entropy     | 1.984034     |
| policy_loss        | -0.00812052  |
| serial_timesteps   | 122880       |
| time_elapsed       | 499          |
| total_timesteps    | 983040       |
| value_loss         | 0.057645816  |
-------------------------------------
--------------------------------------
| approxkl           | 0.011366889   |
| clipfrac           | 0.1595703     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.44         |
| explained_variance | 0.758         |
| fps                | 2175          |
| n_updates          | 481           |
| policy_entropy     | 1.9643891     |
| policy_loss        | -0.0028137367 |
| serial_timesteps   | 123136        |
| time_elapsed       | 500           |
| total_timesteps    | 985088        |
| value_loss         | 0.04898995    |
--------------------------------------
-------------------------------------
| approxkl           | 0.010606692  |
| clipfrac           | 0.15009765   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.44        |
| explained_variance | 0.68         |
| fps                | 2178         |
| n_updates          | 482          |
| policy_entropy     | 1.9614131    |
| policy_loss        | -0.003941833 |
| serial_timesteps   | 123392       |
| time_elapsed       | 501          |
| total_timesteps    | 987136       |
| value_loss         | 0.05148254   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0106835235  |
| clipfrac           | 0.14536133    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.44         |
| explained_variance | 0.707         |
| fps                | 2160          |
| n_updates          | 483           |
| policy_entropy     | 1.9592869     |
| policy_loss        | -0.0012125425 |
| serial_timesteps   | 123648        |
| time_elapsed       | 502           |
| total_timesteps    | 989184        |
| value_loss         | 0.05511471    |
--------------------------------------
Eval num_timesteps=990000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.011292698   |
| clipfrac           | 0.14731446    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.44         |
| explained_variance | 0.683         |
| fps                | 1513          |
| n_updates          | 484           |
| policy_entropy     | 1.9512646     |
| policy_loss        | -0.0032601063 |
| serial_timesteps   | 123904        |
| time_elapsed       | 503           |
| total_timesteps    | 991232        |
| value_loss         | 0.059600372   |
--------------------------------------
-------------------------------------
| approxkl           | 0.011783674  |
| clipfrac           | 0.16069336   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.43        |
| explained_variance | 0.731        |
| fps                | 2162         |
| n_updates          | 485          |
| policy_entropy     | 1.9281632    |
| policy_loss        | -0.004319713 |
| serial_timesteps   | 124160       |
| time_elapsed       | 504          |
| total_timesteps    | 993280       |
| value_loss         | 0.048957057  |
-------------------------------------
--------------------------------------
| approxkl           | 0.011166828   |
| clipfrac           | 0.15463868    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.45         |
| explained_variance | 0.749         |
| fps                | 2193          |
| n_updates          | 486           |
| policy_entropy     | 1.9015604     |
| policy_loss        | -0.0035964712 |
| serial_timesteps   | 124416        |
| time_elapsed       | 505           |
| total_timesteps    | 995328        |
| value_loss         | 0.05089001    |
--------------------------------------
--------------------------------------
| approxkl           | 0.010778497   |
| clipfrac           | 0.15463868    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.45         |
| explained_variance | 0.698         |
| fps                | 2160          |
| n_updates          | 487           |
| policy_entropy     | 1.8906705     |
| policy_loss        | -0.0011014048 |
| serial_timesteps   | 124672        |
| time_elapsed       | 506           |
| total_timesteps    | 997376        |
| value_loss         | 0.052034896   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009981945  |
| clipfrac           | 0.13989258   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.46        |
| explained_variance | 0.742        |
| fps                | 2156         |
| n_updates          | 488          |
| policy_entropy     | 1.8990167    |
| policy_loss        | -0.003954639 |
| serial_timesteps   | 124928       |
| time_elapsed       | 507          |
| total_timesteps    | 999424       |
| value_loss         | 0.051202215  |
-------------------------------------
Saving to logs/train_1M_widowx_reach-v3/ppo2/widowx_reach-v3_1
