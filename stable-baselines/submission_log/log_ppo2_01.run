--------------------------------------------------------------------------
WARNING: There was an error initializing an OpenFabrics device.

  Local host:   n359
  Local device: hfi1_0
--------------------------------------------------------------------------
--------------------------------------------------------------------------
Warning: Open MPI has detected that you are running in an environment with CUDA
devices present and that you are using Intel(r) Ompi-Path networking. However,
the environment variable PSM2_CUDA was not set, meaning that the PSM2 Omni-Path
networking library was not told how to handle CUDA support.

If your application uses CUDA buffers, you should set the environment variable
PSM2_CUDA to 1; otherwise, set it to 0. Setting the variable to the wrong value
can have performance implications on your application, or even cause it to
crash.

Since it was not set, Open MPI has defaulted to setting the PSM2_CUDA
environment variable to 1.

Local hostname: n359
--------------------------------------------------------------------------
/ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

pybullet build time: May 18 2020 02:46:26
b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkWARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff917481d68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff917481d68>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff9174ad1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7ff9174ad1d0>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /ichec/home/users/pierre/.conda/envs/SB_widowx/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

========== widowx_reach-v3 ==========
Seed: 1
OrderedDict([('cliprange', 0.2),
             ('ent_coef', 0.0),
             ('gamma', 0.99),
             ('lam', 0.95),
             ('learning_rate', 0.00025),
             ('n_envs', 8),
             ('n_steps', 256),
             ('n_timesteps', 1000000.0),
             ('nminibatches', 32),
             ('noptepochs', 10),
             ('normalize', True),
             ('policy', 'MlpPolicy')])
Using 8 environments
Overwriting n_timesteps with n=1000000
********goal is : *********** [-0.02323384  0.05728437  0.26001487]
********goal is : *********** [-0.01792143 -0.12325918  0.33145612]
********goal is : *********** [0.01422341 0.05411843 0.29781762]
********goal is : *********** [0.13076835 0.01228038 0.38644897]
********goal is : *********** [-0.07784191  0.0963904   0.28687349]
********goal is : *********** [ 0.11000084 -0.04368525  0.36675979]
********goal is : *********** [-0.11863368  0.07277889  0.3169932 ]
********goal is : *********** [0.10456023 0.12182057 0.37299529]
Normalizing input and reward
TRAINING ENV TYPE 000:  <stable_baselines.common.vec_env.vec_normalize.VecNormalize object at 0x7ff917478080>
Creating test environment
TRAINING ENV TYPE 111:  <stable_baselines.common.vec_env.vec_normalize.VecNormalize object at 0x7ff917478080>
********goal is : *********** [-0.02323384  0.05728437  0.26001487]
Normalization activated: {'norm_reward': False}
PIERRE - CREATE ENV FROM EVALCALLBACK: <stable_baselines.common.vec_env.vec_normalize.VecNormalize object at 0x7ff917481198>
********goal is : *********** [-0.02323384  0.05728437  0.26001487]
Normalization activated: {'norm_reward': False}
TRAINING ENV TYPE 444:  <stable_baselines.common.vec_env.vec_normalize.VecNormalize object at 0x7ff917478080>
Log path: logs/train_1M_widowx_reach-v3/ppo2/widowx_reach-v3_2
-------------------------------------
| approxkl           | 0.006842808  |
| clipfrac           | 0.09033203   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.163        |
| fps                | 1463         |
| n_updates          | 1            |
| policy_entropy     | 8.522959     |
| policy_loss        | -0.011030924 |
| serial_timesteps   | 256          |
| time_elapsed       | 2.19e-05     |
| total_timesteps    | 2048         |
| value_loss         | 0.74089366   |
-------------------------------------
------------------------------------
| approxkl           | 0.00890087  |
| clipfrac           | 0.12495117  |
| ep_len_mean        | 98.6        |
| ep_reward_mean     | -1.93       |
| explained_variance | 0.519       |
| fps                | 2113        |
| n_updates          | 2           |
| policy_entropy     | 8.515132    |
| policy_loss        | -0.01865607 |
| serial_timesteps   | 512         |
| time_elapsed       | 1.4         |
| total_timesteps    | 4096        |
| value_loss         | 0.11541095  |
------------------------------------
-------------------------------------
| approxkl           | 0.009126176  |
| clipfrac           | 0.13300781   |
| ep_len_mean        | 99           |
| ep_reward_mean     | -2.04        |
| explained_variance | 0.224        |
| fps                | 2141         |
| n_updates          | 3            |
| policy_entropy     | 8.502177     |
| policy_loss        | -0.018025573 |
| serial_timesteps   | 768          |
| time_elapsed       | 2.37         |
| total_timesteps    | 6144         |
| value_loss         | 0.1704246    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0100060385 |
| clipfrac           | 0.14760742   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -2.08        |
| explained_variance | 0.214        |
| fps                | 2101         |
| n_updates          | 4            |
| policy_entropy     | 8.481638     |
| policy_loss        | -0.019071218 |
| serial_timesteps   | 1024         |
| time_elapsed       | 3.33         |
| total_timesteps    | 8192         |
| value_loss         | 0.10785755   |
-------------------------------------
Eval num_timesteps=10000, episode_reward=-2.96 +/- 0.04
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.009729444  |
| clipfrac           | 0.146875     |
| ep_len_mean        | 99.4         |
| ep_reward_mean     | -2.15        |
| explained_variance | 0.218        |
| fps                | 1387         |
| n_updates          | 5            |
| policy_entropy     | 8.466394     |
| policy_loss        | -0.016179508 |
| serial_timesteps   | 1280         |
| time_elapsed       | 4.3          |
| total_timesteps    | 10240        |
| value_loss         | 0.10380199   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008542783  |
| clipfrac           | 0.117041014  |
| ep_len_mean        | 99.4         |
| ep_reward_mean     | -2.22        |
| explained_variance | 0.239        |
| fps                | 2116         |
| n_updates          | 6            |
| policy_entropy     | 8.464088     |
| policy_loss        | -0.015323326 |
| serial_timesteps   | 1536         |
| time_elapsed       | 5.78         |
| total_timesteps    | 12288        |
| value_loss         | 0.064592995  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0071089054 |
| clipfrac           | 0.0909668    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.26        |
| explained_variance | 0.162        |
| fps                | 2103         |
| n_updates          | 7            |
| policy_entropy     | 8.469654     |
| policy_loss        | -0.010433057 |
| serial_timesteps   | 1792         |
| time_elapsed       | 6.74         |
| total_timesteps    | 14336        |
| value_loss         | 0.07302989   |
-------------------------------------
-------------------------------------
| approxkl           | 0.006969402  |
| clipfrac           | 0.08979492   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.3         |
| explained_variance | 0.349        |
| fps                | 2006         |
| n_updates          | 8            |
| policy_entropy     | 8.464648     |
| policy_loss        | -0.012946893 |
| serial_timesteps   | 2048         |
| time_elapsed       | 7.72         |
| total_timesteps    | 16384        |
| value_loss         | 0.06989919   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0060602305 |
| clipfrac           | 0.07524414   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.32        |
| explained_variance | 0.3          |
| fps                | 2155         |
| n_updates          | 9            |
| policy_entropy     | 8.44429      |
| policy_loss        | -0.008858262 |
| serial_timesteps   | 2304         |
| time_elapsed       | 8.74         |
| total_timesteps    | 18432        |
| value_loss         | 0.08708737   |
-------------------------------------
Eval num_timesteps=20000, episode_reward=-2.93 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.008921291  |
| clipfrac           | 0.13139649   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.3         |
| explained_variance | 0.426        |
| fps                | 1471         |
| n_updates          | 10           |
| policy_entropy     | 8.422975     |
| policy_loss        | -0.015389708 |
| serial_timesteps   | 2560         |
| time_elapsed       | 9.69         |
| total_timesteps    | 20480        |
| value_loss         | 0.06533646   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077010756 |
| clipfrac           | 0.110888675  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.3         |
| explained_variance | 0.427        |
| fps                | 2097         |
| n_updates          | 11           |
| policy_entropy     | 8.407763     |
| policy_loss        | -0.011495502 |
| serial_timesteps   | 2816         |
| time_elapsed       | 11.1         |
| total_timesteps    | 22528        |
| value_loss         | 0.09878432   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007631898  |
| clipfrac           | 0.1003418    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.33        |
| explained_variance | 0.448        |
| fps                | 2096         |
| n_updates          | 12           |
| policy_entropy     | 8.379909     |
| policy_loss        | -0.013547616 |
| serial_timesteps   | 3072         |
| time_elapsed       | 12.1         |
| total_timesteps    | 24576        |
| value_loss         | 0.091544695  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007917097  |
| clipfrac           | 0.10991211   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.32        |
| explained_variance | 0.618        |
| fps                | 2098         |
| n_updates          | 13           |
| policy_entropy     | 8.3525095    |
| policy_loss        | -0.013449842 |
| serial_timesteps   | 3328         |
| time_elapsed       | 13           |
| total_timesteps    | 26624        |
| value_loss         | 0.06020359   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0065193935 |
| clipfrac           | 0.08549805   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.23        |
| explained_variance | 0.549        |
| fps                | 2108         |
| n_updates          | 14           |
| policy_entropy     | 8.345126     |
| policy_loss        | -0.01192052  |
| serial_timesteps   | 3584         |
| time_elapsed       | 14           |
| total_timesteps    | 28672        |
| value_loss         | 0.06698386   |
-------------------------------------
Eval num_timesteps=30000, episode_reward=-2.84 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
------------------------------------
| approxkl           | 0.007103463 |
| clipfrac           | 0.0953125   |
| ep_len_mean        | 100         |
| ep_reward_mean     | -2.25       |
| explained_variance | 0.492       |
| fps                | 1454        |
| n_updates          | 15          |
| policy_entropy     | 8.355477    |
| policy_loss        | -0.01180913 |
| serial_timesteps   | 3840        |
| time_elapsed       | 15          |
| total_timesteps    | 30720       |
| value_loss         | 0.101934925 |
------------------------------------
-------------------------------------
| approxkl           | 0.00762481   |
| clipfrac           | 0.10478516   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.25        |
| explained_variance | 0.658        |
| fps                | 2124         |
| n_updates          | 16           |
| policy_entropy     | 8.353733     |
| policy_loss        | -0.013208993 |
| serial_timesteps   | 4096         |
| time_elapsed       | 16.4         |
| total_timesteps    | 32768        |
| value_loss         | 0.040354516  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009985548  |
| clipfrac           | 0.14433594   |
| ep_len_mean        | 99.9         |
| ep_reward_mean     | -2.24        |
| explained_variance | 0.685        |
| fps                | 2158         |
| n_updates          | 17           |
| policy_entropy     | 8.352833     |
| policy_loss        | -0.014608467 |
| serial_timesteps   | 4352         |
| time_elapsed       | 17.4         |
| total_timesteps    | 34816        |
| value_loss         | 0.055080783  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010421386  |
| clipfrac           | 0.14750977   |
| ep_len_mean        | 99.9         |
| ep_reward_mean     | -2.26        |
| explained_variance | 0.548        |
| fps                | 2106         |
| n_updates          | 18           |
| policy_entropy     | 8.370049     |
| policy_loss        | -0.018339146 |
| serial_timesteps   | 4608         |
| time_elapsed       | 18.3         |
| total_timesteps    | 36864        |
| value_loss         | 0.08017911   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008609449  |
| clipfrac           | 0.1171875    |
| ep_len_mean        | 99.9         |
| ep_reward_mean     | -2.28        |
| explained_variance | 0.529        |
| fps                | 2067         |
| n_updates          | 19           |
| policy_entropy     | 8.367008     |
| policy_loss        | -0.015787546 |
| serial_timesteps   | 4864         |
| time_elapsed       | 19.3         |
| total_timesteps    | 38912        |
| value_loss         | 0.078611895  |
-------------------------------------
Eval num_timesteps=40000, episode_reward=-2.74 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.0071832566 |
| clipfrac           | 0.09702148   |
| ep_len_mean        | 99.9         |
| ep_reward_mean     | -2.31        |
| explained_variance | 0.436        |
| fps                | 1460         |
| n_updates          | 20           |
| policy_entropy     | 8.360155     |
| policy_loss        | -0.00939375  |
| serial_timesteps   | 5120         |
| time_elapsed       | 20.3         |
| total_timesteps    | 40960        |
| value_loss         | 0.09929331   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0074439077 |
| clipfrac           | 0.09790039   |
| ep_len_mean        | 99.9         |
| ep_reward_mean     | -2.31        |
| explained_variance | 0.624        |
| fps                | 2130         |
| n_updates          | 21           |
| policy_entropy     | 8.340933     |
| policy_loss        | -0.010058472 |
| serial_timesteps   | 5376         |
| time_elapsed       | 21.7         |
| total_timesteps    | 43008        |
| value_loss         | 0.06652571   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0070522213 |
| clipfrac           | 0.09345703   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.25        |
| explained_variance | 0.558        |
| fps                | 2120         |
| n_updates          | 22           |
| policy_entropy     | 8.322211     |
| policy_loss        | -0.011525375 |
| serial_timesteps   | 5632         |
| time_elapsed       | 22.6         |
| total_timesteps    | 45056        |
| value_loss         | 0.08234598   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0056682616 |
| clipfrac           | 0.06713867   |
| ep_len_mean        | 99.9         |
| ep_reward_mean     | -2.28        |
| explained_variance | 0.517        |
| fps                | 2095         |
| n_updates          | 23           |
| policy_entropy     | 8.309472     |
| policy_loss        | -0.008070826 |
| serial_timesteps   | 5888         |
| time_elapsed       | 23.6         |
| total_timesteps    | 47104        |
| value_loss         | 0.09046216   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007728541  |
| clipfrac           | 0.1065918    |
| ep_len_mean        | 99.9         |
| ep_reward_mean     | -2.29        |
| explained_variance | 0.529        |
| fps                | 2076         |
| n_updates          | 24           |
| policy_entropy     | 8.30134      |
| policy_loss        | -0.009800473 |
| serial_timesteps   | 6144         |
| time_elapsed       | 24.6         |
| total_timesteps    | 49152        |
| value_loss         | 0.084854856  |
-------------------------------------
Eval num_timesteps=50000, episode_reward=-0.83 +/- 0.01
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.006208946  |
| clipfrac           | 0.079638675  |
| ep_len_mean        | 99.9         |
| ep_reward_mean     | -2.39        |
| explained_variance | 0.407        |
| fps                | 1433         |
| n_updates          | 25           |
| policy_entropy     | 8.3045435    |
| policy_loss        | -0.008306254 |
| serial_timesteps   | 6400         |
| time_elapsed       | 25.6         |
| total_timesteps    | 51200        |
| value_loss         | 0.11739113   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0058472403  |
| clipfrac           | 0.07011719    |
| ep_len_mean        | 99.9          |
| ep_reward_mean     | -2.38         |
| explained_variance | 0.567         |
| fps                | 2108          |
| n_updates          | 26            |
| policy_entropy     | 8.295891      |
| policy_loss        | -0.0071993237 |
| serial_timesteps   | 6656          |
| time_elapsed       | 27            |
| total_timesteps    | 53248         |
| value_loss         | 0.06985462    |
--------------------------------------
-------------------------------------
| approxkl           | 0.005618578  |
| clipfrac           | 0.06455078   |
| ep_len_mean        | 99.4         |
| ep_reward_mean     | -2.42        |
| explained_variance | 0.491        |
| fps                | 2049         |
| n_updates          | 27           |
| policy_entropy     | 8.258162     |
| policy_loss        | -0.008141772 |
| serial_timesteps   | 6912         |
| time_elapsed       | 28           |
| total_timesteps    | 55296        |
| value_loss         | 0.10806892   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00715408   |
| clipfrac           | 0.09482422   |
| ep_len_mean        | 99.5         |
| ep_reward_mean     | -2.41        |
| explained_variance | 0.517        |
| fps                | 2084         |
| n_updates          | 28           |
| policy_entropy     | 8.242947     |
| policy_loss        | -0.010012061 |
| serial_timesteps   | 7168         |
| time_elapsed       | 29           |
| total_timesteps    | 57344        |
| value_loss         | 0.10465918   |
-------------------------------------
-------------------------------------
| approxkl           | 0.006295924  |
| clipfrac           | 0.07910156   |
| ep_len_mean        | 99.1         |
| ep_reward_mean     | -2.39        |
| explained_variance | 0.569        |
| fps                | 2079         |
| n_updates          | 29           |
| policy_entropy     | 8.221241     |
| policy_loss        | -0.010010616 |
| serial_timesteps   | 7424         |
| time_elapsed       | 29.9         |
| total_timesteps    | 59392        |
| value_loss         | 0.09398695   |
-------------------------------------
Eval num_timesteps=60000, episode_reward=-0.72 +/- 0.01
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.008504318  |
| clipfrac           | 0.11782227   |
| ep_len_mean        | 99.1         |
| ep_reward_mean     | -2.38        |
| explained_variance | 0.513        |
| fps                | 1411         |
| n_updates          | 30           |
| policy_entropy     | 8.19314      |
| policy_loss        | -0.012202855 |
| serial_timesteps   | 7680         |
| time_elapsed       | 30.9         |
| total_timesteps    | 61440        |
| value_loss         | 0.095109984  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008320837  |
| clipfrac           | 0.11538086   |
| ep_len_mean        | 99.1         |
| ep_reward_mean     | -2.43        |
| explained_variance | 0.57         |
| fps                | 1996         |
| n_updates          | 31           |
| policy_entropy     | 8.191816     |
| policy_loss        | -0.013387777 |
| serial_timesteps   | 7936         |
| time_elapsed       | 32.4         |
| total_timesteps    | 63488        |
| value_loss         | 0.06808071   |
-------------------------------------
-------------------------------------
| approxkl           | 0.005601499  |
| clipfrac           | 0.068164065  |
| ep_len_mean        | 99.5         |
| ep_reward_mean     | -2.45        |
| explained_variance | 0.598        |
| fps                | 2080         |
| n_updates          | 32           |
| policy_entropy     | 8.19552      |
| policy_loss        | -0.009739159 |
| serial_timesteps   | 8192         |
| time_elapsed       | 33.4         |
| total_timesteps    | 65536        |
| value_loss         | 0.0771877    |
-------------------------------------
-------------------------------------
| approxkl           | 0.009085709  |
| clipfrac           | 0.13349609   |
| ep_len_mean        | 99.5         |
| ep_reward_mean     | -2.4         |
| explained_variance | 0.609        |
| fps                | 2077         |
| n_updates          | 33           |
| policy_entropy     | 8.200163     |
| policy_loss        | -0.014098669 |
| serial_timesteps   | 8448         |
| time_elapsed       | 34.4         |
| total_timesteps    | 67584        |
| value_loss         | 0.059478812  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0060970252  |
| clipfrac           | 0.070898436   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -2.48         |
| explained_variance | 0.321         |
| fps                | 2055          |
| n_updates          | 34            |
| policy_entropy     | 8.181339      |
| policy_loss        | -0.0072935447 |
| serial_timesteps   | 8704          |
| time_elapsed       | 35.4          |
| total_timesteps    | 69632         |
| value_loss         | 0.12463504    |
--------------------------------------
Eval num_timesteps=70000, episode_reward=-1.68 +/- 0.55
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008193686  |
| clipfrac           | 0.11625977   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.48        |
| explained_variance | 0.483        |
| fps                | 1488         |
| n_updates          | 35           |
| policy_entropy     | 8.148207     |
| policy_loss        | -0.011852704 |
| serial_timesteps   | 8960         |
| time_elapsed       | 36.4         |
| total_timesteps    | 71680        |
| value_loss         | 0.07885827   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0063020005 |
| clipfrac           | 0.08085938   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.47        |
| explained_variance | 0.507        |
| fps                | 1980         |
| n_updates          | 36           |
| policy_entropy     | 8.138041     |
| policy_loss        | -0.00893762  |
| serial_timesteps   | 9216         |
| time_elapsed       | 37.8         |
| total_timesteps    | 73728        |
| value_loss         | 0.08565091   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0083077755 |
| clipfrac           | 0.11035156   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.42        |
| explained_variance | 0.704        |
| fps                | 2061         |
| n_updates          | 37           |
| policy_entropy     | 8.126307     |
| policy_loss        | -0.010891935 |
| serial_timesteps   | 9472         |
| time_elapsed       | 38.8         |
| total_timesteps    | 75776        |
| value_loss         | 0.047609385  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0074914396 |
| clipfrac           | 0.10131836   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.5         |
| explained_variance | 0.482        |
| fps                | 2096         |
| n_updates          | 38           |
| policy_entropy     | 8.09508      |
| policy_loss        | -0.012213453 |
| serial_timesteps   | 9728         |
| time_elapsed       | 39.8         |
| total_timesteps    | 77824        |
| value_loss         | 0.07612635   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00891119   |
| clipfrac           | 0.12763672   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.4         |
| explained_variance | 0.669        |
| fps                | 2100         |
| n_updates          | 39           |
| policy_entropy     | 8.067573     |
| policy_loss        | -0.013781227 |
| serial_timesteps   | 9984         |
| time_elapsed       | 40.8         |
| total_timesteps    | 79872        |
| value_loss         | 0.06759999   |
-------------------------------------
Eval num_timesteps=80000, episode_reward=-1.24 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0074545615 |
| clipfrac           | 0.10058594   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.43        |
| explained_variance | 0.596        |
| fps                | 1463         |
| n_updates          | 40           |
| policy_entropy     | 8.023191     |
| policy_loss        | -0.011280782 |
| serial_timesteps   | 10240        |
| time_elapsed       | 41.7         |
| total_timesteps    | 81920        |
| value_loss         | 0.0944259    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008230962  |
| clipfrac           | 0.11328125   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.39        |
| explained_variance | 0.693        |
| fps                | 1996         |
| n_updates          | 41           |
| policy_entropy     | 7.9852486    |
| policy_loss        | -0.012787344 |
| serial_timesteps   | 10496        |
| time_elapsed       | 43.1         |
| total_timesteps    | 83968        |
| value_loss         | 0.045381866  |
-------------------------------------
-------------------------------------
| approxkl           | 0.006843161  |
| clipfrac           | 0.0890625    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.28        |
| explained_variance | 0.686        |
| fps                | 2099         |
| n_updates          | 42           |
| policy_entropy     | 7.9856644    |
| policy_loss        | -0.008380027 |
| serial_timesteps   | 10752        |
| time_elapsed       | 44.2         |
| total_timesteps    | 86016        |
| value_loss         | 0.044663858  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00773541   |
| clipfrac           | 0.10263672   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.2         |
| explained_variance | 0.664        |
| fps                | 2100         |
| n_updates          | 43           |
| policy_entropy     | 7.989534     |
| policy_loss        | -0.012873632 |
| serial_timesteps   | 11008        |
| time_elapsed       | 45.1         |
| total_timesteps    | 88064        |
| value_loss         | 0.05279786   |
-------------------------------------
Eval num_timesteps=90000, episode_reward=-1.35 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008197921  |
| clipfrac           | 0.10957031   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.16        |
| explained_variance | 0.523        |
| fps                | 1441         |
| n_updates          | 44           |
| policy_entropy     | 7.9862885    |
| policy_loss        | -0.012667348 |
| serial_timesteps   | 11264        |
| time_elapsed       | 46.1         |
| total_timesteps    | 90112        |
| value_loss         | 0.06287067   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0068647237 |
| clipfrac           | 0.08886719   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.93        |
| explained_variance | 0.541        |
| fps                | 2051         |
| n_updates          | 45           |
| policy_entropy     | 7.981917     |
| policy_loss        | -0.006721108 |
| serial_timesteps   | 11520        |
| time_elapsed       | 47.5         |
| total_timesteps    | 92160        |
| value_loss         | 0.048404016  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0068593198  |
| clipfrac           | 0.08525391    |
| ep_len_mean        | 99.6          |
| ep_reward_mean     | -1.89         |
| explained_variance | 0.488         |
| fps                | 2072          |
| n_updates          | 46            |
| policy_entropy     | 7.9601107     |
| policy_loss        | -0.0067865485 |
| serial_timesteps   | 11776         |
| time_elapsed       | 48.5          |
| total_timesteps    | 94208         |
| value_loss         | 0.04452004    |
--------------------------------------
-------------------------------------
| approxkl           | 0.00773074   |
| clipfrac           | 0.107421875  |
| ep_len_mean        | 98.5         |
| ep_reward_mean     | -1.84        |
| explained_variance | 0.651        |
| fps                | 2036         |
| n_updates          | 47           |
| policy_entropy     | 7.916429     |
| policy_loss        | -0.011204387 |
| serial_timesteps   | 12032        |
| time_elapsed       | 49.5         |
| total_timesteps    | 96256        |
| value_loss         | 0.03421738   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0063281194 |
| clipfrac           | 0.07851563   |
| ep_len_mean        | 98.5         |
| ep_reward_mean     | -1.8         |
| explained_variance | 0.583        |
| fps                | 2087         |
| n_updates          | 48           |
| policy_entropy     | 7.912305     |
| policy_loss        | -0.008469821 |
| serial_timesteps   | 12288        |
| time_elapsed       | 50.5         |
| total_timesteps    | 98304        |
| value_loss         | 0.035935167  |
-------------------------------------
Eval num_timesteps=100000, episode_reward=-1.22 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.006699315  |
| clipfrac           | 0.086035155  |
| ep_len_mean        | 98.1         |
| ep_reward_mean     | -1.76        |
| explained_variance | 0.54         |
| fps                | 1415         |
| n_updates          | 49           |
| policy_entropy     | 7.921466     |
| policy_loss        | -0.008363546 |
| serial_timesteps   | 12544        |
| time_elapsed       | 51.5         |
| total_timesteps    | 100352       |
| value_loss         | 0.04924932   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0072583696 |
| clipfrac           | 0.09257813   |
| ep_len_mean        | 97.8         |
| ep_reward_mean     | -1.79        |
| explained_variance | 0.595        |
| fps                | 2091         |
| n_updates          | 50           |
| policy_entropy     | 7.900608     |
| policy_loss        | -0.007108117 |
| serial_timesteps   | 12800        |
| time_elapsed       | 53           |
| total_timesteps    | 102400       |
| value_loss         | 0.046684403  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0074398764 |
| clipfrac           | 0.092041016  |
| ep_len_mean        | 97.8         |
| ep_reward_mean     | -1.81        |
| explained_variance | 0.514        |
| fps                | 2073         |
| n_updates          | 51           |
| policy_entropy     | 7.8789635    |
| policy_loss        | -0.009220208 |
| serial_timesteps   | 13056        |
| time_elapsed       | 53.9         |
| total_timesteps    | 104448       |
| value_loss         | 0.056235693  |
-------------------------------------
--------------------------------------
| approxkl           | 0.00688831    |
| clipfrac           | 0.08598633    |
| ep_len_mean        | 98.9          |
| ep_reward_mean     | -1.93         |
| explained_variance | 0.539         |
| fps                | 2079          |
| n_updates          | 52            |
| policy_entropy     | 7.8648124     |
| policy_loss        | -0.0089976685 |
| serial_timesteps   | 13312         |
| time_elapsed       | 54.9          |
| total_timesteps    | 106496        |
| value_loss         | 0.059401847   |
--------------------------------------
-------------------------------------
| approxkl           | 0.007478658  |
| clipfrac           | 0.09741211   |
| ep_len_mean        | 98.9         |
| ep_reward_mean     | -1.98        |
| explained_variance | 0.583        |
| fps                | 2041         |
| n_updates          | 53           |
| policy_entropy     | 7.863725     |
| policy_loss        | -0.009502231 |
| serial_timesteps   | 13568        |
| time_elapsed       | 55.9         |
| total_timesteps    | 108544       |
| value_loss         | 0.06263622   |
-------------------------------------
Eval num_timesteps=110000, episode_reward=-1.19 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007872226  |
| clipfrac           | 0.10151367   |
| ep_len_mean        | 98.8         |
| ep_reward_mean     | -2.13        |
| explained_variance | 0.392        |
| fps                | 1472         |
| n_updates          | 54           |
| policy_entropy     | 7.8643723    |
| policy_loss        | -0.009955387 |
| serial_timesteps   | 13824        |
| time_elapsed       | 56.9         |
| total_timesteps    | 110592       |
| value_loss         | 0.103293076  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0073374226 |
| clipfrac           | 0.095654294  |
| ep_len_mean        | 99.4         |
| ep_reward_mean     | -2.15        |
| explained_variance | 0.476        |
| fps                | 2024         |
| n_updates          | 55           |
| policy_entropy     | 7.848152     |
| policy_loss        | -0.008582826 |
| serial_timesteps   | 14080        |
| time_elapsed       | 58.3         |
| total_timesteps    | 112640       |
| value_loss         | 0.08222472   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007613805  |
| clipfrac           | 0.103759766  |
| ep_len_mean        | 98.9         |
| ep_reward_mean     | -2.14        |
| explained_variance | 0.636        |
| fps                | 2103         |
| n_updates          | 56           |
| policy_entropy     | 7.836335     |
| policy_loss        | -0.009570032 |
| serial_timesteps   | 14336        |
| time_elapsed       | 59.3         |
| total_timesteps    | 114688       |
| value_loss         | 0.05344252   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0061932206 |
| clipfrac           | 0.075732425  |
| ep_len_mean        | 98.9         |
| ep_reward_mean     | -1.98        |
| explained_variance | 0.611        |
| fps                | 2124         |
| n_updates          | 57           |
| policy_entropy     | 7.843045     |
| policy_loss        | -0.008730499 |
| serial_timesteps   | 14592        |
| time_elapsed       | 60.3         |
| total_timesteps    | 116736       |
| value_loss         | 0.039617423  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008746734  |
| clipfrac           | 0.11860351   |
| ep_len_mean        | 97.7         |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.505        |
| fps                | 2021         |
| n_updates          | 58           |
| policy_entropy     | 7.8797507    |
| policy_loss        | -0.010163793 |
| serial_timesteps   | 14848        |
| time_elapsed       | 61.3         |
| total_timesteps    | 118784       |
| value_loss         | 0.04979998   |
-------------------------------------
Eval num_timesteps=120000, episode_reward=-0.58 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.0065600625 |
| clipfrac           | 0.080322266  |
| ep_len_mean        | 98.3         |
| ep_reward_mean     | -1.84        |
| explained_variance | 0.524        |
| fps                | 1467         |
| n_updates          | 59           |
| policy_entropy     | 7.91799      |
| policy_loss        | -0.008227307 |
| serial_timesteps   | 15104        |
| time_elapsed       | 62.3         |
| total_timesteps    | 120832       |
| value_loss         | 0.0515183    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0070174537 |
| clipfrac           | 0.08798828   |
| ep_len_mean        | 98.3         |
| ep_reward_mean     | -1.76        |
| explained_variance | 0.617        |
| fps                | 2104         |
| n_updates          | 60           |
| policy_entropy     | 7.9351716    |
| policy_loss        | -0.007195398 |
| serial_timesteps   | 15360        |
| time_elapsed       | 63.7         |
| total_timesteps    | 122880       |
| value_loss         | 0.04430117   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0060999123 |
| clipfrac           | 0.06982422   |
| ep_len_mean        | 98.8         |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.67         |
| fps                | 2165         |
| n_updates          | 61           |
| policy_entropy     | 7.931268     |
| policy_loss        | -0.005430954 |
| serial_timesteps   | 15616        |
| time_elapsed       | 64.6         |
| total_timesteps    | 124928       |
| value_loss         | 0.041631762  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0076681217 |
| clipfrac           | 0.101220705  |
| ep_len_mean        | 98.8         |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.689        |
| fps                | 2121         |
| n_updates          | 62           |
| policy_entropy     | 7.906198     |
| policy_loss        | -0.008637962 |
| serial_timesteps   | 15872        |
| time_elapsed       | 65.6         |
| total_timesteps    | 126976       |
| value_loss         | 0.037055537  |
-------------------------------------
-------------------------------------
| approxkl           | 0.005637832  |
| clipfrac           | 0.067871094  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.84        |
| explained_variance | 0.762        |
| fps                | 2108         |
| n_updates          | 63           |
| policy_entropy     | 7.8910813    |
| policy_loss        | -0.007409077 |
| serial_timesteps   | 16128        |
| time_elapsed       | 66.5         |
| total_timesteps    | 129024       |
| value_loss         | 0.032223605  |
-------------------------------------
Eval num_timesteps=130000, episode_reward=-0.60 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.00659415   |
| clipfrac           | 0.08334961   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.552        |
| fps                | 1465         |
| n_updates          | 64           |
| policy_entropy     | 7.8858957    |
| policy_loss        | -0.007605421 |
| serial_timesteps   | 16384        |
| time_elapsed       | 67.5         |
| total_timesteps    | 131072       |
| value_loss         | 0.055464596  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007073731  |
| clipfrac           | 0.0921875    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.715        |
| fps                | 2111         |
| n_updates          | 65           |
| policy_entropy     | 7.8754263    |
| policy_loss        | -0.008217324 |
| serial_timesteps   | 16640        |
| time_elapsed       | 68.9         |
| total_timesteps    | 133120       |
| value_loss         | 0.03903138   |
-------------------------------------
--------------------------------------
| approxkl           | 0.009023974   |
| clipfrac           | 0.11948242    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.87         |
| explained_variance | 0.544         |
| fps                | 2091          |
| n_updates          | 66            |
| policy_entropy     | 7.8841047     |
| policy_loss        | -0.0109166745 |
| serial_timesteps   | 16896         |
| time_elapsed       | 69.9          |
| total_timesteps    | 135168        |
| value_loss         | 0.051934846   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008088194  |
| clipfrac           | 0.10615234   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.709        |
| fps                | 2045         |
| n_updates          | 67           |
| policy_entropy     | 7.8716636    |
| policy_loss        | -0.008213563 |
| serial_timesteps   | 17152        |
| time_elapsed       | 70.9         |
| total_timesteps    | 137216       |
| value_loss         | 0.03211068   |
-------------------------------------
--------------------------------------
| approxkl           | 0.005589052   |
| clipfrac           | 0.061767578   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.9          |
| explained_variance | 0.754         |
| fps                | 2079          |
| n_updates          | 68            |
| policy_entropy     | 7.8712845     |
| policy_loss        | -0.0038734593 |
| serial_timesteps   | 17408         |
| time_elapsed       | 71.9          |
| total_timesteps    | 139264        |
| value_loss         | 0.028212842   |
--------------------------------------
Eval num_timesteps=140000, episode_reward=-0.46 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
------------------------------------
| approxkl           | 0.007555214 |
| clipfrac           | 0.09804688  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.82       |
| explained_variance | 0.782       |
| fps                | 1474        |
| n_updates          | 69          |
| policy_entropy     | 7.873842    |
| policy_loss        | -0.0081785  |
| serial_timesteps   | 17664       |
| time_elapsed       | 72.9        |
| total_timesteps    | 141312      |
| value_loss         | 0.029068265 |
------------------------------------
--------------------------------------
| approxkl           | 0.005540463   |
| clipfrac           | 0.058447264   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.79         |
| explained_variance | 0.756         |
| fps                | 2042          |
| n_updates          | 70            |
| policy_entropy     | 7.8453627     |
| policy_loss        | -0.0024268457 |
| serial_timesteps   | 17920         |
| time_elapsed       | 74.2          |
| total_timesteps    | 143360        |
| value_loss         | 0.035022985   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008392355  |
| clipfrac           | 0.112939455  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.74        |
| explained_variance | 0.74         |
| fps                | 2100         |
| n_updates          | 71           |
| policy_entropy     | 7.8178344    |
| policy_loss        | -0.009719271 |
| serial_timesteps   | 18176        |
| time_elapsed       | 75.2         |
| total_timesteps    | 145408       |
| value_loss         | 0.035222314  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0073578544  |
| clipfrac           | 0.099414065   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.78         |
| explained_variance | 0.732         |
| fps                | 2121          |
| n_updates          | 72            |
| policy_entropy     | 7.8070693     |
| policy_loss        | -0.0076109334 |
| serial_timesteps   | 18432         |
| time_elapsed       | 76.2          |
| total_timesteps    | 147456        |
| value_loss         | 0.036226477   |
--------------------------------------
--------------------------------------
| approxkl           | 0.005753859   |
| clipfrac           | 0.06679688    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.77         |
| explained_variance | 0.613         |
| fps                | 2110          |
| n_updates          | 73            |
| policy_entropy     | 7.816227      |
| policy_loss        | -0.0059971213 |
| serial_timesteps   | 18688         |
| time_elapsed       | 77.2          |
| total_timesteps    | 149504        |
| value_loss         | 0.040027786   |
--------------------------------------
Eval num_timesteps=150000, episode_reward=-0.46 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.0064211315 |
| clipfrac           | 0.07631836   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.76        |
| explained_variance | 0.695        |
| fps                | 1487         |
| n_updates          | 74           |
| policy_entropy     | 7.8272047    |
| policy_loss        | -0.003735094 |
| serial_timesteps   | 18944        |
| time_elapsed       | 78.2         |
| total_timesteps    | 151552       |
| value_loss         | 0.0358964    |
-------------------------------------
-------------------------------------
| approxkl           | 0.006732778  |
| clipfrac           | 0.08496094   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.82        |
| explained_variance | 0.632        |
| fps                | 2125         |
| n_updates          | 75           |
| policy_entropy     | 7.8455553    |
| policy_loss        | -0.007492467 |
| serial_timesteps   | 19200        |
| time_elapsed       | 79.5         |
| total_timesteps    | 153600       |
| value_loss         | 0.050039984  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0073647583 |
| clipfrac           | 0.0972168    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.78        |
| explained_variance | 0.748        |
| fps                | 2140         |
| n_updates          | 76           |
| policy_entropy     | 7.84501      |
| policy_loss        | -0.008342155 |
| serial_timesteps   | 19456        |
| time_elapsed       | 80.5         |
| total_timesteps    | 155648       |
| value_loss         | 0.03245721   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0062183933 |
| clipfrac           | 0.07646485   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.84        |
| explained_variance | 0.677        |
| fps                | 2108         |
| n_updates          | 77           |
| policy_entropy     | 7.817244     |
| policy_loss        | -0.007026513 |
| serial_timesteps   | 19712        |
| time_elapsed       | 81.5         |
| total_timesteps    | 157696       |
| value_loss         | 0.045168377  |
-------------------------------------
--------------------------------------
| approxkl           | 0.006234931   |
| clipfrac           | 0.078271486   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.84         |
| explained_variance | 0.717         |
| fps                | 2122          |
| n_updates          | 78            |
| policy_entropy     | 7.7935333     |
| policy_loss        | -0.0058975797 |
| serial_timesteps   | 19968         |
| time_elapsed       | 82.4          |
| total_timesteps    | 159744        |
| value_loss         | 0.031212246   |
--------------------------------------
Eval num_timesteps=160000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0076265847 |
| clipfrac           | 0.103466794  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.764        |
| fps                | 1481         |
| n_updates          | 79           |
| policy_entropy     | 7.762007     |
| policy_loss        | -0.008195674 |
| serial_timesteps   | 20224        |
| time_elapsed       | 83.4         |
| total_timesteps    | 161792       |
| value_loss         | 0.03327814   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0062770895 |
| clipfrac           | 0.0765625    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.79        |
| explained_variance | 0.712        |
| fps                | 2121         |
| n_updates          | 80           |
| policy_entropy     | 7.7329774    |
| policy_loss        | -0.003931282 |
| serial_timesteps   | 20480        |
| time_elapsed       | 84.8         |
| total_timesteps    | 163840       |
| value_loss         | 0.04085835   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0075804284 |
| clipfrac           | 0.09848633   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.81        |
| explained_variance | 0.755        |
| fps                | 2144         |
| n_updates          | 81           |
| policy_entropy     | 7.7169085    |
| policy_loss        | -0.006400162 |
| serial_timesteps   | 20736        |
| time_elapsed       | 85.7         |
| total_timesteps    | 165888       |
| value_loss         | 0.037119605  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008492033   |
| clipfrac           | 0.118701175   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.76         |
| explained_variance | 0.642         |
| fps                | 2117          |
| n_updates          | 82            |
| policy_entropy     | 7.7124047     |
| policy_loss        | -0.0076820604 |
| serial_timesteps   | 20992         |
| time_elapsed       | 86.7          |
| total_timesteps    | 167936        |
| value_loss         | 0.050058343   |
--------------------------------------
--------------------------------------
| approxkl           | 0.007189691   |
| clipfrac           | 0.09091797    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.83         |
| explained_variance | 0.637         |
| fps                | 2136          |
| n_updates          | 83            |
| policy_entropy     | 7.7082915     |
| policy_loss        | -0.0058862576 |
| serial_timesteps   | 21248         |
| time_elapsed       | 87.7          |
| total_timesteps    | 169984        |
| value_loss         | 0.04756607    |
--------------------------------------
Eval num_timesteps=170000, episode_reward=-0.46 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.006923084   |
| clipfrac           | 0.088574216   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.88         |
| explained_variance | 0.636         |
| fps                | 1494          |
| n_updates          | 84            |
| policy_entropy     | 7.6871595     |
| policy_loss        | -0.0063491426 |
| serial_timesteps   | 21504         |
| time_elapsed       | 88.6          |
| total_timesteps    | 172032        |
| value_loss         | 0.0549965     |
--------------------------------------
-------------------------------------
| approxkl           | 0.006842611  |
| clipfrac           | 0.08413086   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.658        |
| fps                | 2141         |
| n_updates          | 85           |
| policy_entropy     | 7.6477647    |
| policy_loss        | -0.009022624 |
| serial_timesteps   | 21760        |
| time_elapsed       | 90           |
| total_timesteps    | 174080       |
| value_loss         | 0.044068176  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0066786185 |
| clipfrac           | 0.08139648   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.638        |
| fps                | 2159         |
| n_updates          | 86           |
| policy_entropy     | 7.6191635    |
| policy_loss        | -0.006708555 |
| serial_timesteps   | 22016        |
| time_elapsed       | 90.9         |
| total_timesteps    | 176128       |
| value_loss         | 0.056043647  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0071403407 |
| clipfrac           | 0.08588867   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.655        |
| fps                | 2126         |
| n_updates          | 87           |
| policy_entropy     | 7.602214     |
| policy_loss        | -0.008201915 |
| serial_timesteps   | 22272        |
| time_elapsed       | 91.9         |
| total_timesteps    | 178176       |
| value_loss         | 0.050629895  |
-------------------------------------
Eval num_timesteps=180000, episode_reward=-0.43 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.008326698  |
| clipfrac           | 0.115234375  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.84        |
| explained_variance | 0.705        |
| fps                | 1483         |
| n_updates          | 88           |
| policy_entropy     | 7.5748267    |
| policy_loss        | -0.010429621 |
| serial_timesteps   | 22528        |
| time_elapsed       | 92.9         |
| total_timesteps    | 180224       |
| value_loss         | 0.042193335  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008206301  |
| clipfrac           | 0.111816406  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.82        |
| explained_variance | 0.684        |
| fps                | 2136         |
| n_updates          | 89           |
| policy_entropy     | 7.5533156    |
| policy_loss        | -0.008300815 |
| serial_timesteps   | 22784        |
| time_elapsed       | 94.2         |
| total_timesteps    | 182272       |
| value_loss         | 0.046729203  |
-------------------------------------
--------------------------------------
| approxkl           | 0.006892328   |
| clipfrac           | 0.08852539    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.83         |
| explained_variance | 0.695         |
| fps                | 2104          |
| n_updates          | 90            |
| policy_entropy     | 7.532244      |
| policy_loss        | -0.0068292255 |
| serial_timesteps   | 23040         |
| time_elapsed       | 95.2          |
| total_timesteps    | 184320        |
| value_loss         | 0.04535409    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0079854075 |
| clipfrac           | 0.10546875   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.81        |
| explained_variance | 0.694        |
| fps                | 2114         |
| n_updates          | 91           |
| policy_entropy     | 7.5146093    |
| policy_loss        | -0.011081833 |
| serial_timesteps   | 23296        |
| time_elapsed       | 96.2         |
| total_timesteps    | 186368       |
| value_loss         | 0.047106694  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008140307  |
| clipfrac           | 0.111328125  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.79        |
| explained_variance | 0.697        |
| fps                | 2150         |
| n_updates          | 92           |
| policy_entropy     | 7.5053864    |
| policy_loss        | -0.009103393 |
| serial_timesteps   | 23552        |
| time_elapsed       | 97.1         |
| total_timesteps    | 188416       |
| value_loss         | 0.046812564  |
-------------------------------------
Eval num_timesteps=190000, episode_reward=-0.44 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007974795  |
| clipfrac           | 0.10683594   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.84        |
| explained_variance | 0.708        |
| fps                | 1503         |
| n_updates          | 93           |
| policy_entropy     | 7.5080667    |
| policy_loss        | -0.009866128 |
| serial_timesteps   | 23808        |
| time_elapsed       | 98.1         |
| total_timesteps    | 190464       |
| value_loss         | 0.051523633  |
-------------------------------------
------------------------------------
| approxkl           | 0.008134208 |
| clipfrac           | 0.10288086  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.84       |
| explained_variance | 0.607       |
| fps                | 2145        |
| n_updates          | 94          |
| policy_entropy     | 7.4845033   |
| policy_loss        | -0.01076219 |
| serial_timesteps   | 24064       |
| time_elapsed       | 99.5        |
| total_timesteps    | 192512      |
| value_loss         | 0.058231987 |
------------------------------------
--------------------------------------
| approxkl           | 0.008234812   |
| clipfrac           | 0.10527344    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.86         |
| explained_variance | 0.693         |
| fps                | 2141          |
| n_updates          | 95            |
| policy_entropy     | 7.4504776     |
| policy_loss        | -0.0073922337 |
| serial_timesteps   | 24320         |
| time_elapsed       | 100           |
| total_timesteps    | 194560        |
| value_loss         | 0.051153243   |
--------------------------------------
-------------------------------------
| approxkl           | 0.00710366   |
| clipfrac           | 0.091845706  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.664        |
| fps                | 2142         |
| n_updates          | 96           |
| policy_entropy     | 7.4493036    |
| policy_loss        | -0.006462174 |
| serial_timesteps   | 24576        |
| time_elapsed       | 101          |
| total_timesteps    | 196608       |
| value_loss         | 0.052705877  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007861485  |
| clipfrac           | 0.10415039   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.619        |
| fps                | 2112         |
| n_updates          | 97           |
| policy_entropy     | 7.4449997    |
| policy_loss        | -0.008863713 |
| serial_timesteps   | 24832        |
| time_elapsed       | 102          |
| total_timesteps    | 198656       |
| value_loss         | 0.056526482  |
-------------------------------------
Eval num_timesteps=200000, episode_reward=-0.43 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0065225014 |
| clipfrac           | 0.0803711    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.564        |
| fps                | 1468         |
| n_updates          | 98           |
| policy_entropy     | 7.426277     |
| policy_loss        | -0.006537578 |
| serial_timesteps   | 25088        |
| time_elapsed       | 103          |
| total_timesteps    | 200704       |
| value_loss         | 0.058232456  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009473329  |
| clipfrac           | 0.1347168    |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.608        |
| fps                | 2147         |
| n_updates          | 99           |
| policy_entropy     | 7.418123     |
| policy_loss        | -0.009452717 |
| serial_timesteps   | 25344        |
| time_elapsed       | 105          |
| total_timesteps    | 202752       |
| value_loss         | 0.059729714  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0072517926 |
| clipfrac           | 0.08681641   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.541        |
| fps                | 2105         |
| n_updates          | 100          |
| policy_entropy     | 7.4082384    |
| policy_loss        | -0.008132573 |
| serial_timesteps   | 25600        |
| time_elapsed       | 106          |
| total_timesteps    | 204800       |
| value_loss         | 0.065473944  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0060395235 |
| clipfrac           | 0.06865235   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.664        |
| fps                | 2120         |
| n_updates          | 101          |
| policy_entropy     | 7.3936167    |
| policy_loss        | -0.003373466 |
| serial_timesteps   | 25856        |
| time_elapsed       | 107          |
| total_timesteps    | 206848       |
| value_loss         | 0.052056897  |
-------------------------------------
-------------------------------------
| approxkl           | 0.006380312  |
| clipfrac           | 0.07832031   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.703        |
| fps                | 2142         |
| n_updates          | 102          |
| policy_entropy     | 7.382922     |
| policy_loss        | -0.005306407 |
| serial_timesteps   | 26112        |
| time_elapsed       | 108          |
| total_timesteps    | 208896       |
| value_loss         | 0.053245522  |
-------------------------------------
Eval num_timesteps=210000, episode_reward=-0.43 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.008329837  |
| clipfrac           | 0.11147461   |
| ep_len_mean        | 98.6         |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.615        |
| fps                | 1483         |
| n_updates          | 103          |
| policy_entropy     | 7.383409     |
| policy_loss        | -0.009004207 |
| serial_timesteps   | 26368        |
| time_elapsed       | 109          |
| total_timesteps    | 210944       |
| value_loss         | 0.059143562  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009252474  |
| clipfrac           | 0.13266602   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.715        |
| fps                | 2155         |
| n_updates          | 104          |
| policy_entropy     | 7.3927603    |
| policy_loss        | -0.012091271 |
| serial_timesteps   | 26624        |
| time_elapsed       | 110          |
| total_timesteps    | 212992       |
| value_loss         | 0.04738494   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008018542  |
| clipfrac           | 0.10986328   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.92        |
| explained_variance | 0.498        |
| fps                | 2131         |
| n_updates          | 105          |
| policy_entropy     | 7.400611     |
| policy_loss        | -0.012244655 |
| serial_timesteps   | 26880        |
| time_elapsed       | 111          |
| total_timesteps    | 215040       |
| value_loss         | 0.08826287   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010415442  |
| clipfrac           | 0.14282227   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -2.05        |
| explained_variance | 0.503        |
| fps                | 2074         |
| n_updates          | 106          |
| policy_entropy     | 7.3869524    |
| policy_loss        | -0.012645644 |
| serial_timesteps   | 27136        |
| time_elapsed       | 112          |
| total_timesteps    | 217088       |
| value_loss         | 0.0734817    |
-------------------------------------
------------------------------------
| approxkl           | 0.007903414 |
| clipfrac           | 0.10888672  |
| ep_len_mean        | 98.6        |
| ep_reward_mean     | -1.96       |
| explained_variance | 0.511       |
| fps                | 2135        |
| n_updates          | 107         |
| policy_entropy     | 7.378493    |
| policy_loss        | -0.00659136 |
| serial_timesteps   | 27392       |
| time_elapsed       | 113         |
| total_timesteps    | 219136      |
| value_loss         | 0.08135218  |
------------------------------------
Eval num_timesteps=220000, episode_reward=-0.43 +/- 0.00
Episode length: 100.00 +/- 0.00
New best mean reward!
-------------------------------------
| approxkl           | 0.007395909  |
| clipfrac           | 0.09658203   |
| ep_len_mean        | 98.6         |
| ep_reward_mean     | -2.07        |
| explained_variance | 0.475        |
| fps                | 1486         |
| n_updates          | 108          |
| policy_entropy     | 7.370555     |
| policy_loss        | -0.008174324 |
| serial_timesteps   | 27648        |
| time_elapsed       | 114          |
| total_timesteps    | 221184       |
| value_loss         | 0.07971345   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008597185  |
| clipfrac           | 0.12011719   |
| ep_len_mean        | 97.9         |
| ep_reward_mean     | -2.12        |
| explained_variance | 0.52         |
| fps                | 2092         |
| n_updates          | 109          |
| policy_entropy     | 7.363379     |
| policy_loss        | -0.010384618 |
| serial_timesteps   | 27904        |
| time_elapsed       | 115          |
| total_timesteps    | 223232       |
| value_loss         | 0.0900697    |
-------------------------------------
--------------------------------------
| approxkl           | 0.008364065   |
| clipfrac           | 0.111816406   |
| ep_len_mean        | 97.3          |
| ep_reward_mean     | -1.96         |
| explained_variance | 0.626         |
| fps                | 2108          |
| n_updates          | 110           |
| policy_entropy     | 7.349453      |
| policy_loss        | -0.0105407545 |
| serial_timesteps   | 28160         |
| time_elapsed       | 116           |
| total_timesteps    | 225280        |
| value_loss         | 0.05385878    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0067763864 |
| clipfrac           | 0.08735351   |
| ep_len_mean        | 96.7         |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.62         |
| fps                | 2138         |
| n_updates          | 111          |
| policy_entropy     | 7.3508368    |
| policy_loss        | -0.005688035 |
| serial_timesteps   | 28416        |
| time_elapsed       | 117          |
| total_timesteps    | 227328       |
| value_loss         | 0.057091974  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007025459  |
| clipfrac           | 0.086035155  |
| ep_len_mean        | 97.5         |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.629        |
| fps                | 2022         |
| n_updates          | 112          |
| policy_entropy     | 7.3333116    |
| policy_loss        | -0.006680321 |
| serial_timesteps   | 28672        |
| time_elapsed       | 118          |
| total_timesteps    | 229376       |
| value_loss         | 0.056406915  |
-------------------------------------
Eval num_timesteps=230000, episode_reward=-0.43 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0069634756 |
| clipfrac           | 0.08725586   |
| ep_len_mean        | 97.4         |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.625        |
| fps                | 1487         |
| n_updates          | 113          |
| policy_entropy     | 7.308217     |
| policy_loss        | -0.008183656 |
| serial_timesteps   | 28928        |
| time_elapsed       | 119          |
| total_timesteps    | 231424       |
| value_loss         | 0.06256302   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008074134  |
| clipfrac           | 0.105810545  |
| ep_len_mean        | 98.1         |
| ep_reward_mean     | -1.83        |
| explained_variance | 0.607        |
| fps                | 2031         |
| n_updates          | 114          |
| policy_entropy     | 7.3010263    |
| policy_loss        | -0.011484974 |
| serial_timesteps   | 29184        |
| time_elapsed       | 120          |
| total_timesteps    | 233472       |
| value_loss         | 0.049049024  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0089176735 |
| clipfrac           | 0.12387695   |
| ep_len_mean        | 98.3         |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.612        |
| fps                | 2123         |
| n_updates          | 115          |
| policy_entropy     | 7.2943015    |
| policy_loss        | -0.013747787 |
| serial_timesteps   | 29440        |
| time_elapsed       | 121          |
| total_timesteps    | 235520       |
| value_loss         | 0.0606605    |
-------------------------------------
--------------------------------------
| approxkl           | 0.008446379   |
| clipfrac           | 0.11381836    |
| ep_len_mean        | 98.8          |
| ep_reward_mean     | -1.92         |
| explained_variance | 0.358         |
| fps                | 2090          |
| n_updates          | 116           |
| policy_entropy     | 7.285456      |
| policy_loss        | -0.0095660435 |
| serial_timesteps   | 29696         |
| time_elapsed       | 122           |
| total_timesteps    | 237568        |
| value_loss         | 0.12078931    |
--------------------------------------
-------------------------------------
| approxkl           | 0.007057273  |
| clipfrac           | 0.087402344  |
| ep_len_mean        | 99.5         |
| ep_reward_mean     | -2.04        |
| explained_variance | 0.552        |
| fps                | 2082         |
| n_updates          | 117          |
| policy_entropy     | 7.267637     |
| policy_loss        | -0.009052713 |
| serial_timesteps   | 29952        |
| time_elapsed       | 123          |
| total_timesteps    | 239616       |
| value_loss         | 0.084456235  |
-------------------------------------
Eval num_timesteps=240000, episode_reward=-0.44 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009061056  |
| clipfrac           | 0.13212891   |
| ep_len_mean        | 99.5         |
| ep_reward_mean     | -1.99        |
| explained_variance | 0.653        |
| fps                | 1488         |
| n_updates          | 118          |
| policy_entropy     | 7.2564344    |
| policy_loss        | -0.011492332 |
| serial_timesteps   | 30208        |
| time_elapsed       | 124          |
| total_timesteps    | 241664       |
| value_loss         | 0.0504149    |
-------------------------------------
--------------------------------------
| approxkl           | 0.006860655   |
| clipfrac           | 0.08691406    |
| ep_len_mean        | 99.5          |
| ep_reward_mean     | -2.04         |
| explained_variance | 0.613         |
| fps                | 2149          |
| n_updates          | 119           |
| policy_entropy     | 7.2482033     |
| policy_loss        | -0.0064746737 |
| serial_timesteps   | 30464         |
| time_elapsed       | 126           |
| total_timesteps    | 243712        |
| value_loss         | 0.05945342    |
--------------------------------------
-------------------------------------
| approxkl           | 0.00818135   |
| clipfrac           | 0.10839844   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.08        |
| explained_variance | 0.531        |
| fps                | 2122         |
| n_updates          | 120          |
| policy_entropy     | 7.2232566    |
| policy_loss        | -0.008963573 |
| serial_timesteps   | 30720        |
| time_elapsed       | 127          |
| total_timesteps    | 245760       |
| value_loss         | 0.07668676   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008279331  |
| clipfrac           | 0.113867186  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.03        |
| explained_variance | 0.528        |
| fps                | 2093         |
| n_updates          | 121          |
| policy_entropy     | 7.2181497    |
| policy_loss        | -0.009560233 |
| serial_timesteps   | 30976        |
| time_elapsed       | 128          |
| total_timesteps    | 247808       |
| value_loss         | 0.07170523   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008381328  |
| clipfrac           | 0.111572266  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.04        |
| explained_variance | 0.645        |
| fps                | 2126         |
| n_updates          | 122          |
| policy_entropy     | 7.227136     |
| policy_loss        | -0.008162792 |
| serial_timesteps   | 31232        |
| time_elapsed       | 129          |
| total_timesteps    | 249856       |
| value_loss         | 0.06294222   |
-------------------------------------
Eval num_timesteps=250000, episode_reward=-0.45 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.006865293   |
| clipfrac           | 0.08139648    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -2.08         |
| explained_variance | 0.612         |
| fps                | 1503          |
| n_updates          | 123           |
| policy_entropy     | 7.197838      |
| policy_loss        | -0.0061147073 |
| serial_timesteps   | 31488         |
| time_elapsed       | 130           |
| total_timesteps    | 251904        |
| value_loss         | 0.05501578    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0064040413 |
| clipfrac           | 0.07749023   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.06        |
| explained_variance | 0.643        |
| fps                | 2090         |
| n_updates          | 124          |
| policy_entropy     | 7.164319     |
| policy_loss        | -0.004147161 |
| serial_timesteps   | 31744        |
| time_elapsed       | 131          |
| total_timesteps    | 253952       |
| value_loss         | 0.059505142  |
-------------------------------------
--------------------------------------
| approxkl           | 0.006167364   |
| clipfrac           | 0.07358398    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -2.02         |
| explained_variance | 0.681         |
| fps                | 2089          |
| n_updates          | 125           |
| policy_entropy     | 7.147555      |
| policy_loss        | -0.0029834248 |
| serial_timesteps   | 32000         |
| time_elapsed       | 132           |
| total_timesteps    | 256000        |
| value_loss         | 0.05815096    |
--------------------------------------
-------------------------------------
| approxkl           | 0.00750067   |
| clipfrac           | 0.10185547   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.97        |
| explained_variance | 0.662        |
| fps                | 2139         |
| n_updates          | 126          |
| policy_entropy     | 7.1260223    |
| policy_loss        | -0.006740626 |
| serial_timesteps   | 32256        |
| time_elapsed       | 133          |
| total_timesteps    | 258048       |
| value_loss         | 0.054680783  |
-------------------------------------
Eval num_timesteps=260000, episode_reward=-0.45 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.0085470565  |
| clipfrac           | 0.1184082     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.88         |
| explained_variance | 0.676         |
| fps                | 1510          |
| n_updates          | 127           |
| policy_entropy     | 7.13207       |
| policy_loss        | -0.0066261487 |
| serial_timesteps   | 32512         |
| time_elapsed       | 134           |
| total_timesteps    | 260096        |
| value_loss         | 0.056575853   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010082642  |
| clipfrac           | 0.1451172    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.633        |
| fps                | 2132         |
| n_updates          | 128          |
| policy_entropy     | 7.1191015    |
| policy_loss        | -0.014048668 |
| serial_timesteps   | 32768        |
| time_elapsed       | 135          |
| total_timesteps    | 262144       |
| value_loss         | 0.05713901   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008422049  |
| clipfrac           | 0.111572266  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.658        |
| fps                | 2090         |
| n_updates          | 129          |
| policy_entropy     | 7.0920877    |
| policy_loss        | -0.009123958 |
| serial_timesteps   | 33024        |
| time_elapsed       | 136          |
| total_timesteps    | 264192       |
| value_loss         | 0.060067184  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007493958  |
| clipfrac           | 0.09453125   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.97        |
| explained_variance | 0.591        |
| fps                | 2107         |
| n_updates          | 130          |
| policy_entropy     | 7.0867605    |
| policy_loss        | -0.008096357 |
| serial_timesteps   | 33280        |
| time_elapsed       | 137          |
| total_timesteps    | 266240       |
| value_loss         | 0.0661603    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0070435866  |
| clipfrac           | 0.08901367    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.94         |
| explained_variance | 0.608         |
| fps                | 2119          |
| n_updates          | 131           |
| policy_entropy     | 7.0859327     |
| policy_loss        | -0.0047852104 |
| serial_timesteps   | 33536         |
| time_elapsed       | 138           |
| total_timesteps    | 268288        |
| value_loss         | 0.06315546    |
--------------------------------------
Eval num_timesteps=270000, episode_reward=-0.46 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008906345  |
| clipfrac           | 0.123291016  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.01        |
| explained_variance | 0.564        |
| fps                | 1505         |
| n_updates          | 132          |
| policy_entropy     | 7.088249     |
| policy_loss        | -0.010418515 |
| serial_timesteps   | 33792        |
| time_elapsed       | 139          |
| total_timesteps    | 270336       |
| value_loss         | 0.07581334   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007630361  |
| clipfrac           | 0.10234375   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.04        |
| explained_variance | 0.559        |
| fps                | 2090         |
| n_updates          | 133          |
| policy_entropy     | 7.0662894    |
| policy_loss        | -0.008023663 |
| serial_timesteps   | 34048        |
| time_elapsed       | 141          |
| total_timesteps    | 272384       |
| value_loss         | 0.06313898   |
-------------------------------------
--------------------------------------
| approxkl           | 0.007602869   |
| clipfrac           | 0.09990235    |
| ep_len_mean        | 99.5          |
| ep_reward_mean     | -1.98         |
| explained_variance | 0.606         |
| fps                | 2125          |
| n_updates          | 134           |
| policy_entropy     | 7.035783      |
| policy_loss        | -0.0075501604 |
| serial_timesteps   | 34304         |
| time_elapsed       | 141           |
| total_timesteps    | 274432        |
| value_loss         | 0.06645335    |
--------------------------------------
-------------------------------------
| approxkl           | 0.008354095  |
| clipfrac           | 0.10644531   |
| ep_len_mean        | 99.5         |
| ep_reward_mean     | -1.97        |
| explained_variance | 0.598        |
| fps                | 2101         |
| n_updates          | 135          |
| policy_entropy     | 7.0102005    |
| policy_loss        | -0.009753587 |
| serial_timesteps   | 34560        |
| time_elapsed       | 142          |
| total_timesteps    | 276480       |
| value_loss         | 0.06405988   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0058425423  |
| clipfrac           | 0.06987305    |
| ep_len_mean        | 99.5          |
| ep_reward_mean     | -2            |
| explained_variance | 0.678         |
| fps                | 2076          |
| n_updates          | 136           |
| policy_entropy     | 7.0384398     |
| policy_loss        | -0.0066694357 |
| serial_timesteps   | 34816         |
| time_elapsed       | 143           |
| total_timesteps    | 278528        |
| value_loss         | 0.058937527   |
--------------------------------------
Eval num_timesteps=280000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008037628  |
| clipfrac           | 0.11005859   |
| ep_len_mean        | 99.5         |
| ep_reward_mean     | -2.03        |
| explained_variance | 0.666        |
| fps                | 1500         |
| n_updates          | 137          |
| policy_entropy     | 7.0760117    |
| policy_loss        | -0.008660989 |
| serial_timesteps   | 35072        |
| time_elapsed       | 144          |
| total_timesteps    | 280576       |
| value_loss         | 0.057661794  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00824753   |
| clipfrac           | 0.110644534  |
| ep_len_mean        | 99.5         |
| ep_reward_mean     | -2.02        |
| explained_variance | 0.541        |
| fps                | 2142         |
| n_updates          | 138          |
| policy_entropy     | 7.0748       |
| policy_loss        | -0.008673028 |
| serial_timesteps   | 35328        |
| time_elapsed       | 146          |
| total_timesteps    | 282624       |
| value_loss         | 0.083488636  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008601352  |
| clipfrac           | 0.12089844   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.07        |
| explained_variance | 0.647        |
| fps                | 2141         |
| n_updates          | 139          |
| policy_entropy     | 7.0683594    |
| policy_loss        | -0.009278001 |
| serial_timesteps   | 35584        |
| time_elapsed       | 147          |
| total_timesteps    | 284672       |
| value_loss         | 0.06269019   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008546834  |
| clipfrac           | 0.119824216  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.01        |
| explained_variance | 0.61         |
| fps                | 2069         |
| n_updates          | 140          |
| policy_entropy     | 7.074027     |
| policy_loss        | -0.010119707 |
| serial_timesteps   | 35840        |
| time_elapsed       | 148          |
| total_timesteps    | 286720       |
| value_loss         | 0.071770385  |
-------------------------------------
--------------------------------------
| approxkl           | 0.007935001   |
| clipfrac           | 0.10458984    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.99         |
| explained_variance | 0.717         |
| fps                | 2144          |
| n_updates          | 141           |
| policy_entropy     | 7.0794716     |
| policy_loss        | -0.0071899234 |
| serial_timesteps   | 36096         |
| time_elapsed       | 149           |
| total_timesteps    | 288768        |
| value_loss         | 0.048774727   |
--------------------------------------
Eval num_timesteps=290000, episode_reward=-0.49 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008745971  |
| clipfrac           | 0.11606445   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.07        |
| explained_variance | 0.574        |
| fps                | 1518         |
| n_updates          | 142          |
| policy_entropy     | 7.108979     |
| policy_loss        | -0.008697702 |
| serial_timesteps   | 36352        |
| time_elapsed       | 150          |
| total_timesteps    | 290816       |
| value_loss         | 0.076104954  |
-------------------------------------
--------------------------------------
| approxkl           | 0.0070682266  |
| clipfrac           | 0.091748044   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.96         |
| explained_variance | 0.7           |
| fps                | 2150          |
| n_updates          | 143           |
| policy_entropy     | 7.1138315     |
| policy_loss        | -0.0067668213 |
| serial_timesteps   | 36608         |
| time_elapsed       | 151           |
| total_timesteps    | 292864        |
| value_loss         | 0.06251536    |
--------------------------------------
-------------------------------------
| approxkl           | 0.00909443   |
| clipfrac           | 0.12851563   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.05        |
| explained_variance | 0.585        |
| fps                | 2113         |
| n_updates          | 144          |
| policy_entropy     | 7.0845146    |
| policy_loss        | -0.009154355 |
| serial_timesteps   | 36864        |
| time_elapsed       | 152          |
| total_timesteps    | 294912       |
| value_loss         | 0.07187815   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0075833136  |
| clipfrac           | 0.0980957     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -2.01         |
| explained_variance | 0.604         |
| fps                | 2148          |
| n_updates          | 145           |
| policy_entropy     | 7.081298      |
| policy_loss        | -0.0073281876 |
| serial_timesteps   | 37120         |
| time_elapsed       | 153           |
| total_timesteps    | 296960        |
| value_loss         | 0.070760526   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008036988  |
| clipfrac           | 0.10966797   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.03        |
| explained_variance | 0.71         |
| fps                | 2072         |
| n_updates          | 146          |
| policy_entropy     | 7.082415     |
| policy_loss        | -0.008990282 |
| serial_timesteps   | 37376        |
| time_elapsed       | 154          |
| total_timesteps    | 299008       |
| value_loss         | 0.05629436   |
-------------------------------------
Eval num_timesteps=300000, episode_reward=-0.47 +/- 0.00
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.009200766 |
| clipfrac           | 0.13232422  |
| ep_len_mean        | 99.3        |
| ep_reward_mean     | -1.92       |
| explained_variance | 0.627       |
| fps                | 1503        |
| n_updates          | 147         |
| policy_entropy     | 7.050235    |
| policy_loss        | -0.01324264 |
| serial_timesteps   | 37632       |
| time_elapsed       | 155         |
| total_timesteps    | 301056      |
| value_loss         | 0.07216723  |
------------------------------------
-------------------------------------
| approxkl           | 0.009706112  |
| clipfrac           | 0.13701172   |
| ep_len_mean        | 98.6         |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.513        |
| fps                | 2018         |
| n_updates          | 148          |
| policy_entropy     | 7.055346     |
| policy_loss        | -0.012350218 |
| serial_timesteps   | 37888        |
| time_elapsed       | 156          |
| total_timesteps    | 303104       |
| value_loss         | 0.0787274    |
-------------------------------------
--------------------------------------
| approxkl           | 0.009216465   |
| clipfrac           | 0.1270996     |
| ep_len_mean        | 97.9          |
| ep_reward_mean     | -1.88         |
| explained_variance | 0.451         |
| fps                | 2142          |
| n_updates          | 149           |
| policy_entropy     | 7.062314      |
| policy_loss        | -0.0091008125 |
| serial_timesteps   | 38144         |
| time_elapsed       | 157           |
| total_timesteps    | 305152        |
| value_loss         | 0.084170535   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008566541  |
| clipfrac           | 0.12026367   |
| ep_len_mean        | 97.3         |
| ep_reward_mean     | -1.82        |
| explained_variance | 0.592        |
| fps                | 2123         |
| n_updates          | 150          |
| policy_entropy     | 7.0414934    |
| policy_loss        | -0.008326046 |
| serial_timesteps   | 38400        |
| time_elapsed       | 158          |
| total_timesteps    | 307200       |
| value_loss         | 0.07260479   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008148304  |
| clipfrac           | 0.1128418    |
| ep_len_mean        | 97.8         |
| ep_reward_mean     | -1.83        |
| explained_variance | 0.53         |
| fps                | 2125         |
| n_updates          | 151          |
| policy_entropy     | 7.037221     |
| policy_loss        | -0.008257128 |
| serial_timesteps   | 38656        |
| time_elapsed       | 159          |
| total_timesteps    | 309248       |
| value_loss         | 0.0660347    |
-------------------------------------
Eval num_timesteps=310000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008038716  |
| clipfrac           | 0.108789064  |
| ep_len_mean        | 97.4         |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.566        |
| fps                | 1508         |
| n_updates          | 152          |
| policy_entropy     | 7.041897     |
| policy_loss        | -0.009263725 |
| serial_timesteps   | 38912        |
| time_elapsed       | 160          |
| total_timesteps    | 311296       |
| value_loss         | 0.066666216  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009928416  |
| clipfrac           | 0.14716797   |
| ep_len_mean        | 98.7         |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.501        |
| fps                | 2138         |
| n_updates          | 153          |
| policy_entropy     | 7.034767     |
| policy_loss        | -0.012534234 |
| serial_timesteps   | 39168        |
| time_elapsed       | 161          |
| total_timesteps    | 313344       |
| value_loss         | 0.07489623   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009553292  |
| clipfrac           | 0.13911133   |
| ep_len_mean        | 98.1         |
| ep_reward_mean     | -2.01        |
| explained_variance | 0.433        |
| fps                | 2136         |
| n_updates          | 154          |
| policy_entropy     | 7.0446043    |
| policy_loss        | -0.011538256 |
| serial_timesteps   | 39424        |
| time_elapsed       | 162          |
| total_timesteps    | 315392       |
| value_loss         | 0.10875428   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009752683  |
| clipfrac           | 0.1430664    |
| ep_len_mean        | 99           |
| ep_reward_mean     | -2.03        |
| explained_variance | 0.325        |
| fps                | 2096         |
| n_updates          | 155          |
| policy_entropy     | 7.0718207    |
| policy_loss        | -0.010688038 |
| serial_timesteps   | 39680        |
| time_elapsed       | 163          |
| total_timesteps    | 317440       |
| value_loss         | 0.119430736  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0071877493 |
| clipfrac           | 0.096386716  |
| ep_len_mean        | 99           |
| ep_reward_mean     | -2.02        |
| explained_variance | 0.642        |
| fps                | 2145         |
| n_updates          | 156          |
| policy_entropy     | 7.074279     |
| policy_loss        | -0.00776899  |
| serial_timesteps   | 39936        |
| time_elapsed       | 164          |
| total_timesteps    | 319488       |
| value_loss         | 0.05066151   |
-------------------------------------
Eval num_timesteps=320000, episode_reward=-0.48 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009567851  |
| clipfrac           | 0.13251953   |
| ep_len_mean        | 99.4         |
| ep_reward_mean     | -2.02        |
| explained_variance | 0.509        |
| fps                | 1506         |
| n_updates          | 157          |
| policy_entropy     | 7.054599     |
| policy_loss        | -0.011893889 |
| serial_timesteps   | 40192        |
| time_elapsed       | 165          |
| total_timesteps    | 321536       |
| value_loss         | 0.08818344   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010140247  |
| clipfrac           | 0.14736328   |
| ep_len_mean        | 99.4         |
| ep_reward_mean     | -1.98        |
| explained_variance | 0.63         |
| fps                | 2137         |
| n_updates          | 158          |
| policy_entropy     | 7.0289025    |
| policy_loss        | -0.014370819 |
| serial_timesteps   | 40448        |
| time_elapsed       | 167          |
| total_timesteps    | 323584       |
| value_loss         | 0.055942595  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009394331  |
| clipfrac           | 0.13251953   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.06        |
| explained_variance | 0.481        |
| fps                | 2089         |
| n_updates          | 159          |
| policy_entropy     | 6.9940844    |
| policy_loss        | -0.009486221 |
| serial_timesteps   | 40704        |
| time_elapsed       | 168          |
| total_timesteps    | 325632       |
| value_loss         | 0.07591613   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009375887  |
| clipfrac           | 0.1328125    |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -2.01        |
| explained_variance | 0.505        |
| fps                | 2092         |
| n_updates          | 160          |
| policy_entropy     | 6.9727545    |
| policy_loss        | -0.010326882 |
| serial_timesteps   | 40960        |
| time_elapsed       | 169          |
| total_timesteps    | 327680       |
| value_loss         | 0.089869484  |
-------------------------------------
-------------------------------------
| approxkl           | 0.011296938  |
| clipfrac           | 0.16201171   |
| ep_len_mean        | 99           |
| ep_reward_mean     | -2           |
| explained_variance | 0.65         |
| fps                | 2117         |
| n_updates          | 161          |
| policy_entropy     | 6.943882     |
| policy_loss        | -0.013351706 |
| serial_timesteps   | 41216        |
| time_elapsed       | 170          |
| total_timesteps    | 329728       |
| value_loss         | 0.061953038  |
-------------------------------------
Eval num_timesteps=330000, episode_reward=-0.65 +/- 0.06
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.00862713   |
| clipfrac           | 0.11230469   |
| ep_len_mean        | 98.3         |
| ep_reward_mean     | -2.04        |
| explained_variance | 0.392        |
| fps                | 1515         |
| n_updates          | 162          |
| policy_entropy     | 6.920008     |
| policy_loss        | -0.011040129 |
| serial_timesteps   | 41472        |
| time_elapsed       | 171          |
| total_timesteps    | 331776       |
| value_loss         | 0.080983415  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008819397  |
| clipfrac           | 0.12495117   |
| ep_len_mean        | 98.3         |
| ep_reward_mean     | -2.08        |
| explained_variance | 0.554        |
| fps                | 2058         |
| n_updates          | 163          |
| policy_entropy     | 6.9017577    |
| policy_loss        | -0.011625995 |
| serial_timesteps   | 41728        |
| time_elapsed       | 172          |
| total_timesteps    | 333824       |
| value_loss         | 0.08137039   |
-------------------------------------
------------------------------------
| approxkl           | 0.00832965  |
| clipfrac           | 0.119628906 |
| ep_len_mean        | 97.6        |
| ep_reward_mean     | -1.97       |
| explained_variance | 0.614       |
| fps                | 2152        |
| n_updates          | 164         |
| policy_entropy     | 6.8889403   |
| policy_loss        | -0.00994708 |
| serial_timesteps   | 41984       |
| time_elapsed       | 173         |
| total_timesteps    | 335872      |
| value_loss         | 0.05627942  |
------------------------------------
-------------------------------------
| approxkl           | 0.0076741586 |
| clipfrac           | 0.10131836   |
| ep_len_mean        | 98.1         |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.636        |
| fps                | 2172         |
| n_updates          | 165          |
| policy_entropy     | 6.893235     |
| policy_loss        | -0.007571715 |
| serial_timesteps   | 42240        |
| time_elapsed       | 174          |
| total_timesteps    | 337920       |
| value_loss         | 0.053108163  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007159668  |
| clipfrac           | 0.08852539   |
| ep_len_mean        | 98.4         |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.659        |
| fps                | 2156         |
| n_updates          | 166          |
| policy_entropy     | 6.8973703    |
| policy_loss        | -0.006407175 |
| serial_timesteps   | 42496        |
| time_elapsed       | 175          |
| total_timesteps    | 339968       |
| value_loss         | 0.057403415  |
-------------------------------------
Eval num_timesteps=340000, episode_reward=-0.80 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009735723   |
| clipfrac           | 0.13603516    |
| ep_len_mean        | 98.5          |
| ep_reward_mean     | -1.88         |
| explained_variance | 0.676         |
| fps                | 1498          |
| n_updates          | 167           |
| policy_entropy     | 6.9189157     |
| policy_loss        | -0.0117453905 |
| serial_timesteps   | 42752         |
| time_elapsed       | 176           |
| total_timesteps    | 342016        |
| value_loss         | 0.047862448   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009807177  |
| clipfrac           | 0.14321288   |
| ep_len_mean        | 98.5         |
| ep_reward_mean     | -1.82        |
| explained_variance | 0.612        |
| fps                | 2167         |
| n_updates          | 168          |
| policy_entropy     | 6.9324827    |
| policy_loss        | -0.012267965 |
| serial_timesteps   | 43008        |
| time_elapsed       | 177          |
| total_timesteps    | 344064       |
| value_loss         | 0.056542583  |
-------------------------------------
--------------------------------------
| approxkl           | 0.007792446   |
| clipfrac           | 0.09951172    |
| ep_len_mean        | 98.6          |
| ep_reward_mean     | -1.86         |
| explained_variance | 0.443         |
| fps                | 2175          |
| n_updates          | 169           |
| policy_entropy     | 6.9011397     |
| policy_loss        | -0.0076369634 |
| serial_timesteps   | 43264         |
| time_elapsed       | 178           |
| total_timesteps    | 346112        |
| value_loss         | 0.07102047    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0076066693 |
| clipfrac           | 0.099804685  |
| ep_len_mean        | 98.3         |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.619        |
| fps                | 2131         |
| n_updates          | 170          |
| policy_entropy     | 6.903187     |
| policy_loss        | -0.008224534 |
| serial_timesteps   | 43520        |
| time_elapsed       | 179          |
| total_timesteps    | 348160       |
| value_loss         | 0.064198986  |
-------------------------------------
Eval num_timesteps=350000, episode_reward=-0.50 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008152695  |
| clipfrac           | 0.11015625   |
| ep_len_mean        | 98.2         |
| ep_reward_mean     | -1.93        |
| explained_variance | 0.506        |
| fps                | 1504         |
| n_updates          | 171          |
| policy_entropy     | 6.919024     |
| policy_loss        | -0.010308909 |
| serial_timesteps   | 43776        |
| time_elapsed       | 180          |
| total_timesteps    | 350208       |
| value_loss         | 0.08320629   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008232497  |
| clipfrac           | 0.11396484   |
| ep_len_mean        | 98.9         |
| ep_reward_mean     | -1.99        |
| explained_variance | 0.642        |
| fps                | 2170         |
| n_updates          | 172          |
| policy_entropy     | 6.897011     |
| policy_loss        | -0.010020044 |
| serial_timesteps   | 44032        |
| time_elapsed       | 181          |
| total_timesteps    | 352256       |
| value_loss         | 0.05636825   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007966267  |
| clipfrac           | 0.10258789   |
| ep_len_mean        | 98.9         |
| ep_reward_mean     | -1.97        |
| explained_variance | 0.664        |
| fps                | 2152         |
| n_updates          | 173          |
| policy_entropy     | 6.8843956    |
| policy_loss        | -0.009191176 |
| serial_timesteps   | 44288        |
| time_elapsed       | 182          |
| total_timesteps    | 354304       |
| value_loss         | 0.06032344   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008307019  |
| clipfrac           | 0.113427736  |
| ep_len_mean        | 99.6         |
| ep_reward_mean     | -2.05        |
| explained_variance | 0.566        |
| fps                | 2128         |
| n_updates          | 174          |
| policy_entropy     | 6.89572      |
| policy_loss        | -0.010883216 |
| serial_timesteps   | 44544        |
| time_elapsed       | 183          |
| total_timesteps    | 356352       |
| value_loss         | 0.07468272   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008275899  |
| clipfrac           | 0.11030273   |
| ep_len_mean        | 99.6         |
| ep_reward_mean     | -1.97        |
| explained_variance | 0.698        |
| fps                | 2125         |
| n_updates          | 175          |
| policy_entropy     | 6.8855605    |
| policy_loss        | -0.011282412 |
| serial_timesteps   | 44800        |
| time_elapsed       | 184          |
| total_timesteps    | 358400       |
| value_loss         | 0.046909306  |
-------------------------------------
Eval num_timesteps=360000, episode_reward=-0.80 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008319892  |
| clipfrac           | 0.10981445   |
| ep_len_mean        | 99.7         |
| ep_reward_mean     | -2.05        |
| explained_variance | 0.617        |
| fps                | 1510         |
| n_updates          | 176          |
| policy_entropy     | 6.852806     |
| policy_loss        | -0.009382141 |
| serial_timesteps   | 45056        |
| time_elapsed       | 185          |
| total_timesteps    | 360448       |
| value_loss         | 0.06716806   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008887035  |
| clipfrac           | 0.12675782   |
| ep_len_mean        | 99.7         |
| ep_reward_mean     | -2.14        |
| explained_variance | 0.675        |
| fps                | 2173         |
| n_updates          | 177          |
| policy_entropy     | 6.8462915    |
| policy_loss        | -0.011782651 |
| serial_timesteps   | 45312        |
| time_elapsed       | 187          |
| total_timesteps    | 362496       |
| value_loss         | 0.06608881   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0076566986 |
| clipfrac           | 0.10444336   |
| ep_len_mean        | 99.7         |
| ep_reward_mean     | -2.15        |
| explained_variance | 0.665        |
| fps                | 2053         |
| n_updates          | 178          |
| policy_entropy     | 6.850652     |
| policy_loss        | -0.008954152 |
| serial_timesteps   | 45568        |
| time_elapsed       | 187          |
| total_timesteps    | 364544       |
| value_loss         | 0.057793777  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010807744  |
| clipfrac           | 0.15136719   |
| ep_len_mean        | 99.9         |
| ep_reward_mean     | -2.14        |
| explained_variance | 0.679        |
| fps                | 1391         |
| n_updates          | 179          |
| policy_entropy     | 6.855165     |
| policy_loss        | -0.013389988 |
| serial_timesteps   | 45824        |
| time_elapsed       | 188          |
| total_timesteps    | 366592       |
| value_loss         | 0.062280793  |
-------------------------------------
--------------------------------------
| approxkl           | 0.006803616   |
| clipfrac           | 0.082128905   |
| ep_len_mean        | 99.8          |
| ep_reward_mean     | -2.24         |
| explained_variance | 0.659         |
| fps                | 2155          |
| n_updates          | 180           |
| policy_entropy     | 6.859295      |
| policy_loss        | -0.0075492365 |
| serial_timesteps   | 46080         |
| time_elapsed       | 190           |
| total_timesteps    | 368640        |
| value_loss         | 0.067499146   |
--------------------------------------
Eval num_timesteps=370000, episode_reward=-0.92 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007214288  |
| clipfrac           | 0.093164064  |
| ep_len_mean        | 99.8         |
| ep_reward_mean     | -2.23        |
| explained_variance | 0.71         |
| fps                | 1500         |
| n_updates          | 181          |
| policy_entropy     | 6.8388186    |
| policy_loss        | -0.007047396 |
| serial_timesteps   | 46336        |
| time_elapsed       | 191          |
| total_timesteps    | 370688       |
| value_loss         | 0.059734277  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009346256  |
| clipfrac           | 0.13120118   |
| ep_len_mean        | 99.8         |
| ep_reward_mean     | -2.17        |
| explained_variance | 0.635        |
| fps                | 2146         |
| n_updates          | 182          |
| policy_entropy     | 6.828509     |
| policy_loss        | -0.012045248 |
| serial_timesteps   | 46592        |
| time_elapsed       | 192          |
| total_timesteps    | 372736       |
| value_loss         | 0.08000388   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008364503  |
| clipfrac           | 0.11245117   |
| ep_len_mean        | 99.9         |
| ep_reward_mean     | -2.31        |
| explained_variance | 0.541        |
| fps                | 2157         |
| n_updates          | 183          |
| policy_entropy     | 6.8311377    |
| policy_loss        | -0.009947034 |
| serial_timesteps   | 46848        |
| time_elapsed       | 193          |
| total_timesteps    | 374784       |
| value_loss         | 0.12242379   |
-------------------------------------
--------------------------------------
| approxkl           | 0.009978296   |
| clipfrac           | 0.13867188    |
| ep_len_mean        | 99.9          |
| ep_reward_mean     | -2.3          |
| explained_variance | 0.631         |
| fps                | 2158          |
| n_updates          | 184           |
| policy_entropy     | 6.823237      |
| policy_loss        | -0.0108628385 |
| serial_timesteps   | 47104         |
| time_elapsed       | 194           |
| total_timesteps    | 376832        |
| value_loss         | 0.079834595   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009162349  |
| clipfrac           | 0.1274414    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.22        |
| explained_variance | 0.751        |
| fps                | 2113         |
| n_updates          | 185          |
| policy_entropy     | 6.819688     |
| policy_loss        | -0.011830605 |
| serial_timesteps   | 47360        |
| time_elapsed       | 195          |
| total_timesteps    | 378880       |
| value_loss         | 0.053413004  |
-------------------------------------
Eval num_timesteps=380000, episode_reward=-0.93 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010043063  |
| clipfrac           | 0.14555664   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.17        |
| explained_variance | 0.731        |
| fps                | 1529         |
| n_updates          | 186          |
| policy_entropy     | 6.8176775    |
| policy_loss        | -0.014511831 |
| serial_timesteps   | 47616        |
| time_elapsed       | 196          |
| total_timesteps    | 380928       |
| value_loss         | 0.062187783  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009486006   |
| clipfrac           | 0.13447265    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -2.17         |
| explained_variance | 0.686         |
| fps                | 2184          |
| n_updates          | 187           |
| policy_entropy     | 6.810102      |
| policy_loss        | -0.0121598765 |
| serial_timesteps   | 47872         |
| time_elapsed       | 197           |
| total_timesteps    | 382976        |
| value_loss         | 0.060119916   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0076410286 |
| clipfrac           | 0.10131836   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.03        |
| explained_variance | 0.709        |
| fps                | 521          |
| n_updates          | 188          |
| policy_entropy     | 6.825629     |
| policy_loss        | -0.010178109 |
| serial_timesteps   | 48128        |
| time_elapsed       | 198          |
| total_timesteps    | 385024       |
| value_loss         | 0.04855632   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009204599  |
| clipfrac           | 0.13154297   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.94        |
| explained_variance | 0.763        |
| fps                | 2175         |
| n_updates          | 189          |
| policy_entropy     | 6.831622     |
| policy_loss        | -0.011171772 |
| serial_timesteps   | 48384        |
| time_elapsed       | 202          |
| total_timesteps    | 387072       |
| value_loss         | 0.03615053   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0076876283 |
| clipfrac           | 0.09951172   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.92        |
| explained_variance | 0.776        |
| fps                | 2159         |
| n_updates          | 190          |
| policy_entropy     | 6.8013053    |
| policy_loss        | -0.00692776  |
| serial_timesteps   | 48640        |
| time_elapsed       | 203          |
| total_timesteps    | 389120       |
| value_loss         | 0.038428903  |
-------------------------------------
Eval num_timesteps=390000, episode_reward=-0.98 +/- 0.01
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.008187177   |
| clipfrac           | 0.11289062    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.87         |
| explained_variance | 0.77          |
| fps                | 1523          |
| n_updates          | 191           |
| policy_entropy     | 6.7707453     |
| policy_loss        | -0.0061953804 |
| serial_timesteps   | 48896         |
| time_elapsed       | 204           |
| total_timesteps    | 391168        |
| value_loss         | 0.04200776    |
--------------------------------------
-------------------------------------
| approxkl           | 0.009646768  |
| clipfrac           | 0.13793945   |
| ep_len_mean        | 99.2         |
| ep_reward_mean     | -1.83        |
| explained_variance | 0.781        |
| fps                | 2172         |
| n_updates          | 192          |
| policy_entropy     | 6.747354     |
| policy_loss        | -0.011004254 |
| serial_timesteps   | 49152        |
| time_elapsed       | 205          |
| total_timesteps    | 393216       |
| value_loss         | 0.041220542  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007513239  |
| clipfrac           | 0.09770508   |
| ep_len_mean        | 99.2         |
| ep_reward_mean     | -1.8         |
| explained_variance | 0.793        |
| fps                | 2164         |
| n_updates          | 193          |
| policy_entropy     | 6.7294683    |
| policy_loss        | -0.008668451 |
| serial_timesteps   | 49408        |
| time_elapsed       | 206          |
| total_timesteps    | 395264       |
| value_loss         | 0.038128253  |
-------------------------------------
--------------------------------------
| approxkl           | 0.006785835   |
| clipfrac           | 0.08623047    |
| ep_len_mean        | 99.2          |
| ep_reward_mean     | -1.84         |
| explained_variance | 0.784         |
| fps                | 2118          |
| n_updates          | 194           |
| policy_entropy     | 6.7192583     |
| policy_loss        | -0.0047519687 |
| serial_timesteps   | 49664         |
| time_elapsed       | 207           |
| total_timesteps    | 397312        |
| value_loss         | 0.036577173   |
--------------------------------------
-------------------------------------
| approxkl           | 0.008777934  |
| clipfrac           | 0.12358399   |
| ep_len_mean        | 99.2         |
| ep_reward_mean     | -1.82        |
| explained_variance | 0.805        |
| fps                | 2048         |
| n_updates          | 195          |
| policy_entropy     | 6.7024436    |
| policy_loss        | -0.010708625 |
| serial_timesteps   | 49920        |
| time_elapsed       | 208          |
| total_timesteps    | 399360       |
| value_loss         | 0.034466393  |
-------------------------------------
Eval num_timesteps=400000, episode_reward=-1.04 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008371916  |
| clipfrac           | 0.10629883   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.84        |
| explained_variance | 0.777        |
| fps                | 1527         |
| n_updates          | 196          |
| policy_entropy     | 6.6727514    |
| policy_loss        | -0.011711692 |
| serial_timesteps   | 50176        |
| time_elapsed       | 209          |
| total_timesteps    | 401408       |
| value_loss         | 0.03448925   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077448026 |
| clipfrac           | 0.10517578   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.82        |
| explained_variance | 0.796        |
| fps                | 2136         |
| n_updates          | 197          |
| policy_entropy     | 6.6308784    |
| policy_loss        | -0.009089921 |
| serial_timesteps   | 50432        |
| time_elapsed       | 211          |
| total_timesteps    | 403456       |
| value_loss         | 0.030511197  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009250131  |
| clipfrac           | 0.13203125   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.84        |
| explained_variance | 0.781        |
| fps                | 2128         |
| n_updates          | 198          |
| policy_entropy     | 6.611618     |
| policy_loss        | -0.009968535 |
| serial_timesteps   | 50688        |
| time_elapsed       | 212          |
| total_timesteps    | 405504       |
| value_loss         | 0.035898782  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008284131  |
| clipfrac           | 0.11787109   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.794        |
| fps                | 2142         |
| n_updates          | 199          |
| policy_entropy     | 6.612386     |
| policy_loss        | -0.008539704 |
| serial_timesteps   | 50944        |
| time_elapsed       | 213          |
| total_timesteps    | 407552       |
| value_loss         | 0.030530995  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007218712  |
| clipfrac           | 0.09057617   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.79        |
| explained_variance | 0.776        |
| fps                | 2038         |
| n_updates          | 200          |
| policy_entropy     | 6.595582     |
| policy_loss        | -0.004520988 |
| serial_timesteps   | 51200        |
| time_elapsed       | 214          |
| total_timesteps    | 409600       |
| value_loss         | 0.033329237  |
-------------------------------------
Eval num_timesteps=410000, episode_reward=-1.07 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.007917769  |
| clipfrac           | 0.11049805   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.774        |
| fps                | 1499         |
| n_updates          | 201          |
| policy_entropy     | 6.5857673    |
| policy_loss        | -0.010180065 |
| serial_timesteps   | 51456        |
| time_elapsed       | 215          |
| total_timesteps    | 411648       |
| value_loss         | 0.033812575  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010824587  |
| clipfrac           | 0.16450195   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.78        |
| explained_variance | 0.826        |
| fps                | 2138         |
| n_updates          | 202          |
| policy_entropy     | 6.591082     |
| policy_loss        | -0.014723552 |
| serial_timesteps   | 51712        |
| time_elapsed       | 216          |
| total_timesteps    | 413696       |
| value_loss         | 0.02867713   |
-------------------------------------
--------------------------------------
| approxkl           | 0.008275953   |
| clipfrac           | 0.11411133    |
| ep_len_mean        | 99.3          |
| ep_reward_mean     | -1.78         |
| explained_variance | 0.764         |
| fps                | 2136          |
| n_updates          | 203           |
| policy_entropy     | 6.595876      |
| policy_loss        | -0.0075395987 |
| serial_timesteps   | 51968         |
| time_elapsed       | 217           |
| total_timesteps    | 415744        |
| value_loss         | 0.037949655   |
--------------------------------------
-------------------------------------
| approxkl           | 0.013360846  |
| clipfrac           | 0.17626953   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.79        |
| explained_variance | 0.503        |
| fps                | 2143         |
| n_updates          | 204          |
| policy_entropy     | 6.5999236    |
| policy_loss        | -0.014320344 |
| serial_timesteps   | 52224        |
| time_elapsed       | 218          |
| total_timesteps    | 417792       |
| value_loss         | 0.060662985  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0070743323 |
| clipfrac           | 0.089501955  |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.81        |
| explained_variance | 0.764        |
| fps                | 2093         |
| n_updates          | 205          |
| policy_entropy     | 6.603305     |
| policy_loss        | -0.00713654  |
| serial_timesteps   | 52480        |
| time_elapsed       | 219          |
| total_timesteps    | 419840       |
| value_loss         | 0.03183944   |
-------------------------------------
Eval num_timesteps=420000, episode_reward=-1.13 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0092670955 |
| clipfrac           | 0.12758788   |
| ep_len_mean        | 97.8         |
| ep_reward_mean     | -1.76        |
| explained_variance | 0.722        |
| fps                | 1495         |
| n_updates          | 206          |
| policy_entropy     | 6.5890846    |
| policy_loss        | -0.009802204 |
| serial_timesteps   | 52736        |
| time_elapsed       | 220          |
| total_timesteps    | 421888       |
| value_loss         | 0.040706404  |
-------------------------------------
-------------------------------------
| approxkl           | 0.012135891  |
| clipfrac           | 0.1841797    |
| ep_len_mean        | 97           |
| ep_reward_mean     | -1.74        |
| explained_variance | 0.672        |
| fps                | 2148         |
| n_updates          | 207          |
| policy_entropy     | 6.5521517    |
| policy_loss        | -0.015165551 |
| serial_timesteps   | 52992        |
| time_elapsed       | 221          |
| total_timesteps    | 423936       |
| value_loss         | 0.040669255  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008708807  |
| clipfrac           | 0.12016602   |
| ep_len_mean        | 97           |
| ep_reward_mean     | -1.77        |
| explained_variance | 0.73         |
| fps                | 2151         |
| n_updates          | 208          |
| policy_entropy     | 6.4974337    |
| policy_loss        | -0.010812389 |
| serial_timesteps   | 53248        |
| time_elapsed       | 222          |
| total_timesteps    | 425984       |
| value_loss         | 0.03638984   |
-------------------------------------
--------------------------------------
| approxkl           | 0.008967797   |
| clipfrac           | 0.123046875   |
| ep_len_mean        | 96.4          |
| ep_reward_mean     | -1.76         |
| explained_variance | 0.536         |
| fps                | 2106          |
| n_updates          | 209           |
| policy_entropy     | 6.4890327     |
| policy_loss        | -0.0080935145 |
| serial_timesteps   | 53504         |
| time_elapsed       | 223           |
| total_timesteps    | 428032        |
| value_loss         | 0.060978007   |
--------------------------------------
Eval num_timesteps=430000, episode_reward=-1.21 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010119571  |
| clipfrac           | 0.13652344   |
| ep_len_mean        | 96.4         |
| ep_reward_mean     | -1.82        |
| explained_variance | 0.516        |
| fps                | 1489         |
| n_updates          | 210          |
| policy_entropy     | 6.4960685    |
| policy_loss        | -0.013186136 |
| serial_timesteps   | 53760        |
| time_elapsed       | 224          |
| total_timesteps    | 430080       |
| value_loss         | 0.05592537   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010679648  |
| clipfrac           | 0.1565918    |
| ep_len_mean        | 97.2         |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.565        |
| fps                | 2150         |
| n_updates          | 211          |
| policy_entropy     | 6.5023146    |
| policy_loss        | -0.015399803 |
| serial_timesteps   | 54016        |
| time_elapsed       | 225          |
| total_timesteps    | 432128       |
| value_loss         | 0.05033975   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008534339  |
| clipfrac           | 0.11972656   |
| ep_len_mean        | 97.9         |
| ep_reward_mean     | -1.95        |
| explained_variance | 0.536        |
| fps                | 2131         |
| n_updates          | 212          |
| policy_entropy     | 6.505473     |
| policy_loss        | -0.008985232 |
| serial_timesteps   | 54272        |
| time_elapsed       | 226          |
| total_timesteps    | 434176       |
| value_loss         | 0.050693613  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00995761   |
| clipfrac           | 0.13891602   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.93        |
| explained_variance | 0.725        |
| fps                | 2099         |
| n_updates          | 213          |
| policy_entropy     | 6.4986672    |
| policy_loss        | -0.010504631 |
| serial_timesteps   | 54528        |
| time_elapsed       | 227          |
| total_timesteps    | 436224       |
| value_loss         | 0.032419547  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008251077  |
| clipfrac           | 0.11445312   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.649        |
| fps                | 2141         |
| n_updates          | 214          |
| policy_entropy     | 6.491474     |
| policy_loss        | -0.009470608 |
| serial_timesteps   | 54784        |
| time_elapsed       | 228          |
| total_timesteps    | 438272       |
| value_loss         | 0.037241228  |
-------------------------------------
Eval num_timesteps=440000, episode_reward=-1.26 +/- 0.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009683374  |
| clipfrac           | 0.14121094   |
| ep_len_mean        | 97.9         |
| ep_reward_mean     | -1.78        |
| explained_variance | 0.578        |
| fps                | 1506         |
| n_updates          | 215          |
| policy_entropy     | 6.463352     |
| policy_loss        | -0.012399925 |
| serial_timesteps   | 55040        |
| time_elapsed       | 229          |
| total_timesteps    | 440320       |
| value_loss         | 0.051242493  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0099917175 |
| clipfrac           | 0.1416504    |
| ep_len_mean        | 97.9         |
| ep_reward_mean     | -1.76        |
| explained_variance | 0.529        |
| fps                | 2112         |
| n_updates          | 216          |
| policy_entropy     | 6.451972     |
| policy_loss        | -0.011606018 |
| serial_timesteps   | 55296        |
| time_elapsed       | 231          |
| total_timesteps    | 442368       |
| value_loss         | 0.071245424  |
-------------------------------------
-------------------------------------
| approxkl           | 0.01009062   |
| clipfrac           | 0.14140625   |
| ep_len_mean        | 97.8         |
| ep_reward_mean     | -1.75        |
| explained_variance | 0.683        |
| fps                | 2119         |
| n_updates          | 217          |
| policy_entropy     | 6.470487     |
| policy_loss        | -0.013306652 |
| serial_timesteps   | 55552        |
| time_elapsed       | 232          |
| total_timesteps    | 444416       |
| value_loss         | 0.043304633  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010635187  |
| clipfrac           | 0.153125     |
| ep_len_mean        | 96.3         |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.433        |
| fps                | 2159         |
| n_updates          | 218          |
| policy_entropy     | 6.4714212    |
| policy_loss        | -0.011466798 |
| serial_timesteps   | 55808        |
| time_elapsed       | 233          |
| total_timesteps    | 446464       |
| value_loss         | 0.1061558    |
-------------------------------------
-------------------------------------
| approxkl           | 0.011670394  |
| clipfrac           | 0.1722168    |
| ep_len_mean        | 96.3         |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.627        |
| fps                | 2146         |
| n_updates          | 219          |
| policy_entropy     | 6.457785     |
| policy_loss        | -0.015408263 |
| serial_timesteps   | 56064        |
| time_elapsed       | 234          |
| total_timesteps    | 448512       |
| value_loss         | 0.039681204  |
-------------------------------------
Eval num_timesteps=450000, episode_reward=-1.12 +/- 0.03
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.009262158 |
| clipfrac           | 0.1309082   |
| ep_len_mean        | 95.7        |
| ep_reward_mean     | -1.92       |
| explained_variance | 0.708       |
| fps                | 1493        |
| n_updates          | 220         |
| policy_entropy     | 6.437841    |
| policy_loss        | -0.00783577 |
| serial_timesteps   | 56320       |
| time_elapsed       | 234         |
| total_timesteps    | 450560      |
| value_loss         | 0.037929036 |
------------------------------------
-------------------------------------
| approxkl           | 0.009538001  |
| clipfrac           | 0.13481446   |
| ep_len_mean        | 96.4         |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.709        |
| fps                | 2036         |
| n_updates          | 221          |
| policy_entropy     | 6.4338775    |
| policy_loss        | -0.013085185 |
| serial_timesteps   | 56576        |
| time_elapsed       | 236          |
| total_timesteps    | 452608       |
| value_loss         | 0.031806134  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008702404   |
| clipfrac           | 0.11831055    |
| ep_len_mean        | 95.6          |
| ep_reward_mean     | -1.86         |
| explained_variance | 0.702         |
| fps                | 2063          |
| n_updates          | 222           |
| policy_entropy     | 6.419577      |
| policy_loss        | -0.0078053274 |
| serial_timesteps   | 56832         |
| time_elapsed       | 237           |
| total_timesteps    | 454656        |
| value_loss         | 0.033885453   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010059794  |
| clipfrac           | 0.14848633   |
| ep_len_mean        | 97           |
| ep_reward_mean     | -1.8         |
| explained_variance | 0.736        |
| fps                | 2093         |
| n_updates          | 223          |
| policy_entropy     | 6.398654     |
| policy_loss        | -0.011526102 |
| serial_timesteps   | 57088        |
| time_elapsed       | 238          |
| total_timesteps    | 456704       |
| value_loss         | 0.02984232   |
-------------------------------------
-------------------------------------
| approxkl           | 0.007476897  |
| clipfrac           | 0.09790039   |
| ep_len_mean        | 97.5         |
| ep_reward_mean     | -1.79        |
| explained_variance | 0.783        |
| fps                | 2101         |
| n_updates          | 224          |
| policy_entropy     | 6.3858914    |
| policy_loss        | -0.007025504 |
| serial_timesteps   | 57344        |
| time_elapsed       | 239          |
| total_timesteps    | 458752       |
| value_loss         | 0.026747545  |
-------------------------------------
Eval num_timesteps=460000, episode_reward=-1.40 +/- 0.02
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.009994592 |
| clipfrac           | 0.14570312  |
| ep_len_mean        | 97.6        |
| ep_reward_mean     | -1.76       |
| explained_variance | 0.72        |
| fps                | 1481        |
| n_updates          | 225         |
| policy_entropy     | 6.3790045   |
| policy_loss        | -0.01380613 |
| serial_timesteps   | 57600       |
| time_elapsed       | 240         |
| total_timesteps    | 460800      |
| value_loss         | 0.035422448 |
------------------------------------
-------------------------------------
| approxkl           | 0.008828101  |
| clipfrac           | 0.12519531   |
| ep_len_mean        | 97.6         |
| ep_reward_mean     | -1.73        |
| explained_variance | 0.794        |
| fps                | 2113         |
| n_updates          | 226          |
| policy_entropy     | 6.3749113    |
| policy_loss        | -0.011725748 |
| serial_timesteps   | 57856        |
| time_elapsed       | 241          |
| total_timesteps    | 462848       |
| value_loss         | 0.027729858  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00993234   |
| clipfrac           | 0.13095704   |
| ep_len_mean        | 97.1         |
| ep_reward_mean     | -1.78        |
| explained_variance | 0.392        |
| fps                | 2131         |
| n_updates          | 227          |
| policy_entropy     | 6.381503     |
| policy_loss        | -0.011658061 |
| serial_timesteps   | 58112        |
| time_elapsed       | 242          |
| total_timesteps    | 464896       |
| value_loss         | 0.08217889   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008109173  |
| clipfrac           | 0.10859375   |
| ep_len_mean        | 97.2         |
| ep_reward_mean     | -1.78        |
| explained_variance | 0.724        |
| fps                | 2141         |
| n_updates          | 228          |
| policy_entropy     | 6.370693     |
| policy_loss        | -0.009216595 |
| serial_timesteps   | 58368        |
| time_elapsed       | 243          |
| total_timesteps    | 466944       |
| value_loss         | 0.03376387   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008731134  |
| clipfrac           | 0.11606445   |
| ep_len_mean        | 97.2         |
| ep_reward_mean     | -1.79        |
| explained_variance | 0.819        |
| fps                | 2106         |
| n_updates          | 229          |
| policy_entropy     | 6.350174     |
| policy_loss        | -0.007968082 |
| serial_timesteps   | 58624        |
| time_elapsed       | 244          |
| total_timesteps    | 468992       |
| value_loss         | 0.02412493   |
-------------------------------------
Eval num_timesteps=470000, episode_reward=-1.51 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008525627  |
| clipfrac           | 0.11577149   |
| ep_len_mean        | 96.3         |
| ep_reward_mean     | -1.76        |
| explained_variance | 0.757        |
| fps                | 1504         |
| n_updates          | 230          |
| policy_entropy     | 6.3484764    |
| policy_loss        | -0.007831376 |
| serial_timesteps   | 58880        |
| time_elapsed       | 245          |
| total_timesteps    | 471040       |
| value_loss         | 0.033536907  |
-------------------------------------
-------------------------------------
| approxkl           | 0.011035914  |
| clipfrac           | 0.1661621    |
| ep_len_mean        | 96.3         |
| ep_reward_mean     | -1.8         |
| explained_variance | 0.666        |
| fps                | 2128         |
| n_updates          | 231          |
| policy_entropy     | 6.368257     |
| policy_loss        | -0.010902541 |
| serial_timesteps   | 59136        |
| time_elapsed       | 246          |
| total_timesteps    | 473088       |
| value_loss         | 0.04104335   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009682589  |
| clipfrac           | 0.14350586   |
| ep_len_mean        | 97           |
| ep_reward_mean     | -1.75        |
| explained_variance | 0.762        |
| fps                | 2115         |
| n_updates          | 232          |
| policy_entropy     | 6.3683424    |
| policy_loss        | -0.012963923 |
| serial_timesteps   | 59392        |
| time_elapsed       | 247          |
| total_timesteps    | 475136       |
| value_loss         | 0.02719442   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009867715  |
| clipfrac           | 0.13774414   |
| ep_len_mean        | 97           |
| ep_reward_mean     | -1.78        |
| explained_variance | 0.695        |
| fps                | 2153         |
| n_updates          | 233          |
| policy_entropy     | 6.3470073    |
| policy_loss        | -0.012012707 |
| serial_timesteps   | 59648        |
| time_elapsed       | 248          |
| total_timesteps    | 477184       |
| value_loss         | 0.03687407   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009204671  |
| clipfrac           | 0.13208008   |
| ep_len_mean        | 97           |
| ep_reward_mean     | -1.82        |
| explained_variance | 0.536        |
| fps                | 2171         |
| n_updates          | 234          |
| policy_entropy     | 6.33817      |
| policy_loss        | -0.011228862 |
| serial_timesteps   | 59904        |
| time_elapsed       | 249          |
| total_timesteps    | 479232       |
| value_loss         | 0.057712007  |
-------------------------------------
Eval num_timesteps=480000, episode_reward=-1.54 +/- 0.02
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.0082266005  |
| clipfrac           | 0.10683594    |
| ep_len_mean        | 95.7          |
| ep_reward_mean     | -1.85         |
| explained_variance | 0.453         |
| fps                | 1506          |
| n_updates          | 235           |
| policy_entropy     | 6.351548      |
| policy_loss        | -0.0103827175 |
| serial_timesteps   | 60160         |
| time_elapsed       | 250           |
| total_timesteps    | 481280        |
| value_loss         | 0.07513327    |
--------------------------------------
-------------------------------------
| approxkl           | 0.008644637  |
| clipfrac           | 0.119628906  |
| ep_len_mean        | 96.4         |
| ep_reward_mean     | -1.94        |
| explained_variance | 0.439        |
| fps                | 2118         |
| n_updates          | 236          |
| policy_entropy     | 6.372019     |
| policy_loss        | -0.009254517 |
| serial_timesteps   | 60416        |
| time_elapsed       | 252          |
| total_timesteps    | 483328       |
| value_loss         | 0.09084431   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009440293  |
| clipfrac           | 0.1347168    |
| ep_len_mean        | 96.4         |
| ep_reward_mean     | -2.01        |
| explained_variance | 0.582        |
| fps                | 2168         |
| n_updates          | 237          |
| policy_entropy     | 6.3547792    |
| policy_loss        | -0.011758871 |
| serial_timesteps   | 60672        |
| time_elapsed       | 253          |
| total_timesteps    | 485376       |
| value_loss         | 0.06904178   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010309158  |
| clipfrac           | 0.14360352   |
| ep_len_mean        | 96.4         |
| ep_reward_mean     | -2.06        |
| explained_variance | 0.559        |
| fps                | 2106         |
| n_updates          | 238          |
| policy_entropy     | 6.3345494    |
| policy_loss        | -0.010513161 |
| serial_timesteps   | 60928        |
| time_elapsed       | 253          |
| total_timesteps    | 487424       |
| value_loss         | 0.08637167   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0089770695 |
| clipfrac           | 0.12924805   |
| ep_len_mean        | 97.1         |
| ep_reward_mean     | -2.07        |
| explained_variance | 0.674        |
| fps                | 2134         |
| n_updates          | 239          |
| policy_entropy     | 6.31337      |
| policy_loss        | -0.010380376 |
| serial_timesteps   | 61184        |
| time_elapsed       | 254          |
| total_timesteps    | 489472       |
| value_loss         | 0.050419103  |
-------------------------------------
Eval num_timesteps=490000, episode_reward=-1.57 +/- 0.01
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.009692507 |
| clipfrac           | 0.13745117  |
| ep_len_mean        | 97.1        |
| ep_reward_mean     | -2.03       |
| explained_variance | 0.658       |
| fps                | 1478        |
| n_updates          | 240         |
| policy_entropy     | 6.3094926   |
| policy_loss        | -0.009954   |
| serial_timesteps   | 61440       |
| time_elapsed       | 255         |
| total_timesteps    | 491520      |
| value_loss         | 0.05411885  |
------------------------------------
-------------------------------------
| approxkl           | 0.00929928   |
| clipfrac           | 0.13266602   |
| ep_len_mean        | 97.1         |
| ep_reward_mean     | -1.95        |
| explained_variance | 0.676        |
| fps                | 2161         |
| n_updates          | 241          |
| policy_entropy     | 6.308035     |
| policy_loss        | -0.011446776 |
| serial_timesteps   | 61696        |
| time_elapsed       | 257          |
| total_timesteps    | 493568       |
| value_loss         | 0.03565537   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010484296  |
| clipfrac           | 0.15683594   |
| ep_len_mean        | 97.1         |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.708        |
| fps                | 2130         |
| n_updates          | 242          |
| policy_entropy     | 6.2859273    |
| policy_loss        | -0.011068535 |
| serial_timesteps   | 61952        |
| time_elapsed       | 258          |
| total_timesteps    | 495616       |
| value_loss         | 0.037714936  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008997293  |
| clipfrac           | 0.12822266   |
| ep_len_mean        | 97.4         |
| ep_reward_mean     | -1.8         |
| explained_variance | 0.501        |
| fps                | 2102         |
| n_updates          | 243          |
| policy_entropy     | 6.27525      |
| policy_loss        | -0.011107752 |
| serial_timesteps   | 62208        |
| time_elapsed       | 259          |
| total_timesteps    | 497664       |
| value_loss         | 0.06865483   |
-------------------------------------
--------------------------------------
| approxkl           | 0.009450733   |
| clipfrac           | 0.13334961    |
| ep_len_mean        | 95.9          |
| ep_reward_mean     | -1.77         |
| explained_variance | 0.525         |
| fps                | 2056          |
| n_updates          | 244           |
| policy_entropy     | 6.2532096     |
| policy_loss        | -0.0107952645 |
| serial_timesteps   | 62464         |
| time_elapsed       | 260           |
| total_timesteps    | 499712        |
| value_loss         | 0.060333252   |
--------------------------------------
Eval num_timesteps=500000, episode_reward=-1.60 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008784715  |
| clipfrac           | 0.121679686  |
| ep_len_mean        | 95.9         |
| ep_reward_mean     | -1.75        |
| explained_variance | 0.726        |
| fps                | 1501         |
| n_updates          | 245          |
| policy_entropy     | 6.2488127    |
| policy_loss        | -0.010937209 |
| serial_timesteps   | 62720        |
| time_elapsed       | 261          |
| total_timesteps    | 501760       |
| value_loss         | 0.034586348  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00830832   |
| clipfrac           | 0.11630859   |
| ep_len_mean        | 95.3         |
| ep_reward_mean     | -1.76        |
| explained_variance | 0.684        |
| fps                | 2130         |
| n_updates          | 246          |
| policy_entropy     | 6.247785     |
| policy_loss        | -0.008906384 |
| serial_timesteps   | 62976        |
| time_elapsed       | 262          |
| total_timesteps    | 503808       |
| value_loss         | 0.03104189   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008119897  |
| clipfrac           | 0.111279294  |
| ep_len_mean        | 96.5         |
| ep_reward_mean     | -1.75        |
| explained_variance | 0.753        |
| fps                | 2104         |
| n_updates          | 247          |
| policy_entropy     | 6.2178206    |
| policy_loss        | -0.008971618 |
| serial_timesteps   | 63232        |
| time_elapsed       | 263          |
| total_timesteps    | 505856       |
| value_loss         | 0.025595853  |
-------------------------------------
-------------------------------------
| approxkl           | 0.007928314  |
| clipfrac           | 0.10527344   |
| ep_len_mean        | 97.2         |
| ep_reward_mean     | -1.75        |
| explained_variance | 0.573        |
| fps                | 2080         |
| n_updates          | 248          |
| policy_entropy     | 6.1972437    |
| policy_loss        | -0.010739224 |
| serial_timesteps   | 63488        |
| time_elapsed       | 264          |
| total_timesteps    | 507904       |
| value_loss         | 0.042375587  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009659624  |
| clipfrac           | 0.14155273   |
| ep_len_mean        | 98           |
| ep_reward_mean     | -1.77        |
| explained_variance | 0.732        |
| fps                | 2134         |
| n_updates          | 249          |
| policy_entropy     | 6.1899977    |
| policy_loss        | -0.009880456 |
| serial_timesteps   | 63744        |
| time_elapsed       | 265          |
| total_timesteps    | 509952       |
| value_loss         | 0.03274715   |
-------------------------------------
Eval num_timesteps=510000, episode_reward=-1.57 +/- 0.02
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.007819587   |
| clipfrac           | 0.10585938    |
| ep_len_mean        | 98.6          |
| ep_reward_mean     | -1.76         |
| explained_variance | 0.621         |
| fps                | 1504          |
| n_updates          | 250           |
| policy_entropy     | 6.1854124     |
| policy_loss        | -0.0059696734 |
| serial_timesteps   | 64000         |
| time_elapsed       | 266           |
| total_timesteps    | 512000        |
| value_loss         | 0.044700652   |
--------------------------------------
-------------------------------------
| approxkl           | 0.00985837   |
| clipfrac           | 0.14350586   |
| ep_len_mean        | 97.8         |
| ep_reward_mean     | -1.74        |
| explained_variance | 0.703        |
| fps                | 2110         |
| n_updates          | 251          |
| policy_entropy     | 6.183482     |
| policy_loss        | -0.012147345 |
| serial_timesteps   | 64256        |
| time_elapsed       | 267          |
| total_timesteps    | 514048       |
| value_loss         | 0.035958715  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008973899  |
| clipfrac           | 0.12524414   |
| ep_len_mean        | 97.8         |
| ep_reward_mean     | -1.75        |
| explained_variance | 0.651        |
| fps                | 2089         |
| n_updates          | 252          |
| policy_entropy     | 6.1432996    |
| policy_loss        | -0.011049985 |
| serial_timesteps   | 64512        |
| time_elapsed       | 268          |
| total_timesteps    | 516096       |
| value_loss         | 0.03465294   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009730901  |
| clipfrac           | 0.13564453   |
| ep_len_mean        | 96.4         |
| ep_reward_mean     | -1.69        |
| explained_variance | 0.609        |
| fps                | 2132         |
| n_updates          | 253          |
| policy_entropy     | 6.1079516    |
| policy_loss        | -0.009872811 |
| serial_timesteps   | 64768        |
| time_elapsed       | 269          |
| total_timesteps    | 518144       |
| value_loss         | 0.041954733  |
-------------------------------------
Eval num_timesteps=520000, episode_reward=-1.52 +/- 0.08
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008685782  |
| clipfrac           | 0.12597656   |
| ep_len_mean        | 95.7         |
| ep_reward_mean     | -1.72        |
| explained_variance | 0.538        |
| fps                | 1505         |
| n_updates          | 254          |
| policy_entropy     | 6.080158     |
| policy_loss        | -0.010372684 |
| serial_timesteps   | 65024        |
| time_elapsed       | 270          |
| total_timesteps    | 520192       |
| value_loss         | 0.058910973  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00891109   |
| clipfrac           | 0.12905273   |
| ep_len_mean        | 94.9         |
| ep_reward_mean     | -1.69        |
| explained_variance | 0.588        |
| fps                | 2115         |
| n_updates          | 255          |
| policy_entropy     | 6.0663137    |
| policy_loss        | -0.010170782 |
| serial_timesteps   | 65280        |
| time_elapsed       | 272          |
| total_timesteps    | 522240       |
| value_loss         | 0.04433671   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010728049  |
| clipfrac           | 0.15258789   |
| ep_len_mean        | 95.7         |
| ep_reward_mean     | -1.75        |
| explained_variance | 0.596        |
| fps                | 2136         |
| n_updates          | 256          |
| policy_entropy     | 6.082566     |
| policy_loss        | -0.012055091 |
| serial_timesteps   | 65536        |
| time_elapsed       | 273          |
| total_timesteps    | 524288       |
| value_loss         | 0.05032866   |
-------------------------------------
--------------------------------------
| approxkl           | 0.007942937   |
| clipfrac           | 0.10678711    |
| ep_len_mean        | 95            |
| ep_reward_mean     | -1.7          |
| explained_variance | 0.632         |
| fps                | 2128          |
| n_updates          | 257           |
| policy_entropy     | 6.093942      |
| policy_loss        | -0.0071542105 |
| serial_timesteps   | 65792         |
| time_elapsed       | 273           |
| total_timesteps    | 526336        |
| value_loss         | 0.03598501    |
--------------------------------------
-------------------------------------
| approxkl           | 0.008811127  |
| clipfrac           | 0.12207031   |
| ep_len_mean        | 96.4         |
| ep_reward_mean     | -1.73        |
| explained_variance | 0.671        |
| fps                | 2143         |
| n_updates          | 258          |
| policy_entropy     | 6.075834     |
| policy_loss        | -0.009738129 |
| serial_timesteps   | 66048        |
| time_elapsed       | 274          |
| total_timesteps    | 528384       |
| value_loss         | 0.031297274  |
-------------------------------------
Eval num_timesteps=530000, episode_reward=-0.96 +/- 0.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010320449  |
| clipfrac           | 0.1494629    |
| ep_len_mean        | 95.7         |
| ep_reward_mean     | -1.71        |
| explained_variance | 0.653        |
| fps                | 1508         |
| n_updates          | 259          |
| policy_entropy     | 6.0843935    |
| policy_loss        | -0.012803885 |
| serial_timesteps   | 66304        |
| time_elapsed       | 275          |
| total_timesteps    | 530432       |
| value_loss         | 0.043907695  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009853939  |
| clipfrac           | 0.13950196   |
| ep_len_mean        | 96.5         |
| ep_reward_mean     | -1.75        |
| explained_variance | 0.756        |
| fps                | 2137         |
| n_updates          | 260          |
| policy_entropy     | 6.1083255    |
| policy_loss        | -0.011747149 |
| serial_timesteps   | 66560        |
| time_elapsed       | 277          |
| total_timesteps    | 532480       |
| value_loss         | 0.029203255  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0080926595 |
| clipfrac           | 0.10410156   |
| ep_len_mean        | 95.7         |
| ep_reward_mean     | -1.72        |
| explained_variance | 0.64         |
| fps                | 2132         |
| n_updates          | 261          |
| policy_entropy     | 6.111639     |
| policy_loss        | -0.009367151 |
| serial_timesteps   | 66816        |
| time_elapsed       | 278          |
| total_timesteps    | 534528       |
| value_loss         | 0.043849006  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009803305  |
| clipfrac           | 0.14086914   |
| ep_len_mean        | 97.1         |
| ep_reward_mean     | -1.77        |
| explained_variance | 0.729        |
| fps                | 2119         |
| n_updates          | 262          |
| policy_entropy     | 6.097781     |
| policy_loss        | -0.012213497 |
| serial_timesteps   | 67072        |
| time_elapsed       | 279          |
| total_timesteps    | 536576       |
| value_loss         | 0.03033048   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010424778  |
| clipfrac           | 0.14882812   |
| ep_len_mean        | 96.4         |
| ep_reward_mean     | -1.79        |
| explained_variance | 0.693        |
| fps                | 2061         |
| n_updates          | 263          |
| policy_entropy     | 6.0712156    |
| policy_loss        | -0.011709409 |
| serial_timesteps   | 67328        |
| time_elapsed       | 280          |
| total_timesteps    | 538624       |
| value_loss         | 0.041743748  |
-------------------------------------
Eval num_timesteps=540000, episode_reward=-1.06 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009858134   |
| clipfrac           | 0.13759765    |
| ep_len_mean        | 97.8          |
| ep_reward_mean     | -1.81         |
| explained_variance | 0.715         |
| fps                | 1498          |
| n_updates          | 264           |
| policy_entropy     | 6.0361958     |
| policy_loss        | -0.0092615215 |
| serial_timesteps   | 67584         |
| time_elapsed       | 281           |
| total_timesteps    | 540672        |
| value_loss         | 0.03615345    |
--------------------------------------
--------------------------------------
| approxkl           | 0.0090803355  |
| clipfrac           | 0.13173828    |
| ep_len_mean        | 97            |
| ep_reward_mean     | -1.77         |
| explained_variance | 0.693         |
| fps                | 2126          |
| n_updates          | 265           |
| policy_entropy     | 5.9852448     |
| policy_loss        | -0.0109475935 |
| serial_timesteps   | 67840         |
| time_elapsed       | 282           |
| total_timesteps    | 542720        |
| value_loss         | 0.037456788   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010826549  |
| clipfrac           | 0.16357422   |
| ep_len_mean        | 97.1         |
| ep_reward_mean     | -1.78        |
| explained_variance | 0.667        |
| fps                | 2080         |
| n_updates          | 266          |
| policy_entropy     | 5.965068     |
| policy_loss        | -0.010535694 |
| serial_timesteps   | 68096        |
| time_elapsed       | 283          |
| total_timesteps    | 544768       |
| value_loss         | 0.031632278  |
-------------------------------------
-------------------------------------
| approxkl           | 0.01009991   |
| clipfrac           | 0.1480957    |
| ep_len_mean        | 97.1         |
| ep_reward_mean     | -1.77        |
| explained_variance | 0.739        |
| fps                | 2080         |
| n_updates          | 267          |
| policy_entropy     | 5.9419384    |
| policy_loss        | -0.009943947 |
| serial_timesteps   | 68352        |
| time_elapsed       | 284          |
| total_timesteps    | 546816       |
| value_loss         | 0.028068945  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009554266  |
| clipfrac           | 0.1381836    |
| ep_len_mean        | 97.1         |
| ep_reward_mean     | -1.77        |
| explained_variance | 0.695        |
| fps                | 2114         |
| n_updates          | 268          |
| policy_entropy     | 5.8919086    |
| policy_loss        | -0.012035531 |
| serial_timesteps   | 68608        |
| time_elapsed       | 285          |
| total_timesteps    | 548864       |
| value_loss         | 0.0291772    |
-------------------------------------
Eval num_timesteps=550000, episode_reward=-1.10 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.011274422  |
| clipfrac           | 0.16547851   |
| ep_len_mean        | 97.8         |
| ep_reward_mean     | -1.83        |
| explained_variance | 0.551        |
| fps                | 1502         |
| n_updates          | 269          |
| policy_entropy     | 5.890778     |
| policy_loss        | -0.014809156 |
| serial_timesteps   | 68864        |
| time_elapsed       | 286          |
| total_timesteps    | 550912       |
| value_loss         | 0.051474433  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0125782965 |
| clipfrac           | 0.17197266   |
| ep_len_mean        | 98.5         |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.49         |
| fps                | 2110         |
| n_updates          | 270          |
| policy_entropy     | 5.8970633    |
| policy_loss        | -0.016172204 |
| serial_timesteps   | 69120        |
| time_elapsed       | 287          |
| total_timesteps    | 552960       |
| value_loss         | 0.055544745  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008601639  |
| clipfrac           | 0.11899414   |
| ep_len_mean        | 98.5         |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.583        |
| fps                | 2044         |
| n_updates          | 271          |
| policy_entropy     | 5.8724885    |
| policy_loss        | -0.008641697 |
| serial_timesteps   | 69376        |
| time_elapsed       | 288          |
| total_timesteps    | 555008       |
| value_loss         | 0.04408241   |
-------------------------------------
--------------------------------------
| approxkl           | 0.009943467   |
| clipfrac           | 0.14057617    |
| ep_len_mean        | 98.5          |
| ep_reward_mean     | -1.93         |
| explained_variance | 0.563         |
| fps                | 2115          |
| n_updates          | 272           |
| policy_entropy     | 5.844449      |
| policy_loss        | -0.0065977364 |
| serial_timesteps   | 69632         |
| time_elapsed       | 289           |
| total_timesteps    | 557056        |
| value_loss         | 0.062063783   |
--------------------------------------
------------------------------------
| approxkl           | 0.008812797 |
| clipfrac           | 0.11723633  |
| ep_len_mean        | 98.5        |
| ep_reward_mean     | -1.98       |
| explained_variance | 0.511       |
| fps                | 2096        |
| n_updates          | 273         |
| policy_entropy     | 5.835677    |
| policy_loss        | -0.01012327 |
| serial_timesteps   | 69888       |
| time_elapsed       | 290         |
| total_timesteps    | 559104      |
| value_loss         | 0.060481377 |
------------------------------------
Eval num_timesteps=560000, episode_reward=-1.53 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.0104987165 |
| clipfrac           | 0.15043946   |
| ep_len_mean        | 97.8         |
| ep_reward_mean     | -1.96        |
| explained_variance | 0.633        |
| fps                | 1398         |
| n_updates          | 274          |
| policy_entropy     | 5.844458     |
| policy_loss        | -0.011914309 |
| serial_timesteps   | 70144        |
| time_elapsed       | 291          |
| total_timesteps    | 561152       |
| value_loss         | 0.046004586  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0097362455 |
| clipfrac           | 0.13398437   |
| ep_len_mean        | 97.8         |
| ep_reward_mean     | -1.95        |
| explained_variance | 0.666        |
| fps                | 2133         |
| n_updates          | 275          |
| policy_entropy     | 5.8199944    |
| policy_loss        | -0.010849084 |
| serial_timesteps   | 70400        |
| time_elapsed       | 293          |
| total_timesteps    | 563200       |
| value_loss         | 0.041843813  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010114188  |
| clipfrac           | 0.14082031   |
| ep_len_mean        | 97.8         |
| ep_reward_mean     | -1.95        |
| explained_variance | 0.669        |
| fps                | 2148         |
| n_updates          | 276          |
| policy_entropy     | 5.8001323    |
| policy_loss        | -0.008726585 |
| serial_timesteps   | 70656        |
| time_elapsed       | 294          |
| total_timesteps    | 565248       |
| value_loss         | 0.037609957  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009275243  |
| clipfrac           | 0.12958984   |
| ep_len_mean        | 97.8         |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.712        |
| fps                | 2109         |
| n_updates          | 277          |
| policy_entropy     | 5.8168674    |
| policy_loss        | -0.006956595 |
| serial_timesteps   | 70912        |
| time_elapsed       | 295          |
| total_timesteps    | 567296       |
| value_loss         | 0.03057482   |
-------------------------------------
-------------------------------------
| approxkl           | 0.01010783   |
| clipfrac           | 0.14418945   |
| ep_len_mean        | 98.6         |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.779        |
| fps                | 2085         |
| n_updates          | 278          |
| policy_entropy     | 5.8329763    |
| policy_loss        | -0.012317102 |
| serial_timesteps   | 71168        |
| time_elapsed       | 296          |
| total_timesteps    | 569344       |
| value_loss         | 0.026426742  |
-------------------------------------
Eval num_timesteps=570000, episode_reward=-1.56 +/- 0.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010484149  |
| clipfrac           | 0.14213867   |
| ep_len_mean        | 98.5         |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.555        |
| fps                | 1507         |
| n_updates          | 279          |
| policy_entropy     | 5.853728     |
| policy_loss        | -0.010183796 |
| serial_timesteps   | 71424        |
| time_elapsed       | 297          |
| total_timesteps    | 571392       |
| value_loss         | 0.06509189   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010186412  |
| clipfrac           | 0.14819336   |
| ep_len_mean        | 98.5         |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.669        |
| fps                | 2112         |
| n_updates          | 280          |
| policy_entropy     | 5.8675904    |
| policy_loss        | -0.010938426 |
| serial_timesteps   | 71680        |
| time_elapsed       | 298          |
| total_timesteps    | 573440       |
| value_loss         | 0.03665958   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009105003  |
| clipfrac           | 0.13022462   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.92        |
| explained_variance | 0.702        |
| fps                | 2109         |
| n_updates          | 281          |
| policy_entropy     | 5.890844     |
| policy_loss        | -0.009383512 |
| serial_timesteps   | 71936        |
| time_elapsed       | 299          |
| total_timesteps    | 575488       |
| value_loss         | 0.035384595  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00875409   |
| clipfrac           | 0.11298828   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.93        |
| explained_variance | 0.699        |
| fps                | 2074         |
| n_updates          | 282          |
| policy_entropy     | 5.91861      |
| policy_loss        | -0.010482046 |
| serial_timesteps   | 72192        |
| time_elapsed       | 300          |
| total_timesteps    | 577536       |
| value_loss         | 0.038094517  |
-------------------------------------
-------------------------------------
| approxkl           | 0.01038285   |
| clipfrac           | 0.13452148   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.98        |
| explained_variance | 0.668        |
| fps                | 2121         |
| n_updates          | 283          |
| policy_entropy     | 5.911729     |
| policy_loss        | -0.013030333 |
| serial_timesteps   | 72448        |
| time_elapsed       | 301          |
| total_timesteps    | 579584       |
| value_loss         | 0.043281797  |
-------------------------------------
Eval num_timesteps=580000, episode_reward=-1.25 +/- 0.19
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.01070801   |
| clipfrac           | 0.15864258   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.96        |
| explained_variance | 0.813        |
| fps                | 1411         |
| n_updates          | 284          |
| policy_entropy     | 5.887435     |
| policy_loss        | -0.012760003 |
| serial_timesteps   | 72704        |
| time_elapsed       | 302          |
| total_timesteps    | 581632       |
| value_loss         | 0.024406021  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010634133  |
| clipfrac           | 0.1540039    |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.729        |
| fps                | 2103         |
| n_updates          | 285          |
| policy_entropy     | 5.878681     |
| policy_loss        | -0.014615868 |
| serial_timesteps   | 72960        |
| time_elapsed       | 303          |
| total_timesteps    | 583680       |
| value_loss         | 0.033295702  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009228339  |
| clipfrac           | 0.13515624   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.737        |
| fps                | 2097         |
| n_updates          | 286          |
| policy_entropy     | 5.885242     |
| policy_loss        | -0.010270629 |
| serial_timesteps   | 73216        |
| time_elapsed       | 304          |
| total_timesteps    | 585728       |
| value_loss         | 0.030564034  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009317761  |
| clipfrac           | 0.12617187   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.81        |
| explained_variance | 0.744        |
| fps                | 2129         |
| n_updates          | 287          |
| policy_entropy     | 5.8732305    |
| policy_loss        | -0.010167571 |
| serial_timesteps   | 73472        |
| time_elapsed       | 305          |
| total_timesteps    | 587776       |
| value_loss         | 0.029131746  |
-------------------------------------
------------------------------------
| approxkl           | 0.010854995 |
| clipfrac           | 0.15302734  |
| ep_len_mean        | 99.3        |
| ep_reward_mean     | -1.83       |
| explained_variance | 0.627       |
| fps                | 2125        |
| n_updates          | 288         |
| policy_entropy     | 5.87894     |
| policy_loss        | -0.01008206 |
| serial_timesteps   | 73728       |
| time_elapsed       | 306         |
| total_timesteps    | 589824      |
| value_loss         | 0.04492066  |
------------------------------------
Eval num_timesteps=590000, episode_reward=-1.16 +/- 0.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009395737  |
| clipfrac           | 0.12983398   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.728        |
| fps                | 1492         |
| n_updates          | 289          |
| policy_entropy     | 5.874941     |
| policy_loss        | -0.008727727 |
| serial_timesteps   | 73984        |
| time_elapsed       | 307          |
| total_timesteps    | 591872       |
| value_loss         | 0.031254232  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009072902  |
| clipfrac           | 0.12749024   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.786        |
| fps                | 2100         |
| n_updates          | 290          |
| policy_entropy     | 5.8538785    |
| policy_loss        | -0.008332594 |
| serial_timesteps   | 74240        |
| time_elapsed       | 308          |
| total_timesteps    | 593920       |
| value_loss         | 0.026413519  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008766677  |
| clipfrac           | 0.1269043    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.76         |
| fps                | 2123         |
| n_updates          | 291          |
| policy_entropy     | 5.8380585    |
| policy_loss        | -0.009024506 |
| serial_timesteps   | 74496        |
| time_elapsed       | 309          |
| total_timesteps    | 595968       |
| value_loss         | 0.028820306  |
-------------------------------------
--------------------------------------
| approxkl           | 0.007777912   |
| clipfrac           | 0.101708986   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.93         |
| explained_variance | 0.76          |
| fps                | 2117          |
| n_updates          | 292           |
| policy_entropy     | 5.812949      |
| policy_loss        | -0.0064660385 |
| serial_timesteps   | 74752         |
| time_elapsed       | 310           |
| total_timesteps    | 598016        |
| value_loss         | 0.029498419   |
--------------------------------------
Eval num_timesteps=600000, episode_reward=-1.45 +/- 0.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009123482  |
| clipfrac           | 0.12416992   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.92        |
| explained_variance | 0.74         |
| fps                | 1489         |
| n_updates          | 293          |
| policy_entropy     | 5.7910147    |
| policy_loss        | -0.009211065 |
| serial_timesteps   | 75008        |
| time_elapsed       | 311          |
| total_timesteps    | 600064       |
| value_loss         | 0.031398658  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009552446  |
| clipfrac           | 0.13041992   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.729        |
| fps                | 2135         |
| n_updates          | 294          |
| policy_entropy     | 5.793742     |
| policy_loss        | -0.010272788 |
| serial_timesteps   | 75264        |
| time_elapsed       | 313          |
| total_timesteps    | 602112       |
| value_loss         | 0.034196563  |
-------------------------------------
-------------------------------------
| approxkl           | 0.00946808   |
| clipfrac           | 0.1315918    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.96        |
| explained_variance | 0.708        |
| fps                | 2118         |
| n_updates          | 295          |
| policy_entropy     | 5.806552     |
| policy_loss        | -0.009404316 |
| serial_timesteps   | 75520        |
| time_elapsed       | 314          |
| total_timesteps    | 604160       |
| value_loss         | 0.04134989   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009391082  |
| clipfrac           | 0.12792969   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.94        |
| explained_variance | 0.81         |
| fps                | 2113         |
| n_updates          | 296          |
| policy_entropy     | 5.8038034    |
| policy_loss        | -0.008924886 |
| serial_timesteps   | 75776        |
| time_elapsed       | 315          |
| total_timesteps    | 606208       |
| value_loss         | 0.024863493  |
-------------------------------------
-------------------------------------
| approxkl           | 0.011034665  |
| clipfrac           | 0.1605957    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.99        |
| explained_variance | 0.697        |
| fps                | 2108         |
| n_updates          | 297          |
| policy_entropy     | 5.7929606    |
| policy_loss        | -0.005113231 |
| serial_timesteps   | 76032        |
| time_elapsed       | 316          |
| total_timesteps    | 608256       |
| value_loss         | 0.044170342  |
-------------------------------------
Eval num_timesteps=610000, episode_reward=-1.70 +/- 0.03
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009532364   |
| clipfrac           | 0.13422851    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -2            |
| explained_variance | 0.668         |
| fps                | 1511          |
| n_updates          | 298           |
| policy_entropy     | 5.7909594     |
| policy_loss        | -0.0068254955 |
| serial_timesteps   | 76288         |
| time_elapsed       | 317           |
| total_timesteps    | 610304        |
| value_loss         | 0.03534436    |
--------------------------------------
-------------------------------------
| approxkl           | 0.008843678  |
| clipfrac           | 0.12177734   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.03        |
| explained_variance | 0.658        |
| fps                | 2120         |
| n_updates          | 299          |
| policy_entropy     | 5.794631     |
| policy_loss        | -0.006661228 |
| serial_timesteps   | 76544        |
| time_elapsed       | 318          |
| total_timesteps    | 612352       |
| value_loss         | 0.04766369   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010209117  |
| clipfrac           | 0.13862304   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.08        |
| explained_variance | 0.502        |
| fps                | 2073         |
| n_updates          | 300          |
| policy_entropy     | 5.8083086    |
| policy_loss        | -0.008524325 |
| serial_timesteps   | 76800        |
| time_elapsed       | 319          |
| total_timesteps    | 614400       |
| value_loss         | 0.07081871   |
-------------------------------------
------------------------------------
| approxkl           | 0.009874525 |
| clipfrac           | 0.13666992  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -2.06       |
| explained_variance | 0.688       |
| fps                | 2081        |
| n_updates          | 301         |
| policy_entropy     | 5.8040037   |
| policy_loss        | -0.0107964  |
| serial_timesteps   | 77056       |
| time_elapsed       | 320         |
| total_timesteps    | 616448      |
| value_loss         | 0.03347669  |
------------------------------------
-------------------------------------
| approxkl           | 0.011574478  |
| clipfrac           | 0.16870117   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.03        |
| explained_variance | 0.683        |
| fps                | 2116         |
| n_updates          | 302          |
| policy_entropy     | 5.75879      |
| policy_loss        | -0.013423398 |
| serial_timesteps   | 77312        |
| time_elapsed       | 321          |
| total_timesteps    | 618496       |
| value_loss         | 0.03734818   |
-------------------------------------
Eval num_timesteps=620000, episode_reward=-1.94 +/- 0.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.008812578  |
| clipfrac           | 0.121191405  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.97        |
| explained_variance | 0.749        |
| fps                | 1482         |
| n_updates          | 303          |
| policy_entropy     | 5.7086406    |
| policy_loss        | -0.005208374 |
| serial_timesteps   | 77568        |
| time_elapsed       | 322          |
| total_timesteps    | 620544       |
| value_loss         | 0.029659022  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010834357  |
| clipfrac           | 0.15517578   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.96        |
| explained_variance | 0.744        |
| fps                | 2088         |
| n_updates          | 304          |
| policy_entropy     | 5.6906877    |
| policy_loss        | -0.009994233 |
| serial_timesteps   | 77824        |
| time_elapsed       | 323          |
| total_timesteps    | 622592       |
| value_loss         | 0.035769347  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008204626   |
| clipfrac           | 0.11279297    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.9          |
| explained_variance | 0.71          |
| fps                | 2119          |
| n_updates          | 305           |
| policy_entropy     | 5.668111      |
| policy_loss        | -0.0053839507 |
| serial_timesteps   | 78080         |
| time_elapsed       | 324           |
| total_timesteps    | 624640        |
| value_loss         | 0.03258259    |
--------------------------------------
--------------------------------------
| approxkl           | 0.0074698245  |
| clipfrac           | 0.099609375   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.92         |
| explained_variance | 0.708         |
| fps                | 2119          |
| n_updates          | 306           |
| policy_entropy     | 5.6778936     |
| policy_loss        | -0.0064899474 |
| serial_timesteps   | 78336         |
| time_elapsed       | 325           |
| total_timesteps    | 626688        |
| value_loss         | 0.038569905   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009925807  |
| clipfrac           | 0.14506836   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.743        |
| fps                | 2099         |
| n_updates          | 307          |
| policy_entropy     | 5.6850214    |
| policy_loss        | -0.009433084 |
| serial_timesteps   | 78592        |
| time_elapsed       | 326          |
| total_timesteps    | 628736       |
| value_loss         | 0.029579842  |
-------------------------------------
Eval num_timesteps=630000, episode_reward=-1.87 +/- 0.03
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010917537  |
| clipfrac           | 0.14399414   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.708        |
| fps                | 1451         |
| n_updates          | 308          |
| policy_entropy     | 5.6595583    |
| policy_loss        | -0.012637159 |
| serial_timesteps   | 78848        |
| time_elapsed       | 327          |
| total_timesteps    | 630784       |
| value_loss         | 0.035330556  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010487987  |
| clipfrac           | 0.14199218   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.92        |
| explained_variance | 0.704        |
| fps                | 2089         |
| n_updates          | 309          |
| policy_entropy     | 5.641774     |
| policy_loss        | -0.010350151 |
| serial_timesteps   | 79104        |
| time_elapsed       | 329          |
| total_timesteps    | 632832       |
| value_loss         | 0.03558908   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00985175   |
| clipfrac           | 0.14340821   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.774        |
| fps                | 2097         |
| n_updates          | 310          |
| policy_entropy     | 5.6039476    |
| policy_loss        | -0.010843153 |
| serial_timesteps   | 79360        |
| time_elapsed       | 330          |
| total_timesteps    | 634880       |
| value_loss         | 0.028001975  |
-------------------------------------
--------------------------------------
| approxkl           | 0.011268693   |
| clipfrac           | 0.16069336    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.9          |
| explained_variance | 0.744         |
| fps                | 2001          |
| n_updates          | 311           |
| policy_entropy     | 5.5771728     |
| policy_loss        | -0.0121720545 |
| serial_timesteps   | 79616         |
| time_elapsed       | 331           |
| total_timesteps    | 636928        |
| value_loss         | 0.03200963    |
--------------------------------------
--------------------------------------
| approxkl           | 0.010588713   |
| clipfrac           | 0.15244141    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.89         |
| explained_variance | 0.75          |
| fps                | 2060          |
| n_updates          | 312           |
| policy_entropy     | 5.5503855     |
| policy_loss        | -0.0095670875 |
| serial_timesteps   | 79872         |
| time_elapsed       | 332           |
| total_timesteps    | 638976        |
| value_loss         | 0.033592306   |
--------------------------------------
Eval num_timesteps=640000, episode_reward=-1.93 +/- 0.01
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010060997   |
| clipfrac           | 0.1373047     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.9          |
| explained_variance | 0.792         |
| fps                | 1490          |
| n_updates          | 313           |
| policy_entropy     | 5.5306764     |
| policy_loss        | -0.0071065784 |
| serial_timesteps   | 80128         |
| time_elapsed       | 333           |
| total_timesteps    | 641024        |
| value_loss         | 0.030922461   |
--------------------------------------
--------------------------------------
| approxkl           | 0.009827958   |
| clipfrac           | 0.13457032    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.88         |
| explained_variance | 0.646         |
| fps                | 2008          |
| n_updates          | 314           |
| policy_entropy     | 5.529796      |
| policy_loss        | -0.0070043607 |
| serial_timesteps   | 80384         |
| time_elapsed       | 334           |
| total_timesteps    | 643072        |
| value_loss         | 0.041628484   |
--------------------------------------
-------------------------------------
| approxkl           | 0.012206388  |
| clipfrac           | 0.16123047   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.757        |
| fps                | 2087         |
| n_updates          | 315          |
| policy_entropy     | 5.5206904    |
| policy_loss        | -0.012962731 |
| serial_timesteps   | 80640        |
| time_elapsed       | 335          |
| total_timesteps    | 645120       |
| value_loss         | 0.032843895  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009635268  |
| clipfrac           | 0.14208984   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.694        |
| fps                | 2065         |
| n_updates          | 316          |
| policy_entropy     | 5.504522     |
| policy_loss        | -0.009723123 |
| serial_timesteps   | 80896        |
| time_elapsed       | 336          |
| total_timesteps    | 647168       |
| value_loss         | 0.033549912  |
-------------------------------------
--------------------------------------
| approxkl           | 0.010935988   |
| clipfrac           | 0.15927735    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.89         |
| explained_variance | 0.644         |
| fps                | 2121          |
| n_updates          | 317           |
| policy_entropy     | 5.4966264     |
| policy_loss        | -0.0076790117 |
| serial_timesteps   | 81152         |
| time_elapsed       | 337           |
| total_timesteps    | 649216        |
| value_loss         | 0.04536021    |
--------------------------------------
Eval num_timesteps=650000, episode_reward=-2.18 +/- 0.09
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.008910922   |
| clipfrac           | 0.12416992    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.94         |
| explained_variance | 0.62          |
| fps                | 1476          |
| n_updates          | 318           |
| policy_entropy     | 5.479598      |
| policy_loss        | -0.0070219142 |
| serial_timesteps   | 81408         |
| time_elapsed       | 338           |
| total_timesteps    | 651264        |
| value_loss         | 0.04205989    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0107820975 |
| clipfrac           | 0.1552246    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.92        |
| explained_variance | 0.642        |
| fps                | 2064         |
| n_updates          | 319          |
| policy_entropy     | 5.4615927    |
| policy_loss        | -0.007637589 |
| serial_timesteps   | 81664        |
| time_elapsed       | 339          |
| total_timesteps    | 653312       |
| value_loss         | 0.04234972   |
-------------------------------------
-------------------------------------
| approxkl           | 0.011803095  |
| clipfrac           | 0.16049805   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.97        |
| explained_variance | 0.61         |
| fps                | 2119         |
| n_updates          | 320          |
| policy_entropy     | 5.43678      |
| policy_loss        | -0.013146003 |
| serial_timesteps   | 81920        |
| time_elapsed       | 340          |
| total_timesteps    | 655360       |
| value_loss         | 0.050913014  |
-------------------------------------
-------------------------------------
| approxkl           | 0.008821236  |
| clipfrac           | 0.119580075  |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.96        |
| explained_variance | 0.682        |
| fps                | 2132         |
| n_updates          | 321          |
| policy_entropy     | 5.417584     |
| policy_loss        | -0.007856788 |
| serial_timesteps   | 82176        |
| time_elapsed       | 341          |
| total_timesteps    | 657408       |
| value_loss         | 0.0400381    |
-------------------------------------
------------------------------------
| approxkl           | 0.011053296 |
| clipfrac           | 0.1619629   |
| ep_len_mean        | 100         |
| ep_reward_mean     | -2.01       |
| explained_variance | 0.68        |
| fps                | 2128        |
| n_updates          | 322         |
| policy_entropy     | 5.3829007   |
| policy_loss        | -0.00977594 |
| serial_timesteps   | 82432       |
| time_elapsed       | 342         |
| total_timesteps    | 659456      |
| value_loss         | 0.04375674  |
------------------------------------
Eval num_timesteps=660000, episode_reward=-1.93 +/- 0.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010540329  |
| clipfrac           | 0.1494629    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.02        |
| explained_variance | 0.531        |
| fps                | 1399         |
| n_updates          | 323          |
| policy_entropy     | 5.3508773    |
| policy_loss        | -0.008702181 |
| serial_timesteps   | 82688        |
| time_elapsed       | 343          |
| total_timesteps    | 661504       |
| value_loss         | 0.06317228   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010453475  |
| clipfrac           | 0.1503418    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.06        |
| explained_variance | 0.592        |
| fps                | 2102         |
| n_updates          | 324          |
| policy_entropy     | 5.365072     |
| policy_loss        | -0.011593835 |
| serial_timesteps   | 82944        |
| time_elapsed       | 345          |
| total_timesteps    | 663552       |
| value_loss         | 0.058547072  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009663189  |
| clipfrac           | 0.13798828   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.16        |
| explained_variance | 0.564        |
| fps                | 2101         |
| n_updates          | 325          |
| policy_entropy     | 5.403991     |
| policy_loss        | -0.008912661 |
| serial_timesteps   | 83200        |
| time_elapsed       | 346          |
| total_timesteps    | 665600       |
| value_loss         | 0.061674297  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008541622   |
| clipfrac           | 0.11767578    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -2.17         |
| explained_variance | 0.569         |
| fps                | 2150          |
| n_updates          | 326           |
| policy_entropy     | 5.424798      |
| policy_loss        | -0.0039926507 |
| serial_timesteps   | 83456         |
| time_elapsed       | 347           |
| total_timesteps    | 667648        |
| value_loss         | 0.07828745    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0092068445 |
| clipfrac           | 0.12270508   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.25        |
| explained_variance | 0.578        |
| fps                | 2112         |
| n_updates          | 327          |
| policy_entropy     | 5.401696     |
| policy_loss        | -0.003085134 |
| serial_timesteps   | 83712        |
| time_elapsed       | 348          |
| total_timesteps    | 669696       |
| value_loss         | 0.08567901   |
-------------------------------------
Eval num_timesteps=670000, episode_reward=-2.23 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009803862  |
| clipfrac           | 0.13999024   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.22        |
| explained_variance | 0.634        |
| fps                | 1493         |
| n_updates          | 328          |
| policy_entropy     | 5.3694487    |
| policy_loss        | -0.008655114 |
| serial_timesteps   | 83968        |
| time_elapsed       | 348          |
| total_timesteps    | 671744       |
| value_loss         | 0.06979151   |
-------------------------------------
--------------------------------------
| approxkl           | 0.01050101    |
| clipfrac           | 0.15205078    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -2.29         |
| explained_variance | 0.581         |
| fps                | 2127          |
| n_updates          | 329           |
| policy_entropy     | 5.352532      |
| policy_loss        | -0.0061731124 |
| serial_timesteps   | 84224         |
| time_elapsed       | 350           |
| total_timesteps    | 673792        |
| value_loss         | 0.09863374    |
--------------------------------------
--------------------------------------
| approxkl           | 0.009719865   |
| clipfrac           | 0.13535157    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -2.29         |
| explained_variance | 0.669         |
| fps                | 2146          |
| n_updates          | 330           |
| policy_entropy     | 5.3675337     |
| policy_loss        | -0.0054459297 |
| serial_timesteps   | 84480         |
| time_elapsed       | 351           |
| total_timesteps    | 675840        |
| value_loss         | 0.07068545    |
--------------------------------------
-------------------------------------
| approxkl           | 0.012672481  |
| clipfrac           | 0.18388672   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.33        |
| explained_variance | 0.655        |
| fps                | 2101         |
| n_updates          | 331          |
| policy_entropy     | 5.3689766    |
| policy_loss        | -0.009639967 |
| serial_timesteps   | 84736        |
| time_elapsed       | 352          |
| total_timesteps    | 677888       |
| value_loss         | 0.08218266   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00896881   |
| clipfrac           | 0.12148438   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.29        |
| explained_variance | 0.587        |
| fps                | 2156         |
| n_updates          | 332          |
| policy_entropy     | 5.3472457    |
| policy_loss        | -0.002906211 |
| serial_timesteps   | 84992        |
| time_elapsed       | 353          |
| total_timesteps    | 679936       |
| value_loss         | 0.080670886  |
-------------------------------------
Eval num_timesteps=680000, episode_reward=-2.00 +/- 0.04
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.013388713  |
| clipfrac           | 0.20463867   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.24        |
| explained_variance | 0.682        |
| fps                | 1500         |
| n_updates          | 333          |
| policy_entropy     | 5.33173      |
| policy_loss        | -0.014377768 |
| serial_timesteps   | 85248        |
| time_elapsed       | 354          |
| total_timesteps    | 681984       |
| value_loss         | 0.06229205   |
-------------------------------------
-------------------------------------
| approxkl           | 0.011924672  |
| clipfrac           | 0.17802735   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.21        |
| explained_variance | 0.635        |
| fps                | 2085         |
| n_updates          | 334          |
| policy_entropy     | 5.325349     |
| policy_loss        | -0.010326604 |
| serial_timesteps   | 85504        |
| time_elapsed       | 355          |
| total_timesteps    | 684032       |
| value_loss         | 0.047159985  |
-------------------------------------
-------------------------------------
| approxkl           | 0.011068566  |
| clipfrac           | 0.1586914    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.11        |
| explained_variance | 0.69         |
| fps                | 2077         |
| n_updates          | 335          |
| policy_entropy     | 5.3270693    |
| policy_loss        | -0.008946916 |
| serial_timesteps   | 85760        |
| time_elapsed       | 356          |
| total_timesteps    | 686080       |
| value_loss         | 0.038899735  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009876019  |
| clipfrac           | 0.14140625   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -2.06        |
| explained_variance | 0.74         |
| fps                | 2107         |
| n_updates          | 336          |
| policy_entropy     | 5.3350315    |
| policy_loss        | -0.007873854 |
| serial_timesteps   | 86016        |
| time_elapsed       | 357          |
| total_timesteps    | 688128       |
| value_loss         | 0.033337615  |
-------------------------------------
Eval num_timesteps=690000, episode_reward=-1.82 +/- 0.02
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.008330294 |
| clipfrac           | 0.11308594  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.97       |
| explained_variance | 0.725       |
| fps                | 1503        |
| n_updates          | 337         |
| policy_entropy     | 5.3433194   |
| policy_loss        | -0.00390587 |
| serial_timesteps   | 86272       |
| time_elapsed       | 358         |
| total_timesteps    | 690176      |
| value_loss         | 0.034072764 |
------------------------------------
-------------------------------------
| approxkl           | 0.009482069  |
| clipfrac           | 0.13198242   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.97        |
| explained_variance | 0.714        |
| fps                | 2105         |
| n_updates          | 338          |
| policy_entropy     | 5.3261166    |
| policy_loss        | -0.006350927 |
| serial_timesteps   | 86528        |
| time_elapsed       | 359          |
| total_timesteps    | 692224       |
| value_loss         | 0.04102855   |
-------------------------------------
-------------------------------------
| approxkl           | 0.011398157  |
| clipfrac           | 0.16430664   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.93        |
| explained_variance | 0.739        |
| fps                | 2117         |
| n_updates          | 339          |
| policy_entropy     | 5.307997     |
| policy_loss        | -0.011751382 |
| serial_timesteps   | 86784        |
| time_elapsed       | 360          |
| total_timesteps    | 694272       |
| value_loss         | 0.03886723   |
-------------------------------------
--------------------------------------
| approxkl           | 0.010770812   |
| clipfrac           | 0.15649414    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.95         |
| explained_variance | 0.792         |
| fps                | 2102          |
| n_updates          | 340           |
| policy_entropy     | 5.3050084     |
| policy_loss        | -0.0070553906 |
| serial_timesteps   | 87040         |
| time_elapsed       | 361           |
| total_timesteps    | 696320        |
| value_loss         | 0.028814027   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010068605   |
| clipfrac           | 0.14018555    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.93         |
| explained_variance | 0.74          |
| fps                | 2073          |
| n_updates          | 341           |
| policy_entropy     | 5.285184      |
| policy_loss        | -0.0065870606 |
| serial_timesteps   | 87296         |
| time_elapsed       | 362           |
| total_timesteps    | 698368        |
| value_loss         | 0.03268074    |
--------------------------------------
Eval num_timesteps=700000, episode_reward=-1.85 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010579928  |
| clipfrac           | 0.1541504    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.93        |
| explained_variance | 0.759        |
| fps                | 1487         |
| n_updates          | 342          |
| policy_entropy     | 5.277953     |
| policy_loss        | -0.008618287 |
| serial_timesteps   | 87552        |
| time_elapsed       | 363          |
| total_timesteps    | 700416       |
| value_loss         | 0.03319789   |
-------------------------------------
--------------------------------------
| approxkl           | 0.009627443   |
| clipfrac           | 0.13310547    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.93         |
| explained_variance | 0.722         |
| fps                | 2124          |
| n_updates          | 343           |
| policy_entropy     | 5.2530885     |
| policy_loss        | -0.0062624663 |
| serial_timesteps   | 87808         |
| time_elapsed       | 365           |
| total_timesteps    | 702464        |
| value_loss         | 0.036151517   |
--------------------------------------
--------------------------------------
| approxkl           | 0.009405149   |
| clipfrac           | 0.13271484    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.89         |
| explained_variance | 0.775         |
| fps                | 2124          |
| n_updates          | 344           |
| policy_entropy     | 5.2239165     |
| policy_loss        | -0.0025669043 |
| serial_timesteps   | 88064         |
| time_elapsed       | 366           |
| total_timesteps    | 704512        |
| value_loss         | 0.030374724   |
--------------------------------------
--------------------------------------
| approxkl           | 0.008094749   |
| clipfrac           | 0.10898437    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.91         |
| explained_variance | 0.8           |
| fps                | 2123          |
| n_updates          | 345           |
| policy_entropy     | 5.2280707     |
| policy_loss        | -0.0018020484 |
| serial_timesteps   | 88320         |
| time_elapsed       | 367           |
| total_timesteps    | 706560        |
| value_loss         | 0.029504973   |
--------------------------------------
-------------------------------------
| approxkl           | 0.00843643   |
| clipfrac           | 0.11713867   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.759        |
| fps                | 2080         |
| n_updates          | 346          |
| policy_entropy     | 5.239059     |
| policy_loss        | -0.002593703 |
| serial_timesteps   | 88576        |
| time_elapsed       | 368          |
| total_timesteps    | 708608       |
| value_loss         | 0.03222719   |
-------------------------------------
Eval num_timesteps=710000, episode_reward=-1.74 +/- 0.02
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010388335   |
| clipfrac           | 0.14770508    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.9          |
| explained_variance | 0.777         |
| fps                | 1474          |
| n_updates          | 347           |
| policy_entropy     | 5.2546663     |
| policy_loss        | -0.0070482595 |
| serial_timesteps   | 88832         |
| time_elapsed       | 369           |
| total_timesteps    | 710656        |
| value_loss         | 0.03186125    |
--------------------------------------
------------------------------------
| approxkl           | 0.009910288 |
| clipfrac           | 0.13579102  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.87       |
| explained_variance | 0.765       |
| fps                | 2096        |
| n_updates          | 348         |
| policy_entropy     | 5.2433925   |
| policy_loss        | -0.00590494 |
| serial_timesteps   | 89088       |
| time_elapsed       | 370         |
| total_timesteps    | 712704      |
| value_loss         | 0.03136998  |
------------------------------------
--------------------------------------
| approxkl           | 0.009576126   |
| clipfrac           | 0.13496093    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.87         |
| explained_variance | 0.783         |
| fps                | 2088          |
| n_updates          | 349           |
| policy_entropy     | 5.2168646     |
| policy_loss        | -0.0062082806 |
| serial_timesteps   | 89344         |
| time_elapsed       | 371           |
| total_timesteps    | 714752        |
| value_loss         | 0.030015057   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010488354  |
| clipfrac           | 0.15517578   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.795        |
| fps                | 2055         |
| n_updates          | 350          |
| policy_entropy     | 5.211915     |
| policy_loss        | -0.011785775 |
| serial_timesteps   | 89600        |
| time_elapsed       | 372          |
| total_timesteps    | 716800       |
| value_loss         | 0.028719146  |
-------------------------------------
--------------------------------------
| approxkl           | 0.011005597   |
| clipfrac           | 0.15986328    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.85         |
| explained_variance | 0.818         |
| fps                | 2108          |
| n_updates          | 351           |
| policy_entropy     | 5.2204905     |
| policy_loss        | -0.0077163414 |
| serial_timesteps   | 89856         |
| time_elapsed       | 373           |
| total_timesteps    | 718848        |
| value_loss         | 0.027655762   |
--------------------------------------
Eval num_timesteps=720000, episode_reward=-1.70 +/- 0.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009951119  |
| clipfrac           | 0.1395996    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.8          |
| fps                | 1477         |
| n_updates          | 352          |
| policy_entropy     | 5.195588     |
| policy_loss        | -0.008262265 |
| serial_timesteps   | 90112        |
| time_elapsed       | 374          |
| total_timesteps    | 720896       |
| value_loss         | 0.02728399   |
-------------------------------------
--------------------------------------
| approxkl           | 0.009369503   |
| clipfrac           | 0.13544922    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.86         |
| explained_variance | 0.792         |
| fps                | 2117          |
| n_updates          | 353           |
| policy_entropy     | 5.1767387     |
| policy_loss        | -0.0049440893 |
| serial_timesteps   | 90368         |
| time_elapsed       | 375           |
| total_timesteps    | 722944        |
| value_loss         | 0.028514078   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010028377  |
| clipfrac           | 0.14462891   |
| ep_len_mean        | 98.5         |
| ep_reward_mean     | -1.84        |
| explained_variance | 0.761        |
| fps                | 2091         |
| n_updates          | 354          |
| policy_entropy     | 5.185217     |
| policy_loss        | -0.008232666 |
| serial_timesteps   | 90624        |
| time_elapsed       | 376          |
| total_timesteps    | 724992       |
| value_loss         | 0.037030917  |
-------------------------------------
------------------------------------
| approxkl           | 0.010184366 |
| clipfrac           | 0.14443359  |
| ep_len_mean        | 98.5        |
| ep_reward_mean     | -1.83       |
| explained_variance | 0.785       |
| fps                | 2130        |
| n_updates          | 355         |
| policy_entropy     | 5.1902113   |
| policy_loss        | -0.0084552  |
| serial_timesteps   | 90880       |
| time_elapsed       | 377         |
| total_timesteps    | 727040      |
| value_loss         | 0.02886338  |
------------------------------------
-------------------------------------
| approxkl           | 0.0105689    |
| clipfrac           | 0.15332031   |
| ep_len_mean        | 98.5         |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.809        |
| fps                | 2117         |
| n_updates          | 356          |
| policy_entropy     | 5.177431     |
| policy_loss        | -0.009385517 |
| serial_timesteps   | 91136        |
| time_elapsed       | 378          |
| total_timesteps    | 729088       |
| value_loss         | 0.029253116  |
-------------------------------------
Eval num_timesteps=730000, episode_reward=-1.63 +/- 0.03
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.010475786  |
| clipfrac           | 0.14350586   |
| ep_len_mean        | 98.5         |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.829        |
| fps                | 1482         |
| n_updates          | 357          |
| policy_entropy     | 5.1517267    |
| policy_loss        | -0.007904022 |
| serial_timesteps   | 91392        |
| time_elapsed       | 379          |
| total_timesteps    | 731136       |
| value_loss         | 0.026021693  |
-------------------------------------
-------------------------------------
| approxkl           | 0.011045744  |
| clipfrac           | 0.16206054   |
| ep_len_mean        | 99.3         |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.844        |
| fps                | 2100         |
| n_updates          | 358          |
| policy_entropy     | 5.1371503    |
| policy_loss        | -0.009555978 |
| serial_timesteps   | 91648        |
| time_elapsed       | 380          |
| total_timesteps    | 733184       |
| value_loss         | 0.025283992  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009802863   |
| clipfrac           | 0.14174804    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.86         |
| explained_variance | 0.837         |
| fps                | 2135          |
| n_updates          | 359           |
| policy_entropy     | 5.1289077     |
| policy_loss        | -0.0059359777 |
| serial_timesteps   | 91904         |
| time_elapsed       | 381           |
| total_timesteps    | 735232        |
| value_loss         | 0.024244068   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0097289225 |
| clipfrac           | 0.13642578   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.832        |
| fps                | 2139         |
| n_updates          | 360          |
| policy_entropy     | 5.103014     |
| policy_loss        | -0.006138234 |
| serial_timesteps   | 92160        |
| time_elapsed       | 382          |
| total_timesteps    | 737280       |
| value_loss         | 0.025294203  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009413858  |
| clipfrac           | 0.13422851   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.84        |
| explained_variance | 0.82         |
| fps                | 2102         |
| n_updates          | 361          |
| policy_entropy     | 5.0771894    |
| policy_loss        | -0.004741286 |
| serial_timesteps   | 92416        |
| time_elapsed       | 383          |
| total_timesteps    | 739328       |
| value_loss         | 0.026400581  |
-------------------------------------
Eval num_timesteps=740000, episode_reward=-1.57 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.011257472  |
| clipfrac           | 0.16269532   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.838        |
| fps                | 1514         |
| n_updates          | 362          |
| policy_entropy     | 5.0696774    |
| policy_loss        | -0.009679871 |
| serial_timesteps   | 92672        |
| time_elapsed       | 384          |
| total_timesteps    | 741376       |
| value_loss         | 0.02280142   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010944354  |
| clipfrac           | 0.15976563   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.814        |
| fps                | 2140         |
| n_updates          | 363          |
| policy_entropy     | 5.0501747    |
| policy_loss        | -0.010029385 |
| serial_timesteps   | 92928        |
| time_elapsed       | 386          |
| total_timesteps    | 743424       |
| value_loss         | 0.026792387  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009647014   |
| clipfrac           | 0.13354492    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.86         |
| explained_variance | 0.817         |
| fps                | 2043          |
| n_updates          | 364           |
| policy_entropy     | 5.000512      |
| policy_loss        | -0.0073565594 |
| serial_timesteps   | 93184         |
| time_elapsed       | 387           |
| total_timesteps    | 745472        |
| value_loss         | 0.024215873   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010671148  |
| clipfrac           | 0.1571289    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.844        |
| fps                | 2083         |
| n_updates          | 365          |
| policy_entropy     | 4.97362      |
| policy_loss        | -0.008069705 |
| serial_timesteps   | 93440        |
| time_elapsed       | 388          |
| total_timesteps    | 747520       |
| value_loss         | 0.025875863  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009972802  |
| clipfrac           | 0.14223632   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.831        |
| fps                | 2121         |
| n_updates          | 366          |
| policy_entropy     | 4.9640756    |
| policy_loss        | -0.008772904 |
| serial_timesteps   | 93696        |
| time_elapsed       | 389          |
| total_timesteps    | 749568       |
| value_loss         | 0.026661688  |
-------------------------------------
Eval num_timesteps=750000, episode_reward=-1.54 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.011097178  |
| clipfrac           | 0.16430664   |
| ep_len_mean        | 99.2         |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.799        |
| fps                | 1491         |
| n_updates          | 367          |
| policy_entropy     | 4.942834     |
| policy_loss        | -0.011494653 |
| serial_timesteps   | 93952        |
| time_elapsed       | 390          |
| total_timesteps    | 751616       |
| value_loss         | 0.031940006  |
-------------------------------------
--------------------------------------
| approxkl           | 0.010102207   |
| clipfrac           | 0.14423828    |
| ep_len_mean        | 99.2          |
| ep_reward_mean     | -1.85         |
| explained_variance | 0.837         |
| fps                | 2109          |
| n_updates          | 368           |
| policy_entropy     | 4.9305515     |
| policy_loss        | -0.0057566483 |
| serial_timesteps   | 94208         |
| time_elapsed       | 391           |
| total_timesteps    | 753664        |
| value_loss         | 0.02531367    |
--------------------------------------
-------------------------------------
| approxkl           | 0.011050512  |
| clipfrac           | 0.16166992   |
| ep_len_mean        | 99.2         |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.793        |
| fps                | 2100         |
| n_updates          | 369          |
| policy_entropy     | 4.9399977    |
| policy_loss        | -0.011147646 |
| serial_timesteps   | 94464        |
| time_elapsed       | 392          |
| total_timesteps    | 755712       |
| value_loss         | 0.02718608   |
-------------------------------------
--------------------------------------
| approxkl           | 0.009418076   |
| clipfrac           | 0.13237305    |
| ep_len_mean        | 99.2          |
| ep_reward_mean     | -1.85         |
| explained_variance | 0.851         |
| fps                | 2143          |
| n_updates          | 370           |
| policy_entropy     | 4.9397364     |
| policy_loss        | -0.0066785775 |
| serial_timesteps   | 94720         |
| time_elapsed       | 393           |
| total_timesteps    | 757760        |
| value_loss         | 0.024462886   |
--------------------------------------
-------------------------------------
| approxkl           | 0.01049343   |
| clipfrac           | 0.1474121    |
| ep_len_mean        | 99.2         |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.847        |
| fps                | 2152         |
| n_updates          | 371          |
| policy_entropy     | 4.9134994    |
| policy_loss        | -0.008902324 |
| serial_timesteps   | 94976        |
| time_elapsed       | 394          |
| total_timesteps    | 759808       |
| value_loss         | 0.023142595  |
-------------------------------------
Eval num_timesteps=760000, episode_reward=-1.34 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010176933   |
| clipfrac           | 0.14799805    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.86         |
| explained_variance | 0.863         |
| fps                | 1486          |
| n_updates          | 372           |
| policy_entropy     | 4.89663       |
| policy_loss        | -0.0058413004 |
| serial_timesteps   | 95232         |
| time_elapsed       | 395           |
| total_timesteps    | 761856        |
| value_loss         | 0.024055272   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009306288  |
| clipfrac           | 0.1305664    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.839        |
| fps                | 2148         |
| n_updates          | 373          |
| policy_entropy     | 4.9042425    |
| policy_loss        | -0.006125147 |
| serial_timesteps   | 95488        |
| time_elapsed       | 396          |
| total_timesteps    | 763904       |
| value_loss         | 0.02394556   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010320477  |
| clipfrac           | 0.15366212   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.86         |
| fps                | 2163         |
| n_updates          | 374          |
| policy_entropy     | 4.8789396    |
| policy_loss        | -0.007820119 |
| serial_timesteps   | 95744        |
| time_elapsed       | 397          |
| total_timesteps    | 765952       |
| value_loss         | 0.024414912  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0096435    |
| clipfrac           | 0.13481446   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.854        |
| fps                | 2154         |
| n_updates          | 375          |
| policy_entropy     | 4.830337     |
| policy_loss        | -0.007179571 |
| serial_timesteps   | 96000        |
| time_elapsed       | 398          |
| total_timesteps    | 768000       |
| value_loss         | 0.024850339  |
-------------------------------------
Eval num_timesteps=770000, episode_reward=-1.36 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.011855638  |
| clipfrac           | 0.17392579   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.86         |
| fps                | 1504         |
| n_updates          | 376          |
| policy_entropy     | 4.7962027    |
| policy_loss        | -0.011197266 |
| serial_timesteps   | 96256        |
| time_elapsed       | 399          |
| total_timesteps    | 770048       |
| value_loss         | 0.025562758  |
-------------------------------------
--------------------------------------
| approxkl           | 0.010533614   |
| clipfrac           | 0.14975587    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.85         |
| explained_variance | 0.856         |
| fps                | 2156          |
| n_updates          | 377           |
| policy_entropy     | 4.7987757     |
| policy_loss        | -0.0041509145 |
| serial_timesteps   | 96512         |
| time_elapsed       | 400           |
| total_timesteps    | 772096        |
| value_loss         | 0.022430781   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010141296  |
| clipfrac           | 0.14472656   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.84         |
| fps                | 2166         |
| n_updates          | 378          |
| policy_entropy     | 4.8066435    |
| policy_loss        | -0.007893164 |
| serial_timesteps   | 96768        |
| time_elapsed       | 401          |
| total_timesteps    | 774144       |
| value_loss         | 0.023770455  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009932119   |
| clipfrac           | 0.1415039     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.86         |
| explained_variance | 0.855         |
| fps                | 2119          |
| n_updates          | 379           |
| policy_entropy     | 4.813348      |
| policy_loss        | -0.0064343764 |
| serial_timesteps   | 97024         |
| time_elapsed       | 402           |
| total_timesteps    | 776192        |
| value_loss         | 0.023128496   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009112535  |
| clipfrac           | 0.1227539    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.85        |
| explained_variance | 0.826        |
| fps                | 2119         |
| n_updates          | 380          |
| policy_entropy     | 4.799651     |
| policy_loss        | -0.006387499 |
| serial_timesteps   | 97280        |
| time_elapsed       | 403          |
| total_timesteps    | 778240       |
| value_loss         | 0.024070017  |
-------------------------------------
Eval num_timesteps=780000, episode_reward=-1.55 +/- 0.01
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009901712   |
| clipfrac           | 0.13666992    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.85         |
| explained_variance | 0.856         |
| fps                | 1477          |
| n_updates          | 381           |
| policy_entropy     | 4.7743406     |
| policy_loss        | -0.0071092322 |
| serial_timesteps   | 97536         |
| time_elapsed       | 404           |
| total_timesteps    | 780288        |
| value_loss         | 0.023645524   |
--------------------------------------
--------------------------------------
| approxkl           | 0.0105800135  |
| clipfrac           | 0.15083008    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.84         |
| explained_variance | 0.846         |
| fps                | 2139          |
| n_updates          | 382           |
| policy_entropy     | 4.763549      |
| policy_loss        | -0.0061795944 |
| serial_timesteps   | 97792         |
| time_elapsed       | 406           |
| total_timesteps    | 782336        |
| value_loss         | 0.024823463   |
--------------------------------------
--------------------------------------
| approxkl           | 0.0105500985  |
| clipfrac           | 0.15048829    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.85         |
| explained_variance | 0.855         |
| fps                | 2128          |
| n_updates          | 383           |
| policy_entropy     | 4.753971      |
| policy_loss        | -0.0057506813 |
| serial_timesteps   | 98048         |
| time_elapsed       | 407           |
| total_timesteps    | 784384        |
| value_loss         | 0.025336182   |
--------------------------------------
-------------------------------------
| approxkl           | 0.010316305  |
| clipfrac           | 0.1529297    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.863        |
| fps                | 2043         |
| n_updates          | 384          |
| policy_entropy     | 4.7271132    |
| policy_loss        | -0.005792436 |
| serial_timesteps   | 98304        |
| time_elapsed       | 408          |
| total_timesteps    | 786432       |
| value_loss         | 0.021970801  |
-------------------------------------
-------------------------------------
| approxkl           | 0.010336519  |
| clipfrac           | 0.14643554   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.824        |
| fps                | 2023         |
| n_updates          | 385          |
| policy_entropy     | 4.701035     |
| policy_loss        | -0.002904987 |
| serial_timesteps   | 98560        |
| time_elapsed       | 409          |
| total_timesteps    | 788480       |
| value_loss         | 0.025594655  |
-------------------------------------
Eval num_timesteps=790000, episode_reward=-1.65 +/- 0.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009938997  |
| clipfrac           | 0.1421875    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.798        |
| fps                | 1498         |
| n_updates          | 386          |
| policy_entropy     | 4.707513     |
| policy_loss        | -0.006510403 |
| serial_timesteps   | 98816        |
| time_elapsed       | 410          |
| total_timesteps    | 790528       |
| value_loss         | 0.029164936  |
-------------------------------------
--------------------------------------
| approxkl           | 0.007719523   |
| clipfrac           | 0.10527344    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.87         |
| explained_variance | 0.811         |
| fps                | 2094          |
| n_updates          | 387           |
| policy_entropy     | 4.730334      |
| policy_loss        | -0.0028653147 |
| serial_timesteps   | 99072         |
| time_elapsed       | 411           |
| total_timesteps    | 792576        |
| value_loss         | 0.02666606    |
--------------------------------------
-------------------------------------
| approxkl           | 0.010044817  |
| clipfrac           | 0.14423828   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.819        |
| fps                | 2095         |
| n_updates          | 388          |
| policy_entropy     | 4.7297945    |
| policy_loss        | -0.004800583 |
| serial_timesteps   | 99328        |
| time_elapsed       | 412          |
| total_timesteps    | 794624       |
| value_loss         | 0.026616609  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0109148165 |
| clipfrac           | 0.15932617   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.806        |
| fps                | 2056         |
| n_updates          | 389          |
| policy_entropy     | 4.69631      |
| policy_loss        | -0.00978408  |
| serial_timesteps   | 99584        |
| time_elapsed       | 413          |
| total_timesteps    | 796672       |
| value_loss         | 0.026856307  |
-------------------------------------
-------------------------------------
| approxkl           | 0.009495737  |
| clipfrac           | 0.13896485   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.848        |
| fps                | 2103         |
| n_updates          | 390          |
| policy_entropy     | 4.67731      |
| policy_loss        | -0.006300222 |
| serial_timesteps   | 99840        |
| time_elapsed       | 414          |
| total_timesteps    | 798720       |
| value_loss         | 0.023618288  |
-------------------------------------
Eval num_timesteps=800000, episode_reward=-1.61 +/- 0.02
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010730958   |
| clipfrac           | 0.14790039    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.85         |
| explained_variance | 0.832         |
| fps                | 1489          |
| n_updates          | 391           |
| policy_entropy     | 4.6442246     |
| policy_loss        | -0.0070579713 |
| serial_timesteps   | 100096        |
| time_elapsed       | 415           |
| total_timesteps    | 800768        |
| value_loss         | 0.025493165   |
--------------------------------------
-------------------------------------
| approxkl           | 0.009739413  |
| clipfrac           | 0.13081054   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.86        |
| explained_variance | 0.848        |
| fps                | 2120         |
| n_updates          | 392          |
| policy_entropy     | 4.598905     |
| policy_loss        | -0.006856464 |
| serial_timesteps   | 100352       |
| time_elapsed       | 416          |
| total_timesteps    | 802816       |
| value_loss         | 0.025137756  |
-------------------------------------
--------------------------------------
| approxkl           | 0.010244135   |
| clipfrac           | 0.1440918     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.87         |
| explained_variance | 0.849         |
| fps                | 2130          |
| n_updates          | 393           |
| policy_entropy     | 4.58549       |
| policy_loss        | -0.0055479547 |
| serial_timesteps   | 100608        |
| time_elapsed       | 417           |
| total_timesteps    | 804864        |
| value_loss         | 0.023892771   |
--------------------------------------
------------------------------------
| approxkl           | 0.011807037 |
| clipfrac           | 0.16904297  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.86       |
| explained_variance | 0.848       |
| fps                | 2109        |
| n_updates          | 394         |
| policy_entropy     | 4.5762596   |
| policy_loss        | -0.00853822 |
| serial_timesteps   | 100864      |
| time_elapsed       | 418         |
| total_timesteps    | 806912      |
| value_loss         | 0.025090048 |
------------------------------------
--------------------------------------
| approxkl           | 0.010397587   |
| clipfrac           | 0.14956054    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.86         |
| explained_variance | 0.853         |
| fps                | 2071          |
| n_updates          | 395           |
| policy_entropy     | 4.5569725     |
| policy_loss        | -0.0086504305 |
| serial_timesteps   | 101120        |
| time_elapsed       | 419           |
| total_timesteps    | 808960        |
| value_loss         | 0.02543534    |
--------------------------------------
Eval num_timesteps=810000, episode_reward=-1.65 +/- 0.02
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.008905647   |
| clipfrac           | 0.12495117    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.87         |
| explained_variance | 0.821         |
| fps                | 1504          |
| n_updates          | 396           |
| policy_entropy     | 4.5528994     |
| policy_loss        | -0.0044185715 |
| serial_timesteps   | 101376        |
| time_elapsed       | 420           |
| total_timesteps    | 811008        |
| value_loss         | 0.026401157   |
--------------------------------------
--------------------------------------
| approxkl           | 0.0108014075  |
| clipfrac           | 0.15864258    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.88         |
| explained_variance | 0.825         |
| fps                | 2124          |
| n_updates          | 397           |
| policy_entropy     | 4.53976       |
| policy_loss        | -0.0060928967 |
| serial_timesteps   | 101632        |
| time_elapsed       | 422           |
| total_timesteps    | 813056        |
| value_loss         | 0.027609322   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010777386   |
| clipfrac           | 0.1578125     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.89         |
| explained_variance | 0.798         |
| fps                | 2123          |
| n_updates          | 398           |
| policy_entropy     | 4.521035      |
| policy_loss        | -0.0052505652 |
| serial_timesteps   | 101888        |
| time_elapsed       | 422           |
| total_timesteps    | 815104        |
| value_loss         | 0.02883405    |
--------------------------------------
--------------------------------------
| approxkl           | 0.010651445   |
| clipfrac           | 0.15083008    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.89         |
| explained_variance | 0.802         |
| fps                | 2095          |
| n_updates          | 399           |
| policy_entropy     | 4.503335      |
| policy_loss        | -0.0034514158 |
| serial_timesteps   | 102144        |
| time_elapsed       | 423           |
| total_timesteps    | 817152        |
| value_loss         | 0.030597445   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010004958   |
| clipfrac           | 0.14340821    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.9          |
| explained_variance | 0.816         |
| fps                | 2109          |
| n_updates          | 400           |
| policy_entropy     | 4.4924054     |
| policy_loss        | -0.0047265356 |
| serial_timesteps   | 102400        |
| time_elapsed       | 424           |
| total_timesteps    | 819200        |
| value_loss         | 0.028107008   |
--------------------------------------
Eval num_timesteps=820000, episode_reward=-1.71 +/- 0.02
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009347454  |
| clipfrac           | 0.13168946   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.801        |
| fps                | 1513         |
| n_updates          | 401          |
| policy_entropy     | 4.4774027    |
| policy_loss        | -0.003103195 |
| serial_timesteps   | 102656       |
| time_elapsed       | 425          |
| total_timesteps    | 821248       |
| value_loss         | 0.029307226  |
-------------------------------------
--------------------------------------
| approxkl           | 0.010023668   |
| clipfrac           | 0.14204101    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.89         |
| explained_variance | 0.796         |
| fps                | 2129          |
| n_updates          | 402           |
| policy_entropy     | 4.46449       |
| policy_loss        | -0.0054829842 |
| serial_timesteps   | 102912        |
| time_elapsed       | 427           |
| total_timesteps    | 823296        |
| value_loss         | 0.03043423    |
--------------------------------------
--------------------------------------
| approxkl           | 0.009385169   |
| clipfrac           | 0.13022462    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.89         |
| explained_variance | 0.742         |
| fps                | 2107          |
| n_updates          | 403           |
| policy_entropy     | 4.4483824     |
| policy_loss        | -0.0068059647 |
| serial_timesteps   | 103168        |
| time_elapsed       | 428           |
| total_timesteps    | 825344        |
| value_loss         | 0.03430704    |
--------------------------------------
--------------------------------------
| approxkl           | 0.008599615   |
| clipfrac           | 0.115722656   |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.9          |
| explained_variance | 0.794         |
| fps                | 2135          |
| n_updates          | 404           |
| policy_entropy     | 4.41648       |
| policy_loss        | -0.0021072666 |
| serial_timesteps   | 103424        |
| time_elapsed       | 429           |
| total_timesteps    | 827392        |
| value_loss         | 0.031021565   |
--------------------------------------
------------------------------------
| approxkl           | 0.011087005 |
| clipfrac           | 0.15839843  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.89       |
| explained_variance | 0.762       |
| fps                | 2137        |
| n_updates          | 405         |
| policy_entropy     | 4.3861723   |
| policy_loss        | -0.00674344 |
| serial_timesteps   | 103680      |
| time_elapsed       | 430         |
| total_timesteps    | 829440      |
| value_loss         | 0.032418847 |
------------------------------------
Eval num_timesteps=830000, episode_reward=-1.73 +/- 0.01
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.01014774    |
| clipfrac           | 0.14506836    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.9          |
| explained_variance | 0.809         |
| fps                | 1494          |
| n_updates          | 406           |
| policy_entropy     | 4.3913326     |
| policy_loss        | -0.0044559017 |
| serial_timesteps   | 103936        |
| time_elapsed       | 431           |
| total_timesteps    | 831488        |
| value_loss         | 0.03134089    |
--------------------------------------
--------------------------------------
| approxkl           | 0.011248972   |
| clipfrac           | 0.16191407    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.88         |
| explained_variance | 0.786         |
| fps                | 2100          |
| n_updates          | 407           |
| policy_entropy     | 4.4012027     |
| policy_loss        | -0.0068528866 |
| serial_timesteps   | 104192        |
| time_elapsed       | 432           |
| total_timesteps    | 833536        |
| value_loss         | 0.030204719   |
--------------------------------------
------------------------------------
| approxkl           | 0.011348287 |
| clipfrac           | 0.16464844  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.88       |
| explained_variance | 0.793       |
| fps                | 2130        |
| n_updates          | 408         |
| policy_entropy     | 4.385378    |
| policy_loss        | -0.00700939 |
| serial_timesteps   | 104448      |
| time_elapsed       | 433         |
| total_timesteps    | 835584      |
| value_loss         | 0.032205928 |
------------------------------------
--------------------------------------
| approxkl           | 0.010478143   |
| clipfrac           | 0.15297851    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.91         |
| explained_variance | 0.793         |
| fps                | 2119          |
| n_updates          | 409           |
| policy_entropy     | 4.3768907     |
| policy_loss        | -0.0044657686 |
| serial_timesteps   | 104704        |
| time_elapsed       | 434           |
| total_timesteps    | 837632        |
| value_loss         | 0.030672688   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0099120345 |
| clipfrac           | 0.14228515   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.811        |
| fps                | 2124         |
| n_updates          | 410          |
| policy_entropy     | 4.3709955    |
| policy_loss        | -0.004508086 |
| serial_timesteps   | 104960       |
| time_elapsed       | 435          |
| total_timesteps    | 839680       |
| value_loss         | 0.028688854  |
-------------------------------------
Eval num_timesteps=840000, episode_reward=-1.79 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009714924  |
| clipfrac           | 0.13989258   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.771        |
| fps                | 1483         |
| n_updates          | 411          |
| policy_entropy     | 4.353095     |
| policy_loss        | -0.005558679 |
| serial_timesteps   | 105216       |
| time_elapsed       | 436          |
| total_timesteps    | 841728       |
| value_loss         | 0.031533845  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0106326    |
| clipfrac           | 0.15302734   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.738        |
| fps                | 2144         |
| n_updates          | 412          |
| policy_entropy     | 4.333655     |
| policy_loss        | -0.004953399 |
| serial_timesteps   | 105472       |
| time_elapsed       | 437          |
| total_timesteps    | 843776       |
| value_loss         | 0.033949427  |
-------------------------------------
-------------------------------------
| approxkl           | 0.0120281195 |
| clipfrac           | 0.17363282   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.753        |
| fps                | 2106         |
| n_updates          | 413          |
| policy_entropy     | 4.33675      |
| policy_loss        | -0.010815298 |
| serial_timesteps   | 105728       |
| time_elapsed       | 438          |
| total_timesteps    | 845824       |
| value_loss         | 0.03746331   |
-------------------------------------
--------------------------------------
| approxkl           | 0.010111643   |
| clipfrac           | 0.13920899    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.89         |
| explained_variance | 0.764         |
| fps                | 2075          |
| n_updates          | 414           |
| policy_entropy     | 4.322403      |
| policy_loss        | -0.0057064337 |
| serial_timesteps   | 105984        |
| time_elapsed       | 439           |
| total_timesteps    | 847872        |
| value_loss         | 0.03134938    |
--------------------------------------
-------------------------------------
| approxkl           | 0.012546775  |
| clipfrac           | 0.18393555   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.738        |
| fps                | 2115         |
| n_updates          | 415          |
| policy_entropy     | 4.2967415    |
| policy_loss        | -0.008322955 |
| serial_timesteps   | 106240       |
| time_elapsed       | 440          |
| total_timesteps    | 849920       |
| value_loss         | 0.0404656    |
-------------------------------------
Eval num_timesteps=850000, episode_reward=-1.91 +/- 0.01
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.011272969  |
| clipfrac           | 0.15913086   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.709        |
| fps                | 1484         |
| n_updates          | 416          |
| policy_entropy     | 4.2982225    |
| policy_loss        | -0.005229363 |
| serial_timesteps   | 106496       |
| time_elapsed       | 441          |
| total_timesteps    | 851968       |
| value_loss         | 0.037375815  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009963635   |
| clipfrac           | 0.14155273    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.91         |
| explained_variance | 0.731         |
| fps                | 2120          |
| n_updates          | 417           |
| policy_entropy     | 4.2982154     |
| policy_loss        | -0.0037525776 |
| serial_timesteps   | 106752        |
| time_elapsed       | 442           |
| total_timesteps    | 854016        |
| value_loss         | 0.039100707   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010801099   |
| clipfrac           | 0.15668945    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.92         |
| explained_variance | 0.7           |
| fps                | 2121          |
| n_updates          | 418           |
| policy_entropy     | 4.2774873     |
| policy_loss        | -0.0047408952 |
| serial_timesteps   | 107008        |
| time_elapsed       | 443           |
| total_timesteps    | 856064        |
| value_loss         | 0.04227677    |
--------------------------------------
-------------------------------------
| approxkl           | 0.010213883  |
| clipfrac           | 0.1425293    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.765        |
| fps                | 2140         |
| n_updates          | 419          |
| policy_entropy     | 4.265802     |
| policy_loss        | -0.003865705 |
| serial_timesteps   | 107264       |
| time_elapsed       | 444          |
| total_timesteps    | 858112       |
| value_loss         | 0.036168963  |
-------------------------------------
Eval num_timesteps=860000, episode_reward=-1.92 +/- 0.02
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.01008247    |
| clipfrac           | 0.14423828    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.91         |
| explained_variance | 0.746         |
| fps                | 1487          |
| n_updates          | 420           |
| policy_entropy     | 4.26297       |
| policy_loss        | -0.0057648746 |
| serial_timesteps   | 107520        |
| time_elapsed       | 445           |
| total_timesteps    | 860160        |
| value_loss         | 0.04045931    |
--------------------------------------
-------------------------------------
| approxkl           | 0.008733882  |
| clipfrac           | 0.12182617   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.9         |
| explained_variance | 0.735        |
| fps                | 2146         |
| n_updates          | 421          |
| policy_entropy     | 4.2594895    |
| policy_loss        | -0.004339299 |
| serial_timesteps   | 107776       |
| time_elapsed       | 447          |
| total_timesteps    | 862208       |
| value_loss         | 0.03575445   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010772908  |
| clipfrac           | 0.15454102   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.749        |
| fps                | 2029         |
| n_updates          | 422          |
| policy_entropy     | 4.2711725    |
| policy_loss        | -0.006208319 |
| serial_timesteps   | 108032       |
| time_elapsed       | 448          |
| total_timesteps    | 864256       |
| value_loss         | 0.039170243  |
-------------------------------------
--------------------------------------
| approxkl           | 0.008396571   |
| clipfrac           | 0.11699219    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.91         |
| explained_variance | 0.694         |
| fps                | 2132          |
| n_updates          | 423           |
| policy_entropy     | 4.284764      |
| policy_loss        | -0.0015730767 |
| serial_timesteps   | 108288        |
| time_elapsed       | 449           |
| total_timesteps    | 866304        |
| value_loss         | 0.039895937   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010303428   |
| clipfrac           | 0.1529297     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.9          |
| explained_variance | 0.733         |
| fps                | 2109          |
| n_updates          | 424           |
| policy_entropy     | 4.2751093     |
| policy_loss        | -0.0051572355 |
| serial_timesteps   | 108544        |
| time_elapsed       | 450           |
| total_timesteps    | 868352        |
| value_loss         | 0.03904169    |
--------------------------------------
Eval num_timesteps=870000, episode_reward=-1.87 +/- 0.02
Episode length: 100.00 +/- 0.00
------------------------------------
| approxkl           | 0.009694414 |
| clipfrac           | 0.13691406  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.92       |
| explained_variance | 0.733       |
| fps                | 1494        |
| n_updates          | 425         |
| policy_entropy     | 4.2513113   |
| policy_loss        | -0.0024901  |
| serial_timesteps   | 108800      |
| time_elapsed       | 451         |
| total_timesteps    | 870400      |
| value_loss         | 0.040058404 |
------------------------------------
-------------------------------------
| approxkl           | 0.011513495  |
| clipfrac           | 0.16923828   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.786        |
| fps                | 2096         |
| n_updates          | 426          |
| policy_entropy     | 4.2457       |
| policy_loss        | -0.004469446 |
| serial_timesteps   | 109056       |
| time_elapsed       | 452          |
| total_timesteps    | 872448       |
| value_loss         | 0.0340265    |
-------------------------------------
--------------------------------------
| approxkl           | 0.011410724   |
| clipfrac           | 0.1663086     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.91         |
| explained_variance | 0.727         |
| fps                | 2136          |
| n_updates          | 427           |
| policy_entropy     | 4.2408094     |
| policy_loss        | -0.0074595897 |
| serial_timesteps   | 109312        |
| time_elapsed       | 453           |
| total_timesteps    | 874496        |
| value_loss         | 0.037467517   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010792371   |
| clipfrac           | 0.15532227    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.88         |
| explained_variance | 0.752         |
| fps                | 2126          |
| n_updates          | 428           |
| policy_entropy     | 4.2188725     |
| policy_loss        | -0.0054284995 |
| serial_timesteps   | 109568        |
| time_elapsed       | 454           |
| total_timesteps    | 876544        |
| value_loss         | 0.034419872   |
--------------------------------------
--------------------------------------
| approxkl           | 0.011257977   |
| clipfrac           | 0.1671875     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.89         |
| explained_variance | 0.786         |
| fps                | 2137          |
| n_updates          | 429           |
| policy_entropy     | 4.1939936     |
| policy_loss        | -0.0048312843 |
| serial_timesteps   | 109824        |
| time_elapsed       | 455           |
| total_timesteps    | 878592        |
| value_loss         | 0.03359867    |
--------------------------------------
Eval num_timesteps=880000, episode_reward=-1.88 +/- 0.00
Episode length: 100.00 +/- 0.00
-------------------------------------
| approxkl           | 0.009169196  |
| clipfrac           | 0.13002929   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.88        |
| explained_variance | 0.744        |
| fps                | 1472         |
| n_updates          | 430          |
| policy_entropy     | 4.1789074    |
| policy_loss        | -0.003490376 |
| serial_timesteps   | 110080       |
| time_elapsed       | 456          |
| total_timesteps    | 880640       |
| value_loss         | 0.03594435   |
-------------------------------------
-------------------------------------
| approxkl           | 0.013203904  |
| clipfrac           | 0.19414063   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.769        |
| fps                | 2124         |
| n_updates          | 431          |
| policy_entropy     | 4.1502123    |
| policy_loss        | -0.010441696 |
| serial_timesteps   | 110336       |
| time_elapsed       | 457          |
| total_timesteps    | 882688       |
| value_loss         | 0.03839529   |
-------------------------------------
-------------------------------------
| approxkl           | 0.009864321  |
| clipfrac           | 0.1385254    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.87        |
| explained_variance | 0.782        |
| fps                | 2094         |
| n_updates          | 432          |
| policy_entropy     | 4.156951     |
| policy_loss        | -0.003653337 |
| serial_timesteps   | 110592       |
| time_elapsed       | 458          |
| total_timesteps    | 884736       |
| value_loss         | 0.033894815  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009906842   |
| clipfrac           | 0.14418945    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.88         |
| explained_variance | 0.798         |
| fps                | 2112          |
| n_updates          | 433           |
| policy_entropy     | 4.1747813     |
| policy_loss        | -0.0025863745 |
| serial_timesteps   | 110848        |
| time_elapsed       | 459           |
| total_timesteps    | 886784        |
| value_loss         | 0.032671206   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010021167   |
| clipfrac           | 0.14453125    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.91         |
| explained_variance | 0.775         |
| fps                | 2110          |
| n_updates          | 434           |
| policy_entropy     | 4.1940813     |
| policy_loss        | -0.0062317243 |
| serial_timesteps   | 111104        |
| time_elapsed       | 460           |
| total_timesteps    | 888832        |
| value_loss         | 0.03500356    |
--------------------------------------
Eval num_timesteps=890000, episode_reward=-2.04 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.011023912   |
| clipfrac           | 0.16337891    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.88         |
| explained_variance | 0.795         |
| fps                | 1499          |
| n_updates          | 435           |
| policy_entropy     | 4.205369      |
| policy_loss        | -0.0054815873 |
| serial_timesteps   | 111360        |
| time_elapsed       | 461           |
| total_timesteps    | 890880        |
| value_loss         | 0.033170372   |
--------------------------------------
--------------------------------------
| approxkl           | 0.008534307   |
| clipfrac           | 0.1199707     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.91         |
| explained_variance | 0.777         |
| fps                | 2154          |
| n_updates          | 436           |
| policy_entropy     | 4.1927633     |
| policy_loss        | -0.0038458132 |
| serial_timesteps   | 111616        |
| time_elapsed       | 463           |
| total_timesteps    | 892928        |
| value_loss         | 0.034762926   |
--------------------------------------
-------------------------------------
| approxkl           | 0.01157026   |
| clipfrac           | 0.16723633   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.89        |
| explained_variance | 0.71         |
| fps                | 2125         |
| n_updates          | 437          |
| policy_entropy     | 4.1739936    |
| policy_loss        | -0.006474593 |
| serial_timesteps   | 111872       |
| time_elapsed       | 463          |
| total_timesteps    | 894976       |
| value_loss         | 0.041181806  |
-------------------------------------
--------------------------------------
| approxkl           | 0.010448962   |
| clipfrac           | 0.14750977    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.91         |
| explained_variance | 0.744         |
| fps                | 2136          |
| n_updates          | 438           |
| policy_entropy     | 4.1404448     |
| policy_loss        | -0.0045496277 |
| serial_timesteps   | 112128        |
| time_elapsed       | 464           |
| total_timesteps    | 897024        |
| value_loss         | 0.044492133   |
--------------------------------------
--------------------------------------
| approxkl           | 0.0082460595  |
| clipfrac           | 0.11235352    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.91         |
| explained_variance | 0.75          |
| fps                | 2097          |
| n_updates          | 439           |
| policy_entropy     | 4.1119947     |
| policy_loss        | -0.0009722623 |
| serial_timesteps   | 112384        |
| time_elapsed       | 465           |
| total_timesteps    | 899072        |
| value_loss         | 0.03634085    |
--------------------------------------
Eval num_timesteps=900000, episode_reward=-2.00 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.009506663   |
| clipfrac           | 0.1315918     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.92         |
| explained_variance | 0.75          |
| fps                | 1512          |
| n_updates          | 440           |
| policy_entropy     | 4.0932565     |
| policy_loss        | -0.0061789667 |
| serial_timesteps   | 112640        |
| time_elapsed       | 466           |
| total_timesteps    | 901120        |
| value_loss         | 0.03955019    |
--------------------------------------
--------------------------------------
| approxkl           | 0.010216679   |
| clipfrac           | 0.14208984    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.92         |
| explained_variance | 0.695         |
| fps                | 2110          |
| n_updates          | 441           |
| policy_entropy     | 4.071353      |
| policy_loss        | -0.0014551617 |
| serial_timesteps   | 112896        |
| time_elapsed       | 468           |
| total_timesteps    | 903168        |
| value_loss         | 0.041564405   |
--------------------------------------
-------------------------------------
| approxkl           | 0.012063337  |
| clipfrac           | 0.17133789   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.93        |
| explained_variance | 0.695        |
| fps                | 2136         |
| n_updates          | 442          |
| policy_entropy     | 4.0281687    |
| policy_loss        | -0.007022854 |
| serial_timesteps   | 113152       |
| time_elapsed       | 469          |
| total_timesteps    | 905216       |
| value_loss         | 0.046712406  |
-------------------------------------
--------------------------------------
| approxkl           | 0.009856379   |
| clipfrac           | 0.14018555    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.94         |
| explained_variance | 0.728         |
| fps                | 2134          |
| n_updates          | 443           |
| policy_entropy     | 3.9902768     |
| policy_loss        | -0.0012995909 |
| serial_timesteps   | 113408        |
| time_elapsed       | 470           |
| total_timesteps    | 907264        |
| value_loss         | 0.039661556   |
--------------------------------------
-------------------------------------
| approxkl           | 0.01119961   |
| clipfrac           | 0.16054687   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.92        |
| explained_variance | 0.681        |
| fps                | 2124         |
| n_updates          | 444          |
| policy_entropy     | 3.957765     |
| policy_loss        | -0.008024957 |
| serial_timesteps   | 113664       |
| time_elapsed       | 471          |
| total_timesteps    | 909312       |
| value_loss         | 0.045277935  |
-------------------------------------
Eval num_timesteps=910000, episode_reward=-1.97 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010641083   |
| clipfrac           | 0.15908203    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.93         |
| explained_variance | 0.724         |
| fps                | 1478          |
| n_updates          | 445           |
| policy_entropy     | 3.9289067     |
| policy_loss        | -0.0035203919 |
| serial_timesteps   | 113920        |
| time_elapsed       | 472           |
| total_timesteps    | 911360        |
| value_loss         | 0.0444019     |
--------------------------------------
-------------------------------------
| approxkl           | 0.010119392  |
| clipfrac           | 0.14663085   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.92        |
| explained_variance | 0.739        |
| fps                | 2147         |
| n_updates          | 446          |
| policy_entropy     | 3.9222534    |
| policy_loss        | -0.004717491 |
| serial_timesteps   | 114176       |
| time_elapsed       | 473          |
| total_timesteps    | 913408       |
| value_loss         | 0.03799223   |
-------------------------------------
--------------------------------------
| approxkl           | 0.010369654   |
| clipfrac           | 0.14692383    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.92         |
| explained_variance | 0.728         |
| fps                | 2129          |
| n_updates          | 447           |
| policy_entropy     | 3.921455      |
| policy_loss        | -0.0037321683 |
| serial_timesteps   | 114432        |
| time_elapsed       | 474           |
| total_timesteps    | 915456        |
| value_loss         | 0.045615487   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010330221   |
| clipfrac           | 0.14418945    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.93         |
| explained_variance | 0.717         |
| fps                | 2118          |
| n_updates          | 448           |
| policy_entropy     | 3.9191937     |
| policy_loss        | -0.0032833845 |
| serial_timesteps   | 114688        |
| time_elapsed       | 475           |
| total_timesteps    | 917504        |
| value_loss         | 0.040993724   |
--------------------------------------
-------------------------------------
| approxkl           | 0.0108502675 |
| clipfrac           | 0.15419921   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.746        |
| fps                | 2099         |
| n_updates          | 449          |
| policy_entropy     | 3.895576     |
| policy_loss        | -0.008969763 |
| serial_timesteps   | 114944       |
| time_elapsed       | 476          |
| total_timesteps    | 919552       |
| value_loss         | 0.041639574  |
-------------------------------------
Eval num_timesteps=920000, episode_reward=-2.14 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.011717251   |
| clipfrac           | 0.17465821    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.94         |
| explained_variance | 0.719         |
| fps                | 1502          |
| n_updates          | 450           |
| policy_entropy     | 3.8622365     |
| policy_loss        | -0.0060624285 |
| serial_timesteps   | 115200        |
| time_elapsed       | 477           |
| total_timesteps    | 921600        |
| value_loss         | 0.045679517   |
--------------------------------------
--------------------------------------
| approxkl           | 0.0098334     |
| clipfrac           | 0.1371582     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.92         |
| explained_variance | 0.755         |
| fps                | 2153          |
| n_updates          | 451           |
| policy_entropy     | 3.8521        |
| policy_loss        | -0.0020295086 |
| serial_timesteps   | 115456        |
| time_elapsed       | 478           |
| total_timesteps    | 923648        |
| value_loss         | 0.040893104   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010108306   |
| clipfrac           | 0.14589843    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.94         |
| explained_variance | 0.707         |
| fps                | 2112          |
| n_updates          | 452           |
| policy_entropy     | 3.8376935     |
| policy_loss        | -0.0035599326 |
| serial_timesteps   | 115712        |
| time_elapsed       | 479           |
| total_timesteps    | 925696        |
| value_loss         | 0.045456372   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010711291   |
| clipfrac           | 0.15395507    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.91         |
| explained_variance | 0.728         |
| fps                | 2099          |
| n_updates          | 453           |
| policy_entropy     | 3.809468      |
| policy_loss        | -0.0031091005 |
| serial_timesteps   | 115968        |
| time_elapsed       | 480           |
| total_timesteps    | 927744        |
| value_loss         | 0.041218363   |
--------------------------------------
------------------------------------
| approxkl           | 0.011355726 |
| clipfrac           | 0.16342774  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.93       |
| explained_variance | 0.716       |
| fps                | 2128        |
| n_updates          | 454         |
| policy_entropy     | 3.7818036   |
| policy_loss        | -0.00546158 |
| serial_timesteps   | 116224      |
| time_elapsed       | 481         |
| total_timesteps    | 929792      |
| value_loss         | 0.047172472 |
------------------------------------
Eval num_timesteps=930000, episode_reward=-2.36 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010243454   |
| clipfrac           | 0.14121094    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.94         |
| explained_variance | 0.692         |
| fps                | 1494          |
| n_updates          | 455           |
| policy_entropy     | 3.755492      |
| policy_loss        | -0.0041620387 |
| serial_timesteps   | 116480        |
| time_elapsed       | 482           |
| total_timesteps    | 931840        |
| value_loss         | 0.046785012   |
--------------------------------------
--------------------------------------
| approxkl           | 0.0113648875  |
| clipfrac           | 0.16845703    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.94         |
| explained_variance | 0.736         |
| fps                | 1994          |
| n_updates          | 456           |
| policy_entropy     | 3.7447362     |
| policy_loss        | -0.0058217705 |
| serial_timesteps   | 116736        |
| time_elapsed       | 483           |
| total_timesteps    | 933888        |
| value_loss         | 0.04518626    |
--------------------------------------
--------------------------------------
| approxkl           | 0.010381179   |
| clipfrac           | 0.15004882    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.94         |
| explained_variance | 0.704         |
| fps                | 2108          |
| n_updates          | 457           |
| policy_entropy     | 3.7339694     |
| policy_loss        | -0.0020232273 |
| serial_timesteps   | 116992        |
| time_elapsed       | 484           |
| total_timesteps    | 935936        |
| value_loss         | 0.046261087   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010323385   |
| clipfrac           | 0.15009765    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.95         |
| explained_variance | 0.689         |
| fps                | 2115          |
| n_updates          | 458           |
| policy_entropy     | 3.7331872     |
| policy_loss        | -0.0019019444 |
| serial_timesteps   | 117248        |
| time_elapsed       | 485           |
| total_timesteps    | 937984        |
| value_loss         | 0.0503879     |
--------------------------------------
Eval num_timesteps=940000, episode_reward=-2.24 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010365486   |
| clipfrac           | 0.15083008    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.97         |
| explained_variance | 0.715         |
| fps                | 1488          |
| n_updates          | 459           |
| policy_entropy     | 3.713924      |
| policy_loss        | -0.0056239194 |
| serial_timesteps   | 117504        |
| time_elapsed       | 486           |
| total_timesteps    | 940032        |
| value_loss         | 0.046379182   |
--------------------------------------
--------------------------------------
| approxkl           | 0.01016679    |
| clipfrac           | 0.14042969    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.92         |
| explained_variance | 0.755         |
| fps                | 2111          |
| n_updates          | 460           |
| policy_entropy     | 3.6842518     |
| policy_loss        | -0.0045753564 |
| serial_timesteps   | 117760        |
| time_elapsed       | 488           |
| total_timesteps    | 942080        |
| value_loss         | 0.041422796   |
--------------------------------------
-------------------------------------
| approxkl           | 0.011651179  |
| clipfrac           | 0.16591796   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.95        |
| explained_variance | 0.715        |
| fps                | 2136         |
| n_updates          | 461          |
| policy_entropy     | 3.688764     |
| policy_loss        | -0.007545507 |
| serial_timesteps   | 118016       |
| time_elapsed       | 489          |
| total_timesteps    | 944128       |
| value_loss         | 0.039523534  |
-------------------------------------
--------------------------------------
| approxkl           | 0.010829053   |
| clipfrac           | 0.1552246     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.93         |
| explained_variance | 0.712         |
| fps                | 2111          |
| n_updates          | 462           |
| policy_entropy     | 3.6937776     |
| policy_loss        | -0.0049732733 |
| serial_timesteps   | 118272        |
| time_elapsed       | 490           |
| total_timesteps    | 946176        |
| value_loss         | 0.042205747   |
--------------------------------------
--------------------------------------
| approxkl           | 0.012091464   |
| clipfrac           | 0.17597656    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.94         |
| explained_variance | 0.73          |
| fps                | 2100          |
| n_updates          | 463           |
| policy_entropy     | 3.6781826     |
| policy_loss        | -0.0050693387 |
| serial_timesteps   | 118528        |
| time_elapsed       | 491           |
| total_timesteps    | 948224        |
| value_loss         | 0.046290807   |
--------------------------------------
Eval num_timesteps=950000, episode_reward=-2.45 +/- 0.01
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010247489   |
| clipfrac           | 0.13842773    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.95         |
| explained_variance | 0.686         |
| fps                | 1383          |
| n_updates          | 464           |
| policy_entropy     | 3.6520398     |
| policy_loss        | -0.0035730903 |
| serial_timesteps   | 118784        |
| time_elapsed       | 492           |
| total_timesteps    | 950272        |
| value_loss         | 0.048108857   |
--------------------------------------
--------------------------------------
| approxkl           | 0.011792645   |
| clipfrac           | 0.16665038    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.97         |
| explained_variance | 0.683         |
| fps                | 2097          |
| n_updates          | 465           |
| policy_entropy     | 3.6389744     |
| policy_loss        | -0.0049213516 |
| serial_timesteps   | 119040        |
| time_elapsed       | 493           |
| total_timesteps    | 952320        |
| value_loss         | 0.052833885   |
--------------------------------------
--------------------------------------
| approxkl           | 0.0118934335  |
| clipfrac           | 0.17197266    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.95         |
| explained_variance | 0.703         |
| fps                | 2118          |
| n_updates          | 466           |
| policy_entropy     | 3.6213918     |
| policy_loss        | -0.0065544276 |
| serial_timesteps   | 119296        |
| time_elapsed       | 494           |
| total_timesteps    | 954368        |
| value_loss         | 0.045238797   |
--------------------------------------
------------------------------------
| approxkl           | 0.012171696 |
| clipfrac           | 0.17905274  |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.93       |
| explained_variance | 0.705       |
| fps                | 2080        |
| n_updates          | 467         |
| policy_entropy     | 3.5935109   |
| policy_loss        | -0.00800004 |
| serial_timesteps   | 119552      |
| time_elapsed       | 495         |
| total_timesteps    | 956416      |
| value_loss         | 0.045398913 |
------------------------------------
-------------------------------------
| approxkl           | 0.011595802  |
| clipfrac           | 0.1595703    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.98        |
| explained_variance | 0.605        |
| fps                | 2063         |
| n_updates          | 468          |
| policy_entropy     | 3.5692978    |
| policy_loss        | -0.007817371 |
| serial_timesteps   | 119808       |
| time_elapsed       | 496          |
| total_timesteps    | 958464       |
| value_loss         | 0.055416107  |
-------------------------------------
Eval num_timesteps=960000, episode_reward=-1.88 +/- 0.01
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.012634717   |
| clipfrac           | 0.18100587    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.96         |
| explained_variance | 0.668         |
| fps                | 1499          |
| n_updates          | 469           |
| policy_entropy     | 3.5456405     |
| policy_loss        | -0.0066530975 |
| serial_timesteps   | 120064        |
| time_elapsed       | 497           |
| total_timesteps    | 960512        |
| value_loss         | 0.053103793   |
--------------------------------------
--------------------------------------
| approxkl           | 0.01128222    |
| clipfrac           | 0.16386719    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.97         |
| explained_variance | 0.696         |
| fps                | 2129          |
| n_updates          | 470           |
| policy_entropy     | 3.5358994     |
| policy_loss        | -0.0065989243 |
| serial_timesteps   | 120320        |
| time_elapsed       | 498           |
| total_timesteps    | 962560        |
| value_loss         | 0.050359927   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010617605   |
| clipfrac           | 0.15625       |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.96         |
| explained_variance | 0.7           |
| fps                | 2100          |
| n_updates          | 471           |
| policy_entropy     | 3.5397682     |
| policy_loss        | -0.0032347392 |
| serial_timesteps   | 120576        |
| time_elapsed       | 499           |
| total_timesteps    | 964608        |
| value_loss         | 0.049403097   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010665286   |
| clipfrac           | 0.153125      |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.96         |
| explained_variance | 0.731         |
| fps                | 2116          |
| n_updates          | 472           |
| policy_entropy     | 3.5225658     |
| policy_loss        | -0.0021622882 |
| serial_timesteps   | 120832        |
| time_elapsed       | 500           |
| total_timesteps    | 966656        |
| value_loss         | 0.044707414   |
--------------------------------------
-------------------------------------
| approxkl           | 0.011529323  |
| clipfrac           | 0.1650879    |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.94        |
| explained_variance | 0.672        |
| fps                | 2035         |
| n_updates          | 473          |
| policy_entropy     | 3.5041142    |
| policy_loss        | -0.005263375 |
| serial_timesteps   | 121088       |
| time_elapsed       | 501          |
| total_timesteps    | 968704       |
| value_loss         | 0.04773183   |
-------------------------------------
Eval num_timesteps=970000, episode_reward=-2.01 +/- 0.21
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010395541   |
| clipfrac           | 0.14750977    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.91         |
| explained_variance | 0.747         |
| fps                | 821           |
| n_updates          | 474           |
| policy_entropy     | 3.4962711     |
| policy_loss        | -0.0059977286 |
| serial_timesteps   | 121344        |
| time_elapsed       | 502           |
| total_timesteps    | 970752        |
| value_loss         | 0.042373274   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010521871   |
| clipfrac           | 0.14882812    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.94         |
| explained_variance | 0.68          |
| fps                | 2114          |
| n_updates          | 475           |
| policy_entropy     | 3.469659      |
| policy_loss        | -0.0009343366 |
| serial_timesteps   | 121600        |
| time_elapsed       | 505           |
| total_timesteps    | 972800        |
| value_loss         | 0.0465048     |
--------------------------------------
-------------------------------------
| approxkl           | 0.011716945  |
| clipfrac           | 0.171875     |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.92        |
| explained_variance | 0.737        |
| fps                | 2135         |
| n_updates          | 476          |
| policy_entropy     | 3.4601684    |
| policy_loss        | -0.007128563 |
| serial_timesteps   | 121856       |
| time_elapsed       | 506          |
| total_timesteps    | 974848       |
| value_loss         | 0.04420146   |
-------------------------------------
-------------------------------------
| approxkl           | 0.012579721  |
| clipfrac           | 0.17563477   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.95        |
| explained_variance | 0.733        |
| fps                | 2116         |
| n_updates          | 477          |
| policy_entropy     | 3.453685     |
| policy_loss        | -0.006076618 |
| serial_timesteps   | 122112       |
| time_elapsed       | 507          |
| total_timesteps    | 976896       |
| value_loss         | 0.042243395  |
-------------------------------------
-------------------------------------
| approxkl           | 0.012403813  |
| clipfrac           | 0.17348632   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.91        |
| explained_variance | 0.699        |
| fps                | 2106         |
| n_updates          | 478          |
| policy_entropy     | 3.4658923    |
| policy_loss        | -0.008221818 |
| serial_timesteps   | 122368       |
| time_elapsed       | 508          |
| total_timesteps    | 978944       |
| value_loss         | 0.04967288   |
-------------------------------------
Eval num_timesteps=980000, episode_reward=-1.93 +/- 0.00
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.010791151   |
| clipfrac           | 0.15458985    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.94         |
| explained_variance | 0.632         |
| fps                | 1499          |
| n_updates          | 479           |
| policy_entropy     | 3.4610991     |
| policy_loss        | -0.0039660693 |
| serial_timesteps   | 122624        |
| time_elapsed       | 509           |
| total_timesteps    | 980992        |
| value_loss         | 0.05730232    |
--------------------------------------
--------------------------------------
| approxkl           | 0.010788664   |
| clipfrac           | 0.1527832     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.94         |
| explained_variance | 0.662         |
| fps                | 2114          |
| n_updates          | 480           |
| policy_entropy     | 3.4427083     |
| policy_loss        | -0.0031662197 |
| serial_timesteps   | 122880        |
| time_elapsed       | 510           |
| total_timesteps    | 983040        |
| value_loss         | 0.04502534    |
--------------------------------------
--------------------------------------
| approxkl           | 0.010665842   |
| clipfrac           | 0.1503418     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.97         |
| explained_variance | 0.691         |
| fps                | 2117          |
| n_updates          | 481           |
| policy_entropy     | 3.4636338     |
| policy_loss        | -0.0033879317 |
| serial_timesteps   | 123136        |
| time_elapsed       | 511           |
| total_timesteps    | 985088        |
| value_loss         | 0.053431146   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010523894   |
| clipfrac           | 0.14233398    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.97         |
| explained_variance | 0.677         |
| fps                | 2105          |
| n_updates          | 482           |
| policy_entropy     | 3.4999967     |
| policy_loss        | -0.0067678606 |
| serial_timesteps   | 123392        |
| time_elapsed       | 512           |
| total_timesteps    | 987136        |
| value_loss         | 0.05076623    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0122168055 |
| clipfrac           | 0.17480469   |
| ep_len_mean        | 100          |
| ep_reward_mean     | -1.97        |
| explained_variance | 0.75         |
| fps                | 2124         |
| n_updates          | 483          |
| policy_entropy     | 3.488498     |
| policy_loss        | -0.006219322 |
| serial_timesteps   | 123648       |
| time_elapsed       | 513          |
| total_timesteps    | 989184       |
| value_loss         | 0.044227023  |
-------------------------------------
Eval num_timesteps=990000, episode_reward=-1.92 +/- 0.01
Episode length: 100.00 +/- 0.00
--------------------------------------
| approxkl           | 0.011043576   |
| clipfrac           | 0.14780274    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.97         |
| explained_variance | 0.747         |
| fps                | 1494          |
| n_updates          | 484           |
| policy_entropy     | 3.4460418     |
| policy_loss        | -0.0063211285 |
| serial_timesteps   | 123904        |
| time_elapsed       | 514           |
| total_timesteps    | 991232        |
| value_loss         | 0.043973535   |
--------------------------------------
--------------------------------------
| approxkl           | 0.010250766   |
| clipfrac           | 0.14213867    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.94         |
| explained_variance | 0.723         |
| fps                | 2116          |
| n_updates          | 485           |
| policy_entropy     | 3.4097953     |
| policy_loss        | -0.0052426523 |
| serial_timesteps   | 124160        |
| time_elapsed       | 515           |
| total_timesteps    | 993280        |
| value_loss         | 0.044667955   |
--------------------------------------
--------------------------------------
| approxkl           | 0.011266532   |
| clipfrac           | 0.1583496     |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.94         |
| explained_variance | 0.725         |
| fps                | 2113          |
| n_updates          | 486           |
| policy_entropy     | 3.3757885     |
| policy_loss        | -0.0022334317 |
| serial_timesteps   | 124416        |
| time_elapsed       | 516           |
| total_timesteps    | 995328        |
| value_loss         | 0.042597212   |
--------------------------------------
------------------------------------
| approxkl           | 0.011598654 |
| clipfrac           | 0.1649414   |
| ep_len_mean        | 100         |
| ep_reward_mean     | -1.92       |
| explained_variance | 0.678       |
| fps                | 2131        |
| n_updates          | 487         |
| policy_entropy     | 3.361525    |
| policy_loss        | -0.00711217 |
| serial_timesteps   | 124672      |
| time_elapsed       | 517         |
| total_timesteps    | 997376      |
| value_loss         | 0.046554584 |
------------------------------------
--------------------------------------
| approxkl           | 0.011275058   |
| clipfrac           | 0.16191407    |
| ep_len_mean        | 100           |
| ep_reward_mean     | -1.93         |
| explained_variance | 0.734         |
| fps                | 2138          |
| n_updates          | 488           |
| policy_entropy     | 3.3712788     |
| policy_loss        | -0.0056393966 |
| serial_timesteps   | 124928        |
| time_elapsed       | 518           |
| total_timesteps    | 999424        |
| value_loss         | 0.04319729    |
--------------------------------------
Saving to logs/train_1M_widowx_reach-v3/ppo2/widowx_reach-v3_2
