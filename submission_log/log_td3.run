doodad not detected
Not a valid git repo: /ichec/home/users/pierre/pierreExeter_github/rlkit/rlkit/..
2020-05-17 22:42:12.745195 IST | Variant:
2020-05-17 22:42:12.745994 IST | {
  "algo_kwargs": {
    "batch_size": 100,
    "replay_buffer_size": 1000000,
    "max_path_length": 1000,
    "num_steps_per_eval": 1000,
    "discount": 0.99,
    "num_epochs": 3000,
    "num_steps_per_epoch": 5000
  }
}
pybullet build time: May 16 2020 18:16:17
b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
gripper_aux_linkb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frameb3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:
base_link********goal is : *********** [-0.01108877  0.05831717  0.37601762]
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.[0m
2020-05-17 22:42:17.689079 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #0 | Collecting samples for evaluation
---------------------------  --------------
QF1 Loss                        0.000489888
QF2 Loss                        0.000242968
Policy Loss                     0.0465979
Q1 Predictions Mean             0.00438397
Q1 Predictions Std              0.000577668
Q1 Predictions Max              0.00566336
Q1 Predictions Min              0.0027564
Q2 Predictions Mean            -0.00334234
Q2 Predictions Std              0.000415165
Q2 Predictions Max             -0.0023091
Q2 Predictions Min             -0.00422458
Q Targets Mean                 -0.0154955
Q Targets Std                   0.00961857
Q Targets Max                  -0.00342236
Q Targets Min                  -0.0487441
Bellman Errors 1 Mean           0.000489888
Bellman Errors 1 Std            0.000526447
Bellman Errors 1 Max            0.00277478
Bellman Errors 1 Min            6.38824e-05
Bellman Errors 2 Mean           0.000242968
Bellman Errors 2 Std            0.00038388
Bellman Errors 2 Max            0.00206863
Bellman Errors 2 Min            8.65966e-09
Policy Action Mean              0.000223125
Policy Action Std               0.00397789
Policy Action Max               0.00765337
Policy Action Min              -0.00479106
Test Rewards Mean              -0.0467463
Test Rewards Std                0.00730505
Test Rewards Max               -0.00355369
Test Rewards Min               -0.0483987
Test Returns Mean             -46.7463
Test Returns Std                0
Test Returns Max              -46.7463
Test Returns Min              -46.7463
Test Actions Mean              -0.0219042
Test Actions Std                0.0208687
Test Actions Max                0.0247983
Test Actions Min               -0.035959
Num Paths                       5
Exploration Rewards Mean       -0.0127556
Exploration Rewards Std         0.0111312
Exploration Rewards Max        -0.000192963
Exploration Rewards Min        -0.0672874
Exploration Returns Mean      -12.7556
Exploration Returns Std         6.75348
Exploration Returns Max        -7.17843
Exploration Returns Min       -25.0967
Exploration Actions Mean       -0.000126159
Exploration Actions Std         0.100033
Exploration Actions Max         0.431076
Exploration Actions Min        -0.396071
Final total_distance Mean       0.219997
Final total_distance Std        0
Final total_distance Max        0.219997
Final total_distance Min        0.219997
AverageReturn                 -46.7463
Number of train steps total     1
Number of env steps total    5000
Number of rollouts total        5
Train Time (s)                  0.375819
(Previous) Eval Time (s)        0
Sample Time (s)                 3.62127
Epoch Time (s)                  3.99709
Total Train Time (s)            5.08921
Epoch                           0
---------------------------  --------------
2020-05-17 22:42:18.520711 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #0 | Epoch Duration: 5.153507709503174
2020-05-17 22:42:18.521070 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #0 | Started Training: True
2020-05-17 22:52:27.801536 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #1 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         0.000957553
QF2 Loss                         0.00150531
Policy Loss                      0.0323044
Q1 Predictions Mean             -0.0466375
Q1 Predictions Std               0.000934575
Q1 Predictions Max              -0.0439961
Q1 Predictions Min              -0.0484472
Q2 Predictions Mean             -0.0551528
Q2 Predictions Std               0.00104301
Q2 Predictions Max              -0.0534073
Q2 Predictions Min              -0.057475
Q Targets Mean                  -0.0186273
Q Targets Std                    0.0133766
Q Targets Max                   -0.00444335
Q Targets Min                   -0.061467
Bellman Errors 1 Mean            0.000957552
Bellman Errors 1 Std             0.000536525
Bellman Errors 1 Max             0.0017843
Bellman Errors 1 Min             3.73189e-06
Bellman Errors 2 Mean            0.00150531
Bellman Errors 2 Std             0.000750043
Bellman Errors 2 Max             0.00263325
Bellman Errors 2 Min             1.63492e-06
Policy Action Mean              -0.0225783
Policy Action Std                0.0222048
Policy Action Max                0.0284004
Policy Action Min               -0.0398259
Test Rewards Mean               -0.0100033
Test Rewards Std                 1.73472e-18
Test Rewards Max                -0.0100033
Test Rewards Min                -0.0100033
Test Returns Mean              -10.0033
Test Returns Std                 0
Test Returns Max               -10.0033
Test Returns Min               -10.0033
Test Actions Mean               -1
Test Actions Std                 1.48113e-07
Test Actions Max                -0.999999
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.020456
Exploration Rewards Std          0.0115649
Exploration Rewards Max         -0.00344249
Exploration Rewards Min         -0.0421196
Exploration Returns Mean       -20.456
Exploration Returns Std         11.3091
Exploration Returns Max         -7.74351
Exploration Returns Min        -41.7355
Exploration Actions Mean        -0.955427
Exploration Actions Std          0.0870778
Exploration Actions Max          0.788258
Exploration Actions Min         -1
Final total_distance Mean        0.100016
Final total_distance Std         0
Final total_distance Max         0.100016
Final total_distance Min         0.100016
AverageReturn                  -10.0033
Number of train steps total   5001
Number of env steps total    10000
Number of rollouts total        10
Train Time (s)                 605.119
(Previous) Eval Time (s)         1.09979
Sample Time (s)                  4.01028
Epoch Time (s)                 610.229
Total Train Time (s)           615.037
Epoch                            1
---------------------------  ---------------
2020-05-17 22:52:28.614185 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #1 | Epoch Duration: 610.0928719043732
2020-05-17 22:52:28.614416 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #1 | Started Training: True
2020-05-17 23:02:52.511226 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #2 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         6.21652e-06
QF2 Loss                         3.42113e-06
Policy Loss                      0.21135
Q1 Predictions Mean             -0.217245
Q1 Predictions Std               0.108902
Q1 Predictions Max              -0.0833315
Q1 Predictions Min              -0.494226
Q2 Predictions Mean             -0.216622
Q2 Predictions Std               0.108678
Q2 Predictions Max              -0.0837049
Q2 Predictions Min              -0.493727
Q Targets Mean                  -0.215894
Q Targets Std                    0.109001
Q Targets Max                   -0.081082
Q Targets Min                   -0.495282
Bellman Errors 1 Mean            6.21652e-06
Bellman Errors 1 Std             1.04729e-05
Bellman Errors 1 Max             5.06475e-05
Bellman Errors 1 Min             3.91005e-10
Bellman Errors 2 Mean            3.42113e-06
Bellman Errors 2 Std             8.34918e-06
Bellman Errors 2 Max             6.64368e-05
Bellman Errors 2 Min             8.88303e-11
Policy Action Mean              -1
Policy Action Std                4.14456e-07
Policy Action Max               -0.999997
Policy Action Min               -1
Test Rewards Mean               -0.0100033
Test Rewards Std                 3.46945e-18
Test Rewards Max                -0.0100033
Test Rewards Min                -0.0100033
Test Returns Mean              -10.0033
Test Returns Std                 0
Test Returns Max               -10.0033
Test Returns Min               -10.0033
Test Actions Mean               -1
Test Actions Std                 2.43457e-08
Test Actions Max                -1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0148561
Exploration Rewards Std          0.0041781
Exploration Rewards Max         -0.0074691
Exploration Rewards Min         -0.0199164
Exploration Returns Mean       -14.8561
Exploration Returns Std          3.43329
Exploration Returns Max         -9.23467
Exploration Returns Min        -19.0678
Exploration Actions Mean        -0.960677
Exploration Actions Std          0.058196
Exploration Actions Max         -0.586767
Exploration Actions Min         -1
Final total_distance Mean        0.100016
Final total_distance Std         0
Final total_distance Max         0.100016
Final total_distance Min         0.100016
AverageReturn                  -10.0033
Number of train steps total  10001
Number of env steps total    15000
Number of rollouts total        15
Train Time (s)                 619.298
(Previous) Eval Time (s)         0.816453
Sample Time (s)                  4.43595
Epoch Time (s)                 624.551
Total Train Time (s)          1239.66
Epoch                            2
---------------------------  ---------------
2020-05-17 23:02:53.381049 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #2 | Epoch Duration: 624.7664103507996
2020-05-17 23:02:53.381295 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #2 | Started Training: True
2020-05-17 23:13:24.044237 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #3 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         1.31118e-05
QF2 Loss                         1.03202e-05
Policy Loss                      0.369871
Q1 Predictions Mean             -0.376118
Q1 Predictions Std               0.17858
Q1 Predictions Max              -0.131297
Q1 Predictions Min              -0.9202
Q2 Predictions Mean             -0.37528
Q2 Predictions Std               0.178522
Q2 Predictions Max              -0.130381
Q2 Predictions Min              -0.919891
Q Targets Mean                  -0.374324
Q Targets Std                    0.179243
Q Targets Max                   -0.128416
Q Targets Min                   -0.920614
Bellman Errors 1 Mean            1.31118e-05
Bellman Errors 1 Std             2.11424e-05
Bellman Errors 1 Max             0.000136611
Bellman Errors 1 Min             1.49641e-09
Bellman Errors 2 Mean            1.03202e-05
Bellman Errors 2 Std             1.99564e-05
Bellman Errors 2 Max             0.000108493
Bellman Errors 2 Min             2.49489e-12
Policy Action Mean              -1
Policy Action Std                4.10797e-08
Policy Action Max               -1
Policy Action Min               -1
Test Rewards Mean               -0.0100033
Test Rewards Std                 3.46945e-18
Test Rewards Max                -0.0100033
Test Rewards Min                -0.0100033
Test Returns Mean              -10.0033
Test Returns Std                 0
Test Returns Max               -10.0033
Test Returns Min               -10.0033
Test Actions Mean               -1
Test Actions Std                 2.43335e-08
Test Actions Max                -1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0160216
Exploration Rewards Std          0.00367559
Exploration Rewards Max         -0.0085062
Exploration Rewards Min         -0.0191426
Exploration Returns Mean       -16.0216
Exploration Returns Std          2.17671
Exploration Returns Max        -12.1875
Exploration Returns Min        -18.828
Exploration Actions Mean        -0.960135
Exploration Actions Std          0.0583081
Exploration Actions Max         -0.622645
Exploration Actions Min         -1
Final total_distance Mean        0.100016
Final total_distance Std         0
Final total_distance Max         0.100016
Final total_distance Min         0.100016
AverageReturn                  -10.0033
Number of train steps total  15001
Number of env steps total    20000
Number of rollouts total        20
Train Time (s)                 626.551
(Previous) Eval Time (s)         0.883706
Sample Time (s)                  3.95624
Epoch Time (s)                 631.391
Total Train Time (s)          1871.03
Epoch                            3
---------------------------  ---------------
2020-05-17 23:13:24.904440 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #3 | Epoch Duration: 631.5229120254517
2020-05-17 23:13:24.904685 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #3 | Started Training: True
2020-05-17 23:24:18.125104 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #4 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         2.8897e-05
QF2 Loss                         3.0855e-05
Policy Loss                      0.488879
Q1 Predictions Mean             -0.493929
Q1 Predictions Std               0.2201
Q1 Predictions Max              -0.200776
Q1 Predictions Min              -1.29179
Q2 Predictions Mean             -0.492963
Q2 Predictions Std               0.219838
Q2 Predictions Max              -0.201324
Q2 Predictions Min              -1.28898
Q Targets Mean                  -0.492613
Q Targets Std                    0.220902
Q Targets Max                   -0.19807
Q Targets Min                   -1.29749
Bellman Errors 1 Mean            2.8897e-05
Bellman Errors 1 Std             6.43871e-05
Bellman Errors 1 Max             0.000459783
Bellman Errors 1 Min             2.65823e-09
Bellman Errors 2 Mean            3.0855e-05
Bellman Errors 2 Std             6.86859e-05
Bellman Errors 2 Max             0.000378834
Bellman Errors 2 Min             3.25375e-09
Policy Action Mean              -1
Policy Action Std                3.65002e-08
Policy Action Max               -1
Policy Action Min               -1
Test Rewards Mean               -0.063976
Test Rewards Std                 0.00229067
Test Rewards Max                -0.00723724
Test Rewards Min                -0.0641089
Test Returns Mean              -63.976
Test Returns Std                 0
Test Returns Max               -63.976
Test Returns Min               -63.976
Test Actions Mean                0
Test Actions Std                 1
Test Actions Max                 1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0343129
Exploration Rewards Std          0.0244932
Exploration Rewards Max         -0.00178227
Exploration Rewards Min         -0.0755265
Exploration Returns Mean       -34.3129
Exploration Returns Std         24.119
Exploration Returns Max        -13.5232
Exploration Returns Min        -64.3621
Exploration Actions Mean        -0.565258
Exploration Actions Std          0.774708
Exploration Actions Max          1
Exploration Actions Min         -1
Final total_distance Mean        0.253197
Final total_distance Std         0
Final total_distance Max         0.253197
Final total_distance Min         0.253197
AverageReturn                  -63.976
Number of train steps total  20001
Number of env steps total    25000
Number of rollouts total        25
Train Time (s)                 649.133
(Previous) Eval Time (s)         0.864375
Sample Time (s)                  3.93796
Epoch Time (s)                 653.936
Total Train Time (s)          2524.93
Epoch                            4
---------------------------  ---------------
2020-05-17 23:24:18.949507 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #4 | Epoch Duration: 654.0445392131805
2020-05-17 23:24:18.949856 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #4 | Started Training: True
2020-05-17 23:35:33.051799 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #5 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         9.68474e-05
QF2 Loss                         9.17259e-05
Policy Loss                      0.429541
Q1 Predictions Mean             -0.447099
Q1 Predictions Std               0.0847076
Q1 Predictions Max              -0.38654
Q1 Predictions Min              -0.657012
Q2 Predictions Mean             -0.446122
Q2 Predictions Std               0.0845402
Q2 Predictions Max              -0.386227
Q2 Predictions Min              -0.656027
Q Targets Mean                  -0.444526
Q Targets Std                    0.0853098
Q Targets Max                   -0.377084
Q Targets Min                   -0.678659
Bellman Errors 1 Mean            9.68474e-05
Bellman Errors 1 Std             0.000146496
Bellman Errors 1 Max             0.000791907
Bellman Errors 1 Min             8.67362e-09
Bellman Errors 2 Mean            9.17259e-05
Bellman Errors 2 Std             0.000137426
Bellman Errors 2 Max             0.000761391
Bellman Errors 2 Min             7.96166e-09
Policy Action Mean               0
Policy Action Std                1
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean               -0.063976
Test Rewards Std                 0.00229067
Test Rewards Max                -0.00723724
Test Rewards Min                -0.0641089
Test Returns Mean              -63.976
Test Returns Std                 0
Test Returns Max               -63.976
Test Returns Min               -63.976
Test Actions Mean                0
Test Actions Std                 1
Test Actions Max                 1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0637752
Exploration Rewards Std          0.00251405
Exploration Rewards Max         -0.00610927
Exploration Rewards Min         -0.0651745
Exploration Returns Mean       -63.7752
Exploration Returns Std          0.916394
Exploration Returns Max        -62.4879
Exploration Returns Min        -65.0318
Exploration Actions Mean        -0.000138358
Exploration Actions Std          0.961518
Exploration Actions Max          1
Exploration Actions Min         -1
Final total_distance Mean        0.253197
Final total_distance Std         0
Final total_distance Max         0.253197
Final total_distance Min         0.253197
AverageReturn                  -63.976
Number of train steps total  25001
Number of env steps total    30000
Number of rollouts total        30
Train Time (s)                 670.026
(Previous) Eval Time (s)         0.828032
Sample Time (s)                  3.92682
Epoch Time (s)                 674.781
Total Train Time (s)          3199.68
Epoch                            5
---------------------------  ---------------
2020-05-17 23:35:33.853536 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #5 | Epoch Duration: 674.9033768177032
2020-05-17 23:35:33.853886 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #5 | Started Training: True
2020-05-17 23:46:48.967316 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #6 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         0.000269128
QF2 Loss                         0.000290151
Policy Loss                      1.25201
Q1 Predictions Mean             -1.20519
Q1 Predictions Std               0.0855707
Q1 Predictions Max              -0.93951
Q1 Predictions Min              -1.35003
Q2 Predictions Mean             -1.20616
Q2 Predictions Std               0.0845348
Q2 Predictions Max              -0.937865
Q2 Predictions Min              -1.35508
Q Targets Mean                  -1.19747
Q Targets Std                    0.0865251
Q Targets Max                   -0.943226
Q Targets Min                   -1.34641
Bellman Errors 1 Mean            0.000269128
Bellman Errors 1 Std             0.000497015
Bellman Errors 1 Max             0.00319451
Bellman Errors 1 Min             1.08253e-09
Bellman Errors 2 Mean            0.000290151
Bellman Errors 2 Std             0.000536873
Bellman Errors 2 Max             0.00337697
Bellman Errors 2 Min             1.32609e-08
Policy Action Mean               0
Policy Action Std                1
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean               -0.063976
Test Rewards Std                 0.00229067
Test Rewards Max                -0.00723724
Test Rewards Min                -0.0641089
Test Returns Mean              -63.976
Test Returns Std                 0
Test Returns Max               -63.976
Test Returns Min               -63.976
Test Actions Mean                0
Test Actions Std                 1
Test Actions Max                 1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0627209
Exploration Rewards Std          0.00266341
Exploration Rewards Max         -0.00620707
Exploration Rewards Min         -0.0646033
Exploration Returns Mean       -62.7209
Exploration Returns Std          1.36234
Exploration Returns Max        -60.6685
Exploration Returns Min        -64.4681
Exploration Actions Mean        -6.86883e-05
Exploration Actions Std          0.962027
Exploration Actions Max          1
Exploration Actions Min         -1
Final total_distance Mean        0.253197
Final total_distance Std         0
Final total_distance Max         0.253197
Final total_distance Min         0.253197
AverageReturn                  -63.976
Number of train steps total  30001
Number of env steps total    35000
Number of rollouts total        35
Train Time (s)                 670.782
(Previous) Eval Time (s)         0.805355
Sample Time (s)                  4.17849
Epoch Time (s)                 675.766
Total Train Time (s)          3875.51
Epoch                            6
---------------------------  ---------------
2020-05-17 23:46:49.832916 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #6 | Epoch Duration: 675.9787967205048
2020-05-17 23:46:49.833144 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #6 | Started Training: True
2020-05-17 23:57:58.711424 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #7 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         0.000374445
QF2 Loss                         0.000334114
Policy Loss                      1.90494
Q1 Predictions Mean             -1.86748
Q1 Predictions Std               0.0796505
Q1 Predictions Max              -1.45416
Q1 Predictions Min              -1.98674
Q2 Predictions Mean             -1.86989
Q2 Predictions Std               0.0790832
Q2 Predictions Max              -1.46399
Q2 Predictions Min              -1.99024
Q Targets Mean                  -1.87701
Q Targets Std                    0.0792125
Q Targets Max                   -1.47764
Q Targets Min                   -1.9787
Bellman Errors 1 Mean            0.000374445
Bellman Errors 1 Std             0.000757737
Bellman Errors 1 Max             0.00477992
Bellman Errors 1 Min             3.51021e-09
Bellman Errors 2 Mean            0.000334114
Bellman Errors 2 Std             0.000699169
Bellman Errors 2 Max             0.00450859
Bellman Errors 2 Min             2.23112e-08
Policy Action Mean               0
Policy Action Std                1
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean               -0.063976
Test Rewards Std                 0.00229067
Test Rewards Max                -0.00723724
Test Rewards Min                -0.0641089
Test Returns Mean              -63.976
Test Returns Std                 0
Test Returns Max               -63.976
Test Returns Min               -63.976
Test Actions Mean                0
Test Actions Std                 1
Test Actions Max                 1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0635152
Exploration Rewards Std          0.00280846
Exploration Rewards Max         -0.00616803
Exploration Rewards Min         -0.0651575
Exploration Returns Mean       -63.5152
Exploration Returns Std          1.26879
Exploration Returns Max        -61.2953
Exploration Returns Min        -64.7592
Exploration Actions Mean         0.000199401
Exploration Actions Std          0.961835
Exploration Actions Max          1
Exploration Actions Min         -1
Final total_distance Mean        0.253197
Final total_distance Std         0
Final total_distance Max         0.253197
Final total_distance Min         0.253197
AverageReturn                  -63.976
Number of train steps total  35001
Number of env steps total    40000
Number of rollouts total        40
Train Time (s)                 664.704
(Previous) Eval Time (s)         0.869618
Sample Time (s)                  4.02091
Epoch Time (s)                 669.595
Total Train Time (s)          4545.1
Epoch                            7
---------------------------  ---------------
2020-05-17 23:57:59.567653 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #7 | Epoch Duration: 669.7342917919159
2020-05-17 23:57:59.567878 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #7 | Started Training: True
2020-05-18 00:09:00.290038 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #8 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         0.000251069
QF2 Loss                         0.000252762
Policy Loss                      2.46521
Q1 Predictions Mean             -2.42562
Q1 Predictions Std               0.0924357
Q1 Predictions Max              -2.19404
Q1 Predictions Min              -2.56514
Q2 Predictions Mean             -2.42892
Q2 Predictions Std               0.0897918
Q2 Predictions Max              -2.19434
Q2 Predictions Min              -2.58091
Q Targets Mean                  -2.43124
Q Targets Std                    0.0941374
Q Targets Max                   -2.18832
Q Targets Min                   -2.60249
Bellman Errors 1 Mean            0.000251069
Bellman Errors 1 Std             0.000385582
Bellman Errors 1 Max             0.00172808
Bellman Errors 1 Min             7.80792e-08
Bellman Errors 2 Mean            0.000252762
Bellman Errors 2 Std             0.000335473
Bellman Errors 2 Max             0.00138036
Bellman Errors 2 Min             2.75122e-11
Policy Action Mean               0
Policy Action Std                1
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean               -0.063976
Test Rewards Std                 0.00229067
Test Rewards Max                -0.00723724
Test Rewards Min                -0.0641089
Test Returns Mean              -63.976
Test Returns Std                 0
Test Returns Max               -63.976
Test Returns Min               -63.976
Test Actions Mean                0
Test Actions Std                 1
Test Actions Max                 1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0628742
Exploration Rewards Std          0.00252073
Exploration Rewards Max         -0.00595116
Exploration Rewards Min         -0.0646437
Exploration Returns Mean       -62.8742
Exploration Returns Std          1.00908
Exploration Returns Max        -61.3494
Exploration Returns Min        -64.5053
Exploration Actions Mean         0.000624703
Exploration Actions Std          0.96188
Exploration Actions Max          1
Exploration Actions Min         -1
Final total_distance Mean        0.253197
Final total_distance Std         0
Final total_distance Max         0.253197
Final total_distance Min         0.253197
AverageReturn                  -63.976
Number of train steps total  40001
Number of env steps total    45000
Number of rollouts total        45
Train Time (s)                 656.452
(Previous) Eval Time (s)         0.859942
Sample Time (s)                  4.11235
Epoch Time (s)                 661.424
Total Train Time (s)          5206.49
Epoch                            8
---------------------------  ---------------
2020-05-18 00:09:01.118092 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #8 | Epoch Duration: 661.5499918460846
2020-05-18 00:09:01.118318 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #8 | Started Training: True
2020-05-18 00:20:13.420572 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #9 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         0.00020863
QF2 Loss                         0.000181608
Policy Loss                      2.91975
Q1 Predictions Mean             -2.89796
Q1 Predictions Std               0.114445
Q1 Predictions Max              -2.71346
Q1 Predictions Min              -3.10789
Q2 Predictions Mean             -2.9025
Q2 Predictions Std               0.114548
Q2 Predictions Max              -2.71429
Q2 Predictions Min              -3.11408
Q Targets Mean                  -2.90189
Q Targets Std                    0.11575
Q Targets Max                   -2.71153
Q Targets Min                   -3.15247
Bellman Errors 1 Mean            0.00020863
Bellman Errors 1 Std             0.00039205
Bellman Errors 1 Max             0.00198716
Bellman Errors 1 Min             1.3481e-09
Bellman Errors 2 Mean            0.000181608
Bellman Errors 2 Std             0.000345106
Bellman Errors 2 Max             0.00203569
Bellman Errors 2 Min             5.2934e-08
Policy Action Mean               0
Policy Action Std                1
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean               -0.063976
Test Rewards Std                 0.00229067
Test Rewards Max                -0.00723724
Test Rewards Min                -0.0641089
Test Returns Mean              -63.976
Test Returns Std                 0
Test Returns Max               -63.976
Test Returns Min               -63.976
Test Actions Mean                0
Test Actions Std                 1
Test Actions Max                 1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0626968
Exploration Rewards Std          0.00288603
Exploration Rewards Max         -0.00625356
Exploration Rewards Min         -0.0658386
Exploration Returns Mean       -62.6968
Exploration Returns Std          1.7639
Exploration Returns Max        -60.6516
Exploration Returns Min        -65.6979
Exploration Actions Mean         0.000218814
Exploration Actions Std          0.96164
Exploration Actions Max          1
Exploration Actions Min         -1
Final total_distance Mean        0.253197
Final total_distance Std         0
Final total_distance Max         0.253197
Final total_distance Min         0.253197
AverageReturn                  -63.976
Number of train steps total  45001
Number of env steps total    50000
Number of rollouts total        50
Train Time (s)                 668.033
(Previous) Eval Time (s)         0.831527
Sample Time (s)                  4.10766
Epoch Time (s)                 672.972
Total Train Time (s)          5879.6
Epoch                            9
---------------------------  ---------------
2020-05-18 00:20:14.380704 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #9 | Epoch Duration: 673.2621440887451
2020-05-18 00:20:14.380990 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #9 | Started Training: True
2020-05-18 00:31:23.871964 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #10 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         0.00024093
QF2 Loss                         0.000212411
Policy Loss                      3.35618
Q1 Predictions Mean             -3.34155
Q1 Predictions Std               0.119316
Q1 Predictions Max              -3.00945
Q1 Predictions Min              -3.5004
Q2 Predictions Mean             -3.34989
Q2 Predictions Std               0.119913
Q2 Predictions Max              -3.01348
Q2 Predictions Min              -3.50126
Q Targets Mean                  -3.34789
Q Targets Std                    0.114825
Q Targets Max                   -3.02066
Q Targets Min                   -3.54415
Bellman Errors 1 Mean            0.00024093
Bellman Errors 1 Std             0.000523886
Bellman Errors 1 Max             0.00294715
Bellman Errors 1 Min             8.0496e-10
Bellman Errors 2 Mean            0.000212411
Bellman Errors 2 Std             0.000356007
Bellman Errors 2 Max             0.00183915
Bellman Errors 2 Min             6.70409e-08
Policy Action Mean               0
Policy Action Std                1
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean               -0.063976
Test Rewards Std                 0.00229067
Test Rewards Max                -0.00723724
Test Rewards Min                -0.0641089
Test Returns Mean              -63.976
Test Returns Std                 0
Test Returns Max               -63.976
Test Returns Min               -63.976
Test Actions Mean                0
Test Actions Std                 1
Test Actions Max                 1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0636937
Exploration Rewards Std          0.00307991
Exploration Rewards Max         -0.0061835
Exploration Rewards Min         -0.0677163
Exploration Returns Mean       -63.6937
Exploration Returns Std          2.00461
Exploration Returns Max        -61.8342
Exploration Returns Min        -67.5648
Exploration Actions Mean        -0.000581355
Exploration Actions Std          0.961733
Exploration Actions Max          1
Exploration Actions Min         -1
Final total_distance Mean        0.253197
Final total_distance Std         0
Final total_distance Max         0.253197
Final total_distance Min         0.253197
AverageReturn                  -63.976
Number of train steps total  50001
Number of env steps total    55000
Number of rollouts total        55
Train Time (s)                 665.247
(Previous) Eval Time (s)         0.965812
Sample Time (s)                  4.08863
Epoch Time (s)                 670.301
Total Train Time (s)          6549.78
Epoch                           10
---------------------------  ---------------
2020-05-18 00:31:24.712119 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #10 | Epoch Duration: 670.3308145999908
2020-05-18 00:31:24.712458 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #10 | Started Training: True
2020-05-18 00:42:41.280027 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #11 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         0.000286055
QF2 Loss                         0.000385383
Policy Loss                      3.78071
Q1 Predictions Mean             -3.75448
Q1 Predictions Std               0.115446
Q1 Predictions Max              -3.29392
Q1 Predictions Min              -3.95277
Q2 Predictions Mean             -3.74894
Q2 Predictions Std               0.116751
Q2 Predictions Max              -3.28114
Q2 Predictions Min              -3.94569
Q Targets Mean                  -3.75961
Q Targets Std                    0.114235
Q Targets Max                   -3.30893
Q Targets Min                   -3.9895
Bellman Errors 1 Mean            0.000286055
Bellman Errors 1 Std             0.000840199
Bellman Errors 1 Max             0.00762563
Bellman Errors 1 Min             6.87805e-10
Bellman Errors 2 Mean            0.000385383
Bellman Errors 2 Std             0.00102997
Bellman Errors 2 Max             0.00881985
Bellman Errors 2 Min             1.84173e-09
Policy Action Mean               0
Policy Action Std                1
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean               -0.063976
Test Rewards Std                 0.00229067
Test Rewards Max                -0.00723724
Test Rewards Min                -0.0641089
Test Returns Mean              -63.976
Test Returns Std                 0
Test Returns Max               -63.976
Test Returns Min               -63.976
Test Actions Mean                0
Test Actions Std                 1
Test Actions Max                 1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0638847
Exploration Rewards Std          0.00252654
Exploration Rewards Max         -0.00611428
Exploration Rewards Min         -0.0651031
Exploration Returns Mean       -63.8847
Exploration Returns Std          0.685679
Exploration Returns Max        -62.9519
Exploration Returns Min        -64.9604
Exploration Actions Mean        -9.4366e-05
Exploration Actions Std          0.961937
Exploration Actions Max          1
Exploration Actions Min         -1
Final total_distance Mean        0.253197
Final total_distance Std         0
Final total_distance Max         0.253197
Final total_distance Min         0.253197
AverageReturn                  -63.976
Number of train steps total  55001
Number of env steps total    60000
Number of rollouts total        60
Train Time (s)                 672.324
(Previous) Eval Time (s)         0.843531
Sample Time (s)                  4.08936
Epoch Time (s)                 677.257
Total Train Time (s)          7227.07
Epoch                           11
---------------------------  ---------------
2020-05-18 00:42:42.152777 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #11 | Epoch Duration: 677.4400835037231
2020-05-18 00:42:42.153010 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #11 | Started Training: True
2020-05-18 00:53:42.158198 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #12 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         0.000303876
QF2 Loss                         0.000299185
Policy Loss                      4.1071
Q1 Predictions Mean             -4.09459
Q1 Predictions Std               0.118589
Q1 Predictions Max              -3.89487
Q1 Predictions Min              -4.34277
Q2 Predictions Mean             -4.08637
Q2 Predictions Std               0.116078
Q2 Predictions Max              -3.88979
Q2 Predictions Min              -4.33658
Q Targets Mean                  -4.08954
Q Targets Std                    0.117743
Q Targets Max                   -3.86582
Q Targets Min                   -4.28093
Bellman Errors 1 Mean            0.000303876
Bellman Errors 1 Std             0.000710287
Bellman Errors 1 Max             0.0041016
Bellman Errors 1 Min             4.45652e-11
Bellman Errors 2 Mean            0.000299185
Bellman Errors 2 Std             0.000687778
Bellman Errors 2 Max             0.00482889
Bellman Errors 2 Min             2.40285e-07
Policy Action Mean               0
Policy Action Std                1
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean               -0.063976
Test Rewards Std                 0.00229067
Test Rewards Max                -0.00723724
Test Rewards Min                -0.0641089
Test Returns Mean              -63.976
Test Returns Std                 0
Test Returns Max               -63.976
Test Returns Min               -63.976
Test Actions Mean                0
Test Actions Std                 1
Test Actions Max                 1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0635287
Exploration Rewards Std          0.00294872
Exploration Rewards Max         -0.00598733
Exploration Rewards Min         -0.0663895
Exploration Returns Mean       -63.5287
Exploration Returns Std          1.76404
Exploration Returns Max        -61.012
Exploration Returns Min        -66.2403
Exploration Actions Mean        -7.16894e-06
Exploration Actions Std          0.962453
Exploration Actions Max          1
Exploration Actions Min         -1
Final total_distance Mean        0.253197
Final total_distance Std         0
Final total_distance Max         0.253197
Final total_distance Min         0.253197
AverageReturn                  -63.976
Number of train steps total  60001
Number of env steps total    65000
Number of rollouts total        65
Train Time (s)                 655.734
(Previous) Eval Time (s)         0.877774
Sample Time (s)                  4.11372
Epoch Time (s)                 660.726
Total Train Time (s)          7887.83
Epoch                           12
---------------------------  ---------------
2020-05-18 00:53:43.067331 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #12 | Epoch Duration: 660.9140253067017
2020-05-18 00:53:43.067662 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #12 | Started Training: True
2020-05-18 01:05:04.269832 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #13 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         0.000455435
QF2 Loss                         0.000494043
Policy Loss                      4.45373
Q1 Predictions Mean             -4.41733
Q1 Predictions Std               0.140494
Q1 Predictions Max              -3.78543
Q1 Predictions Min              -4.55441
Q2 Predictions Mean             -4.41816
Q2 Predictions Std               0.141942
Q2 Predictions Max              -3.78335
Q2 Predictions Min              -4.55533
Q Targets Mean                  -4.42454
Q Targets Std                    0.131662
Q Targets Max                   -3.83164
Q Targets Min                   -4.61737
Bellman Errors 1 Mean            0.000455435
Bellman Errors 1 Std             0.00111955
Bellman Errors 1 Max             0.0055411
Bellman Errors 1 Min             2.03274e-08
Bellman Errors 2 Mean            0.000494043
Bellman Errors 2 Std             0.00119199
Bellman Errors 2 Max             0.00607167
Bellman Errors 2 Min             1.24174e-07
Policy Action Mean               0
Policy Action Std                1
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean               -0.063976
Test Rewards Std                 0.00229067
Test Rewards Max                -0.00723724
Test Rewards Min                -0.0641089
Test Returns Mean              -63.976
Test Returns Std                 0
Test Returns Max               -63.976
Test Returns Min               -63.976
Test Actions Mean                0
Test Actions Std                 1
Test Actions Max                 1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0623068
Exploration Rewards Std          0.00251554
Exploration Rewards Max         -0.00602855
Exploration Rewards Min         -0.0637564
Exploration Returns Mean       -62.3068
Exploration Returns Std          1.04944
Exploration Returns Max        -60.584
Exploration Returns Min        -63.6225
Exploration Actions Mean        -0.000606021
Exploration Actions Std          0.961863
Exploration Actions Max          1
Exploration Actions Min         -1
Final total_distance Mean        0.253197
Final total_distance Std         0
Final total_distance Max         0.253197
Final total_distance Min         0.253197
AverageReturn                  -63.976
Number of train steps total  65001
Number of env steps total    70000
Number of rollouts total        70
Train Time (s)                 677.02
(Previous) Eval Time (s)         0.9126
Sample Time (s)                  4.02731
Epoch Time (s)                 681.96
Total Train Time (s)          8569.73
Epoch                           13
---------------------------  ---------------
2020-05-18 01:05:05.121314 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #13 | Epoch Duration: 682.0534222126007
2020-05-18 01:05:05.121553 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #13 | Started Training: True
2020-05-18 01:16:24.472332 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #14 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         0.000300483
QF2 Loss                         0.000220145
Policy Loss                      4.69342
Q1 Predictions Mean             -4.66528
Q1 Predictions Std               0.14673
Q1 Predictions Max              -4.39545
Q1 Predictions Min              -4.83208
Q2 Predictions Mean             -4.66466
Q2 Predictions Std               0.140512
Q2 Predictions Max              -4.40623
Q2 Predictions Min              -4.83145
Q Targets Mean                  -4.66717
Q Targets Std                    0.137986
Q Targets Max                   -4.37607
Q Targets Min                   -4.85521
Bellman Errors 1 Mean            0.000300483
Bellman Errors 1 Std             0.000718686
Bellman Errors 1 Max             0.00450875
Bellman Errors 1 Min             1.86636e-07
Bellman Errors 2 Mean            0.000220145
Bellman Errors 2 Std             0.000609114
Bellman Errors 2 Max             0.0033422
Bellman Errors 2 Min             2.41221e-09
Policy Action Mean               0
Policy Action Std                1
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean               -0.063976
Test Rewards Std                 0.00229067
Test Rewards Max                -0.00723724
Test Rewards Min                -0.0641089
Test Returns Mean              -63.976
Test Returns Std                 0
Test Returns Max               -63.976
Test Returns Min               -63.976
Test Actions Mean                0
Test Actions Std                 1
Test Actions Max                 1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0622956
Exploration Rewards Std          0.00261162
Exploration Rewards Max         -0.00667229
Exploration Rewards Min         -0.0638888
Exploration Returns Mean       -62.2956
Exploration Returns Std          1.35406
Exploration Returns Max        -59.8805
Exploration Returns Min        -63.7567
Exploration Actions Mean         0.000466322
Exploration Actions Std          0.962347
Exploration Actions Max          1
Exploration Actions Min         -1
Final total_distance Mean        0.253197
Final total_distance Std         0
Final total_distance Max         0.253197
Final total_distance Min         0.253197
AverageReturn                  -63.976
Number of train steps total  70001
Number of env steps total    75000
Number of rollouts total        75
Train Time (s)                 675.063
(Previous) Eval Time (s)         0.855192
Sample Time (s)                  4.13283
Epoch Time (s)                 680.051
Total Train Time (s)          9249.79
Epoch                           14
---------------------------  ---------------
2020-05-18 01:16:25.330252 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #14 | Epoch Duration: 680.208477973938
2020-05-18 01:16:25.330496 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #14 | Started Training: True
2020-05-18 01:27:41.865825 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #15 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         0.00036229
QF2 Loss                         0.000535451
Policy Loss                      4.93893
Q1 Predictions Mean             -4.91595
Q1 Predictions Std               0.144599
Q1 Predictions Max              -4.49773
Q1 Predictions Min              -5.18857
Q2 Predictions Mean             -4.8993
Q2 Predictions Std               0.140951
Q2 Predictions Max              -4.47966
Q2 Predictions Min              -5.18185
Q Targets Mean                  -4.9123
Q Targets Std                    0.145385
Q Targets Max                   -4.4757
Q Targets Min                   -5.22218
Bellman Errors 1 Mean            0.00036229
Bellman Errors 1 Std             0.000738582
Bellman Errors 1 Max             0.00405213
Bellman Errors 1 Min             1.336e-06
Bellman Errors 2 Mean            0.000535451
Bellman Errors 2 Std             0.00104193
Bellman Errors 2 Max             0.00542409
Bellman Errors 2 Min             4.3301e-09
Policy Action Mean               0
Policy Action Std                1
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean               -0.063976
Test Rewards Std                 0.00229067
Test Rewards Max                -0.00723724
Test Rewards Min                -0.0641089
Test Returns Mean              -63.976
Test Returns Std                 0
Test Returns Max               -63.976
Test Returns Min               -63.976
Test Actions Mean                0
Test Actions Std                 1
Test Actions Max                 1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0638623
Exploration Rewards Std          0.00254967
Exploration Rewards Max         -0.00675026
Exploration Rewards Min         -0.0651487
Exploration Returns Mean       -63.8623
Exploration Returns Std          0.53917
Exploration Returns Max        -63.1217
Exploration Returns Min        -64.6942
Exploration Actions Mean        -0.000323653
Exploration Actions Std          0.961989
Exploration Actions Max          1
Exploration Actions Min         -1
Final total_distance Mean        0.253197
Final total_distance Std         0
Final total_distance Max         0.253197
Final total_distance Min         0.253197
AverageReturn                  -63.976
Number of train steps total  75001
Number of env steps total    80000
Number of rollouts total        80
Train Time (s)                 672.43
(Previous) Eval Time (s)         0.861341
Sample Time (s)                  3.95204
Epoch Time (s)                 677.243
Total Train Time (s)          9927.04
Epoch                           15
---------------------------  ---------------
2020-05-18 01:27:42.728250 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #15 | Epoch Duration: 677.3975162506104
2020-05-18 01:27:42.728542 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #15 | Started Training: True
2020-05-18 01:38:54.517410 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #16 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         0.000306261
QF2 Loss                         0.000287332
Policy Loss                      5.14956
Q1 Predictions Mean             -5.13815
Q1 Predictions Std               0.143148
Q1 Predictions Max              -4.76053
Q1 Predictions Min              -5.56917
Q2 Predictions Mean             -5.14332
Q2 Predictions Std               0.141963
Q2 Predictions Max              -4.76856
Q2 Predictions Min              -5.6063
Q Targets Mean                  -5.14275
Q Targets Std                    0.147908
Q Targets Max                   -4.74489
Q Targets Min                   -5.59432
Bellman Errors 1 Mean            0.000306261
Bellman Errors 1 Std             0.000719719
Bellman Errors 1 Max             0.00436179
Bellman Errors 1 Min             1.42109e-10
Bellman Errors 2 Mean            0.000287332
Bellman Errors 2 Std             0.000616181
Bellman Errors 2 Max             0.00294997
Bellman Errors 2 Min             5.53337e-09
Policy Action Mean               0
Policy Action Std                1
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean               -0.063976
Test Rewards Std                 0.00229067
Test Rewards Max                -0.00723724
Test Rewards Min                -0.0641089
Test Returns Mean              -63.976
Test Returns Std                 0
Test Returns Max               -63.976
Test Returns Min               -63.976
Test Actions Mean                0
Test Actions Std                 1
Test Actions Max                 1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0620266
Exploration Rewards Std          0.00339582
Exploration Rewards Max         -0.00551677
Exploration Rewards Min         -0.0651967
Exploration Returns Mean       -62.0266
Exploration Returns Std          2.51381
Exploration Returns Max        -59.1506
Exploration Returns Min        -65.0564
Exploration Actions Mean        -0.000190396
Exploration Actions Std          0.962114
Exploration Actions Max          1
Exploration Actions Min         -1
Final total_distance Mean        0.253197
Final total_distance Std         0
Final total_distance Max         0.253197
Final total_distance Min         0.253197
AverageReturn                  -63.976
Number of train steps total  80001
Number of env steps total    85000
Number of rollouts total        85
Train Time (s)                 667.524
(Previous) Eval Time (s)         0.867043
Sample Time (s)                  4.10933
Epoch Time (s)                 672.5
Total Train Time (s)         10599.5
Epoch                           16
---------------------------  ---------------
2020-05-18 01:38:55.380178 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #16 | Epoch Duration: 672.6513929367065
2020-05-18 01:38:55.380431 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #16 | Started Training: True
2020-05-18 01:50:04.850674 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #17 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         0.000522081
QF2 Loss                         0.000408845
Policy Loss                      5.34724
Q1 Predictions Mean             -5.31765
Q1 Predictions Std               0.143565
Q1 Predictions Max              -4.95124
Q1 Predictions Min              -5.62083
Q2 Predictions Mean             -5.32296
Q2 Predictions Std               0.14337
Q2 Predictions Max              -4.96276
Q2 Predictions Min              -5.62344
Q Targets Mean                  -5.32822
Q Targets Std                    0.145225
Q Targets Max                   -4.97404
Q Targets Min                   -5.64214
Bellman Errors 1 Mean            0.000522081
Bellman Errors 1 Std             0.00106091
Bellman Errors 1 Max             0.00599685
Bellman Errors 1 Min             4.05876e-06
Bellman Errors 2 Mean            0.000408845
Bellman Errors 2 Std             0.0010214
Bellman Errors 2 Max             0.00699287
Bellman Errors 2 Min             9.02446e-10
Policy Action Mean               0
Policy Action Std                1
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean               -0.063976
Test Rewards Std                 0.00229067
Test Rewards Max                -0.00723724
Test Rewards Min                -0.0641089
Test Returns Mean              -63.976
Test Returns Std                 0
Test Returns Max               -63.976
Test Returns Min               -63.976
Test Actions Mean                0
Test Actions Std                 1
Test Actions Max                 1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0640165
Exploration Rewards Std          0.00251014
Exploration Rewards Max         -0.0071647
Exploration Rewards Min         -0.0651799
Exploration Returns Mean       -64.0165
Exploration Returns Std          0.907513
Exploration Returns Max        -62.7119
Exploration Returns Min        -65.0351
Exploration Actions Mean        -0.00036851
Exploration Actions Std          0.961391
Exploration Actions Max          1
Exploration Actions Min         -1
Final total_distance Mean        0.253197
Final total_distance Std         0
Final total_distance Max         0.253197
Final total_distance Min         0.253197
AverageReturn                  -63.976
Number of train steps total  85001
Number of env steps total    90000
Number of rollouts total        90
Train Time (s)                 665.222
(Previous) Eval Time (s)         0.866281
Sample Time (s)                  4.09048
Epoch Time (s)                 670.179
Total Train Time (s)         11269.7
Epoch                           17
---------------------------  ---------------
2020-05-18 01:50:05.713997 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #17 | Epoch Duration: 670.3333117961884
2020-05-18 01:50:05.714271 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #17 | Started Training: True
2020-05-18 02:01:29.567091 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #18 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         0.00035161
QF2 Loss                         0.000210884
Policy Loss                      5.4948
Q1 Predictions Mean             -5.50904
Q1 Predictions Std               0.142766
Q1 Predictions Max              -5.19922
Q1 Predictions Min              -5.88517
Q2 Predictions Mean             -5.50179
Q2 Predictions Std               0.139691
Q2 Predictions Max              -5.20027
Q2 Predictions Min              -5.89303
Q Targets Mean                  -5.49878
Q Targets Std                    0.138351
Q Targets Max                   -5.1655
Q Targets Min                   -5.90349
Bellman Errors 1 Mean            0.00035161
Bellman Errors 1 Std             0.000803366
Bellman Errors 1 Max             0.00720589
Bellman Errors 1 Min             4.29878e-07
Bellman Errors 2 Mean            0.000210884
Bellman Errors 2 Std             0.000793934
Bellman Errors 2 Max             0.007162
Bellman Errors 2 Min             1.74083e-07
Policy Action Mean               0
Policy Action Std                1
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean               -0.063976
Test Rewards Std                 0.00229067
Test Rewards Max                -0.00723724
Test Rewards Min                -0.0641089
Test Returns Mean              -63.976
Test Returns Std                 0
Test Returns Max               -63.976
Test Returns Min               -63.976
Test Actions Mean                0
Test Actions Std                 1
Test Actions Max                 1
Test Actions Min                -1
Num Paths                        5
Exploration Rewards Mean        -0.0620983
Exploration Rewards Std          0.00261608
Exploration Rewards Max         -0.00614129
Exploration Rewards Min         -0.064461
Exploration Returns Mean       -62.0983
Exploration Returns Std          0.933543
Exploration Returns Max        -60.5124
Exploration Returns Min        -63.0914
Exploration Actions Mean         0.00041793
Exploration Actions Std          0.961737
Exploration Actions Max          1
Exploration Actions Min         -1
Final total_distance Mean        0.253197
Final total_distance Std         0
Final total_distance Max         0.253197
Final total_distance Min         0.253197
AverageReturn                  -63.976
Number of train steps total  90001
Number of env steps total    95000
Number of rollouts total        95
Train Time (s)                 679.538
(Previous) Eval Time (s)         0.868499
Sample Time (s)                  4.1556
Epoch Time (s)                 684.562
Total Train Time (s)         11954.3
Epoch                           18
---------------------------  ---------------
2020-05-18 02:01:30.432367 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #18 | Epoch Duration: 684.7178401947021
2020-05-18 02:01:30.432604 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #18 | Started Training: True
2020-05-18 02:12:53.887456 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #19 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.00026812
QF2 Loss                          0.000238924
Policy Loss                       5.66037
Q1 Predictions Mean              -5.66083
Q1 Predictions Std                0.104851
Q1 Predictions Max               -5.41864
Q1 Predictions Min               -5.96628
Q2 Predictions Mean              -5.66174
Q2 Predictions Std                0.108752
Q2 Predictions Max               -5.40406
Q2 Predictions Min               -5.97731
Q Targets Mean                   -5.66203
Q Targets Std                     0.110914
Q Targets Max                    -5.38925
Q Targets Min                    -5.97446
Bellman Errors 1 Mean             0.00026812
Bellman Errors 1 Std              0.00085562
Bellman Errors 1 Max              0.00635285
Bellman Errors 1 Min              1.56638e-09
Bellman Errors 2 Mean             0.000238924
Bellman Errors 2 Std              0.000815205
Bellman Errors 2 Max              0.00507819
Bellman Errors 2 Min              1.91221e-10
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0629346
Exploration Rewards Std           0.00252585
Exploration Rewards Max          -0.00649481
Exploration Rewards Min          -0.0640017
Exploration Returns Mean        -62.9346
Exploration Returns Std           1.05503
Exploration Returns Max         -60.8722
Exploration Returns Min         -63.863
Exploration Actions Mean          0.000537169
Exploration Actions Std           0.961528
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total   95001
Number of env steps total    100000
Number of rollouts total        100
Train Time (s)                  679.231
(Previous) Eval Time (s)          0.868737
Sample Time (s)                   4.06942
Epoch Time (s)                  684.169
Total Train Time (s)          12638.4
Epoch                            19
---------------------------  ----------------
2020-05-18 02:12:54.704702 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #19 | Epoch Duration: 684.2718825340271
2020-05-18 02:12:54.704928 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #19 | Started Training: True
2020-05-18 02:24:13.330354 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #20 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000243326
QF2 Loss                          0.000151212
Policy Loss                       5.78228
Q1 Predictions Mean              -5.78401
Q1 Predictions Std                0.0860637
Q1 Predictions Max               -5.59863
Q1 Predictions Min               -5.97764
Q2 Predictions Mean              -5.78075
Q2 Predictions Std                0.0901468
Q2 Predictions Max               -5.58548
Q2 Predictions Min               -5.97718
Q Targets Mean                   -5.77688
Q Targets Std                     0.093648
Q Targets Max                    -5.54902
Q Targets Min                    -5.98105
Bellman Errors 1 Mean             0.000243326
Bellman Errors 1 Std              0.00059817
Bellman Errors 1 Max              0.00306978
Bellman Errors 1 Min              7.36691e-11
Bellman Errors 2 Mean             0.000151212
Bellman Errors 2 Std              0.00033751
Bellman Errors 2 Max              0.00165773
Bellman Errors 2 Min              1.73204e-08
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.063535
Exploration Rewards Std           0.00282614
Exploration Rewards Max          -0.00626056
Exploration Rewards Min          -0.0650793
Exploration Returns Mean        -63.535
Exploration Returns Std           1.55735
Exploration Returns Max         -60.7265
Exploration Returns Min         -64.8566
Exploration Actions Mean         -0.000182226
Exploration Actions Std           0.961539
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  100001
Number of env steps total    105000
Number of rollouts total        105
Train Time (s)                  674.355
(Previous) Eval Time (s)          0.820651
Sample Time (s)                   4.11429
Epoch Time (s)                  679.29
Total Train Time (s)          13317.7
Epoch                            20
---------------------------  ----------------
2020-05-18 02:24:14.166194 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #20 | Epoch Duration: 679.4610333442688
2020-05-18 02:24:14.166479 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #20 | Started Training: True
2020-05-18 02:35:15.038565 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #21 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000195829
QF2 Loss                          0.000167287
Policy Loss                       5.89515
Q1 Predictions Mean              -5.88426
Q1 Predictions Std                0.14642
Q1 Predictions Max               -5.54983
Q1 Predictions Min               -6.31771
Q2 Predictions Mean              -5.88593
Q2 Predictions Std                0.145052
Q2 Predictions Max               -5.55604
Q2 Predictions Min               -6.3199
Q Targets Mean                   -5.88774
Q Targets Std                     0.142879
Q Targets Max                    -5.54098
Q Targets Min                    -6.33478
Bellman Errors 1 Mean             0.000195829
Bellman Errors 1 Std              0.000640688
Bellman Errors 1 Max              0.0056086
Bellman Errors 1 Min              2.3575e-08
Bellman Errors 2 Mean             0.000167287
Bellman Errors 2 Std              0.000557436
Bellman Errors 2 Max              0.004838
Bellman Errors 2 Min              1.4918e-09
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.064589
Exploration Rewards Std           0.0034637
Exploration Rewards Max          -0.00681262
Exploration Rewards Min          -0.0690478
Exploration Returns Mean        -64.589
Exploration Returns Std           2.54202
Exploration Returns Max         -60.9616
Exploration Returns Min         -68.8924
Exploration Actions Mean         -0.000342181
Exploration Actions Std           0.962041
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  105001
Number of env steps total    110000
Number of rollouts total        110
Train Time (s)                  656.608
(Previous) Eval Time (s)          0.839374
Sample Time (s)                   4.10699
Epoch Time (s)                  661.554
Total Train Time (s)          13979.3
Epoch                            21
---------------------------  ----------------
2020-05-18 02:35:15.925157 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #21 | Epoch Duration: 661.7584493160248
2020-05-18 02:35:15.925393 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #21 | Started Training: True
2020-05-18 02:46:38.658189 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #22 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000167073
QF2 Loss                          0.000183124
Policy Loss                       5.96307
Q1 Predictions Mean              -5.95852
Q1 Predictions Std                0.181379
Q1 Predictions Max               -5.52699
Q1 Predictions Min               -6.29706
Q2 Predictions Mean              -5.96201
Q2 Predictions Std                0.183934
Q2 Predictions Max               -5.52742
Q2 Predictions Min               -6.31842
Q Targets Mean                   -5.95739
Q Targets Std                     0.184593
Q Targets Max                    -5.4814
Q Targets Min                    -6.28551
Bellman Errors 1 Mean             0.000167073
Bellman Errors 1 Std              0.000489384
Bellman Errors 1 Max              0.00308555
Bellman Errors 1 Min              1.96655e-09
Bellman Errors 2 Mean             0.000183124
Bellman Errors 2 Std              0.000452537
Bellman Errors 2 Max              0.00273968
Bellman Errors 2 Min              2.80147e-09
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0624121
Exploration Rewards Std           0.00290358
Exploration Rewards Max          -0.00614432
Exploration Rewards Min          -0.0651702
Exploration Returns Mean        -62.4121
Exploration Returns Std           1.36177
Exploration Returns Max         -60.5716
Exploration Returns Min         -64.2139
Exploration Actions Mean         -0.000211447
Exploration Actions Std           0.961163
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  110001
Number of env steps total    115000
Number of rollouts total        115
Train Time (s)                  678.447
(Previous) Eval Time (s)          0.89114
Sample Time (s)                   4.12621
Epoch Time (s)                  683.464
Total Train Time (s)          14662.7
Epoch                            22
---------------------------  ----------------
2020-05-18 02:46:39.502104 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #22 | Epoch Duration: 683.5764541625977
2020-05-18 02:46:39.502380 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #22 | Started Training: True
2020-05-18 02:58:05.279146 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #23 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000227057
QF2 Loss                          0.000252423
Policy Loss                       6.04238
Q1 Predictions Mean              -6.01973
Q1 Predictions Std                0.189063
Q1 Predictions Max               -5.50742
Q1 Predictions Min               -6.27783
Q2 Predictions Mean              -6.01481
Q2 Predictions Std                0.184956
Q2 Predictions Max               -5.51259
Q2 Predictions Min               -6.27556
Q Targets Mean                   -6.02042
Q Targets Std                     0.187957
Q Targets Max                    -5.47043
Q Targets Min                    -6.3047
Bellman Errors 1 Mean             0.000227057
Bellman Errors 1 Std              0.000619616
Bellman Errors 1 Max              0.00437522
Bellman Errors 1 Min              1.22382e-08
Bellman Errors 2 Mean             0.000252423
Bellman Errors 2 Std              0.00059614
Bellman Errors 2 Max              0.00346689
Bellman Errors 2 Min              3.30058e-08
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0629295
Exploration Rewards Std           0.00260347
Exploration Rewards Max          -0.00641051
Exploration Rewards Min          -0.0648527
Exploration Returns Mean        -62.9295
Exploration Returns Std           1.20771
Exploration Returns Max         -61.8822
Exploration Returns Min         -64.7109
Exploration Actions Mean          0.000142878
Exploration Actions Std           0.962007
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  115001
Number of env steps total    120000
Number of rollouts total        120
Train Time (s)                  681.537
(Previous) Eval Time (s)          0.847237
Sample Time (s)                   4.08512
Epoch Time (s)                  686.469
Total Train Time (s)          15349.2
Epoch                            23
---------------------------  ----------------
2020-05-18 02:58:06.098061 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #23 | Epoch Duration: 686.5954463481903
2020-05-18 02:58:06.098310 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #23 | Started Training: True
2020-05-18 03:09:30.862110 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #24 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000394595
QF2 Loss                          0.000265725
Policy Loss                       6.17151
Q1 Predictions Mean              -6.14049
Q1 Predictions Std                0.176096
Q1 Predictions Max               -5.57764
Q1 Predictions Min               -6.6095
Q2 Predictions Mean              -6.14905
Q2 Predictions Std                0.174426
Q2 Predictions Max               -5.59495
Q2 Predictions Min               -6.59223
Q Targets Mean                   -6.15509
Q Targets Std                     0.183682
Q Targets Max                    -5.5606
Q Targets Min                    -6.66037
Bellman Errors 1 Mean             0.000394595
Bellman Errors 1 Std              0.000642284
Bellman Errors 1 Max              0.00435442
Bellman Errors 1 Min              5.02268e-08
Bellman Errors 2 Mean             0.000265725
Bellman Errors 2 Std              0.00075436
Bellman Errors 2 Max              0.00464261
Bellman Errors 2 Min              1.92449e-09
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.063682
Exploration Rewards Std           0.00251171
Exploration Rewards Max          -0.00674386
Exploration Rewards Min          -0.0650716
Exploration Returns Mean        -63.682
Exploration Returns Std           0.977533
Exploration Returns Max         -62.1766
Exploration Returns Min         -64.9305
Exploration Actions Mean          0.00077475
Exploration Actions Std           0.961826
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  120001
Number of env steps total    125000
Number of rollouts total        125
Train Time (s)                  680.506
(Previous) Eval Time (s)          0.822512
Sample Time (s)                   4.10087
Epoch Time (s)                  685.43
Total Train Time (s)          16034.7
Epoch                            24
---------------------------  ----------------
2020-05-18 03:09:31.736636 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #24 | Epoch Duration: 685.6380808353424
2020-05-18 03:09:31.736880 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #24 | Started Training: True
2020-05-18 03:20:35.344851 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #25 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000198334
QF2 Loss                          0.000196307
Policy Loss                       6.18039
Q1 Predictions Mean              -6.18329
Q1 Predictions Std                0.285697
Q1 Predictions Max               -5.41289
Q1 Predictions Min               -6.87215
Q2 Predictions Mean              -6.18024
Q2 Predictions Std                0.287597
Q2 Predictions Max               -5.40482
Q2 Predictions Min               -6.87405
Q Targets Mean                   -6.18051
Q Targets Std                     0.287406
Q Targets Max                    -5.37659
Q Targets Min                    -6.88206
Bellman Errors 1 Mean             0.000198334
Bellman Errors 1 Std              0.000659821
Bellman Errors 1 Max              0.00557502
Bellman Errors 1 Min              3.80353e-08
Bellman Errors 2 Mean             0.000196307
Bellman Errors 2 Std              0.000766497
Bellman Errors 2 Max              0.00684596
Bellman Errors 2 Min              5.18435e-09
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0636302
Exploration Rewards Std           0.00247272
Exploration Rewards Max          -0.00606965
Exploration Rewards Min          -0.0650662
Exploration Returns Mean        -63.6302
Exploration Returns Std           0.888457
Exploration Returns Max         -62.4002
Exploration Returns Min         -64.9285
Exploration Actions Mean          0.000472088
Exploration Actions Std           0.961855
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  125001
Number of env steps total    130000
Number of rollouts total        130
Train Time (s)                  659.364
(Previous) Eval Time (s)          0.878282
Sample Time (s)                   4.08376
Epoch Time (s)                  664.326
Total Train Time (s)          16698.9
Epoch                            25
---------------------------  ----------------
2020-05-18 03:20:36.177546 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #25 | Epoch Duration: 664.4404487609863
2020-05-18 03:20:36.177772 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #25 | Started Training: True
2020-05-18 03:31:48.048413 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #26 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000553302
QF2 Loss                          0.000429406
Policy Loss                       6.27524
Q1 Predictions Mean              -6.26643
Q1 Predictions Std                0.249462
Q1 Predictions Max               -5.51912
Q1 Predictions Min               -6.59023
Q2 Predictions Mean              -6.27314
Q2 Predictions Std                0.251437
Q2 Predictions Max               -5.52037
Q2 Predictions Min               -6.60162
Q Targets Mean                   -6.27561
Q Targets Std                     0.264626
Q Targets Max                    -5.44599
Q Targets Min                    -6.60974
Bellman Errors 1 Mean             0.000553302
Bellman Errors 1 Std              0.00112552
Bellman Errors 1 Max              0.00657156
Bellman Errors 1 Min              4.52283e-08
Bellman Errors 2 Mean             0.000429406
Bellman Errors 2 Std              0.00117163
Bellman Errors 2 Max              0.00683555
Bellman Errors 2 Min              1.02191e-08
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0625691
Exploration Rewards Std           0.00258355
Exploration Rewards Max          -0.00640459
Exploration Rewards Min          -0.0641978
Exploration Returns Mean        -62.5691
Exploration Returns Std           1.01663
Exploration Returns Max         -61.2477
Exploration Returns Min         -63.9254
Exploration Actions Mean         -0.000162133
Exploration Actions Std           0.961828
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  130001
Number of env steps total    135000
Number of rollouts total        135
Train Time (s)                  667.625
(Previous) Eval Time (s)          0.83627
Sample Time (s)                   4.08913
Epoch Time (s)                  672.551
Total Train Time (s)          17371.5
Epoch                            26
---------------------------  ----------------
2020-05-18 03:31:48.866181 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #26 | Epoch Duration: 672.6881885528564
2020-05-18 03:31:48.866417 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #26 | Started Training: True
2020-05-18 03:43:11.984534 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #27 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000690627
QF2 Loss                          0.000730301
Policy Loss                       6.40691
Q1 Predictions Mean              -6.40718
Q1 Predictions Std                0.287507
Q1 Predictions Max               -5.72755
Q1 Predictions Min               -7.83459
Q2 Predictions Mean              -6.4114
Q2 Predictions Std                0.292686
Q2 Predictions Max               -5.71005
Q2 Predictions Min               -7.82084
Q Targets Mean                   -6.40681
Q Targets Std                     0.289976
Q Targets Max                    -5.65843
Q Targets Min                    -7.80224
Bellman Errors 1 Mean             0.000690627
Bellman Errors 1 Std              0.00221029
Bellman Errors 1 Max              0.0175926
Bellman Errors 1 Min              2.1837e-09
Bellman Errors 2 Mean             0.000730301
Bellman Errors 2 Std              0.00256022
Bellman Errors 2 Max              0.0221272
Bellman Errors 2 Min              3.16059e-07
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0630967
Exploration Rewards Std           0.00283726
Exploration Rewards Max          -0.00681862
Exploration Rewards Min          -0.0656496
Exploration Returns Mean        -63.0967
Exploration Returns Std           1.68116
Exploration Returns Max         -60.9371
Exploration Returns Min         -65.507
Exploration Actions Mean          0.000638737
Exploration Actions Std           0.961749
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  135001
Number of env steps total    140000
Number of rollouts total        140
Train Time (s)                  678.872
(Previous) Eval Time (s)          0.821496
Sample Time (s)                   4.0913
Epoch Time (s)                  683.785
Total Train Time (s)          18055.3
Epoch                            27
---------------------------  ----------------
2020-05-18 03:43:12.814766 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #27 | Epoch Duration: 683.9481165409088
2020-05-18 03:43:12.815020 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #27 | Started Training: True
2020-05-18 03:54:33.849516 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #28 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000741181
QF2 Loss                          0.000609885
Policy Loss                       6.54775
Q1 Predictions Mean              -6.56458
Q1 Predictions Std                0.257509
Q1 Predictions Max               -5.92238
Q1 Predictions Min               -7.70156
Q2 Predictions Mean              -6.559
Q2 Predictions Std                0.254215
Q2 Predictions Max               -5.93416
Q2 Predictions Min               -7.70411
Q Targets Mean                   -6.55396
Q Targets Std                     0.255303
Q Targets Max                    -5.85176
Q Targets Min                    -7.71258
Bellman Errors 1 Mean             0.000741181
Bellman Errors 1 Std              0.00216702
Bellman Errors 1 Max              0.0201168
Bellman Errors 1 Min              7.30981e-08
Bellman Errors 2 Mean             0.000609885
Bellman Errors 2 Std              0.0019857
Bellman Errors 2 Max              0.0166008
Bellman Errors 2 Min              4.54313e-08
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0646027
Exploration Rewards Std           0.00301476
Exploration Rewards Max          -0.00705437
Exploration Rewards Min          -0.0670488
Exploration Returns Mean        -64.6027
Exploration Returns Std           1.90593
Exploration Returns Max         -61.5801
Exploration Returns Min         -66.9055
Exploration Actions Mean          1.86168e-05
Exploration Actions Std           0.961736
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  140001
Number of env steps total    145000
Number of rollouts total        145
Train Time (s)                  676.778
(Previous) Eval Time (s)          0.833991
Sample Time (s)                   4.10089
Epoch Time (s)                  681.712
Total Train Time (s)          18737
Epoch                            28
---------------------------  ----------------
2020-05-18 03:54:34.715606 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #28 | Epoch Duration: 681.9003603458405
2020-05-18 03:54:34.715848 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #28 | Started Training: True
2020-05-18 04:06:00.049106 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #29 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000757898
QF2 Loss                          0.000719188
Policy Loss                       6.59209
Q1 Predictions Mean              -6.57014
Q1 Predictions Std                0.212877
Q1 Predictions Max               -5.92527
Q1 Predictions Min               -7.19499
Q2 Predictions Mean              -6.5737
Q2 Predictions Std                0.212201
Q2 Predictions Max               -5.93987
Q2 Predictions Min               -7.20918
Q Targets Mean                   -6.57967
Q Targets Std                     0.215715
Q Targets Max                    -5.88732
Q Targets Min                    -7.29685
Bellman Errors 1 Mean             0.000757898
Bellman Errors 1 Std              0.00205203
Bellman Errors 1 Max              0.013956
Bellman Errors 1 Min              5.84462e-08
Bellman Errors 2 Mean             0.000719188
Bellman Errors 2 Std              0.00200035
Bellman Errors 2 Max              0.013269
Bellman Errors 2 Min              1.51398e-07
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0641314
Exploration Rewards Std           0.00245023
Exploration Rewards Max          -0.00668993
Exploration Rewards Min          -0.0655335
Exploration Returns Mean        -64.1314
Exploration Returns Std           0.688858
Exploration Returns Max         -63.3108
Exploration Returns Min         -65.3942
Exploration Actions Mean         -8.99591e-05
Exploration Actions Std           0.961266
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  145001
Number of env steps total    150000
Number of rollouts total        150
Train Time (s)                  681.2
(Previous) Eval Time (s)          0.869621
Sample Time (s)                   3.9814
Epoch Time (s)                  686.051
Total Train Time (s)          19423
Epoch                            29
---------------------------  ----------------
2020-05-18 04:06:00.885778 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #29 | Epoch Duration: 686.1696996688843
2020-05-18 04:06:00.886001 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #29 | Started Training: True
2020-05-18 04:17:08.586343 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #30 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.00131345
QF2 Loss                          0.00118458
Policy Loss                       6.6825
Q1 Predictions Mean              -6.66071
Q1 Predictions Std                0.202637
Q1 Predictions Max               -6.1496
Q1 Predictions Min               -7.25507
Q2 Predictions Mean              -6.66342
Q2 Predictions Std                0.19858
Q2 Predictions Max               -6.16515
Q2 Predictions Min               -7.26587
Q Targets Mean                   -6.67134
Q Targets Std                     0.193524
Q Targets Max                    -6.11325
Q Targets Min                    -7.25409
Bellman Errors 1 Mean             0.00131345
Bellman Errors 1 Std              0.0063722
Bellman Errors 1 Max              0.0617752
Bellman Errors 1 Min              6.38693e-10
Bellman Errors 2 Mean             0.00118458
Bellman Errors 2 Std              0.00561531
Bellman Errors 2 Max              0.0547374
Bellman Errors 2 Min              1.11413e-11
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0615139
Exploration Rewards Std           0.00237683
Exploration Rewards Max          -0.00619745
Exploration Rewards Min          -0.0629156
Exploration Returns Mean        -61.5139
Exploration Returns Std           0.811095
Exploration Returns Max         -60.4846
Exploration Returns Min         -62.7801
Exploration Actions Mean          0.000245752
Exploration Actions Std           0.961806
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  150001
Number of env steps total    155000
Number of rollouts total        155
Train Time (s)                  663.55
(Previous) Eval Time (s)          0.840294
Sample Time (s)                   3.99558
Epoch Time (s)                  668.386
Total Train Time (s)          20091.4
Epoch                            30
---------------------------  ----------------
2020-05-18 04:17:09.402879 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #30 | Epoch Duration: 668.5166640281677
2020-05-18 04:17:09.403102 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #30 | Started Training: True
2020-05-18 04:28:34.821574 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #31 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.00079582
QF2 Loss                          0.000723405
Policy Loss                       6.71948
Q1 Predictions Mean              -6.70181
Q1 Predictions Std                0.234642
Q1 Predictions Max               -6.1038
Q1 Predictions Min               -7.74836
Q2 Predictions Mean              -6.70446
Q2 Predictions Std                0.235485
Q2 Predictions Max               -6.105
Q2 Predictions Min               -7.75439
Q Targets Mean                   -6.7186
Q Targets Std                     0.231938
Q Targets Max                    -6.08213
Q Targets Min                    -7.81546
Bellman Errors 1 Mean             0.00079582
Bellman Errors 1 Std              0.00250922
Bellman Errors 1 Max              0.0193634
Bellman Errors 1 Min              3.17132e-07
Bellman Errors 2 Mean             0.000723405
Bellman Errors 2 Std              0.00243921
Bellman Errors 2 Max              0.0188791
Bellman Errors 2 Min              5.2948e-07
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0631263
Exploration Rewards Std           0.00266577
Exploration Rewards Max          -0.00717128
Exploration Rewards Min          -0.064852
Exploration Returns Mean        -63.1263
Exploration Returns Std           1.39089
Exploration Returns Max         -60.9527
Exploration Returns Min         -64.7152
Exploration Actions Mean          0.000492039
Exploration Actions Std           0.961654
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  155001
Number of env steps total    160000
Number of rollouts total        160
Train Time (s)                  681.233
(Previous) Eval Time (s)          0.821844
Sample Time (s)                   4.03
Epoch Time (s)                  686.085
Total Train Time (s)          20777.5
Epoch                            31
---------------------------  ----------------
2020-05-18 04:28:35.660272 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #31 | Epoch Duration: 686.2569320201874
2020-05-18 04:28:35.660528 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #31 | Started Training: True
2020-05-18 04:39:53.188536 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #32 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.00096848
QF2 Loss                          0.00081661
Policy Loss                       6.76241
Q1 Predictions Mean              -6.77564
Q1 Predictions Std                0.327175
Q1 Predictions Max               -5.83978
Q1 Predictions Min               -8.3351
Q2 Predictions Mean              -6.75949
Q2 Predictions Std                0.324702
Q2 Predictions Max               -5.83927
Q2 Predictions Min               -8.33637
Q Targets Mean                   -6.76375
Q Targets Std                     0.323561
Q Targets Max                    -5.83095
Q Targets Min                    -8.40055
Bellman Errors 1 Mean             0.00096848
Bellman Errors 1 Std              0.00242734
Bellman Errors 1 Max              0.0163148
Bellman Errors 1 Min              2.06936e-07
Bellman Errors 2 Mean             0.00081661
Bellman Errors 2 Std              0.00271365
Bellman Errors 2 Max              0.017713
Bellman Errors 2 Min              8.55744e-09
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0640064
Exploration Rewards Std           0.00270626
Exploration Rewards Max          -0.0068169
Exploration Rewards Min          -0.0660043
Exploration Returns Mean        -64.0064
Exploration Returns Std           1.37866
Exploration Returns Max         -61.7839
Exploration Returns Min         -65.8625
Exploration Actions Mean          0.000137275
Exploration Actions Std           0.961813
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  160001
Number of env steps total    165000
Number of rollouts total        165
Train Time (s)                  673.272
(Previous) Eval Time (s)          0.842301
Sample Time (s)                   4.09589
Epoch Time (s)                  678.21
Total Train Time (s)          21455.7
Epoch                            32
---------------------------  ----------------
2020-05-18 04:39:53.975940 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #32 | Epoch Duration: 678.3151714801788
2020-05-18 04:39:53.976213 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #32 | Started Training: True
2020-05-18 04:51:13.562006 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #33 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.00123488
QF2 Loss                          0.00137454
Policy Loss                       6.80829
Q1 Predictions Mean              -6.77385
Q1 Predictions Std                0.295813
Q1 Predictions Max               -5.95694
Q1 Predictions Min               -8.40471
Q2 Predictions Mean              -6.76729
Q2 Predictions Std                0.295595
Q2 Predictions Max               -5.95147
Q2 Predictions Min               -8.3935
Q Targets Mean                   -6.78265
Q Targets Std                     0.28677
Q Targets Max                    -5.89679
Q Targets Min                    -8.35394
Bellman Errors 1 Mean             0.00123488
Bellman Errors 1 Std              0.00350928
Bellman Errors 1 Max              0.0193397
Bellman Errors 1 Min              9.34235e-08
Bellman Errors 2 Mean             0.00137454
Bellman Errors 2 Std              0.00381846
Bellman Errors 2 Max              0.0209797
Bellman Errors 2 Min              4.45652e-11
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0637047
Exploration Rewards Std           0.00292713
Exploration Rewards Max          -0.00655687
Exploration Rewards Min          -0.0665245
Exploration Returns Mean        -63.7047
Exploration Returns Std           1.48829
Exploration Returns Max         -62.2309
Exploration Returns Min         -66.3785
Exploration Actions Mean         -0.000123117
Exploration Actions Std           0.962269
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  165001
Number of env steps total    170000
Number of rollouts total        170
Train Time (s)                  675.289
(Previous) Eval Time (s)          0.792422
Sample Time (s)                   4.1368
Epoch Time (s)                  680.218
Total Train Time (s)          22136
Epoch                            33
---------------------------  ----------------
2020-05-18 04:51:14.421623 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #33 | Epoch Duration: 680.4451804161072
2020-05-18 04:51:14.421854 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #33 | Started Training: True
2020-05-18 05:02:24.147662 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #34 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000114858
QF2 Loss                          0.000168293
Policy Loss                       6.90273
Q1 Predictions Mean              -6.89639
Q1 Predictions Std                0.176336
Q1 Predictions Max               -6.23353
Q1 Predictions Min               -7.60453
Q2 Predictions Mean              -6.89355
Q2 Predictions Std                0.178503
Q2 Predictions Max               -6.21894
Q2 Predictions Min               -7.63156
Q Targets Mean                   -6.89533
Q Targets Std                     0.17678
Q Targets Max                    -6.22698
Q Targets Min                    -7.56534
Bellman Errors 1 Mean             0.000114858
Bellman Errors 1 Std              0.000311781
Bellman Errors 1 Max              0.00165431
Bellman Errors 1 Min              7.54371e-08
Bellman Errors 2 Mean             0.000168293
Bellman Errors 2 Std              0.000566483
Bellman Errors 2 Max              0.00438443
Bellman Errors 2 Min              1.88288e-09
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0644788
Exploration Rewards Std           0.00265782
Exploration Rewards Max          -0.0057868
Exploration Rewards Min          -0.0660502
Exploration Returns Mean        -64.4788
Exploration Returns Std           1.10336
Exploration Returns Max         -63.1233
Exploration Returns Min         -65.9095
Exploration Actions Mean         -5.17199e-05
Exploration Actions Std           0.961881
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  170001
Number of env steps total    175000
Number of rollouts total        175
Train Time (s)                  665.625
(Previous) Eval Time (s)          0.863815
Sample Time (s)                   3.9495
Epoch Time (s)                  670.439
Total Train Time (s)          22806.4
Epoch                            34
---------------------------  ----------------
2020-05-18 05:02:25.011947 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #34 | Epoch Duration: 670.589866399765
2020-05-18 05:02:25.012176 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #34 | Started Training: True
2020-05-18 05:13:45.475564 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #35 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000395553
QF2 Loss                          0.000331112
Policy Loss                       6.91058
Q1 Predictions Mean              -6.89203
Q1 Predictions Std                0.0959462
Q1 Predictions Max               -6.54883
Q1 Predictions Min               -7.13945
Q2 Predictions Mean              -6.89618
Q2 Predictions Std                0.0973473
Q2 Predictions Max               -6.54623
Q2 Predictions Min               -7.14469
Q Targets Mean                   -6.90123
Q Targets Std                     0.100539
Q Targets Max                    -6.48907
Q Targets Min                    -7.14443
Bellman Errors 1 Mean             0.000395553
Bellman Errors 1 Std              0.000943005
Bellman Errors 1 Max              0.00481515
Bellman Errors 1 Min              2.88164e-08
Bellman Errors 2 Mean             0.000331112
Bellman Errors 2 Std              0.000835687
Bellman Errors 2 Max              0.00409516
Bellman Errors 2 Min              2.04636e-12
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0636948
Exploration Rewards Std           0.00271184
Exploration Rewards Max          -0.00641546
Exploration Rewards Min          -0.0651984
Exploration Returns Mean        -63.6948
Exploration Returns Std           1.28708
Exploration Returns Max         -61.4672
Exploration Returns Min         -65.0579
Exploration Actions Mean          0.000289771
Exploration Actions Std           0.962303
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  175001
Number of env steps total    180000
Number of rollouts total        180
Train Time (s)                  676.342
(Previous) Eval Time (s)          0.8678
Sample Time (s)                   3.96721
Epoch Time (s)                  681.177
Total Train Time (s)          23487.5
Epoch                            35
---------------------------  ----------------
2020-05-18 05:13:46.261796 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #35 | Epoch Duration: 681.2493751049042
2020-05-18 05:13:46.262075 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #35 | Started Training: True
2020-05-18 05:25:12.871744 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #36 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000155952
QF2 Loss                          0.00026174
Policy Loss                       6.91497
Q1 Predictions Mean              -6.92022
Q1 Predictions Std                0.112229
Q1 Predictions Max               -6.66607
Q1 Predictions Min               -7.47855
Q2 Predictions Mean              -6.92373
Q2 Predictions Std                0.112965
Q2 Predictions Max               -6.65755
Q2 Predictions Min               -7.45589
Q Targets Mean                   -6.91492
Q Targets Std                     0.109754
Q Targets Max                    -6.6492
Q Targets Min                    -7.4773
Bellman Errors 1 Mean             0.000155952
Bellman Errors 1 Std              0.00039164
Bellman Errors 1 Max              0.00298348
Bellman Errors 1 Min              6.60568e-08
Bellman Errors 2 Mean             0.00026174
Bellman Errors 2 Std              0.000430656
Bellman Errors 2 Max              0.00385184
Bellman Errors 2 Min              8.65475e-07
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0633708
Exploration Rewards Std           0.00282794
Exploration Rewards Max          -0.00611021
Exploration Rewards Min          -0.0657241
Exploration Returns Mean        -63.3708
Exploration Returns Std           1.57149
Exploration Returns Max         -61.0843
Exploration Returns Min         -65.5843
Exploration Actions Mean          0.000456625
Exploration Actions Std           0.962391
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  180001
Number of env steps total    185000
Number of rollouts total        185
Train Time (s)                  682.441
(Previous) Eval Time (s)          0.790926
Sample Time (s)                   4.01143
Epoch Time (s)                  687.243
Total Train Time (s)          24174.8
Epoch                            36
---------------------------  ----------------
2020-05-18 05:25:13.680426 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #36 | Epoch Duration: 687.4181241989136
2020-05-18 05:25:13.680664 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #36 | Started Training: True
2020-05-18 05:36:30.507197 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #37 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000370985
QF2 Loss                          0.000442205
Policy Loss                       6.91279
Q1 Predictions Mean              -6.92428
Q1 Predictions Std                0.0948594
Q1 Predictions Max               -6.74859
Q1 Predictions Min               -7.2443
Q2 Predictions Mean              -6.92728
Q2 Predictions Std                0.0950259
Q2 Predictions Max               -6.75032
Q2 Predictions Min               -7.24076
Q Targets Mean                   -6.91307
Q Targets Std                     0.0926493
Q Targets Max                    -6.72589
Q Targets Min                    -7.22788
Bellman Errors 1 Mean             0.000370985
Bellman Errors 1 Std              0.000428927
Bellman Errors 1 Max              0.00236689
Bellman Errors 1 Min              4.43745e-07
Bellman Errors 2 Mean             0.000442205
Bellman Errors 2 Std              0.000385942
Bellman Errors 2 Max              0.00283895
Bellman Errors 2 Min              1.65439e-07
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0636091
Exploration Rewards Std           0.00280426
Exploration Rewards Max          -0.00690522
Exploration Rewards Min          -0.065086
Exploration Returns Mean        -63.6091
Exploration Returns Std           1.55879
Exploration Returns Max         -60.9837
Exploration Returns Min         -64.9475
Exploration Actions Mean         -0.000505649
Exploration Actions Std           0.961825
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  185001
Number of env steps total    190000
Number of rollouts total        190
Train Time (s)                  672.711
(Previous) Eval Time (s)          0.811989
Sample Time (s)                   3.96219
Epoch Time (s)                  677.485
Total Train Time (s)          24852.3
Epoch                            37
---------------------------  ----------------
2020-05-18 05:36:31.316949 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #37 | Epoch Duration: 677.6360650062561
2020-05-18 05:36:31.317179 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #37 | Started Training: True
2020-05-18 05:48:00.368683 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #38 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000403573
QF2 Loss                          0.000421718
Policy Loss                       6.9189
Q1 Predictions Mean              -6.91456
Q1 Predictions Std                0.0903629
Q1 Predictions Max               -6.77881
Q1 Predictions Min               -7.27358
Q2 Predictions Mean              -6.901
Q2 Predictions Std                0.0897302
Q2 Predictions Max               -6.76893
Q2 Predictions Min               -7.25501
Q Targets Mean                   -6.90667
Q Targets Std                     0.0935385
Q Targets Max                    -6.76649
Q Targets Min                    -7.2758
Bellman Errors 1 Mean             0.000403573
Bellman Errors 1 Std              0.00249102
Bellman Errors 1 Max              0.0243817
Bellman Errors 1 Min              7.95103e-09
Bellman Errors 2 Mean             0.000421718
Bellman Errors 2 Std              0.00225381
Bellman Errors 2 Max              0.0221281
Bellman Errors 2 Min              8.0363e-09
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0623064
Exploration Rewards Std           0.00332907
Exploration Rewards Max          -0.00562882
Exploration Rewards Min          -0.0653203
Exploration Returns Mean        -62.3064
Exploration Returns Std           2.14014
Exploration Returns Max         -59.605
Exploration Returns Min         -65.1795
Exploration Actions Mean          0.000389879
Exploration Actions Std           0.962205
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  190001
Number of env steps total    195000
Number of rollouts total        195
Train Time (s)                  684.925
(Previous) Eval Time (s)          0.813319
Sample Time (s)                   3.97091
Epoch Time (s)                  689.709
Total Train Time (s)          25542
Epoch                            38
---------------------------  ----------------
2020-05-18 05:48:01.215638 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #38 | Epoch Duration: 689.8982274532318
2020-05-18 05:48:01.215895 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #38 | Started Training: True
2020-05-18 05:59:14.444982 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #39 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000513983
QF2 Loss                          0.000286215
Policy Loss                       6.87568
Q1 Predictions Mean              -6.89721
Q1 Predictions Std                0.0898669
Q1 Predictions Max               -6.77289
Q1 Predictions Min               -7.26541
Q2 Predictions Mean              -6.89011
Q2 Predictions Std                0.0894539
Q2 Predictions Max               -6.77057
Q2 Predictions Min               -7.2676
Q Targets Mean                   -6.88123
Q Targets Std                     0.0889528
Q Targets Max                    -6.75544
Q Targets Min                    -7.30024
Bellman Errors 1 Mean             0.000513983
Bellman Errors 1 Std              0.000382703
Bellman Errors 1 Max              0.00262202
Bellman Errors 1 Min              2.47348e-07
Bellman Errors 2 Mean             0.000286215
Bellman Errors 2 Std              0.000429784
Bellman Errors 2 Max              0.00309928
Bellman Errors 2 Min              1.16133e-08
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0633759
Exploration Rewards Std           0.00263144
Exploration Rewards Max          -0.00619701
Exploration Rewards Min          -0.0650093
Exploration Returns Mean        -63.3759
Exploration Returns Std           0.808768
Exploration Returns Max         -62.4204
Exploration Returns Min         -64.8617
Exploration Actions Mean          5.7961e-05
Exploration Actions Std           0.961861
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  195001
Number of env steps total    200000
Number of rollouts total        200
Train Time (s)                  669.045
(Previous) Eval Time (s)          0.852193
Sample Time (s)                   4.02969
Epoch Time (s)                  673.927
Total Train Time (s)          26215.9
Epoch                            39
---------------------------  ----------------
2020-05-18 05:59:15.298359 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #39 | Epoch Duration: 674.0822374820709
2020-05-18 05:59:15.298600 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #39 | Started Training: True
2020-05-18 06:10:31.864858 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #40 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000183766
QF2 Loss                          0.000185864
Policy Loss                       6.87662
Q1 Predictions Mean              -6.86879
Q1 Predictions Std                0.0689433
Q1 Predictions Max               -6.74256
Q1 Predictions Min               -7.06829
Q2 Predictions Mean              -6.86468
Q2 Predictions Std                0.0689099
Q2 Predictions Max               -6.74013
Q2 Predictions Min               -7.06482
Q Targets Mean                   -6.86426
Q Targets Std                     0.0730209
Q Targets Max                    -6.73317
Q Targets Min                    -7.06568
Bellman Errors 1 Mean             0.000183766
Bellman Errors 1 Std              0.000686157
Bellman Errors 1 Max              0.00639861
Bellman Errors 1 Min              9.74273e-09
Bellman Errors 2 Mean             0.000185864
Bellman Errors 2 Std              0.000714264
Bellman Errors 2 Max              0.00645994
Bellman Errors 2 Min              1.20281e-10
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0638703
Exploration Rewards Std           0.00268534
Exploration Rewards Max          -0.0063321
Exploration Rewards Min          -0.0658735
Exploration Returns Mean        -63.8703
Exploration Returns Std           1.3101
Exploration Returns Max         -61.7564
Exploration Returns Min         -65.7267
Exploration Actions Mean          1.03806e-05
Exploration Actions Std           0.962001
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  200001
Number of env steps total    205000
Number of rollouts total        205
Train Time (s)                  672.389
(Previous) Eval Time (s)          0.857041
Sample Time (s)                   4.01767
Epoch Time (s)                  677.263
Total Train Time (s)          26893.2
Epoch                            40
---------------------------  ----------------
2020-05-18 06:10:32.724850 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #40 | Epoch Duration: 677.4260263442993
2020-05-18 06:10:32.725076 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #40 | Started Training: True
2020-05-18 06:21:54.828232 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #41 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000118495
QF2 Loss                          0.000129285
Policy Loss                       6.85679
Q1 Predictions Mean              -6.85218
Q1 Predictions Std                0.0765497
Q1 Predictions Max               -6.74517
Q1 Predictions Min               -7.1793
Q2 Predictions Mean              -6.85632
Q2 Predictions Std                0.0768721
Q2 Predictions Max               -6.74796
Q2 Predictions Min               -7.18004
Q Targets Mean                   -6.85343
Q Targets Std                     0.0756997
Q Targets Max                    -6.73963
Q Targets Min                    -7.18468
Bellman Errors 1 Mean             0.000118495
Bellman Errors 1 Std              0.000389721
Bellman Errors 1 Max              0.00274557
Bellman Errors 1 Min              3.82215e-10
Bellman Errors 2 Mean             0.000129285
Bellman Errors 2 Std              0.000438487
Bellman Errors 2 Max              0.00325087
Bellman Errors 2 Min              1.22382e-08
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0626414
Exploration Rewards Std           0.00282559
Exploration Rewards Max          -0.00650324
Exploration Rewards Min          -0.0648443
Exploration Returns Mean        -62.6414
Exploration Returns Std           1.66377
Exploration Returns Max         -60.3831
Exploration Returns Min         -64.7036
Exploration Actions Mean         -0.000269164
Exploration Actions Std           0.96269
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  205001
Number of env steps total    210000
Number of rollouts total        210
Train Time (s)                  677.949
(Previous) Eval Time (s)          0.865636
Sample Time (s)                   4.00236
Epoch Time (s)                  682.817
Total Train Time (s)          27576
Epoch                            41
---------------------------  ----------------
2020-05-18 06:21:55.673312 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #41 | Epoch Duration: 682.948000907898
2020-05-18 06:21:55.673549 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #41 | Started Training: True
2020-05-18 06:33:15.486685 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #42 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000180189
QF2 Loss                          0.000261178
Policy Loss                       6.83698
Q1 Predictions Mean              -6.84162
Q1 Predictions Std                0.100302
Q1 Predictions Max               -6.70632
Q1 Predictions Min               -7.3821
Q2 Predictions Mean              -6.85194
Q2 Predictions Std                0.10092
Q2 Predictions Max               -6.71862
Q2 Predictions Min               -7.40677
Q Targets Mean                   -6.8426
Q Targets Std                     0.104341
Q Targets Max                    -6.70182
Q Targets Min                    -7.44491
Bellman Errors 1 Mean             0.000180189
Bellman Errors 1 Std              0.000643578
Bellman Errors 1 Max              0.00394611
Bellman Errors 1 Min              4.81123e-10
Bellman Errors 2 Mean             0.000261178
Bellman Errors 2 Std              0.000605109
Bellman Errors 2 Max              0.00470579
Bellman Errors 2 Min              1.20174e-07
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0621648
Exploration Rewards Std           0.00271507
Exploration Rewards Max          -0.00640837
Exploration Rewards Min          -0.0650645
Exploration Returns Mean        -62.1648
Exploration Returns Std           1.53811
Exploration Returns Max         -60.7853
Exploration Returns Min         -64.9279
Exploration Actions Mean          3.28346e-06
Exploration Actions Std           0.962339
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  210001
Number of env steps total    215000
Number of rollouts total        215
Train Time (s)                  675.654
(Previous) Eval Time (s)          0.848667
Sample Time (s)                   4.00209
Epoch Time (s)                  680.505
Total Train Time (s)          28256.6
Epoch                            42
---------------------------  ----------------
2020-05-18 06:33:16.437798 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #42 | Epoch Duration: 680.7640309333801
2020-05-18 06:33:16.438039 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #42 | Started Training: True
2020-05-18 06:44:20.448004 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #43 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000181045
QF2 Loss                          0.000256925
Policy Loss                       6.84518
Q1 Predictions Mean              -6.82189
Q1 Predictions Std                0.114461
Q1 Predictions Max               -6.67993
Q1 Predictions Min               -7.55687
Q2 Predictions Mean              -6.81755
Q2 Predictions Std                0.113625
Q2 Predictions Max               -6.65567
Q2 Predictions Min               -7.54526
Q Targets Mean                   -6.83048
Q Targets Std                     0.118564
Q Targets Max                    -6.63877
Q Targets Min                    -7.59313
Bellman Errors 1 Mean             0.000181045
Bellman Errors 1 Std              0.000302083
Bellman Errors 1 Max              0.00169341
Bellman Errors 1 Min              2.13182e-06
Bellman Errors 2 Mean             0.000256925
Bellman Errors 2 Std              0.000487774
Bellman Errors 2 Max              0.00425345
Bellman Errors 2 Min              1.6453e-08
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0624738
Exploration Rewards Std           0.00260395
Exploration Rewards Max          -0.00687647
Exploration Rewards Min          -0.0639544
Exploration Returns Mean        -62.4738
Exploration Returns Std           1.28472
Exploration Returns Max         -60.2238
Exploration Returns Min         -63.8212
Exploration Actions Mean         -0.000157948
Exploration Actions Std           0.962203
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  215001
Number of env steps total    220000
Number of rollouts total        220
Train Time (s)                  659.852
(Previous) Eval Time (s)          0.954528
Sample Time (s)                   4.00448
Epoch Time (s)                  664.811
Total Train Time (s)          28921.3
Epoch                            43
---------------------------  ----------------
2020-05-18 06:44:21.236271 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #43 | Epoch Duration: 664.7979965209961
2020-05-18 06:44:21.236509 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #43 | Started Training: True
2020-05-18 06:55:37.396721 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #44 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.00019509
QF2 Loss                          0.000187384
Policy Loss                       6.83136
Q1 Predictions Mean              -6.81313
Q1 Predictions Std                0.102853
Q1 Predictions Max               -6.65244
Q1 Predictions Min               -7.31714
Q2 Predictions Mean              -6.81336
Q2 Predictions Std                0.104008
Q2 Predictions Max               -6.64166
Q2 Predictions Min               -7.31171
Q Targets Mean                   -6.82069
Q Targets Std                     0.104618
Q Targets Max                    -6.65343
Q Targets Min                    -7.3403
Bellman Errors 1 Mean             0.00019509
Bellman Errors 1 Std              0.000535806
Bellman Errors 1 Max              0.00424922
Bellman Errors 1 Min              4.43109e-07
Bellman Errors 2 Mean             0.000187384
Bellman Errors 2 Std              0.000498393
Bellman Errors 2 Max              0.00342189
Bellman Errors 2 Min              9.78042e-07
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0625251
Exploration Rewards Std           0.00270521
Exploration Rewards Max          -0.00591458
Exploration Rewards Min          -0.0644724
Exploration Returns Mean        -62.5251
Exploration Returns Std           1.20129
Exploration Returns Max         -60.8283
Exploration Returns Min         -64.3325
Exploration Actions Mean          0.000213365
Exploration Actions Std           0.961615
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  220001
Number of env steps total    225000
Number of rollouts total        225
Train Time (s)                  672.032
(Previous) Eval Time (s)          0.791885
Sample Time (s)                   3.97577
Epoch Time (s)                  676.8
Total Train Time (s)          29598.1
Epoch                            44
---------------------------  ----------------
2020-05-18 06:55:38.202346 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #44 | Epoch Duration: 676.9655656814575
2020-05-18 06:55:38.202711 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #44 | Started Training: True
2020-05-18 07:06:54.500513 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #45 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000371085
QF2 Loss                          0.000226505
Policy Loss                       6.78037
Q1 Predictions Mean              -6.79975
Q1 Predictions Std                0.0966552
Q1 Predictions Max               -6.60891
Q1 Predictions Min               -7.38567
Q2 Predictions Mean              -6.79445
Q2 Predictions Std                0.0946247
Q2 Predictions Max               -6.61007
Q2 Predictions Min               -7.35098
Q Targets Mean                   -6.78614
Q Targets Std                     0.0936908
Q Targets Max                    -6.55662
Q Targets Min                    -7.30708
Bellman Errors 1 Mean             0.000371085
Bellman Errors 1 Std              0.000909202
Bellman Errors 1 Max              0.00617563
Bellman Errors 1 Min              5.81008e-06
Bellman Errors 2 Mean             0.000226505
Bellman Errors 2 Std              0.000736485
Bellman Errors 2 Max              0.00614367
Bellman Errors 2 Min              1.68557e-07
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0628274
Exploration Rewards Std           0.0030218
Exploration Rewards Max          -0.00603646
Exploration Rewards Min          -0.0651287
Exploration Returns Mean        -62.8274
Exploration Returns Std           1.74591
Exploration Returns Max         -60.0525
Exploration Returns Min         -64.9577
Exploration Actions Mean         -0.000191869
Exploration Actions Std           0.962209
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  225001
Number of env steps total    230000
Number of rollouts total        230
Train Time (s)                  672.158
(Previous) Eval Time (s)          0.809044
Sample Time (s)                   3.98255
Epoch Time (s)                  676.95
Total Train Time (s)          30275.1
Epoch                            45
---------------------------  ----------------
2020-05-18 07:06:55.337381 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #45 | Epoch Duration: 677.1344127655029
2020-05-18 07:06:55.337690 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #45 | Started Training: True
2020-05-18 07:18:16.332865 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #46 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000109287
QF2 Loss                          0.000165659
Policy Loss                       6.78355
Q1 Predictions Mean              -6.77153
Q1 Predictions Std                0.086825
Q1 Predictions Max               -6.49944
Q1 Predictions Min               -7.02442
Q2 Predictions Mean              -6.76395
Q2 Predictions Std                0.0869549
Q2 Predictions Max               -6.48981
Q2 Predictions Min               -7.01834
Q Targets Mean                   -6.77112
Q Targets Std                     0.0826475
Q Targets Max                    -6.50905
Q Targets Min                    -7.02198
Bellman Errors 1 Mean             0.000109287
Bellman Errors 1 Std              0.00027811
Bellman Errors 1 Max              0.00139568
Bellman Errors 1 Min              1.0055e-07
Bellman Errors 2 Mean             0.000165659
Bellman Errors 2 Std              0.000453483
Bellman Errors 2 Max              0.00222403
Bellman Errors 2 Min              8.29482e-09
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0634336
Exploration Rewards Std           0.00276771
Exploration Rewards Max          -0.00622818
Exploration Rewards Min          -0.0649679
Exploration Returns Mean        -63.4336
Exploration Returns Std           1.50064
Exploration Returns Max         -60.9018
Exploration Returns Min         -64.8254
Exploration Actions Mean         -0.000262816
Exploration Actions Std           0.961834
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  230001
Number of env steps total    235000
Number of rollouts total        235
Train Time (s)                  676.836
(Previous) Eval Time (s)          0.841641
Sample Time (s)                   4.00606
Epoch Time (s)                  681.684
Total Train Time (s)          30956.7
Epoch                            46
---------------------------  ----------------
2020-05-18 07:18:17.163005 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #46 | Epoch Duration: 681.8250560760498
2020-05-18 07:18:17.163296 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #46 | Started Training: True
2020-05-18 07:29:34.269095 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #47 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000231703
QF2 Loss                          0.000249606
Policy Loss                       6.76539
Q1 Predictions Mean              -6.77926
Q1 Predictions Std                0.102031
Q1 Predictions Max               -6.48584
Q1 Predictions Min               -6.98114
Q2 Predictions Mean              -6.78452
Q2 Predictions Std                0.103498
Q2 Predictions Max               -6.48533
Q2 Predictions Min               -6.98972
Q Targets Mean                   -6.77832
Q Targets Std                     0.106701
Q Targets Max                    -6.4127
Q Targets Min                    -6.99697
Bellman Errors 1 Mean             0.000231703
Bellman Errors 1 Std              0.000925852
Bellman Errors 1 Max              0.00741668
Bellman Errors 1 Min              5.74823e-09
Bellman Errors 2 Mean             0.000249606
Bellman Errors 2 Std              0.000921266
Bellman Errors 2 Max              0.00751779
Bellman Errors 2 Min              2.05205e-09
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0632514
Exploration Rewards Std           0.00254303
Exploration Rewards Max          -0.00688135
Exploration Rewards Min          -0.0654481
Exploration Returns Mean        -63.2514
Exploration Returns Std           1.12019
Exploration Returns Max         -61.8988
Exploration Returns Min         -65.3106
Exploration Actions Mean         -0.000313
Exploration Actions Std           0.962054
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  235001
Number of env steps total    240000
Number of rollouts total        240
Train Time (s)                  672.893
(Previous) Eval Time (s)          0.833619
Sample Time (s)                   4.05227
Epoch Time (s)                  677.779
Total Train Time (s)          31634.5
Epoch                            47
---------------------------  ----------------
2020-05-18 07:29:35.075366 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #47 | Epoch Duration: 677.9118251800537
2020-05-18 07:29:35.075616 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #47 | Started Training: True
2020-05-18 07:40:49.382659 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #48 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000348989
QF2 Loss                          0.000426592
Policy Loss                       6.78455
Q1 Predictions Mean              -6.79979
Q1 Predictions Std                0.13759
Q1 Predictions Max               -6.52776
Q1 Predictions Min               -7.54128
Q2 Predictions Mean              -6.80383
Q2 Predictions Std                0.136704
Q2 Predictions Max               -6.53842
Q2 Predictions Min               -7.54065
Q Targets Mean                   -6.79402
Q Targets Std                     0.139255
Q Targets Max                    -6.49358
Q Targets Min                    -7.53126
Bellman Errors 1 Mean             0.000348989
Bellman Errors 1 Std              0.000810068
Bellman Errors 1 Max              0.00462417
Bellman Errors 1 Min              2.06003e-08
Bellman Errors 2 Mean             0.000426592
Bellman Errors 2 Std              0.00094045
Bellman Errors 2 Max              0.00515746
Bellman Errors 2 Min              5.23943e-07
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.063201
Exploration Rewards Std           0.00237407
Exploration Rewards Max          -0.00556363
Exploration Rewards Min          -0.0642333
Exploration Returns Mean        -63.201
Exploration Returns Std           0.491759
Exploration Returns Max         -62.7096
Exploration Returns Min         -64.0994
Exploration Actions Mean         -0.00010403
Exploration Actions Std           0.961585
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  240001
Number of env steps total    245000
Number of rollouts total        245
Train Time (s)                  670.093
(Previous) Eval Time (s)          0.809834
Sample Time (s)                   4.05437
Epoch Time (s)                  674.957
Total Train Time (s)          32309.5
Epoch                            48
---------------------------  ----------------
2020-05-18 07:40:50.229943 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #48 | Epoch Duration: 675.1540880203247
2020-05-18 07:40:50.230204 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #48 | Started Training: True
2020-05-18 07:52:18.622767 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #49 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000322437
QF2 Loss                          0.000345025
Policy Loss                       6.79547
Q1 Predictions Mean              -6.79729
Q1 Predictions Std                0.120335
Q1 Predictions Max               -6.56778
Q1 Predictions Min               -7.42748
Q2 Predictions Mean              -6.79912
Q2 Predictions Std                0.12053
Q2 Predictions Max               -6.56618
Q2 Predictions Min               -7.42183
Q Targets Mean                   -6.79559
Q Targets Std                     0.11835
Q Targets Max                    -6.5384
Q Targets Min                    -7.44326
Bellman Errors 1 Mean             0.000322437
Bellman Errors 1 Std              0.000954869
Bellman Errors 1 Max              0.00615877
Bellman Errors 1 Min              6.10098e-08
Bellman Errors 2 Mean             0.000345025
Bellman Errors 2 Std              0.000930622
Bellman Errors 2 Max              0.00576792
Bellman Errors 2 Min              8.18545e-10
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.062242
Exploration Rewards Std           0.00281074
Exploration Rewards Max          -0.00666538
Exploration Rewards Min          -0.064445
Exploration Returns Mean        -62.242
Exploration Returns Std           1.70306
Exploration Returns Max         -59.7024
Exploration Returns Min         -64.3106
Exploration Actions Mean          0.000128189
Exploration Actions Std           0.962499
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  245001
Number of env steps total    250000
Number of rollouts total        250
Train Time (s)                  684.11
(Previous) Eval Time (s)          0.850751
Sample Time (s)                   4.1276
Epoch Time (s)                  689.088
Total Train Time (s)          32998.6
Epoch                            49
---------------------------  ----------------
2020-05-18 07:52:19.491195 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #49 | Epoch Duration: 689.2607591152191
2020-05-18 07:52:19.491440 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #49 | Started Training: True
2020-05-18 08:03:51.692700 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #50 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000252929
QF2 Loss                          0.000292526
Policy Loss                       6.77704
Q1 Predictions Mean              -6.76231
Q1 Predictions Std                0.0955298
Q1 Predictions Max               -6.51596
Q1 Predictions Min               -7.03189
Q2 Predictions Mean              -6.76097
Q2 Predictions Std                0.0970893
Q2 Predictions Max               -6.50992
Q2 Predictions Min               -7.03243
Q Targets Mean                   -6.76832
Q Targets Std                     0.0944167
Q Targets Max                    -6.48818
Q Targets Min                    -7.06241
Bellman Errors 1 Mean             0.000252929
Bellman Errors 1 Std              0.000852771
Bellman Errors 1 Max              0.00596668
Bellman Errors 1 Min              3.16595e-09
Bellman Errors 2 Mean             0.000292526
Bellman Errors 2 Std              0.0010014
Bellman Errors 2 Max              0.00693661
Bellman Errors 2 Min              2.41221e-09
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.063638
Exploration Rewards Std           0.00254475
Exploration Rewards Max          -0.00623936
Exploration Rewards Min          -0.0649639
Exploration Returns Mean        -63.638
Exploration Returns Std           0.686919
Exploration Returns Max         -62.4109
Exploration Returns Min         -64.2291
Exploration Actions Mean         -6.17679e-05
Exploration Actions Std           0.962049
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  250001
Number of env steps total    255000
Number of rollouts total        255
Train Time (s)                  687.86
(Previous) Eval Time (s)          0.872013
Sample Time (s)                   4.17748
Epoch Time (s)                  692.91
Total Train Time (s)          33691.5
Epoch                            50
---------------------------  ----------------
2020-05-18 08:03:52.522034 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #50 | Epoch Duration: 693.0303723812103
2020-05-18 08:03:52.522254 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #50 | Started Training: True
2020-05-18 08:15:21.213286 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #51 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000167071
QF2 Loss                          0.000139645
Policy Loss                       6.77383
Q1 Predictions Mean              -6.78426
Q1 Predictions Std                0.100661
Q1 Predictions Max               -6.50152
Q1 Predictions Min               -7.15695
Q2 Predictions Mean              -6.78246
Q2 Predictions Std                0.100167
Q2 Predictions Max               -6.50379
Q2 Predictions Min               -7.14938
Q Targets Mean                   -6.77595
Q Targets Std                     0.102504
Q Targets Max                    -6.45124
Q Targets Min                    -7.11322
Bellman Errors 1 Mean             0.000167071
Bellman Errors 1 Std              0.000391175
Bellman Errors 1 Max              0.00328931
Bellman Errors 1 Min              1.02191e-08
Bellman Errors 2 Mean             0.000139645
Bellman Errors 2 Std              0.000402218
Bellman Errors 2 Max              0.00358439
Bellman Errors 2 Min              3.53862e-06
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.06353
Exploration Rewards Std           0.00283775
Exploration Rewards Max          -0.00630797
Exploration Rewards Min          -0.0662648
Exploration Returns Mean        -63.53
Exploration Returns Std           1.41246
Exploration Returns Max         -62.2147
Exploration Returns Min         -66.1229
Exploration Actions Mean          0.000974795
Exploration Actions Std           0.962067
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  255001
Number of env steps total    260000
Number of rollouts total        260
Train Time (s)                  684.371
(Previous) Eval Time (s)          0.832797
Sample Time (s)                   4.15871
Epoch Time (s)                  689.363
Total Train Time (s)          34380.8
Epoch                            51
---------------------------  ----------------
2020-05-18 08:15:22.033871 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #51 | Epoch Duration: 689.5113892555237
2020-05-18 08:15:22.034109 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #51 | Started Training: True
2020-05-18 08:26:25.155752 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #52 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000518046
QF2 Loss                          0.000371402
Policy Loss                       6.7491
Q1 Predictions Mean              -6.73466
Q1 Predictions Std                0.124436
Q1 Predictions Max               -6.37243
Q1 Predictions Min               -6.98788
Q2 Predictions Mean              -6.73934
Q2 Predictions Std                0.123532
Q2 Predictions Max               -6.38032
Q2 Predictions Min               -6.99352
Q Targets Mean                   -6.75177
Q Targets Std                     0.122631
Q Targets Max                    -6.35111
Q Targets Min                    -7.0025
Bellman Errors 1 Mean             0.000518046
Bellman Errors 1 Std              0.000957754
Bellman Errors 1 Max              0.00493788
Bellman Errors 1 Min              1.29661e-06
Bellman Errors 2 Mean             0.000371402
Bellman Errors 2 Std              0.00078854
Bellman Errors 2 Max              0.00412726
Bellman Errors 2 Min              1.01946e-05
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0625324
Exploration Rewards Std           0.00279047
Exploration Rewards Max          -0.00711125
Exploration Rewards Min          -0.0652993
Exploration Returns Mean        -62.5324
Exploration Returns Std           1.67499
Exploration Returns Max         -60.0023
Exploration Returns Min         -65.1641
Exploration Actions Mean         -0.000225485
Exploration Actions Std           0.961365
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  260001
Number of env steps total    265000
Number of rollouts total        265
Train Time (s)                  658.796
(Previous) Eval Time (s)          0.824161
Sample Time (s)                   4.16886
Epoch Time (s)                  663.789
Total Train Time (s)          35044.6
Epoch                            52
---------------------------  ----------------
2020-05-18 08:26:25.991605 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #52 | Epoch Duration: 663.9572732448578
2020-05-18 08:26:25.991848 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #52 | Started Training: True
2020-05-18 08:38:00.292413 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #53 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000246143
QF2 Loss                          0.000192885
Policy Loss                       6.76262
Q1 Predictions Mean              -6.76491
Q1 Predictions Std                0.0801164
Q1 Predictions Max               -6.45832
Q1 Predictions Min               -7.29846
Q2 Predictions Mean              -6.76356
Q2 Predictions Std                0.0804221
Q2 Predictions Max               -6.44454
Q2 Predictions Min               -7.28197
Q Targets Mean                   -6.76308
Q Targets Std                     0.0793139
Q Targets Max                    -6.42335
Q Targets Min                    -7.21039
Bellman Errors 1 Mean             0.000246143
Bellman Errors 1 Std              0.00104961
Bellman Errors 1 Max              0.00775606
Bellman Errors 1 Min              1.33159e-08
Bellman Errors 2 Mean             0.000192885
Bellman Errors 2 Std              0.000776139
Bellman Errors 2 Max              0.00512382
Bellman Errors 2 Min              1.96655e-09
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0619952
Exploration Rewards Std           0.00253898
Exploration Rewards Max          -0.00712616
Exploration Rewards Min          -0.0640042
Exploration Returns Mean        -61.9952
Exploration Returns Std           1.2323
Exploration Returns Max         -60.8892
Exploration Returns Min         -63.8706
Exploration Actions Mean         -0.000122047
Exploration Actions Std           0.962349
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  265001
Number of env steps total    270000
Number of rollouts total        270
Train Time (s)                  690.097
(Previous) Eval Time (s)          0.839251
Sample Time (s)                   4.04178
Epoch Time (s)                  694.978
Total Train Time (s)          35739.6
Epoch                            53
---------------------------  ----------------
2020-05-18 08:38:01.083216 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #53 | Epoch Duration: 695.091078042984
2020-05-18 08:38:01.083616 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #53 | Started Training: True
2020-05-18 08:49:32.644630 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #54 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000289781
QF2 Loss                          0.000335054
Policy Loss                       6.78124
Q1 Predictions Mean              -6.78192
Q1 Predictions Std                0.0985462
Q1 Predictions Max               -6.59363
Q1 Predictions Min               -7.17747
Q2 Predictions Mean              -6.78586
Q2 Predictions Std                0.0974592
Q2 Predictions Max               -6.59823
Q2 Predictions Min               -7.18029
Q Targets Mean                   -6.78085
Q Targets Std                     0.104912
Q Targets Max                    -6.52178
Q Targets Min                    -7.18487
Bellman Errors 1 Mean             0.000289781
Bellman Errors 1 Std              0.000935742
Bellman Errors 1 Max              0.00636327
Bellman Errors 1 Min              2.31378e-08
Bellman Errors 2 Mean             0.000335054
Bellman Errors 2 Std              0.00105413
Bellman Errors 2 Max              0.0071287
Bellman Errors 2 Min              1.89905e-08
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0631231
Exploration Rewards Std           0.00267833
Exploration Rewards Max          -0.00701934
Exploration Rewards Min          -0.0651037
Exploration Returns Mean        -63.1231
Exploration Returns Std           1.37341
Exploration Returns Max         -61.1475
Exploration Returns Min         -64.9659
Exploration Actions Mean          0.000559322
Exploration Actions Std           0.962079
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  270001
Number of env steps total    275000
Number of rollouts total        275
Train Time (s)                  687.336
(Previous) Eval Time (s)          0.794451
Sample Time (s)                   4.06229
Epoch Time (s)                  692.193
Total Train Time (s)          36431.8
Epoch                            54
---------------------------  ----------------
2020-05-18 08:49:33.451478 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #54 | Epoch Duration: 692.3676254749298
2020-05-18 08:49:33.451766 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #54 | Started Training: True
2020-05-18 09:01:06.075955 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #55 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000350986
QF2 Loss                          0.000378798
Policy Loss                       6.73867
Q1 Predictions Mean              -6.74375
Q1 Predictions Std                0.0912495
Q1 Predictions Max               -6.51586
Q1 Predictions Min               -7.07178
Q2 Predictions Mean              -6.74675
Q2 Predictions Std                0.0930982
Q2 Predictions Max               -6.51523
Q2 Predictions Min               -7.08101
Q Targets Mean                   -6.73596
Q Targets Std                     0.0973623
Q Targets Max                    -6.44762
Q Targets Min                    -7.01642
Bellman Errors 1 Mean             0.000350986
Bellman Errors 1 Std              0.000925512
Bellman Errors 1 Max              0.00546413
Bellman Errors 1 Min              3.91594e-08
Bellman Errors 2 Mean             0.000378798
Bellman Errors 2 Std              0.000916529
Bellman Errors 2 Max              0.00534697
Bellman Errors 2 Min              3.82215e-08
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0606218
Exploration Rewards Std           0.00265922
Exploration Rewards Max          -0.00526733
Exploration Rewards Min          -0.0626833
Exploration Returns Mean        -60.6218
Exploration Returns Std           1.49872
Exploration Returns Max         -58.6429
Exploration Returns Min         -62.5508
Exploration Actions Mean          0.000429623
Exploration Actions Std           0.961587
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  275001
Number of env steps total    280000
Number of rollouts total        280
Train Time (s)                  688.408
(Previous) Eval Time (s)          0.810298
Sample Time (s)                   4.05467
Epoch Time (s)                  693.273
Total Train Time (s)          37125.1
Epoch                            55
---------------------------  ----------------
2020-05-18 09:01:06.924968 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #55 | Epoch Duration: 693.4729607105255
2020-05-18 09:01:06.925231 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #55 | Started Training: True
2020-05-18 09:12:16.436205 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #56 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000189538
QF2 Loss                          0.00013293
Policy Loss                       6.75699
Q1 Predictions Mean              -6.76546
Q1 Predictions Std                0.10362
Q1 Predictions Max               -6.44496
Q1 Predictions Min               -7.39588
Q2 Predictions Mean              -6.76092
Q2 Predictions Std                0.102334
Q2 Predictions Max               -6.43373
Q2 Predictions Min               -7.36632
Q Targets Mean                   -6.75701
Q Targets Std                     0.106072
Q Targets Max                    -6.41427
Q Targets Min                    -7.41275
Bellman Errors 1 Mean             0.000189538
Bellman Errors 1 Std              0.000601339
Bellman Errors 1 Max              0.00557238
Bellman Errors 1 Min              2.14716e-06
Bellman Errors 2 Mean             0.00013293
Bellman Errors 2 Std              0.000492786
Bellman Errors 2 Max              0.00389291
Bellman Errors 2 Min              5.61633e-08
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0632988
Exploration Rewards Std           0.00275883
Exploration Rewards Max          -0.00590011
Exploration Rewards Min          -0.0651622
Exploration Returns Mean        -63.2988
Exploration Returns Std           1.48587
Exploration Returns Max         -61.2741
Exploration Returns Min         -65.0155
Exploration Actions Mean         -0.000341043
Exploration Actions Std           0.962296
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  280001
Number of env steps total    285000
Number of rollouts total        285
Train Time (s)                  665.311
(Previous) Eval Time (s)          0.852606
Sample Time (s)                   4.0402
Epoch Time (s)                  670.203
Total Train Time (s)          37795.3
Epoch                            56
---------------------------  ----------------
2020-05-18 09:12:17.282144 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #56 | Epoch Duration: 670.3566699028015
2020-05-18 09:12:17.282366 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #56 | Started Training: True
2020-05-18 09:23:36.056117 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #57 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000481991
QF2 Loss                          0.000450413
Policy Loss                       6.72266
Q1 Predictions Mean              -6.72933
Q1 Predictions Std                0.109244
Q1 Predictions Max               -6.35803
Q1 Predictions Min               -7.0496
Q2 Predictions Mean              -6.72685
Q2 Predictions Std                0.109366
Q2 Predictions Max               -6.35578
Q2 Predictions Min               -7.04747
Q Targets Mean                   -6.72234
Q Targets Std                     0.109149
Q Targets Max                    -6.3426
Q Targets Min                    -7.04115
Bellman Errors 1 Mean             0.000481991
Bellman Errors 1 Std              0.00329892
Bellman Errors 1 Max              0.0332582
Bellman Errors 1 Min              4.45413e-06
Bellman Errors 2 Mean             0.000450413
Bellman Errors 2 Std              0.00331628
Bellman Errors 2 Max              0.0333983
Bellman Errors 2 Min              4.68214e-07
Policy Action Mean                0
Policy Action Std                 1
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                -0.063976
Test Rewards Std                  0.00229067
Test Rewards Max                 -0.00723724
Test Rewards Min                 -0.0641089
Test Returns Mean               -63.976
Test Returns Std                  0
Test Returns Max                -63.976
Test Returns Min                -63.976
Test Actions Mean                 0
Test Actions Std                  1
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean         -0.0628369
Exploration Rewards Std           0.00319439
Exploration Rewards Max          -0.0061772
Exploration Rewards Min          -0.0667492
Exploration Returns Mean        -62.8369
Exploration Returns Std           2.22462
Exploration Returns Max         -60.089
Exploration Returns Min         -66.6039
Exploration Actions Mean          0.000123456
Exploration Actions Std           0.96233
Exploration Actions Max           1
Exploration Actions Min          -1
Final total_distance Mean         0.253197
Final total_distance Std          0
Final total_distance Max          0.253197
Final total_distance Min          0.253197
AverageReturn                   -63.976
Number of train steps total  285001
Number of env steps total    290000
Number of rollouts total        290
Train Time (s)                  674.532
(Previous) Eval Time (s)          0.849279
Sample Time (s)                   4.0785
Epoch Time (s)                  679.46
Total Train Time (s)          38474.7
Epoch                            57
---------------------------  ----------------
2020-05-18 09:23:36.887258 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #57 | Epoch Duration: 679.6046662330627
2020-05-18 09:23:36.887488 IST | [TD3_Experiment_2020_05_17_22_42_12_0000--s-0] Iteration #57 | Started Training: True
